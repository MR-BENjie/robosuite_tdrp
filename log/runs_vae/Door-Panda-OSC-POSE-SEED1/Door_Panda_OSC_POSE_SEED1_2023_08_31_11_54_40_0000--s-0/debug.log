2023-08-31 11:57:22.274932 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size             6000
trainer/QF1 Loss                 22.0841
trainer/QF2 Loss                 22.0629
trainer/Policy Loss              -4.63921
trainer/Q1 Predictions Mean      -0.00782699
trainer/Q1 Predictions Std        0.00124516
trainer/Q1 Predictions Max       -0.00404867
trainer/Q1 Predictions Min       -0.0106219
trainer/Q2 Predictions Mean      -0.00554833
trainer/Q2 Predictions Std        0.00118531
trainer/Q2 Predictions Max       -0.00221893
trainer/Q2 Predictions Min       -0.00925008
trainer/Q Targets Mean            4.65619
trainer/Q Targets Std             0.575405
trainer/Q Targets Max             6.71702
trainer/Q Targets Min             3.16324
trainer/Log Pis Mean             -4.64722
trainer/Log Pis Std               0.558452
trainer/Log Pis Max              -2.95492
trainer/Log Pis Min              -6.31954
trainer/Policy mu Mean           -0.000816608
trainer/Policy mu Std             0.00112264
trainer/Policy mu Max             0.00183647
trainer/Policy mu Min            -0.00322988
trainer/Policy log std Mean      -0.000102269
trainer/Policy log std Std        0.00108832
trainer/Policy log std Max        0.00209591
trainer/Policy log std Min       -0.00266523
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total    6000
exploration/num paths total      12
exploration/path length Mean    500
exploration/path length Std       0
exploration/path length Max     500
exploration/path length Min     500
exploration/Rewards Mean          0.00471733
exploration/Rewards Std           0.0093243
exploration/Rewards Max           0.203478
exploration/Rewards Min           0.000281505
exploration/Returns Mean          2.35867
exploration/Returns Std           2.26253
exploration/Returns Max           7.46226
exploration/Returns Min           0.698751
exploration/Actions Mean          0.00100945
exploration/Actions Std           0.627191
exploration/Actions Max           0.999397
exploration/Actions Min          -0.999869
exploration/Num Paths            10
exploration/Average Returns       2.35867
evaluation/num steps total     5000
evaluation/num paths total       10
evaluation/path length Mean     500
evaluation/path length Std        0
evaluation/path length Max      500
evaluation/path length Min      500
evaluation/Rewards Mean           0.00666728
evaluation/Rewards Std            0.00251217
evaluation/Rewards Max            0.0141427
evaluation/Rewards Min            0.00240105
evaluation/Returns Mean           3.33364
evaluation/Returns Std            0.575852
evaluation/Returns Max            4.42995
evaluation/Returns Min            2.75393
evaluation/ExplReturns Mean       3.33364
evaluation/ExplReturns Std        0.575852
evaluation/ExplReturns Max        4.42995
evaluation/ExplReturns Min        2.75393
evaluation/Actions Mean          -0.000804638
evaluation/Actions Std            0.00126711
evaluation/Actions Max            0.00124758
evaluation/Actions Min           -0.00256363
evaluation/Num Paths             10
evaluation/Average Returns        3.33364
time/data storing (s)             0.0295054
time/evaluation sampling (s)     64.9663
time/exploration sampling (s)    67.5162
time/logging (s)                  0.0248521
time/saving (s)                   0.0150458
time/training (s)                10.4374
time/epoch (s)                  142.989
time/total (s)                  162.756
Epoch                             0
-----------------------------  --------------
2023-08-31 11:59:43.786094 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   0.0558839
trainer/QF2 Loss                   0.0565069
trainer/Policy Loss              -22.3247
trainer/Q1 Predictions Mean       17.5482
trainer/Q1 Predictions Std         0.229269
trainer/Q1 Predictions Max        18.1045
trainer/Q1 Predictions Min        16.6515
trainer/Q2 Predictions Mean       17.543
trainer/Q2 Predictions Std         0.226218
trainer/Q2 Predictions Max        18.0734
trainer/Q2 Predictions Min        16.671
trainer/Q Targets Mean            17.4911
trainer/Q Targets Std              0.30885
trainer/Q Targets Max             18.7829
trainer/Q Targets Min             16.6172
trainer/Log Pis Mean              -4.79107
trainer/Log Pis Std                0.316851
trainer/Log Pis Max               -4.01269
trainer/Log Pis Min               -6.58284
trainer/Policy mu Mean            -0.00174765
trainer/Policy mu Std              0.00657146
trainer/Policy mu Max              0.0105111
trainer/Policy mu Min             -0.0200966
trainer/Policy log std Mean       -0.142039
trainer/Policy log std Std         0.00518641
trainer/Policy log std Max        -0.119513
trainer/Policy log std Min        -0.157895
trainer/Alpha                      0.74055
trainer/Alpha Loss                -3.53805
exploration/num steps total    11000
exploration/num paths total       22
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00194828
exploration/Rewards Std            0.00178018
exploration/Rewards Max            0.0185905
exploration/Rewards Min            0.00039364
exploration/Returns Mean           0.974141
exploration/Returns Std            0.35669
exploration/Returns Max            1.83927
exploration/Returns Min            0.704181
exploration/Actions Mean          -0.0051957
exploration/Actions Std            0.583039
exploration/Actions Max            0.998748
exploration/Actions Min           -0.997164
exploration/Num Paths             10
exploration/Average Returns        0.974141
evaluation/num steps total     10000
evaluation/num paths total        20
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0046466
evaluation/Rewards Std             0.00109004
evaluation/Rewards Max             0.00737993
evaluation/Rewards Min             0.00189869
evaluation/Returns Mean            2.3233
evaluation/Returns Std             0.397236
evaluation/Returns Max             3.09954
evaluation/Returns Min             1.75941
evaluation/ExplReturns Mean        2.3233
evaluation/ExplReturns Std         0.397236
evaluation/ExplReturns Max         3.09954
evaluation/ExplReturns Min         1.75941
evaluation/Actions Mean           -0.00195986
evaluation/Actions Std             0.0062171
evaluation/Actions Max             0.0078965
evaluation/Actions Min            -0.0162947
evaluation/Num Paths              10
evaluation/Average Returns         2.3233
time/data storing (s)              0.029422
time/evaluation sampling (s)      61.5105
time/exploration sampling (s)     69.0991
time/logging (s)                   0.0249088
time/saving (s)                    0.0641961
time/training (s)                 10.7795
time/epoch (s)                   141.508
time/total (s)                   304.266
Epoch                              1
-----------------------------  --------------
2023-08-31 12:02:03.366573 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 2 finished
-----------------------------  ---------------
replay_buffer/size             16000
trainer/QF1 Loss                   0.0275964
trainer/QF2 Loss                   0.0289205
trainer/Policy Loss              -34.4999
trainer/Q1 Predictions Mean       29.7301
trainer/Q1 Predictions Std         0.44939
trainer/Q1 Predictions Max        30.4509
trainer/Q1 Predictions Min        27.9844
trainer/Q2 Predictions Mean       29.7453
trainer/Q2 Predictions Std         0.441179
trainer/Q2 Predictions Max        30.4863
trainer/Q2 Predictions Min        28.0833
trainer/Q Targets Mean            29.6834
trainer/Q Targets Std              0.440807
trainer/Q Targets Max             30.7552
trainer/Q Targets Min             28.1434
trainer/Log Pis Mean              -4.78238
trainer/Log Pis Std                0.290165
trainer/Log Pis Max               -3.89794
trainer/Log Pis Min               -6.21149
trainer/Policy mu Mean             0.00039113
trainer/Policy mu Std              0.00755466
trainer/Policy mu Max              0.0238671
trainer/Policy mu Min             -0.0218739
trainer/Policy log std Mean       -0.132134
trainer/Policy log std Std         0.00712002
trainer/Policy log std Max        -0.110618
trainer/Policy log std Min        -0.154828
trainer/Alpha                      0.548616
trainer/Alpha Loss                -7.07009
exploration/num steps total    16000
exploration/num paths total       32
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00341595
exploration/Rewards Std            0.00672712
exploration/Rewards Max            0.0738695
exploration/Rewards Min            0.000317138
exploration/Returns Mean           1.70797
exploration/Returns Std            2.63058
exploration/Returns Max            9.58756
exploration/Returns Min            0.711044
exploration/Actions Mean           0.00274883
exploration/Actions Std            0.590294
exploration/Actions Max            0.999554
exploration/Actions Min           -0.999701
exploration/Num Paths             10
exploration/Average Returns        1.70797
evaluation/num steps total     15000
evaluation/num paths total        30
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00418648
evaluation/Rewards Std             0.00124762
evaluation/Rewards Max             0.00755494
evaluation/Rewards Min             0.00202451
evaluation/Returns Mean            2.09324
evaluation/Returns Std             0.581638
evaluation/Returns Max             3.66309
evaluation/Returns Min             1.58012
evaluation/ExplReturns Mean        2.09324
evaluation/ExplReturns Std         0.581638
evaluation/ExplReturns Max         3.66309
evaluation/ExplReturns Min         1.58012
evaluation/Actions Mean           -0.00134015
evaluation/Actions Std             0.0051176
evaluation/Actions Max             0.00733055
evaluation/Actions Min            -0.0113779
evaluation/Num Paths              10
evaluation/Average Returns         2.09324
time/data storing (s)              0.0297364
time/evaluation sampling (s)      61.4281
time/exploration sampling (s)     67.7116
time/logging (s)                   0.0251516
time/saving (s)                    0.0654604
time/training (s)                 10.3173
time/epoch (s)                   139.577
time/total (s)                   443.846
Epoch                              2
-----------------------------  ---------------
2023-08-31 12:04:24.356230 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 3 finished
-----------------------------  ---------------
replay_buffer/size             21000
trainer/QF1 Loss                   0.0322909
trainer/QF2 Loss                   0.0277987
trainer/Policy Loss              -43.0085
trainer/Q1 Predictions Mean       38.2625
trainer/Q1 Predictions Std         0.474876
trainer/Q1 Predictions Max        38.9785
trainer/Q1 Predictions Min        36.3
trainer/Q2 Predictions Mean       38.2913
trainer/Q2 Predictions Std         0.467016
trainer/Q2 Predictions Max        39.0228
trainer/Q2 Predictions Min        36.3818
trainer/Q Targets Mean            38.359
trainer/Q Targets Std              0.484209
trainer/Q Targets Max             39.3732
trainer/Q Targets Min             36.4214
trainer/Log Pis Mean              -4.7514
trainer/Log Pis Std                0.276743
trainer/Log Pis Max               -4.07604
trainer/Log Pis Min               -5.78874
trainer/Policy mu Mean             0.00239412
trainer/Policy mu Std              0.0207031
trainer/Policy mu Max              0.0564145
trainer/Policy mu Min             -0.0470119
trainer/Policy log std Mean       -0.135124
trainer/Policy log std Std         0.00723069
trainer/Policy log std Max        -0.11325
trainer/Policy log std Min        -0.159187
trainer/Alpha                      0.406424
trainer/Alpha Loss               -10.5769
exploration/num steps total    21000
exploration/num paths total       42
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00475706
exploration/Rewards Std            0.0124598
exploration/Rewards Max            0.179679
exploration/Rewards Min            0.00022009
exploration/Returns Mean           2.37853
exploration/Returns Std            3.14525
exploration/Returns Max            9.94443
exploration/Returns Min            0.712071
exploration/Actions Mean           0.00111375
exploration/Actions Std            0.58821
exploration/Actions Max            0.997353
exploration/Actions Min           -0.996287
exploration/Num Paths             10
exploration/Average Returns        2.37853
evaluation/num steps total     20000
evaluation/num paths total        40
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00389223
evaluation/Rewards Std             0.000953499
evaluation/Rewards Max             0.00637305
evaluation/Rewards Min             0.00201849
evaluation/Returns Mean            1.94612
evaluation/Returns Std             0.322368
evaluation/Returns Max             2.45123
evaluation/Returns Min             1.61599
evaluation/ExplReturns Mean        1.94612
evaluation/ExplReturns Std         0.322368
evaluation/ExplReturns Max         2.45123
evaluation/ExplReturns Min         1.61599
evaluation/Actions Mean            0.00227162
evaluation/Actions Std             0.0176215
evaluation/Actions Max             0.0368553
evaluation/Actions Min            -0.0333707
evaluation/Num Paths              10
evaluation/Average Returns         1.94612
time/data storing (s)              0.0293639
time/evaluation sampling (s)      61.6711
time/exploration sampling (s)     68.6016
time/logging (s)                   0.0251014
time/saving (s)                    0.0697282
time/training (s)                 10.5894
time/epoch (s)                   140.986
time/total (s)                   584.835
Epoch                              3
-----------------------------  ---------------
2023-08-31 12:06:47.627640 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 4 finished
-----------------------------  ---------------
replay_buffer/size             26000
trainer/QF1 Loss                   0.0111237
trainer/QF2 Loss                   0.0113498
trainer/Policy Loss              -48.7817
trainer/Q1 Predictions Mean       44.0138
trainer/Q1 Predictions Std         0.433948
trainer/Q1 Predictions Max        44.7894
trainer/Q1 Predictions Min        42.1471
trainer/Q2 Predictions Mean       44.0331
trainer/Q2 Predictions Std         0.427167
trainer/Q2 Predictions Max        44.8136
trainer/Q2 Predictions Min        42.228
trainer/Q Targets Mean            44.041
trainer/Q Targets Std              0.426189
trainer/Q Targets Max             44.8859
trainer/Q Targets Min             42.1827
trainer/Log Pis Mean              -4.77222
trainer/Log Pis Std                0.294883
trainer/Log Pis Max               -4.03155
trainer/Log Pis Min               -5.91389
trainer/Policy mu Mean            -0.00281854
trainer/Policy mu Std              0.0214032
trainer/Policy mu Max              0.0495351
trainer/Policy mu Min             -0.10078
trainer/Policy log std Mean       -0.138812
trainer/Policy log std Std         0.00795599
trainer/Policy log std Max        -0.120731
trainer/Policy log std Min        -0.165751
trainer/Alpha                      0.301104
trainer/Alpha Loss               -14.1267
exploration/num steps total    26000
exploration/num paths total       52
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00218598
exploration/Rewards Std            0.00220145
exploration/Rewards Max            0.0340113
exploration/Rewards Min            1.03658e-05
exploration/Returns Mean           1.09299
exploration/Returns Std            0.595915
exploration/Returns Max            2.69093
exploration/Returns Min            0.710196
exploration/Actions Mean          -0.00250727
exploration/Actions Std            0.585093
exploration/Actions Max            0.999256
exploration/Actions Min           -0.998878
exploration/Num Paths             10
exploration/Average Returns        1.09299
evaluation/num steps total     25000
evaluation/num paths total        50
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00222106
evaluation/Rewards Std             0.000414786
evaluation/Rewards Max             0.00455868
evaluation/Rewards Min             0.0016132
evaluation/Returns Mean            1.11053
evaluation/Returns Std             0.111015
evaluation/Returns Max             1.29235
evaluation/Returns Min             0.986907
evaluation/ExplReturns Mean        1.11053
evaluation/ExplReturns Std         0.111015
evaluation/ExplReturns Max         1.29235
evaluation/ExplReturns Min         0.986907
evaluation/Actions Mean           -0.00391773
evaluation/Actions Std             0.0179509
evaluation/Actions Max             0.0317871
evaluation/Actions Min            -0.0734447
evaluation/Num Paths              10
evaluation/Average Returns         1.11053
time/data storing (s)              0.0294851
time/evaluation sampling (s)      62.1179
time/exploration sampling (s)     68.0485
time/logging (s)                   0.0251985
time/saving (s)                    0.0809419
time/training (s)                 12.9662
time/epoch (s)                   143.268
time/total (s)                   728.106
Epoch                              4
-----------------------------  ---------------
2023-08-31 12:09:08.490381 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 5 finished
-----------------------------  ---------------
replay_buffer/size             31000
trainer/QF1 Loss                   0.00773575
trainer/QF2 Loss                   0.00817054
trainer/Policy Loss              -52.2383
trainer/Q1 Predictions Mean       47.4932
trainer/Q1 Predictions Std         0.43915
trainer/Q1 Predictions Max        48.183
trainer/Q1 Predictions Min        45.229
trainer/Q2 Predictions Mean       47.4787
trainer/Q2 Predictions Std         0.437261
trainer/Q2 Predictions Max        48.1396
trainer/Q2 Predictions Min        45.2315
trainer/Q Targets Mean            47.4829
trainer/Q Targets Std              0.448777
trainer/Q Targets Max             48.2064
trainer/Q Targets Min             45.0471
trainer/Log Pis Mean              -4.77307
trainer/Log Pis Std                0.295731
trainer/Log Pis Max               -3.9804
trainer/Log Pis Min               -5.75321
trainer/Policy mu Mean             0.000494619
trainer/Policy mu Std              0.0365839
trainer/Policy mu Max              0.118911
trainer/Policy mu Min             -0.149727
trainer/Policy log std Mean       -0.130555
trainer/Policy log std Std         0.00789786
trainer/Policy log std Max        -0.110639
trainer/Policy log std Min        -0.151603
trainer/Alpha                      0.223069
trainer/Alpha Loss               -17.6593
exploration/num steps total    31000
exploration/num paths total       62
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00282347
exploration/Rewards Std            0.00370669
exploration/Rewards Max            0.0485395
exploration/Rewards Min            0.000251966
exploration/Returns Mean           1.41173
exploration/Returns Std            1.0706
exploration/Returns Max            4.07838
exploration/Returns Min            0.715018
exploration/Actions Mean          -0.000233935
exploration/Actions Std            0.589389
exploration/Actions Max            0.997822
exploration/Actions Min           -0.998461
exploration/Num Paths             10
exploration/Average Returns        1.41173
evaluation/num steps total     30000
evaluation/num paths total        60
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0023498
evaluation/Rewards Std             0.000538458
evaluation/Rewards Max             0.00537051
evaluation/Rewards Min             0.00145206
evaluation/Returns Mean            1.1749
evaluation/Returns Std             0.136483
evaluation/Returns Max             1.39955
evaluation/Returns Min             1.00711
evaluation/ExplReturns Mean        1.1749
evaluation/ExplReturns Std         0.136483
evaluation/ExplReturns Max         1.39955
evaluation/ExplReturns Min         1.00711
evaluation/Actions Mean            0.00166159
evaluation/Actions Std             0.0283445
evaluation/Actions Max             0.0532501
evaluation/Actions Min            -0.102177
evaluation/Num Paths              10
evaluation/Average Returns         1.1749
time/data storing (s)              0.0292658
time/evaluation sampling (s)      61.6022
time/exploration sampling (s)     68.1402
time/logging (s)                   0.0254949
time/saving (s)                    0.0748734
time/training (s)                 10.9876
time/epoch (s)                   140.86
time/total (s)                   868.969
Epoch                              5
-----------------------------  ---------------
2023-08-31 12:11:31.564454 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 6 finished
-----------------------------  ---------------
replay_buffer/size             36000
trainer/QF1 Loss                   0.00598609
trainer/QF2 Loss                   0.00731829
trainer/Policy Loss              -54.0907
trainer/Q1 Predictions Mean       49.3198
trainer/Q1 Predictions Std         0.393266
trainer/Q1 Predictions Max        50.028
trainer/Q1 Predictions Min        47.4965
trainer/Q2 Predictions Mean       49.3439
trainer/Q2 Predictions Std         0.393299
trainer/Q2 Predictions Max        50.1559
trainer/Q2 Predictions Min        47.4881
trainer/Q Targets Mean            49.3204
trainer/Q Targets Std              0.399848
trainer/Q Targets Max             50.0654
trainer/Q Targets Min             47.5179
trainer/Log Pis Mean              -4.77063
trainer/Log Pis Std                0.311205
trainer/Log Pis Max               -4.12715
trainer/Log Pis Min               -6.78033
trainer/Policy mu Mean            -0.00538559
trainer/Policy mu Std              0.0436825
trainer/Policy mu Max              0.119848
trainer/Policy mu Min             -0.178381
trainer/Policy log std Mean       -0.131959
trainer/Policy log std Std         0.00851131
trainer/Policy log std Max        -0.110653
trainer/Policy log std Min        -0.161204
trainer/Alpha                      0.165266
trainer/Alpha Loss               -21.1859
exploration/num steps total    36000
exploration/num paths total       72
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00165406
exploration/Rewards Std            0.00102917
exploration/Rewards Max            0.0181205
exploration/Rewards Min            0.000418824
exploration/Returns Mean           0.827031
exploration/Returns Std            0.149003
exploration/Returns Max            1.09407
exploration/Returns Min            0.707433
exploration/Actions Mean           0.0010009
exploration/Actions Std            0.587606
exploration/Actions Max            0.999425
exploration/Actions Min           -0.997042
exploration/Num Paths             10
exploration/Average Returns        0.827031
evaluation/num steps total     35000
evaluation/num paths total        70
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00995682
evaluation/Rewards Std             0.0108718
evaluation/Rewards Max             0.0527813
evaluation/Rewards Min             0.00139401
evaluation/Returns Mean            4.97841
evaluation/Returns Std             0.948255
evaluation/Returns Max             6.3927
evaluation/Returns Min             3.52786
evaluation/ExplReturns Mean        4.97841
evaluation/ExplReturns Std         0.948255
evaluation/ExplReturns Max         6.3927
evaluation/ExplReturns Min         3.52786
evaluation/Actions Mean           -0.00261519
evaluation/Actions Std             0.0331944
evaluation/Actions Max             0.067796
evaluation/Actions Min            -0.14408
evaluation/Num Paths              10
evaluation/Average Returns         4.97841
time/data storing (s)              0.029628
time/evaluation sampling (s)      63.1164
time/exploration sampling (s)     69.2268
time/logging (s)                   0.0251569
time/saving (s)                    0.0645486
time/training (s)                 10.6078
time/epoch (s)                   143.07
time/total (s)                  1012.04
Epoch                              6
-----------------------------  ---------------
2023-08-31 12:13:53.237635 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 7 finished
-----------------------------  ---------------
replay_buffer/size             41000
trainer/QF1 Loss                   0.00531288
trainer/QF2 Loss                   0.00539019
trainer/Policy Loss              -54.6592
trainer/Q1 Predictions Mean       49.906
trainer/Q1 Predictions Std         0.48103
trainer/Q1 Predictions Max        50.7228
trainer/Q1 Predictions Min        47.8716
trainer/Q2 Predictions Mean       49.8957
trainer/Q2 Predictions Std         0.478093
trainer/Q2 Predictions Max        50.6654
trainer/Q2 Predictions Min        47.8287
trainer/Q Targets Mean            49.9346
trainer/Q Targets Std              0.476895
trainer/Q Targets Max             50.7409
trainer/Q Targets Min             47.9539
trainer/Log Pis Mean              -4.77081
trainer/Log Pis Std                0.394853
trainer/Log Pis Max               -3.70787
trainer/Log Pis Min               -6.58939
trainer/Policy mu Mean             0.00115783
trainer/Policy mu Std              0.0583508
trainer/Policy mu Max              0.221031
trainer/Policy mu Min             -0.211533
trainer/Policy log std Mean       -0.125588
trainer/Policy log std Std         0.00948184
trainer/Policy log std Max        -0.0930393
trainer/Policy log std Min        -0.152891
trainer/Alpha                      0.12244
trainer/Alpha Loss               -24.7167
exploration/num steps total    41000
exploration/num paths total       82
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00266753
exploration/Rewards Std            0.00292289
exploration/Rewards Max            0.0271257
exploration/Rewards Min            0.000415748
exploration/Returns Mean           1.33377
exploration/Returns Std            0.831772
exploration/Returns Max            3.31829
exploration/Returns Min            0.742166
exploration/Actions Mean           0.00435748
exploration/Actions Std            0.590743
exploration/Actions Max            0.9991
exploration/Actions Min           -0.999697
exploration/Num Paths             10
exploration/Average Returns        1.33377
evaluation/num steps total     40000
evaluation/num paths total        80
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0054493
evaluation/Rewards Std             0.00285052
evaluation/Rewards Max             0.0142085
evaluation/Rewards Min             0.00152556
evaluation/Returns Mean            2.72465
evaluation/Returns Std             0.586756
evaluation/Returns Max             4.24397
evaluation/Returns Min             2.1556
evaluation/ExplReturns Mean        2.72465
evaluation/ExplReturns Std         0.586756
evaluation/ExplReturns Max         4.24397
evaluation/ExplReturns Min         2.1556
evaluation/Actions Mean            0.00134519
evaluation/Actions Std             0.035164
evaluation/Actions Max             0.0710971
evaluation/Actions Min            -0.168399
evaluation/Num Paths              10
evaluation/Average Returns         2.72465
time/data storing (s)              0.0299888
time/evaluation sampling (s)      62.331
time/exploration sampling (s)     68.2132
time/logging (s)                   0.0253311
time/saving (s)                    0.0835002
time/training (s)                 10.9868
time/epoch (s)                   141.67
time/total (s)                  1153.71
Epoch                              7
-----------------------------  ---------------
2023-08-31 12:16:15.884339 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 8 finished
-----------------------------  ---------------
replay_buffer/size             46000
trainer/QF1 Loss                   0.00279254
trainer/QF2 Loss                   0.00328977
trainer/Policy Loss              -54.5423
trainer/Q1 Predictions Mean       49.7488
trainer/Q1 Predictions Std         0.43743
trainer/Q1 Predictions Max        50.3932
trainer/Q1 Predictions Min        47.8427
trainer/Q2 Predictions Mean       49.7513
trainer/Q2 Predictions Std         0.437615
trainer/Q2 Predictions Max        50.3866
trainer/Q2 Predictions Min        47.8184
trainer/Q Targets Mean            49.742
trainer/Q Targets Std              0.437382
trainer/Q Targets Max             50.372
trainer/Q Targets Min             47.8827
trainer/Log Pis Mean              -4.801
trainer/Log Pis Std                0.374883
trainer/Log Pis Max               -3.7993
trainer/Log Pis Min               -6.46954
trainer/Policy mu Mean             0.000313215
trainer/Policy mu Std              0.0631051
trainer/Policy mu Max              0.287626
trainer/Policy mu Min             -0.187946
trainer/Policy log std Mean       -0.129995
trainer/Policy log std Std         0.00849765
trainer/Policy log std Max        -0.0961069
trainer/Policy log std Min        -0.159826
trainer/Alpha                      0.0907176
trainer/Alpha Loss               -28.3189
exploration/num steps total    46000
exploration/num paths total       92
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00229558
exploration/Rewards Std            0.00358406
exploration/Rewards Max            0.0713504
exploration/Rewards Min            0.00024846
exploration/Returns Mean           1.14779
exploration/Returns Std            0.554393
exploration/Returns Max            2.33562
exploration/Returns Min            0.69394
exploration/Actions Mean           0.00379045
exploration/Actions Std            0.590429
exploration/Actions Max            0.998476
exploration/Actions Min           -0.998455
exploration/Num Paths             10
exploration/Average Returns        1.14779
evaluation/num steps total     45000
evaluation/num paths total        90
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00588526
evaluation/Rewards Std             0.00226426
evaluation/Rewards Max             0.0122103
evaluation/Rewards Min             0.00168283
evaluation/Returns Mean            2.94263
evaluation/Returns Std             0.636381
evaluation/Returns Max             4.08569
evaluation/Returns Min             1.86894
evaluation/ExplReturns Mean        2.94263
evaluation/ExplReturns Std         0.636381
evaluation/ExplReturns Max         4.08569
evaluation/ExplReturns Min         1.86894
evaluation/Actions Mean           -0.00422455
evaluation/Actions Std             0.0382938
evaluation/Actions Max             0.083772
evaluation/Actions Min            -0.163527
evaluation/Num Paths              10
evaluation/Average Returns         2.94263
time/data storing (s)              0.0297974
time/evaluation sampling (s)      62.5802
time/exploration sampling (s)     69.5056
time/logging (s)                   0.0254991
time/saving (s)                    0.0688208
time/training (s)                 10.4335
time/epoch (s)                   142.643
time/total (s)                  1296.36
Epoch                              8
-----------------------------  ---------------
2023-08-31 12:18:38.781626 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 9 finished
-----------------------------  ---------------
replay_buffer/size             51000
trainer/QF1 Loss                   0.00290413
trainer/QF2 Loss                   0.00340003
trainer/Policy Loss              -53.7758
trainer/Q1 Predictions Mean       49.0456
trainer/Q1 Predictions Std         0.382012
trainer/Q1 Predictions Max        50.0372
trainer/Q1 Predictions Min        47.4035
trainer/Q2 Predictions Mean       49.0348
trainer/Q2 Predictions Std         0.378143
trainer/Q2 Predictions Max        50.0368
trainer/Q2 Predictions Min        47.3793
trainer/Q Targets Mean            49.0692
trainer/Q Targets Std              0.383874
trainer/Q Targets Max             50.0668
trainer/Q Targets Min             47.3285
trainer/Log Pis Mean              -4.74653
trainer/Log Pis Std                0.391864
trainer/Log Pis Max               -3.33746
trainer/Log Pis Min               -6.48637
trainer/Policy mu Mean             0.00301258
trainer/Policy mu Std              0.0866353
trainer/Policy mu Max              0.43772
trainer/Policy mu Min             -0.234969
trainer/Policy log std Mean       -0.127759
trainer/Policy log std Std         0.00936324
trainer/Policy log std Max        -0.0762673
trainer/Policy log std Min        -0.154295
trainer/Alpha                      0.0672194
trainer/Alpha Loss               -31.7097
exploration/num steps total    51000
exploration/num paths total      102
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00335056
exploration/Rewards Std            0.00578898
exploration/Rewards Max            0.105391
exploration/Rewards Min            0.000204186
exploration/Returns Mean           1.67528
exploration/Returns Std            1.251
exploration/Returns Max            4.50329
exploration/Returns Min            0.742951
exploration/Actions Mean           0.000874139
exploration/Actions Std            0.59371
exploration/Actions Max            0.99778
exploration/Actions Min           -0.99916
exploration/Num Paths             10
exploration/Average Returns        1.67528
evaluation/num steps total     50000
evaluation/num paths total       100
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0159559
evaluation/Rewards Std             0.0102008
evaluation/Rewards Max             0.0406771
evaluation/Rewards Min             0.00223094
evaluation/Returns Mean            7.97796
evaluation/Returns Std             1.9478
evaluation/Returns Max            10.4646
evaluation/Returns Min             5.33551
evaluation/ExplReturns Mean        7.97796
evaluation/ExplReturns Std         1.9478
evaluation/ExplReturns Max        10.4646
evaluation/ExplReturns Min         5.33551
evaluation/Actions Mean           -0.00950283
evaluation/Actions Std             0.0429639
evaluation/Actions Max             0.101487
evaluation/Actions Min            -0.189526
evaluation/Num Paths              10
evaluation/Average Returns         7.97796
time/data storing (s)              0.0297149
time/evaluation sampling (s)      61.8891
time/exploration sampling (s)     70.0726
time/logging (s)                   0.0252841
time/saving (s)                    0.069494
time/training (s)                 10.8074
time/epoch (s)                   142.894
time/total (s)                  1439.26
Epoch                              9
-----------------------------  ---------------
2023-08-31 12:21:01.643887 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 10 finished
-----------------------------  ---------------
replay_buffer/size             56000
trainer/QF1 Loss                   0.00277902
trainer/QF2 Loss                   0.00234538
trainer/Policy Loss              -52.598
trainer/Q1 Predictions Mean       47.886
trainer/Q1 Predictions Std         0.404681
trainer/Q1 Predictions Max        48.5289
trainer/Q1 Predictions Min        46.0986
trainer/Q2 Predictions Mean       47.878
trainer/Q2 Predictions Std         0.406562
trainer/Q2 Predictions Max        48.537
trainer/Q2 Predictions Min        46.0738
trainer/Q Targets Mean            47.8684
trainer/Q Targets Std              0.402803
trainer/Q Targets Max             48.4915
trainer/Q Targets Min             46.0868
trainer/Log Pis Mean              -4.72338
trainer/Log Pis Std                0.510029
trainer/Log Pis Max               -2.47592
trainer/Log Pis Min               -6.11969
trainer/Policy mu Mean            -0.00954157
trainer/Policy mu Std              0.112497
trainer/Policy mu Max              0.538331
trainer/Policy mu Min             -0.436163
trainer/Policy log std Mean       -0.123108
trainer/Policy log std Std         0.0126315
trainer/Policy log std Max        -0.0709436
trainer/Policy log std Min        -0.162915
trainer/Alpha                      0.049814
trainer/Alpha Loss               -35.1603
exploration/num steps total    56000
exploration/num paths total      112
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00533337
exploration/Rewards Std            0.00653022
exploration/Rewards Max            0.0537416
exploration/Rewards Min            0.000304347
exploration/Returns Mean           2.66669
exploration/Returns Std            2.77427
exploration/Returns Max            8.87636
exploration/Returns Min            0.695616
exploration/Actions Mean          -0.00614258
exploration/Actions Std            0.59227
exploration/Actions Max            0.999829
exploration/Actions Min           -0.998375
exploration/Num Paths             10
exploration/Average Returns        2.66669
evaluation/num steps total     55000
evaluation/num paths total       110
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0681142
evaluation/Rewards Std             0.0545413
evaluation/Rewards Max             0.217361
evaluation/Rewards Min             0.00205916
evaluation/Returns Mean           34.0571
evaluation/Returns Std             4.5882
evaluation/Returns Max            39.8607
evaluation/Returns Min            22.7376
evaluation/ExplReturns Mean       34.0571
evaluation/ExplReturns Std         4.5882
evaluation/ExplReturns Max        39.8607
evaluation/ExplReturns Min        22.7376
evaluation/Actions Mean           -0.0162298
evaluation/Actions Std             0.0591364
evaluation/Actions Max             0.11178
evaluation/Actions Min            -0.382547
evaluation/Num Paths              10
evaluation/Average Returns        34.0571
time/data storing (s)              0.0294719
time/evaluation sampling (s)      63.703
time/exploration sampling (s)     68.5909
time/logging (s)                   0.0253649
time/saving (s)                    0.0637789
time/training (s)                 10.4464
time/epoch (s)                   142.859
time/total (s)                  1582.12
Epoch                             10
-----------------------------  ---------------
2023-08-31 12:23:26.622852 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 11 finished
-----------------------------  ---------------
replay_buffer/size             61000
trainer/QF1 Loss                   0.00159921
trainer/QF2 Loss                   0.00254393
trainer/Policy Loss              -51.1669
trainer/Q1 Predictions Mean       46.4849
trainer/Q1 Predictions Std         0.35464
trainer/Q1 Predictions Max        47.0661
trainer/Q1 Predictions Min        44.9404
trainer/Q2 Predictions Mean       46.5011
trainer/Q2 Predictions Std         0.352894
trainer/Q2 Predictions Max        47.0754
trainer/Q2 Predictions Min        45.0042
trainer/Q Targets Mean            46.4738
trainer/Q Targets Std              0.352258
trainer/Q Targets Max             47.0486
trainer/Q Targets Min             44.9741
trainer/Log Pis Mean              -4.67626
trainer/Log Pis Std                0.512451
trainer/Log Pis Max               -2.93063
trainer/Log Pis Min               -6.16263
trainer/Policy mu Mean            -0.00163037
trainer/Policy mu Std              0.130987
trainer/Policy mu Max              0.762438
trainer/Policy mu Min             -0.646415
trainer/Policy log std Mean       -0.127282
trainer/Policy log std Std         0.0109517
trainer/Policy log std Max        -0.0875053
trainer/Policy log std Min        -0.196335
trainer/Alpha                      0.0369238
trainer/Alpha Loss               -38.5153
exploration/num steps total    61000
exploration/num paths total      122
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0104569
exploration/Rewards Std            0.0119603
exploration/Rewards Max            0.0939577
exploration/Rewards Min            0.000388573
exploration/Returns Mean           5.22846
exploration/Returns Std            3.81621
exploration/Returns Max           12.1333
exploration/Returns Min            0.706769
exploration/Actions Mean          -0.0128428
exploration/Actions Std            0.590854
exploration/Actions Max            0.998228
exploration/Actions Min           -0.999348
exploration/Num Paths             10
exploration/Average Returns        5.22846
evaluation/num steps total     60000
evaluation/num paths total       120
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.133119
evaluation/Rewards Std             0.0775766
evaluation/Rewards Max             0.261568
evaluation/Rewards Min             0.00160123
evaluation/Returns Mean           66.5597
evaluation/Returns Std            10.9004
evaluation/Returns Max            77.0958
evaluation/Returns Min            35.9027
evaluation/ExplReturns Mean       66.5597
evaluation/ExplReturns Std        10.9004
evaluation/ExplReturns Max        77.0958
evaluation/ExplReturns Min        35.9027
evaluation/Actions Mean           -0.0179806
evaluation/Actions Std             0.0721777
evaluation/Actions Max             0.162729
evaluation/Actions Min            -0.534078
evaluation/Num Paths              10
evaluation/Average Returns        66.5597
time/data storing (s)              0.029644
time/evaluation sampling (s)      65.0924
time/exploration sampling (s)     69.3162
time/logging (s)                   0.0253863
time/saving (s)                    0.0514906
time/training (s)                 10.4605
time/epoch (s)                   144.976
time/total (s)                  1727.1
Epoch                             11
-----------------------------  ---------------
2023-08-31 12:25:54.435641 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 12 finished
-----------------------------  ---------------
replay_buffer/size             66000
trainer/QF1 Loss                   0.00266768
trainer/QF2 Loss                   0.00162545
trainer/Policy Loss              -49.4955
trainer/Q1 Predictions Mean       44.8986
trainer/Q1 Predictions Std         0.365486
trainer/Q1 Predictions Max        46.0632
trainer/Q1 Predictions Min        43.3646
trainer/Q2 Predictions Mean       44.9451
trainer/Q2 Predictions Std         0.363926
trainer/Q2 Predictions Max        46.1103
trainer/Q2 Predictions Min        43.3954
trainer/Q Targets Mean            44.9334
trainer/Q Targets Std              0.364342
trainer/Q Targets Max             46.0848
trainer/Q Targets Min             43.3501
trainer/Log Pis Mean              -4.59255
trainer/Log Pis Std                0.620481
trainer/Log Pis Max               -2.02238
trainer/Log Pis Min               -6.72569
trainer/Policy mu Mean            -0.00970039
trainer/Policy mu Std              0.165047
trainer/Policy mu Max              0.879115
trainer/Policy mu Min             -0.988324
trainer/Policy log std Mean       -0.125525
trainer/Policy log std Std         0.015495
trainer/Policy log std Max        -0.0677861
trainer/Policy log std Min        -0.225067
trainer/Alpha                      0.0273771
trainer/Alpha Loss               -41.7071
exploration/num steps total    66000
exploration/num paths total      132
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0183433
exploration/Rewards Std            0.0262849
exploration/Rewards Max            0.24636
exploration/Rewards Min            0.000625587
exploration/Returns Mean           9.17167
exploration/Returns Std            4.79624
exploration/Returns Max           16.7712
exploration/Returns Min            0.922873
exploration/Actions Mean          -0.0216122
exploration/Actions Std            0.596554
exploration/Actions Max            0.99845
exploration/Actions Min           -0.998252
exploration/Num Paths             10
exploration/Average Returns        9.17167
evaluation/num steps total     65000
evaluation/num paths total       130
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.153414
evaluation/Rewards Std             0.0779281
evaluation/Rewards Max             0.250313
evaluation/Rewards Min             0.00209184
evaluation/Returns Mean           76.7071
evaluation/Returns Std             4.28575
evaluation/Returns Max            81.6613
evaluation/Returns Min            66.184
evaluation/ExplReturns Mean       76.7071
evaluation/ExplReturns Std         4.28575
evaluation/ExplReturns Max        81.6613
evaluation/ExplReturns Min        66.184
evaluation/Actions Mean           -0.0257601
evaluation/Actions Std             0.0928767
evaluation/Actions Max             0.193943
evaluation/Actions Min            -0.791762
evaluation/Num Paths              10
evaluation/Average Returns        76.7071
time/data storing (s)              0.0298357
time/evaluation sampling (s)      66.6483
time/exploration sampling (s)     70.4419
time/logging (s)                   0.0254388
time/saving (s)                    0.0751902
time/training (s)                 10.5888
time/epoch (s)                   147.809
time/total (s)                  1874.91
Epoch                             12
-----------------------------  ---------------
2023-08-31 12:28:21.100617 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 13 finished
-----------------------------  ---------------
replay_buffer/size             71000
trainer/QF1 Loss                   0.00377701
trainer/QF2 Loss                   0.0105575
trainer/Policy Loss              -47.705
trainer/Q1 Predictions Mean       43.1748
trainer/Q1 Predictions Std         0.317831
trainer/Q1 Predictions Max        43.8843
trainer/Q1 Predictions Min        41.9791
trainer/Q2 Predictions Mean       43.1281
trainer/Q2 Predictions Std         0.319758
trainer/Q2 Predictions Max        43.8838
trainer/Q2 Predictions Min        41.9599
trainer/Q Targets Mean            43.2232
trainer/Q Targets Std              0.318242
trainer/Q Targets Max             43.9039
trainer/Q Targets Min             42.1194
trainer/Log Pis Mean              -4.5723
trainer/Log Pis Std                0.77963
trainer/Log Pis Max               -1.53799
trainer/Log Pis Min               -7.31471
trainer/Policy mu Mean            -0.0152436
trainer/Policy mu Std              0.214395
trainer/Policy mu Max              1.11777
trainer/Policy mu Min             -1.46897
trainer/Policy log std Mean       -0.132704
trainer/Policy log std Std         0.0208615
trainer/Policy log std Max        -0.0288212
trainer/Policy log std Min        -0.271278
trainer/Alpha                      0.0203072
trainer/Alpha Loss               -45.0913
exploration/num steps total    71000
exploration/num paths total      142
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0116406
exploration/Rewards Std            0.0223732
exploration/Rewards Max            0.210064
exploration/Rewards Min            0.000212331
exploration/Returns Mean           5.82028
exploration/Returns Std            4.82367
exploration/Returns Max           13.8254
exploration/Returns Min            0.687933
exploration/Actions Mean          -0.0124383
exploration/Actions Std            0.590982
exploration/Actions Max            0.998967
exploration/Actions Min           -0.998551
exploration/Num Paths             10
exploration/Average Returns        5.82028
evaluation/num steps total     70000
evaluation/num paths total       140
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0308
evaluation/Rewards Std             0.0451626
evaluation/Rewards Max             0.20261
evaluation/Rewards Min             4.64756e-07
evaluation/Returns Mean           15.4
evaluation/Returns Std             8.45446
evaluation/Returns Max            39.0882
evaluation/Returns Min             6.82046
evaluation/ExplReturns Mean       15.4
evaluation/ExplReturns Std         8.45446
evaluation/ExplReturns Max        39.0882
evaluation/ExplReturns Min         6.82046
evaluation/Actions Mean           -0.0201012
evaluation/Actions Std             0.114914
evaluation/Actions Max             0.279593
evaluation/Actions Min            -0.920152
evaluation/Num Paths              10
evaluation/Average Returns        15.4
time/data storing (s)              0.0294738
time/evaluation sampling (s)      65.8433
time/exploration sampling (s)     70.4025
time/logging (s)                   0.0310744
time/saving (s)                    0.119756
time/training (s)                 10.2411
time/epoch (s)                   146.667
time/total (s)                  2021.58
Epoch                             13
-----------------------------  ---------------
2023-08-31 12:30:50.217751 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 14 finished
-----------------------------  ---------------
replay_buffer/size             76000
trainer/QF1 Loss                   0.00240603
trainer/QF2 Loss                   0.00164528
trainer/Policy Loss              -45.8828
trainer/Q1 Predictions Mean       41.4563
trainer/Q1 Predictions Std         0.520545
trainer/Q1 Predictions Max        42.2519
trainer/Q1 Predictions Min        36.7079
trainer/Q2 Predictions Mean       41.4149
trainer/Q2 Predictions Std         0.523571
trainer/Q2 Predictions Max        42.2443
trainer/Q2 Predictions Min        36.6481
trainer/Q Targets Mean            41.4274
trainer/Q Targets Std              0.52322
trainer/Q Targets Max             42.274
trainer/Q Targets Min             36.6703
trainer/Log Pis Mean              -4.46013
trainer/Log Pis Std                0.899729
trainer/Log Pis Max               -1.20286
trainer/Log Pis Min               -6.89624
trainer/Policy mu Mean            -0.0021098
trainer/Policy mu Std              0.272017
trainer/Policy mu Max              0.988429
trainer/Policy mu Min             -1.56372
trainer/Policy log std Mean       -0.13145
trainer/Policy log std Std         0.0322645
trainer/Policy log std Max         0.0211626
trainer/Policy log std Min        -0.399991
trainer/Alpha                      0.0150799
trainer/Alpha Loss               -48.0649
exploration/num steps total    76000
exploration/num paths total      152
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0913422
exploration/Rewards Std            0.201782
exploration/Rewards Max            1
exploration/Rewards Min            0.000310319
exploration/Returns Mean          45.6711
exploration/Returns Std           68.1857
exploration/Returns Max          236.807
exploration/Returns Min            3.56336
exploration/Actions Mean          -0.0254651
exploration/Actions Std            0.608187
exploration/Actions Max            0.999481
exploration/Actions Min           -0.99855
exploration/Num Paths             10
exploration/Average Returns       45.6711
evaluation/num steps total     75000
evaluation/num paths total       150
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.160047
evaluation/Rewards Std             0.132556
evaluation/Rewards Max             0.329656
evaluation/Rewards Min             0.00138176
evaluation/Returns Mean           80.0237
evaluation/Returns Std            41.8043
evaluation/Returns Max           131.529
evaluation/Returns Min            31.5496
evaluation/ExplReturns Mean       80.0237
evaluation/ExplReturns Std        41.8043
evaluation/ExplReturns Max       131.529
evaluation/ExplReturns Min        31.5496
evaluation/Actions Mean           -0.038498
evaluation/Actions Std             0.264735
evaluation/Actions Max             0.846012
evaluation/Actions Min            -0.912399
evaluation/Num Paths              10
evaluation/Average Returns        80.0237
time/data storing (s)              0.0294201
time/evaluation sampling (s)      67.8365
time/exploration sampling (s)     70.8358
time/logging (s)                   0.0252384
time/saving (s)                    0.0666753
time/training (s)                 10.3143
time/epoch (s)                   149.108
time/total (s)                  2170.69
Epoch                             14
-----------------------------  ---------------
2023-08-31 12:33:15.293689 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 15 finished
-----------------------------  ---------------
replay_buffer/size             81000
trainer/QF1 Loss                   0.00357036
trainer/QF2 Loss                   0.00344821
trainer/Policy Loss              -43.8378
trainer/Q1 Predictions Mean       39.5709
trainer/Q1 Predictions Std         0.853847
trainer/Q1 Predictions Max        42.2776
trainer/Q1 Predictions Min        33.2048
trainer/Q2 Predictions Mean       39.5945
trainer/Q2 Predictions Std         0.851772
trainer/Q2 Predictions Max        42.2891
trainer/Q2 Predictions Min        33.3417
trainer/Q Targets Mean            39.6002
trainer/Q Targets Std              0.864253
trainer/Q Targets Max             42.6591
trainer/Q Targets Min             33.2055
trainer/Log Pis Mean              -4.25977
trainer/Log Pis Std                1.15854
trainer/Log Pis Max                1.52428
trainer/Log Pis Min               -6.72932
trainer/Policy mu Mean             0.000627887
trainer/Policy mu Std              0.341067
trainer/Policy mu Max              1.43541
trainer/Policy mu Min             -1.89525
trainer/Policy log std Mean       -0.121155
trainer/Policy log std Std         0.0414192
trainer/Policy log std Max         0.0540042
trainer/Policy log std Min        -0.561567
trainer/Alpha                      0.0112115
trainer/Alpha Loss               -50.5622
exploration/num steps total    81000
exploration/num paths total      162
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.014528
exploration/Rewards Std            0.0389176
exploration/Rewards Max            0.317279
exploration/Rewards Min            2.10445e-06
exploration/Returns Mean           7.26402
exploration/Returns Std            6.3465
exploration/Returns Max           24.9634
exploration/Returns Min            2.19964
exploration/Actions Mean          -0.0139675
exploration/Actions Std            0.617802
exploration/Actions Max            0.999258
exploration/Actions Min           -0.999079
exploration/Num Paths             10
exploration/Average Returns        7.26402
evaluation/num steps total     80000
evaluation/num paths total       160
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00488542
evaluation/Rewards Std             0.0101366
evaluation/Rewards Max             0.0752175
evaluation/Rewards Min             1.73749e-07
evaluation/Returns Mean            2.44271
evaluation/Returns Std             0.623698
evaluation/Returns Max             3.40218
evaluation/Returns Min             1.47056
evaluation/ExplReturns Mean        2.44271
evaluation/ExplReturns Std         0.623698
evaluation/ExplReturns Max         3.40218
evaluation/ExplReturns Min         1.47056
evaluation/Actions Mean           -0.00326987
evaluation/Actions Std             0.240161
evaluation/Actions Max             0.96191
evaluation/Actions Min            -0.953136
evaluation/Num Paths              10
evaluation/Average Returns         2.44271
time/data storing (s)              0.0295574
time/evaluation sampling (s)      63.6598
time/exploration sampling (s)     67.4705
time/logging (s)                   0.0256751
time/saving (s)                    0.0642182
time/training (s)                 13.8231
time/epoch (s)                   145.073
time/total (s)                  2315.77
Epoch                             15
-----------------------------  ---------------
2023-08-31 12:35:42.479033 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size             86000
trainer/QF1 Loss                   0.00421841
trainer/QF2 Loss                   0.004337
trainer/Policy Loss              -41.459
trainer/Q1 Predictions Mean       37.8889
trainer/Q1 Predictions Std         1.15325
trainer/Q1 Predictions Max        45.1243
trainer/Q1 Predictions Min        29.2674
trainer/Q2 Predictions Mean       37.8765
trainer/Q2 Predictions Std         1.14428
trainer/Q2 Predictions Max        45.2073
trainer/Q2 Predictions Min        29.3455
trainer/Q Targets Mean            37.9074
trainer/Q Targets Std              1.1609
trainer/Q Targets Max             45.429
trainer/Q Targets Min             29.2858
trainer/Log Pis Mean              -3.57413
trainer/Log Pis Std                1.52551
trainer/Log Pis Max                2.03577
trainer/Log Pis Min               -7.35516
trainer/Policy mu Mean             0.0369139
trainer/Policy mu Std              0.482426
trainer/Policy mu Max              1.71947
trainer/Policy mu Min             -2.31743
trainer/Policy log std Mean       -0.143441
trainer/Policy log std Std         0.0735865
trainer/Policy log std Max         0.195543
trainer/Policy log std Min        -0.710986
trainer/Alpha                      0.00835767
trainer/Alpha Loss               -50.5897
exploration/num steps total    86000
exploration/num paths total      172
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00782082
exploration/Rewards Std            0.0188843
exploration/Rewards Max            0.255821
exploration/Rewards Min            1.05751e-06
exploration/Returns Mean           3.91041
exploration/Returns Std            1.74498
exploration/Returns Max            6.59759
exploration/Returns Min            1.66498
exploration/Actions Mean          -0.00234462
exploration/Actions Std            0.657509
exploration/Actions Max            0.999799
exploration/Actions Min           -0.999729
exploration/Num Paths             10
exploration/Average Returns        3.91041
evaluation/num steps total     85000
evaluation/num paths total       170
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00853083
evaluation/Rewards Std             0.0133161
evaluation/Rewards Max             0.116623
evaluation/Rewards Min             0.000509331
evaluation/Returns Mean            4.26541
evaluation/Returns Std             1.80611
evaluation/Returns Max             6.86291
evaluation/Returns Min             1.88699
evaluation/ExplReturns Mean        4.26541
evaluation/ExplReturns Std         1.80611
evaluation/ExplReturns Max         6.86291
evaluation/ExplReturns Min         1.88699
evaluation/Actions Mean            0.0160588
evaluation/Actions Std             0.40783
evaluation/Actions Max             0.99834
evaluation/Actions Min            -0.998589
evaluation/Num Paths              10
evaluation/Average Returns         4.26541
time/data storing (s)              0.0299854
time/evaluation sampling (s)      64.7262
time/exploration sampling (s)     68.6207
time/logging (s)                   0.0259762
time/saving (s)                    0.0658068
time/training (s)                 13.7136
time/epoch (s)                   147.182
time/total (s)                  2462.95
Epoch                             16
-----------------------------  ---------------
2023-08-31 12:38:09.540306 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 17 finished
-----------------------------  ---------------
replay_buffer/size             91000
trainer/QF1 Loss                   0.00486233
trainer/QF2 Loss                   0.00450021
trainer/Policy Loss              -39.1244
trainer/Q1 Predictions Mean       36.1146
trainer/Q1 Predictions Std         1.42941
trainer/Q1 Predictions Max        42.2197
trainer/Q1 Predictions Min        26.8475
trainer/Q2 Predictions Mean       36.1181
trainer/Q2 Predictions Std         1.42632
trainer/Q2 Predictions Max        42.1815
trainer/Q2 Predictions Min        26.8042
trainer/Q Targets Mean            36.1305
trainer/Q Targets Std              1.45304
trainer/Q Targets Max             42.7837
trainer/Q Targets Min             26.7627
trainer/Log Pis Mean              -2.99184
trainer/Log Pis Std                2.44844
trainer/Log Pis Max                8.91386
trainer/Log Pis Min               -9.31646
trainer/Policy mu Mean             0.0464991
trainer/Policy mu Std              0.616611
trainer/Policy mu Max              2.53001
trainer/Policy mu Min             -2.62236
trainer/Policy log std Mean       -0.147215
trainer/Policy log std Std         0.102506
trainer/Policy log std Max         0.400047
trainer/Policy log std Min        -0.814798
trainer/Alpha                      0.00628216
trainer/Alpha Loss               -50.6562
exploration/num steps total    91000
exploration/num paths total      182
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00979204
exploration/Rewards Std            0.0238473
exploration/Rewards Max            0.314302
exploration/Rewards Min            1.54896e-06
exploration/Returns Mean           4.89602
exploration/Returns Std            1.8994
exploration/Returns Max            7.53002
exploration/Returns Min            1.93662
exploration/Actions Mean           0.00182713
exploration/Actions Std            0.663008
exploration/Actions Max            0.999716
exploration/Actions Min           -0.999919
exploration/Num Paths             10
exploration/Average Returns        4.89602
evaluation/num steps total     90000
evaluation/num paths total       180
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0118863
evaluation/Rewards Std             0.0252284
evaluation/Rewards Max             0.210817
evaluation/Rewards Min             0.00166898
evaluation/Returns Mean            5.94317
evaluation/Returns Std             1.13615
evaluation/Returns Max             7.8496
evaluation/Returns Min             4.34658
evaluation/ExplReturns Mean        5.94317
evaluation/ExplReturns Std         1.13615
evaluation/ExplReturns Max         7.8496
evaluation/ExplReturns Min         4.34658
evaluation/Actions Mean            0.0484324
evaluation/Actions Std             0.463638
evaluation/Actions Max             0.992017
evaluation/Actions Min            -0.991201
evaluation/Num Paths              10
evaluation/Average Returns         5.94317
time/data storing (s)              0.0295121
time/evaluation sampling (s)      63.2279
time/exploration sampling (s)     69.335
time/logging (s)                   0.0253817
time/saving (s)                    0.0700181
time/training (s)                 14.3694
time/epoch (s)                   147.057
time/total (s)                  2610.01
Epoch                             17
-----------------------------  ---------------
2023-08-31 12:40:32.684588 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 18 finished
-----------------------------  ---------------
replay_buffer/size             96000
trainer/QF1 Loss                   0.00265895
trainer/QF2 Loss                   0.00292478
trainer/Policy Loss              -35.6555
trainer/Q1 Predictions Mean       34.4336
trainer/Q1 Predictions Std         1.34205
trainer/Q1 Predictions Max        36.5411
trainer/Q1 Predictions Min        26.1916
trainer/Q2 Predictions Mean       34.4316
trainer/Q2 Predictions Std         1.3407
trainer/Q2 Predictions Max        36.5983
trainer/Q2 Predictions Min        26.3984
trainer/Q Targets Mean            34.4393
trainer/Q Targets Std              1.35204
trainer/Q Targets Max             36.8508
trainer/Q Targets Min             26.1699
trainer/Log Pis Mean              -1.18918
trainer/Log Pis Std                3.39938
trainer/Log Pis Max               11.6452
trainer/Log Pis Min               -8.87491
trainer/Policy mu Mean             0.0928086
trainer/Policy mu Std              0.896068
trainer/Policy mu Max              2.7153
trainer/Policy mu Min             -2.75948
trainer/Policy log std Mean       -0.207343
trainer/Policy log std Std         0.140448
trainer/Policy log std Max         0.243903
trainer/Policy log std Min        -0.713779
trainer/Alpha                      0.00479549
trainer/Alpha Loss               -43.7288
exploration/num steps total    96000
exploration/num paths total      192
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00283754
exploration/Rewards Std            0.00444871
exploration/Rewards Max            0.0807042
exploration/Rewards Min            0.000446523
exploration/Returns Mean           1.41877
exploration/Returns Std            0.646316
exploration/Returns Max            3.07437
exploration/Returns Min            0.977444
exploration/Actions Mean           0.04679
exploration/Actions Std            0.653274
exploration/Actions Max            0.999975
exploration/Actions Min           -0.9996
exploration/Num Paths             10
exploration/Average Returns        1.41877
evaluation/num steps total     95000
evaluation/num paths total       190
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00257547
evaluation/Rewards Std             0.0044
evaluation/Rewards Max             0.0613587
evaluation/Rewards Min             8.22885e-07
evaluation/Returns Mean            1.28774
evaluation/Returns Std             0.550785
evaluation/Returns Max             2.89541
evaluation/Returns Min             0.944316
evaluation/ExplReturns Mean        1.28774
evaluation/ExplReturns Std         0.550785
evaluation/ExplReturns Max         2.89541
evaluation/ExplReturns Min         0.944316
evaluation/Actions Mean            0.0671146
evaluation/Actions Std             0.465704
evaluation/Actions Max             0.994679
evaluation/Actions Min            -0.990534
evaluation/Num Paths              10
evaluation/Average Returns         1.28774
time/data storing (s)              0.0297864
time/evaluation sampling (s)      63.2053
time/exploration sampling (s)     68.9482
time/logging (s)                   0.0253518
time/saving (s)                    0.0504901
time/training (s)                 10.8817
time/epoch (s)                   143.141
time/total (s)                  2753.15
Epoch                             18
-----------------------------  ---------------
2023-08-31 12:43:03.073324 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 19 finished
-----------------------------  ----------------
replay_buffer/size             101000
trainer/QF1 Loss                    0.00575244
trainer/QF2 Loss                    0.00439001
trainer/Policy Loss               -33.3985
trainer/Q1 Predictions Mean        33.1461
trainer/Q1 Predictions Std          1.34896
trainer/Q1 Predictions Max         47.8383
trainer/Q1 Predictions Min         25.2748
trainer/Q2 Predictions Mean        33.1273
trainer/Q2 Predictions Std          1.3485
trainer/Q2 Predictions Max         47.8387
trainer/Q2 Predictions Min         25.27
trainer/Q Targets Mean             33.0992
trainer/Q Targets Std               1.36708
trainer/Q Targets Max              48.2553
trainer/Q Targets Min              25.1967
trainer/Log Pis Mean               -0.237096
trainer/Log Pis Std                 3.50363
trainer/Log Pis Max                18.7553
trainer/Log Pis Min                -8.4265
trainer/Policy mu Mean              0.132669
trainer/Policy mu Std               0.994791
trainer/Policy mu Max               2.93723
trainer/Policy mu Min              -2.93234
trainer/Policy log std Mean        -0.22303
trainer/Policy log std Std          0.134624
trainer/Policy log std Max          0.233975
trainer/Policy log std Min         -0.710783
trainer/Alpha                       0.00369916
trainer/Alpha Loss                -40.5234
exploration/num steps total    101000
exploration/num paths total       202
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00829315
exploration/Rewards Std             0.0218267
exploration/Rewards Max             0.295998
exploration/Rewards Min             0.000625397
exploration/Returns Mean            4.14658
exploration/Returns Std             4.79469
exploration/Returns Max            17.9274
exploration/Returns Min             1.24695
exploration/Actions Mean            0.0924954
exploration/Actions Std             0.670999
exploration/Actions Max             0.999563
exploration/Actions Min            -0.99993
exploration/Num Paths              10
exploration/Average Returns         4.14658
evaluation/num steps total     100000
evaluation/num paths total        200
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0422945
evaluation/Rewards Std              0.0756794
evaluation/Rewards Max              0.280231
evaluation/Rewards Min              0.000128217
evaluation/Returns Mean            21.1473
evaluation/Returns Std             24.955
evaluation/Returns Max             86.8165
evaluation/Returns Min              2.71185
evaluation/ExplReturns Mean        21.1473
evaluation/ExplReturns Std         24.955
evaluation/ExplReturns Max         86.8165
evaluation/ExplReturns Min          2.71185
evaluation/Actions Mean             0.133942
evaluation/Actions Std              0.570809
evaluation/Actions Max              0.999879
evaluation/Actions Min             -0.999878
evaluation/Num Paths               10
evaluation/Average Returns         21.1473
time/data storing (s)               0.0298653
time/evaluation sampling (s)       69.0557
time/exploration sampling (s)      70.52
time/logging (s)                    0.025416
time/saving (s)                     0.0705114
time/training (s)                  10.6837
time/epoch (s)                    150.385
time/total (s)                   2903.54
Epoch                              19
-----------------------------  ----------------
2023-08-31 12:45:34.594100 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 20 finished
-----------------------------  ----------------
replay_buffer/size             106000
trainer/QF1 Loss                    0.0216782
trainer/QF2 Loss                    0.0228956
trainer/Policy Loss               -31.0615
trainer/Q1 Predictions Mean        31.7353
trainer/Q1 Predictions Std          1.74373
trainer/Q1 Predictions Max         46.0416
trainer/Q1 Predictions Min         23.8814
trainer/Q2 Predictions Mean        31.7386
trainer/Q2 Predictions Std          1.74082
trainer/Q2 Predictions Max         46.0853
trainer/Q2 Predictions Min         23.9317
trainer/Q Targets Mean             31.7146
trainer/Q Targets Std               1.81961
trainer/Q Targets Max              46.762
trainer/Q Targets Min              23.9876
trainer/Log Pis Mean                0.697513
trainer/Log Pis Std                 3.94511
trainer/Log Pis Max                18.3979
trainer/Log Pis Min                -7.67431
trainer/Policy mu Mean              0.0523913
trainer/Policy mu Std               1.15176
trainer/Policy mu Max               3.76754
trainer/Policy mu Min              -3.53627
trainer/Policy log std Mean        -0.212812
trainer/Policy log std Std          0.171027
trainer/Policy log std Max          0.349358
trainer/Policy log std Min         -0.792044
trainer/Alpha                       0.00286276
trainer/Alpha Loss                -36.9056
exploration/num steps total    106000
exploration/num paths total       212
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00985745
exploration/Rewards Std             0.0279485
exploration/Rewards Max             0.31666
exploration/Rewards Min             4.15056e-06
exploration/Returns Mean            4.92873
exploration/Returns Std             3.3413
exploration/Returns Max            10.4205
exploration/Returns Min             1.24521
exploration/Actions Mean            0.0581821
exploration/Actions Std             0.679369
exploration/Actions Max             0.999862
exploration/Actions Min            -0.999859
exploration/Num Paths              10
exploration/Average Returns         4.92873
evaluation/num steps total     105000
evaluation/num paths total        210
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0464733
evaluation/Rewards Std              0.091828
evaluation/Rewards Max              0.354663
evaluation/Rewards Min              5.01588e-06
evaluation/Returns Mean            23.2367
evaluation/Returns Std             35.7249
evaluation/Returns Max            125.719
evaluation/Returns Min              2.47846
evaluation/ExplReturns Mean        23.2367
evaluation/ExplReturns Std         35.7249
evaluation/ExplReturns Max        125.719
evaluation/ExplReturns Min          2.47846
evaluation/Actions Mean            -0.00890623
evaluation/Actions Std              0.544603
evaluation/Actions Max              0.998232
evaluation/Actions Min             -0.999926
evaluation/Num Paths               10
evaluation/Average Returns         23.2367
time/data storing (s)               0.029913
time/evaluation sampling (s)       69.2228
time/exploration sampling (s)      71.3098
time/logging (s)                    0.0255215
time/saving (s)                     0.0720373
time/training (s)                  10.8573
time/epoch (s)                    151.517
time/total (s)                   3055.06
Epoch                              20
-----------------------------  ----------------
2023-08-31 12:48:02.107889 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 21 finished
-----------------------------  ----------------
replay_buffer/size             111000
trainer/QF1 Loss                    0.00929783
trainer/QF2 Loss                    0.00922367
trainer/Policy Loss               -27.5356
trainer/Q1 Predictions Mean        30.1521
trainer/Q1 Predictions Std          2.04923
trainer/Q1 Predictions Max         49.2392
trainer/Q1 Predictions Min         24.0585
trainer/Q2 Predictions Mean        30.1592
trainer/Q2 Predictions Std          2.0512
trainer/Q2 Predictions Max         49.2663
trainer/Q2 Predictions Min         24.0723
trainer/Q Targets Mean             30.1191
trainer/Q Targets Std               2.05282
trainer/Q Targets Max              49.558
trainer/Q Targets Min              24.0731
trainer/Log Pis Mean                2.64901
trainer/Log Pis Std                 5.20551
trainer/Log Pis Max                28.1742
trainer/Log Pis Min                -6.84827
trainer/Policy mu Mean              0.0842746
trainer/Policy mu Std               1.3198
trainer/Policy mu Max               4.66922
trainer/Policy mu Min              -4.73789
trainer/Policy log std Mean        -0.237188
trainer/Policy log std Std          0.203224
trainer/Policy log std Max          0.750314
trainer/Policy log std Min         -1.04032
trainer/Alpha                       0.00224931
trainer/Alpha Loss                -26.5276
exploration/num steps total    111000
exploration/num paths total       222
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0554936
exploration/Rewards Std             0.199008
exploration/Rewards Max             1
exploration/Rewards Min             0.000292071
exploration/Returns Mean           27.7468
exploration/Returns Std            62.2538
exploration/Returns Max           214.34
exploration/Returns Min             4.30265
exploration/Actions Mean            0.0838937
exploration/Actions Std             0.714482
exploration/Actions Max             0.99999
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns        27.7468
evaluation/num steps total     110000
evaluation/num paths total        220
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00885417
evaluation/Rewards Std              0.0205135
evaluation/Rewards Max              0.271947
evaluation/Rewards Min              2.2688e-05
evaluation/Returns Mean             4.42708
evaluation/Returns Std              1.67652
evaluation/Returns Max              7.84773
evaluation/Returns Min              2.28751
evaluation/ExplReturns Mean         4.42708
evaluation/ExplReturns Std          1.67652
evaluation/ExplReturns Max          7.84773
evaluation/ExplReturns Min          2.28751
evaluation/Actions Mean             0.0696595
evaluation/Actions Std              0.640613
evaluation/Actions Max              0.999388
evaluation/Actions Min             -0.999692
evaluation/Num Paths               10
evaluation/Average Returns          4.42708
time/data storing (s)               0.0293046
time/evaluation sampling (s)       66.7853
time/exploration sampling (s)      70.1393
time/logging (s)                    0.0260982
time/saving (s)                     0.0764371
time/training (s)                  10.4545
time/epoch (s)                    147.511
time/total (s)                   3202.58
Epoch                              21
-----------------------------  ----------------
2023-08-31 12:50:33.092940 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 22 finished
-----------------------------  ----------------
replay_buffer/size             116000
trainer/QF1 Loss                    0.0065826
trainer/QF2 Loss                    0.00650852
trainer/Policy Loss               -25.0146
trainer/Q1 Predictions Mean        28.8287
trainer/Q1 Predictions Std          1.73602
trainer/Q1 Predictions Max         50.2328
trainer/Q1 Predictions Min         22.4042
trainer/Q2 Predictions Mean        28.8363
trainer/Q2 Predictions Std          1.73632
trainer/Q2 Predictions Max         50.2359
trainer/Q2 Predictions Min         22.3252
trainer/Q Targets Mean             28.8254
trainer/Q Targets Std               1.74462
trainer/Q Targets Max              50.2654
trainer/Q Targets Min              22.1022
trainer/Log Pis Mean                3.85674
trainer/Log Pis Std                 5.39769
trainer/Log Pis Max                34.6553
trainer/Log Pis Min                -9.10819
trainer/Policy mu Mean             -0.121093
trainer/Policy mu Std               1.46587
trainer/Policy mu Max               4.77754
trainer/Policy mu Min              -5.27379
trainer/Policy log std Mean        -0.221122
trainer/Policy log std Std          0.221749
trainer/Policy log std Max          0.381804
trainer/Policy log std Min         -0.909076
trainer/Alpha                       0.00183736
trainer/Alpha Loss                -19.8001
exploration/num steps total    116000
exploration/num paths total       232
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0157306
exploration/Rewards Std             0.0305517
exploration/Rewards Max             0.270804
exploration/Rewards Min             6.64329e-06
exploration/Returns Mean            7.86528
exploration/Returns Std             3.3935
exploration/Returns Max            12.3732
exploration/Returns Min             2.70167
exploration/Actions Mean           -0.0425624
exploration/Actions Std             0.760819
exploration/Actions Max             1
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns         7.86528
evaluation/num steps total     115000
evaluation/num paths total        230
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0131588
evaluation/Rewards Std              0.0246663
evaluation/Rewards Max              0.202247
evaluation/Rewards Min              0.000131284
evaluation/Returns Mean             6.5794
evaluation/Returns Std              1.9979
evaluation/Returns Max             10.8029
evaluation/Returns Min              3.15334
evaluation/ExplReturns Mean         6.5794
evaluation/ExplReturns Std          1.9979
evaluation/ExplReturns Max         10.8029
evaluation/ExplReturns Min          3.15334
evaluation/Actions Mean            -0.027085
evaluation/Actions Std              0.702517
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999995
evaluation/Num Paths               10
evaluation/Average Returns          6.5794
time/data storing (s)               0.0295608
time/evaluation sampling (s)       65.2239
time/exploration sampling (s)      71.5102
time/logging (s)                    0.025261
time/saving (s)                     0.0838189
time/training (s)                  14.108
time/epoch (s)                    150.981
time/total (s)                   3353.56
Epoch                              22
-----------------------------  ----------------
2023-08-31 12:52:52.461789 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 23 finished
-----------------------------  ----------------
replay_buffer/size             121000
trainer/QF1 Loss                    0.00540387
trainer/QF2 Loss                    0.00607769
trainer/Policy Loss               -21.1179
trainer/Q1 Predictions Mean        27.6723
trainer/Q1 Predictions Std          1.8202
trainer/Q1 Predictions Max         51.1917
trainer/Q1 Predictions Min         22.2798
trainer/Q2 Predictions Mean        27.6872
trainer/Q2 Predictions Std          1.82462
trainer/Q2 Predictions Max         51.3019
trainer/Q2 Predictions Min         22.3259
trainer/Q Targets Mean             27.6495
trainer/Q Targets Std               1.82998
trainer/Q Targets Max              51.2771
trainer/Q Targets Min              22.3307
trainer/Log Pis Mean                6.61639
trainer/Log Pis Std                 6.08928
trainer/Log Pis Max                31.686
trainer/Log Pis Min                -7.4588
trainer/Policy mu Mean             -0.140148
trainer/Policy mu Std               1.69916
trainer/Policy mu Max               5.78543
trainer/Policy mu Min              -5.71259
trainer/Policy log std Mean        -0.28816
trainer/Policy log std Std          0.206132
trainer/Policy log std Max          0.415765
trainer/Policy log std Min         -0.875757
trainer/Alpha                       0.00164349
trainer/Alpha Loss                 -2.4593
exploration/num steps total    121000
exploration/num paths total       242
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0033457
exploration/Rewards Std             0.010866
exploration/Rewards Max             0.12441
exploration/Rewards Min             4.11469e-06
exploration/Returns Mean            1.67285
exploration/Returns Std             0.375502
exploration/Returns Max             2.4521
exploration/Returns Min             1.24204
exploration/Actions Mean            0.0506875
exploration/Actions Std             0.695348
exploration/Actions Max             0.999983
exploration/Actions Min            -0.999902
exploration/Num Paths              10
exploration/Average Returns         1.67285
evaluation/num steps total     120000
evaluation/num paths total        240
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00267232
evaluation/Rewards Std              0.00736559
evaluation/Rewards Max              0.108556
evaluation/Rewards Min              0.000293526
evaluation/Returns Mean             1.33616
evaluation/Returns Std              0.148516
evaluation/Returns Max              1.62527
evaluation/Returns Min              1.12946
evaluation/ExplReturns Mean         1.33616
evaluation/ExplReturns Std          0.148516
evaluation/ExplReturns Max          1.62527
evaluation/ExplReturns Min          1.12946
evaluation/Actions Mean             0.0711724
evaluation/Actions Std              0.522632
evaluation/Actions Max              0.997828
evaluation/Actions Min             -0.998433
evaluation/Num Paths               10
evaluation/Average Returns          1.33616
time/data storing (s)               0.0302034
time/evaluation sampling (s)       61.0065
time/exploration sampling (s)      66.9717
time/logging (s)                    0.025481
time/saving (s)                     0.0645794
time/training (s)                  11.267
time/epoch (s)                    139.365
time/total (s)                   3492.93
Epoch                              23
-----------------------------  ----------------
2023-08-31 12:55:17.168434 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 24 finished
-----------------------------  ----------------
replay_buffer/size             126000
trainer/QF1 Loss                    0.00634676
trainer/QF2 Loss                    0.00933363
trainer/Policy Loss               -19.0408
trainer/Q1 Predictions Mean        26.49
trainer/Q1 Predictions Std          1.96514
trainer/Q1 Predictions Max         52.0085
trainer/Q1 Predictions Min         22.2432
trainer/Q2 Predictions Mean        26.4927
trainer/Q2 Predictions Std          1.96703
trainer/Q2 Predictions Max         52.1663
trainer/Q2 Predictions Min         22.4197
trainer/Q Targets Mean             26.4968
trainer/Q Targets Std               1.97645
trainer/Q Targets Max              52.155
trainer/Q Targets Min              22.18
trainer/Log Pis Mean                7.49126
trainer/Log Pis Std                 6.48831
trainer/Log Pis Max                31.3976
trainer/Log Pis Min                -6.56652
trainer/Policy mu Mean             -0.312331
trainer/Policy mu Std               1.76954
trainer/Policy mu Max               4.502
trainer/Policy mu Min              -5.51402
trainer/Policy log std Mean        -0.281587
trainer/Policy log std Std          0.235936
trainer/Policy log std Max          0.498959
trainer/Policy log std Min         -0.894156
trainer/Alpha                       0.00166103
trainer/Alpha Loss                  3.14422
exploration/num steps total    126000
exploration/num paths total       252
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00981865
exploration/Rewards Std             0.0258127
exploration/Rewards Max             0.314899
exploration/Rewards Min             1.9422e-05
exploration/Returns Mean            4.90932
exploration/Returns Std             2.32944
exploration/Returns Max            10.4107
exploration/Returns Min             2.20546
exploration/Actions Mean            0.0101325
exploration/Actions Std             0.738181
exploration/Actions Max             0.999998
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         4.90932
evaluation/num steps total     125000
evaluation/num paths total        250
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00736598
evaluation/Rewards Std              0.0240117
evaluation/Rewards Max              0.384636
evaluation/Rewards Min              4.53992e-06
evaluation/Returns Mean             3.68299
evaluation/Returns Std              2.80694
evaluation/Returns Max              9.99004
evaluation/Returns Min              1.06711
evaluation/ExplReturns Mean         3.68299
evaluation/ExplReturns Std          2.80694
evaluation/ExplReturns Max          9.99004
evaluation/ExplReturns Min          1.06711
evaluation/Actions Mean             0.0573871
evaluation/Actions Std              0.665357
evaluation/Actions Max              0.999967
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          3.68299
time/data storing (s)               0.0303149
time/evaluation sampling (s)       64.0706
time/exploration sampling (s)      69.3751
time/logging (s)                    0.0258127
time/saving (s)                     0.0397156
time/training (s)                  11.1619
time/epoch (s)                    144.703
time/total (s)                   3637.63
Epoch                              24
-----------------------------  ----------------
2023-08-31 12:57:48.240893 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 25 finished
-----------------------------  ----------------
replay_buffer/size             131000
trainer/QF1 Loss                    0.033501
trainer/QF2 Loss                    0.0463459
trainer/Policy Loss               -19.197
trainer/Q1 Predictions Mean        25.6137
trainer/Q1 Predictions Std          2.2305
trainer/Q1 Predictions Max         53.7972
trainer/Q1 Predictions Min         20.1387
trainer/Q2 Predictions Mean        25.5759
trainer/Q2 Predictions Std          2.21782
trainer/Q2 Predictions Max         53.4127
trainer/Q2 Predictions Min         20.1004
trainer/Q Targets Mean             25.6909
trainer/Q Targets Std               2.3148
trainer/Q Targets Max              55.895
trainer/Q Targets Min              20.3167
trainer/Log Pis Mean                6.45057
trainer/Log Pis Std                 5.9472
trainer/Log Pis Max                33.1543
trainer/Log Pis Min                -6.47776
trainer/Policy mu Mean             -0.315106
trainer/Policy mu Std               1.67975
trainer/Policy mu Max               5.08462
trainer/Policy mu Min              -5.02372
trainer/Policy log std Mean        -0.235191
trainer/Policy log std Std          0.229196
trainer/Policy log std Max          0.912925
trainer/Policy log std Min         -0.857394
trainer/Alpha                       0.00175026
trainer/Alpha Loss                 -3.4878
exploration/num steps total    131000
exploration/num paths total       262
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0615804
exploration/Rewards Std             0.133734
exploration/Rewards Max             1
exploration/Rewards Min             0.000977475
exploration/Returns Mean           30.7902
exploration/Returns Std            24.4003
exploration/Returns Max            79.5968
exploration/Returns Min            10.022
exploration/Actions Mean           -0.104294
exploration/Actions Std             0.745245
exploration/Actions Max             0.999998
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        30.7902
evaluation/num steps total     130000
evaluation/num paths total        260
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0695
evaluation/Rewards Std              0.0736305
evaluation/Rewards Max              0.336497
evaluation/Rewards Min              0.000740365
evaluation/Returns Mean            34.75
evaluation/Returns Std             24.4007
evaluation/Returns Max             81.2412
evaluation/Returns Min              6.77284
evaluation/ExplReturns Mean        34.75
evaluation/ExplReturns Std         24.4007
evaluation/ExplReturns Max         81.2412
evaluation/ExplReturns Min          6.77284
evaluation/Actions Mean            -0.0163219
evaluation/Actions Std              0.780696
evaluation/Actions Max              0.999996
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         34.75
time/data storing (s)               0.0295072
time/evaluation sampling (s)       67.6413
time/exploration sampling (s)      72.4412
time/logging (s)                    0.0251859
time/saving (s)                     0.0501035
time/training (s)                  10.8809
time/epoch (s)                    151.068
time/total (s)                   3788.7
Epoch                              25
-----------------------------  ----------------
2023-08-31 13:00:13.267053 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 26 finished
-----------------------------  ----------------
replay_buffer/size             136000
trainer/QF1 Loss                    0.0104741
trainer/QF2 Loss                    0.0099581
trainer/Policy Loss               -17.7377
trainer/Q1 Predictions Mean        24.4227
trainer/Q1 Predictions Std          2.11838
trainer/Q1 Predictions Max         55.5309
trainer/Q1 Predictions Min         19.5916
trainer/Q2 Predictions Mean        24.4145
trainer/Q2 Predictions Std          2.11411
trainer/Q2 Predictions Max         55.4946
trainer/Q2 Predictions Min         19.4713
trainer/Q Targets Mean             24.4455
trainer/Q Targets Std               2.13659
trainer/Q Targets Max              55.8799
trainer/Q Targets Min              19.6047
trainer/Log Pis Mean                6.72382
trainer/Log Pis Std                 6.40016
trainer/Log Pis Max                32.535
trainer/Log Pis Min                -8.32453
trainer/Policy mu Mean             -0.0978264
trainer/Policy mu Std               1.73602
trainer/Policy mu Max               5.54901
trainer/Policy mu Min              -5.09443
trainer/Policy log std Mean        -0.253492
trainer/Policy log std Std          0.219818
trainer/Policy log std Max          0.797668
trainer/Policy log std Min         -1.02033
trainer/Alpha                       0.00196568
trainer/Alpha Loss                 -1.72114
exploration/num steps total    136000
exploration/num paths total       272
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0102525
exploration/Rewards Std             0.0133792
exploration/Rewards Max             0.1898
exploration/Rewards Min             0.000614456
exploration/Returns Mean            5.12627
exploration/Returns Std             1.7091
exploration/Returns Max             7.90314
exploration/Returns Min             2.94726
exploration/Actions Mean           -0.0192471
exploration/Actions Std             0.637929
exploration/Actions Max             0.999885
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         5.12627
evaluation/num steps total     135000
evaluation/num paths total        270
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.100842
evaluation/Rewards Std              0.275315
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00180315
evaluation/Returns Mean            50.4209
evaluation/Returns Std            126.768
evaluation/Returns Max            430.589
evaluation/Returns Min              4.39868
evaluation/ExplReturns Mean        50.4209
evaluation/ExplReturns Std        126.768
evaluation/ExplReturns Max        430.589
evaluation/ExplReturns Min          4.39868
evaluation/Actions Mean            -0.0190972
evaluation/Actions Std              0.533251
evaluation/Actions Max              0.999932
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         50.4209
time/data storing (s)               0.0298217
time/evaluation sampling (s)       64.398
time/exploration sampling (s)      69.2929
time/logging (s)                    0.0254101
time/saving (s)                     0.0674428
time/training (s)                  11.209
time/epoch (s)                    145.023
time/total (s)                   3933.73
Epoch                              26
-----------------------------  ----------------
2023-08-31 13:02:41.141717 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 27 finished
-----------------------------  ----------------
replay_buffer/size             141000
trainer/QF1 Loss                    0.0173118
trainer/QF2 Loss                    0.0196528
trainer/Policy Loss               -17.2553
trainer/Q1 Predictions Mean        23.6658
trainer/Q1 Predictions Std          1.77179
trainer/Q1 Predictions Max         37.2696
trainer/Q1 Predictions Min         19.7703
trainer/Q2 Predictions Mean        23.6558
trainer/Q2 Predictions Std          1.77864
trainer/Q2 Predictions Max         37.3051
trainer/Q2 Predictions Min         19.8437
trainer/Q Targets Mean             23.6314
trainer/Q Targets Std               1.74409
trainer/Q Targets Max              36.8421
trainer/Q Targets Min              19.9594
trainer/Log Pis Mean                6.46065
trainer/Log Pis Std                 6.45342
trainer/Log Pis Max                29.1484
trainer/Log Pis Min                -5.12768
trainer/Policy mu Mean             -0.0662376
trainer/Policy mu Std               1.7308
trainer/Policy mu Max               5.13848
trainer/Policy mu Min              -5.05197
trainer/Policy log std Mean        -0.211048
trainer/Policy log std Std          0.217564
trainer/Policy log std Max          0.476534
trainer/Policy log std Min         -0.972297
trainer/Alpha                       0.00209639
trainer/Alpha Loss                 -3.32641
exploration/num steps total    141000
exploration/num paths total       282
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0444251
exploration/Rewards Std             0.11684
exploration/Rewards Max             1
exploration/Rewards Min             0.000453551
exploration/Returns Mean           22.2125
exploration/Returns Std            18.3469
exploration/Returns Max            63.8127
exploration/Returns Min             7.83431
exploration/Actions Mean            0.027268
exploration/Actions Std             0.736272
exploration/Actions Max             0.999999
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        22.2125
evaluation/num steps total     140000
evaluation/num paths total        280
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.1074
evaluation/Rewards Std              0.239183
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000170391
evaluation/Returns Mean            53.7001
evaluation/Returns Std             81.2585
evaluation/Returns Max            293.148
evaluation/Returns Min              7.98435
evaluation/ExplReturns Mean        53.7001
evaluation/ExplReturns Std         81.2585
evaluation/ExplReturns Max        293.148
evaluation/ExplReturns Min          7.98435
evaluation/Actions Mean             0.0564712
evaluation/Actions Std              0.704195
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999997
evaluation/Num Paths               10
evaluation/Average Returns         53.7001
time/data storing (s)               0.0301075
time/evaluation sampling (s)       67.6779
time/exploration sampling (s)      69.0757
time/logging (s)                    0.0254793
time/saving (s)                     0.0634131
time/training (s)                  10.9986
time/epoch (s)                    147.871
time/total (s)                   4081.6
Epoch                              27
-----------------------------  ----------------
2023-08-31 13:05:06.721177 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 28 finished
-----------------------------  ----------------
replay_buffer/size             146000
trainer/QF1 Loss                    0.0152973
trainer/QF2 Loss                    0.0185375
trainer/Policy Loss               -16.0281
trainer/Q1 Predictions Mean        23.0685
trainer/Q1 Predictions Std          3.76348
trainer/Q1 Predictions Max         55.1959
trainer/Q1 Predictions Min         19.8919
trainer/Q2 Predictions Mean        23.0588
trainer/Q2 Predictions Std          3.74961
trainer/Q2 Predictions Max         55.0242
trainer/Q2 Predictions Min         20.0558
trainer/Q Targets Mean             23.1249
trainer/Q Targets Std               3.79079
trainer/Q Targets Max              55.5459
trainer/Q Targets Min              20.0334
trainer/Log Pis Mean                7.09153
trainer/Log Pis Std                 5.57582
trainer/Log Pis Max                29.9672
trainer/Log Pis Min                -7.23893
trainer/Policy mu Mean             -0.202809
trainer/Policy mu Std               1.7411
trainer/Policy mu Max               5.25861
trainer/Policy mu Min              -4.75504
trainer/Policy log std Mean        -0.227793
trainer/Policy log std Std          0.236251
trainer/Policy log std Max          0.528538
trainer/Policy log std Min         -0.863168
trainer/Alpha                       0.00235523
trainer/Alpha Loss                  0.553865
exploration/num steps total    146000
exploration/num paths total       292
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0694321
exploration/Rewards Std             0.115441
exploration/Rewards Max             0.354739
exploration/Rewards Min             0.000517746
exploration/Returns Mean           34.716
exploration/Returns Std            51.7627
exploration/Returns Max           140.401
exploration/Returns Min             2.22402
exploration/Actions Mean           -0.138324
exploration/Actions Std             0.730015
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns        34.716
evaluation/num steps total     145000
evaluation/num paths total        290
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0129207
evaluation/Rewards Std              0.0199685
evaluation/Rewards Max              0.162418
evaluation/Rewards Min              0.000794869
evaluation/Returns Mean             6.46034
evaluation/Returns Std              4.52183
evaluation/Returns Max             17.4689
evaluation/Returns Min              2.83686
evaluation/ExplReturns Mean         6.46034
evaluation/ExplReturns Std          4.52183
evaluation/ExplReturns Max         17.4689
evaluation/ExplReturns Min          2.83686
evaluation/Actions Mean            -0.113315
evaluation/Actions Std              0.565829
evaluation/Actions Max              0.999985
evaluation/Actions Min             -0.999923
evaluation/Num Paths               10
evaluation/Average Returns          6.46034
time/data storing (s)               0.0299087
time/evaluation sampling (s)       64.3381
time/exploration sampling (s)      70.392
time/logging (s)                    0.0259548
time/saving (s)                     0.0706716
time/training (s)                  10.7197
time/epoch (s)                    145.576
time/total (s)                   4227.18
Epoch                              28
-----------------------------  ----------------
2023-08-31 13:07:30.518508 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 29 finished
-----------------------------  ----------------
replay_buffer/size             151000
trainer/QF1 Loss                    0.0100617
trainer/QF2 Loss                    0.0114655
trainer/Policy Loss               -15.2162
trainer/Q1 Predictions Mean        22.0305
trainer/Q1 Predictions Std          1.86494
trainer/Q1 Predictions Max         36.0294
trainer/Q1 Predictions Min         19.0788
trainer/Q2 Predictions Mean        22.0274
trainer/Q2 Predictions Std          1.88145
trainer/Q2 Predictions Max         36.1688
trainer/Q2 Predictions Min         19.0258
trainer/Q Targets Mean             22.0087
trainer/Q Targets Std               1.85603
trainer/Q Targets Max              35.9362
trainer/Q Targets Min              18.8781
trainer/Log Pis Mean                6.91213
trainer/Log Pis Std                 5.61273
trainer/Log Pis Max                28.4389
trainer/Log Pis Min                -5.02642
trainer/Policy mu Mean             -0.0470731
trainer/Policy mu Std               1.71505
trainer/Policy mu Max               5.3402
trainer/Policy mu Min              -4.46233
trainer/Policy log std Mean        -0.208507
trainer/Policy log std Std          0.258053
trainer/Policy log std Max          1.08267
trainer/Policy log std Min         -0.876184
trainer/Alpha                       0.00259987
trainer/Alpha Loss                 -0.523009
exploration/num steps total    151000
exploration/num paths total       302
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0380861
exploration/Rewards Std             0.0496687
exploration/Rewards Max             0.439739
exploration/Rewards Min             0.000967365
exploration/Returns Mean           19.0431
exploration/Returns Std             7.1381
exploration/Returns Max            33.9756
exploration/Returns Min            12.8042
exploration/Actions Mean           -0.0133012
exploration/Actions Std             0.695155
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999977
exploration/Num Paths              10
exploration/Average Returns        19.0431
evaluation/num steps total     150000
evaluation/num paths total        300
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0434843
evaluation/Rewards Std              0.035885
evaluation/Rewards Max              0.190024
evaluation/Rewards Min              0.00234971
evaluation/Returns Mean            21.7421
evaluation/Returns Std              1.41467
evaluation/Returns Max             23.7648
evaluation/Returns Min             19.3041
evaluation/ExplReturns Mean        21.7421
evaluation/ExplReturns Std          1.41467
evaluation/ExplReturns Max         23.7648
evaluation/ExplReturns Min         19.3041
evaluation/Actions Mean             0.0101502
evaluation/Actions Std              0.629048
evaluation/Actions Max              0.992172
evaluation/Actions Min             -0.994364
evaluation/Num Paths               10
evaluation/Average Returns         21.7421
time/data storing (s)               0.0294465
time/evaluation sampling (s)       63.8425
time/exploration sampling (s)      69.1587
time/logging (s)                    0.0254076
time/saving (s)                     0.0612753
time/training (s)                  10.6759
time/epoch (s)                    143.793
time/total (s)                   4370.98
Epoch                              29
-----------------------------  ----------------
2023-08-31 13:09:59.835167 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 30 finished
-----------------------------  ----------------
replay_buffer/size             156000
trainer/QF1 Loss                    0.0473828
trainer/QF2 Loss                    0.0434682
trainer/Policy Loss               -13.7079
trainer/Q1 Predictions Mean        21.1652
trainer/Q1 Predictions Std          2.05415
trainer/Q1 Predictions Max         43.0194
trainer/Q1 Predictions Min         17.9338
trainer/Q2 Predictions Mean        21.1953
trainer/Q2 Predictions Std          2.06973
trainer/Q2 Predictions Max         43.2477
trainer/Q2 Predictions Min         17.9505
trainer/Q Targets Mean             21.2535
trainer/Q Targets Std               2.05357
trainer/Q Targets Max              42.9194
trainer/Q Targets Min              17.9237
trainer/Log Pis Mean                7.52493
trainer/Log Pis Std                 5.31102
trainer/Log Pis Max                25.6394
trainer/Log Pis Min                -8.13933
trainer/Policy mu Mean             -0.00730104
trainer/Policy mu Std               1.77046
trainer/Policy mu Max               5.40536
trainer/Policy mu Min              -4.29276
trainer/Policy log std Mean        -0.266998
trainer/Policy log std Std          0.245203
trainer/Policy log std Max          0.626844
trainer/Policy log std Min         -0.971258
trainer/Alpha                       0.00308021
trainer/Alpha Loss                  3.03567
exploration/num steps total    156000
exploration/num paths total       312
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00312096
exploration/Rewards Std             0.00691319
exploration/Rewards Max             0.0999062
exploration/Rewards Min             9.34208e-07
exploration/Returns Mean            1.56048
exploration/Returns Std             0.381977
exploration/Returns Max             2.36048
exploration/Returns Min             1.00597
exploration/Actions Mean           -0.00713785
exploration/Actions Std             0.747085
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns         1.56048
evaluation/num steps total     155000
evaluation/num paths total        310
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00235074
evaluation/Rewards Std              0.0055228
evaluation/Rewards Max              0.134483
evaluation/Rewards Min              0.000368038
evaluation/Returns Mean             1.17537
evaluation/Returns Std              0.270643
evaluation/Returns Max              1.91338
evaluation/Returns Min              0.932546
evaluation/ExplReturns Mean         1.17537
evaluation/ExplReturns Std          0.270643
evaluation/ExplReturns Max          1.91338
evaluation/ExplReturns Min          0.932546
evaluation/Actions Mean             0.0105909
evaluation/Actions Std              0.693295
evaluation/Actions Max              0.999985
evaluation/Actions Min             -0.999829
evaluation/Num Paths               10
evaluation/Average Returns          1.17537
time/data storing (s)               0.0298556
time/evaluation sampling (s)       67.9923
time/exploration sampling (s)      70.5633
time/logging (s)                    0.0254109
time/saving (s)                     0.0672515
time/training (s)                  10.635
time/epoch (s)                    149.313
time/total (s)                   4520.29
Epoch                              30
-----------------------------  ----------------
2023-08-31 13:12:34.872592 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 31 finished
-----------------------------  ----------------
replay_buffer/size             161000
trainer/QF1 Loss                    0.0179783
trainer/QF2 Loss                    0.0191453
trainer/Policy Loss               -13.7493
trainer/Q1 Predictions Mean        20.8281
trainer/Q1 Predictions Std          2.64041
trainer/Q1 Predictions Max         44.0756
trainer/Q1 Predictions Min         17.9899
trainer/Q2 Predictions Mean        20.8375
trainer/Q2 Predictions Std          2.65963
trainer/Q2 Predictions Max         44.1912
trainer/Q2 Predictions Min         17.8879
trainer/Q Targets Mean             20.8718
trainer/Q Targets Std               2.64814
trainer/Q Targets Max              43.7163
trainer/Q Targets Min              18.115
trainer/Log Pis Mean                7.16491
trainer/Log Pis Std                 5.38793
trainer/Log Pis Max                28.0146
trainer/Log Pis Min                -5.03262
trainer/Policy mu Mean              0.0989076
trainer/Policy mu Std               1.72899
trainer/Policy mu Max               4.57283
trainer/Policy mu Min              -3.69027
trainer/Policy log std Mean        -0.265903
trainer/Policy log std Std          0.253501
trainer/Policy log std Max          0.786597
trainer/Policy log std Min         -0.865297
trainer/Alpha                       0.00315529
trainer/Alpha Loss                  0.949687
exploration/num steps total    161000
exploration/num paths total       322
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00455214
exploration/Rewards Std             0.0100307
exploration/Rewards Max             0.104703
exploration/Rewards Min             1.15067e-05
exploration/Returns Mean            2.27607
exploration/Returns Std             0.800969
exploration/Returns Max             3.88026
exploration/Returns Min             1.43731
exploration/Actions Mean            0.0622192
exploration/Actions Std             0.798295
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns         2.27607
evaluation/num steps total     160000
evaluation/num paths total        320
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0133333
evaluation/Rewards Std              0.0490153
evaluation/Rewards Max              0.407322
evaluation/Rewards Min              4.39829e-06
evaluation/Returns Mean             6.66664
evaluation/Returns Std              9.72278
evaluation/Returns Max             35.2389
evaluation/Returns Min              1.79579
evaluation/ExplReturns Mean         6.66664
evaluation/ExplReturns Std          9.72278
evaluation/ExplReturns Max         35.2389
evaluation/ExplReturns Min          1.79579
evaluation/Actions Mean             0.0891358
evaluation/Actions Std              0.71734
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.999965
evaluation/Num Paths               10
evaluation/Average Returns          6.66664
time/data storing (s)               0.0296648
time/evaluation sampling (s)       69.2267
time/exploration sampling (s)      74.8651
time/logging (s)                    0.0253677
time/saving (s)                     0.0650113
time/training (s)                  10.8219
time/epoch (s)                    155.034
time/total (s)                   4675.33
Epoch                              31
-----------------------------  ----------------
2023-08-31 13:15:06.708285 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 32 finished
-----------------------------  ----------------
replay_buffer/size             166000
trainer/QF1 Loss                    0.0435531
trainer/QF2 Loss                    0.0446127
trainer/Policy Loss               -12.6645
trainer/Q1 Predictions Mean        19.949
trainer/Q1 Predictions Std          2.29091
trainer/Q1 Predictions Max         38.5641
trainer/Q1 Predictions Min         16.4285
trainer/Q2 Predictions Mean        19.9674
trainer/Q2 Predictions Std          2.31742
trainer/Q2 Predictions Max         38.5906
trainer/Q2 Predictions Min         16.6083
trainer/Q Targets Mean             20.0009
trainer/Q Targets Std               2.29522
trainer/Q Targets Max              38.4643
trainer/Q Targets Min              16.5321
trainer/Log Pis Mean                7.38624
trainer/Log Pis Std                 5.94285
trainer/Log Pis Max                28.2801
trainer/Log Pis Min                -6.61821
trainer/Policy mu Mean              0.0100478
trainer/Policy mu Std               1.77265
trainer/Policy mu Max               5.70373
trainer/Policy mu Min              -4.75659
trainer/Policy log std Mean        -0.270647
trainer/Policy log std Std          0.269881
trainer/Policy log std Max          1.0151
trainer/Policy log std Min         -1.00107
trainer/Alpha                       0.00315065
trainer/Alpha Loss                  2.22488
exploration/num steps total    166000
exploration/num paths total       332
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00179343
exploration/Rewards Std             0.0018342
exploration/Rewards Max             0.0195216
exploration/Rewards Min             0.000316873
exploration/Returns Mean            0.896717
exploration/Returns Std             0.11484
exploration/Returns Max             1.18021
exploration/Returns Min             0.782396
exploration/Actions Mean            0.155597
exploration/Actions Std             0.785131
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         0.896717
evaluation/num steps total     165000
evaluation/num paths total        330
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00170241
evaluation/Rewards Std              0.00165258
evaluation/Rewards Max              0.0290406
evaluation/Rewards Min              0.000321074
evaluation/Returns Mean             0.851204
evaluation/Returns Std              0.0424213
evaluation/Returns Max              0.914546
evaluation/Returns Min              0.791244
evaluation/ExplReturns Mean         0.851204
evaluation/ExplReturns Std          0.0424213
evaluation/ExplReturns Max          0.914546
evaluation/ExplReturns Min          0.791244
evaluation/Actions Mean             0.0501828
evaluation/Actions Std              0.632881
evaluation/Actions Max              0.999493
evaluation/Actions Min             -0.998967
evaluation/Num Paths               10
evaluation/Average Returns          0.851204
time/data storing (s)               0.0298959
time/evaluation sampling (s)       70.1043
time/exploration sampling (s)      70.8464
time/logging (s)                    0.0255998
time/saving (s)                     0.0656622
time/training (s)                  10.7604
time/epoch (s)                    151.832
time/total (s)                   4827.17
Epoch                              32
-----------------------------  ----------------
2023-08-31 13:17:40.377962 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 33 finished
-----------------------------  ----------------
replay_buffer/size             171000
trainer/QF1 Loss                    0.0330679
trainer/QF2 Loss                    0.035226
trainer/Policy Loss               -11.8973
trainer/Q1 Predictions Mean        19.4463
trainer/Q1 Predictions Std          3.58757
trainer/Q1 Predictions Max         59.3159
trainer/Q1 Predictions Min         15.8489
trainer/Q2 Predictions Mean        19.4581
trainer/Q2 Predictions Std          3.57298
trainer/Q2 Predictions Max         59.1065
trainer/Q2 Predictions Min         15.9183
trainer/Q Targets Mean             19.403
trainer/Q Targets Std               3.62919
trainer/Q Targets Max              59.7017
trainer/Q Targets Min              15.8459
trainer/Log Pis Mean                7.58816
trainer/Log Pis Std                 6.09787
trainer/Log Pis Max                26.4785
trainer/Log Pis Min                -7.77558
trainer/Policy mu Mean             -0.129417
trainer/Policy mu Std               1.79317
trainer/Policy mu Max               4.39114
trainer/Policy mu Min              -6.13875
trainer/Policy log std Mean        -0.268619
trainer/Policy log std Std          0.248833
trainer/Policy log std Max          0.817045
trainer/Policy log std Min         -1.13651
trainer/Alpha                       0.00326732
trainer/Alpha Loss                  3.36678
exploration/num steps total    171000
exploration/num paths total       342
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0446608
exploration/Rewards Std             0.0851061
exploration/Rewards Max             0.38633
exploration/Rewards Min             0.000634206
exploration/Returns Mean           22.3304
exploration/Returns Std            33.9453
exploration/Returns Max           122.153
exploration/Returns Min             3.74457
exploration/Actions Mean           -0.0185825
exploration/Actions Std             0.803764
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns        22.3304
evaluation/num steps total     170000
evaluation/num paths total        340
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0901159
evaluation/Rewards Std              0.107317
evaluation/Rewards Max              0.399586
evaluation/Rewards Min              0.000541785
evaluation/Returns Mean            45.058
evaluation/Returns Std             37.6988
evaluation/Returns Max            106.907
evaluation/Returns Min              7.67236
evaluation/ExplReturns Mean        45.058
evaluation/ExplReturns Std         37.6988
evaluation/ExplReturns Max        106.907
evaluation/ExplReturns Min          7.67236
evaluation/Actions Mean            -0.0536565
evaluation/Actions Std              0.823376
evaluation/Actions Max              0.999987
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         45.058
time/data storing (s)               0.0297703
time/evaluation sampling (s)       69.2682
time/exploration sampling (s)      73.8397
time/logging (s)                    0.0255112
time/saving (s)                     0.0679442
time/training (s)                  10.4348
time/epoch (s)                    153.666
time/total (s)                   4980.83
Epoch                              33
-----------------------------  ----------------
2023-08-31 13:20:15.216907 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 34 finished
-----------------------------  ----------------
replay_buffer/size             176000
trainer/QF1 Loss                    0.0212622
trainer/QF2 Loss                    0.0224245
trainer/Policy Loss               -12.086
trainer/Q1 Predictions Mean        18.6767
trainer/Q1 Predictions Std          3.06603
trainer/Q1 Predictions Max         59.5226
trainer/Q1 Predictions Min         15.7717
trainer/Q2 Predictions Mean        18.7009
trainer/Q2 Predictions Std          3.06066
trainer/Q2 Predictions Max         59.4574
trainer/Q2 Predictions Min         15.7733
trainer/Q Targets Mean             18.669
trainer/Q Targets Std               3.08497
trainer/Q Targets Max              59.9073
trainer/Q Targets Min              15.8039
trainer/Log Pis Mean                6.68932
trainer/Log Pis Std                 6.10848
trainer/Log Pis Max                29.3147
trainer/Log Pis Min                -7.40908
trainer/Policy mu Mean              0.0798809
trainer/Policy mu Std               1.70742
trainer/Policy mu Max               5.68167
trainer/Policy mu Min              -4.23304
trainer/Policy log std Mean        -0.240273
trainer/Policy log std Std          0.261695
trainer/Policy log std Max          0.738748
trainer/Policy log std Min         -0.954523
trainer/Alpha                       0.00311918
trainer/Alpha Loss                 -1.79268
exploration/num steps total    176000
exploration/num paths total       352
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00681737
exploration/Rewards Std             0.00844513
exploration/Rewards Max             0.0932971
exploration/Rewards Min             0.000410941
exploration/Returns Mean            3.40869
exploration/Returns Std             0.859284
exploration/Returns Max             4.92541
exploration/Returns Min             1.9548
exploration/Actions Mean            0.056064
exploration/Actions Std             0.721003
exploration/Actions Max             0.999978
exploration/Actions Min            -0.999926
exploration/Num Paths              10
exploration/Average Returns         3.40869
evaluation/num steps total     175000
evaluation/num paths total        350
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00962843
evaluation/Rewards Std              0.0159017
evaluation/Rewards Max              0.134114
evaluation/Rewards Min              0.000826561
evaluation/Returns Mean             4.81422
evaluation/Returns Std              3.12876
evaluation/Returns Max             11.8496
evaluation/Returns Min              1.74067
evaluation/ExplReturns Mean         4.81422
evaluation/ExplReturns Std          3.12876
evaluation/ExplReturns Max         11.8496
evaluation/ExplReturns Min          1.74067
evaluation/Actions Mean             0.0106936
evaluation/Actions Std              0.639464
evaluation/Actions Max              0.999354
evaluation/Actions Min             -0.999436
evaluation/Num Paths               10
evaluation/Average Returns          4.81422
time/data storing (s)               0.0298027
time/evaluation sampling (s)       68.1917
time/exploration sampling (s)      72.8802
time/logging (s)                    0.0257564
time/saving (s)                     0.0671905
time/training (s)                  13.6409
time/epoch (s)                    154.836
time/total (s)                   5135.67
Epoch                              34
-----------------------------  ----------------
2023-08-31 13:22:53.050763 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 35 finished
-----------------------------  ----------------
replay_buffer/size             181000
trainer/QF1 Loss                    0.0271856
trainer/QF2 Loss                    0.0280404
trainer/Policy Loss               -11.9813
trainer/Q1 Predictions Mean        18.1912
trainer/Q1 Predictions Std          2.67178
trainer/Q1 Predictions Max         44.2314
trainer/Q1 Predictions Min         15.191
trainer/Q2 Predictions Mean        18.1779
trainer/Q2 Predictions Std          2.67406
trainer/Q2 Predictions Max         44.4128
trainer/Q2 Predictions Min         15.2194
trainer/Q Targets Mean             18.0976
trainer/Q Targets Std               2.62914
trainer/Q Targets Max              43.3106
trainer/Q Targets Min              15.088
trainer/Log Pis Mean                6.28648
trainer/Log Pis Std                 6.00163
trainer/Log Pis Max                37.937
trainer/Log Pis Min                -6.67777
trainer/Policy mu Mean              0.0103526
trainer/Policy mu Std               1.68379
trainer/Policy mu Max               4.47704
trainer/Policy mu Min              -5.60459
trainer/Policy log std Mean        -0.184489
trainer/Policy log std Std          0.2847
trainer/Policy log std Max          0.964473
trainer/Policy log std Min         -1.05399
trainer/Alpha                       0.00277822
trainer/Alpha Loss                 -4.1996
exploration/num steps total    181000
exploration/num paths total       362
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0206331
exploration/Rewards Std             0.0533135
exploration/Rewards Max             0.289488
exploration/Rewards Min             4.98377e-05
exploration/Returns Mean           10.3165
exploration/Returns Std            11.9211
exploration/Returns Max            44.1084
exploration/Returns Min             0.84753
exploration/Actions Mean            0.142586
exploration/Actions Std             0.767085
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        10.3165
evaluation/num steps total     180000
evaluation/num paths total        360
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0164037
evaluation/Rewards Std              0.0209155
evaluation/Rewards Max              0.245274
evaluation/Rewards Min              2.10173e-05
evaluation/Returns Mean             8.20183
evaluation/Returns Std              4.53732
evaluation/Returns Max             17.5944
evaluation/Returns Min              2.56753
evaluation/ExplReturns Mean         8.20183
evaluation/ExplReturns Std          4.53732
evaluation/ExplReturns Max         17.5944
evaluation/ExplReturns Min          2.56753
evaluation/Actions Mean             0.128533
evaluation/Actions Std              0.700522
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999984
evaluation/Num Paths               10
evaluation/Average Returns          8.20183
time/data storing (s)               0.0297826
time/evaluation sampling (s)       71.8435
time/exploration sampling (s)      74.8728
time/logging (s)                    0.0255304
time/saving (s)                     0.0689393
time/training (s)                  10.9895
time/epoch (s)                    157.83
time/total (s)                   5293.51
Epoch                              35
-----------------------------  ----------------
2023-08-31 13:25:28.528706 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 36 finished
-----------------------------  ----------------
replay_buffer/size             186000
trainer/QF1 Loss                    0.0386374
trainer/QF2 Loss                    0.050727
trainer/Policy Loss                -8.7333
trainer/Q1 Predictions Mean        17.6988
trainer/Q1 Predictions Std          3.625
trainer/Q1 Predictions Max         57.8132
trainer/Q1 Predictions Min         14.8565
trainer/Q2 Predictions Mean        17.6844
trainer/Q2 Predictions Std          3.6002
trainer/Q2 Predictions Max         57.4569
trainer/Q2 Predictions Min         14.8714
trainer/Q Targets Mean             17.7213
trainer/Q Targets Std               3.69218
trainer/Q Targets Max              58.6542
trainer/Q Targets Min              14.9489
trainer/Log Pis Mean                9.00432
trainer/Log Pis Std                 6.1456
trainer/Log Pis Max                24.5497
trainer/Log Pis Min                -4.1273
trainer/Policy mu Mean             -0.0456331
trainer/Policy mu Std               1.91511
trainer/Policy mu Max               4.77418
trainer/Policy mu Min              -4.48431
trainer/Policy log std Mean        -0.28439
trainer/Policy log std Std          0.248946
trainer/Policy log std Max          0.717959
trainer/Policy log std Min         -1.05152
trainer/Alpha                       0.00296847
trainer/Alpha Loss                 11.6655
exploration/num steps total    186000
exploration/num paths total       372
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0597936
exploration/Rewards Std             0.219415
exploration/Rewards Max             1
exploration/Rewards Min             9.66117e-05
exploration/Returns Mean           29.8968
exploration/Returns Std            80.6583
exploration/Returns Max           271.785
exploration/Returns Min             0.85064
exploration/Actions Mean            0.0621644
exploration/Actions Std             0.805625
exploration/Actions Max             1
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns        29.8968
evaluation/num steps total     185000
evaluation/num paths total        370
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0719434
evaluation/Rewards Std              0.248352
evaluation/Rewards Max              1
evaluation/Rewards Min              1.10078e-05
evaluation/Returns Mean            35.9717
evaluation/Returns Std            100.1
evaluation/Returns Max            336.195
evaluation/Returns Min              0.82605
evaluation/ExplReturns Mean        35.9717
evaluation/ExplReturns Std        100.1
evaluation/ExplReturns Max        336.195
evaluation/ExplReturns Min          0.82605
evaluation/Actions Mean             0.0033691
evaluation/Actions Std              0.803081
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns         35.9717
time/data storing (s)               0.0301092
time/evaluation sampling (s)       71.2427
time/exploration sampling (s)      73.5287
time/logging (s)                    0.0256037
time/saving (s)                     0.070054
time/training (s)                  10.5771
time/epoch (s)                    155.474
time/total (s)                   5448.98
Epoch                              36
-----------------------------  ----------------
2023-08-31 13:28:03.627363 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 37 finished
-----------------------------  ----------------
replay_buffer/size             191000
trainer/QF1 Loss                    0.0285203
trainer/QF2 Loss                    0.0256141
trainer/Policy Loss                -9.76891
trainer/Q1 Predictions Mean        17.3827
trainer/Q1 Predictions Std          4.57424
trainer/Q1 Predictions Max         62.2454
trainer/Q1 Predictions Min         13.4726
trainer/Q2 Predictions Mean        17.4005
trainer/Q2 Predictions Std          4.57089
trainer/Q2 Predictions Max         61.9333
trainer/Q2 Predictions Min         13.6616
trainer/Q Targets Mean             17.3742
trainer/Q Targets Std               4.54748
trainer/Q Targets Max              61.8552
trainer/Q Targets Min              13.6064
trainer/Log Pis Mean                7.6935
trainer/Log Pis Std                 5.9575
trainer/Log Pis Max                33.3124
trainer/Log Pis Min                -6.16209
trainer/Policy mu Mean             -0.255801
trainer/Policy mu Std               1.78749
trainer/Policy mu Max               4.9048
trainer/Policy mu Min              -5.09309
trainer/Policy log std Mean        -0.251165
trainer/Policy log std Std          0.24642
trainer/Policy log std Max          0.704072
trainer/Policy log std Min         -1.07077
trainer/Alpha                       0.00301495
trainer/Alpha Loss                  4.02532
exploration/num steps total    191000
exploration/num paths total       382
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.124595
exploration/Rewards Std             0.155895
exploration/Rewards Max             0.42408
exploration/Rewards Min             0.000300003
exploration/Returns Mean           62.2977
exploration/Returns Std            68.8745
exploration/Returns Max           170.373
exploration/Returns Min             5.79409
exploration/Actions Mean           -0.128945
exploration/Actions Std             0.796601
exploration/Actions Max             0.999999
exploration/Actions Min            -0.99999
exploration/Num Paths              10
exploration/Average Returns        62.2977
evaluation/num steps total     190000
evaluation/num paths total        380
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.115763
evaluation/Rewards Std              0.120488
evaluation/Rewards Max              0.422113
evaluation/Rewards Min              0.000445824
evaluation/Returns Mean            57.8816
evaluation/Returns Std             42.5429
evaluation/Returns Max            148.438
evaluation/Returns Min             11.9943
evaluation/ExplReturns Mean        57.8816
evaluation/ExplReturns Std         42.5429
evaluation/ExplReturns Max        148.438
evaluation/ExplReturns Min         11.9943
evaluation/Actions Mean            -0.109696
evaluation/Actions Std              0.775071
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.999677
evaluation/Num Paths               10
evaluation/Average Returns         57.8816
time/data storing (s)               0.0295205
time/evaluation sampling (s)       70.6839
time/exploration sampling (s)      73.818
time/logging (s)                    0.0255997
time/saving (s)                     0.0694433
time/training (s)                  10.4685
time/epoch (s)                    155.095
time/total (s)                   5604.08
Epoch                              37
-----------------------------  ----------------
2023-08-31 13:30:39.677064 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 38 finished
-----------------------------  ---------------
replay_buffer/size             196000
trainer/QF1 Loss                    0.0465569
trainer/QF2 Loss                    0.0499943
trainer/Policy Loss                -9.85447
trainer/Q1 Predictions Mean        16.9198
trainer/Q1 Predictions Std          4.80351
trainer/Q1 Predictions Max         64.5819
trainer/Q1 Predictions Min         13.3594
trainer/Q2 Predictions Mean        16.9385
trainer/Q2 Predictions Std          4.80296
trainer/Q2 Predictions Max         64.7645
trainer/Q2 Predictions Min         13.3425
trainer/Q Targets Mean             16.8613
trainer/Q Targets Std               4.84474
trainer/Q Targets Max              65.1016
trainer/Q Targets Min              13.3134
trainer/Log Pis Mean                7.16139
trainer/Log Pis Std                 5.35021
trainer/Log Pis Max                30.8616
trainer/Log Pis Min                -5.38244
trainer/Policy mu Mean             -0.216153
trainer/Policy mu Std               1.75479
trainer/Policy mu Max               4.94745
trainer/Policy mu Min              -5.08302
trainer/Policy log std Mean        -0.257488
trainer/Policy log std Std          0.265667
trainer/Policy log std Max          0.606475
trainer/Policy log std Min         -1.13411
trainer/Alpha                       0.00297514
trainer/Alpha Loss                  0.938885
exploration/num steps total    196000
exploration/num paths total       392
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0460414
exploration/Rewards Std             0.0879675
exploration/Rewards Max             0.406369
exploration/Rewards Min             4.9569e-06
exploration/Returns Mean           23.0207
exploration/Returns Std            30.2318
exploration/Returns Max           107.812
exploration/Returns Min             4.77536
exploration/Actions Mean           -0.124334
exploration/Actions Std             0.752378
exploration/Actions Max             0.999962
exploration/Actions Min            -0.999962
exploration/Num Paths              10
exploration/Average Returns        23.0207
evaluation/num steps total     195000
evaluation/num paths total        390
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0236157
evaluation/Rewards Std              0.0466171
evaluation/Rewards Max              0.325367
evaluation/Rewards Min              0.00083307
evaluation/Returns Mean            11.8078
evaluation/Returns Std              8.19661
evaluation/Returns Max             34.5753
evaluation/Returns Min              6.60056
evaluation/ExplReturns Mean        11.8078
evaluation/ExplReturns Std          8.19661
evaluation/ExplReturns Max         34.5753
evaluation/ExplReturns Min          6.60056
evaluation/Actions Mean            -0.138986
evaluation/Actions Std              0.692306
evaluation/Actions Max              0.999585
evaluation/Actions Min             -0.99995
evaluation/Num Paths               10
evaluation/Average Returns         11.8078
time/data storing (s)               0.0297204
time/evaluation sampling (s)       70.1162
time/exploration sampling (s)      74.9358
time/logging (s)                    0.0256754
time/saving (s)                     0.0704471
time/training (s)                  10.8683
time/epoch (s)                    156.046
time/total (s)                   5760.13
Epoch                              38
-----------------------------  ---------------
2023-08-31 13:33:13.614399 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 39 finished
-----------------------------  ----------------
replay_buffer/size             201000
trainer/QF1 Loss                    0.0358553
trainer/QF2 Loss                    0.0366165
trainer/Policy Loss               -10.332
trainer/Q1 Predictions Mean        16.4689
trainer/Q1 Predictions Std          5.13517
trainer/Q1 Predictions Max         67.8462
trainer/Q1 Predictions Min         13.1455
trainer/Q2 Predictions Mean        16.4666
trainer/Q2 Predictions Std          5.14978
trainer/Q2 Predictions Max         67.9694
trainer/Q2 Predictions Min         13.1023
trainer/Q Targets Mean             16.4045
trainer/Q Targets Std               5.21213
trainer/Q Targets Max              69.3751
trainer/Q Targets Min              13.0034
trainer/Log Pis Mean                6.21939
trainer/Log Pis Std                 5.72519
trainer/Log Pis Max                43.8816
trainer/Log Pis Min                -7.77553
trainer/Policy mu Mean              0.00842809
trainer/Policy mu Std               1.67232
trainer/Policy mu Max               7.808
trainer/Policy mu Min              -3.97149
trainer/Policy log std Mean        -0.258963
trainer/Policy log std Std          0.252165
trainer/Policy log std Max          0.634828
trainer/Policy log std Min         -1.00296
trainer/Alpha                       0.00305061
trainer/Alpha Loss                 -4.52141
exploration/num steps total    201000
exploration/num paths total       402
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0481688
exploration/Rewards Std             0.0846896
exploration/Rewards Max             0.34614
exploration/Rewards Min             9.06417e-05
exploration/Returns Mean           24.0844
exploration/Returns Std            25.1612
exploration/Returns Max            79.2346
exploration/Returns Min             4.76985
exploration/Actions Mean           -0.154556
exploration/Actions Std             0.746994
exploration/Actions Max             1
exploration/Actions Min            -0.999996
exploration/Num Paths              10
exploration/Average Returns        24.0844
evaluation/num steps total     200000
evaluation/num paths total        400
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.131339
evaluation/Rewards Std              0.133519
evaluation/Rewards Max              0.3258
evaluation/Rewards Min              0.000545201
evaluation/Returns Mean            65.6694
evaluation/Returns Std             58.8282
evaluation/Returns Max            151.345
evaluation/Returns Min              3.81867
evaluation/ExplReturns Mean        65.6694
evaluation/ExplReturns Std         58.8282
evaluation/ExplReturns Max        151.345
evaluation/ExplReturns Min          3.81867
evaluation/Actions Mean            -0.0831727
evaluation/Actions Std              0.808003
evaluation/Actions Max              1
evaluation/Actions Min             -0.999899
evaluation/Num Paths               10
evaluation/Average Returns         65.6694
time/data storing (s)               0.0298322
time/evaluation sampling (s)       68.7079
time/exploration sampling (s)      71.5256
time/logging (s)                    0.0255544
time/saving (s)                     0.0716025
time/training (s)                  13.5731
time/epoch (s)                    153.934
time/total (s)                   5914.07
Epoch                              39
-----------------------------  ----------------
2023-08-31 13:35:43.346578 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 40 finished
-----------------------------  ----------------
replay_buffer/size             206000
trainer/QF1 Loss                    0.091187
trainer/QF2 Loss                    0.108458
trainer/Policy Loss                -9.73751
trainer/Q1 Predictions Mean        16.5139
trainer/Q1 Predictions Std          5.65092
trainer/Q1 Predictions Max         69.4181
trainer/Q1 Predictions Min         12.2512
trainer/Q2 Predictions Mean        16.5052
trainer/Q2 Predictions Std          5.64606
trainer/Q2 Predictions Max         69.3236
trainer/Q2 Predictions Min         12.3198
trainer/Q Targets Mean             16.5692
trainer/Q Targets Std               5.7935
trainer/Q Targets Max              71.3134
trainer/Q Targets Min              12.4533
trainer/Log Pis Mean                6.8695
trainer/Log Pis Std                 5.97732
trainer/Log Pis Max                29.4598
trainer/Log Pis Min                -5.49595
trainer/Policy mu Mean              0.0815596
trainer/Policy mu Std               1.7548
trainer/Policy mu Max               5.62437
trainer/Policy mu Min              -5.20115
trainer/Policy log std Mean        -0.269747
trainer/Policy log std Std          0.253146
trainer/Policy log std Max          0.671978
trainer/Policy log std Min         -1.19135
trainer/Alpha                       0.00313323
trainer/Alpha Loss                 -0.75239
exploration/num steps total    206000
exploration/num paths total       412
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.238823
exploration/Rewards Std             0.347377
exploration/Rewards Max             1
exploration/Rewards Min             0.000283622
exploration/Returns Mean          119.412
exploration/Returns Std           150.846
exploration/Returns Max           422.394
exploration/Returns Min             3.55497
exploration/Actions Mean           -0.00580228
exploration/Actions Std             0.775534
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999993
exploration/Num Paths              10
exploration/Average Returns       119.412
evaluation/num steps total     205000
evaluation/num paths total        410
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.148252
evaluation/Rewards Std              0.24662
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000538141
evaluation/Returns Mean            74.1258
evaluation/Returns Std             98.982
evaluation/Returns Max            342.972
evaluation/Returns Min              2.67496
evaluation/ExplReturns Mean        74.1258
evaluation/ExplReturns Std         98.982
evaluation/ExplReturns Max        342.972
evaluation/ExplReturns Min          2.67496
evaluation/Actions Mean             0.0632627
evaluation/Actions Std              0.749301
evaluation/Actions Max              0.999989
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         74.1258
time/data storing (s)               0.0294561
time/evaluation sampling (s)       68.0832
time/exploration sampling (s)      70.8865
time/logging (s)                    0.0258768
time/saving (s)                     0.0658587
time/training (s)                  10.6379
time/epoch (s)                    149.729
time/total (s)                   6063.8
Epoch                              40
-----------------------------  ----------------
2023-08-31 13:38:18.458091 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 41 finished
-----------------------------  ----------------
replay_buffer/size             211000
trainer/QF1 Loss                    0.221822
trainer/QF2 Loss                    0.21277
trainer/Policy Loss                -7.88799
trainer/Q1 Predictions Mean        15.6344
trainer/Q1 Predictions Std          2.6533
trainer/Q1 Predictions Max         37.6027
trainer/Q1 Predictions Min         11.7888
trainer/Q2 Predictions Mean        15.6141
trainer/Q2 Predictions Std          2.65403
trainer/Q2 Predictions Max         37.5365
trainer/Q2 Predictions Min         11.4906
trainer/Q Targets Mean             15.5109
trainer/Q Targets Std               2.59367
trainer/Q Targets Max              35.3456
trainer/Q Targets Min              11.6337
trainer/Log Pis Mean                7.81466
trainer/Log Pis Std                 5.83295
trainer/Log Pis Max                30.8857
trainer/Log Pis Min                -7.49758
trainer/Policy mu Mean             -0.123648
trainer/Policy mu Std               1.835
trainer/Policy mu Max               5.34492
trainer/Policy mu Min              -6.19996
trainer/Policy log std Mean        -0.277439
trainer/Policy log std Std          0.24088
trainer/Policy log std Max          0.606584
trainer/Policy log std Min         -0.910145
trainer/Alpha                       0.00337784
trainer/Alpha Loss                  4.63624
exploration/num steps total    211000
exploration/num paths total       422
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0453294
exploration/Rewards Std             0.0922181
exploration/Rewards Max             0.403276
exploration/Rewards Min             1.00622e-05
exploration/Returns Mean           22.6647
exploration/Returns Std            27.4578
exploration/Returns Max            99.474
exploration/Returns Min             2.84464
exploration/Actions Mean           -0.0930673
exploration/Actions Std             0.814062
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999997
exploration/Num Paths              10
exploration/Average Returns        22.6647
evaluation/num steps total     210000
evaluation/num paths total        420
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.121857
evaluation/Rewards Std              0.146766
evaluation/Rewards Max              0.421194
evaluation/Rewards Min              0.000310886
evaluation/Returns Mean            60.9283
evaluation/Returns Std             65.2404
evaluation/Returns Max            196.785
evaluation/Returns Min              7.81779
evaluation/ExplReturns Mean        60.9283
evaluation/ExplReturns Std         65.2404
evaluation/ExplReturns Max        196.785
evaluation/ExplReturns Min          7.81779
evaluation/Actions Mean            -0.0926594
evaluation/Actions Std              0.788703
evaluation/Actions Max              1
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns         60.9283
time/data storing (s)               0.0300878
time/evaluation sampling (s)       69.9663
time/exploration sampling (s)      73.9598
time/logging (s)                    0.0256103
time/saving (s)                     0.0705729
time/training (s)                  11.0552
time/epoch (s)                    155.108
time/total (s)                   6218.91
Epoch                              41
-----------------------------  ----------------
2023-08-31 13:40:47.598474 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 42 finished
-----------------------------  ----------------
replay_buffer/size             216000
trainer/QF1 Loss                    0.2538
trainer/QF2 Loss                    0.265047
trainer/Policy Loss                -8.29347
trainer/Q1 Predictions Mean        16.0814
trainer/Q1 Predictions Std          6.00167
trainer/Q1 Predictions Max         66.0731
trainer/Q1 Predictions Min         11.3016
trainer/Q2 Predictions Mean        16.0632
trainer/Q2 Predictions Std          5.98273
trainer/Q2 Predictions Max         65.7372
trainer/Q2 Predictions Min         11.1326
trainer/Q Targets Mean             15.9733
trainer/Q Targets Std               6.30598
trainer/Q Targets Max              68.3034
trainer/Q Targets Min              11.4721
trainer/Log Pis Mean                7.89259
trainer/Log Pis Std                 6.14716
trainer/Log Pis Max                29.5225
trainer/Log Pis Min                -6.33629
trainer/Policy mu Mean             -0.255468
trainer/Policy mu Std               1.80698
trainer/Policy mu Max               5.52676
trainer/Policy mu Min              -4.36927
trainer/Policy log std Mean        -0.306366
trainer/Policy log std Std          0.241874
trainer/Policy log std Max          0.543128
trainer/Policy log std Min         -0.985678
trainer/Alpha                       0.00332204
trainer/Alpha Loss                  5.09421
exploration/num steps total    216000
exploration/num paths total       432
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.095524
exploration/Rewards Std             0.273994
exploration/Rewards Max             1
exploration/Rewards Min             0.000153301
exploration/Returns Mean           47.762
exploration/Returns Std           124.778
exploration/Returns Max           422.036
exploration/Returns Min             2.63862
exploration/Actions Mean           -0.266938
exploration/Actions Std             0.747144
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        47.762
evaluation/num steps total     215000
evaluation/num paths total        430
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0461538
evaluation/Rewards Std              0.163501
evaluation/Rewards Max              1
evaluation/Rewards Min              8.27143e-05
evaluation/Returns Mean            23.0769
evaluation/Returns Std             41.7783
evaluation/Returns Max            147.942
evaluation/Returns Min              4.75149
evaluation/ExplReturns Mean        23.0769
evaluation/ExplReturns Std         41.7783
evaluation/ExplReturns Max        147.942
evaluation/ExplReturns Min          4.75149
evaluation/Actions Mean            -0.263095
evaluation/Actions Std              0.682944
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999997
evaluation/Num Paths               10
evaluation/Average Returns         23.0769
time/data storing (s)               0.0297662
time/evaluation sampling (s)       66.9906
time/exploration sampling (s)      71.6989
time/logging (s)                    0.0252338
time/saving (s)                     0.0649451
time/training (s)                  10.3269
time/epoch (s)                    149.136
time/total (s)                   6368.05
Epoch                              42
-----------------------------  ----------------
2023-08-31 13:43:18.600118 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 43 finished
-----------------------------  ----------------
replay_buffer/size             221000
trainer/QF1 Loss                    0.412799
trainer/QF2 Loss                    0.414817
trainer/Policy Loss                -9.16815
trainer/Q1 Predictions Mean        16.3681
trainer/Q1 Predictions Std          9.30493
trainer/Q1 Predictions Max         71.3478
trainer/Q1 Predictions Min         10.5118
trainer/Q2 Predictions Mean        16.3713
trainer/Q2 Predictions Std          9.30789
trainer/Q2 Predictions Max         71.5039
trainer/Q2 Predictions Min         10.6146
trainer/Q Targets Mean             16.3786
trainer/Q Targets Std               9.64811
trainer/Q Targets Max              75.2794
trainer/Q Targets Min              10.68
trainer/Log Pis Mean                7.31863
trainer/Log Pis Std                 6.07376
trainer/Log Pis Max                32.9599
trainer/Log Pis Min                -4.40164
trainer/Policy mu Mean             -0.298951
trainer/Policy mu Std               1.73526
trainer/Policy mu Max               5.702
trainer/Policy mu Min              -5.32861
trainer/Policy log std Mean        -0.318571
trainer/Policy log std Std          0.231758
trainer/Policy log std Max          0.498018
trainer/Policy log std Min         -1.25667
trainer/Alpha                       0.00331115
trainer/Alpha Loss                  1.81953
exploration/num steps total    221000
exploration/num paths total       442
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.162796
exploration/Rewards Std             0.275866
exploration/Rewards Max             1
exploration/Rewards Min             5.29707e-06
exploration/Returns Mean           81.3981
exploration/Returns Std           126.432
exploration/Returns Max           426.957
exploration/Returns Min             2.04405
exploration/Actions Mean           -0.154209
exploration/Actions Std             0.778724
exploration/Actions Max             0.999877
exploration/Actions Min            -0.999989
exploration/Num Paths              10
exploration/Average Returns        81.3981
evaluation/num steps total     220000
evaluation/num paths total        440
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.05596
evaluation/Rewards Std              0.10555
evaluation/Rewards Max              1
evaluation/Rewards Min              1.70925e-06
evaluation/Returns Mean            27.98
evaluation/Returns Std             49.3963
evaluation/Returns Max            150.201
evaluation/Returns Min              2.42345
evaluation/ExplReturns Mean        27.98
evaluation/ExplReturns Std         49.3963
evaluation/ExplReturns Max        150.201
evaluation/ExplReturns Min          2.42345
evaluation/Actions Mean            -0.159282
evaluation/Actions Std              0.737054
evaluation/Actions Max              0.999269
evaluation/Actions Min             -0.999982
evaluation/Num Paths               10
evaluation/Average Returns         27.98
time/data storing (s)               0.0300962
time/evaluation sampling (s)       65.3077
time/exploration sampling (s)      75.0568
time/logging (s)                    0.0255037
time/saving (s)                     0.0821458
time/training (s)                  10.4962
time/epoch (s)                    150.998
time/total (s)                   6519.05
Epoch                              43
-----------------------------  ----------------
2023-08-31 13:45:51.963502 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 44 finished
-----------------------------  ----------------
replay_buffer/size             226000
trainer/QF1 Loss                    0.0758944
trainer/QF2 Loss                    0.0840014
trainer/Policy Loss               -10.2212
trainer/Q1 Predictions Mean        15.4907
trainer/Q1 Predictions Std          8.29579
trainer/Q1 Predictions Max         75.3799
trainer/Q1 Predictions Min         10.6669
trainer/Q2 Predictions Mean        15.4978
trainer/Q2 Predictions Std          8.28222
trainer/Q2 Predictions Max         75.1489
trainer/Q2 Predictions Min         10.4607
trainer/Q Targets Mean             15.5242
trainer/Q Targets Std               8.35408
trainer/Q Targets Max              75.3506
trainer/Q Targets Min              10.7961
trainer/Log Pis Mean                5.34814
trainer/Log Pis Std                 5.08493
trainer/Log Pis Max                21.0383
trainer/Log Pis Min                -5.51813
trainer/Policy mu Mean             -0.280633
trainer/Policy mu Std               1.58374
trainer/Policy mu Max               4.37498
trainer/Policy mu Min              -4.21314
trainer/Policy log std Mean        -0.257786
trainer/Policy log std Std          0.218079
trainer/Policy log std Max          0.483085
trainer/Policy log std Min         -0.891311
trainer/Alpha                       0.00307219
trainer/Alpha Loss                 -9.5563
exploration/num steps total    226000
exploration/num paths total       452
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0110015
exploration/Rewards Std             0.0290652
exploration/Rewards Max             0.322022
exploration/Rewards Min             4.2826e-06
exploration/Returns Mean            5.50075
exploration/Returns Std             4.17444
exploration/Returns Max            15.6447
exploration/Returns Min             1.8259
exploration/Actions Mean           -0.28393
exploration/Actions Std             0.738264
exploration/Actions Max             0.999895
exploration/Actions Min            -0.999991
exploration/Num Paths              10
exploration/Average Returns         5.50075
evaluation/num steps total     225000
evaluation/num paths total        450
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0123759
evaluation/Rewards Std              0.0221979
evaluation/Rewards Max              0.260097
evaluation/Rewards Min              0.000366842
evaluation/Returns Mean             6.18796
evaluation/Returns Std              2.68477
evaluation/Returns Max             12.0684
evaluation/Returns Min              3.23482
evaluation/ExplReturns Mean         6.18796
evaluation/ExplReturns Std          2.68477
evaluation/ExplReturns Max         12.0684
evaluation/ExplReturns Min          3.23482
evaluation/Actions Mean            -0.251575
evaluation/Actions Std              0.712307
evaluation/Actions Max              0.999206
evaluation/Actions Min             -0.999213
evaluation/Num Paths               10
evaluation/Average Returns          6.18796
time/data storing (s)               0.0297782
time/evaluation sampling (s)       69.4122
time/exploration sampling (s)      74.1871
time/logging (s)                    0.0256093
time/saving (s)                     0.0769841
time/training (s)                   9.62807
time/epoch (s)                    153.36
time/total (s)                   6672.41
Epoch                              44
-----------------------------  ----------------
2023-08-31 13:48:22.933118 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 45 finished
-----------------------------  ----------------
replay_buffer/size             231000
trainer/QF1 Loss                    0.0662342
trainer/QF2 Loss                    0.0674505
trainer/Policy Loss                -9.1466
trainer/Q1 Predictions Mean        14.6679
trainer/Q1 Predictions Std          6.57568
trainer/Q1 Predictions Max         77.2814
trainer/Q1 Predictions Min          9.19735
trainer/Q2 Predictions Mean        14.6594
trainer/Q2 Predictions Std          6.59726
trainer/Q2 Predictions Max         77.4518
trainer/Q2 Predictions Min          9.13765
trainer/Q Targets Mean             14.6524
trainer/Q Targets Std               6.61078
trainer/Q Targets Max              79.1211
trainer/Q Targets Min               9.28541
trainer/Log Pis Mean                5.57588
trainer/Log Pis Std                 5.88774
trainer/Log Pis Max                31.3627
trainer/Log Pis Min                -7.7869
trainer/Policy mu Mean             -0.062228
trainer/Policy mu Std               1.6264
trainer/Policy mu Max               5.11794
trainer/Policy mu Min              -5.73259
trainer/Policy log std Mean        -0.318581
trainer/Policy log std Std          0.186466
trainer/Policy log std Max          0.305062
trainer/Policy log std Min         -1.02065
trainer/Alpha                       0.00312762
trainer/Alpha Loss                 -8.21311
exploration/num steps total    231000
exploration/num paths total       462
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.10775
exploration/Rewards Std             0.271697
exploration/Rewards Max             1
exploration/Rewards Min             0.000467993
exploration/Returns Mean           53.8748
exploration/Returns Std           122.699
exploration/Returns Max           421.398
exploration/Returns Min             5.07889
exploration/Actions Mean           -0.0311862
exploration/Actions Std             0.78344
exploration/Actions Max             1
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns        53.8748
evaluation/num steps total     230000
evaluation/num paths total        460
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0400547
evaluation/Rewards Std              0.0726213
evaluation/Rewards Max              0.358262
evaluation/Rewards Min              2.12869e-06
evaluation/Returns Mean            20.0273
evaluation/Returns Std             33.2709
evaluation/Returns Max             87.6713
evaluation/Returns Min              1.94468
evaluation/ExplReturns Mean        20.0273
evaluation/ExplReturns Std         33.2709
evaluation/ExplReturns Max         87.6713
evaluation/ExplReturns Min          1.94468
evaluation/Actions Mean            -0.0266926
evaluation/Actions Std              0.838856
evaluation/Actions Max              0.999981
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         20.0273
time/data storing (s)               0.0303112
time/evaluation sampling (s)       65.6926
time/exploration sampling (s)      74.4296
time/logging (s)                    0.0277783
time/saving (s)                     0.0703352
time/training (s)                  10.7175
time/epoch (s)                    150.968
time/total (s)                   6823.38
Epoch                              45
-----------------------------  ----------------
2023-08-31 13:51:02.468499 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 46 finished
-----------------------------  ----------------
replay_buffer/size             236000
trainer/QF1 Loss                    0.188449
trainer/QF2 Loss                    0.202336
trainer/Policy Loss                -8.1111
trainer/Q1 Predictions Mean        14.3162
trainer/Q1 Predictions Std          5.78359
trainer/Q1 Predictions Max         71.287
trainer/Q1 Predictions Min          8.93448
trainer/Q2 Predictions Mean        14.3057
trainer/Q2 Predictions Std          5.78433
trainer/Q2 Predictions Max         71.4001
trainer/Q2 Predictions Min          8.62269
trainer/Q Targets Mean             14.4513
trainer/Q Targets Std               5.7719
trainer/Q Targets Max              71.048
trainer/Q Targets Min               8.61201
trainer/Log Pis Mean                6.26068
trainer/Log Pis Std                 5.49952
trainer/Log Pis Max                22.178
trainer/Log Pis Min                -7.87434
trainer/Policy mu Mean             -0.0504333
trainer/Policy mu Std               1.67549
trainer/Policy mu Max               4.76072
trainer/Policy mu Min              -5.07654
trainer/Policy log std Mean        -0.328918
trainer/Policy log std Std          0.198636
trainer/Policy log std Max          0.464783
trainer/Policy log std Min         -1.20804
trainer/Alpha                       0.00309922
trainer/Alpha Loss                 -4.27073
exploration/num steps total    236000
exploration/num paths total       472
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0949129
exploration/Rewards Std             0.279167
exploration/Rewards Max             1
exploration/Rewards Min             1.45749e-05
exploration/Returns Mean           47.4565
exploration/Returns Std           129.78
exploration/Returns Max           436.763
exploration/Returns Min             2.281
exploration/Actions Mean           -0.0795899
exploration/Actions Std             0.779742
exploration/Actions Max             1
exploration/Actions Min            -0.999985
exploration/Num Paths              10
exploration/Average Returns        47.4565
evaluation/num steps total     235000
evaluation/num paths total        470
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0114983
evaluation/Rewards Std              0.0232426
evaluation/Rewards Max              0.279265
evaluation/Rewards Min              1.0352e-05
evaluation/Returns Mean             5.74915
evaluation/Returns Std              6.39156
evaluation/Returns Max             23.3097
evaluation/Returns Min              1.98399
evaluation/ExplReturns Mean         5.74915
evaluation/ExplReturns Std          6.39156
evaluation/ExplReturns Max         23.3097
evaluation/ExplReturns Min          1.98399
evaluation/Actions Mean            -0.124939
evaluation/Actions Std              0.732003
evaluation/Actions Max              0.999969
evaluation/Actions Min             -0.999888
evaluation/Num Paths               10
evaluation/Average Returns          5.74915
time/data storing (s)               0.0294153
time/evaluation sampling (s)       71.5473
time/exploration sampling (s)      77.4326
time/logging (s)                    0.028092
time/saving (s)                     0.0308499
time/training (s)                  10.4636
time/epoch (s)                    159.532
time/total (s)                   6982.92
Epoch                              46
-----------------------------  ----------------
2023-08-31 13:53:36.589002 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 47 finished
-----------------------------  ----------------
replay_buffer/size             241000
trainer/QF1 Loss                    0.270985
trainer/QF2 Loss                    0.286018
trainer/Policy Loss                -9.34255
trainer/Q1 Predictions Mean        16.1074
trainer/Q1 Predictions Std         12.0274
trainer/Q1 Predictions Max        108.715
trainer/Q1 Predictions Min          8.04009
trainer/Q2 Predictions Mean        16.1229
trainer/Q2 Predictions Std         12.0389
trainer/Q2 Predictions Max        108.674
trainer/Q2 Predictions Min          7.997
trainer/Q Targets Mean             16.0622
trainer/Q Targets Std              11.9719
trainer/Q Targets Max             108.517
trainer/Q Targets Min               8.04559
trainer/Log Pis Mean                6.86005
trainer/Log Pis Std                 5.73785
trainer/Log Pis Max                23.7343
trainer/Log Pis Min                -9.12323
trainer/Policy mu Mean             -0.0438454
trainer/Policy mu Std               1.68708
trainer/Policy mu Max               4.68606
trainer/Policy mu Min              -4.18187
trainer/Policy log std Mean        -0.414257
trainer/Policy log std Std          0.171171
trainer/Policy log std Max          0.187648
trainer/Policy log std Min         -1.09478
trainer/Alpha                       0.00323286
trainer/Alpha Loss                 -0.80251
exploration/num steps total    241000
exploration/num paths total       482
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.25759
exploration/Rewards Std             0.415385
exploration/Rewards Max             1
exploration/Rewards Min             0.000831224
exploration/Returns Mean          128.795
exploration/Returns Std           182.168
exploration/Returns Max           429.591
exploration/Returns Min             3.55432
exploration/Actions Mean           -0.0195942
exploration/Actions Std             0.796757
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns       128.795
evaluation/num steps total     240000
evaluation/num paths total        480
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.109541
evaluation/Rewards Std              0.273804
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00142043
evaluation/Returns Mean            54.7707
evaluation/Returns Std            124.669
evaluation/Returns Max            424.969
evaluation/Returns Min              5.05411
evaluation/ExplReturns Mean        54.7707
evaluation/ExplReturns Std        124.669
evaluation/ExplReturns Max        424.969
evaluation/ExplReturns Min          5.05411
evaluation/Actions Mean            -0.151239
evaluation/Actions Std              0.749188
evaluation/Actions Max              0.99997
evaluation/Actions Min             -0.999845
evaluation/Num Paths               10
evaluation/Average Returns         54.7707
time/data storing (s)               0.0298884
time/evaluation sampling (s)       68.3937
time/exploration sampling (s)      72.3373
time/logging (s)                    0.0256695
time/saving (s)                     0.0813037
time/training (s)                  13.2464
time/epoch (s)                    154.114
time/total (s)                   7137.03
Epoch                              47
-----------------------------  ----------------
2023-08-31 13:56:05.166572 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 48 finished
-----------------------------  ----------------
replay_buffer/size             246000
trainer/QF1 Loss                    0.276842
trainer/QF2 Loss                    0.319315
trainer/Policy Loss               -10.0877
trainer/Q1 Predictions Mean        16.2499
trainer/Q1 Predictions Std         12.684
trainer/Q1 Predictions Max        106.013
trainer/Q1 Predictions Min          9.30909
trainer/Q2 Predictions Mean        16.2522
trainer/Q2 Predictions Std         12.7066
trainer/Q2 Predictions Max        106.011
trainer/Q2 Predictions Min          9.11658
trainer/Q Targets Mean             16.1615
trainer/Q Targets Std              12.7478
trainer/Q Targets Max             108.544
trainer/Q Targets Min               9.25933
trainer/Log Pis Mean                6.24321
trainer/Log Pis Std                 5.93337
trainer/Log Pis Max                30.3378
trainer/Log Pis Min                -4.72115
trainer/Policy mu Mean              0.104066
trainer/Policy mu Std               1.63171
trainer/Policy mu Max               5.05804
trainer/Policy mu Min              -4.28714
trainer/Policy log std Mean        -0.439752
trainer/Policy log std Std          0.161398
trainer/Policy log std Max          0.160521
trainer/Policy log std Min         -1.17808
trainer/Alpha                       0.00331253
trainer/Alpha Loss                 -4.32106
exploration/num steps total    246000
exploration/num paths total       492
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.333065
exploration/Rewards Std             0.447467
exploration/Rewards Max             1
exploration/Rewards Min             0.00132661
exploration/Returns Mean          166.532
exploration/Returns Std           188.93
exploration/Returns Max           432.871
exploration/Returns Min            10.2283
exploration/Actions Mean            0.111001
exploration/Actions Std             0.7716
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999989
exploration/Num Paths              10
exploration/Average Returns       166.532
evaluation/num steps total     245000
evaluation/num paths total        490
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.331113
evaluation/Rewards Std              0.415206
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000518438
evaluation/Returns Mean           165.556
evaluation/Returns Std            165.679
evaluation/Returns Max            426.658
evaluation/Returns Min             10.7546
evaluation/ExplReturns Mean       165.556
evaluation/ExplReturns Std        165.679
evaluation/ExplReturns Max        426.658
evaluation/ExplReturns Min         10.7546
evaluation/Actions Mean             0.116262
evaluation/Actions Std              0.73901
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999962
evaluation/Num Paths               10
evaluation/Average Returns        165.556
time/data storing (s)               0.0298969
time/evaluation sampling (s)       65.6356
time/exploration sampling (s)      69.9339
time/logging (s)                    0.0252766
time/saving (s)                     0.0714978
time/training (s)                  12.8773
time/epoch (s)                    148.573
time/total (s)                   7285.61
Epoch                              48
-----------------------------  ----------------
2023-08-31 13:58:37.684501 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 49 finished
-----------------------------  ---------------
replay_buffer/size             251000
trainer/QF1 Loss                    0.147263
trainer/QF2 Loss                    0.159086
trainer/Policy Loss                -9.0383
trainer/Q1 Predictions Mean        15.3678
trainer/Q1 Predictions Std         12.7121
trainer/Q1 Predictions Max        108.226
trainer/Q1 Predictions Min          8.88279
trainer/Q2 Predictions Mean        15.3327
trainer/Q2 Predictions Std         12.6794
trainer/Q2 Predictions Max        108.104
trainer/Q2 Predictions Min          8.79004
trainer/Q Targets Mean             15.4962
trainer/Q Targets Std              12.7897
trainer/Q Targets Max             109.049
trainer/Q Targets Min               8.81295
trainer/Log Pis Mean                6.39901
trainer/Log Pis Std                 5.61763
trainer/Log Pis Max                23.0682
trainer/Log Pis Min                -5.50347
trainer/Policy mu Mean              0.206564
trainer/Policy mu Std               1.64403
trainer/Policy mu Max               4.95994
trainer/Policy mu Min              -4.04231
trainer/Policy log std Mean        -0.472548
trainer/Policy log std Std          0.156395
trainer/Policy log std Max          0.150182
trainer/Policy log std Min         -0.990719
trainer/Alpha                       0.00390866
trainer/Alpha Loss                 -3.3323
exploration/num steps total    251000
exploration/num paths total       502
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.757953
exploration/Rewards Std             0.409378
exploration/Rewards Max             1
exploration/Rewards Min             0.00101887
exploration/Returns Mean          378.976
exploration/Returns Std           183.951
exploration/Returns Max           481.319
exploration/Returns Min             7.32802
exploration/Actions Mean            0.232132
exploration/Actions Std             0.836341
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns       378.976
evaluation/num steps total     250000
evaluation/num paths total        500
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.568064
evaluation/Rewards Std              0.392822
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00172349
evaluation/Returns Mean           284.032
evaluation/Returns Std            164.974
evaluation/Returns Max            479.811
evaluation/Returns Min             46.3088
evaluation/ExplReturns Mean       284.032
evaluation/ExplReturns Std        164.974
evaluation/ExplReturns Max        479.811
evaluation/ExplReturns Min         46.3088
evaluation/Actions Mean             0.184075
evaluation/Actions Std              0.840319
evaluation/Actions Max              0.999975
evaluation/Actions Min             -0.999979
evaluation/Num Paths               10
evaluation/Average Returns        284.032
time/data storing (s)               0.0296934
time/evaluation sampling (s)       68.4218
time/exploration sampling (s)      73.0567
time/logging (s)                    0.0251954
time/saving (s)                     0.0210439
time/training (s)                  10.9597
time/epoch (s)                    152.514
time/total (s)                   7438.13
Epoch                              49
-----------------------------  ---------------
2023-08-31 14:01:08.268655 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 50 finished
-----------------------------  ----------------
replay_buffer/size             256000
trainer/QF1 Loss                    0.286812
trainer/QF2 Loss                    0.287011
trainer/Policy Loss                -9.95925
trainer/Q1 Predictions Mean        16.2992
trainer/Q1 Predictions Std         13.7289
trainer/Q1 Predictions Max         91.1418
trainer/Q1 Predictions Min          8.04839
trainer/Q2 Predictions Mean        16.3188
trainer/Q2 Predictions Std         13.7053
trainer/Q2 Predictions Max         91.7679
trainer/Q2 Predictions Min          8.1237
trainer/Q Targets Mean             16.3009
trainer/Q Targets Std              13.725
trainer/Q Targets Max              91.2841
trainer/Q Targets Min               8.25237
trainer/Log Pis Mean                6.49285
trainer/Log Pis Std                 5.35376
trainer/Log Pis Max                27.1161
trainer/Log Pis Min                -5.62485
trainer/Policy mu Mean             -0.263904
trainer/Policy mu Std               1.6216
trainer/Policy mu Max               4.32547
trainer/Policy mu Min              -4.61392
trainer/Policy log std Mean        -0.51678
trainer/Policy log std Std          0.175347
trainer/Policy log std Max          0.474928
trainer/Policy log std Min         -1.2713
trainer/Alpha                       0.00438872
trainer/Alpha Loss                 -2.75323
exploration/num steps total    256000
exploration/num paths total       512
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.110437
exploration/Rewards Std             0.127022
exploration/Rewards Max             1
exploration/Rewards Min             0.000657654
exploration/Returns Mean           55.2183
exploration/Returns Std            35.0081
exploration/Returns Max           122.986
exploration/Returns Min            21.9491
exploration/Actions Mean           -0.115463
exploration/Actions Std             0.793875
exploration/Actions Max             0.999981
exploration/Actions Min            -0.999997
exploration/Num Paths              10
exploration/Average Returns        55.2183
evaluation/num steps total     255000
evaluation/num paths total        510
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.176141
evaluation/Rewards Std              0.261305
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0013852
evaluation/Returns Mean            88.0706
evaluation/Returns Std            115.632
evaluation/Returns Max            418.523
evaluation/Returns Min             15.1904
evaluation/ExplReturns Mean        88.0706
evaluation/ExplReturns Std        115.632
evaluation/ExplReturns Max        418.523
evaluation/ExplReturns Min         15.1904
evaluation/Actions Mean            -0.10454
evaluation/Actions Std              0.756024
evaluation/Actions Max              0.999959
evaluation/Actions Min             -0.999992
evaluation/Num Paths               10
evaluation/Average Returns         88.0706
time/data storing (s)               0.0292338
time/evaluation sampling (s)       67.2388
time/exploration sampling (s)      72.0667
time/logging (s)                    0.025735
time/saving (s)                     0.0638735
time/training (s)                  11.1566
time/epoch (s)                    150.581
time/total (s)                   7588.71
Epoch                              50
-----------------------------  ----------------
2023-08-31 14:03:36.074178 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size             261000
trainer/QF1 Loss                    0.786724
trainer/QF2 Loss                    0.753807
trainer/Policy Loss               -10.5954
trainer/Q1 Predictions Mean        16.998
trainer/Q1 Predictions Std         14.9306
trainer/Q1 Predictions Max         92.436
trainer/Q1 Predictions Min          7.29324
trainer/Q2 Predictions Mean        17.0178
trainer/Q2 Predictions Std         14.9754
trainer/Q2 Predictions Max         92.6679
trainer/Q2 Predictions Min          7.54312
trainer/Q Targets Mean             17.1192
trainer/Q Targets Std              14.9575
trainer/Q Targets Max              92.5573
trainer/Q Targets Min               7.23761
trainer/Log Pis Mean                6.57187
trainer/Log Pis Std                 5.05194
trainer/Log Pis Max                24.9975
trainer/Log Pis Min                -6.55411
trainer/Policy mu Mean              0.163982
trainer/Policy mu Std               1.60721
trainer/Policy mu Max               3.72245
trainer/Policy mu Min              -5.06477
trainer/Policy log std Mean        -0.534581
trainer/Policy log std Std          0.163387
trainer/Policy log std Max          0.108415
trainer/Policy log std Min         -1.29515
trainer/Alpha                       0.00476804
trainer/Alpha Loss                 -2.28869
exploration/num steps total    261000
exploration/num paths total       522
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.203325
exploration/Rewards Std             0.31575
exploration/Rewards Max             1
exploration/Rewards Min             0.00196864
exploration/Returns Mean          101.662
exploration/Returns Std           103.441
exploration/Returns Max           358.212
exploration/Returns Min             9.19762
exploration/Actions Mean            0.192603
exploration/Actions Std             0.687765
exploration/Actions Max             0.999994
exploration/Actions Min            -0.999912
exploration/Num Paths              10
exploration/Average Returns       101.662
evaluation/num steps total     260000
evaluation/num paths total        520
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.202879
evaluation/Rewards Std              0.322497
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00136714
evaluation/Returns Mean           101.44
evaluation/Returns Std             89.525
evaluation/Returns Max            273.621
evaluation/Returns Min             10.3484
evaluation/ExplReturns Mean       101.44
evaluation/ExplReturns Std         89.525
evaluation/ExplReturns Max        273.621
evaluation/ExplReturns Min         10.3484
evaluation/Actions Mean             0.148715
evaluation/Actions Std              0.650616
evaluation/Actions Max              0.999978
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns        101.44
time/data storing (s)               0.0300763
time/evaluation sampling (s)       66.0341
time/exploration sampling (s)      70.8485
time/logging (s)                    0.025696
time/saving (s)                     0.0647649
time/training (s)                  10.7987
time/epoch (s)                    147.802
time/total (s)                   7736.51
Epoch                              51
-----------------------------  ---------------
2023-08-31 14:06:05.921528 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             266000
trainer/QF1 Loss                    0.314876
trainer/QF2 Loss                    0.347982
trainer/Policy Loss                -8.25077
trainer/Q1 Predictions Mean        17.0303
trainer/Q1 Predictions Std         14.6441
trainer/Q1 Predictions Max        106.748
trainer/Q1 Predictions Min          7.27538
trainer/Q2 Predictions Mean        17.0253
trainer/Q2 Predictions Std         14.6487
trainer/Q2 Predictions Max        107.409
trainer/Q2 Predictions Min          7.44984
trainer/Q Targets Mean             16.959
trainer/Q Targets Std              14.5673
trainer/Q Targets Max             106.241
trainer/Q Targets Min               7.1854
trainer/Log Pis Mean                9.01075
trainer/Log Pis Std                 7.77513
trainer/Log Pis Max                37.175
trainer/Log Pis Min                -7.1017
trainer/Policy mu Mean              0.143637
trainer/Policy mu Std               1.81142
trainer/Policy mu Max               5.27179
trainer/Policy mu Min              -5.8066
trainer/Policy log std Mean        -0.565054
trainer/Policy log std Std          0.174248
trainer/Policy log std Max          0.0947438
trainer/Policy log std Min         -1.29172
trainer/Alpha                       0.00539576
trainer/Alpha Loss                 10.5011
exploration/num steps total    266000
exploration/num paths total       532
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0259463
exploration/Rewards Std             0.0306318
exploration/Rewards Max             0.276772
exploration/Rewards Min             0.00068704
exploration/Returns Mean           12.9732
exploration/Returns Std             4.4269
exploration/Returns Max            22.3748
exploration/Returns Min             6.93755
exploration/Actions Mean            0.164232
exploration/Actions Std             0.675867
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        12.9732
evaluation/num steps total     265000
evaluation/num paths total        530
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0708704
evaluation/Rewards Std              0.0604773
evaluation/Rewards Max              0.311309
evaluation/Rewards Min              0.00220341
evaluation/Returns Mean            35.4352
evaluation/Returns Std             28.4042
evaluation/Returns Max             92.9566
evaluation/Returns Min             14.9765
evaluation/ExplReturns Mean        35.4352
evaluation/ExplReturns Std         28.4042
evaluation/ExplReturns Max         92.9566
evaluation/ExplReturns Min         14.9765
evaluation/Actions Mean             0.139046
evaluation/Actions Std              0.631673
evaluation/Actions Max              0.999942
evaluation/Actions Min             -0.999147
evaluation/Num Paths               10
evaluation/Average Returns         35.4352
time/data storing (s)               0.029833
time/evaluation sampling (s)       68.4587
time/exploration sampling (s)      70.0135
time/logging (s)                    0.0254531
time/saving (s)                     0.0827502
time/training (s)                  11.2331
time/epoch (s)                    149.843
time/total (s)                   7886.36
Epoch                              52
-----------------------------  ---------------
2023-08-31 14:08:36.136385 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 53 finished
-----------------------------  ----------------
replay_buffer/size             271000
trainer/QF1 Loss                    0.471231
trainer/QF2 Loss                    0.474674
trainer/Policy Loss               -10.3531
trainer/Q1 Predictions Mean        16.4385
trainer/Q1 Predictions Std         13.068
trainer/Q1 Predictions Max         95.9019
trainer/Q1 Predictions Min          7.54569
trainer/Q2 Predictions Mean        16.4427
trainer/Q2 Predictions Std         13.083
trainer/Q2 Predictions Max         96.1152
trainer/Q2 Predictions Min          8.28773
trainer/Q Targets Mean             16.5645
trainer/Q Targets Std              13.1812
trainer/Q Targets Max              96.538
trainer/Q Targets Min               7.99796
trainer/Log Pis Mean                6.24164
trainer/Log Pis Std                 5.71162
trainer/Log Pis Max                33.123
trainer/Log Pis Min                -7.17126
trainer/Policy mu Mean              0.0465011
trainer/Policy mu Std               1.62164
trainer/Policy mu Max               4.43592
trainer/Policy mu Min              -4.47039
trainer/Policy log std Mean        -0.552211
trainer/Policy log std Std          0.182359
trainer/Policy log std Max          0.220822
trainer/Policy log std Min         -1.29309
trainer/Alpha                       0.00548495
trainer/Alpha Loss                 -3.94802
exploration/num steps total    271000
exploration/num paths total       542
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.502403
exploration/Rewards Std             0.413548
exploration/Rewards Max             1
exploration/Rewards Min             0.00154822
exploration/Returns Mean          251.201
exploration/Returns Std           156.58
exploration/Returns Max           481.649
exploration/Returns Min            25.0635
exploration/Actions Mean            0.136558
exploration/Actions Std             0.787609
exploration/Actions Max             0.999997
exploration/Actions Min            -0.99998
exploration/Num Paths              10
exploration/Average Returns       251.201
evaluation/num steps total     270000
evaluation/num paths total        540
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.173125
evaluation/Rewards Std              0.255241
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000703575
evaluation/Returns Mean            86.5625
evaluation/Returns Std            106.26
evaluation/Returns Max            335.501
evaluation/Returns Min              7.99773
evaluation/ExplReturns Mean        86.5625
evaluation/ExplReturns Std        106.26
evaluation/ExplReturns Max        335.501
evaluation/ExplReturns Min          7.99773
evaluation/Actions Mean            -0.00487312
evaluation/Actions Std              0.683714
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999961
evaluation/Num Paths               10
evaluation/Average Returns         86.5625
time/data storing (s)               0.0300563
time/evaluation sampling (s)       66.2227
time/exploration sampling (s)      72.7685
time/logging (s)                    0.0256151
time/saving (s)                     0.0714774
time/training (s)                  11.093
time/epoch (s)                    150.211
time/total (s)                   8036.57
Epoch                              53
-----------------------------  ----------------
2023-08-31 14:11:04.992213 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 54 finished
-----------------------------  ----------------
replay_buffer/size             276000
trainer/QF1 Loss                    0.520549
trainer/QF2 Loss                    0.482952
trainer/Policy Loss               -12.6576
trainer/Q1 Predictions Mean        18.6792
trainer/Q1 Predictions Std         16.4055
trainer/Q1 Predictions Max         97.53
trainer/Q1 Predictions Min          7.62392
trainer/Q2 Predictions Mean        18.6579
trainer/Q2 Predictions Std         16.4225
trainer/Q2 Predictions Max         97.2316
trainer/Q2 Predictions Min          7.70281
trainer/Q Targets Mean             18.6309
trainer/Q Targets Std              16.5203
trainer/Q Targets Max              96.2259
trainer/Q Targets Min               7.44507
trainer/Log Pis Mean                6.21484
trainer/Log Pis Std                 5.34822
trainer/Log Pis Max                31.3865
trainer/Log Pis Min                -6.17318
trainer/Policy mu Mean              0.0549174
trainer/Policy mu Std               1.5947
trainer/Policy mu Max               5.53333
trainer/Policy mu Min              -4.91144
trainer/Policy log std Mean        -0.561087
trainer/Policy log std Std          0.18522
trainer/Policy log std Max          0.022337
trainer/Policy log std Min         -1.53183
trainer/Alpha                       0.00584068
trainer/Alpha Loss                 -4.03798
exploration/num steps total    276000
exploration/num paths total       552
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.371985
exploration/Rewards Std             0.439556
exploration/Rewards Max             1
exploration/Rewards Min             2.16099e-06
exploration/Returns Mean          185.993
exploration/Returns Std           159.71
exploration/Returns Max           383.135
exploration/Returns Min             2.57126
exploration/Actions Mean            0.149709
exploration/Actions Std             0.747633
exploration/Actions Max             0.999994
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       185.993
evaluation/num steps total     275000
evaluation/num paths total        550
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.133227
evaluation/Rewards Std              0.231996
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000967465
evaluation/Returns Mean            66.6136
evaluation/Returns Std             78.9131
evaluation/Returns Max            280.986
evaluation/Returns Min              6.88754
evaluation/ExplReturns Mean        66.6136
evaluation/ExplReturns Std         78.9131
evaluation/ExplReturns Max        280.986
evaluation/ExplReturns Min          6.88754
evaluation/Actions Mean             0.0713428
evaluation/Actions Std              0.664275
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.999994
evaluation/Num Paths               10
evaluation/Average Returns         66.6136
time/data storing (s)               0.0299348
time/evaluation sampling (s)       67.6267
time/exploration sampling (s)      70.6532
time/logging (s)                    0.0256295
time/saving (s)                     0.0643795
time/training (s)                  10.4523
time/epoch (s)                    148.852
time/total (s)                   8185.43
Epoch                              54
-----------------------------  ----------------
2023-08-31 14:13:36.859919 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 55 finished
-----------------------------  ----------------
replay_buffer/size             281000
trainer/QF1 Loss                    0.453126
trainer/QF2 Loss                    0.415119
trainer/Policy Loss               -14.8571
trainer/Q1 Predictions Mean        21.7382
trainer/Q1 Predictions Std         19.7412
trainer/Q1 Predictions Max        104.146
trainer/Q1 Predictions Min          5.30918
trainer/Q2 Predictions Mean        21.7042
trainer/Q2 Predictions Std         19.6761
trainer/Q2 Predictions Max        104.089
trainer/Q2 Predictions Min          5.71301
trainer/Q Targets Mean             21.6519
trainer/Q Targets Std              19.6132
trainer/Q Targets Max             104.44
trainer/Q Targets Min               4.83306
trainer/Log Pis Mean                7.12543
trainer/Log Pis Std                 5.8213
trainer/Log Pis Max                32.4889
trainer/Log Pis Min                -5.64974
trainer/Policy mu Mean             -0.154133
trainer/Policy mu Std               1.66876
trainer/Policy mu Max               5.00257
trainer/Policy mu Min              -3.90357
trainer/Policy log std Mean        -0.574829
trainer/Policy log std Std          0.182784
trainer/Policy log std Max          0.294923
trainer/Policy log std Min         -1.38817
trainer/Alpha                       0.00647618
trainer/Alpha Loss                  0.632175
exploration/num steps total    281000
exploration/num paths total       562
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.43936
exploration/Rewards Std             0.462628
exploration/Rewards Max             1
exploration/Rewards Min             3.80596e-06
exploration/Returns Mean          219.68
exploration/Returns Std           217.811
exploration/Returns Max           484.524
exploration/Returns Min             6.43914
exploration/Actions Mean            0.0465908
exploration/Actions Std             0.793309
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999964
exploration/Num Paths              10
exploration/Average Returns       219.68
evaluation/num steps total     280000
evaluation/num paths total        560
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.471597
evaluation/Rewards Std              0.425831
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00202419
evaluation/Returns Mean           235.799
evaluation/Returns Std            206.009
evaluation/Returns Max            485.425
evaluation/Returns Min             10.6205
evaluation/ExplReturns Mean       235.799
evaluation/ExplReturns Std        206.009
evaluation/ExplReturns Max        485.425
evaluation/ExplReturns Min         10.6205
evaluation/Actions Mean             0.0132634
evaluation/Actions Std              0.782521
evaluation/Actions Max              0.999915
evaluation/Actions Min             -0.999846
evaluation/Num Paths               10
evaluation/Average Returns        235.799
time/data storing (s)               0.0297732
time/evaluation sampling (s)       66.8115
time/exploration sampling (s)      70.9121
time/logging (s)                    0.0257548
time/saving (s)                     0.0675196
time/training (s)                  14.0174
time/epoch (s)                    151.864
time/total (s)                   8337.3
Epoch                              55
-----------------------------  ----------------
2023-08-31 14:16:08.961481 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 56 finished
-----------------------------  ----------------
replay_buffer/size             286000
trainer/QF1 Loss                    0.331495
trainer/QF2 Loss                    0.269953
trainer/Policy Loss               -13.1435
trainer/Q1 Predictions Mean        19.7211
trainer/Q1 Predictions Std         16.4625
trainer/Q1 Predictions Max         88.0579
trainer/Q1 Predictions Min          7.3914
trainer/Q2 Predictions Mean        19.6701
trainer/Q2 Predictions Std         16.4389
trainer/Q2 Predictions Max         87.6757
trainer/Q2 Predictions Min          7.65956
trainer/Q Targets Mean             19.7232
trainer/Q Targets Std              16.5115
trainer/Q Targets Max              87.9483
trainer/Q Targets Min               7.83143
trainer/Log Pis Mean                6.84709
trainer/Log Pis Std                 4.70679
trainer/Log Pis Max                28.2114
trainer/Log Pis Min                -3.95808
trainer/Policy mu Mean             -0.0346453
trainer/Policy mu Std               1.60535
trainer/Policy mu Max               5.0146
trainer/Policy mu Min              -3.95418
trainer/Policy log std Mean        -0.581525
trainer/Policy log std Std          0.17509
trainer/Policy log std Max         -0.0141192
trainer/Policy log std Min         -1.31822
trainer/Alpha                       0.00704528
trainer/Alpha Loss                 -0.7577
exploration/num steps total    286000
exploration/num paths total       572
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.377237
exploration/Rewards Std             0.434468
exploration/Rewards Max             1
exploration/Rewards Min             0.00125981
exploration/Returns Mean          188.618
exploration/Returns Std           193.327
exploration/Returns Max           485.362
exploration/Returns Min            11.7562
exploration/Actions Mean            0.120158
exploration/Actions Std             0.75226
exploration/Actions Max             0.999976
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns       188.618
evaluation/num steps total     285000
evaluation/num paths total        570
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.266118
evaluation/Rewards Std              0.385201
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000435666
evaluation/Returns Mean           133.059
evaluation/Returns Std            167.932
evaluation/Returns Max            485.81
evaluation/Returns Min              8.19519
evaluation/ExplReturns Mean       133.059
evaluation/ExplReturns Std        167.932
evaluation/ExplReturns Max        485.81
evaluation/ExplReturns Min          8.19519
evaluation/Actions Mean             0.10144
evaluation/Actions Std              0.747205
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.99995
evaluation/Num Paths               10
evaluation/Average Returns        133.059
time/data storing (s)               0.0298996
time/evaluation sampling (s)       67.791
time/exploration sampling (s)      71.5256
time/logging (s)                    0.0255812
time/saving (s)                     0.0698902
time/training (s)                  12.6556
time/epoch (s)                    152.098
time/total (s)                   8489.4
Epoch                              56
-----------------------------  ----------------
2023-08-31 14:18:38.086568 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 57 finished
-----------------------------  ---------------
replay_buffer/size             291000
trainer/QF1 Loss                    1.28885
trainer/QF2 Loss                    1.37857
trainer/Policy Loss               -17.3604
trainer/Q1 Predictions Mean        25.1764
trainer/Q1 Predictions Std         23.3574
trainer/Q1 Predictions Max        107.801
trainer/Q1 Predictions Min          7.65326
trainer/Q2 Predictions Mean        25.1342
trainer/Q2 Predictions Std         23.2989
trainer/Q2 Predictions Max        107.845
trainer/Q2 Predictions Min          7.71375
trainer/Q Targets Mean             25.1538
trainer/Q Targets Std              23.5435
trainer/Q Targets Max             108.221
trainer/Q Targets Min               7.28517
trainer/Log Pis Mean                8.12927
trainer/Log Pis Std                 5.14417
trainer/Log Pis Max                37.6495
trainer/Log Pis Min                -4.03252
trainer/Policy mu Mean              0.00271498
trainer/Policy mu Std               1.71961
trainer/Policy mu Max               4.17479
trainer/Policy mu Min              -4.88647
trainer/Policy log std Mean        -0.609421
trainer/Policy log std Std          0.200863
trainer/Policy log std Max         -0.0111538
trainer/Policy log std Min         -1.42138
trainer/Alpha                       0.00747311
trainer/Alpha Loss                  5.52969
exploration/num steps total    291000
exploration/num paths total       582
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.715309
exploration/Rewards Std             0.430572
exploration/Rewards Max             1
exploration/Rewards Min             0.00101918
exploration/Returns Mean          357.655
exploration/Returns Std           112.651
exploration/Returns Max           479.643
exploration/Returns Min           154.875
exploration/Actions Mean            0.325994
exploration/Actions Std             0.71134
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns       357.655
evaluation/num steps total     290000
evaluation/num paths total        580
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.521514
evaluation/Rewards Std              0.442088
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00178478
evaluation/Returns Mean           260.757
evaluation/Returns Std            143.862
evaluation/Returns Max            448.57
evaluation/Returns Min             19.0467
evaluation/ExplReturns Mean       260.757
evaluation/ExplReturns Std        143.862
evaluation/ExplReturns Max        448.57
evaluation/ExplReturns Min         19.0467
evaluation/Actions Mean             0.20814
evaluation/Actions Std              0.741252
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.999991
evaluation/Num Paths               10
evaluation/Average Returns        260.757
time/data storing (s)               0.0298903
time/evaluation sampling (s)       66.7097
time/exploration sampling (s)      71.8724
time/logging (s)                    0.0255723
time/saving (s)                     0.066388
time/training (s)                  10.4174
time/epoch (s)                    149.121
time/total (s)                   8638.52
Epoch                              57
-----------------------------  ---------------
2023-08-31 14:21:05.813369 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size             296000
trainer/QF1 Loss                    1.50873
trainer/QF2 Loss                    1.50077
trainer/Policy Loss               -16.8565
trainer/Q1 Predictions Mean        23.7881
trainer/Q1 Predictions Std         19.6426
trainer/Q1 Predictions Max        109.525
trainer/Q1 Predictions Min          6.52201
trainer/Q2 Predictions Mean        23.8113
trainer/Q2 Predictions Std         19.703
trainer/Q2 Predictions Max        109.522
trainer/Q2 Predictions Min          7.47022
trainer/Q Targets Mean             23.967
trainer/Q Targets Std              19.9367
trainer/Q Targets Max             109.58
trainer/Q Targets Min               6.88537
trainer/Log Pis Mean                7.3096
trainer/Log Pis Std                 5.6594
trainer/Log Pis Max                29.5484
trainer/Log Pis Min                -5.43467
trainer/Policy mu Mean              0.0553825
trainer/Policy mu Std               1.67061
trainer/Policy mu Max               4.95048
trainer/Policy mu Min              -4.48446
trainer/Policy log std Mean        -0.597849
trainer/Policy log std Std          0.177203
trainer/Policy log std Max          0.0366874
trainer/Policy log std Min         -1.32808
trainer/Alpha                       0.00853687
trainer/Alpha Loss                  1.47477
exploration/num steps total    296000
exploration/num paths total       592
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.781649
exploration/Rewards Std             0.37358
exploration/Rewards Max             1
exploration/Rewards Min             0.00184301
exploration/Returns Mean          390.824
exploration/Returns Std           113.847
exploration/Returns Max           469.688
exploration/Returns Min            93.3811
exploration/Actions Mean            0.377108
exploration/Actions Std             0.717249
exploration/Actions Max             0.999963
exploration/Actions Min            -0.999942
exploration/Num Paths              10
exploration/Average Returns       390.824
evaluation/num steps total     295000
evaluation/num paths total        590
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.798177
evaluation/Rewards Std              0.384161
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00132098
evaluation/Returns Mean           399.088
evaluation/Returns Std            129.844
evaluation/Returns Max            457.616
evaluation/Returns Min             12.5105
evaluation/ExplReturns Mean       399.088
evaluation/ExplReturns Std        129.844
evaluation/ExplReturns Max        457.616
evaluation/ExplReturns Min         12.5105
evaluation/Actions Mean             0.411888
evaluation/Actions Std              0.692641
evaluation/Actions Max              0.999888
evaluation/Actions Min             -0.999943
evaluation/Num Paths               10
evaluation/Average Returns        399.088
time/data storing (s)               0.0299482
time/evaluation sampling (s)       65.7976
time/exploration sampling (s)      71.2502
time/logging (s)                    0.0254642
time/saving (s)                     0.0624598
time/training (s)                  10.5572
time/epoch (s)                    147.723
time/total (s)                   8786.25
Epoch                              58
-----------------------------  ---------------
2023-08-31 14:23:34.098579 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size             301000
trainer/QF1 Loss                    0.832544
trainer/QF2 Loss                    0.780666
trainer/Policy Loss               -18.8777
trainer/Q1 Predictions Mean        26.081
trainer/Q1 Predictions Std         20.976
trainer/Q1 Predictions Max         98.3521
trainer/Q1 Predictions Min          7.91899
trainer/Q2 Predictions Mean        26.0792
trainer/Q2 Predictions Std         20.986
trainer/Q2 Predictions Max         98.5525
trainer/Q2 Predictions Min          8.04513
trainer/Q Targets Mean             26.1159
trainer/Q Targets Std              20.9462
trainer/Q Targets Max              98.3093
trainer/Q Targets Min               7.8373
trainer/Log Pis Mean                7.53206
trainer/Log Pis Std                 4.86371
trainer/Log Pis Max                24.462
trainer/Log Pis Min                -2.29788
trainer/Policy mu Mean              0.0435669
trainer/Policy mu Std               1.65641
trainer/Policy mu Max               4.6685
trainer/Policy mu Min              -4.00106
trainer/Policy log std Mean        -0.620094
trainer/Policy log std Std          0.182362
trainer/Policy log std Max          0.234954
trainer/Policy log std Min         -1.20872
trainer/Alpha                       0.00909493
trainer/Alpha Loss                  2.50086
exploration/num steps total    301000
exploration/num paths total       602
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.532079
exploration/Rewards Std             0.449147
exploration/Rewards Max             1
exploration/Rewards Min             0.0013426
exploration/Returns Mean          266.04
exploration/Returns Std           208.673
exploration/Returns Max           486.828
exploration/Returns Min             8.51138
exploration/Actions Mean            0.235328
exploration/Actions Std             0.72162
exploration/Actions Max             0.99997
exploration/Actions Min            -0.999982
exploration/Num Paths              10
exploration/Average Returns       266.04
evaluation/num steps total     300000
evaluation/num paths total        600
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.646934
evaluation/Rewards Std              0.451662
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00274634
evaluation/Returns Mean           323.467
evaluation/Returns Std            192.706
evaluation/Returns Max            487.927
evaluation/Returns Min              6.83812
evaluation/ExplReturns Mean       323.467
evaluation/ExplReturns Std        192.706
evaluation/ExplReturns Max        487.927
evaluation/ExplReturns Min          6.83812
evaluation/Actions Mean             0.398776
evaluation/Actions Std              0.645865
evaluation/Actions Max              0.99996
evaluation/Actions Min             -0.999964
evaluation/Num Paths               10
evaluation/Average Returns        323.467
time/data storing (s)               0.0298867
time/evaluation sampling (s)       65.0639
time/exploration sampling (s)      72.5028
time/logging (s)                    0.0257566
time/saving (s)                     0.0732476
time/training (s)                  10.5861
time/epoch (s)                    148.282
time/total (s)                   8934.53
Epoch                              59
-----------------------------  ---------------
2023-08-31 14:26:11.643985 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size             306000
trainer/QF1 Loss                    0.871039
trainer/QF2 Loss                    0.868232
trainer/Policy Loss               -20.0753
trainer/Q1 Predictions Mean        26.8478
trainer/Q1 Predictions Std         21.3064
trainer/Q1 Predictions Max         98.0744
trainer/Q1 Predictions Min          7.37562
trainer/Q2 Predictions Mean        26.9219
trainer/Q2 Predictions Std         21.3241
trainer/Q2 Predictions Max         98.5636
trainer/Q2 Predictions Min          7.53396
trainer/Q Targets Mean             26.9402
trainer/Q Targets Std              21.3343
trainer/Q Targets Max              98.6105
trainer/Q Targets Min               7.52528
trainer/Log Pis Mean                7.17244
trainer/Log Pis Std                 5.01177
trainer/Log Pis Max                23.5837
trainer/Log Pis Min                -8.23191
trainer/Policy mu Mean              0.0425009
trainer/Policy mu Std               1.64303
trainer/Policy mu Max               4.52258
trainer/Policy mu Min              -4.54814
trainer/Policy log std Mean        -0.63613
trainer/Policy log std Std          0.186535
trainer/Policy log std Max          0.125176
trainer/Policy log std Min         -1.34448
trainer/Alpha                       0.00997344
trainer/Alpha Loss                  0.794602
exploration/num steps total    306000
exploration/num paths total       612
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.572104
exploration/Rewards Std             0.425818
exploration/Rewards Max             1
exploration/Rewards Min             0.00123129
exploration/Returns Mean          286.052
exploration/Returns Std           170.55
exploration/Returns Max           485.474
exploration/Returns Min            11.0915
exploration/Actions Mean            0.257619
exploration/Actions Std             0.718469
exploration/Actions Max             0.999946
exploration/Actions Min            -0.999963
exploration/Num Paths              10
exploration/Average Returns       286.052
evaluation/num steps total     305000
evaluation/num paths total        610
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.613485
evaluation/Rewards Std              0.435584
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00257614
evaluation/Returns Mean           306.742
evaluation/Returns Std            168.417
evaluation/Returns Max            486.055
evaluation/Returns Min             21.6537
evaluation/ExplReturns Mean       306.742
evaluation/ExplReturns Std        168.417
evaluation/ExplReturns Max        486.055
evaluation/ExplReturns Min         21.6537
evaluation/Actions Mean             0.360781
evaluation/Actions Std              0.673325
evaluation/Actions Max              0.999945
evaluation/Actions Min             -0.999988
evaluation/Num Paths               10
evaluation/Average Returns        306.742
time/data storing (s)               0.0297432
time/evaluation sampling (s)       70.494
time/exploration sampling (s)      74.0707
time/logging (s)                    0.0255657
time/saving (s)                     0.070349
time/training (s)                  12.851
time/epoch (s)                    157.541
time/total (s)                   9092.07
Epoch                              60
-----------------------------  ---------------
2023-08-31 14:28:44.265219 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 61 finished
-----------------------------  ----------------
replay_buffer/size             311000
trainer/QF1 Loss                    0.463035
trainer/QF2 Loss                    0.608821
trainer/Policy Loss               -19.5818
trainer/Q1 Predictions Mean        26.626
trainer/Q1 Predictions Std         20.4518
trainer/Q1 Predictions Max        104.183
trainer/Q1 Predictions Min          5.11356
trainer/Q2 Predictions Mean        26.4901
trainer/Q2 Predictions Std         20.365
trainer/Q2 Predictions Max        105.161
trainer/Q2 Predictions Min          4.48759
trainer/Q Targets Mean             26.7296
trainer/Q Targets Std              20.4952
trainer/Q Targets Max             104.008
trainer/Q Targets Min               4.74265
trainer/Log Pis Mean                7.40826
trainer/Log Pis Std                 4.8223
trainer/Log Pis Max                22.7459
trainer/Log Pis Min                -3.4565
trainer/Policy mu Mean              0.0474499
trainer/Policy mu Std               1.65737
trainer/Policy mu Max               5.57063
trainer/Policy mu Min              -4.50021
trainer/Policy log std Mean        -0.629098
trainer/Policy log std Std          0.192122
trainer/Policy log std Max          0.0576053
trainer/Policy log std Min         -1.29489
trainer/Alpha                       0.0102807
trainer/Alpha Loss                  1.86887
exploration/num steps total    311000
exploration/num paths total       622
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.467741
exploration/Rewards Std             0.467172
exploration/Rewards Max             1
exploration/Rewards Min             0.000662753
exploration/Returns Mean          233.871
exploration/Returns Std           190.628
exploration/Returns Max           484.527
exploration/Returns Min            16.8213
exploration/Actions Mean            0.266416
exploration/Actions Std             0.718685
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999971
exploration/Num Paths              10
exploration/Average Returns       233.871
evaluation/num steps total     310000
evaluation/num paths total        620
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.466158
evaluation/Rewards Std              0.472613
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000827373
evaluation/Returns Mean           233.079
evaluation/Returns Std            182.216
evaluation/Returns Max            485.157
evaluation/Returns Min             16.4939
evaluation/ExplReturns Mean       233.079
evaluation/ExplReturns Std        182.216
evaluation/ExplReturns Max        485.157
evaluation/ExplReturns Min         16.4939
evaluation/Actions Mean             0.269805
evaluation/Actions Std              0.684678
evaluation/Actions Max              0.999965
evaluation/Actions Min             -0.999804
evaluation/Num Paths               10
evaluation/Average Returns        233.079
time/data storing (s)               0.0297453
time/evaluation sampling (s)       68.076
time/exploration sampling (s)      73.7699
time/logging (s)                    0.0255451
time/saving (s)                     0.0732534
time/training (s)                  10.643
time/epoch (s)                    152.617
time/total (s)                   9244.69
Epoch                              61
-----------------------------  ----------------
2023-08-31 14:31:15.275136 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size             316000
trainer/QF1 Loss                    0.707163
trainer/QF2 Loss                    0.6467
trainer/Policy Loss               -25.6699
trainer/Q1 Predictions Mean        32.6211
trainer/Q1 Predictions Std         23.3154
trainer/Q1 Predictions Max        106.004
trainer/Q1 Predictions Min          7.94505
trainer/Q2 Predictions Mean        32.5629
trainer/Q2 Predictions Std         23.3594
trainer/Q2 Predictions Max        105.597
trainer/Q2 Predictions Min          7.95652
trainer/Q Targets Mean             32.4815
trainer/Q Targets Std              23.4165
trainer/Q Targets Max             106.98
trainer/Q Targets Min               7.39828
trainer/Log Pis Mean                7.30242
trainer/Log Pis Std                 5.67483
trainer/Log Pis Max                27.6969
trainer/Log Pis Min                -5.85347
trainer/Policy mu Mean              0.0740653
trainer/Policy mu Std               1.62576
trainer/Policy mu Max               4.44882
trainer/Policy mu Min              -5.23196
trainer/Policy log std Mean        -0.645421
trainer/Policy log std Std          0.205045
trainer/Policy log std Max          0.291255
trainer/Policy log std Min         -1.34257
trainer/Alpha                       0.0103096
trainer/Alpha Loss                  1.38347
exploration/num steps total    316000
exploration/num paths total       632
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.503349
exploration/Rewards Std             0.460509
exploration/Rewards Max             1
exploration/Rewards Min             0.00104936
exploration/Returns Mean          251.674
exploration/Returns Std           156.993
exploration/Returns Max           436.529
exploration/Returns Min             8.18812
exploration/Actions Mean            0.209468
exploration/Actions Std             0.711
exploration/Actions Max             0.999984
exploration/Actions Min            -0.999988
exploration/Num Paths              10
exploration/Average Returns       251.674
evaluation/num steps total     315000
evaluation/num paths total        630
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.379681
evaluation/Rewards Std              0.436871
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00109784
evaluation/Returns Mean           189.84
evaluation/Returns Std            186.105
evaluation/Returns Max            486.788
evaluation/Returns Min             17.8315
evaluation/ExplReturns Mean       189.84
evaluation/ExplReturns Std        186.105
evaluation/ExplReturns Max        486.788
evaluation/ExplReturns Min         17.8315
evaluation/Actions Mean             0.144541
evaluation/Actions Std              0.711243
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.999961
evaluation/Num Paths               10
evaluation/Average Returns        189.84
time/data storing (s)               0.0299751
time/evaluation sampling (s)       67.1451
time/exploration sampling (s)      70.7803
time/logging (s)                    0.0257406
time/saving (s)                     0.0623273
time/training (s)                  12.9629
time/epoch (s)                    151.006
time/total (s)                   9395.7
Epoch                              62
-----------------------------  ---------------
2023-08-31 14:33:48.462438 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             321000
trainer/QF1 Loss                    0.684139
trainer/QF2 Loss                    0.657686
trainer/Policy Loss               -26.6141
trainer/Q1 Predictions Mean        33.0744
trainer/Q1 Predictions Std         23.7173
trainer/Q1 Predictions Max        111.476
trainer/Q1 Predictions Min          6.55836
trainer/Q2 Predictions Mean        33.1581
trainer/Q2 Predictions Std         23.6809
trainer/Q2 Predictions Max        111.577
trainer/Q2 Predictions Min          7.41703
trainer/Q Targets Mean             33.0129
trainer/Q Targets Std              23.7933
trainer/Q Targets Max             112.294
trainer/Q Targets Min               7.54366
trainer/Log Pis Mean                6.90287
trainer/Log Pis Std                 4.70456
trainer/Log Pis Max                23.4524
trainer/Log Pis Min                -4.40846
trainer/Policy mu Mean              0.210262
trainer/Policy mu Std               1.56341
trainer/Policy mu Max               4.42305
trainer/Policy mu Min              -4.18276
trainer/Policy log std Mean        -0.661076
trainer/Policy log std Std          0.206396
trainer/Policy log std Max         -0.021597
trainer/Policy log std Min         -1.43406
trainer/Alpha                       0.0105091
trainer/Alpha Loss                 -0.442457
exploration/num steps total    321000
exploration/num paths total       642
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.699138
exploration/Rewards Std             0.420842
exploration/Rewards Max             1
exploration/Rewards Min             0.00131064
exploration/Returns Mean          349.569
exploration/Returns Std           151.189
exploration/Returns Max           484.447
exploration/Returns Min            55.28
exploration/Actions Mean            0.311515
exploration/Actions Std             0.695002
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999902
exploration/Num Paths              10
exploration/Average Returns       349.569
evaluation/num steps total     320000
evaluation/num paths total        640
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.492975
evaluation/Rewards Std              0.467324
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00109005
evaluation/Returns Mean           246.488
evaluation/Returns Std            191.029
evaluation/Returns Max            484.555
evaluation/Returns Min              7.9126
evaluation/ExplReturns Mean       246.488
evaluation/ExplReturns Std        191.029
evaluation/ExplReturns Max        484.555
evaluation/ExplReturns Min          7.9126
evaluation/Actions Mean             0.188175
evaluation/Actions Std              0.674733
evaluation/Actions Max              0.999955
evaluation/Actions Min             -0.999996
evaluation/Num Paths               10
evaluation/Average Returns        246.488
time/data storing (s)               0.0296824
time/evaluation sampling (s)       67.6922
time/exploration sampling (s)      74.7135
time/logging (s)                    0.0254548
time/saving (s)                     0.0732624
time/training (s)                  10.6492
time/epoch (s)                    153.183
time/total (s)                   9548.89
Epoch                              63
-----------------------------  ---------------
2023-08-31 14:36:18.876719 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 64 finished
-----------------------------  ----------------
replay_buffer/size             326000
trainer/QF1 Loss                    0.874183
trainer/QF2 Loss                    0.914264
trainer/Policy Loss               -24.8559
trainer/Q1 Predictions Mean        31.4994
trainer/Q1 Predictions Std         20.1206
trainer/Q1 Predictions Max        114.07
trainer/Q1 Predictions Min          6.769
trainer/Q2 Predictions Mean        31.5445
trainer/Q2 Predictions Std         20.1875
trainer/Q2 Predictions Max        114.119
trainer/Q2 Predictions Min          7.17911
trainer/Q Targets Mean             31.4309
trainer/Q Targets Std              20.1169
trainer/Q Targets Max             114.121
trainer/Q Targets Min               7.11325
trainer/Log Pis Mean                7.10737
trainer/Log Pis Std                 5.08436
trainer/Log Pis Max                26.2193
trainer/Log Pis Min                -4.42735
trainer/Policy mu Mean              0.0399743
trainer/Policy mu Std               1.61516
trainer/Policy mu Max               5.7456
trainer/Policy mu Min              -5.07063
trainer/Policy log std Mean        -0.684166
trainer/Policy log std Std          0.212383
trainer/Policy log std Max          0.0780331
trainer/Policy log std Min         -1.43103
trainer/Alpha                       0.0106901
trainer/Alpha Loss                  0.487319
exploration/num steps total    326000
exploration/num paths total       652
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.360737
exploration/Rewards Std             0.454237
exploration/Rewards Max             1
exploration/Rewards Min             0.000221725
exploration/Returns Mean          180.369
exploration/Returns Std           166.222
exploration/Returns Max           446.286
exploration/Returns Min            10.6052
exploration/Actions Mean            0.220338
exploration/Actions Std             0.695644
exploration/Actions Max             1
exploration/Actions Min            -0.999997
exploration/Num Paths              10
exploration/Average Returns       180.369
evaluation/num steps total     325000
evaluation/num paths total        650
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.277805
evaluation/Rewards Std              0.422299
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00025605
evaluation/Returns Mean           138.903
evaluation/Returns Std            188.479
evaluation/Returns Max            465.967
evaluation/Returns Min             10.1434
evaluation/ExplReturns Mean       138.903
evaluation/ExplReturns Std        188.479
evaluation/ExplReturns Max        465.967
evaluation/ExplReturns Min         10.1434
evaluation/Actions Mean             0.249235
evaluation/Actions Std              0.563506
evaluation/Actions Max              0.999722
evaluation/Actions Min             -0.999877
evaluation/Num Paths               10
evaluation/Average Returns        138.903
time/data storing (s)               0.0297073
time/evaluation sampling (s)       67.1037
time/exploration sampling (s)      72.276
time/logging (s)                    0.0254324
time/saving (s)                     0.0619991
time/training (s)                  10.9137
time/epoch (s)                    150.41
time/total (s)                   9699.3
Epoch                              64
-----------------------------  ----------------
2023-08-31 14:38:48.954220 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size             331000
trainer/QF1 Loss                    1.15874
trainer/QF2 Loss                    1.04631
trainer/Policy Loss               -27.4897
trainer/Q1 Predictions Mean        34.6641
trainer/Q1 Predictions Std         22.6061
trainer/Q1 Predictions Max         96.9628
trainer/Q1 Predictions Min          7.53697
trainer/Q2 Predictions Mean        34.6465
trainer/Q2 Predictions Std         22.6409
trainer/Q2 Predictions Max         96.4008
trainer/Q2 Predictions Min          6.42796
trainer/Q Targets Mean             34.6012
trainer/Q Targets Std              22.5183
trainer/Q Targets Max              96.5361
trainer/Q Targets Min               5.66699
trainer/Log Pis Mean                7.58067
trainer/Log Pis Std                 5.68684
trainer/Log Pis Max                28.6471
trainer/Log Pis Min                -9.17177
trainer/Policy mu Mean              0.0344029
trainer/Policy mu Std               1.63803
trainer/Policy mu Max               5.92508
trainer/Policy mu Min              -5.58135
trainer/Policy log std Mean        -0.683599
trainer/Policy log std Std          0.230656
trainer/Policy log std Max          0.112165
trainer/Policy log std Min         -1.57377
trainer/Alpha                       0.0106048
trainer/Alpha Loss                  2.64013
exploration/num steps total    331000
exploration/num paths total       662
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.576511
exploration/Rewards Std             0.449496
exploration/Rewards Max             1
exploration/Rewards Min             0.00135756
exploration/Returns Mean          288.255
exploration/Returns Std           197.617
exploration/Returns Max           479.44
exploration/Returns Min            12.2912
exploration/Actions Mean            0.207516
exploration/Actions Std             0.71293
exploration/Actions Max             0.999978
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns       288.255
evaluation/num steps total     330000
evaluation/num paths total        660
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.57583
evaluation/Rewards Std              0.427866
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00131638
evaluation/Returns Mean           287.915
evaluation/Returns Std            157.576
evaluation/Returns Max            480.543
evaluation/Returns Min             48.5702
evaluation/ExplReturns Mean       287.915
evaluation/ExplReturns Std        157.576
evaluation/ExplReturns Max        480.543
evaluation/ExplReturns Min         48.5702
evaluation/Actions Mean             0.120665
evaluation/Actions Std              0.685435
evaluation/Actions Max              0.999725
evaluation/Actions Min             -0.99978
evaluation/Num Paths               10
evaluation/Average Returns        287.915
time/data storing (s)               0.0300656
time/evaluation sampling (s)       68.9614
time/exploration sampling (s)      71.8056
time/logging (s)                    0.0255569
time/saving (s)                     0.0688456
time/training (s)                   9.18235
time/epoch (s)                    150.074
time/total (s)                   9849.38
Epoch                              65
-----------------------------  ---------------
2023-08-31 14:41:19.623384 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size             336000
trainer/QF1 Loss                    0.697838
trainer/QF2 Loss                    0.707703
trainer/Policy Loss               -27.1293
trainer/Q1 Predictions Mean        33.2572
trainer/Q1 Predictions Std         19.9296
trainer/Q1 Predictions Max         91.4743
trainer/Q1 Predictions Min          6.09653
trainer/Q2 Predictions Mean        33.1729
trainer/Q2 Predictions Std         19.9286
trainer/Q2 Predictions Max         91.2543
trainer/Q2 Predictions Min          5.08686
trainer/Q Targets Mean             33.2024
trainer/Q Targets Std              19.9233
trainer/Q Targets Max              91.6256
trainer/Q Targets Min               5.39953
trainer/Log Pis Mean                6.53799
trainer/Log Pis Std                 4.36686
trainer/Log Pis Max                23.968
trainer/Log Pis Min                -6.7828
trainer/Policy mu Mean              0.147374
trainer/Policy mu Std               1.557
trainer/Policy mu Max               3.88013
trainer/Policy mu Min              -4.48815
trainer/Policy log std Mean        -0.666837
trainer/Policy log std Std          0.219624
trainer/Policy log std Max          0.103035
trainer/Policy log std Min         -1.45533
trainer/Alpha                       0.0111892
trainer/Alpha Loss                 -2.07572
exploration/num steps total    336000
exploration/num paths total       672
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.757728
exploration/Rewards Std             0.398824
exploration/Rewards Max             1
exploration/Rewards Min             0.00286056
exploration/Returns Mean          378.864
exploration/Returns Std            99.8475
exploration/Returns Max           468.175
exploration/Returns Min           229.145
exploration/Actions Mean            0.35546
exploration/Actions Std             0.668906
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999889
exploration/Num Paths              10
exploration/Average Returns       378.864
evaluation/num steps total     335000
evaluation/num paths total        670
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.651642
evaluation/Rewards Std              0.452848
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00139596
evaluation/Returns Mean           325.821
evaluation/Returns Std            195.654
evaluation/Returns Max            466.586
evaluation/Returns Min             10.6357
evaluation/ExplReturns Mean       325.821
evaluation/ExplReturns Std        195.654
evaluation/ExplReturns Max        466.586
evaluation/ExplReturns Min         10.6357
evaluation/Actions Mean             0.343968
evaluation/Actions Std              0.655829
evaluation/Actions Max              0.999934
evaluation/Actions Min             -0.999936
evaluation/Num Paths               10
evaluation/Average Returns        325.821
time/data storing (s)               0.0296607
time/evaluation sampling (s)       67.8309
time/exploration sampling (s)      72.2519
time/logging (s)                    0.0254684
time/saving (s)                     0.0658936
time/training (s)                  10.4613
time/epoch (s)                    150.665
time/total (s)                  10000
Epoch                              66
-----------------------------  ---------------
2023-08-31 14:43:48.537749 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size             341000
trainer/QF1 Loss                    0.788535
trainer/QF2 Loss                    0.871453
trainer/Policy Loss               -29.6898
trainer/Q1 Predictions Mean        36.04
trainer/Q1 Predictions Std         22.4848
trainer/Q1 Predictions Max        115.839
trainer/Q1 Predictions Min          5.5564
trainer/Q2 Predictions Mean        36.1608
trainer/Q2 Predictions Std         22.5515
trainer/Q2 Predictions Max        116.379
trainer/Q2 Predictions Min          5.75755
trainer/Q Targets Mean             36.0106
trainer/Q Targets Std              22.4073
trainer/Q Targets Max             116.519
trainer/Q Targets Min               6.15806
trainer/Log Pis Mean                6.85478
trainer/Log Pis Std                 5.05886
trainer/Log Pis Max                20.2957
trainer/Log Pis Min                -6.41058
trainer/Policy mu Mean              0.0223762
trainer/Policy mu Std               1.59916
trainer/Policy mu Max               4.5323
trainer/Policy mu Min              -4.92081
trainer/Policy log std Mean        -0.676919
trainer/Policy log std Std          0.230742
trainer/Policy log std Max         -0.0492193
trainer/Policy log std Min         -1.5479
trainer/Alpha                       0.0111524
trainer/Alpha Loss                 -0.652918
exploration/num steps total    341000
exploration/num paths total       682
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.420939
exploration/Rewards Std             0.427738
exploration/Rewards Max             1
exploration/Rewards Min             0.00060994
exploration/Returns Mean          210.47
exploration/Returns Std           166.324
exploration/Returns Max           475.648
exploration/Returns Min            18.0519
exploration/Actions Mean            0.109552
exploration/Actions Std             0.66768
exploration/Actions Max             0.999937
exploration/Actions Min            -0.999984
exploration/Num Paths              10
exploration/Average Returns       210.47
evaluation/num steps total     340000
evaluation/num paths total        680
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.361983
evaluation/Rewards Std              0.431419
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00136023
evaluation/Returns Mean           180.991
evaluation/Returns Std            184.456
evaluation/Returns Max            455.836
evaluation/Returns Min             11.3001
evaluation/ExplReturns Mean       180.991
evaluation/ExplReturns Std        184.456
evaluation/ExplReturns Max        455.836
evaluation/ExplReturns Min         11.3001
evaluation/Actions Mean             0.0690912
evaluation/Actions Std              0.650643
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999902
evaluation/Num Paths               10
evaluation/Average Returns        180.991
time/data storing (s)               0.0299819
time/evaluation sampling (s)       66.6783
time/exploration sampling (s)      71.3564
time/logging (s)                    0.0256452
time/saving (s)                     0.0664844
time/training (s)                  10.7538
time/epoch (s)                    148.911
time/total (s)                  10149
Epoch                              67
-----------------------------  ---------------
2023-08-31 14:46:16.123531 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size             346000
trainer/QF1 Loss                    0.80587
trainer/QF2 Loss                    0.891605
trainer/Policy Loss               -30.1871
trainer/Q1 Predictions Mean        36.1391
trainer/Q1 Predictions Std         21.5249
trainer/Q1 Predictions Max        115.097
trainer/Q1 Predictions Min          8.01681
trainer/Q2 Predictions Mean        36.2189
trainer/Q2 Predictions Std         21.5149
trainer/Q2 Predictions Max        115.019
trainer/Q2 Predictions Min          9.04584
trainer/Q Targets Mean             35.8948
trainer/Q Targets Std              21.4665
trainer/Q Targets Max             114.293
trainer/Q Targets Min               8.31732
trainer/Log Pis Mean                6.38585
trainer/Log Pis Std                 4.47113
trainer/Log Pis Max                20.8809
trainer/Log Pis Min                -3.82409
trainer/Policy mu Mean              0.0370481
trainer/Policy mu Std               1.55095
trainer/Policy mu Max               3.84285
trainer/Policy mu Min              -6.56736
trainer/Policy log std Mean        -0.645792
trainer/Policy log std Std          0.226403
trainer/Policy log std Max          0.125868
trainer/Policy log std Min         -1.53332
trainer/Alpha                       0.0114931
trainer/Alpha Loss                 -2.74266
exploration/num steps total    346000
exploration/num paths total       692
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.683381
exploration/Rewards Std             0.408542
exploration/Rewards Max             1
exploration/Rewards Min             0.00161673
exploration/Returns Mean          341.69
exploration/Returns Std           155.653
exploration/Returns Max           485.402
exploration/Returns Min            35.2614
exploration/Actions Mean            0.20452
exploration/Actions Std             0.723669
exploration/Actions Max             0.999999
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       341.69
evaluation/num steps total     345000
evaluation/num paths total        690
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.753188
evaluation/Rewards Std              0.395907
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00178471
evaluation/Returns Mean           376.594
evaluation/Returns Std            131.686
evaluation/Returns Max            482.705
evaluation/Returns Min             22.8462
evaluation/ExplReturns Mean       376.594
evaluation/ExplReturns Std        131.686
evaluation/ExplReturns Max        482.705
evaluation/ExplReturns Min         22.8462
evaluation/Actions Mean             0.272211
evaluation/Actions Std              0.671478
evaluation/Actions Max              0.999774
evaluation/Actions Min             -0.999833
evaluation/Num Paths               10
evaluation/Average Returns        376.594
time/data storing (s)               0.0296318
time/evaluation sampling (s)       65.9382
time/exploration sampling (s)      71.1899
time/logging (s)                    0.0257242
time/saving (s)                     0.0700874
time/training (s)                  10.3284
time/epoch (s)                    147.582
time/total (s)                  10296.5
Epoch                              68
-----------------------------  ---------------
2023-08-31 14:48:43.803249 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 69 finished
-----------------------------  ----------------
replay_buffer/size             351000
trainer/QF1 Loss                    0.912208
trainer/QF2 Loss                    0.964539
trainer/Policy Loss               -34.6148
trainer/Q1 Predictions Mean        41.4034
trainer/Q1 Predictions Std         22.5443
trainer/Q1 Predictions Max        115.453
trainer/Q1 Predictions Min          6.70297
trainer/Q2 Predictions Mean        41.3492
trainer/Q2 Predictions Std         22.4481
trainer/Q2 Predictions Max        115.214
trainer/Q2 Predictions Min          7.29739
trainer/Q Targets Mean             41.2846
trainer/Q Targets Std              22.457
trainer/Q Targets Max             114.804
trainer/Q Targets Min               6.94057
trainer/Log Pis Mean                7.12791
trainer/Log Pis Std                 5.10769
trainer/Log Pis Max                28.2391
trainer/Log Pis Min                -4.99969
trainer/Policy mu Mean              0.183782
trainer/Policy mu Std               1.59632
trainer/Policy mu Max               4.17785
trainer/Policy mu Min              -4.62261
trainer/Policy log std Mean        -0.633207
trainer/Policy log std Std          0.236046
trainer/Policy log std Max          0.122715
trainer/Policy log std Min         -1.51653
trainer/Alpha                       0.0121567
trainer/Alpha Loss                  0.56406
exploration/num steps total    351000
exploration/num paths total       702
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.531323
exploration/Rewards Std             0.424834
exploration/Rewards Max             1
exploration/Rewards Min             0.000691346
exploration/Returns Mean          265.661
exploration/Returns Std           185.537
exploration/Returns Max           481.324
exploration/Returns Min            29.7069
exploration/Actions Mean            0.234475
exploration/Actions Std             0.700375
exploration/Actions Max             0.999952
exploration/Actions Min            -0.999909
exploration/Num Paths              10
exploration/Average Returns       265.661
evaluation/num steps total     350000
evaluation/num paths total        700
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.915522
evaluation/Rewards Std              0.255823
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0027364
evaluation/Returns Mean           457.761
evaluation/Returns Std             39.351
evaluation/Returns Max            483.254
evaluation/Returns Min            374.663
evaluation/ExplReturns Mean       457.761
evaluation/ExplReturns Std         39.351
evaluation/ExplReturns Max        483.254
evaluation/ExplReturns Min        374.663
evaluation/Actions Mean             0.390759
evaluation/Actions Std              0.647141
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.999927
evaluation/Num Paths               10
evaluation/Average Returns        457.761
time/data storing (s)               0.030187
time/evaluation sampling (s)       64.5897
time/exploration sampling (s)      72.4911
time/logging (s)                    0.0257522
time/saving (s)                     0.0728751
time/training (s)                  10.4663
time/epoch (s)                    147.676
time/total (s)                  10444.2
Epoch                              69
-----------------------------  ----------------
2023-08-31 14:51:17.249440 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size             356000
trainer/QF1 Loss                    0.85089
trainer/QF2 Loss                    0.911243
trainer/Policy Loss               -36.4402
trainer/Q1 Predictions Mean        42.5819
trainer/Q1 Predictions Std         23.9955
trainer/Q1 Predictions Max        113.963
trainer/Q1 Predictions Min          9.5782
trainer/Q2 Predictions Mean        42.5908
trainer/Q2 Predictions Std         23.9281
trainer/Q2 Predictions Max        114.346
trainer/Q2 Predictions Min          8.89826
trainer/Q Targets Mean             42.6092
trainer/Q Targets Std              24.0812
trainer/Q Targets Max             114.452
trainer/Q Targets Min               9.17727
trainer/Log Pis Mean                6.58735
trainer/Log Pis Std                 4.93055
trainer/Log Pis Max                27.6068
trainer/Log Pis Min                -7.93112
trainer/Policy mu Mean              0.15885
trainer/Policy mu Std               1.5637
trainer/Policy mu Max               4.46779
trainer/Policy mu Min              -4.86705
trainer/Policy log std Mean        -0.638796
trainer/Policy log std Std          0.217336
trainer/Policy log std Max          0.0774541
trainer/Policy log std Min         -1.54837
trainer/Alpha                       0.0117679
trainer/Alpha Loss                 -1.83305
exploration/num steps total    356000
exploration/num paths total       712
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.740849
exploration/Rewards Std             0.417862
exploration/Rewards Max             1
exploration/Rewards Min             0.000642379
exploration/Returns Mean          370.424
exploration/Returns Std           177.174
exploration/Returns Max           483.013
exploration/Returns Min            16.2812
exploration/Actions Mean            0.346251
exploration/Actions Std             0.634355
exploration/Actions Max             0.999976
exploration/Actions Min            -0.99991
exploration/Num Paths              10
exploration/Average Returns       370.424
evaluation/num steps total     355000
evaluation/num paths total        710
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.934335
evaluation/Rewards Std              0.225778
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00299771
evaluation/Returns Mean           467.167
evaluation/Returns Std             29.8588
evaluation/Returns Max            483.011
evaluation/Returns Min            403.117
evaluation/ExplReturns Mean       467.167
evaluation/ExplReturns Std         29.8588
evaluation/ExplReturns Max        483.011
evaluation/ExplReturns Min        403.117
evaluation/Actions Mean             0.49722
evaluation/Actions Std              0.567654
evaluation/Actions Max              0.999809
evaluation/Actions Min             -0.998639
evaluation/Num Paths               10
evaluation/Average Returns        467.167
time/data storing (s)               0.0298363
time/evaluation sampling (s)       69.8459
time/exploration sampling (s)      72.9477
time/logging (s)                    0.0256899
time/saving (s)                     0.0881188
time/training (s)                  10.505
time/epoch (s)                    153.442
time/total (s)                  10597.7
Epoch                              70
-----------------------------  ----------------
2023-08-31 14:53:50.310763 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 71 finished
-----------------------------  ----------------
replay_buffer/size             361000
trainer/QF1 Loss                    1.22077
trainer/QF2 Loss                    1.08094
trainer/Policy Loss               -35.3008
trainer/Q1 Predictions Mean        41.8451
trainer/Q1 Predictions Std         22.484
trainer/Q1 Predictions Max        113.334
trainer/Q1 Predictions Min          9.01534
trainer/Q2 Predictions Mean        41.8503
trainer/Q2 Predictions Std         22.5089
trainer/Q2 Predictions Max        113.599
trainer/Q2 Predictions Min          8.95296
trainer/Q Targets Mean             41.7484
trainer/Q Targets Std              22.5238
trainer/Q Targets Max             113.067
trainer/Q Targets Min               9.26393
trainer/Log Pis Mean                6.95529
trainer/Log Pis Std                 5.39662
trainer/Log Pis Max                30.6343
trainer/Log Pis Min                -3.78315
trainer/Policy mu Mean             -0.000331434
trainer/Policy mu Std               1.64041
trainer/Policy mu Max               4.90569
trainer/Policy mu Min              -4.98893
trainer/Policy log std Mean        -0.6496
trainer/Policy log std Std          0.22327
trainer/Policy log std Max         -0.0486105
trainer/Policy log std Min         -1.57423
trainer/Alpha                       0.0114869
trainer/Alpha Loss                 -0.199697
exploration/num steps total    361000
exploration/num paths total       722
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.583004
exploration/Rewards Std             0.445823
exploration/Rewards Max             1
exploration/Rewards Min             0.00326182
exploration/Returns Mean          291.502
exploration/Returns Std           195.006
exploration/Returns Max           484.587
exploration/Returns Min            51.152
exploration/Actions Mean            0.167293
exploration/Actions Std             0.665878
exploration/Actions Max             0.999983
exploration/Actions Min            -0.999953
exploration/Num Paths              10
exploration/Average Returns       291.502
evaluation/num steps total     360000
evaluation/num paths total        720
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.420601
evaluation/Rewards Std              0.425037
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00292799
evaluation/Returns Mean           210.301
evaluation/Returns Std            173.019
evaluation/Returns Max            482.869
evaluation/Returns Min             40.5244
evaluation/ExplReturns Mean       210.301
evaluation/ExplReturns Std        173.019
evaluation/ExplReturns Max        482.869
evaluation/ExplReturns Min         40.5244
evaluation/Actions Mean             0.131469
evaluation/Actions Std              0.604443
evaluation/Actions Max              0.999951
evaluation/Actions Min             -0.999855
evaluation/Num Paths               10
evaluation/Average Returns        210.301
time/data storing (s)               0.029902
time/evaluation sampling (s)       68.714
time/exploration sampling (s)      73.9167
time/logging (s)                    0.0256502
time/saving (s)                     0.0632939
time/training (s)                  10.3079
time/epoch (s)                    153.057
time/total (s)                  10750.7
Epoch                              71
-----------------------------  ----------------
2023-08-31 14:56:26.907977 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size             366000
trainer/QF1 Loss                    0.778985
trainer/QF2 Loss                    0.748391
trainer/Policy Loss               -33.9807
trainer/Q1 Predictions Mean        41.1775
trainer/Q1 Predictions Std         21.4026
trainer/Q1 Predictions Max         92.4263
trainer/Q1 Predictions Min          5.06341
trainer/Q2 Predictions Mean        41.2609
trainer/Q2 Predictions Std         21.5033
trainer/Q2 Predictions Max         93.0832
trainer/Q2 Predictions Min          4.81835
trainer/Q Targets Mean             41.2276
trainer/Q Targets Std              21.5237
trainer/Q Targets Max              95.3838
trainer/Q Targets Min               4.25051
trainer/Log Pis Mean                7.66223
trainer/Log Pis Std                 5.40198
trainer/Log Pis Max                34.0043
trainer/Log Pis Min                -4.21267
trainer/Policy mu Mean              0.0575168
trainer/Policy mu Std               1.6555
trainer/Policy mu Max               4.53423
trainer/Policy mu Min              -4.03065
trainer/Policy log std Mean        -0.676798
trainer/Policy log std Std          0.214289
trainer/Policy log std Max         -0.0103799
trainer/Policy log std Min         -1.51622
trainer/Alpha                       0.010967
trainer/Alpha Loss                  2.98879
exploration/num steps total    366000
exploration/num paths total       732
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.782635
exploration/Rewards Std             0.396986
exploration/Rewards Max             1
exploration/Rewards Min             0.00327759
exploration/Returns Mean          391.318
exploration/Returns Std           185.471
exploration/Returns Max           485.329
exploration/Returns Min            19.7083
exploration/Actions Mean            0.301447
exploration/Actions Std             0.653506
exploration/Actions Max             0.999995
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       391.318
evaluation/num steps total     365000
evaluation/num paths total        730
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.946846
evaluation/Rewards Std              0.20287
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00239214
evaluation/Returns Mean           473.423
evaluation/Returns Std             29.6541
evaluation/Returns Max            485.309
evaluation/Returns Min            384.525
evaluation/ExplReturns Mean       473.423
evaluation/ExplReturns Std         29.6541
evaluation/ExplReturns Max        485.309
evaluation/ExplReturns Min        384.525
evaluation/Actions Mean             0.332776
evaluation/Actions Std              0.702309
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.999978
evaluation/Num Paths               10
evaluation/Average Returns        473.423
time/data storing (s)               0.0300395
time/evaluation sampling (s)       68.7459
time/exploration sampling (s)      75.7739
time/logging (s)                    0.0256538
time/saving (s)                     0.0715074
time/training (s)                  11.9462
time/epoch (s)                    156.593
time/total (s)                  10907.3
Epoch                              72
-----------------------------  ---------------
2023-08-31 14:58:56.428420 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size             371000
trainer/QF1 Loss                    0.848805
trainer/QF2 Loss                    0.989006
trainer/Policy Loss               -39.86
trainer/Q1 Predictions Mean        46.3317
trainer/Q1 Predictions Std         24.0361
trainer/Q1 Predictions Max        112.77
trainer/Q1 Predictions Min          6.25761
trainer/Q2 Predictions Mean        46.3247
trainer/Q2 Predictions Std         24.0192
trainer/Q2 Predictions Max        112.82
trainer/Q2 Predictions Min          5.94878
trainer/Q Targets Mean             46.5406
trainer/Q Targets Std              24.2575
trainer/Q Targets Max             113.819
trainer/Q Targets Min               6.16899
trainer/Log Pis Mean                6.87574
trainer/Log Pis Std                 4.62573
trainer/Log Pis Max                23.2783
trainer/Log Pis Min                -3.45533
trainer/Policy mu Mean              0.144615
trainer/Policy mu Std               1.58913
trainer/Policy mu Max               4.89401
trainer/Policy mu Min              -5.19423
trainer/Policy log std Mean        -0.6647
trainer/Policy log std Std          0.211519
trainer/Policy log std Max         -0.00513858
trainer/Policy log std Min         -1.42121
trainer/Alpha                       0.01146
trainer/Alpha Loss                 -0.555328
exploration/num steps total    371000
exploration/num paths total       742
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.690409
exploration/Rewards Std             0.440176
exploration/Rewards Max             1
exploration/Rewards Min             0.00191806
exploration/Returns Mean          345.204
exploration/Returns Std           208.47
exploration/Returns Max           484.472
exploration/Returns Min            20.7918
exploration/Actions Mean            0.270323
exploration/Actions Std             0.621039
exploration/Actions Max             0.99997
exploration/Actions Min            -0.999324
exploration/Num Paths              10
exploration/Average Returns       345.204
evaluation/num steps total     370000
evaluation/num paths total        740
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.664142
evaluation/Rewards Std              0.448058
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00283307
evaluation/Returns Mean           332.071
evaluation/Returns Std            202.286
evaluation/Returns Max            483.706
evaluation/Returns Min             11.7471
evaluation/ExplReturns Mean       332.071
evaluation/ExplReturns Std        202.286
evaluation/ExplReturns Max        483.706
evaluation/ExplReturns Min         11.7471
evaluation/Actions Mean             0.331882
evaluation/Actions Std              0.546912
evaluation/Actions Max              0.999328
evaluation/Actions Min             -0.998676
evaluation/Num Paths               10
evaluation/Average Returns        332.071
time/data storing (s)               0.0296907
time/evaluation sampling (s)       64.4557
time/exploration sampling (s)      69.6475
time/logging (s)                    0.0254631
time/saving (s)                     0.109554
time/training (s)                  15.2485
time/epoch (s)                    149.516
time/total (s)                  11056.8
Epoch                              73
-----------------------------  ---------------
2023-08-31 15:01:23.161598 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size             376000
trainer/QF1 Loss                    0.771208
trainer/QF2 Loss                    0.933254
trainer/Policy Loss               -39.7931
trainer/Q1 Predictions Mean        46.5227
trainer/Q1 Predictions Std         24.326
trainer/Q1 Predictions Max        112.448
trainer/Q1 Predictions Min          7.3066
trainer/Q2 Predictions Mean        46.4059
trainer/Q2 Predictions Std         24.2704
trainer/Q2 Predictions Max        112.058
trainer/Q2 Predictions Min          7.533
trainer/Q Targets Mean             46.5563
trainer/Q Targets Std              24.4684
trainer/Q Targets Max             113.106
trainer/Q Targets Min               7.16288
trainer/Log Pis Mean                7.07273
trainer/Log Pis Std                 4.73574
trainer/Log Pis Max                25.2699
trainer/Log Pis Min                -4.68987
trainer/Policy mu Mean              0.0617172
trainer/Policy mu Std               1.59403
trainer/Policy mu Max               4.51152
trainer/Policy mu Min              -5.0195
trainer/Policy log std Mean        -0.653072
trainer/Policy log std Std          0.209064
trainer/Policy log std Max         -0.0462794
trainer/Policy log std Min         -1.44027
trainer/Alpha                       0.0111976
trainer/Alpha Loss                  0.326724
exploration/num steps total    376000
exploration/num paths total       752
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.504586
exploration/Rewards Std             0.469386
exploration/Rewards Max             1
exploration/Rewards Min             0.00229115
exploration/Returns Mean          252.293
exploration/Returns Std           224.347
exploration/Returns Max           485.188
exploration/Returns Min            11.5574
exploration/Actions Mean            0.11487
exploration/Actions Std             0.6406
exploration/Actions Max             0.999982
exploration/Actions Min            -0.999885
exploration/Num Paths              10
exploration/Average Returns       252.293
evaluation/num steps total     375000
evaluation/num paths total        750
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.614764
evaluation/Rewards Std              0.454903
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00217632
evaluation/Returns Mean           307.382
evaluation/Returns Std            219.193
evaluation/Returns Max            485.469
evaluation/Returns Min              8.9371
evaluation/ExplReturns Mean       307.382
evaluation/ExplReturns Std        219.193
evaluation/ExplReturns Max        485.469
evaluation/ExplReturns Min          8.9371
evaluation/Actions Mean             0.20381
evaluation/Actions Std              0.644491
evaluation/Actions Max              0.999795
evaluation/Actions Min             -0.998799
evaluation/Num Paths               10
evaluation/Average Returns        307.382
time/data storing (s)               0.0295713
time/evaluation sampling (s)       64.3375
time/exploration sampling (s)      70.4201
time/logging (s)                    0.0256028
time/saving (s)                     0.0783761
time/training (s)                  11.8382
time/epoch (s)                    146.729
time/total (s)                  11203.6
Epoch                              74
-----------------------------  ---------------
2023-08-31 15:03:50.706673 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size             381000
trainer/QF1 Loss                    0.873873
trainer/QF2 Loss                    0.850717
trainer/Policy Loss               -41.1383
trainer/Q1 Predictions Mean        47.775
trainer/Q1 Predictions Std         23.2056
trainer/Q1 Predictions Max        112.247
trainer/Q1 Predictions Min         10.8509
trainer/Q2 Predictions Mean        47.7103
trainer/Q2 Predictions Std         23.1455
trainer/Q2 Predictions Max        111.356
trainer/Q2 Predictions Min         11.0786
trainer/Q Targets Mean             47.7764
trainer/Q Targets Std              23.119
trainer/Q Targets Max             111.75
trainer/Q Targets Min              10.8712
trainer/Log Pis Mean                7.03363
trainer/Log Pis Std                 4.91026
trainer/Log Pis Max                31.313
trainer/Log Pis Min                -7.89105
trainer/Policy mu Mean             -0.102982
trainer/Policy mu Std               1.59963
trainer/Policy mu Max               4.48764
trainer/Policy mu Min              -5.60125
trainer/Policy log std Mean        -0.669516
trainer/Policy log std Std          0.217072
trainer/Policy log std Max         -0.0525756
trainer/Policy log std Min         -1.52868
trainer/Alpha                       0.011155
trainer/Alpha Loss                  0.151173
exploration/num steps total    381000
exploration/num paths total       762
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.96231
exploration/Rewards Std             0.165887
exploration/Rewards Max             1
exploration/Rewards Min             0.00225138
exploration/Returns Mean          481.155
exploration/Returns Std             3.08776
exploration/Returns Max           485.339
exploration/Returns Min           474.313
exploration/Actions Mean            0.149634
exploration/Actions Std             0.618051
exploration/Actions Max             0.999981
exploration/Actions Min            -0.999722
exploration/Num Paths              10
exploration/Average Returns       481.155
evaluation/num steps total     380000
evaluation/num paths total        760
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.875092
evaluation/Rewards Std              0.294884
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00306492
evaluation/Returns Mean           437.546
evaluation/Returns Std            115.395
evaluation/Returns Max            485.574
evaluation/Returns Min             97.4542
evaluation/ExplReturns Mean       437.546
evaluation/ExplReturns Std        115.395
evaluation/ExplReturns Max        485.574
evaluation/ExplReturns Min         97.4542
evaluation/Actions Mean             0.1842
evaluation/Actions Std              0.561885
evaluation/Actions Max              0.999834
evaluation/Actions Min             -0.99887
evaluation/Num Paths               10
evaluation/Average Returns        437.546
time/data storing (s)               0.0295378
time/evaluation sampling (s)       64.1807
time/exploration sampling (s)      68.1985
time/logging (s)                    0.0259248
time/saving (s)                     0.0721273
time/training (s)                  15.0347
time/epoch (s)                    147.541
time/total (s)                  11351.1
Epoch                              75
-----------------------------  ---------------
2023-08-31 15:06:16.751548 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size             386000
trainer/QF1 Loss                    1.5551
trainer/QF2 Loss                    1.72681
trainer/Policy Loss               -40.5341
trainer/Q1 Predictions Mean        46.9686
trainer/Q1 Predictions Std         24.1183
trainer/Q1 Predictions Max        113.665
trainer/Q1 Predictions Min          3.82008
trainer/Q2 Predictions Mean        46.873
trainer/Q2 Predictions Std         24.0727
trainer/Q2 Predictions Max        113.498
trainer/Q2 Predictions Min          4.84766
trainer/Q Targets Mean             46.6482
trainer/Q Targets Std              24.0846
trainer/Q Targets Max             114.362
trainer/Q Targets Min               4.63783
trainer/Log Pis Mean                6.74164
trainer/Log Pis Std                 4.6614
trainer/Log Pis Max                26.1738
trainer/Log Pis Min                -4.1832
trainer/Policy mu Mean              0.0517823
trainer/Policy mu Std               1.59227
trainer/Policy mu Max               5.94218
trainer/Policy mu Min              -3.97522
trainer/Policy log std Mean        -0.662661
trainer/Policy log std Std          0.226294
trainer/Policy log std Max         -0.0220208
trainer/Policy log std Min         -1.63848
trainer/Alpha                       0.01145
trainer/Alpha Loss                 -1.1548
exploration/num steps total    386000
exploration/num paths total       772
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.634954
exploration/Rewards Std             0.431923
exploration/Rewards Max             1
exploration/Rewards Min             0.00135161
exploration/Returns Mean          317.477
exploration/Returns Std           167.211
exploration/Returns Max           483.38
exploration/Returns Min            36.975
exploration/Actions Mean            0.135684
exploration/Actions Std             0.667289
exploration/Actions Max             0.999969
exploration/Actions Min            -0.999934
exploration/Num Paths              10
exploration/Average Returns       317.477
evaluation/num steps total     385000
evaluation/num paths total        770
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.640913
evaluation/Rewards Std              0.397942
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00219424
evaluation/Returns Mean           320.457
evaluation/Returns Std            181.43
evaluation/Returns Max            485.059
evaluation/Returns Min             71.8102
evaluation/ExplReturns Mean       320.457
evaluation/ExplReturns Std        181.43
evaluation/ExplReturns Max        485.059
evaluation/ExplReturns Min         71.8102
evaluation/Actions Mean             0.214418
evaluation/Actions Std              0.650701
evaluation/Actions Max              0.999494
evaluation/Actions Min             -0.998794
evaluation/Num Paths               10
evaluation/Average Returns        320.457
time/data storing (s)               0.0299457
time/evaluation sampling (s)       66.0192
time/exploration sampling (s)      68.932
time/logging (s)                    0.0255899
time/saving (s)                     0.0667112
time/training (s)                  10.9671
time/epoch (s)                    146.041
time/total (s)                  11497.2
Epoch                              76
-----------------------------  ---------------
2023-08-31 15:08:38.322234 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size             391000
trainer/QF1 Loss                    1.02316
trainer/QF2 Loss                    1.06434
trainer/Policy Loss               -43.5303
trainer/Q1 Predictions Mean        49.6539
trainer/Q1 Predictions Std         23.8035
trainer/Q1 Predictions Max        114.005
trainer/Q1 Predictions Min         11.2059
trainer/Q2 Predictions Mean        49.703
trainer/Q2 Predictions Std         23.8107
trainer/Q2 Predictions Max        114.314
trainer/Q2 Predictions Min         11.1461
trainer/Q Targets Mean             49.6511
trainer/Q Targets Std              23.6506
trainer/Q Targets Max             113.239
trainer/Q Targets Min              11.0064
trainer/Log Pis Mean                6.61899
trainer/Log Pis Std                 5.21459
trainer/Log Pis Max                38.6668
trainer/Log Pis Min                -3.19581
trainer/Policy mu Mean             -0.0091754
trainer/Policy mu Std               1.59484
trainer/Policy mu Max               5.94247
trainer/Policy mu Min              -6.25687
trainer/Policy log std Mean        -0.661706
trainer/Policy log std Std          0.226137
trainer/Policy log std Max          0.0886183
trainer/Policy log std Min         -1.65919
trainer/Alpha                       0.0116154
trainer/Alpha Loss                 -1.69747
exploration/num steps total    391000
exploration/num paths total       782
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.934069
exploration/Rewards Std             0.228261
exploration/Rewards Max             1
exploration/Rewards Min             0.00289178
exploration/Returns Mean          467.035
exploration/Returns Std            42.3599
exploration/Returns Max           485.241
exploration/Returns Min           340.294
exploration/Actions Mean            0.16308
exploration/Actions Std             0.690899
exploration/Actions Max             0.999984
exploration/Actions Min            -0.99997
exploration/Num Paths              10
exploration/Average Returns       467.035
evaluation/num steps total     390000
evaluation/num paths total        780
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.965689
evaluation/Rewards Std              0.157078
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00312274
evaluation/Returns Mean           482.845
evaluation/Returns Std              1.25088
evaluation/Returns Max            485.024
evaluation/Returns Min            480.945
evaluation/ExplReturns Mean       482.845
evaluation/ExplReturns Std          1.25088
evaluation/ExplReturns Max        485.024
evaluation/ExplReturns Min        480.945
evaluation/Actions Mean             0.142371
evaluation/Actions Std              0.634417
evaluation/Actions Max              0.999454
evaluation/Actions Min             -0.999886
evaluation/Num Paths               10
evaluation/Average Returns        482.845
time/data storing (s)               0.0297873
time/evaluation sampling (s)       63.9707
time/exploration sampling (s)      66.7968
time/logging (s)                    0.0252663
time/saving (s)                     0.070047
time/training (s)                  10.6738
time/epoch (s)                    141.566
time/total (s)                  11638.7
Epoch                              77
-----------------------------  ---------------
2023-08-31 15:11:01.210384 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size             396000
trainer/QF1 Loss                    0.612464
trainer/QF2 Loss                    0.63626
trainer/Policy Loss               -44.2622
trainer/Q1 Predictions Mean        49.7624
trainer/Q1 Predictions Std         22.8081
trainer/Q1 Predictions Max        100.088
trainer/Q1 Predictions Min          8.14225
trainer/Q2 Predictions Mean        49.7754
trainer/Q2 Predictions Std         22.9635
trainer/Q2 Predictions Max         99.5446
trainer/Q2 Predictions Min          7.75749
trainer/Q Targets Mean             49.6389
trainer/Q Targets Std              22.8028
trainer/Q Targets Max             100.274
trainer/Q Targets Min               7.77616
trainer/Log Pis Mean                5.84188
trainer/Log Pis Std                 4.49887
trainer/Log Pis Max                23.3898
trainer/Log Pis Min                -4.97867
trainer/Policy mu Mean             -0.0753534
trainer/Policy mu Std               1.53251
trainer/Policy mu Max               4.684
trainer/Policy mu Min              -5.07579
trainer/Policy log std Mean        -0.654597
trainer/Policy log std Std          0.217182
trainer/Policy log std Max         -0.0227995
trainer/Policy log std Min         -1.69994
trainer/Alpha                       0.0109989
trainer/Alpha Loss                 -5.22276
exploration/num steps total    396000
exploration/num paths total       792
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.747088
exploration/Rewards Std             0.395316
exploration/Rewards Max             1
exploration/Rewards Min             0.00272474
exploration/Returns Mean          373.544
exploration/Returns Std           150.302
exploration/Returns Max           486.119
exploration/Returns Min            84.136
exploration/Actions Mean            0.0651929
exploration/Actions Std             0.6939
exploration/Actions Max             0.999953
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       373.544
evaluation/num steps total     395000
evaluation/num paths total        790
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.938964
evaluation/Rewards Std              0.219917
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00254266
evaluation/Returns Mean           469.482
evaluation/Returns Std             36.6724
evaluation/Returns Max            486.64
evaluation/Returns Min            359.666
evaluation/ExplReturns Mean       469.482
evaluation/ExplReturns Std         36.6724
evaluation/ExplReturns Max        486.64
evaluation/ExplReturns Min        359.666
evaluation/Actions Mean             0.162654
evaluation/Actions Std              0.684949
evaluation/Actions Max              0.999959
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns        469.482
time/data storing (s)               0.0296297
time/evaluation sampling (s)       62.5771
time/exploration sampling (s)      69.3252
time/logging (s)                    0.0253813
time/saving (s)                     0.0657268
time/training (s)                  10.8613
time/epoch (s)                    142.884
time/total (s)                  11781.6
Epoch                              78
-----------------------------  ---------------
2023-08-31 15:13:24.589405 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 79 finished
-----------------------------  ----------------
replay_buffer/size             401000
trainer/QF1 Loss                    1.46299
trainer/QF2 Loss                    1.27514
trainer/Policy Loss               -44.3117
trainer/Q1 Predictions Mean        51.3816
trainer/Q1 Predictions Std         24.008
trainer/Q1 Predictions Max        104.768
trainer/Q1 Predictions Min          7.25122
trainer/Q2 Predictions Mean        51.4225
trainer/Q2 Predictions Std         24.0126
trainer/Q2 Predictions Max        105.447
trainer/Q2 Predictions Min          6.81915
trainer/Q Targets Mean             51.2375
trainer/Q Targets Std              23.9912
trainer/Q Targets Max             104.481
trainer/Q Targets Min               6.82613
trainer/Log Pis Mean                7.52786
trainer/Log Pis Std                 5.34086
trainer/Log Pis Max                25.2115
trainer/Log Pis Min                -3.61636
trainer/Policy mu Mean              0.141859
trainer/Policy mu Std               1.64312
trainer/Policy mu Max               4.76454
trainer/Policy mu Min              -4.21886
trainer/Policy log std Mean        -0.674102
trainer/Policy log std Std          0.224878
trainer/Policy log std Max          0.0401626
trainer/Policy log std Min         -1.9824
trainer/Alpha                       0.0111889
trainer/Alpha Loss                  2.37161
exploration/num steps total    401000
exploration/num paths total       802
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.838624
exploration/Rewards Std             0.351136
exploration/Rewards Max             1
exploration/Rewards Min             0.00290348
exploration/Returns Mean          419.312
exploration/Returns Std           146.46
exploration/Returns Max           486.281
exploration/Returns Min            10.3952
exploration/Actions Mean            0.215037
exploration/Actions Std             0.718646
exploration/Actions Max             0.999994
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns       419.312
evaluation/num steps total     400000
evaluation/num paths total        800
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.830244
evaluation/Rewards Std              0.360056
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000842858
evaluation/Returns Mean           415.122
evaluation/Returns Std            142.401
evaluation/Returns Max            486.702
evaluation/Returns Min             10.2326
evaluation/ExplReturns Mean       415.122
evaluation/ExplReturns Std        142.401
evaluation/ExplReturns Max        486.702
evaluation/ExplReturns Min         10.2326
evaluation/Actions Mean             0.227719
evaluation/Actions Std              0.690462
evaluation/Actions Max              0.999949
evaluation/Actions Min             -0.999994
evaluation/Num Paths               10
evaluation/Average Returns        415.122
time/data storing (s)               0.0294626
time/evaluation sampling (s)       63.8568
time/exploration sampling (s)      68.6892
time/logging (s)                    0.0254952
time/saving (s)                     0.0687343
time/training (s)                  10.7055
time/epoch (s)                    143.375
time/total (s)                  11925
Epoch                              79
-----------------------------  ----------------
2023-08-31 15:15:54.227926 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size             406000
trainer/QF1 Loss                    0.984156
trainer/QF2 Loss                    0.949645
trainer/Policy Loss               -42.2824
trainer/Q1 Predictions Mean        48.6134
trainer/Q1 Predictions Std         22.228
trainer/Q1 Predictions Max        106.554
trainer/Q1 Predictions Min          8.85397
trainer/Q2 Predictions Mean        48.7611
trainer/Q2 Predictions Std         22.3233
trainer/Q2 Predictions Max        107.214
trainer/Q2 Predictions Min          9.79382
trainer/Q Targets Mean             48.6773
trainer/Q Targets Std              22.352
trainer/Q Targets Max             108.366
trainer/Q Targets Min               9.59216
trainer/Log Pis Mean                6.86891
trainer/Log Pis Std                 4.64352
trainer/Log Pis Max                24.3702
trainer/Log Pis Min                -3.61132
trainer/Policy mu Mean             -0.083203
trainer/Policy mu Std               1.58923
trainer/Policy mu Max               5.37482
trainer/Policy mu Min              -6.65688
trainer/Policy log std Mean        -0.655809
trainer/Policy log std Std          0.222447
trainer/Policy log std Max         -0.0754737
trainer/Policy log std Min         -1.65328
trainer/Alpha                       0.011907
trainer/Alpha Loss                 -0.580807
exploration/num steps total    406000
exploration/num paths total       812
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.655972
exploration/Rewards Std             0.435875
exploration/Rewards Max             1
exploration/Rewards Min             0.00115439
exploration/Returns Mean          327.986
exploration/Returns Std           194.922
exploration/Returns Max           486.438
exploration/Returns Min            17.6132
exploration/Actions Mean            0.127259
exploration/Actions Std             0.697702
exploration/Actions Max             0.999986
exploration/Actions Min            -0.999901
exploration/Num Paths              10
exploration/Average Returns       327.986
evaluation/num steps total     405000
evaluation/num paths total        810
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.745645
evaluation/Rewards Std              0.402329
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00139916
evaluation/Returns Mean           372.823
evaluation/Returns Std            162.469
evaluation/Returns Max            486.405
evaluation/Returns Min             13.6148
evaluation/ExplReturns Mean       372.823
evaluation/ExplReturns Std        162.469
evaluation/ExplReturns Max        486.405
evaluation/ExplReturns Min         13.6148
evaluation/Actions Mean             0.188245
evaluation/Actions Std              0.644299
evaluation/Actions Max              0.999572
evaluation/Actions Min             -0.999846
evaluation/Num Paths               10
evaluation/Average Returns        372.823
time/data storing (s)               0.0298953
time/evaluation sampling (s)       65.2357
time/exploration sampling (s)      71.202
time/logging (s)                    0.0256185
time/saving (s)                     0.0658462
time/training (s)                  13.0756
time/epoch (s)                    149.635
time/total (s)                  12074.6
Epoch                              80
-----------------------------  ---------------
2023-08-31 15:18:19.867819 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size             411000
trainer/QF1 Loss                    0.733607
trainer/QF2 Loss                    0.681187
trainer/Policy Loss               -45.6948
trainer/Q1 Predictions Mean        52.458
trainer/Q1 Predictions Std         25.441
trainer/Q1 Predictions Max        112.727
trainer/Q1 Predictions Min          6.71512
trainer/Q2 Predictions Mean        52.4536
trainer/Q2 Predictions Std         25.5028
trainer/Q2 Predictions Max        113.154
trainer/Q2 Predictions Min          6.74039
trainer/Q Targets Mean             52.31
trainer/Q Targets Std              25.5688
trainer/Q Targets Max             112.809
trainer/Q Targets Min               6.45598
trainer/Log Pis Mean                7.19686
trainer/Log Pis Std                 4.94888
trainer/Log Pis Max                31.049
trainer/Log Pis Min                -4.56328
trainer/Policy mu Mean              0.070048
trainer/Policy mu Std               1.61237
trainer/Policy mu Max               4.89297
trainer/Policy mu Min              -4.82769
trainer/Policy log std Mean        -0.65284
trainer/Policy log std Std          0.227904
trainer/Policy log std Max          0.223233
trainer/Policy log std Min         -1.78579
trainer/Alpha                       0.0116443
trainer/Alpha Loss                  0.8766
exploration/num steps total    411000
exploration/num paths total       822
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.863267
exploration/Rewards Std             0.324044
exploration/Rewards Max             1
exploration/Rewards Min             0.00085931
exploration/Returns Mean          431.633
exploration/Returns Std           138.878
exploration/Returns Max           485.921
exploration/Returns Min            15.5241
exploration/Actions Mean            0.0772859
exploration/Actions Std             0.73855
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999993
exploration/Num Paths              10
exploration/Average Returns       431.633
evaluation/num steps total     410000
evaluation/num paths total        820
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.874203
evaluation/Rewards Std              0.283886
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0022412
evaluation/Returns Mean           437.102
evaluation/Returns Std            111.531
evaluation/Returns Max            485.481
evaluation/Returns Min            104.406
evaluation/ExplReturns Mean       437.102
evaluation/ExplReturns Std        111.531
evaluation/ExplReturns Max        485.481
evaluation/ExplReturns Min        104.406
evaluation/Actions Mean             0.102557
evaluation/Actions Std              0.68466
evaluation/Actions Max              0.999971
evaluation/Actions Min             -0.999984
evaluation/Num Paths               10
evaluation/Average Returns        437.102
time/data storing (s)               0.0299575
time/evaluation sampling (s)       64.3856
time/exploration sampling (s)      70.2241
time/logging (s)                    0.0257438
time/saving (s)                     0.0718862
time/training (s)                  10.8988
time/epoch (s)                    145.636
time/total (s)                  12220.3
Epoch                              81
-----------------------------  ---------------
2023-08-31 15:20:49.478347 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size             416000
trainer/QF1 Loss                    0.885942
trainer/QF2 Loss                    0.910823
trainer/Policy Loss               -47.937
trainer/Q1 Predictions Mean        54.1274
trainer/Q1 Predictions Std         25.7157
trainer/Q1 Predictions Max        110.274
trainer/Q1 Predictions Min          9.50679
trainer/Q2 Predictions Mean        54.0539
trainer/Q2 Predictions Std         25.6146
trainer/Q2 Predictions Max        110.41
trainer/Q2 Predictions Min          9.09128
trainer/Q Targets Mean             53.9606
trainer/Q Targets Std              25.7294
trainer/Q Targets Max             111.217
trainer/Q Targets Min               9.25318
trainer/Log Pis Mean                6.49657
trainer/Log Pis Std                 4.63728
trainer/Log Pis Max                21.1693
trainer/Log Pis Min                -6.57968
trainer/Policy mu Mean              0.167048
trainer/Policy mu Std               1.56295
trainer/Policy mu Max               5.54496
trainer/Policy mu Min              -4.22307
trainer/Policy log std Mean        -0.656286
trainer/Policy log std Std          0.237546
trainer/Policy log std Max          0.138886
trainer/Policy log std Min         -1.69885
trainer/Alpha                       0.0115449
trainer/Alpha Loss                 -2.24602
exploration/num steps total    416000
exploration/num paths total       832
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.872662
exploration/Rewards Std             0.318104
exploration/Rewards Max             1
exploration/Rewards Min             0.00233127
exploration/Returns Mean          436.331
exploration/Returns Std           134.116
exploration/Returns Max           485.915
exploration/Returns Min            34.0982
exploration/Actions Mean            0.189677
exploration/Actions Std             0.689009
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns       436.331
evaluation/num steps total     415000
evaluation/num paths total        830
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.780907
evaluation/Rewards Std              0.399741
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00161709
evaluation/Returns Mean           390.454
evaluation/Returns Std            186.832
evaluation/Returns Max            485.488
evaluation/Returns Min              9.16989
evaluation/ExplReturns Mean       390.454
evaluation/ExplReturns Std        186.832
evaluation/ExplReturns Max        485.488
evaluation/ExplReturns Min          9.16989
evaluation/Actions Mean             0.26888
evaluation/Actions Std              0.601313
evaluation/Actions Max              0.999971
evaluation/Actions Min             -0.999861
evaluation/Num Paths               10
evaluation/Average Returns        390.454
time/data storing (s)               0.0300486
time/evaluation sampling (s)       65.2731
time/exploration sampling (s)      68.57
time/logging (s)                    0.0256583
time/saving (s)                     0.0681039
time/training (s)                  15.6394
time/epoch (s)                    149.606
time/total (s)                  12369.9
Epoch                              82
-----------------------------  ---------------
2023-08-31 15:23:18.818999 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 83 finished
-----------------------------  ----------------
replay_buffer/size             421000
trainer/QF1 Loss                    1.59613
trainer/QF2 Loss                    1.53483
trainer/Policy Loss               -50.9581
trainer/Q1 Predictions Mean        57.5383
trainer/Q1 Predictions Std         25.2206
trainer/Q1 Predictions Max        110.594
trainer/Q1 Predictions Min          9.05659
trainer/Q2 Predictions Mean        57.4474
trainer/Q2 Predictions Std         25.0824
trainer/Q2 Predictions Max        110.062
trainer/Q2 Predictions Min          9.96663
trainer/Q Targets Mean             57.5154
trainer/Q Targets Std              25.2118
trainer/Q Targets Max             108.841
trainer/Q Targets Min              10.2157
trainer/Log Pis Mean                6.85843
trainer/Log Pis Std                 4.83726
trainer/Log Pis Max                27.7709
trainer/Log Pis Min                -4.48355
trainer/Policy mu Mean              0.150994
trainer/Policy mu Std               1.5879
trainer/Policy mu Max               4.87557
trainer/Policy mu Min              -5.21265
trainer/Policy log std Mean        -0.649556
trainer/Policy log std Std          0.232072
trainer/Policy log std Max          0.0885876
trainer/Policy log std Min         -1.5897
trainer/Alpha                       0.0118535
trainer/Alpha Loss                 -0.627846
exploration/num steps total    421000
exploration/num paths total       842
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.693723
exploration/Rewards Std             0.438294
exploration/Rewards Max             1
exploration/Rewards Min             0.000993949
exploration/Returns Mean          346.861
exploration/Returns Std           180.474
exploration/Returns Max           486.23
exploration/Returns Min            16.0778
exploration/Actions Mean            0.00300811
exploration/Actions Std             0.713698
exploration/Actions Max             0.999991
exploration/Actions Min            -0.999932
exploration/Num Paths              10
exploration/Average Returns       346.861
evaluation/num steps total     420000
evaluation/num paths total        840
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.790015
evaluation/Rewards Std              0.382215
evaluation/Rewards Max              1
evaluation/Rewards Min              0.000546198
evaluation/Returns Mean           395.007
evaluation/Returns Std            176.647
evaluation/Returns Max            486
evaluation/Returns Min             22.9271
evaluation/ExplReturns Mean       395.007
evaluation/ExplReturns Std        176.647
evaluation/ExplReturns Max        486
evaluation/ExplReturns Min         22.9271
evaluation/Actions Mean             0.12467
evaluation/Actions Std              0.62951
evaluation/Actions Max              0.999976
evaluation/Actions Min             -0.999811
evaluation/Num Paths               10
evaluation/Average Returns        395.007
time/data storing (s)               0.0300145
time/evaluation sampling (s)       66.2663
time/exploration sampling (s)      71.6622
time/logging (s)                    0.0257092
time/saving (s)                     0.0688591
time/training (s)                  11.2836
time/epoch (s)                    149.337
time/total (s)                  12519.2
Epoch                              83
-----------------------------  ----------------
2023-08-31 15:25:45.502024 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size             426000
trainer/QF1 Loss                    1.09803
trainer/QF2 Loss                    1.23965
trainer/Policy Loss               -51.254
trainer/Q1 Predictions Mean        57.8293
trainer/Q1 Predictions Std         24.0675
trainer/Q1 Predictions Max        108.564
trainer/Q1 Predictions Min         11.3594
trainer/Q2 Predictions Mean        58.0664
trainer/Q2 Predictions Std         24.2713
trainer/Q2 Predictions Max        109.244
trainer/Q2 Predictions Min         10.7889
trainer/Q Targets Mean             57.726
trainer/Q Targets Std              24.2104
trainer/Q Targets Max             108.522
trainer/Q Targets Min              11.3714
trainer/Log Pis Mean                7.16942
trainer/Log Pis Std                 5.28176
trainer/Log Pis Max                29.8329
trainer/Log Pis Min                -7.95446
trainer/Policy mu Mean              0.0848249
trainer/Policy mu Std               1.59375
trainer/Policy mu Max               5.05318
trainer/Policy mu Min              -3.92561
trainer/Policy log std Mean        -0.688069
trainer/Policy log std Std          0.230808
trainer/Policy log std Max         -0.0438641
trainer/Policy log std Min         -1.73869
trainer/Alpha                       0.0115328
trainer/Alpha Loss                  0.756037
exploration/num steps total    426000
exploration/num paths total       852
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.953009
exploration/Rewards Std             0.1857
exploration/Rewards Max             1
exploration/Rewards Min             0.00301211
exploration/Returns Mean          476.505
exploration/Returns Std            21.4987
exploration/Returns Max           485.443
exploration/Returns Min           412.237
exploration/Actions Mean            0.227866
exploration/Actions Std             0.653121
exploration/Actions Max             0.999989
exploration/Actions Min            -0.999923
exploration/Num Paths              10
exploration/Average Returns       476.505
evaluation/num steps total     425000
evaluation/num paths total        850
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.843301
evaluation/Rewards Std              0.346058
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00283245
evaluation/Returns Mean           421.651
evaluation/Returns Std             90.9523
evaluation/Returns Max            485.085
evaluation/Returns Min            238.947
evaluation/ExplReturns Mean       421.651
evaluation/ExplReturns Std         90.9523
evaluation/ExplReturns Max        485.085
evaluation/ExplReturns Min        238.947
evaluation/Actions Mean             0.202098
evaluation/Actions Std              0.658134
evaluation/Actions Max              0.999818
evaluation/Actions Min             -0.999996
evaluation/Num Paths               10
evaluation/Average Returns        421.651
time/data storing (s)               0.0298325
time/evaluation sampling (s)       67.119
time/exploration sampling (s)      68.4898
time/logging (s)                    0.0257008
time/saving (s)                     0.060891
time/training (s)                  10.9538
time/epoch (s)                    146.679
time/total (s)                  12665.9
Epoch                              84
-----------------------------  ---------------
2023-08-31 15:28:18.435916 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size             431000
trainer/QF1 Loss                    0.923425
trainer/QF2 Loss                    0.81562
trainer/Policy Loss               -47.3128
trainer/Q1 Predictions Mean        53.985
trainer/Q1 Predictions Std         23.3749
trainer/Q1 Predictions Max        107.475
trainer/Q1 Predictions Min          5.45945
trainer/Q2 Predictions Mean        53.9401
trainer/Q2 Predictions Std         23.3541
trainer/Q2 Predictions Max        107.536
trainer/Q2 Predictions Min          5.35532
trainer/Q Targets Mean             53.8238
trainer/Q Targets Std              23.32
trainer/Q Targets Max             106.698
trainer/Q Targets Min               5.46681
trainer/Log Pis Mean                7.12282
trainer/Log Pis Std                 5.18932
trainer/Log Pis Max                28.4039
trainer/Log Pis Min                -4.42473
trainer/Policy mu Mean              0.147484
trainer/Policy mu Std               1.61006
trainer/Policy mu Max               4.58423
trainer/Policy mu Min              -4.11871
trainer/Policy log std Mean        -0.688946
trainer/Policy log std Std          0.234836
trainer/Policy log std Max          0.10015
trainer/Policy log std Min         -1.64088
trainer/Alpha                       0.0116573
trainer/Alpha Loss                  0.546761
exploration/num steps total    431000
exploration/num paths total       862
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.918217
exploration/Rewards Std             0.229186
exploration/Rewards Max             1
exploration/Rewards Min             0.00287777
exploration/Returns Mean          459.108
exploration/Returns Std            77.232
exploration/Returns Max           486.156
exploration/Returns Min           227.423
exploration/Actions Mean            0.302088
exploration/Actions Std             0.740069
exploration/Actions Max             0.999981
exploration/Actions Min            -0.999661
exploration/Num Paths              10
exploration/Average Returns       459.108
evaluation/num steps total     430000
evaluation/num paths total        860
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.901884
evaluation/Rewards Std              0.248256
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00227166
evaluation/Returns Mean           450.942
evaluation/Returns Std            100.289
evaluation/Returns Max            486.722
evaluation/Returns Min            150.105
evaluation/ExplReturns Mean       450.942
evaluation/ExplReturns Std        100.289
evaluation/ExplReturns Max        486.722
evaluation/ExplReturns Min        150.105
evaluation/Actions Mean             0.423713
evaluation/Actions Std              0.646482
evaluation/Actions Max              0.999702
evaluation/Actions Min             -0.999807
evaluation/Num Paths               10
evaluation/Average Returns        450.942
time/data storing (s)               0.0301472
time/evaluation sampling (s)       68.213
time/exploration sampling (s)      73.8851
time/logging (s)                    0.0256681
time/saving (s)                     0.0726793
time/training (s)                  10.7032
time/epoch (s)                    152.93
time/total (s)                  12818.8
Epoch                              85
-----------------------------  ---------------
2023-08-31 15:30:53.941280 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size             436000
trainer/QF1 Loss                    1.0153
trainer/QF2 Loss                    1.04369
trainer/Policy Loss               -48.2103
trainer/Q1 Predictions Mean        54.5491
trainer/Q1 Predictions Std         24.3189
trainer/Q1 Predictions Max        106.352
trainer/Q1 Predictions Min          7.69018
trainer/Q2 Predictions Mean        54.6975
trainer/Q2 Predictions Std         24.4142
trainer/Q2 Predictions Max        106.403
trainer/Q2 Predictions Min          5.97075
trainer/Q Targets Mean             54.6452
trainer/Q Targets Std              24.5102
trainer/Q Targets Max             106.796
trainer/Q Targets Min               8.02767
trainer/Log Pis Mean                6.84643
trainer/Log Pis Std                 5.03999
trainer/Log Pis Max                24.4628
trainer/Log Pis Min                -2.88406
trainer/Policy mu Mean              0.183639
trainer/Policy mu Std               1.59212
trainer/Policy mu Max               5.41087
trainer/Policy mu Min              -4.36534
trainer/Policy log std Mean        -0.657371
trainer/Policy log std Std          0.23101
trainer/Policy log std Max          0.0340437
trainer/Policy log std Min         -1.78483
trainer/Alpha                       0.0114318
trainer/Alpha Loss                 -0.686658
exploration/num steps total    436000
exploration/num paths total       872
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.969197
exploration/Rewards Std             0.151678
exploration/Rewards Max             1
exploration/Rewards Min             0.00298614
exploration/Returns Mean          484.599
exploration/Returns Std             2.07232
exploration/Returns Max           486.548
exploration/Returns Min           478.801
exploration/Actions Mean            0.203026
exploration/Actions Std             0.718856
exploration/Actions Max             0.999966
exploration/Actions Min            -0.999789
exploration/Num Paths              10
exploration/Average Returns       484.599
evaluation/num steps total     435000
evaluation/num paths total        870
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.876683
evaluation/Rewards Std              0.315042
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0029787
evaluation/Returns Mean           438.341
evaluation/Returns Std            133.147
evaluation/Returns Max            486.294
evaluation/Returns Min             39.0101
evaluation/ExplReturns Mean       438.341
evaluation/ExplReturns Std        133.147
evaluation/ExplReturns Max        486.294
evaluation/ExplReturns Min         39.0101
evaluation/Actions Mean             0.20696
evaluation/Actions Std              0.665748
evaluation/Actions Max              0.9999
evaluation/Actions Min             -0.999476
evaluation/Num Paths               10
evaluation/Average Returns        438.341
time/data storing (s)               0.0297203
time/evaluation sampling (s)       69.2715
time/exploration sampling (s)      72.78
time/logging (s)                    0.0256455
time/saving (s)                     0.0661747
time/training (s)                  13.3282
time/epoch (s)                    155.501
time/total (s)                  12974.3
Epoch                              86
-----------------------------  ---------------
2023-08-31 15:33:24.450261 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size             441000
trainer/QF1 Loss                    1.15831
trainer/QF2 Loss                    0.963458
trainer/Policy Loss               -50.3048
trainer/Q1 Predictions Mean        56.4832
trainer/Q1 Predictions Std         24.4733
trainer/Q1 Predictions Max        104.712
trainer/Q1 Predictions Min          7.83272
trainer/Q2 Predictions Mean        56.5937
trainer/Q2 Predictions Std         24.4853
trainer/Q2 Predictions Max        105.027
trainer/Q2 Predictions Min          7.88112
trainer/Q Targets Mean             56.9818
trainer/Q Targets Std              24.7817
trainer/Q Targets Max             106.34
trainer/Q Targets Min               8.88823
trainer/Log Pis Mean                6.67432
trainer/Log Pis Std                 4.71869
trainer/Log Pis Max                22.3184
trainer/Log Pis Min                -4.81604
trainer/Policy mu Mean             -0.00135083
trainer/Policy mu Std               1.58232
trainer/Policy mu Max               4.39902
trainer/Policy mu Min              -4.70519
trainer/Policy log std Mean        -0.688235
trainer/Policy log std Std          0.249855
trainer/Policy log std Max         -0.106858
trainer/Policy log std Min         -1.62569
trainer/Alpha                       0.011688
trainer/Alpha Loss                 -1.4491
exploration/num steps total    441000
exploration/num paths total       882
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.886198
exploration/Rewards Std             0.268703
exploration/Rewards Max             1
exploration/Rewards Min             0.00241469
exploration/Returns Mean          443.099
exploration/Returns Std           107.147
exploration/Returns Max           485.196
exploration/Returns Min           122.324
exploration/Actions Mean           -0.00999915
exploration/Actions Std             0.714859
exploration/Actions Max             0.99991
exploration/Actions Min            -0.999996
exploration/Num Paths              10
exploration/Average Returns       443.099
evaluation/num steps total     440000
evaluation/num paths total        880
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.883719
evaluation/Rewards Std              0.270245
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00224523
evaluation/Returns Mean           441.86
evaluation/Returns Std            105.141
evaluation/Returns Max            484.799
evaluation/Returns Min            128.021
evaluation/ExplReturns Mean       441.86
evaluation/ExplReturns Std        105.141
evaluation/ExplReturns Max        484.799
evaluation/ExplReturns Min        128.021
evaluation/Actions Mean             0.0747134
evaluation/Actions Std              0.64987
evaluation/Actions Max              0.999189
evaluation/Actions Min             -0.999883
evaluation/Num Paths               10
evaluation/Average Returns        441.86
time/data storing (s)               0.0304583
time/evaluation sampling (s)       67.7518
time/exploration sampling (s)      71.3676
time/logging (s)                    0.0254455
time/saving (s)                     0.0734408
time/training (s)                  11.256
time/epoch (s)                    150.505
time/total (s)                  13124.8
Epoch                              87
-----------------------------  ---------------
2023-08-31 15:35:56.976925 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size             446000
trainer/QF1 Loss                    1.05426
trainer/QF2 Loss                    0.95275
trainer/Policy Loss               -51.2577
trainer/Q1 Predictions Mean        57.9916
trainer/Q1 Predictions Std         26.9025
trainer/Q1 Predictions Max        105.862
trainer/Q1 Predictions Min          7.30715
trainer/Q2 Predictions Mean        58.0737
trainer/Q2 Predictions Std         26.872
trainer/Q2 Predictions Max        106.266
trainer/Q2 Predictions Min          5.7256
trainer/Q Targets Mean             58.0951
trainer/Q Targets Std              26.8132
trainer/Q Targets Max             105.99
trainer/Q Targets Min               5.44116
trainer/Log Pis Mean                7.09784
trainer/Log Pis Std                 5.00989
trainer/Log Pis Max                27.0628
trainer/Log Pis Min                -5.03487
trainer/Policy mu Mean              0.110815
trainer/Policy mu Std               1.59277
trainer/Policy mu Max               5.22294
trainer/Policy mu Min              -4.25997
trainer/Policy log std Mean        -0.670021
trainer/Policy log std Std          0.249981
trainer/Policy log std Max          0.194321
trainer/Policy log std Min         -1.64126
trainer/Alpha                       0.0119165
trainer/Alpha Loss                  0.433414
exploration/num steps total    446000
exploration/num paths total       892
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.948596
exploration/Rewards Std             0.18716
exploration/Rewards Max             1
exploration/Rewards Min             0.00283333
exploration/Returns Mean          474.298
exploration/Returns Std            28.2121
exploration/Returns Max           485.213
exploration/Returns Min           389.917
exploration/Actions Mean            0.209647
exploration/Actions Std             0.723425
exploration/Actions Max             0.999979
exploration/Actions Min            -0.999914
exploration/Num Paths              10
exploration/Average Returns       474.298
evaluation/num steps total     445000
evaluation/num paths total        890
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.967741
evaluation/Rewards Std              0.154806
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00254707
evaluation/Returns Mean           483.871
evaluation/Returns Std              1.4718
evaluation/Returns Max            485.22
evaluation/Returns Min            480.358
evaluation/ExplReturns Mean       483.871
evaluation/ExplReturns Std          1.4718
evaluation/ExplReturns Max        485.22
evaluation/ExplReturns Min        480.358
evaluation/Actions Mean            -0.0231787
evaluation/Actions Std              0.821005
evaluation/Actions Max              0.999892
evaluation/Actions Min             -0.999186
evaluation/Num Paths               10
evaluation/Average Returns        483.871
time/data storing (s)               0.0295647
time/evaluation sampling (s)       69.5381
time/exploration sampling (s)      72.1403
time/logging (s)                    0.025695
time/saving (s)                     0.0733743
time/training (s)                  10.7159
time/epoch (s)                    152.523
time/total (s)                  13277.4
Epoch                              88
-----------------------------  ---------------
2023-08-31 15:38:31.020507 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size             451000
trainer/QF1 Loss                    1.75795
trainer/QF2 Loss                    1.5011
trainer/Policy Loss               -53.4452
trainer/Q1 Predictions Mean        60.1593
trainer/Q1 Predictions Std         24.9175
trainer/Q1 Predictions Max        105.23
trainer/Q1 Predictions Min          8.47954
trainer/Q2 Predictions Mean        60.1093
trainer/Q2 Predictions Std         24.9001
trainer/Q2 Predictions Max        105.357
trainer/Q2 Predictions Min          8.70804
trainer/Q Targets Mean             60.1394
trainer/Q Targets Std              24.9446
trainer/Q Targets Max             105.44
trainer/Q Targets Min               9.21509
trainer/Log Pis Mean                7.16046
trainer/Log Pis Std                 5.10217
trainer/Log Pis Max                30.3235
trainer/Log Pis Min                -8.93485
trainer/Policy mu Mean             -0.0343327
trainer/Policy mu Std               1.58552
trainer/Policy mu Max               4.61057
trainer/Policy mu Min              -6.54806
trainer/Policy log std Mean        -0.701452
trainer/Policy log std Std          0.25612
trainer/Policy log std Max          0.0149571
trainer/Policy log std Min         -1.70418
trainer/Alpha                       0.0115796
trainer/Alpha Loss                  0.715412
exploration/num steps total    451000
exploration/num paths total       902
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.968787
exploration/Rewards Std             0.152225
exploration/Rewards Max             1
exploration/Rewards Min             0.00282907
exploration/Returns Mean          484.394
exploration/Returns Std             1.00577
exploration/Returns Max           485.746
exploration/Returns Min           482.583
exploration/Actions Mean           -0.0197782
exploration/Actions Std             0.78205
exploration/Actions Max             0.999964
exploration/Actions Min            -0.999953
exploration/Num Paths              10
exploration/Average Returns       484.394
evaluation/num steps total     450000
evaluation/num paths total        900
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.955504
evaluation/Rewards Std              0.174413
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00209851
evaluation/Returns Mean           477.752
evaluation/Returns Std             21.3177
evaluation/Returns Max            486.417
evaluation/Returns Min            413.934
evaluation/ExplReturns Mean       477.752
evaluation/ExplReturns Std         21.3177
evaluation/ExplReturns Max        486.417
evaluation/ExplReturns Min        413.934
evaluation/Actions Mean             0.178154
evaluation/Actions Std              0.714958
evaluation/Actions Max              0.999864
evaluation/Actions Min             -0.999575
evaluation/Num Paths               10
evaluation/Average Returns        477.752
time/data storing (s)               0.0294151
time/evaluation sampling (s)       67.7594
time/exploration sampling (s)      75.5012
time/logging (s)                    0.0283034
time/saving (s)                     0.0308083
time/training (s)                  10.693
time/epoch (s)                    154.042
time/total (s)                  13431.4
Epoch                              89
-----------------------------  ---------------
2023-08-31 15:41:00.324576 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size             456000
trainer/QF1 Loss                    1.14551
trainer/QF2 Loss                    1.13031
trainer/Policy Loss               -54.2825
trainer/Q1 Predictions Mean        60.4344
trainer/Q1 Predictions Std         26.0493
trainer/Q1 Predictions Max        106.221
trainer/Q1 Predictions Min          6.66769
trainer/Q2 Predictions Mean        60.4409
trainer/Q2 Predictions Std         26.0658
trainer/Q2 Predictions Max        106.005
trainer/Q2 Predictions Min          5.04447
trainer/Q Targets Mean             60.6959
trainer/Q Targets Std              26.1345
trainer/Q Targets Max             106.049
trainer/Q Targets Min               5.62946
trainer/Log Pis Mean                6.59542
trainer/Log Pis Std                 4.21413
trainer/Log Pis Max                19.1632
trainer/Log Pis Min                -3.79862
trainer/Policy mu Mean              0.162351
trainer/Policy mu Std               1.5693
trainer/Policy mu Max               5.27303
trainer/Policy mu Min              -5.57275
trainer/Policy log std Mean        -0.680574
trainer/Policy log std Std          0.25662
trainer/Policy log std Max         -0.0720382
trainer/Policy log std Min         -1.86182
trainer/Alpha                       0.0120659
trainer/Alpha Loss                 -1.78727
exploration/num steps total    456000
exploration/num paths total       912
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.919507
exploration/Rewards Std             0.227255
exploration/Rewards Max             1
exploration/Rewards Min             0.0026957
exploration/Returns Mean          459.754
exploration/Returns Std            47.854
exploration/Returns Max           484.969
exploration/Returns Min           352.26
exploration/Actions Mean            0.102851
exploration/Actions Std             0.757145
exploration/Actions Max             0.999996
exploration/Actions Min            -0.999871
exploration/Num Paths              10
exploration/Average Returns       459.754
evaluation/num steps total     455000
evaluation/num paths total        910
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.947464
evaluation/Rewards Std              0.190443
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00222887
evaluation/Returns Mean           473.732
evaluation/Returns Std             22.0496
evaluation/Returns Max            484.4
evaluation/Returns Min            408.269
evaluation/ExplReturns Mean       473.732
evaluation/ExplReturns Std         22.0496
evaluation/ExplReturns Max        484.4
evaluation/ExplReturns Min        408.269
evaluation/Actions Mean             0.160717
evaluation/Actions Std              0.70667
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.999713
evaluation/Num Paths               10
evaluation/Average Returns        473.732
time/data storing (s)               0.0298696
time/evaluation sampling (s)       66.5401
time/exploration sampling (s)      72.0164
time/logging (s)                    0.0258564
time/saving (s)                     0.0671358
time/training (s)                  10.6181
time/epoch (s)                    149.298
time/total (s)                  13580.7
Epoch                              90
-----------------------------  ---------------
2023-08-31 15:43:33.496914 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size             461000
trainer/QF1 Loss                    0.960858
trainer/QF2 Loss                    0.876462
trainer/Policy Loss               -51.9709
trainer/Q1 Predictions Mean        58.6605
trainer/Q1 Predictions Std         23.7075
trainer/Q1 Predictions Max        105.212
trainer/Q1 Predictions Min         15.2349
trainer/Q2 Predictions Mean        58.6814
trainer/Q2 Predictions Std         23.7296
trainer/Q2 Predictions Max        105.246
trainer/Q2 Predictions Min         15.455
trainer/Q Targets Mean             58.6941
trainer/Q Targets Std              23.7765
trainer/Q Targets Max             105.71
trainer/Q Targets Min              14.2725
trainer/Log Pis Mean                7.26008
trainer/Log Pis Std                 5.32621
trainer/Log Pis Max                35.2883
trainer/Log Pis Min                -6.97188
trainer/Policy mu Mean              0.0538093
trainer/Policy mu Std               1.62591
trainer/Policy mu Max               6.77433
trainer/Policy mu Min              -5.70499
trainer/Policy log std Mean        -0.70864
trainer/Policy log std Std          0.264798
trainer/Policy log std Max         -0.0428728
trainer/Policy log std Min         -1.74536
trainer/Alpha                       0.0116889
trainer/Alpha Loss                  1.15715
exploration/num steps total    461000
exploration/num paths total       922
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.94295
exploration/Rewards Std             0.197064
exploration/Rewards Max             1
exploration/Rewards Min             0.0023483
exploration/Returns Mean          471.475
exploration/Returns Std            20.284
exploration/Returns Max           483.296
exploration/Returns Min           416.425
exploration/Actions Mean            0.0598501
exploration/Actions Std             0.697359
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999712
exploration/Num Paths              10
exploration/Average Returns       471.475
evaluation/num steps total     460000
evaluation/num paths total        920
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.903793
evaluation/Rewards Std              0.255383
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00204032
evaluation/Returns Mean           451.897
evaluation/Returns Std             92.0359
evaluation/Returns Max            484.489
evaluation/Returns Min            175.821
evaluation/ExplReturns Mean       451.897
evaluation/ExplReturns Std         92.0359
evaluation/ExplReturns Max        484.489
evaluation/ExplReturns Min        175.821
evaluation/Actions Mean             0.0475206
evaluation/Actions Std              0.680849
evaluation/Actions Max              0.999684
evaluation/Actions Min             -0.999964
evaluation/Num Paths               10
evaluation/Average Returns        451.897
time/data storing (s)               0.0299006
time/evaluation sampling (s)       68.9464
time/exploration sampling (s)      73.6474
time/logging (s)                    0.0256344
time/saving (s)                     0.0699465
time/training (s)                  10.4488
time/epoch (s)                    153.168
time/total (s)                  13733.9
Epoch                              91
-----------------------------  ---------------
2023-08-31 15:46:04.040239 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size             466000
trainer/QF1 Loss                    0.838654
trainer/QF2 Loss                    0.968173
trainer/Policy Loss               -54.5367
trainer/Q1 Predictions Mean        60.9003
trainer/Q1 Predictions Std         23.4357
trainer/Q1 Predictions Max        110.642
trainer/Q1 Predictions Min         11.4989
trainer/Q2 Predictions Mean        60.7884
trainer/Q2 Predictions Std         23.3937
trainer/Q2 Predictions Max        109.344
trainer/Q2 Predictions Min         12.6138
trainer/Q Targets Mean             60.9936
trainer/Q Targets Std              23.548
trainer/Q Targets Max             110.122
trainer/Q Targets Min              12.1177
trainer/Log Pis Mean                6.71327
trainer/Log Pis Std                 4.98661
trainer/Log Pis Max                26.2505
trainer/Log Pis Min                -5.74304
trainer/Policy mu Mean              0.0743811
trainer/Policy mu Std               1.55478
trainer/Policy mu Max               4.29975
trainer/Policy mu Min              -4.11206
trainer/Policy log std Mean        -0.700962
trainer/Policy log std Std          0.248254
trainer/Policy log std Max          0.0598004
trainer/Policy log std Min         -1.57563
trainer/Alpha                       0.0116869
trainer/Alpha Loss                 -1.27578
exploration/num steps total    466000
exploration/num paths total       932
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.933698
exploration/Rewards Std             0.229943
exploration/Rewards Max             1
exploration/Rewards Min             0.00213679
exploration/Returns Mean          466.849
exploration/Returns Std            54.3272
exploration/Returns Max           486.494
exploration/Returns Min           303.92
exploration/Actions Mean            0.304685
exploration/Actions Std             0.659115
exploration/Actions Max             0.999914
exploration/Actions Min            -0.999733
exploration/Num Paths              10
exploration/Average Returns       466.849
evaluation/num steps total     465000
evaluation/num paths total        930
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.968744
evaluation/Rewards Std              0.151579
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00253045
evaluation/Returns Mean           484.372
evaluation/Returns Std              3.96181
evaluation/Returns Max            486.362
evaluation/Returns Min            472.608
evaluation/ExplReturns Mean       484.372
evaluation/ExplReturns Std          3.96181
evaluation/ExplReturns Max        486.362
evaluation/ExplReturns Min        472.608
evaluation/Actions Mean             0.42548
evaluation/Actions Std              0.554871
evaluation/Actions Max              0.999595
evaluation/Actions Min             -0.999207
evaluation/Num Paths               10
evaluation/Average Returns        484.372
time/data storing (s)               0.0297267
time/evaluation sampling (s)       68.0704
time/exploration sampling (s)      71.8948
time/logging (s)                    0.0255447
time/saving (s)                     0.0528433
time/training (s)                  10.4659
time/epoch (s)                    150.539
time/total (s)                  13884.4
Epoch                              92
-----------------------------  ---------------
2023-08-31 15:48:36.344539 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size             471000
trainer/QF1 Loss                    0.851576
trainer/QF2 Loss                    0.754623
trainer/Policy Loss               -52.5964
trainer/Q1 Predictions Mean        59.3446
trainer/Q1 Predictions Std         24.9297
trainer/Q1 Predictions Max        104.611
trainer/Q1 Predictions Min          8.47137
trainer/Q2 Predictions Mean        59.2494
trainer/Q2 Predictions Std         24.983
trainer/Q2 Predictions Max        104.149
trainer/Q2 Predictions Min          9.21095
trainer/Q Targets Mean             59.0931
trainer/Q Targets Std              24.9492
trainer/Q Targets Max             104.035
trainer/Q Targets Min               8.76852
trainer/Log Pis Mean                7.15294
trainer/Log Pis Std                 4.37312
trainer/Log Pis Max                24.2584
trainer/Log Pis Min                -3.21974
trainer/Policy mu Mean              0.0110175
trainer/Policy mu Std               1.60464
trainer/Policy mu Max               4.78379
trainer/Policy mu Min              -4.90673
trainer/Policy log std Mean        -0.682871
trainer/Policy log std Std          0.268265
trainer/Policy log std Max         -0.0701366
trainer/Policy log std Min         -1.761
trainer/Alpha                       0.0121775
trainer/Alpha Loss                  0.674172
exploration/num steps total    471000
exploration/num paths total       942
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.964371
exploration/Rewards Std             0.160025
exploration/Rewards Max             1
exploration/Rewards Min             0.00309322
exploration/Returns Mean          482.186
exploration/Returns Std             2.99943
exploration/Returns Max           484.83
exploration/Returns Min           474.565
exploration/Actions Mean           -0.0274974
exploration/Actions Std             0.747123
exploration/Actions Max             0.999993
exploration/Actions Min            -0.999945
exploration/Num Paths              10
exploration/Average Returns       482.186
evaluation/num steps total     470000
evaluation/num paths total        940
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.966301
evaluation/Rewards Std              0.156225
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00346071
evaluation/Returns Mean           483.15
evaluation/Returns Std              1.6118
evaluation/Returns Max            484.634
evaluation/Returns Min            478.999
evaluation/ExplReturns Mean       483.15
evaluation/ExplReturns Std          1.6118
evaluation/ExplReturns Max        484.634
evaluation/ExplReturns Min        478.999
evaluation/Actions Mean            -0.170138
evaluation/Actions Std              0.760236
evaluation/Actions Max              0.999677
evaluation/Actions Min             -0.998922
evaluation/Num Paths               10
evaluation/Average Returns        483.15
time/data storing (s)               0.0297059
time/evaluation sampling (s)       69.1029
time/exploration sampling (s)      73.0853
time/logging (s)                    0.0254868
time/saving (s)                     0.0863981
time/training (s)                   9.97025
time/epoch (s)                    152.3
time/total (s)                  14036.7
Epoch                              93
-----------------------------  ---------------
2023-08-31 15:51:10.822426 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size             476000
trainer/QF1 Loss                    0.915575
trainer/QF2 Loss                    1.03066
trainer/Policy Loss               -56.005
trainer/Q1 Predictions Mean        62.7841
trainer/Q1 Predictions Std         23.6954
trainer/Q1 Predictions Max        104.579
trainer/Q1 Predictions Min         22.0594
trainer/Q2 Predictions Mean        62.8253
trainer/Q2 Predictions Std         23.7354
trainer/Q2 Predictions Max        104.438
trainer/Q2 Predictions Min         21.8441
trainer/Q Targets Mean             62.6314
trainer/Q Targets Std              23.5945
trainer/Q Targets Max             103.897
trainer/Q Targets Min              22.593
trainer/Log Pis Mean                7.21473
trainer/Log Pis Std                 4.55817
trainer/Log Pis Max                23.7244
trainer/Log Pis Min                -5.52489
trainer/Policy mu Mean              0.00607841
trainer/Policy mu Std               1.59917
trainer/Policy mu Max               4.86425
trainer/Policy mu Min              -3.99696
trainer/Policy log std Mean        -0.696224
trainer/Policy log std Std          0.255152
trainer/Policy log std Max          0.066247
trainer/Policy log std Min         -1.64992
trainer/Alpha                       0.0120765
trainer/Alpha Loss                  0.948392
exploration/num steps total    476000
exploration/num paths total       952
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.96797
exploration/Rewards Std             0.154463
exploration/Rewards Max             1
exploration/Rewards Min             0.00207611
exploration/Returns Mean          483.985
exploration/Returns Std             1.27067
exploration/Returns Max           485.333
exploration/Returns Min           481.162
exploration/Actions Mean            0.137678
exploration/Actions Std             0.717623
exploration/Actions Max             0.999887
exploration/Actions Min            -0.999929
exploration/Num Paths              10
exploration/Average Returns       483.985
evaluation/num steps total     475000
evaluation/num paths total        950
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.969224
evaluation/Rewards Std              0.150731
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00291079
evaluation/Returns Mean           484.612
evaluation/Returns Std              1.29972
evaluation/Returns Max            485.807
evaluation/Returns Min            482.158
evaluation/ExplReturns Mean       484.612
evaluation/ExplReturns Std          1.29972
evaluation/ExplReturns Max        485.807
evaluation/ExplReturns Min        482.158
evaluation/Actions Mean             0.00357518
evaluation/Actions Std              0.697474
evaluation/Actions Max              0.999612
evaluation/Actions Min             -0.999966
evaluation/Num Paths               10
evaluation/Average Returns        484.612
time/data storing (s)               0.0300104
time/evaluation sampling (s)       68.6507
time/exploration sampling (s)      75.2805
time/logging (s)                    0.025596
time/saving (s)                     0.0678445
time/training (s)                  10.4193
time/epoch (s)                    154.474
time/total (s)                  14191.2
Epoch                              94
-----------------------------  ---------------
2023-08-31 15:53:44.196789 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size             481000
trainer/QF1 Loss                    0.738337
trainer/QF2 Loss                    0.59911
trainer/Policy Loss               -56.8383
trainer/Q1 Predictions Mean        63.5774
trainer/Q1 Predictions Std         25.5941
trainer/Q1 Predictions Max        103.137
trainer/Q1 Predictions Min         10.566
trainer/Q2 Predictions Mean        63.5743
trainer/Q2 Predictions Std         25.5644
trainer/Q2 Predictions Max        103.075
trainer/Q2 Predictions Min         11.8876
trainer/Q Targets Mean             63.6262
trainer/Q Targets Std              25.5059
trainer/Q Targets Max             103.14
trainer/Q Targets Min              12.0224
trainer/Log Pis Mean                7.16692
trainer/Log Pis Std                 4.61712
trainer/Log Pis Max                25.5976
trainer/Log Pis Min                -3.4855
trainer/Policy mu Mean              0.168873
trainer/Policy mu Std               1.62022
trainer/Policy mu Max               4.44801
trainer/Policy mu Min              -4.72919
trainer/Policy log std Mean        -0.664089
trainer/Policy log std Std          0.24019
trainer/Policy log std Max          0.00428778
trainer/Policy log std Min         -1.57166
trainer/Alpha                       0.0118947
trainer/Alpha Loss                  0.739762
exploration/num steps total    481000
exploration/num paths total       962
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967175
exploration/Rewards Std             0.154689
exploration/Rewards Max             1
exploration/Rewards Min             0.00254061
exploration/Returns Mean          483.588
exploration/Returns Std             1.3809
exploration/Returns Max           485.767
exploration/Returns Min           481.597
exploration/Actions Mean            0.256693
exploration/Actions Std             0.722052
exploration/Actions Max             0.999987
exploration/Actions Min            -0.999898
exploration/Num Paths              10
exploration/Average Returns       483.588
evaluation/num steps total     480000
evaluation/num paths total        960
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.969739
evaluation/Rewards Std              0.149153
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00299624
evaluation/Returns Mean           484.87
evaluation/Returns Std              0.968838
evaluation/Returns Max            486.439
evaluation/Returns Min            483.426
evaluation/ExplReturns Mean       484.87
evaluation/ExplReturns Std          0.968838
evaluation/ExplReturns Max        486.439
evaluation/ExplReturns Min        483.426
evaluation/Actions Mean             0.135947
evaluation/Actions Std              0.765498
evaluation/Actions Max              0.99954
evaluation/Actions Min             -0.997815
evaluation/Num Paths               10
evaluation/Average Returns        484.87
time/data storing (s)               0.0297576
time/evaluation sampling (s)       70.0015
time/exploration sampling (s)      72.4281
time/logging (s)                    0.0255849
time/saving (s)                     0.0812872
time/training (s)                  10.8041
time/epoch (s)                    153.37
time/total (s)                  14344.6
Epoch                              95
-----------------------------  ---------------
2023-08-31 15:56:14.354363 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size             486000
trainer/QF1 Loss                    0.710325
trainer/QF2 Loss                    0.94356
trainer/Policy Loss               -56.8317
trainer/Q1 Predictions Mean        63.4155
trainer/Q1 Predictions Std         24.6779
trainer/Q1 Predictions Max        103.623
trainer/Q1 Predictions Min         13.9739
trainer/Q2 Predictions Mean        63.6122
trainer/Q2 Predictions Std         24.786
trainer/Q2 Predictions Max        103.722
trainer/Q2 Predictions Min         15.785
trainer/Q Targets Mean             63.3765
trainer/Q Targets Std              24.6246
trainer/Q Targets Max             103.384
trainer/Q Targets Min              15.1107
trainer/Log Pis Mean                7.0969
trainer/Log Pis Std                 4.4015
trainer/Log Pis Max                23.3143
trainer/Log Pis Min                -3.02947
trainer/Policy mu Mean              0.127877
trainer/Policy mu Std               1.61197
trainer/Policy mu Max               4.10969
trainer/Policy mu Min              -6.27962
trainer/Policy log std Mean        -0.690455
trainer/Policy log std Std          0.250516
trainer/Policy log std Max         -0.0404565
trainer/Policy log std Min         -1.6376
trainer/Alpha                       0.0114609
trainer/Alpha Loss                  0.433035
exploration/num steps total    486000
exploration/num paths total       972
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.9689
exploration/Rewards Std             0.152477
exploration/Rewards Max             1
exploration/Rewards Min             0.00232083
exploration/Returns Mean          484.45
exploration/Returns Std             0.665775
exploration/Returns Max           485.605
exploration/Returns Min           483.129
exploration/Actions Mean            0.188912
exploration/Actions Std             0.691452
exploration/Actions Max             0.999994
exploration/Actions Min            -0.999889
exploration/Num Paths              10
exploration/Average Returns       484.45
evaluation/num steps total     485000
evaluation/num paths total        970
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.917066
evaluation/Rewards Std              0.262228
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00258563
evaluation/Returns Mean           458.533
evaluation/Returns Std             77.1054
evaluation/Returns Max            484.806
evaluation/Returns Min            227.225
evaluation/ExplReturns Mean       458.533
evaluation/ExplReturns Std         77.1054
evaluation/ExplReturns Max        484.806
evaluation/ExplReturns Min        227.225
evaluation/Actions Mean             0.071717
evaluation/Actions Std              0.690182
evaluation/Actions Max              0.999976
evaluation/Actions Min             -0.999831
evaluation/Num Paths               10
evaluation/Average Returns        458.533
time/data storing (s)               0.0299213
time/evaluation sampling (s)       65.1212
time/exploration sampling (s)      70.714
time/logging (s)                    0.0255643
time/saving (s)                     0.0919994
time/training (s)                  14.1708
time/epoch (s)                    150.153
time/total (s)                  14494.7
Epoch                              96
-----------------------------  ---------------
2023-08-31 15:58:46.149149 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size             491000
trainer/QF1 Loss                    1.06715
trainer/QF2 Loss                    0.869882
trainer/Policy Loss               -57.6112
trainer/Q1 Predictions Mean        63.8585
trainer/Q1 Predictions Std         23.1637
trainer/Q1 Predictions Max        101.445
trainer/Q1 Predictions Min         15.9185
trainer/Q2 Predictions Mean        63.9432
trainer/Q2 Predictions Std         23.1428
trainer/Q2 Predictions Max        101.681
trainer/Q2 Predictions Min         15.7423
trainer/Q Targets Mean             64.0959
trainer/Q Targets Std              23.1681
trainer/Q Targets Max             101.984
trainer/Q Targets Min              16.0188
trainer/Log Pis Mean                6.72144
trainer/Log Pis Std                 4.58305
trainer/Log Pis Max                21.1806
trainer/Log Pis Min                -4.0659
trainer/Policy mu Mean             -0.0505128
trainer/Policy mu Std               1.55374
trainer/Policy mu Max               4.5933
trainer/Policy mu Min              -5.30745
trainer/Policy log std Mean        -0.696368
trainer/Policy log std Std          0.25572
trainer/Policy log std Max         -0.11355
trainer/Policy log std Min         -1.74496
trainer/Alpha                       0.0114582
trainer/Alpha Loss                 -1.24481
exploration/num steps total    491000
exploration/num paths total       982
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.964351
exploration/Rewards Std             0.162607
exploration/Rewards Max             1
exploration/Rewards Min             0.00172364
exploration/Returns Mean          482.176
exploration/Returns Std             2.74752
exploration/Returns Max           485.102
exploration/Returns Min           476.295
exploration/Actions Mean           -0.00656916
exploration/Actions Std             0.704821
exploration/Actions Max             0.999899
exploration/Actions Min            -0.999565
exploration/Num Paths              10
exploration/Average Returns       482.176
evaluation/num steps total     490000
evaluation/num paths total        980
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.966774
evaluation/Rewards Std              0.157047
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00342163
evaluation/Returns Mean           483.387
evaluation/Returns Std              0.835472
evaluation/Returns Max            484.454
evaluation/Returns Min            481.984
evaluation/ExplReturns Mean       483.387
evaluation/ExplReturns Std          0.835472
evaluation/ExplReturns Max        484.454
evaluation/ExplReturns Min        481.984
evaluation/Actions Mean            -0.0951447
evaluation/Actions Std              0.605959
evaluation/Actions Max              0.999662
evaluation/Actions Min             -0.999417
evaluation/Num Paths               10
evaluation/Average Returns        483.387
time/data storing (s)               0.0297883
time/evaluation sampling (s)       66.5117
time/exploration sampling (s)      74.091
time/logging (s)                    0.0254083
time/saving (s)                     0.0665784
time/training (s)                  11.066
time/epoch (s)                    151.791
time/total (s)                  14646.5
Epoch                              97
-----------------------------  ---------------
2023-08-31 16:01:17.959409 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size             496000
trainer/QF1 Loss                    0.614738
trainer/QF2 Loss                    0.691766
trainer/Policy Loss               -59.0831
trainer/Q1 Predictions Mean        65.5251
trainer/Q1 Predictions Std         25.1395
trainer/Q1 Predictions Max        101.526
trainer/Q1 Predictions Min          0.539884
trainer/Q2 Predictions Mean        65.3838
trainer/Q2 Predictions Std         25.0071
trainer/Q2 Predictions Max        101.483
trainer/Q2 Predictions Min         -0.0569456
trainer/Q Targets Mean             65.424
trainer/Q Targets Std              25.1712
trainer/Q Targets Max             101.61
trainer/Q Targets Min              -0.184932
trainer/Log Pis Mean                6.73914
trainer/Log Pis Std                 4.7552
trainer/Log Pis Max                25.8345
trainer/Log Pis Min                -4.32873
trainer/Policy mu Mean              0.153412
trainer/Policy mu Std               1.55651
trainer/Policy mu Max               4.34911
trainer/Policy mu Min              -4.37784
trainer/Policy log std Mean        -0.683714
trainer/Policy log std Std          0.242664
trainer/Policy log std Max          0.147973
trainer/Policy log std Min         -1.5943
trainer/Alpha                       0.0113019
trainer/Alpha Loss                 -1.16931
exploration/num steps total    496000
exploration/num paths total       992
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967166
exploration/Rewards Std             0.156963
exploration/Rewards Max             1
exploration/Rewards Min             0.00210148
exploration/Returns Mean          483.583
exploration/Returns Std             0.809572
exploration/Returns Max           484.875
exploration/Returns Min           482.366
exploration/Actions Mean            0.149989
exploration/Actions Std             0.695741
exploration/Actions Max             0.99997
exploration/Actions Min            -0.999929
exploration/Num Paths              10
exploration/Average Returns       483.583
evaluation/num steps total     495000
evaluation/num paths total        990
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.948042
evaluation/Rewards Std              0.205364
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00132032
evaluation/Returns Mean           474.021
evaluation/Returns Std             29.8741
evaluation/Returns Max            485.109
evaluation/Returns Min            384.42
evaluation/ExplReturns Mean       474.021
evaluation/ExplReturns Std         29.8741
evaluation/ExplReturns Max        485.109
evaluation/ExplReturns Min        384.42
evaluation/Actions Mean             0.113723
evaluation/Actions Std              0.62895
evaluation/Actions Max              0.99988
evaluation/Actions Min             -0.999821
evaluation/Num Paths               10
evaluation/Average Returns        474.021
time/data storing (s)               0.0304319
time/evaluation sampling (s)       67.4418
time/exploration sampling (s)      72.7786
time/logging (s)                    0.0254742
time/saving (s)                     0.0612621
time/training (s)                  11.4687
time/epoch (s)                    151.806
time/total (s)                  14798.3
Epoch                              98
-----------------------------  ---------------
2023-08-31 16:03:42.686599 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size             501000
trainer/QF1 Loss                    0.821273
trainer/QF2 Loss                    0.802538
trainer/Policy Loss               -57.3233
trainer/Q1 Predictions Mean        63.8779
trainer/Q1 Predictions Std         23.9926
trainer/Q1 Predictions Max        102.706
trainer/Q1 Predictions Min         12.1077
trainer/Q2 Predictions Mean        63.8334
trainer/Q2 Predictions Std         23.8711
trainer/Q2 Predictions Max        102.261
trainer/Q2 Predictions Min         13.2913
trainer/Q Targets Mean             63.9087
trainer/Q Targets Std              23.8869
trainer/Q Targets Max             102.356
trainer/Q Targets Min              13.9597
trainer/Log Pis Mean                6.86978
trainer/Log Pis Std                 4.89019
trainer/Log Pis Max                25.7136
trainer/Log Pis Min                -7.59825
trainer/Policy mu Mean              0.0723289
trainer/Policy mu Std               1.58518
trainer/Policy mu Max               4.42365
trainer/Policy mu Min              -4.98908
trainer/Policy log std Mean        -0.706056
trainer/Policy log std Std          0.242968
trainer/Policy log std Max         -0.0534003
trainer/Policy log std Min         -1.56417
trainer/Alpha                       0.0112576
trainer/Alpha Loss                 -0.584237
exploration/num steps total    501000
exploration/num paths total      1002
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967832
exploration/Rewards Std             0.15346
exploration/Rewards Max             1
exploration/Rewards Min             0.0026897
exploration/Returns Mean          483.916
exploration/Returns Std             0.852734
exploration/Returns Max           485.015
exploration/Returns Min           482.458
exploration/Actions Mean            0.135908
exploration/Actions Std             0.697877
exploration/Actions Max             0.999981
exploration/Actions Min            -0.999989
exploration/Num Paths              10
exploration/Average Returns       483.916
evaluation/num steps total     500000
evaluation/num paths total       1000
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.959896
evaluation/Rewards Std              0.176222
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00313595
evaluation/Returns Mean           479.948
evaluation/Returns Std             13.3242
evaluation/Returns Max            485.565
evaluation/Returns Min            440.004
evaluation/ExplReturns Mean       479.948
evaluation/ExplReturns Std         13.3242
evaluation/ExplReturns Max        485.565
evaluation/ExplReturns Min        440.004
evaluation/Actions Mean             0.153995
evaluation/Actions Std              0.670624
evaluation/Actions Max              0.999986
evaluation/Actions Min             -0.999944
evaluation/Num Paths               10
evaluation/Average Returns        479.948
time/data storing (s)               0.0300158
time/evaluation sampling (s)       64.0104
time/exploration sampling (s)      69.9989
time/logging (s)                    0.0256199
time/saving (s)                     0.0620707
time/training (s)                  10.5962
time/epoch (s)                    144.723
time/total (s)                  14943.1
Epoch                              99
-----------------------------  ---------------
2023-08-31 16:06:11.034057 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size             506000
trainer/QF1 Loss                    0.836811
trainer/QF2 Loss                    0.754774
trainer/Policy Loss               -59.1734
trainer/Q1 Predictions Mean        66.3378
trainer/Q1 Predictions Std         23.8734
trainer/Q1 Predictions Max        104.217
trainer/Q1 Predictions Min         17.731
trainer/Q2 Predictions Mean        66.3784
trainer/Q2 Predictions Std         23.9674
trainer/Q2 Predictions Max        103.517
trainer/Q2 Predictions Min         18.1377
trainer/Q Targets Mean             66.4059
trainer/Q Targets Std              23.9941
trainer/Q Targets Max             103.866
trainer/Q Targets Min              18.0006
trainer/Log Pis Mean                7.58116
trainer/Log Pis Std                 5.1155
trainer/Log Pis Max                21.9899
trainer/Log Pis Min                -5.01699
trainer/Policy mu Mean              0.133593
trainer/Policy mu Std               1.61986
trainer/Policy mu Max               5.7506
trainer/Policy mu Min              -4.40537
trainer/Policy log std Mean        -0.694526
trainer/Policy log std Std          0.255921
trainer/Policy log std Max          0.00809848
trainer/Policy log std Min         -1.84246
trainer/Alpha                       0.0113153
trainer/Alpha Loss                  2.6045
exploration/num steps total    506000
exploration/num paths total      1012
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.948563
exploration/Rewards Std             0.200236
exploration/Rewards Max             1
exploration/Rewards Min             0.00237013
exploration/Returns Mean          474.282
exploration/Returns Std            22.7055
exploration/Returns Max           484.469
exploration/Returns Min           406.602
exploration/Actions Mean            0.235892
exploration/Actions Std             0.685259
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999973
exploration/Num Paths              10
exploration/Average Returns       474.282
evaluation/num steps total     505000
evaluation/num paths total       1010
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.968419
evaluation/Rewards Std              0.153379
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00342209
evaluation/Returns Mean           484.209
evaluation/Returns Std              0.802097
evaluation/Returns Max            485.143
evaluation/Returns Min            482.353
evaluation/ExplReturns Mean       484.209
evaluation/ExplReturns Std          0.802097
evaluation/ExplReturns Max        485.143
evaluation/ExplReturns Min        482.353
evaluation/Actions Mean             0.163078
evaluation/Actions Std              0.685774
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.999074
evaluation/Num Paths               10
evaluation/Average Returns        484.209
time/data storing (s)               0.030066
time/evaluation sampling (s)       66.9808
time/exploration sampling (s)      70.7265
time/logging (s)                    0.0255347
time/saving (s)                     0.0694031
time/training (s)                  10.5108
time/epoch (s)                    148.343
time/total (s)                  15091.4
Epoch                             100
-----------------------------  ---------------
2023-08-31 16:08:35.980188 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size             511000
trainer/QF1 Loss                    0.891651
trainer/QF2 Loss                    0.855787
trainer/Policy Loss               -59.7435
trainer/Q1 Predictions Mean        66.6935
trainer/Q1 Predictions Std         23.6714
trainer/Q1 Predictions Max        107.078
trainer/Q1 Predictions Min          0.795834
trainer/Q2 Predictions Mean        66.7375
trainer/Q2 Predictions Std         23.7007
trainer/Q2 Predictions Max        107.638
trainer/Q2 Predictions Min          1.12282
trainer/Q Targets Mean             66.6521
trainer/Q Targets Std              23.6099
trainer/Q Targets Max             106.379
trainer/Q Targets Min               1.43886
trainer/Log Pis Mean                7.36989
trainer/Log Pis Std                 4.75533
trainer/Log Pis Max                22.9047
trainer/Log Pis Min                -4.71828
trainer/Policy mu Mean             -0.0294576
trainer/Policy mu Std               1.58432
trainer/Policy mu Max               3.83877
trainer/Policy mu Min              -3.88142
trainer/Policy log std Mean        -0.753255
trainer/Policy log std Std          0.267384
trainer/Policy log std Max         -0.0303219
trainer/Policy log std Min         -1.77745
trainer/Alpha                       0.0110046
trainer/Alpha Loss                  1.66805
exploration/num steps total    511000
exploration/num paths total      1022
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.937911
exploration/Rewards Std             0.221091
exploration/Rewards Max             1
exploration/Rewards Min             0.00275071
exploration/Returns Mean          468.956
exploration/Returns Std            41.2848
exploration/Returns Max           484.709
exploration/Returns Min           345.167
exploration/Actions Mean            0.127995
exploration/Actions Std             0.684406
exploration/Actions Max             1
exploration/Actions Min            -0.999946
exploration/Num Paths              10
exploration/Average Returns       468.956
evaluation/num steps total     510000
evaluation/num paths total       1020
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.965201
evaluation/Rewards Std              0.158696
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00279957
evaluation/Returns Mean           482.6
evaluation/Returns Std              1.87332
evaluation/Returns Max            483.9
evaluation/Returns Min            477.313
evaluation/ExplReturns Mean       482.6
evaluation/ExplReturns Std          1.87332
evaluation/ExplReturns Max        483.9
evaluation/ExplReturns Min        477.313
evaluation/Actions Mean            -0.113369
evaluation/Actions Std              0.638102
evaluation/Actions Max              0.999753
evaluation/Actions Min             -0.999458
evaluation/Num Paths               10
evaluation/Average Returns        482.6
time/data storing (s)               0.0294649
time/evaluation sampling (s)       64.7785
time/exploration sampling (s)      69.2486
time/logging (s)                    0.0253645
time/saving (s)                     0.0602592
time/training (s)                  10.7997
time/epoch (s)                    144.942
time/total (s)                  15236.4
Epoch                             101
-----------------------------  ---------------
2023-08-31 16:11:04.958598 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size             516000
trainer/QF1 Loss                    0.688742
trainer/QF2 Loss                    0.590632
trainer/Policy Loss               -61.2213
trainer/Q1 Predictions Mean        67.756
trainer/Q1 Predictions Std         24.9886
trainer/Q1 Predictions Max        104.227
trainer/Q1 Predictions Min         17.6703
trainer/Q2 Predictions Mean        67.8697
trainer/Q2 Predictions Std         25.0223
trainer/Q2 Predictions Max        103.699
trainer/Q2 Predictions Min         17.1229
trainer/Q Targets Mean             67.6961
trainer/Q Targets Std              24.9299
trainer/Q Targets Max             103.577
trainer/Q Targets Min              17.5538
trainer/Log Pis Mean                6.93544
trainer/Log Pis Std                 5.0252
trainer/Log Pis Max                23.0573
trainer/Log Pis Min                -6.18887
trainer/Policy mu Mean              0.0662181
trainer/Policy mu Std               1.61543
trainer/Policy mu Max               4.76309
trainer/Policy mu Min              -4.29201
trainer/Policy log std Mean        -0.70871
trainer/Policy log std Std          0.256704
trainer/Policy log std Max          0.0644858
trainer/Policy log std Min         -1.81234
trainer/Alpha                       0.010738
trainer/Alpha Loss                 -0.292731
exploration/num steps total    516000
exploration/num paths total      1032
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.966439
exploration/Rewards Std             0.158161
exploration/Rewards Max             1
exploration/Rewards Min             0.00220938
exploration/Returns Mean          483.22
exploration/Returns Std             1.13953
exploration/Returns Max           484.804
exploration/Returns Min           481.453
exploration/Actions Mean            0.134878
exploration/Actions Std             0.694971
exploration/Actions Max             0.999984
exploration/Actions Min            -0.999742
exploration/Num Paths              10
exploration/Average Returns       483.22
evaluation/num steps total     515000
evaluation/num paths total       1030
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.934534
evaluation/Rewards Std              0.229987
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0030663
evaluation/Returns Mean           467.267
evaluation/Returns Std             46.5418
evaluation/Returns Max            483.861
evaluation/Returns Min            327.649
evaluation/ExplReturns Mean       467.267
evaluation/ExplReturns Std         46.5418
evaluation/ExplReturns Max        483.861
evaluation/ExplReturns Min        327.649
evaluation/Actions Mean             0.0232688
evaluation/Actions Std              0.722257
evaluation/Actions Max              0.999899
evaluation/Actions Min             -0.998411
evaluation/Num Paths               10
evaluation/Average Returns        467.267
time/data storing (s)               0.0298714
time/evaluation sampling (s)       67.4383
time/exploration sampling (s)      70.8454
time/logging (s)                    0.0254921
time/saving (s)                     0.0629263
time/training (s)                  10.5725
time/epoch (s)                    148.974
time/total (s)                  15385.3
Epoch                             102
-----------------------------  ---------------
2023-08-31 16:13:26.606580 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size             521000
trainer/QF1 Loss                    0.833737
trainer/QF2 Loss                    0.865803
trainer/Policy Loss               -63.3507
trainer/Q1 Predictions Mean        69.5082
trainer/Q1 Predictions Std         23.7837
trainer/Q1 Predictions Max        100.694
trainer/Q1 Predictions Min         10.871
trainer/Q2 Predictions Mean        69.4415
trainer/Q2 Predictions Std         23.8249
trainer/Q2 Predictions Max        100.392
trainer/Q2 Predictions Min         10.1728
trainer/Q Targets Mean             69.7471
trainer/Q Targets Std              23.9746
trainer/Q Targets Max             100.933
trainer/Q Targets Min              10.8493
trainer/Log Pis Mean                6.49193
trainer/Log Pis Std                 4.71109
trainer/Log Pis Max                19.7614
trainer/Log Pis Min                -7.06801
trainer/Policy mu Mean              0.0776836
trainer/Policy mu Std               1.56952
trainer/Policy mu Max               4.28339
trainer/Policy mu Min              -4.29924
trainer/Policy log std Mean        -0.69293
trainer/Policy log std Std          0.236125
trainer/Policy log std Max         -0.0274888
trainer/Policy log std Min         -1.57849
trainer/Alpha                       0.010594
trainer/Alpha Loss                 -2.31037
exploration/num steps total    521000
exploration/num paths total      1042
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.95088
exploration/Rewards Std             0.183125
exploration/Rewards Max             1
exploration/Rewards Min             0.00294961
exploration/Returns Mean          475.44
exploration/Returns Std            12.1946
exploration/Returns Max           484.454
exploration/Returns Min           447.798
exploration/Actions Mean            0.143083
exploration/Actions Std             0.6505
exploration/Actions Max             0.999984
exploration/Actions Min            -0.999953
exploration/Num Paths              10
exploration/Average Returns       475.44
evaluation/num steps total     520000
evaluation/num paths total       1040
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.963692
evaluation/Rewards Std              0.161261
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00151074
evaluation/Returns Mean           481.846
evaluation/Returns Std              4.79491
evaluation/Returns Max            484.164
evaluation/Returns Min            467.571
evaluation/ExplReturns Mean       481.846
evaluation/ExplReturns Std          4.79491
evaluation/ExplReturns Max        484.164
evaluation/ExplReturns Min        467.571
evaluation/Actions Mean             0.229623
evaluation/Actions Std              0.580309
evaluation/Actions Max              0.999868
evaluation/Actions Min             -0.998924
evaluation/Num Paths               10
evaluation/Average Returns        481.846
time/data storing (s)               0.0302221
time/evaluation sampling (s)       62.4768
time/exploration sampling (s)      68.2948
time/logging (s)                    0.0255518
time/saving (s)                     0.0640833
time/training (s)                  10.7525
time/epoch (s)                    141.644
time/total (s)                  15527
Epoch                             103
-----------------------------  ---------------
2023-08-31 16:15:56.271752 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size             526000
trainer/QF1 Loss                    0.77298
trainer/QF2 Loss                    0.783848
trainer/Policy Loss               -60.7909
trainer/Q1 Predictions Mean        67.3553
trainer/Q1 Predictions Std         24.5649
trainer/Q1 Predictions Max        108.347
trainer/Q1 Predictions Min         15.1261
trainer/Q2 Predictions Mean        67.4717
trainer/Q2 Predictions Std         24.4995
trainer/Q2 Predictions Max        107.388
trainer/Q2 Predictions Min         14.129
trainer/Q Targets Mean             67.3099
trainer/Q Targets Std              24.4305
trainer/Q Targets Max             108.124
trainer/Q Targets Min              14.5396
trainer/Log Pis Mean                6.98676
trainer/Log Pis Std                 5.06765
trainer/Log Pis Max                23.2439
trainer/Log Pis Min                -6.4996
trainer/Policy mu Mean              0.0778662
trainer/Policy mu Std               1.5908
trainer/Policy mu Max               4.67021
trainer/Policy mu Min              -5.0188
trainer/Policy log std Mean        -0.690161
trainer/Policy log std Std          0.230436
trainer/Policy log std Max         -0.11879
trainer/Policy log std Min         -1.59327
trainer/Alpha                       0.0103268
trainer/Alpha Loss                 -0.0605666
exploration/num steps total    526000
exploration/num paths total      1052
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.883586
exploration/Rewards Std             0.307732
exploration/Rewards Max             1
exploration/Rewards Min             0.00226782
exploration/Returns Mean          441.793
exploration/Returns Std           100.098
exploration/Returns Max           485.526
exploration/Returns Min           151.768
exploration/Actions Mean            0.0861964
exploration/Actions Std             0.740958
exploration/Actions Max             0.999908
exploration/Actions Min            -0.999984
exploration/Num Paths              10
exploration/Average Returns       441.793
evaluation/num steps total     525000
evaluation/num paths total       1050
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.873708
evaluation/Rewards Std              0.319802
evaluation/Rewards Max              1
evaluation/Rewards Min              0.0024876
evaluation/Returns Mean           436.854
evaluation/Returns Std            139.889
evaluation/Returns Max            484.483
evaluation/Returns Min             17.2043
evaluation/ExplReturns Mean       436.854
evaluation/ExplReturns Std        139.889
evaluation/ExplReturns Max        484.483
evaluation/ExplReturns Min         17.2043
evaluation/Actions Mean             0.110937
evaluation/Actions Std              0.70078
evaluation/Actions Max              0.99941
evaluation/Actions Min             -0.999037
evaluation/Num Paths               10
evaluation/Average Returns        436.854
time/data storing (s)               0.0295013
time/evaluation sampling (s)       67.1588
time/exploration sampling (s)      73.7653
time/logging (s)                    0.0255567
time/saving (s)                     0.0716024
time/training (s)                   8.6103
time/epoch (s)                    149.661
time/total (s)                  15676.6
Epoch                             104
-----------------------------  ---------------
2023-08-31 16:18:30.684051 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size             531000
trainer/QF1 Loss                    0.990648
trainer/QF2 Loss                    1.15064
trainer/Policy Loss               -59.8844
trainer/Q1 Predictions Mean        66.7992
trainer/Q1 Predictions Std         24.5292
trainer/Q1 Predictions Max        109.018
trainer/Q1 Predictions Min         13.2056
trainer/Q2 Predictions Mean        66.784
trainer/Q2 Predictions Std         24.4196
trainer/Q2 Predictions Max        107.187
trainer/Q2 Predictions Min         12.6626
trainer/Q Targets Mean             66.6096
trainer/Q Targets Std              24.3747
trainer/Q Targets Max             107.894
trainer/Q Targets Min              12.8691
trainer/Log Pis Mean                7.27316
trainer/Log Pis Std                 5.12021
trainer/Log Pis Max                27.5275
trainer/Log Pis Min                -9.12814
trainer/Policy mu Mean              0.157185
trainer/Policy mu Std               1.61843
trainer/Policy mu Max               5.03354
trainer/Policy mu Min              -4.58302
trainer/Policy log std Mean        -0.680398
trainer/Policy log std Std          0.248811
trainer/Policy log std Max          0.00273955
trainer/Policy log std Min         -1.68844
trainer/Alpha                       0.0103391
trainer/Alpha Loss                  1.24888
exploration/num steps total    531000
exploration/num paths total      1062
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.966771
exploration/Rewards Std             0.156292
exploration/Rewards Max             1
exploration/Rewards Min             0.002181
exploration/Returns Mean          483.386
exploration/Returns Std             0.951877
exploration/Returns Max           485.121
exploration/Returns Min           481.951
exploration/Actions Mean            0.113458
exploration/Actions Std             0.739616
exploration/Actions Max             0.999987
exploration/Actions Min            -0.999933
exploration/Num Paths              10
exploration/Average Returns       483.386
evaluation/num steps total     530000
evaluation/num paths total       1060
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.967142
evaluation/Rewards Std              0.155606
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00326437
evaluation/Returns Mean           483.571
evaluation/Returns Std              1.59009
evaluation/Returns Max            484.971
evaluation/Returns Min            479.854
evaluation/ExplReturns Mean       483.571
evaluation/ExplReturns Std          1.59009
evaluation/ExplReturns Max        484.971
evaluation/ExplReturns Min        479.854
evaluation/Actions Mean             0.0711658
evaluation/Actions Std              0.685414
evaluation/Actions Max              0.999847
evaluation/Actions Min             -0.999193
evaluation/Num Paths               10
evaluation/Average Returns        483.571
time/data storing (s)               0.0296494
time/evaluation sampling (s)       65.9156
time/exploration sampling (s)      75.6519
time/logging (s)                    0.0254573
time/saving (s)                     0.082308
time/training (s)                  12.7032
time/epoch (s)                    154.408
time/total (s)                  15831.1
Epoch                             105
-----------------------------  ---------------
2023-08-31 16:21:04.023856 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size             536000
trainer/QF1 Loss                    1.00109
trainer/QF2 Loss                    0.878058
trainer/Policy Loss               -58.4042
trainer/Q1 Predictions Mean        65.2882
trainer/Q1 Predictions Std         22.5064
trainer/Q1 Predictions Max        101.939
trainer/Q1 Predictions Min         11.4871
trainer/Q2 Predictions Mean        65.2216
trainer/Q2 Predictions Std         22.4808
trainer/Q2 Predictions Max        101.658
trainer/Q2 Predictions Min         10.9262
trainer/Q Targets Mean             65.0219
trainer/Q Targets Std              22.3866
trainer/Q Targets Max             102.757
trainer/Q Targets Min              11.715
trainer/Log Pis Mean                7.21188
trainer/Log Pis Std                 5.09681
trainer/Log Pis Max                31.401
trainer/Log Pis Min                -4.83132
trainer/Policy mu Mean              0.124625
trainer/Policy mu Std               1.62343
trainer/Policy mu Max               5.74463
trainer/Policy mu Min              -4.57818
trainer/Policy log std Mean        -0.709534
trainer/Policy log std Std          0.248727
trainer/Policy log std Max         -0.0582565
trainer/Policy log std Min         -1.68242
trainer/Alpha                       0.0106231
trainer/Alpha Loss                  0.96296
exploration/num steps total    536000
exploration/num paths total      1072
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967603
exploration/Rewards Std             0.157158
exploration/Rewards Max             1
exploration/Rewards Min             0.00223306
exploration/Returns Mean          483.802
exploration/Returns Std             0.945562
exploration/Returns Max           484.705
exploration/Returns Min           481.722
exploration/Actions Mean           -0.00606255
exploration/Actions Std             0.743403
exploration/Actions Max             0.999972
exploration/Actions Min            -0.99992
exploration/Num Paths              10
exploration/Average Returns       483.802
evaluation/num steps total     535000
evaluation/num paths total       1070
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.968241
evaluation/Rewards Std              0.155589
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00236884
evaluation/Returns Mean           484.121
evaluation/Returns Std              0.859107
evaluation/Returns Max            485.629
evaluation/Returns Min            482.855
evaluation/ExplReturns Mean       484.121
evaluation/ExplReturns Std          0.859107
evaluation/ExplReturns Max        485.629
evaluation/ExplReturns Min        482.855
evaluation/Actions Mean             0.0702248
evaluation/Actions Std              0.731106
evaluation/Actions Max              0.99955
evaluation/Actions Min             -0.999497
evaluation/Num Paths               10
evaluation/Average Returns        484.121
time/data storing (s)               0.0298103
time/evaluation sampling (s)       68.5351
time/exploration sampling (s)      74.6696
time/logging (s)                    0.0254177
time/saving (s)                     0.0634484
time/training (s)                  10.0122
time/epoch (s)                    153.336
time/total (s)                  15984.4
Epoch                             106
-----------------------------  ---------------
2023-08-31 16:23:32.279970 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size             541000
trainer/QF1 Loss                    1.0978
trainer/QF2 Loss                    1.09498
trainer/Policy Loss               -63.6545
trainer/Q1 Predictions Mean        70.036
trainer/Q1 Predictions Std         23.598
trainer/Q1 Predictions Max        104.959
trainer/Q1 Predictions Min         21.7794
trainer/Q2 Predictions Mean        70.1831
trainer/Q2 Predictions Std         23.6309
trainer/Q2 Predictions Max        104.906
trainer/Q2 Predictions Min         21.8901
trainer/Q Targets Mean             69.8595
trainer/Q Targets Std              23.6674
trainer/Q Targets Max             104.998
trainer/Q Targets Min              21.6762
trainer/Log Pis Mean                6.80486
trainer/Log Pis Std                 4.85597
trainer/Log Pis Max                24.1464
trainer/Log Pis Min                -3.38165
trainer/Policy mu Mean              0.144408
trainer/Policy mu Std               1.57021
trainer/Policy mu Max               4.21125
trainer/Policy mu Min              -4.93042
trainer/Policy log std Mean        -0.718451
trainer/Policy log std Std          0.255401
trainer/Policy log std Max          0.102058
trainer/Policy log std Min         -1.80648
trainer/Alpha                       0.0106126
trainer/Alpha Loss                 -0.887067
exploration/num steps total    541000
exploration/num paths total      1082
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.968096
exploration/Rewards Std             0.152853
exploration/Rewards Max             1
exploration/Rewards Min             0.00293129
exploration/Returns Mean          484.048
exploration/Returns Std             0.820836
exploration/Returns Max           485.291
exploration/Returns Min           482.78
exploration/Actions Mean            0.0992286
exploration/Actions Std             0.661427
exploration/Actions Max             0.999868
exploration/Actions Min            -0.999918
exploration/Num Paths              10
exploration/Average Returns       484.048
evaluation/num steps total     540000
evaluation/num paths total       1080
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.96707
evaluation/Rewards Std              0.154998
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00297898
evaluation/Returns Mean           483.535
evaluation/Returns Std              0.691715
evaluation/Returns Max            484.061
evaluation/Returns Min            481.767
evaluation/ExplReturns Mean       483.535
evaluation/ExplReturns Std          0.691715
evaluation/ExplReturns Max        484.061
evaluation/ExplReturns Min        481.767
evaluation/Actions Mean             0.0522442
evaluation/Actions Std              0.687483
evaluation/Actions Max              0.999623
evaluation/Actions Min             -0.999879
evaluation/Num Paths               10
evaluation/Average Returns        483.535
time/data storing (s)               0.030173
time/evaluation sampling (s)       67.6027
time/exploration sampling (s)      71.2694
time/logging (s)                    0.0255947
time/saving (s)                     0.0624819
time/training (s)                   9.26175
time/epoch (s)                    148.252
time/total (s)                  16132.7
Epoch                             107
-----------------------------  ---------------
2023-08-31 16:26:00.587755 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size             546000
trainer/QF1 Loss                    1.21048
trainer/QF2 Loss                    0.956511
trainer/Policy Loss               -61.5388
trainer/Q1 Predictions Mean        67.7976
trainer/Q1 Predictions Std         23.5363
trainer/Q1 Predictions Max        103.826
trainer/Q1 Predictions Min         20.6359
trainer/Q2 Predictions Mean        67.7792
trainer/Q2 Predictions Std         23.6027
trainer/Q2 Predictions Max        103.77
trainer/Q2 Predictions Min         21.1004
trainer/Q Targets Mean             67.5593
trainer/Q Targets Std              23.365
trainer/Q Targets Max             103.776
trainer/Q Targets Min              21.8648
trainer/Log Pis Mean                6.58953
trainer/Log Pis Std                 4.70295
trainer/Log Pis Max                25.5246
trainer/Log Pis Min                -5.01173
trainer/Policy mu Mean              0.0504044
trainer/Policy mu Std               1.56933
trainer/Policy mu Max               4.29984
trainer/Policy mu Min              -5.68814
trainer/Policy log std Mean        -0.707314
trainer/Policy log std Std          0.262702
trainer/Policy log std Max          0.113819
trainer/Policy log std Min         -1.75845
trainer/Alpha                       0.010892
trainer/Alpha Loss                 -1.85516
exploration/num steps total    546000
exploration/num paths total      1092
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967661
exploration/Rewards Std             0.158317
exploration/Rewards Max             1
exploration/Rewards Min             0.00200189
exploration/Returns Mean          483.831
exploration/Returns Std             0.724793
exploration/Returns Max           484.817
exploration/Returns Min           482.354
exploration/Actions Mean            0.243405
exploration/Actions Std             0.641974
exploration/Actions Max             0.999992
exploration/Actions Min            -0.999904
exploration/Num Paths              10
exploration/Average Returns       483.831
evaluation/num steps total     545000
evaluation/num paths total       1090
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.967857
evaluation/Rewards Std              0.158421
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00322159
evaluation/Returns Mean           483.929
evaluation/Returns Std              0.44799
evaluation/Returns Max            484.594
evaluation/Returns Min            483.24
evaluation/ExplReturns Mean       483.929
evaluation/ExplReturns Std          0.44799
evaluation/ExplReturns Max        484.594
evaluation/ExplReturns Min        483.24
evaluation/Actions Mean             0.279029
evaluation/Actions Std              0.619296
evaluation/Actions Max              0.999766
evaluation/Actions Min             -0.998578
evaluation/Num Paths               10
evaluation/Average Returns        483.929
time/data storing (s)               0.0300927
time/evaluation sampling (s)       65.9949
time/exploration sampling (s)      71.8086
time/logging (s)                    0.0256164
time/saving (s)                     0.0701564
time/training (s)                  10.3743
time/epoch (s)                    148.304
time/total (s)                  16281
Epoch                             108
-----------------------------  ---------------
2023-08-31 16:28:33.876149 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size             551000
trainer/QF1 Loss                    1.01488
trainer/QF2 Loss                    0.827355
trainer/Policy Loss               -63.3515
trainer/Q1 Predictions Mean        70.0827
trainer/Q1 Predictions Std         23.6914
trainer/Q1 Predictions Max        101.635
trainer/Q1 Predictions Min         17.0915
trainer/Q2 Predictions Mean        70.0902
trainer/Q2 Predictions Std         23.7192
trainer/Q2 Predictions Max        101.47
trainer/Q2 Predictions Min         16.5479
trainer/Q Targets Mean             70.14
trainer/Q Targets Std              23.7991
trainer/Q Targets Max             101.85
trainer/Q Targets Min              15.9264
trainer/Log Pis Mean                7.00753
trainer/Log Pis Std                 4.78386
trainer/Log Pis Max                21.2551
trainer/Log Pis Min                -4.42751
trainer/Policy mu Mean              0.169722
trainer/Policy mu Std               1.57433
trainer/Policy mu Max               5.49393
trainer/Policy mu Min              -5.98678
trainer/Policy log std Mean        -0.725997
trainer/Policy log std Std          0.283346
trainer/Policy log std Max         -0.0727274
trainer/Policy log std Min         -1.87602
trainer/Alpha                       0.0104325
trainer/Alpha Loss                  0.0343405
exploration/num steps total    551000
exploration/num paths total      1102
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.966345
exploration/Rewards Std             0.159232
exploration/Rewards Max             1
exploration/Rewards Min             0.00266375
exploration/Returns Mean          483.172
exploration/Returns Std             1.30415
exploration/Returns Max           484.275
exploration/Returns Min           479.569
exploration/Actions Mean           -0.023681
exploration/Actions Std             0.731565
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999926
exploration/Num Paths              10
exploration/Average Returns       483.172
evaluation/num steps total     550000
evaluation/num paths total       1100
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.966685
evaluation/Rewards Std              0.158248
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00263929
evaluation/Returns Mean           483.342
evaluation/Returns Std              0.893565
evaluation/Returns Max            484.366
evaluation/Returns Min            481.271
evaluation/ExplReturns Mean       483.342
evaluation/ExplReturns Std          0.893565
evaluation/ExplReturns Max        484.366
evaluation/ExplReturns Min        481.271
evaluation/Actions Mean             0.0241698
evaluation/Actions Std              0.729468
evaluation/Actions Max              0.999676
evaluation/Actions Min             -0.997904
evaluation/Num Paths               10
evaluation/Average Returns        483.342
time/data storing (s)               0.0293665
time/evaluation sampling (s)       65.8674
time/exploration sampling (s)      72.3928
time/logging (s)                    0.0255923
time/saving (s)                     0.0755965
time/training (s)                  14.8935
time/epoch (s)                    153.284
time/total (s)                  16434.2
Epoch                             109
-----------------------------  ---------------
2023-08-31 16:31:13.381418 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size             556000
trainer/QF1 Loss                    0.651004
trainer/QF2 Loss                    0.698414
trainer/Policy Loss               -65.0783
trainer/Q1 Predictions Mean        71.1578
trainer/Q1 Predictions Std         24.8243
trainer/Q1 Predictions Max        103.832
trainer/Q1 Predictions Min         11.0704
trainer/Q2 Predictions Mean        71.1247
trainer/Q2 Predictions Std         24.8455
trainer/Q2 Predictions Max        103.491
trainer/Q2 Predictions Min         11.8614
trainer/Q Targets Mean             71.2199
trainer/Q Targets Std              24.7009
trainer/Q Targets Max             104.295
trainer/Q Targets Min              11.9656
trainer/Log Pis Mean                6.31745
trainer/Log Pis Std                 4.65754
trainer/Log Pis Max                22.2132
trainer/Log Pis Min                -6.48597
trainer/Policy mu Mean              0.0215933
trainer/Policy mu Std               1.52731
trainer/Policy mu Max               3.86839
trainer/Policy mu Min              -4.4662
trainer/Policy log std Mean        -0.698373
trainer/Policy log std Std          0.248355
trainer/Policy log std Max          0.14013
trainer/Policy log std Min         -1.81756
trainer/Alpha                       0.0100686
trainer/Alpha Loss                 -3.13837
exploration/num steps total    556000
exploration/num paths total      1112
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967465
exploration/Rewards Std             0.153957
exploration/Rewards Max             1
exploration/Rewards Min             0.0023006
exploration/Returns Mean          483.733
exploration/Returns Std             0.49969
exploration/Returns Max           484.494
exploration/Returns Min           482.668
exploration/Actions Mean            0.00195951
exploration/Actions Std             0.762203
exploration/Actions Max             0.999695
exploration/Actions Min            -0.999683
exploration/Num Paths              10
exploration/Average Returns       483.733
evaluation/num steps total     555000
evaluation/num paths total       1110
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.966645
evaluation/Rewards Std              0.155733
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00320918
evaluation/Returns Mean           483.322
evaluation/Returns Std              0.699079
evaluation/Returns Max            484.127
evaluation/Returns Min            481.634
evaluation/ExplReturns Mean       483.322
evaluation/ExplReturns Std          0.699079
evaluation/ExplReturns Max        484.127
evaluation/ExplReturns Min        481.634
evaluation/Actions Mean             0.106671
evaluation/Actions Std              0.728824
evaluation/Actions Max              0.999108
evaluation/Actions Min             -0.999717
evaluation/Num Paths               10
evaluation/Average Returns        483.322
time/data storing (s)               0.0297368
time/evaluation sampling (s)       68.0358
time/exploration sampling (s)      77.132
time/logging (s)                    0.0254616
time/saving (s)                     0.0663631
time/training (s)                  14.2116
time/epoch (s)                    159.501
time/total (s)                  16593.7
Epoch                             110
-----------------------------  ---------------
2023-08-31 16:33:41.487070 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size             561000
trainer/QF1 Loss                    1.0989
trainer/QF2 Loss                    1.10098
trainer/Policy Loss               -61.6448
trainer/Q1 Predictions Mean        67.8541
trainer/Q1 Predictions Std         23.4218
trainer/Q1 Predictions Max        106.504
trainer/Q1 Predictions Min         23.6509
trainer/Q2 Predictions Mean        67.6798
trainer/Q2 Predictions Std         23.3451
trainer/Q2 Predictions Max        104.683
trainer/Q2 Predictions Min         22.8961
trainer/Q Targets Mean             67.8565
trainer/Q Targets Std              23.46
trainer/Q Targets Max             103.606
trainer/Q Targets Min              22.8271
trainer/Log Pis Mean                6.43317
trainer/Log Pis Std                 4.63363
trainer/Log Pis Max                19.5831
trainer/Log Pis Min                -4.06463
trainer/Policy mu Mean              0.0786059
trainer/Policy mu Std               1.56345
trainer/Policy mu Max               4.75406
trainer/Policy mu Min              -4.37659
trainer/Policy log std Mean        -0.731634
trainer/Policy log std Std          0.257555
trainer/Policy log std Max         -0.111312
trainer/Policy log std Min         -1.77854
trainer/Alpha                       0.00970276
trainer/Alpha Loss                 -2.62743
exploration/num steps total    561000
exploration/num paths total      1122
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.966789
exploration/Rewards Std             0.15798
exploration/Rewards Max             1
exploration/Rewards Min             0.00344842
exploration/Returns Mean          483.394
exploration/Returns Std             0.940957
exploration/Returns Max           485.062
exploration/Returns Min           481.881
exploration/Actions Mean            0.252717
exploration/Actions Std             0.657479
exploration/Actions Max             0.999978
exploration/Actions Min            -0.99988
exploration/Num Paths              10
exploration/Average Returns       483.394
evaluation/num steps total     560000
evaluation/num paths total       1120
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.966077
evaluation/Rewards Std              0.158492
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00269461
evaluation/Returns Mean           483.038
evaluation/Returns Std              1.2068
evaluation/Returns Max            484.522
evaluation/Returns Min            480.934
evaluation/ExplReturns Mean       483.038
evaluation/ExplReturns Std          1.2068
evaluation/ExplReturns Max        484.522
evaluation/ExplReturns Min        480.934
evaluation/Actions Mean             0.255274
evaluation/Actions Std              0.612736
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.999773
evaluation/Num Paths               10
evaluation/Average Returns        483.038
time/data storing (s)               0.0295955
time/evaluation sampling (s)       64.7517
time/exploration sampling (s)      68.4583
time/logging (s)                    0.0254755
time/saving (s)                     0.0170137
time/training (s)                  14.8194
time/epoch (s)                    148.101
time/total (s)                  16741.9
Epoch                             111
-----------------------------  ---------------
2023-08-31 16:36:06.230193 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size             566000
trainer/QF1 Loss                    0.629478
trainer/QF2 Loss                    0.557195
trainer/Policy Loss               -64.3018
trainer/Q1 Predictions Mean        70.475
trainer/Q1 Predictions Std         25.1068
trainer/Q1 Predictions Max        109.455
trainer/Q1 Predictions Min         14.2574
trainer/Q2 Predictions Mean        70.5732
trainer/Q2 Predictions Std         25.1801
trainer/Q2 Predictions Max        109.702
trainer/Q2 Predictions Min         14.2244
trainer/Q Targets Mean             70.417
trainer/Q Targets Std              25.135
trainer/Q Targets Max             109.656
trainer/Q Targets Min              14.396
trainer/Log Pis Mean                6.51781
trainer/Log Pis Std                 4.82176
trainer/Log Pis Max                25.5225
trainer/Log Pis Min                -6.92028
trainer/Policy mu Mean              0.189143
trainer/Policy mu Std               1.53082
trainer/Policy mu Max               3.96508
trainer/Policy mu Min              -3.82853
trainer/Policy log std Mean        -0.70661
trainer/Policy log std Std          0.255501
trainer/Policy log std Max          0.00393415
trainer/Policy log std Min         -1.78799
trainer/Alpha                       0.00997811
trainer/Alpha Loss                 -2.22152
exploration/num steps total    566000
exploration/num paths total      1132
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967206
exploration/Rewards Std             0.158653
exploration/Rewards Max             1
exploration/Rewards Min             0.00279035
exploration/Returns Mean          483.603
exploration/Returns Std             0.72046
exploration/Returns Max           484.7
exploration/Returns Min           482.119
exploration/Actions Mean            0.146379
exploration/Actions Std             0.675239
exploration/Actions Max             0.999956
exploration/Actions Min            -0.99998
exploration/Num Paths              10
exploration/Average Returns       483.603
evaluation/num steps total     565000
evaluation/num paths total       1130
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.967118
evaluation/Rewards Std              0.159611
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00323825
evaluation/Returns Mean           483.559
evaluation/Returns Std              0.565667
evaluation/Returns Max            484.313
evaluation/Returns Min            482.56
evaluation/ExplReturns Mean       483.559
evaluation/ExplReturns Std          0.565667
evaluation/ExplReturns Max        484.313
evaluation/ExplReturns Min        482.56
evaluation/Actions Mean             0.171524
evaluation/Actions Std              0.630804
evaluation/Actions Max              0.999706
evaluation/Actions Min             -0.999594
evaluation/Num Paths               10
evaluation/Average Returns        483.559
time/data storing (s)               0.0292815
time/evaluation sampling (s)       63.3992
time/exploration sampling (s)      70.1524
time/logging (s)                    0.0255355
time/saving (s)                     0.0662529
time/training (s)                  11.0663
time/epoch (s)                    144.739
time/total (s)                  16886.6
Epoch                             112
-----------------------------  ---------------
2023-08-31 16:38:30.033965 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size             571000
trainer/QF1 Loss                    0.910992
trainer/QF2 Loss                    0.879964
trainer/Policy Loss               -62.2516
trainer/Q1 Predictions Mean        68.8295
trainer/Q1 Predictions Std         23.916
trainer/Q1 Predictions Max        102.698
trainer/Q1 Predictions Min         14.8972
trainer/Q2 Predictions Mean        68.9356
trainer/Q2 Predictions Std         23.9415
trainer/Q2 Predictions Max        102.828
trainer/Q2 Predictions Min         14.8733
trainer/Q Targets Mean             69.0961
trainer/Q Targets Std              24.0511
trainer/Q Targets Max             102.607
trainer/Q Targets Min              15.2221
trainer/Log Pis Mean                6.94754
trainer/Log Pis Std                 5.44227
trainer/Log Pis Max                36.6313
trainer/Log Pis Min                -3.48822
trainer/Policy mu Mean              0.131391
trainer/Policy mu Std               1.5854
trainer/Policy mu Max               6.12908
trainer/Policy mu Min              -4.86046
trainer/Policy log std Mean        -0.716109
trainer/Policy log std Std          0.261312
trainer/Policy log std Max         -0.0201973
trainer/Policy log std Min         -1.94195
trainer/Alpha                       0.00952652
trainer/Alpha Loss                 -0.244138
exploration/num steps total    571000
exploration/num paths total      1142
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.96629
exploration/Rewards Std             0.158677
exploration/Rewards Max             1
exploration/Rewards Min             0.0026505
exploration/Returns Mean          483.145
exploration/Returns Std             1.2231
exploration/Returns Max           484.924
exploration/Returns Min           480.594
exploration/Actions Mean            0.063584
exploration/Actions Std             0.671858
exploration/Actions Max             0.999958
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns       483.145
evaluation/num steps total     570000
evaluation/num paths total       1140
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.962259
evaluation/Rewards Std              0.170774
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00262452
evaluation/Returns Mean           481.129
evaluation/Returns Std              7.5608
evaluation/Returns Max            484.988
evaluation/Returns Min            458.626
evaluation/ExplReturns Mean       481.129
evaluation/ExplReturns Std          7.5608
evaluation/ExplReturns Max        484.988
evaluation/ExplReturns Min        458.626
evaluation/Actions Mean             0.105941
evaluation/Actions Std              0.59964
evaluation/Actions Max              0.999955
evaluation/Actions Min             -0.999936
evaluation/Num Paths               10
evaluation/Average Returns        481.129
time/data storing (s)               0.0300332
time/evaluation sampling (s)       63.0932
time/exploration sampling (s)      69.6632
time/logging (s)                    0.0255187
time/saving (s)                     0.0688772
time/training (s)                  10.9187
time/epoch (s)                    143.8
time/total (s)                  17030.4
Epoch                             113
-----------------------------  ---------------
2023-08-31 16:41:00.222634 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size             576000
trainer/QF1 Loss                    0.722198
trainer/QF2 Loss                    0.594214
trainer/Policy Loss               -69.8788
trainer/Q1 Predictions Mean        75.6996
trainer/Q1 Predictions Std         23.2482
trainer/Q1 Predictions Max        102.443
trainer/Q1 Predictions Min         15.1394
trainer/Q2 Predictions Mean        75.9034
trainer/Q2 Predictions Std         23.2833
trainer/Q2 Predictions Max        102.511
trainer/Q2 Predictions Min         17.4246
trainer/Q Targets Mean             75.8179
trainer/Q Targets Std              23.2313
trainer/Q Targets Max             102.654
trainer/Q Targets Min              16.3551
trainer/Log Pis Mean                6.17937
trainer/Log Pis Std                 4.97109
trainer/Log Pis Max                23.4663
trainer/Log Pis Min                -4.37267
trainer/Policy mu Mean              0.0640236
trainer/Policy mu Std               1.54557
trainer/Policy mu Max               4.79447
trainer/Policy mu Min              -4.56145
trainer/Policy log std Mean        -0.681253
trainer/Policy log std Std          0.269511
trainer/Policy log std Max          0.210001
trainer/Policy log std Min         -1.94717
trainer/Alpha                       0.00971051
trainer/Alpha Loss                 -3.80324
exploration/num steps total    576000
exploration/num paths total      1152
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.965657
exploration/Rewards Std             0.15975
exploration/Rewards Max             1
exploration/Rewards Min             0.00234818
exploration/Returns Mean          482.828
exploration/Returns Std             1.15432
exploration/Returns Max           484.421
exploration/Returns Min           480.93
exploration/Actions Mean            0.101642
exploration/Actions Std             0.711866
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999941
exploration/Num Paths              10
exploration/Average Returns       482.828
evaluation/num steps total     575000
evaluation/num paths total       1150
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.965045
evaluation/Rewards Std              0.161988
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00344176
evaluation/Returns Mean           482.523
evaluation/Returns Std              1.95383
evaluation/Returns Max            485.289
evaluation/Returns Min            478.742
evaluation/ExplReturns Mean       482.523
evaluation/ExplReturns Std          1.95383
evaluation/ExplReturns Max        485.289
evaluation/ExplReturns Min        478.742
evaluation/Actions Mean             0.124768
evaluation/Actions Std              0.68462
evaluation/Actions Max              0.999739
evaluation/Actions Min             -0.999619
evaluation/Num Paths               10
evaluation/Average Returns        482.523
time/data storing (s)               0.0302596
time/evaluation sampling (s)       66.6022
time/exploration sampling (s)      70.8212
time/logging (s)                    0.025532
time/saving (s)                     0.0823373
time/training (s)                  12.6231
time/epoch (s)                    150.185
time/total (s)                  17180.6
Epoch                             114
-----------------------------  ---------------
2023-08-31 16:43:30.989557 CST | [Door_Panda_OSC_POSE_SEED1_2023_08_31_11_54_40_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size             581000
trainer/QF1 Loss                    0.714487
trainer/QF2 Loss                    0.680113
trainer/Policy Loss               -67.8353
trainer/Q1 Predictions Mean        73.6624
trainer/Q1 Predictions Std         24.4638
trainer/Q1 Predictions Max        103.49
trainer/Q1 Predictions Min         20.1117
trainer/Q2 Predictions Mean        73.6003
trainer/Q2 Predictions Std         24.4861
trainer/Q2 Predictions Max        103.594
trainer/Q2 Predictions Min         19.7362
trainer/Q Targets Mean             73.7101
trainer/Q Targets Std              24.5811
trainer/Q Targets Max             103.965
trainer/Q Targets Min              20.3283
trainer/Log Pis Mean                6.03904
trainer/Log Pis Std                 5.46806
trainer/Log Pis Max                37.0349
trainer/Log Pis Min                -6.75702
trainer/Policy mu Mean              0.145429
trainer/Policy mu Std               1.52431
trainer/Policy mu Max               6.76352
trainer/Policy mu Min              -6.81148
trainer/Policy log std Mean        -0.712523
trainer/Policy log std Std          0.256554
trainer/Policy log std Max         -0.0234998
trainer/Policy log std Min         -1.62134
trainer/Alpha                       0.0090793
trainer/Alpha Loss                 -4.51813
exploration/num steps total    581000
exploration/num paths total      1162
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.967244
exploration/Rewards Std             0.157263
exploration/Rewards Max             1
exploration/Rewards Min             0.002448
exploration/Returns Mean          483.622
exploration/Returns Std             0.821688
exploration/Returns Max           484.803
exploration/Returns Min           481.728
exploration/Actions Mean            0.288247
exploration/Actions Std             0.635214
exploration/Actions Max             0.999983
exploration/Actions Min            -0.999928
exploration/Num Paths              10
exploration/Average Returns       483.622
evaluation/num steps total     580000
evaluation/num paths total       1160
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.967248
evaluation/Rewards Std              0.156834
evaluation/Rewards Max              1
evaluation/Rewards Min              0.00299705
evaluation/Returns Mean           483.624
evaluation/Returns Std              0.416221
evaluation/Returns Max            484.21
evaluation/Returns Min            482.994
evaluation/ExplReturns Mean       483.624
evaluation/ExplReturns Std          0.416221
evaluation/ExplReturns Max        484.21
evaluation/ExplReturns Min        482.994
evaluation/Actions Mean             0.223305
evaluation/Actions Std              0.615389
evaluation/Actions Max              0.999907
evaluation/Actions Min             -0.999356
evaluation/Num Paths               10
evaluation/Average Returns        483.624
time/data storing (s)               0.0301089
time/evaluation sampling (s)       68.0176
time/exploration sampling (s)      71.4804
time/logging (s)                    0.0256632
time/saving (s)                     0.0714567
time/training (s)                  11.1376
time/epoch (s)                    150.763
time/total (s)                  17331.3
Epoch                             115
-----------------------------  ---------------
