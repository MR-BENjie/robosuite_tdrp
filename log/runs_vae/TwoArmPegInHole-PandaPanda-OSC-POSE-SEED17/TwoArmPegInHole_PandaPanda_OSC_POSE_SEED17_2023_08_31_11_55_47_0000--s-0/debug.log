2023-08-31 11:59:59.706082 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size             6000
trainer/QF1 Loss                 72.0458
trainer/QF2 Loss                 72.1067
trainer/Policy Loss              -7.99988
trainer/Q1 Predictions Mean      -0.00137043
trainer/Q1 Predictions Std        0.00162397
trainer/Q1 Predictions Max        0.00371016
trainer/Q1 Predictions Min       -0.00648411
trainer/Q2 Predictions Mean      -0.00498355
trainer/Q2 Predictions Std        0.00214776
trainer/Q2 Predictions Max        0.00130772
trainer/Q2 Predictions Min       -0.0118958
trainer/Q Targets Mean            8.45583
trainer/Q Targets Std             0.722071
trainer/Q Targets Max            10.4138
trainer/Q Targets Min             6.07738
trainer/Log Pis Mean             -8.00506
trainer/Log Pis Std               0.736569
trainer/Log Pis Max              -6.07043
trainer/Log Pis Min              -9.80772
trainer/Policy mu Mean           -0.000500092
trainer/Policy mu Std             0.000915275
trainer/Policy mu Max             0.00253272
trainer/Policy mu Min            -0.00314702
trainer/Policy log std Mean       0.00013885
trainer/Policy log std Std        0.00136077
trainer/Policy log std Max        0.00399633
trainer/Policy log std Min       -0.0028278
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total    6000
exploration/num paths total      12
exploration/path length Mean    500
exploration/path length Std       0
exploration/path length Max     500
exploration/path length Min     500
exploration/Rewards Mean          0.427468
exploration/Rewards Std           0.0908018
exploration/Rewards Max           0.669317
exploration/Rewards Min           0.180895
exploration/Returns Mean        213.734
exploration/Returns Std          26.6926
exploration/Returns Max         252.811
exploration/Returns Min         177.301
exploration/Actions Mean         -0.0023993
exploration/Actions Std           0.628457
exploration/Actions Max           0.999809
exploration/Actions Min          -0.999718
exploration/Num Paths            10
exploration/Average Returns     213.734
evaluation/num steps total     5000
evaluation/num paths total       10
evaluation/path length Mean     500
evaluation/path length Std        0
evaluation/path length Max      500
evaluation/path length Min      500
evaluation/Rewards Mean           0.513053
evaluation/Rewards Std            0.0108956
evaluation/Rewards Max            0.531147
evaluation/Rewards Min            0.486015
evaluation/Returns Mean         256.527
evaluation/Returns Std            4.94362
evaluation/Returns Max          261.923
evaluation/Returns Min          247.352
evaluation/ExplReturns Mean     256.527
evaluation/ExplReturns Std        4.94362
evaluation/ExplReturns Max      261.923
evaluation/ExplReturns Min      247.352
evaluation/Actions Mean          -0.000586606
evaluation/Actions Std            0.000859648
evaluation/Actions Max            0.00107957
evaluation/Actions Min           -0.00207395
evaluation/Num Paths             10
evaluation/Average Returns      256.527
time/data storing (s)             0.0312606
time/evaluation sampling (s)    102.536
time/exploration sampling (s)   111.766
time/logging (s)                  0.0252577
time/saving (s)                   0.0163841
time/training (s)                 8.94164
time/epoch (s)                  223.316
time/total (s)                  253.005
Epoch                             0
-----------------------------  --------------
2023-08-31 12:03:45.922830 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 1 finished
-----------------------------  ---------------
replay_buffer/size             11000
trainer/QF1 Loss                   0.114147
trainer/QF2 Loss                   0.116333
trainer/Policy Loss              -39.1505
trainer/Q1 Predictions Mean       30.9868
trainer/Q1 Predictions Std         0.835463
trainer/Q1 Predictions Max        33.0471
trainer/Q1 Predictions Min        28.4587
trainer/Q2 Predictions Mean       30.9833
trainer/Q2 Predictions Std         0.833353
trainer/Q2 Predictions Max        33.0569
trainer/Q2 Predictions Min        28.1254
trainer/Q Targets Mean            30.9508
trainer/Q Targets Std              0.769579
trainer/Q Targets Max             32.9409
trainer/Q Targets Min             28.7717
trainer/Log Pis Mean              -8.21956
trainer/Log Pis Std                0.366043
trainer/Log Pis Max               -7.40085
trainer/Log Pis Min              -10.0106
trainer/Policy mu Mean             0.00106502
trainer/Policy mu Std              0.0128769
trainer/Policy mu Max              0.038013
trainer/Policy mu Min             -0.0196898
trainer/Policy log std Mean       -0.12846
trainer/Policy log std Std         0.00785233
trainer/Policy log std Max        -0.105359
trainer/Policy log std Min        -0.155564
trainer/Alpha                      0.740549
trainer/Alpha Loss                -6.06715
exploration/num steps total    11000
exploration/num paths total       22
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.459818
exploration/Rewards Std            0.0765
exploration/Rewards Max            0.679563
exploration/Rewards Min            0.23655
exploration/Returns Mean         229.909
exploration/Returns Std           17.357
exploration/Returns Max          257.397
exploration/Returns Min          191.386
exploration/Actions Mean           0.000338839
exploration/Actions Std            0.59047
exploration/Actions Max            0.998869
exploration/Actions Min           -0.998994
exploration/Num Paths             10
exploration/Average Returns      229.909
evaluation/num steps total     10000
evaluation/num paths total        20
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.565043
evaluation/Rewards Std             0.0363771
evaluation/Rewards Max             0.647956
evaluation/Rewards Min             0.4976
evaluation/Returns Mean          282.521
evaluation/Returns Std             6.94979
evaluation/Returns Max           293.232
evaluation/Returns Min           268.96
evaluation/ExplReturns Mean      282.521
evaluation/ExplReturns Std         6.94979
evaluation/ExplReturns Max       293.232
evaluation/ExplReturns Min       268.96
evaluation/Actions Mean            0.000894393
evaluation/Actions Std             0.0128431
evaluation/Actions Max             0.0291029
evaluation/Actions Min            -0.0138999
evaluation/Num Paths              10
evaluation/Average Returns       282.521
time/data storing (s)              0.0311903
time/evaluation sampling (s)     105.029
time/exploration sampling (s)    110.677
time/logging (s)                   0.0256715
time/saving (s)                    0.0660387
time/training (s)                 10.3849
time/epoch (s)                   226.214
time/total (s)                   479.221
Epoch                              1
-----------------------------  ---------------
2023-08-31 12:07:32.858715 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   0.0942015
trainer/QF2 Loss                   0.0836343
trainer/Policy Loss              -62.3119
trainer/Q1 Predictions Mean       54.1758
trainer/Q1 Predictions Std         1.20731
trainer/Q1 Predictions Max        57.6189
trainer/Q1 Predictions Min        51.6516
trainer/Q2 Predictions Mean       54.1499
trainer/Q2 Predictions Std         1.18945
trainer/Q2 Predictions Max        57.4951
trainer/Q2 Predictions Min        51.6217
trainer/Q Targets Mean            54.0679
trainer/Q Targets Std              1.19796
trainer/Q Targets Max             57.3647
trainer/Q Targets Min             51.4547
trainer/Log Pis Mean              -8.21212
trainer/Log Pis Std                0.38545
trainer/Log Pis Max               -7.23396
trainer/Log Pis Min              -10.0301
trainer/Policy mu Mean             0.00444021
trainer/Policy mu Std              0.0230473
trainer/Policy mu Max              0.0545137
trainer/Policy mu Min             -0.0618944
trainer/Policy log std Mean       -0.12648
trainer/Policy log std Std         0.0076405
trainer/Policy log std Max        -0.105586
trainer/Policy log std Min        -0.150002
trainer/Alpha                      0.548607
trainer/Alpha Loss               -12.1288
exploration/num steps total    16000
exploration/num paths total       32
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.469334
exploration/Rewards Std            0.0783282
exploration/Rewards Max            0.675655
exploration/Rewards Min            0.221316
exploration/Returns Mean         234.667
exploration/Returns Std           23.2279
exploration/Returns Max          275.367
exploration/Returns Min          194.395
exploration/Actions Mean           0.00453946
exploration/Actions Std            0.59198
exploration/Actions Max            0.999086
exploration/Actions Min           -0.998355
exploration/Num Paths             10
exploration/Average Returns      234.667
evaluation/num steps total     15000
evaluation/num paths total        30
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.556953
evaluation/Rewards Std             0.0384654
evaluation/Rewards Max             0.631016
evaluation/Rewards Min             0.487284
evaluation/Returns Mean          278.477
evaluation/Returns Std             4.68594
evaluation/Returns Max           289.245
evaluation/Returns Min           272.064
evaluation/ExplReturns Mean      278.477
evaluation/ExplReturns Std         4.68594
evaluation/ExplReturns Max       289.245
evaluation/ExplReturns Min       272.064
evaluation/Actions Mean            0.00306345
evaluation/Actions Std             0.0238598
evaluation/Actions Max             0.0419619
evaluation/Actions Min            -0.0527397
evaluation/Num Paths              10
evaluation/Average Returns       278.477
time/data storing (s)              0.0310838
time/evaluation sampling (s)     105.947
time/exploration sampling (s)    110.685
time/logging (s)                   0.0256156
time/saving (s)                    0.078921
time/training (s)                 10.1647
time/epoch (s)                   226.933
time/total (s)                   706.156
Epoch                              2
-----------------------------  --------------
2023-08-31 12:11:20.314972 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 3 finished
-----------------------------  --------------
replay_buffer/size             21000
trainer/QF1 Loss                   0.0878941
trainer/QF2 Loss                   0.068813
trainer/Policy Loss              -78.9989
trainer/Q1 Predictions Mean       70.8924
trainer/Q1 Predictions Std         1.45393
trainer/Q1 Predictions Max        74.669
trainer/Q1 Predictions Min        66.5882
trainer/Q2 Predictions Mean       70.8457
trainer/Q2 Predictions Std         1.4466
trainer/Q2 Predictions Max        74.5984
trainer/Q2 Predictions Min        66.884
trainer/Q Targets Mean            70.7996
trainer/Q Targets Std              1.46149
trainer/Q Targets Max             74.4224
trainer/Q Targets Min             66.8239
trainer/Log Pis Mean              -8.18481
trainer/Log Pis Std                0.50745
trainer/Log Pis Max               -7.09322
trainer/Log Pis Min              -11.049
trainer/Policy mu Mean             0.0107165
trainer/Policy mu Std              0.0437983
trainer/Policy mu Max              0.151941
trainer/Policy mu Min             -0.100211
trainer/Policy log std Mean       -0.130563
trainer/Policy log std Std         0.00933576
trainer/Policy log std Max        -0.0966716
trainer/Policy log std Min        -0.166102
trainer/Alpha                      0.406444
trainer/Alpha Loss               -18.1665
exploration/num steps total    21000
exploration/num paths total       42
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.473489
exploration/Rewards Std            0.08461
exploration/Rewards Max            0.719556
exploration/Rewards Min            0.208382
exploration/Returns Mean         236.744
exploration/Returns Std           20.3173
exploration/Returns Max          269.263
exploration/Returns Min          200.839
exploration/Actions Mean           0.00802696
exploration/Actions Std            0.591721
exploration/Actions Max            0.998201
exploration/Actions Min           -0.998873
exploration/Num Paths             10
exploration/Average Returns      236.744
evaluation/num steps total     20000
evaluation/num paths total        40
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.59337
evaluation/Rewards Std             0.0571741
evaluation/Rewards Max             0.717492
evaluation/Rewards Min             0.409142
evaluation/Returns Mean          296.685
evaluation/Returns Std             9.71617
evaluation/Returns Max           311.316
evaluation/Returns Min           278.658
evaluation/ExplReturns Mean      296.685
evaluation/ExplReturns Std         9.71617
evaluation/ExplReturns Max       311.316
evaluation/ExplReturns Min       278.658
evaluation/Actions Mean            0.00221254
evaluation/Actions Std             0.0356301
evaluation/Actions Max             0.0850382
evaluation/Actions Min            -0.0876861
evaluation/Num Paths              10
evaluation/Average Returns       296.685
time/data storing (s)              0.0311583
time/evaluation sampling (s)     106.808
time/exploration sampling (s)    109.966
time/logging (s)                   0.0262852
time/saving (s)                    0.0732881
time/training (s)                 10.5489
time/epoch (s)                   227.453
time/total (s)                   933.613
Epoch                              3
-----------------------------  --------------
2023-08-31 12:15:12.333585 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size             26000
trainer/QF1 Loss                   0.0811531
trainer/QF2 Loss                   0.0708934
trainer/Policy Loss              -90.4985
trainer/Q1 Predictions Mean       82.3407
trainer/Q1 Predictions Std         1.83708
trainer/Q1 Predictions Max        86.235
trainer/Q1 Predictions Min        76.2633
trainer/Q2 Predictions Mean       82.306
trainer/Q2 Predictions Std         1.80032
trainer/Q2 Predictions Max        86.2512
trainer/Q2 Predictions Min        76.2405
trainer/Q Targets Mean            82.2325
trainer/Q Targets Std              1.80581
trainer/Q Targets Max             86.1595
trainer/Q Targets Min             76.6791
trainer/Log Pis Mean              -8.20792
trainer/Log Pis Std                0.536416
trainer/Log Pis Max               -6.51143
trainer/Log Pis Min              -10.6712
trainer/Policy mu Mean             0.0101021
trainer/Policy mu Std              0.0735851
trainer/Policy mu Max              0.230783
trainer/Policy mu Min             -0.197435
trainer/Policy log std Mean       -0.13396
trainer/Policy log std Std         0.00934762
trainer/Policy log std Max        -0.1008
trainer/Policy log std Min        -0.168236
trainer/Alpha                      0.301164
trainer/Alpha Loss               -24.2454
exploration/num steps total    26000
exploration/num paths total       52
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.493845
exploration/Rewards Std            0.0943197
exploration/Rewards Max            0.73419
exploration/Rewards Min            0.131643
exploration/Returns Mean         246.923
exploration/Returns Std           30.3746
exploration/Returns Max          280.261
exploration/Returns Min          166.596
exploration/Actions Mean           0.00797541
exploration/Actions Std            0.591299
exploration/Actions Max            0.999115
exploration/Actions Min           -0.999403
exploration/Num Paths             10
exploration/Average Returns      246.923
evaluation/num steps total     25000
evaluation/num paths total        50
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.596992
evaluation/Rewards Std             0.0739073
evaluation/Rewards Max             0.69741
evaluation/Rewards Min             0.341766
evaluation/Returns Mean          298.496
evaluation/Returns Std            18.0708
evaluation/Returns Max           314.306
evaluation/Returns Min           255.858
evaluation/ExplReturns Mean      298.496
evaluation/ExplReturns Std        18.0708
evaluation/ExplReturns Max       314.306
evaluation/ExplReturns Min       255.858
evaluation/Actions Mean            0.00195924
evaluation/Actions Std             0.0671967
evaluation/Actions Max             0.165716
evaluation/Actions Min            -0.178648
evaluation/Num Paths              10
evaluation/Average Returns       298.496
time/data storing (s)              0.0310765
time/evaluation sampling (s)     108.562
time/exploration sampling (s)    110.203
time/logging (s)                   0.0257363
time/saving (s)                    0.0757445
time/training (s)                 13.1171
time/epoch (s)                   232.015
time/total (s)                  1165.63
Epoch                              4
-----------------------------  --------------
2023-08-31 12:19:04.971612 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size             31000
trainer/QF1 Loss                   0.0865658
trainer/QF2 Loss                   0.0863628
trainer/Policy Loss              -98.5081
trainer/Q1 Predictions Mean       90.369
trainer/Q1 Predictions Std         2.25396
trainer/Q1 Predictions Max        98.2798
trainer/Q1 Predictions Min        84.2325
trainer/Q2 Predictions Mean       90.3993
trainer/Q2 Predictions Std         2.23465
trainer/Q2 Predictions Max        97.8726
trainer/Q2 Predictions Min        84.4703
trainer/Q Targets Mean            90.404
trainer/Q Targets Std              2.24296
trainer/Q Targets Max             97.4014
trainer/Q Targets Min             84.3256
trainer/Log Pis Mean              -8.14199
trainer/Log Pis Std                0.601529
trainer/Log Pis Max               -6.03803
trainer/Log Pis Min              -10.9909
trainer/Policy mu Mean            -0.00333185
trainer/Policy mu Std              0.104167
trainer/Policy mu Max              0.257005
trainer/Policy mu Min             -0.288879
trainer/Policy log std Mean       -0.127015
trainer/Policy log std Std         0.00989823
trainer/Policy log std Max        -0.0931461
trainer/Policy log std Min        -0.156553
trainer/Alpha                      0.223214
trainer/Alpha Loss               -30.1993
exploration/num steps total    31000
exploration/num paths total       62
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.515992
exploration/Rewards Std            0.0793959
exploration/Rewards Max            0.920406
exploration/Rewards Min            0.269474
exploration/Returns Mean         257.996
exploration/Returns Std           19.6537
exploration/Returns Max          274.507
exploration/Returns Min          207.302
exploration/Actions Mean          -0.00197125
exploration/Actions Std            0.592167
exploration/Actions Max            0.99941
exploration/Actions Min           -0.999863
exploration/Num Paths             10
exploration/Average Returns      257.996
evaluation/num steps total     30000
evaluation/num paths total        60
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.591273
evaluation/Rewards Std             0.113583
evaluation/Rewards Max             0.715759
evaluation/Rewards Min             0.292046
evaluation/Returns Mean          295.637
evaluation/Returns Std            48.124
evaluation/Returns Max           341.647
evaluation/Returns Min           182.638
evaluation/ExplReturns Mean      295.637
evaluation/ExplReturns Std        48.124
evaluation/ExplReturns Max       341.647
evaluation/ExplReturns Min       182.638
evaluation/Actions Mean           -0.00853706
evaluation/Actions Std             0.0906592
evaluation/Actions Max             0.233502
evaluation/Actions Min            -0.267882
evaluation/Num Paths              10
evaluation/Average Returns       295.637
time/data storing (s)              0.0311264
time/evaluation sampling (s)     111.22
time/exploration sampling (s)    111.285
time/logging (s)                   0.0256194
time/saving (s)                    0.0716873
time/training (s)                 10.0007
time/epoch (s)                   232.635
time/total (s)                  1398.27
Epoch                              5
-----------------------------  --------------
2023-08-31 12:22:54.045782 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size             36000
trainer/QF1 Loss                   0.0927149
trainer/QF2 Loss                   0.103089
trainer/Policy Loss             -103.621
trainer/Q1 Predictions Mean       95.6422
trainer/Q1 Predictions Std         2.41161
trainer/Q1 Predictions Max       103.057
trainer/Q1 Predictions Min        87.9961
trainer/Q2 Predictions Mean       95.6699
trainer/Q2 Predictions Std         2.43192
trainer/Q2 Predictions Max       103.12
trainer/Q2 Predictions Min        87.8909
trainer/Q Targets Mean            95.5696
trainer/Q Targets Std              2.41935
trainer/Q Targets Max            102.301
trainer/Q Targets Min             87.67
trainer/Log Pis Mean              -7.98376
trainer/Log Pis Std                0.767343
trainer/Log Pis Max               -5.23687
trainer/Log Pis Min              -10.2816
trainer/Policy mu Mean             0.014515
trainer/Policy mu Std              0.157468
trainer/Policy mu Max              0.397554
trainer/Policy mu Min             -0.485302
trainer/Policy log std Mean       -0.135977
trainer/Policy log std Std         0.0144971
trainer/Policy log std Max        -0.087084
trainer/Policy log std Min        -0.19767
trainer/Alpha                      0.165517
trainer/Alpha Loss               -35.9385
exploration/num steps total    36000
exploration/num paths total       72
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.480095
exploration/Rewards Std            0.0884307
exploration/Rewards Max            0.70246
exploration/Rewards Min            0.20636
exploration/Returns Mean         240.048
exploration/Returns Std           19.1159
exploration/Returns Max          266.274
exploration/Returns Min          205.056
exploration/Actions Mean           0.0145853
exploration/Actions Std            0.59206
exploration/Actions Max            0.998918
exploration/Actions Min           -0.998055
exploration/Num Paths             10
exploration/Average Returns      240.048
evaluation/num steps total     35000
evaluation/num paths total        70
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.478546
evaluation/Rewards Std             0.126188
evaluation/Rewards Max             0.690654
evaluation/Rewards Min             0.058641
evaluation/Returns Mean          239.273
evaluation/Returns Std            24.3272
evaluation/Returns Max           267.153
evaluation/Returns Min           194.286
evaluation/ExplReturns Mean      239.273
evaluation/ExplReturns Std        24.3272
evaluation/ExplReturns Max       267.153
evaluation/ExplReturns Min       194.286
evaluation/Actions Mean            0.00944909
evaluation/Actions Std             0.124446
evaluation/Actions Max             0.345307
evaluation/Actions Min            -0.42144
evaluation/Num Paths              10
evaluation/Average Returns       239.273
time/data storing (s)              0.0308007
time/evaluation sampling (s)     107.817
time/exploration sampling (s)    110.829
time/logging (s)                   0.0258867
time/saving (s)                    0.0731501
time/training (s)                 10.2955
time/epoch (s)                   229.071
time/total (s)                  1627.34
Epoch                              6
-----------------------------  --------------
2023-08-31 12:26:41.976597 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             41000
trainer/QF1 Loss                   0.124594
trainer/QF2 Loss                   0.108786
trainer/Policy Loss             -106.042
trainer/Q1 Predictions Mean       98.1587
trainer/Q1 Predictions Std         2.44404
trainer/Q1 Predictions Max       104.179
trainer/Q1 Predictions Min        90.6665
trainer/Q2 Predictions Mean       98.2583
trainer/Q2 Predictions Std         2.44571
trainer/Q2 Predictions Max       104.247
trainer/Q2 Predictions Min        90.7349
trainer/Q Targets Mean            98.2201
trainer/Q Targets Std              2.45575
trainer/Q Targets Max            103.906
trainer/Q Targets Min             90.284
trainer/Log Pis Mean              -7.84366
trainer/Log Pis Std                0.958226
trainer/Log Pis Max               -4.61854
trainer/Log Pis Min              -10.4618
trainer/Policy mu Mean             0.0149519
trainer/Policy mu Std              0.206041
trainer/Policy mu Max              0.543817
trainer/Policy mu Min             -0.672885
trainer/Policy log std Mean       -0.125878
trainer/Policy log std Std         0.0184759
trainer/Policy log std Max        -0.0803492
trainer/Policy log std Min        -0.21195
trainer/Alpha                      0.122822
trainer/Alpha Loss               -41.6067
exploration/num steps total    41000
exploration/num paths total       82
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.483744
exploration/Rewards Std            0.0866539
exploration/Rewards Max            0.692488
exploration/Rewards Min            0.228249
exploration/Returns Mean         241.872
exploration/Returns Std           16.5985
exploration/Returns Max          267.746
exploration/Returns Min          215.31
exploration/Actions Mean           0.0205506
exploration/Actions Std            0.59747
exploration/Actions Max            0.998984
exploration/Actions Min           -0.99897
exploration/Num Paths             10
exploration/Average Returns      241.872
evaluation/num steps total     40000
evaluation/num paths total        80
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.42114
evaluation/Rewards Std             0.122018
evaluation/Rewards Max             0.644886
evaluation/Rewards Min             0.11923
evaluation/Returns Mean          210.57
evaluation/Returns Std            33.7023
evaluation/Returns Max           292.879
evaluation/Returns Min           174.706
evaluation/ExplReturns Mean      210.57
evaluation/ExplReturns Std        33.7023
evaluation/ExplReturns Max       292.879
evaluation/ExplReturns Min       174.706
evaluation/Actions Mean            0.024317
evaluation/Actions Std             0.145676
evaluation/Actions Max             0.459397
evaluation/Actions Min            -0.589604
evaluation/Num Paths              10
evaluation/Average Returns       210.57
time/data storing (s)              0.0313204
time/evaluation sampling (s)     107.251
time/exploration sampling (s)    110.43
time/logging (s)                   0.0256882
time/saving (s)                    0.0680422
time/training (s)                 10.1209
time/epoch (s)                   227.927
time/total (s)                  1855.27
Epoch                              7
-----------------------------  -------------
2023-08-31 12:30:30.971602 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             46000
trainer/QF1 Loss                   0.137768
trainer/QF2 Loss                   0.109913
trainer/Policy Loss             -107.697
trainer/Q1 Predictions Mean      100.203
trainer/Q1 Predictions Std         3.22709
trainer/Q1 Predictions Max       108.636
trainer/Q1 Predictions Min        81.2339
trainer/Q2 Predictions Mean      100.07
trainer/Q2 Predictions Std         3.22307
trainer/Q2 Predictions Max       108.265
trainer/Q2 Predictions Min        80.888
trainer/Q Targets Mean           100.096
trainer/Q Targets Std              3.21217
trainer/Q Targets Max            107.641
trainer/Q Targets Min             81.2468
trainer/Log Pis Mean              -7.56947
trainer/Log Pis Std                1.15236
trainer/Log Pis Max               -3.93756
trainer/Log Pis Min              -11.4805
trainer/Policy mu Mean             0.0199985
trainer/Policy mu Std              0.262011
trainer/Policy mu Max              0.829457
trainer/Policy mu Min             -0.917362
trainer/Policy log std Mean       -0.133419
trainer/Policy log std Std         0.0277957
trainer/Policy log std Max        -0.0765606
trainer/Policy log std Min        -0.272659
trainer/Alpha                      0.0912212
trainer/Alpha Loss               -46.8527
exploration/num steps total    46000
exploration/num paths total       92
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.441073
exploration/Rewards Std            0.0937697
exploration/Rewards Max            0.673191
exploration/Rewards Min            0.151483
exploration/Returns Mean         220.536
exploration/Returns Std           19.7145
exploration/Returns Max          242.524
exploration/Returns Min          188.147
exploration/Actions Mean           0.0349977
exploration/Actions Std            0.598734
exploration/Actions Max            0.999281
exploration/Actions Min           -0.999243
exploration/Num Paths             10
exploration/Average Returns      220.536
evaluation/num steps total     45000
evaluation/num paths total        90
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.382626
evaluation/Rewards Std             0.121829
evaluation/Rewards Max             0.622978
evaluation/Rewards Min             0.12157
evaluation/Returns Mean          191.313
evaluation/Returns Std            33.1059
evaluation/Returns Max           250.303
evaluation/Returns Min           133.634
evaluation/ExplReturns Mean      191.313
evaluation/ExplReturns Std        33.1059
evaluation/ExplReturns Max       250.303
evaluation/ExplReturns Min       133.634
evaluation/Actions Mean            0.0341714
evaluation/Actions Std             0.195698
evaluation/Actions Max             0.692916
evaluation/Actions Min            -0.732865
evaluation/Num Paths              10
evaluation/Average Returns       191.313
time/data storing (s)              0.0313737
time/evaluation sampling (s)     107.308
time/exploration sampling (s)    110.692
time/logging (s)                   0.0260875
time/saving (s)                    0.0719167
time/training (s)                 10.8622
time/epoch (s)                   228.992
time/total (s)                  2084.27
Epoch                              8
-----------------------------  -------------
2023-08-31 12:34:19.315064 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size             51000
trainer/QF1 Loss                   0.117727
trainer/QF2 Loss                   0.114385
trainer/Policy Loss             -107.799
trainer/Q1 Predictions Mean      100.567
trainer/Q1 Predictions Std         3.07927
trainer/Q1 Predictions Max       107.42
trainer/Q1 Predictions Min        90.1428
trainer/Q2 Predictions Mean      100.59
trainer/Q2 Predictions Std         3.08706
trainer/Q2 Predictions Max       107.398
trainer/Q2 Predictions Min        89.6764
trainer/Q Targets Mean           100.544
trainer/Q Targets Std              3.08951
trainer/Q Targets Max            107.285
trainer/Q Targets Min             89.7853
trainer/Log Pis Mean              -7.16433
trainer/Log Pis Std                1.46001
trainer/Log Pis Max               -1.79574
trainer/Log Pis Min              -10.9077
trainer/Policy mu Mean             0.0123915
trainer/Policy mu Std              0.338455
trainer/Policy mu Max              0.824191
trainer/Policy mu Min             -1.37203
trainer/Policy log std Mean       -0.131479
trainer/Policy log std Std         0.0384015
trainer/Policy log std Max        -0.00357099
trainer/Policy log std Min        -0.372079
trainer/Alpha                      0.0678486
trainer/Alpha Loss               -51.5555
exploration/num steps total    51000
exploration/num paths total      102
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.468065
exploration/Rewards Std            0.0849576
exploration/Rewards Max            0.665488
exploration/Rewards Min            0.218006
exploration/Returns Mean         234.033
exploration/Returns Std           18.8355
exploration/Returns Max          258.479
exploration/Returns Min          200.242
exploration/Actions Mean           0.0373899
exploration/Actions Std            0.606397
exploration/Actions Max            0.998884
exploration/Actions Min           -0.998867
exploration/Num Paths             10
exploration/Average Returns      234.033
evaluation/num steps total     50000
evaluation/num paths total       100
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.438932
evaluation/Rewards Std             0.116895
evaluation/Rewards Max             0.733981
evaluation/Rewards Min             0.170084
evaluation/Returns Mean          219.466
evaluation/Returns Std            28.2691
evaluation/Returns Max           256.689
evaluation/Returns Min           165.725
evaluation/ExplReturns Mean      219.466
evaluation/ExplReturns Std        28.2691
evaluation/ExplReturns Max       256.689
evaluation/ExplReturns Min       165.725
evaluation/Actions Mean            0.0388181
evaluation/Actions Std             0.227777
evaluation/Actions Max             0.884286
evaluation/Actions Min            -0.933488
evaluation/Num Paths              10
evaluation/Average Returns       219.466
time/data storing (s)              0.0311248
time/evaluation sampling (s)     107.016
time/exploration sampling (s)    111.1
time/logging (s)                   0.0258179
time/saving (s)                    0.0686375
time/training (s)                 10.0982
time/epoch (s)                   228.34
time/total (s)                  2312.61
Epoch                              9
-----------------------------  --------------
2023-08-31 12:38:14.491057 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 10 finished
-----------------------------  -------------
replay_buffer/size             56000
trainer/QF1 Loss                   0.138798
trainer/QF2 Loss                   0.131212
trainer/Policy Loss             -107.136
trainer/Q1 Predictions Mean      100.267
trainer/Q1 Predictions Std         3.17199
trainer/Q1 Predictions Max       111.165
trainer/Q1 Predictions Min        84.9374
trainer/Q2 Predictions Mean      100.293
trainer/Q2 Predictions Std         3.15795
trainer/Q2 Predictions Max       111.44
trainer/Q2 Predictions Min        85.1055
trainer/Q Targets Mean           100.196
trainer/Q Targets Std              3.21433
trainer/Q Targets Max            111.336
trainer/Q Targets Min             84.405
trainer/Log Pis Mean              -6.79249
trainer/Log Pis Std                1.81883
trainer/Log Pis Max               -1.36306
trainer/Log Pis Min              -11.4892
trainer/Policy mu Mean             0.0280907
trainer/Policy mu Std              0.435221
trainer/Policy mu Max              1.3923
trainer/Policy mu Min             -1.62705
trainer/Policy log std Mean       -0.141667
trainer/Policy log std Std         0.0549819
trainer/Policy log std Max        -0.0218931
trainer/Policy log std Min        -0.463275
trainer/Alpha                      0.0505892
trainer/Alpha Loss               -56.0716
exploration/num steps total    56000
exploration/num paths total      112
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.460897
exploration/Rewards Std            0.0942837
exploration/Rewards Max            0.712284
exploration/Rewards Min            0.212667
exploration/Returns Mean         230.449
exploration/Returns Std           24.5307
exploration/Returns Max          270.835
exploration/Returns Min          173.789
exploration/Actions Mean           0.044592
exploration/Actions Std            0.612552
exploration/Actions Max            0.999486
exploration/Actions Min           -0.99891
exploration/Num Paths             10
exploration/Average Returns      230.449
evaluation/num steps total     55000
evaluation/num paths total       110
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.493949
evaluation/Rewards Std             0.116297
evaluation/Rewards Max             0.70784
evaluation/Rewards Min             0.128749
evaluation/Returns Mean          246.975
evaluation/Returns Std            40.1329
evaluation/Returns Max           318.418
evaluation/Returns Min           181.522
evaluation/ExplReturns Mean      246.975
evaluation/ExplReturns Std        40.1329
evaluation/ExplReturns Max       318.418
evaluation/ExplReturns Min       181.522
evaluation/Actions Mean            0.0604489
evaluation/Actions Std             0.307204
evaluation/Actions Max             0.837358
evaluation/Actions Min            -0.930773
evaluation/Num Paths              10
evaluation/Average Returns       246.975
time/data storing (s)              0.0308302
time/evaluation sampling (s)     109.242
time/exploration sampling (s)    111.479
time/logging (s)                   0.0256169
time/saving (s)                    0.0683676
time/training (s)                 14.3272
time/epoch (s)                   235.172
time/total (s)                  2547.78
Epoch                             10
-----------------------------  -------------
2023-08-31 12:42:00.251629 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 11 finished
-----------------------------  -------------
replay_buffer/size             61000
trainer/QF1 Loss                   0.156786
trainer/QF2 Loss                   0.146885
trainer/Policy Loss             -105.621
trainer/Q1 Predictions Mean       99.4535
trainer/Q1 Predictions Std         3.5554
trainer/Q1 Predictions Max       107.808
trainer/Q1 Predictions Min        82.3857
trainer/Q2 Predictions Mean       99.4618
trainer/Q2 Predictions Std         3.54518
trainer/Q2 Predictions Max       107.859
trainer/Q2 Predictions Min        82.8609
trainer/Q Targets Mean            99.4239
trainer/Q Targets Std              3.55692
trainer/Q Targets Max            107.244
trainer/Q Targets Min             81.8437
trainer/Log Pis Mean              -6.07601
trainer/Log Pis Std                2.6128
trainer/Log Pis Max                9.27056
trainer/Log Pis Min              -12.9596
trainer/Policy mu Mean             0.0621554
trainer/Policy mu Std              0.540526
trainer/Policy mu Max              2.31849
trainer/Policy mu Min             -2.36597
trainer/Policy log std Mean       -0.151774
trainer/Policy log std Std         0.0718444
trainer/Policy log std Max         0.0264225
trainer/Policy log std Min        -0.503541
trainer/Alpha                      0.0378556
trainer/Alpha Loss               -59.1753
exploration/num steps total    61000
exploration/num paths total      122
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.461295
exploration/Rewards Std            0.0860055
exploration/Rewards Max            0.719253
exploration/Rewards Min            0.21052
exploration/Returns Mean         230.647
exploration/Returns Std           13.8179
exploration/Returns Max          247.919
exploration/Returns Min          198.176
exploration/Actions Mean           0.0456844
exploration/Actions Std            0.623784
exploration/Actions Max            0.999003
exploration/Actions Min           -0.999274
exploration/Num Paths             10
exploration/Average Returns      230.647
evaluation/num steps total     60000
evaluation/num paths total       120
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.423567
evaluation/Rewards Std             0.0696827
evaluation/Rewards Max             0.678805
evaluation/Rewards Min             0.164971
evaluation/Returns Mean          211.783
evaluation/Returns Std             5.58017
evaluation/Returns Max           222.778
evaluation/Returns Min           202.954
evaluation/ExplReturns Mean      211.783
evaluation/ExplReturns Std         5.58017
evaluation/ExplReturns Max       222.778
evaluation/ExplReturns Min       202.954
evaluation/Actions Mean            0.068299
evaluation/Actions Std             0.363446
evaluation/Actions Max             0.968744
evaluation/Actions Min            -0.967479
evaluation/Num Paths              10
evaluation/Average Returns       211.783
time/data storing (s)              0.0311182
time/evaluation sampling (s)     105.366
time/exploration sampling (s)    109.945
time/logging (s)                   0.0257331
time/saving (s)                    0.0646865
time/training (s)                 10.3245
time/epoch (s)                   225.757
time/total (s)                  2773.54
Epoch                             11
-----------------------------  -------------
2023-08-31 12:45:46.129546 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 12 finished
-----------------------------  -------------
replay_buffer/size             66000
trainer/QF1 Loss                   0.140492
trainer/QF2 Loss                   0.154174
trainer/Policy Loss             -103.191
trainer/Q1 Predictions Mean       98.3165
trainer/Q1 Predictions Std         3.60097
trainer/Q1 Predictions Max       107.785
trainer/Q1 Predictions Min        81.8297
trainer/Q2 Predictions Mean       98.4151
trainer/Q2 Predictions Std         3.59019
trainer/Q2 Predictions Max       107.907
trainer/Q2 Predictions Min        82.4082
trainer/Q Targets Mean            98.2862
trainer/Q Targets Std              3.64525
trainer/Q Targets Max            107.601
trainer/Q Targets Min             81.8177
trainer/Log Pis Mean              -4.71904
trainer/Log Pis Std                2.9139
trainer/Log Pis Max                4.48204
trainer/Log Pis Min              -11.5786
trainer/Policy mu Mean             0.0406983
trainer/Policy mu Std              0.649993
trainer/Policy mu Max              2.45793
trainer/Policy mu Min             -2.34404
trainer/Policy log std Mean       -0.176186
trainer/Policy log std Std         0.0892845
trainer/Policy log std Max         0.0193034
trainer/Policy log std Min        -0.730359
trainer/Alpha                      0.02844
trainer/Alpha Loss               -59.5144
exploration/num steps total    66000
exploration/num paths total      132
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.446989
exploration/Rewards Std            0.0893255
exploration/Rewards Max            0.707277
exploration/Rewards Min            0.166554
exploration/Returns Mean         223.494
exploration/Returns Std           11.5434
exploration/Returns Max          236.859
exploration/Returns Min          203.045
exploration/Actions Mean           0.0356205
exploration/Actions Std            0.63047
exploration/Actions Max            0.999378
exploration/Actions Min           -0.999289
exploration/Num Paths             10
exploration/Average Returns      223.494
evaluation/num steps total     65000
evaluation/num paths total       130
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.42845
evaluation/Rewards Std             0.0874369
evaluation/Rewards Max             0.685675
evaluation/Rewards Min             0.173532
evaluation/Returns Mean          214.225
evaluation/Returns Std            18.1905
evaluation/Returns Max           245.707
evaluation/Returns Min           193.205
evaluation/ExplReturns Mean      214.225
evaluation/ExplReturns Std        18.1905
evaluation/ExplReturns Max       245.707
evaluation/ExplReturns Min       193.205
evaluation/Actions Mean            0.0435988
evaluation/Actions Std             0.441742
evaluation/Actions Max             0.966387
evaluation/Actions Min            -0.972635
evaluation/Num Paths              10
evaluation/Average Returns       214.225
time/data storing (s)              0.0312463
time/evaluation sampling (s)     104.284
time/exploration sampling (s)    111.37
time/logging (s)                   0.0263812
time/saving (s)                    0.083526
time/training (s)                 10.0803
time/epoch (s)                   225.875
time/total (s)                  2999.42
Epoch                             12
-----------------------------  -------------
2023-08-31 12:49:30.239701 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 13 finished
-----------------------------  -------------
replay_buffer/size             71000
trainer/QF1 Loss                   0.183724
trainer/QF2 Loss                   0.176897
trainer/Policy Loss             -101.27
trainer/Q1 Predictions Mean       97.3744
trainer/Q1 Predictions Std         3.26104
trainer/Q1 Predictions Max       103.624
trainer/Q1 Predictions Min        84.1121
trainer/Q2 Predictions Mean       97.3022
trainer/Q2 Predictions Std         3.23321
trainer/Q2 Predictions Max       103.532
trainer/Q2 Predictions Min        84.2129
trainer/Q Targets Mean            97.4194
trainer/Q Targets Std              3.26567
trainer/Q Targets Max            103.996
trainer/Q Targets Min             84.4543
trainer/Log Pis Mean              -3.82798
trainer/Log Pis Std                3.27363
trainer/Log Pis Max                7.10265
trainer/Log Pis Min              -13.1217
trainer/Policy mu Mean             0.0151912
trainer/Policy mu Std              0.758931
trainer/Policy mu Max              2.1673
trainer/Policy mu Min             -2.25739
trainer/Policy log std Mean       -0.193268
trainer/Policy log std Std         0.0973268
trainer/Policy log std Max         0.0525099
trainer/Policy log std Min        -0.612776
trainer/Alpha                      0.0214951
trainer/Alpha Loss               -60.774
exploration/num steps total    71000
exploration/num paths total      142
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.467595
exploration/Rewards Std            0.105231
exploration/Rewards Max            0.723022
exploration/Rewards Min            0.172189
exploration/Returns Mean         233.798
exploration/Returns Std           18.1876
exploration/Returns Max          255.438
exploration/Returns Min          198.344
exploration/Actions Mean           0.0380418
exploration/Actions Std            0.644531
exploration/Actions Max            0.999467
exploration/Actions Min           -0.999112
exploration/Num Paths             10
exploration/Average Returns      233.798
evaluation/num steps total     70000
evaluation/num paths total       140
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.483027
evaluation/Rewards Std             0.0815761
evaluation/Rewards Max             0.704679
evaluation/Rewards Min             0.214856
evaluation/Returns Mean          241.514
evaluation/Returns Std             9.83623
evaluation/Returns Max           257.178
evaluation/Returns Min           221.418
evaluation/ExplReturns Mean      241.514
evaluation/ExplReturns Std         9.83623
evaluation/ExplReturns Max       257.178
evaluation/ExplReturns Min       221.418
evaluation/Actions Mean            0.0407964
evaluation/Actions Std             0.50898
evaluation/Actions Max             0.984692
evaluation/Actions Min            -0.968539
evaluation/Num Paths              10
evaluation/Average Returns       241.514
time/data storing (s)              0.0314392
time/evaluation sampling (s)     103.415
time/exploration sampling (s)    110.079
time/logging (s)                   0.0261284
time/saving (s)                    0.086096
time/training (s)                 10.4685
time/epoch (s)                   224.106
time/total (s)                  3223.53
Epoch                             13
-----------------------------  -------------
2023-08-31 12:53:15.007344 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size             76000
trainer/QF1 Loss                   0.207592
trainer/QF2 Loss                   0.198447
trainer/Policy Loss              -97.4769
trainer/Q1 Predictions Mean       95.6501
trainer/Q1 Predictions Std         4.86754
trainer/Q1 Predictions Max       103.541
trainer/Q1 Predictions Min        56.0471
trainer/Q2 Predictions Mean       95.5761
trainer/Q2 Predictions Std         4.83968
trainer/Q2 Predictions Max       103.513
trainer/Q2 Predictions Min        56.4324
trainer/Q Targets Mean            95.5099
trainer/Q Targets Std              4.92104
trainer/Q Targets Max            103.214
trainer/Q Targets Min             56.5803
trainer/Log Pis Mean              -1.69424
trainer/Log Pis Std                3.73752
trainer/Log Pis Max               12.9358
trainer/Log Pis Min              -11.1159
trainer/Policy mu Mean             0.00766246
trainer/Policy mu Std              0.90576
trainer/Policy mu Max              2.54662
trainer/Policy mu Min             -2.77115
trainer/Policy log std Mean       -0.2302
trainer/Policy log std Std         0.119579
trainer/Policy log std Max         0.0581691
trainer/Policy log std Min        -0.826023
trainer/Alpha                      0.0163795
trainer/Alpha Loss               -56.3032
exploration/num steps total    76000
exploration/num paths total      152
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.446487
exploration/Rewards Std            0.126499
exploration/Rewards Max            0.715213
exploration/Rewards Min            0.0945328
exploration/Returns Mean         223.244
exploration/Returns Std           23.2426
exploration/Returns Max          256.823
exploration/Returns Min          179.069
exploration/Actions Mean           0.0713794
exploration/Actions Std            0.653704
exploration/Actions Max            0.999753
exploration/Actions Min           -0.999826
exploration/Num Paths             10
exploration/Average Returns      223.244
evaluation/num steps total     75000
evaluation/num paths total       150
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.458638
evaluation/Rewards Std             0.125366
evaluation/Rewards Max             0.737149
evaluation/Rewards Min             0.106352
evaluation/Returns Mean          229.319
evaluation/Returns Std            24.4224
evaluation/Returns Max           259.264
evaluation/Returns Min           183.064
evaluation/ExplReturns Mean      229.319
evaluation/ExplReturns Std        24.4224
evaluation/ExplReturns Max       259.264
evaluation/ExplReturns Min       183.064
evaluation/Actions Mean            0.0841467
evaluation/Actions Std             0.490373
evaluation/Actions Max             0.988607
evaluation/Actions Min            -0.995341
evaluation/Num Paths              10
evaluation/Average Returns       229.319
time/data storing (s)              0.0316009
time/evaluation sampling (s)     104.48
time/exploration sampling (s)    109.871
time/logging (s)                   0.0258463
time/saving (s)                    0.0728621
time/training (s)                 10.2827
time/epoch (s)                   224.764
time/total (s)                  3448.3
Epoch                             14
-----------------------------  --------------
2023-08-31 12:57:01.050519 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 15 finished
-----------------------------  -------------
replay_buffer/size             81000
trainer/QF1 Loss                   0.269228
trainer/QF2 Loss                   0.264673
trainer/Policy Loss              -93.1558
trainer/Q1 Predictions Mean       93.2139
trainer/Q1 Predictions Std         5.68656
trainer/Q1 Predictions Max       103.565
trainer/Q1 Predictions Min        64.4286
trainer/Q2 Predictions Mean       93.2222
trainer/Q2 Predictions Std         5.6853
trainer/Q2 Predictions Max       103.484
trainer/Q2 Predictions Min        64.5325
trainer/Q Targets Mean            93.3295
trainer/Q Targets Std              5.73824
trainer/Q Targets Max            102.976
trainer/Q Targets Min             62.0425
trainer/Log Pis Mean               0.243248
trainer/Log Pis Std                4.77517
trainer/Log Pis Max               14.657
trainer/Log Pis Min              -12.3371
trainer/Policy mu Mean             0.0228316
trainer/Policy mu Std              1.05857
trainer/Policy mu Max              2.94237
trainer/Policy mu Min             -3.00021
trainer/Policy log std Mean       -0.264535
trainer/Policy log std Std         0.140965
trainer/Policy log std Max         0.220749
trainer/Policy log std Min        -0.827535
trainer/Alpha                      0.0125688
trainer/Alpha Loss               -51.451
exploration/num steps total    81000
exploration/num paths total      162
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.455713
exploration/Rewards Std            0.121471
exploration/Rewards Max            0.935841
exploration/Rewards Min            0.116221
exploration/Returns Mean         227.857
exploration/Returns Std           18.0397
exploration/Returns Max          252.075
exploration/Returns Min          195.514
exploration/Actions Mean           0.0228859
exploration/Actions Std            0.658971
exploration/Actions Max            0.999707
exploration/Actions Min           -0.999723
exploration/Num Paths             10
exploration/Average Returns      227.857
evaluation/num steps total     80000
evaluation/num paths total       160
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.460672
evaluation/Rewards Std             0.113994
evaluation/Rewards Max             0.714907
evaluation/Rewards Min             0.14632
evaluation/Returns Mean          230.336
evaluation/Returns Std            21.2636
evaluation/Returns Max           262.38
evaluation/Returns Min           192.198
evaluation/ExplReturns Mean      230.336
evaluation/ExplReturns Std        21.2636
evaluation/ExplReturns Max       262.38
evaluation/ExplReturns Min       192.198
evaluation/Actions Mean            0.0643944
evaluation/Actions Std             0.535972
evaluation/Actions Max             0.993878
evaluation/Actions Min            -0.996655
evaluation/Num Paths              10
evaluation/Average Returns       230.336
time/data storing (s)              0.0312093
time/evaluation sampling (s)     104.983
time/exploration sampling (s)    110.521
time/logging (s)                   0.0259052
time/saving (s)                    0.0663094
time/training (s)                 10.4124
time/epoch (s)                   226.04
time/total (s)                  3674.34
Epoch                             15
-----------------------------  -------------
2023-08-31 13:00:56.859728 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size             86000
trainer/QF1 Loss                   0.233042
trainer/QF2 Loss                   0.200664
trainer/Policy Loss              -88.6127
trainer/Q1 Predictions Mean       90.8975
trainer/Q1 Predictions Std         6.99881
trainer/Q1 Predictions Max        98.8107
trainer/Q1 Predictions Min        42.9605
trainer/Q2 Predictions Mean       90.9302
trainer/Q2 Predictions Std         6.99569
trainer/Q2 Predictions Max        98.551
trainer/Q2 Predictions Min        43.845
trainer/Q Targets Mean            90.9604
trainer/Q Targets Std              7.11369
trainer/Q Targets Max             98.9243
trainer/Q Targets Min             42.5866
trainer/Log Pis Mean               2.5207
trainer/Log Pis Std                5.82826
trainer/Log Pis Max               32.2775
trainer/Log Pis Min              -13.0311
trainer/Policy mu Mean            -0.00832109
trainer/Policy mu Std              1.20723
trainer/Policy mu Max              4.27195
trainer/Policy mu Min             -3.42162
trainer/Policy log std Mean       -0.280242
trainer/Policy log std Std         0.151569
trainer/Policy log std Max         0.266019
trainer/Policy log std Min        -0.839941
trainer/Alpha                      0.00982198
trainer/Alpha Loss               -43.8218
exploration/num steps total    86000
exploration/num paths total      172
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.390057
exploration/Rewards Std            0.136568
exploration/Rewards Max            0.72922
exploration/Rewards Min            0.0856553
exploration/Returns Mean         195.029
exploration/Returns Std           33.0661
exploration/Returns Max          239.39
exploration/Returns Min          138.248
exploration/Actions Mean           0.0210383
exploration/Actions Std            0.714897
exploration/Actions Max            0.999973
exploration/Actions Min           -0.999842
exploration/Num Paths             10
exploration/Average Returns      195.029
evaluation/num steps total     85000
evaluation/num paths total       170
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.447893
evaluation/Rewards Std             0.124018
evaluation/Rewards Max             0.702197
evaluation/Rewards Min             0.0838
evaluation/Returns Mean          223.947
evaluation/Returns Std            32.8441
evaluation/Returns Max           267.362
evaluation/Returns Min           154.921
evaluation/ExplReturns Mean      223.947
evaluation/ExplReturns Std        32.8441
evaluation/ExplReturns Max       267.362
evaluation/ExplReturns Min       154.921
evaluation/Actions Mean            0.0142589
evaluation/Actions Std             0.628294
evaluation/Actions Max             0.999782
evaluation/Actions Min            -0.998824
evaluation/Num Paths              10
evaluation/Average Returns       223.947
time/data storing (s)              0.0310676
time/evaluation sampling (s)     107.054
time/exploration sampling (s)    114.911
time/logging (s)                   0.026125
time/saving (s)                    0.0861837
time/training (s)                 13.6975
time/epoch (s)                   235.806
time/total (s)                  3910.15
Epoch                             16
-----------------------------  --------------
2023-08-31 13:04:45.501993 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size             91000
trainer/QF1 Loss                   0.240803
trainer/QF2 Loss                   0.237415
trainer/Policy Loss              -84.2962
trainer/Q1 Predictions Mean       88.4391
trainer/Q1 Predictions Std         9.36768
trainer/Q1 Predictions Max        98.1922
trainer/Q1 Predictions Min        41.0358
trainer/Q2 Predictions Mean       88.4983
trainer/Q2 Predictions Std         9.3616
trainer/Q2 Predictions Max        98.0224
trainer/Q2 Predictions Min        41.3602
trainer/Q Targets Mean            88.4081
trainer/Q Targets Std              9.35171
trainer/Q Targets Max             98.0828
trainer/Q Targets Min             40.7335
trainer/Log Pis Mean               4.36892
trainer/Log Pis Std                6.49965
trainer/Log Pis Max               31.4411
trainer/Log Pis Min               -8.64318
trainer/Policy mu Mean            -0.0812256
trainer/Policy mu Std              1.32442
trainer/Policy mu Max              4.09235
trainer/Policy mu Min             -3.91711
trainer/Policy log std Mean       -0.299187
trainer/Policy log std Std         0.176621
trainer/Policy log std Max         0.987391
trainer/Policy log std Min        -0.8944
trainer/Alpha                      0.00779092
trainer/Alpha Loss               -37.0456
exploration/num steps total    91000
exploration/num paths total      182
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.524206
exploration/Rewards Std            0.0971627
exploration/Rewards Max            0.71944
exploration/Rewards Min            0.211762
exploration/Returns Mean         262.103
exploration/Returns Std           25.844
exploration/Returns Max          308.602
exploration/Returns Min          218.194
exploration/Actions Mean          -0.0560485
exploration/Actions Std            0.711053
exploration/Actions Max            0.999932
exploration/Actions Min           -0.999954
exploration/Num Paths             10
exploration/Average Returns      262.103
evaluation/num steps total     90000
evaluation/num paths total       180
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.546862
evaluation/Rewards Std             0.0971037
evaluation/Rewards Max             0.955388
evaluation/Rewards Min             0.107006
evaluation/Returns Mean          273.431
evaluation/Returns Std            29.0104
evaluation/Returns Max           341.703
evaluation/Returns Min           233.702
evaluation/ExplReturns Mean      273.431
evaluation/ExplReturns Std        29.0104
evaluation/ExplReturns Max       341.703
evaluation/ExplReturns Min       233.702
evaluation/Actions Mean           -0.0756544
evaluation/Actions Std             0.649413
evaluation/Actions Max             0.999828
evaluation/Actions Min            -0.999987
evaluation/Num Paths              10
evaluation/Average Returns       273.431
time/data storing (s)              0.0315006
time/evaluation sampling (s)     106.632
time/exploration sampling (s)    111.586
time/logging (s)                   0.0264057
time/saving (s)                    0.0692035
time/training (s)                 10.2939
time/epoch (s)                   228.639
time/total (s)                  4138.79
Epoch                             17
-----------------------------  --------------
2023-08-31 13:08:38.157781 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size             96000
trainer/QF1 Loss                   0.207072
trainer/QF2 Loss                   0.227553
trainer/Policy Loss              -82.0128
trainer/Q1 Predictions Mean       89.0407
trainer/Q1 Predictions Std         6.40448
trainer/Q1 Predictions Max        96.1182
trainer/Q1 Predictions Min        42.2586
trainer/Q2 Predictions Mean       89.0308
trainer/Q2 Predictions Std         6.40867
trainer/Q2 Predictions Max        96.3284
trainer/Q2 Predictions Min        42.2292
trainer/Q Targets Mean            89.1348
trainer/Q Targets Std              6.40602
trainer/Q Targets Max             96.5253
trainer/Q Targets Min             42.5333
trainer/Log Pis Mean               7.24986
trainer/Log Pis Std                6.16874
trainer/Log Pis Max               27.5722
trainer/Log Pis Min               -7.08331
trainer/Policy mu Mean             0.141779
trainer/Policy mu Std              1.45912
trainer/Policy mu Max              4.93853
trainer/Policy mu Min             -3.48791
trainer/Policy log std Mean       -0.356419
trainer/Policy log std Std         0.151538
trainer/Policy log std Max         0.143311
trainer/Policy log std Min        -0.865886
trainer/Alpha                      0.00624574
trainer/Alpha Loss               -24.1102
exploration/num steps total    96000
exploration/num paths total      192
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.594391
exploration/Rewards Std            0.07309
exploration/Rewards Max            0.960627
exploration/Rewards Min            0.264088
exploration/Returns Mean         297.196
exploration/Returns Std           10.4543
exploration/Returns Max          307.044
exploration/Returns Min          276.584
exploration/Actions Mean           0.0616066
exploration/Actions Std            0.713927
exploration/Actions Max            0.999969
exploration/Actions Min           -0.999892
exploration/Num Paths             10
exploration/Average Returns      297.196
evaluation/num steps total     95000
evaluation/num paths total       190
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.574504
evaluation/Rewards Std             0.0669936
evaluation/Rewards Max             0.743179
evaluation/Rewards Min             0.268269
evaluation/Returns Mean          287.252
evaluation/Returns Std            13.9334
evaluation/Returns Max           306.289
evaluation/Returns Min           263.266
evaluation/ExplReturns Mean      287.252
evaluation/ExplReturns Std        13.9334
evaluation/ExplReturns Max       306.289
evaluation/ExplReturns Min       263.266
evaluation/Actions Mean            0.069477
evaluation/Actions Std             0.671176
evaluation/Actions Max             0.999753
evaluation/Actions Min            -0.99897
evaluation/Num Paths              10
evaluation/Average Returns       287.252
time/data storing (s)              0.0318093
time/evaluation sampling (s)     107.776
time/exploration sampling (s)    111.754
time/logging (s)                   0.0264743
time/saving (s)                    0.0752878
time/training (s)                 12.9888
time/epoch (s)                   232.652
time/total (s)                  4371.45
Epoch                             18
-----------------------------  --------------
2023-08-31 13:12:24.818628 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 19 finished
-----------------------------  ---------------
replay_buffer/size             101000
trainer/QF1 Loss                    0.22885
trainer/QF2 Loss                    0.259922
trainer/Policy Loss               -79.1309
trainer/Q1 Predictions Mean        87.0498
trainer/Q1 Predictions Std          6.99792
trainer/Q1 Predictions Max         95.2744
trainer/Q1 Predictions Min         42.4701
trainer/Q2 Predictions Mean        86.9989
trainer/Q2 Predictions Std          6.9629
trainer/Q2 Predictions Max         95.0494
trainer/Q2 Predictions Min         42.5447
trainer/Q Targets Mean             87.0307
trainer/Q Targets Std               7.05585
trainer/Q Targets Max              95.048
trainer/Q Targets Min              42.5479
trainer/Log Pis Mean                8.09596
trainer/Log Pis Std                 6.81191
trainer/Log Pis Max                38.9498
trainer/Log Pis Min                -6.87482
trainer/Policy mu Mean              0.207112
trainer/Policy mu Std               1.52685
trainer/Policy mu Max               4.54297
trainer/Policy mu Min              -3.91432
trainer/Policy log std Mean        -0.342651
trainer/Policy log std Std          0.153197
trainer/Policy log std Max          0.275383
trainer/Policy log std Min         -0.832964
trainer/Alpha                       0.00518575
trainer/Alpha Loss                -20.5418
exploration/num steps total    101000
exploration/num paths total       202
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.363459
exploration/Rewards Std             0.115974
exploration/Rewards Max             0.725897
exploration/Rewards Min             0.0485173
exploration/Returns Mean          181.73
exploration/Returns Std            25.7789
exploration/Returns Max           256.013
exploration/Returns Min           163.047
exploration/Actions Mean            0.0584823
exploration/Actions Std             0.708804
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999903
exploration/Num Paths              10
exploration/Average Returns       181.73
evaluation/num steps total     100000
evaluation/num paths total        200
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.344326
evaluation/Rewards Std              0.103946
evaluation/Rewards Max              0.713941
evaluation/Rewards Min              0.072596
evaluation/Returns Mean           172.163
evaluation/Returns Std             16.074
evaluation/Returns Max            215.22
evaluation/Returns Min            149.688
evaluation/ExplReturns Mean       172.163
evaluation/ExplReturns Std         16.074
evaluation/ExplReturns Max        215.22
evaluation/ExplReturns Min        149.688
evaluation/Actions Mean             0.0856512
evaluation/Actions Std              0.654354
evaluation/Actions Max              0.999979
evaluation/Actions Min             -0.999946
evaluation/Num Paths               10
evaluation/Average Returns        172.163
time/data storing (s)               0.0310634
time/evaluation sampling (s)      106.332
time/exploration sampling (s)     109.625
time/logging (s)                    0.0260288
time/saving (s)                     0.0688135
time/training (s)                  10.5745
time/epoch (s)                    226.657
time/total (s)                   4598.1
Epoch                              19
-----------------------------  ---------------
2023-08-31 13:16:13.954589 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             106000
trainer/QF1 Loss                    0.313687
trainer/QF2 Loss                    0.266678
trainer/Policy Loss               -73.01
trainer/Q1 Predictions Mean        84.8161
trainer/Q1 Predictions Std          8.58133
trainer/Q1 Predictions Max         94.388
trainer/Q1 Predictions Min         42.541
trainer/Q2 Predictions Mean        84.7909
trainer/Q2 Predictions Std          8.60344
trainer/Q2 Predictions Max         93.9393
trainer/Q2 Predictions Min         42.7936
trainer/Q Targets Mean             84.7307
trainer/Q Targets Std               8.56617
trainer/Q Targets Max              93.8224
trainer/Q Targets Min              42.7343
trainer/Log Pis Mean               12.0522
trainer/Log Pis Std                 9.65603
trainer/Log Pis Max                54.0616
trainer/Log Pis Min                -6.86176
trainer/Policy mu Mean              0.0249555
trainer/Policy mu Std               1.73002
trainer/Policy mu Max               5.72832
trainer/Policy mu Min              -5.5198
trainer/Policy log std Mean        -0.382161
trainer/Policy log std Std          0.142739
trainer/Policy log std Max          0.612981
trainer/Policy log std Min         -1.09392
trainer/Alpha                       0.0045324
trainer/Alpha Loss                  0.28154
exploration/num steps total    106000
exploration/num paths total       212
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.429806
exploration/Rewards Std             0.131855
exploration/Rewards Max             0.740224
exploration/Rewards Min             0.122614
exploration/Returns Mean          214.903
exploration/Returns Std            31.4969
exploration/Returns Max           254.618
exploration/Returns Min           149.723
exploration/Actions Mean           -0.0505312
exploration/Actions Std             0.727742
exploration/Actions Max             0.999979
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns       214.903
evaluation/num steps total     105000
evaluation/num paths total        210
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.460447
evaluation/Rewards Std              0.118682
evaluation/Rewards Max              0.728469
evaluation/Rewards Min              0.116484
evaluation/Returns Mean           230.223
evaluation/Returns Std             30.8788
evaluation/Returns Max            257.433
evaluation/Returns Min            156.588
evaluation/ExplReturns Mean       230.223
evaluation/ExplReturns Std         30.8788
evaluation/ExplReturns Max        257.433
evaluation/ExplReturns Min        156.588
evaluation/Actions Mean            -0.0287149
evaluation/Actions Std              0.681375
evaluation/Actions Max              0.999836
evaluation/Actions Min             -0.999996
evaluation/Num Paths               10
evaluation/Average Returns        230.223
time/data storing (s)               0.0313409
time/evaluation sampling (s)      106.465
time/exploration sampling (s)     110.907
time/logging (s)                    0.0261963
time/saving (s)                     0.066205
time/training (s)                  11.6377
time/epoch (s)                    229.133
time/total (s)                   4827.24
Epoch                              20
-----------------------------  --------------
2023-08-31 13:20:01.486526 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 21 finished
-----------------------------  ---------------
replay_buffer/size             111000
trainer/QF1 Loss                    0.242898
trainer/QF2 Loss                    0.261662
trainer/Policy Loss               -72.558
trainer/Q1 Predictions Mean        83.4367
trainer/Q1 Predictions Std          8.85537
trainer/Q1 Predictions Max         92.7542
trainer/Q1 Predictions Min         37.8059
trainer/Q2 Predictions Mean        83.3824
trainer/Q2 Predictions Std          8.87662
trainer/Q2 Predictions Max         92.6884
trainer/Q2 Predictions Min         37.6499
trainer/Q Targets Mean             83.6178
trainer/Q Targets Std               8.90423
trainer/Q Targets Max              93.1444
trainer/Q Targets Min              37.6585
trainer/Log Pis Mean               11.0838
trainer/Log Pis Std                 8.53016
trainer/Log Pis Max                50.4825
trainer/Log Pis Min                -6.8857
trainer/Policy mu Mean             -0.00886229
trainer/Policy mu Std               1.68938
trainer/Policy mu Max               4.92604
trainer/Policy mu Min              -6.77202
trainer/Policy log std Mean        -0.365333
trainer/Policy log std Std          0.135808
trainer/Policy log std Max          0.40142
trainer/Policy log std Min         -0.852081
trainer/Alpha                       0.00442783
trainer/Alpha Loss                 -4.96573
exploration/num steps total    111000
exploration/num paths total       222
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.500925
exploration/Rewards Std             0.0958846
exploration/Rewards Max             0.733585
exploration/Rewards Min             0.209172
exploration/Returns Mean          250.462
exploration/Returns Std            20.0362
exploration/Returns Max           281.14
exploration/Returns Min           212.597
exploration/Actions Mean           -0.0957286
exploration/Actions Std             0.728519
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999952
exploration/Num Paths              10
exploration/Average Returns       250.462
evaluation/num steps total     110000
evaluation/num paths total        220
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.522295
evaluation/Rewards Std              0.0872142
evaluation/Rewards Max              0.730597
evaluation/Rewards Min              0.253895
evaluation/Returns Mean           261.148
evaluation/Returns Std             20.7369
evaluation/Returns Max            283.241
evaluation/Returns Min            213.923
evaluation/ExplReturns Mean       261.148
evaluation/ExplReturns Std         20.7369
evaluation/ExplReturns Max        283.241
evaluation/ExplReturns Min        213.923
evaluation/Actions Mean            -0.0972165
evaluation/Actions Std              0.695041
evaluation/Actions Max              0.99977
evaluation/Actions Min             -0.999915
evaluation/Num Paths               10
evaluation/Average Returns        261.148
time/data storing (s)               0.0321975
time/evaluation sampling (s)      105.719
time/exploration sampling (s)     111.614
time/logging (s)                    0.0266048
time/saving (s)                     0.0647718
time/training (s)                  10.072
time/epoch (s)                    227.529
time/total (s)                   5054.77
Epoch                              21
-----------------------------  ---------------
2023-08-31 13:23:46.227691 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 22 finished
-----------------------------  ---------------
replay_buffer/size             116000
trainer/QF1 Loss                    0.279968
trainer/QF2 Loss                    0.310539
trainer/Policy Loss               -73.0035
trainer/Q1 Predictions Mean        83.2593
trainer/Q1 Predictions Std          7.42682
trainer/Q1 Predictions Max         92.2112
trainer/Q1 Predictions Min         41.0316
trainer/Q2 Predictions Mean        83.337
trainer/Q2 Predictions Std          7.39849
trainer/Q2 Predictions Max         92.3997
trainer/Q2 Predictions Min         41.1877
trainer/Q Targets Mean             83.0695
trainer/Q Targets Std               7.52191
trainer/Q Targets Max              92.1353
trainer/Q Targets Min              38.9857
trainer/Log Pis Mean               10.5354
trainer/Log Pis Std                 8.3283
trainer/Log Pis Max                62.688
trainer/Log Pis Min                -7.16165
trainer/Policy mu Mean              0.165601
trainer/Policy mu Std               1.66707
trainer/Policy mu Max               6.43496
trainer/Policy mu Min              -6.0515
trainer/Policy log std Mean        -0.351505
trainer/Policy log std Std          0.145264
trainer/Policy log std Max          0.44135
trainer/Policy log std Min         -0.885358
trainer/Alpha                       0.00425414
trainer/Alpha Loss                 -7.99618
exploration/num steps total    116000
exploration/num paths total       232
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.423049
exploration/Rewards Std             0.131123
exploration/Rewards Max             0.722861
exploration/Rewards Min             0.0902283
exploration/Returns Mean          211.525
exploration/Returns Std            23.1511
exploration/Returns Max           266.769
exploration/Returns Min           184.593
exploration/Actions Mean            0.0967594
exploration/Actions Std             0.709109
exploration/Actions Max             1
exploration/Actions Min            -0.999992
exploration/Num Paths              10
exploration/Average Returns       211.525
evaluation/num steps total     115000
evaluation/num paths total        230
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.420355
evaluation/Rewards Std              0.115553
evaluation/Rewards Max              0.679811
evaluation/Rewards Min              0.048758
evaluation/Returns Mean           210.177
evaluation/Returns Std             18.2237
evaluation/Returns Max            241.342
evaluation/Returns Min            183.912
evaluation/ExplReturns Mean       210.177
evaluation/ExplReturns Std         18.2237
evaluation/ExplReturns Max        241.342
evaluation/ExplReturns Min        183.912
evaluation/Actions Mean             0.179207
evaluation/Actions Std              0.654994
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999996
evaluation/Num Paths               10
evaluation/Average Returns        210.177
time/data storing (s)               0.0309971
time/evaluation sampling (s)      104.442
time/exploration sampling (s)     109.844
time/logging (s)                    0.0274646
time/saving (s)                     0.0736009
time/training (s)                  10.3211
time/epoch (s)                    224.738
time/total (s)                   5279.51
Epoch                              22
-----------------------------  ---------------
2023-08-31 13:27:36.910306 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 23 finished
-----------------------------  ---------------
replay_buffer/size             121000
trainer/QF1 Loss                    0.194418
trainer/QF2 Loss                    0.209074
trainer/Policy Loss               -71.4053
trainer/Q1 Predictions Mean        81.6762
trainer/Q1 Predictions Std          8.32293
trainer/Q1 Predictions Max         90.7822
trainer/Q1 Predictions Min         42.4351
trainer/Q2 Predictions Mean        81.5878
trainer/Q2 Predictions Std          8.33587
trainer/Q2 Predictions Max         90.4893
trainer/Q2 Predictions Min         42.4658
trainer/Q Targets Mean             81.7257
trainer/Q Targets Std               8.31208
trainer/Q Targets Max              91.153
trainer/Q Targets Min              42.5749
trainer/Log Pis Mean               10.4361
trainer/Log Pis Std                 7.76818
trainer/Log Pis Max                36.472
trainer/Log Pis Min                -7.33671
trainer/Policy mu Mean              0.0308116
trainer/Policy mu Std               1.67243
trainer/Policy mu Max               4.41104
trainer/Policy mu Min              -4.46552
trainer/Policy log std Mean        -0.36199
trainer/Policy log std Std          0.138137
trainer/Policy log std Max          0.148428
trainer/Policy log std Min         -0.90615
trainer/Alpha                       0.00427132
trainer/Alpha Loss                 -8.53238
exploration/num steps total    121000
exploration/num paths total       242
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.506551
exploration/Rewards Std             0.0987196
exploration/Rewards Max             0.721551
exploration/Rewards Min             0.153851
exploration/Returns Mean          253.275
exploration/Returns Std            24.0415
exploration/Returns Max           301.903
exploration/Returns Min           228.292
exploration/Actions Mean            0.0231389
exploration/Actions Std             0.726092
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns       253.275
evaluation/num steps total     120000
evaluation/num paths total        240
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.496667
evaluation/Rewards Std              0.104229
evaluation/Rewards Max              0.938649
evaluation/Rewards Min              0.198201
evaluation/Returns Mean           248.334
evaluation/Returns Std             16.53
evaluation/Returns Max            292.765
evaluation/Returns Min            231.418
evaluation/ExplReturns Mean       248.334
evaluation/ExplReturns Std         16.53
evaluation/ExplReturns Max        292.765
evaluation/ExplReturns Min        231.418
evaluation/Actions Mean             0.0304976
evaluation/Actions Std              0.663191
evaluation/Actions Max              0.999975
evaluation/Actions Min             -0.999926
evaluation/Num Paths               10
evaluation/Average Returns        248.334
time/data storing (s)               0.0312147
time/evaluation sampling (s)      107.043
time/exploration sampling (s)     113.725
time/logging (s)                    0.026878
time/saving (s)                     0.0914216
time/training (s)                   9.76085
time/epoch (s)                    230.679
time/total (s)                   5510.19
Epoch                              23
-----------------------------  ---------------
2023-08-31 13:31:23.544703 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 24 finished
-----------------------------  ---------------
replay_buffer/size             126000
trainer/QF1 Loss                    0.207793
trainer/QF2 Loss                    0.220315
trainer/Policy Loss               -68.5962
trainer/Q1 Predictions Mean        81.0136
trainer/Q1 Predictions Std          7.69218
trainer/Q1 Predictions Max         90.1241
trainer/Q1 Predictions Min         46.2669
trainer/Q2 Predictions Mean        80.886
trainer/Q2 Predictions Std          7.71115
trainer/Q2 Predictions Max         90.2742
trainer/Q2 Predictions Min         46.2035
trainer/Q Targets Mean             80.9353
trainer/Q Targets Std               7.6619
trainer/Q Targets Max              90.3541
trainer/Q Targets Min              45.6066
trainer/Log Pis Mean               12.5235
trainer/Log Pis Std                 9.60389
trainer/Log Pis Max                52.3022
trainer/Log Pis Min                -5.7146
trainer/Policy mu Mean              0.0134917
trainer/Policy mu Std               1.77123
trainer/Policy mu Max               5.17063
trainer/Policy mu Min              -5.89346
trainer/Policy log std Mean        -0.352892
trainer/Policy log std Std          0.151418
trainer/Policy log std Max          0.285254
trainer/Policy log std Min         -0.977032
trainer/Alpha                       0.00402241
trainer/Alpha Loss                  2.88786
exploration/num steps total    126000
exploration/num paths total       252
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.48885
exploration/Rewards Std             0.0833183
exploration/Rewards Max             0.699213
exploration/Rewards Min             0.167494
exploration/Returns Mean          244.425
exploration/Returns Std             8.15588
exploration/Returns Max           259.715
exploration/Returns Min           229.681
exploration/Actions Mean            0.0989003
exploration/Actions Std             0.738788
exploration/Actions Max             0.999989
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       244.425
evaluation/num steps total     125000
evaluation/num paths total        250
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.502402
evaluation/Rewards Std              0.0887769
evaluation/Rewards Max              0.959036
evaluation/Rewards Min              0.229896
evaluation/Returns Mean           251.201
evaluation/Returns Std             14.6788
evaluation/Returns Max            274.79
evaluation/Returns Min            234.804
evaluation/ExplReturns Mean       251.201
evaluation/ExplReturns Std         14.6788
evaluation/ExplReturns Max        274.79
evaluation/ExplReturns Min        234.804
evaluation/Actions Mean             0.0853532
evaluation/Actions Std              0.702193
evaluation/Actions Max              0.999757
evaluation/Actions Min             -0.999879
evaluation/Num Paths               10
evaluation/Average Returns        251.201
time/data storing (s)               0.0313459
time/evaluation sampling (s)      105.889
time/exploration sampling (s)     110.417
time/logging (s)                    0.0261944
time/saving (s)                     0.0720156
time/training (s)                  10.1944
time/epoch (s)                    226.63
time/total (s)                   5736.83
Epoch                              24
-----------------------------  ---------------
2023-08-31 13:35:11.286637 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 25 finished
-----------------------------  ---------------
replay_buffer/size             131000
trainer/QF1 Loss                    0.270614
trainer/QF2 Loss                    0.233091
trainer/Policy Loss               -67.658
trainer/Q1 Predictions Mean        79.5554
trainer/Q1 Predictions Std          6.70093
trainer/Q1 Predictions Max         88.3224
trainer/Q1 Predictions Min         47.3665
trainer/Q2 Predictions Mean        79.5834
trainer/Q2 Predictions Std          6.7195
trainer/Q2 Predictions Max         88.4322
trainer/Q2 Predictions Min         47.3015
trainer/Q Targets Mean             79.4051
trainer/Q Targets Std               6.75233
trainer/Q Targets Max              88.1966
trainer/Q Targets Min              48.0522
trainer/Log Pis Mean               12.0684
trainer/Log Pis Std                 9.15223
trainer/Log Pis Max                46.3628
trainer/Log Pis Min                -8.82686
trainer/Policy mu Mean             -0.0345969
trainer/Policy mu Std               1.7699
trainer/Policy mu Max               6.35655
trainer/Policy mu Min              -5.47668
trainer/Policy log std Mean        -0.361525
trainer/Policy log std Std          0.133497
trainer/Policy log std Max          0.315414
trainer/Policy log std Min         -0.866708
trainer/Alpha                       0.00388872
trainer/Alpha Loss                  0.379374
exploration/num steps total    131000
exploration/num paths total       262
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.531314
exploration/Rewards Std             0.0913189
exploration/Rewards Max             0.731367
exploration/Rewards Min             0.160643
exploration/Returns Mean          265.657
exploration/Returns Std            16.7321
exploration/Returns Max           279.209
exploration/Returns Min           219.818
exploration/Actions Mean            0.0771706
exploration/Actions Std             0.735101
exploration/Actions Max             0.999976
exploration/Actions Min            -0.999975
exploration/Num Paths              10
exploration/Average Returns       265.657
evaluation/num steps total     130000
evaluation/num paths total        260
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.537295
evaluation/Rewards Std              0.0769522
evaluation/Rewards Max              0.948196
evaluation/Rewards Min              0.249211
evaluation/Returns Mean           268.648
evaluation/Returns Std             10.0943
evaluation/Returns Max            289.047
evaluation/Returns Min            250.858
evaluation/ExplReturns Mean       268.648
evaluation/ExplReturns Std         10.0943
evaluation/ExplReturns Max        289.047
evaluation/ExplReturns Min        250.858
evaluation/Actions Mean             0.078
evaluation/Actions Std              0.701727
evaluation/Actions Max              0.999939
evaluation/Actions Min             -0.999828
evaluation/Num Paths               10
evaluation/Average Returns        268.648
time/data storing (s)               0.0310765
time/evaluation sampling (s)      105.867
time/exploration sampling (s)     111.497
time/logging (s)                    0.0265911
time/saving (s)                     0.0723387
time/training (s)                  10.2445
time/epoch (s)                    227.739
time/total (s)                   5964.57
Epoch                              25
-----------------------------  ---------------
2023-08-31 13:38:57.749388 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 26 finished
-----------------------------  ---------------
replay_buffer/size             136000
trainer/QF1 Loss                    0.25522
trainer/QF2 Loss                    0.213972
trainer/Policy Loss               -69.1659
trainer/Q1 Predictions Mean        78.8376
trainer/Q1 Predictions Std          6.13974
trainer/Q1 Predictions Max         87.1547
trainer/Q1 Predictions Min         46.5942
trainer/Q2 Predictions Mean        78.9429
trainer/Q2 Predictions Std          6.16132
trainer/Q2 Predictions Max         87.5345
trainer/Q2 Predictions Min         47.2302
trainer/Q Targets Mean             79.0175
trainer/Q Targets Std               6.18125
trainer/Q Targets Max              87.7236
trainer/Q Targets Min              47.1268
trainer/Log Pis Mean                9.88633
trainer/Log Pis Std                 8.70617
trainer/Log Pis Max                45.3898
trainer/Log Pis Min                -9.49704
trainer/Policy mu Mean             -0.167307
trainer/Policy mu Std               1.65689
trainer/Policy mu Max               5.5813
trainer/Policy mu Min              -5.52807
trainer/Policy log std Mean        -0.327196
trainer/Policy log std Std          0.138714
trainer/Policy log std Max          0.318729
trainer/Policy log std Min         -0.946566
trainer/Alpha                       0.00379526
trainer/Alpha Loss                -11.7812
exploration/num steps total    136000
exploration/num paths total       272
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.5472
exploration/Rewards Std             0.0954378
exploration/Rewards Max             0.943879
exploration/Rewards Min             0.203998
exploration/Returns Mean          273.6
exploration/Returns Std            28.3397
exploration/Returns Max           321.177
exploration/Returns Min           223.59
exploration/Actions Mean           -0.035242
exploration/Actions Std             0.736006
exploration/Actions Max             0.999984
exploration/Actions Min            -0.999959
exploration/Num Paths              10
exploration/Average Returns       273.6
evaluation/num steps total     135000
evaluation/num paths total        270
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.550611
evaluation/Rewards Std              0.0951406
evaluation/Rewards Max              0.977659
evaluation/Rewards Min              0.164698
evaluation/Returns Mean           275.306
evaluation/Returns Std             22.7991
evaluation/Returns Max            327.173
evaluation/Returns Min            238.042
evaluation/ExplReturns Mean       275.306
evaluation/ExplReturns Std         22.7991
evaluation/ExplReturns Max        327.173
evaluation/ExplReturns Min        238.042
evaluation/Actions Mean            -0.0368934
evaluation/Actions Std              0.687029
evaluation/Actions Max              0.99989
evaluation/Actions Min             -0.999929
evaluation/Num Paths               10
evaluation/Average Returns        275.306
time/data storing (s)               0.0311038
time/evaluation sampling (s)      106.008
time/exploration sampling (s)     109.956
time/logging (s)                    0.0265455
time/saving (s)                     0.076048
time/training (s)                  10.3617
time/epoch (s)                    226.459
time/total (s)                   6191.03
Epoch                              26
-----------------------------  ---------------
2023-08-31 13:42:52.769925 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 27 finished
-----------------------------  ---------------
replay_buffer/size             141000
trainer/QF1 Loss                    0.17141
trainer/QF2 Loss                    0.163492
trainer/Policy Loss               -66.1512
trainer/Q1 Predictions Mean        77.5786
trainer/Q1 Predictions Std          6.60821
trainer/Q1 Predictions Max         85.4321
trainer/Q1 Predictions Min         49.3513
trainer/Q2 Predictions Mean        77.4943
trainer/Q2 Predictions Std          6.63713
trainer/Q2 Predictions Max         85.2323
trainer/Q2 Predictions Min         48.5829
trainer/Q Targets Mean             77.6315
trainer/Q Targets Std               6.63684
trainer/Q Targets Max              85.2786
trainer/Q Targets Min              48.5616
trainer/Log Pis Mean               11.5067
trainer/Log Pis Std                 8.27446
trainer/Log Pis Max                46.5383
trainer/Log Pis Min                -8.60325
trainer/Policy mu Mean             -0.0675604
trainer/Policy mu Std               1.71765
trainer/Policy mu Max               5.90798
trainer/Policy mu Min              -4.53388
trainer/Policy log std Mean        -0.355737
trainer/Policy log std Std          0.133363
trainer/Policy log std Max          0.421974
trainer/Policy log std Min         -0.910324
trainer/Alpha                       0.003799
trainer/Alpha Loss                 -2.74929
exploration/num steps total    141000
exploration/num paths total       282
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.603007
exploration/Rewards Std             0.0750974
exploration/Rewards Max             0.931234
exploration/Rewards Min             0.299108
exploration/Returns Mean          301.503
exploration/Returns Std            15.4205
exploration/Returns Max           334.19
exploration/Returns Min           281.62
exploration/Actions Mean            0.00730451
exploration/Actions Std             0.73916
exploration/Actions Max             0.999949
exploration/Actions Min            -0.999984
exploration/Num Paths              10
exploration/Average Returns       301.503
evaluation/num steps total     140000
evaluation/num paths total        280
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.614631
evaluation/Rewards Std              0.0713056
evaluation/Rewards Max              0.936599
evaluation/Rewards Min              0.304898
evaluation/Returns Mean           307.316
evaluation/Returns Std             12.1454
evaluation/Returns Max            334.872
evaluation/Returns Min            295.242
evaluation/ExplReturns Mean       307.316
evaluation/ExplReturns Std         12.1454
evaluation/ExplReturns Max        334.872
evaluation/ExplReturns Min        295.242
evaluation/Actions Mean             0.0096289
evaluation/Actions Std              0.717772
evaluation/Actions Max              0.999599
evaluation/Actions Min             -0.999829
evaluation/Num Paths               10
evaluation/Average Returns        307.316
time/data storing (s)               0.0313908
time/evaluation sampling (s)      108.318
time/exploration sampling (s)     112.83
time/logging (s)                    0.0259851
time/saving (s)                     0.0653633
time/training (s)                  13.7457
time/epoch (s)                    235.016
time/total (s)                   6426.05
Epoch                              27
-----------------------------  ---------------
2023-08-31 13:46:39.547279 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             146000
trainer/QF1 Loss                    0.196748
trainer/QF2 Loss                    0.178466
trainer/Policy Loss               -66.412
trainer/Q1 Predictions Mean        76.679
trainer/Q1 Predictions Std          6.57929
trainer/Q1 Predictions Max         85.249
trainer/Q1 Predictions Min         44.9058
trainer/Q2 Predictions Mean        76.7261
trainer/Q2 Predictions Std          6.57767
trainer/Q2 Predictions Max         85.347
trainer/Q2 Predictions Min         44.7714
trainer/Q Targets Mean             76.7111
trainer/Q Targets Std               6.55099
trainer/Q Targets Max              85.439
trainer/Q Targets Min              44.9412
trainer/Log Pis Mean               10.4371
trainer/Log Pis Std                 8.51236
trainer/Log Pis Max                50.0894
trainer/Log Pis Min                -4.90388
trainer/Policy mu Mean             -0.0696975
trainer/Policy mu Std               1.67026
trainer/Policy mu Max               4.5579
trainer/Policy mu Min              -5.49348
trainer/Policy log std Mean        -0.345206
trainer/Policy log std Std          0.137662
trainer/Policy log std Max          0.166864
trainer/Policy log std Min         -0.964435
trainer/Alpha                       0.003649
trainer/Alpha Loss                 -8.77242
exploration/num steps total    146000
exploration/num paths total       292
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.500767
exploration/Rewards Std             0.097308
exploration/Rewards Max             0.95331
exploration/Rewards Min             0.0778754
exploration/Returns Mean          250.384
exploration/Returns Std            16.1555
exploration/Returns Max           280.619
exploration/Returns Min           224.024
exploration/Actions Mean            0.0351491
exploration/Actions Std             0.739428
exploration/Actions Max             1
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns       250.384
evaluation/num steps total     145000
evaluation/num paths total        290
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.511578
evaluation/Rewards Std              0.0859253
evaluation/Rewards Max              0.725042
evaluation/Rewards Min              0.106889
evaluation/Returns Mean           255.789
evaluation/Returns Std             17.3476
evaluation/Returns Max            286.55
evaluation/Returns Min            234.237
evaluation/ExplReturns Mean       255.789
evaluation/ExplReturns Std         17.3476
evaluation/ExplReturns Max        286.55
evaluation/ExplReturns Min        234.237
evaluation/Actions Mean             0.0377324
evaluation/Actions Std              0.697841
evaluation/Actions Max              0.99998
evaluation/Actions Min             -0.999916
evaluation/Num Paths               10
evaluation/Average Returns        255.789
time/data storing (s)               0.0315173
time/evaluation sampling (s)      105.443
time/exploration sampling (s)     111.152
time/logging (s)                    0.0266811
time/saving (s)                     0.0755526
time/training (s)                  10.0461
time/epoch (s)                    226.775
time/total (s)                   6652.83
Epoch                              28
-----------------------------  --------------
2023-08-31 13:50:28.420967 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 29 finished
-----------------------------  ---------------
replay_buffer/size             151000
trainer/QF1 Loss                    0.20631
trainer/QF2 Loss                    0.169895
trainer/Policy Loss               -64.9108
trainer/Q1 Predictions Mean        75.6747
trainer/Q1 Predictions Std          6.52984
trainer/Q1 Predictions Max         84.3036
trainer/Q1 Predictions Min         44.2511
trainer/Q2 Predictions Mean        75.5793
trainer/Q2 Predictions Std          6.52906
trainer/Q2 Predictions Max         84.1316
trainer/Q2 Predictions Min         43.7261
trainer/Q Targets Mean             75.5613
trainer/Q Targets Std               6.4932
trainer/Q Targets Max              84.3372
trainer/Q Targets Min              44.1358
trainer/Log Pis Mean               10.8201
trainer/Log Pis Std                10.1438
trainer/Log Pis Max                67.2239
trainer/Log Pis Min                -7.84785
trainer/Policy mu Mean             -0.00682928
trainer/Policy mu Std               1.70081
trainer/Policy mu Max               7.24485
trainer/Policy mu Min              -6.82661
trainer/Policy log std Mean        -0.35335
trainer/Policy log std Std          0.141019
trainer/Policy log std Max          0.176956
trainer/Policy log std Min         -1.04171
trainer/Alpha                       0.00353414
trainer/Alpha Loss                 -6.66052
exploration/num steps total    151000
exploration/num paths total       302
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.517978
exploration/Rewards Std             0.105422
exploration/Rewards Max             0.96834
exploration/Rewards Min             0.191436
exploration/Returns Mean          258.989
exploration/Returns Std            26.1036
exploration/Returns Max           304.578
exploration/Returns Min           204.866
exploration/Actions Mean           -0.00363177
exploration/Actions Std             0.733395
exploration/Actions Max             0.999975
exploration/Actions Min            -0.999952
exploration/Num Paths              10
exploration/Average Returns       258.989
evaluation/num steps total     150000
evaluation/num paths total        300
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.534145
evaluation/Rewards Std              0.0682644
evaluation/Rewards Max              0.73568
evaluation/Rewards Min              0.298251
evaluation/Returns Mean           267.072
evaluation/Returns Std              9.83306
evaluation/Returns Max            285.303
evaluation/Returns Min            250.741
evaluation/ExplReturns Mean       267.072
evaluation/ExplReturns Std          9.83306
evaluation/ExplReturns Max        285.303
evaluation/ExplReturns Min        250.741
evaluation/Actions Mean             0.0579079
evaluation/Actions Std              0.704874
evaluation/Actions Max              0.999839
evaluation/Actions Min             -0.999707
evaluation/Num Paths               10
evaluation/Average Returns        267.072
time/data storing (s)               0.0310158
time/evaluation sampling (s)      106.851
time/exploration sampling (s)     111.611
time/logging (s)                    0.0264454
time/saving (s)                     0.0824327
time/training (s)                  10.2681
time/epoch (s)                    228.87
time/total (s)                   6881.7
Epoch                              29
-----------------------------  ---------------
2023-08-31 13:54:19.977562 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 30 finished
-----------------------------  ---------------
replay_buffer/size             156000
trainer/QF1 Loss                    0.186591
trainer/QF2 Loss                    0.184797
trainer/Policy Loss               -63.2656
trainer/Q1 Predictions Mean        74.8374
trainer/Q1 Predictions Std          5.38865
trainer/Q1 Predictions Max         82.1473
trainer/Q1 Predictions Min         46.9515
trainer/Q2 Predictions Mean        74.8716
trainer/Q2 Predictions Std          5.36046
trainer/Q2 Predictions Max         82.1501
trainer/Q2 Predictions Min         46.9831
trainer/Q Targets Mean             74.8636
trainer/Q Targets Std               5.36649
trainer/Q Targets Max              82.4328
trainer/Q Targets Min              47.5154
trainer/Log Pis Mean               11.7052
trainer/Log Pis Std                 8.37858
trainer/Log Pis Max                42.8844
trainer/Log Pis Min                -8.99827
trainer/Policy mu Mean             -0.20839
trainer/Policy mu Std               1.7072
trainer/Policy mu Max               4.97564
trainer/Policy mu Min              -5.32056
trainer/Policy log std Mean        -0.360765
trainer/Policy log std Std          0.150391
trainer/Policy log std Max          0.220847
trainer/Policy log std Min         -0.868456
trainer/Alpha                       0.00360629
trainer/Alpha Loss                 -1.65818
exploration/num steps total    156000
exploration/num paths total       312
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.545769
exploration/Rewards Std             0.0646086
exploration/Rewards Max             0.717036
exploration/Rewards Min             0.3322
exploration/Returns Mean          272.885
exploration/Returns Std             7.59653
exploration/Returns Max           285.216
exploration/Returns Min           264.595
exploration/Actions Mean           -0.0327827
exploration/Actions Std             0.716367
exploration/Actions Max             0.999955
exploration/Actions Min            -0.999901
exploration/Num Paths              10
exploration/Average Returns       272.885
evaluation/num steps total     155000
evaluation/num paths total        310
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.566618
evaluation/Rewards Std              0.0796314
evaluation/Rewards Max              0.954497
evaluation/Rewards Min              0.300445
evaluation/Returns Mean           283.309
evaluation/Returns Std             13.3477
evaluation/Returns Max            302.92
evaluation/Returns Min            259.42
evaluation/ExplReturns Mean       283.309
evaluation/ExplReturns Std         13.3477
evaluation/ExplReturns Max        302.92
evaluation/ExplReturns Min        259.42
evaluation/Actions Mean            -0.047253
evaluation/Actions Std              0.698157
evaluation/Actions Max              0.999498
evaluation/Actions Min             -0.999339
evaluation/Num Paths               10
evaluation/Average Returns        283.309
time/data storing (s)               0.0312008
time/evaluation sampling (s)      107.784
time/exploration sampling (s)     113.538
time/logging (s)                    0.0267091
time/saving (s)                     0.0749349
time/training (s)                  10.099
time/epoch (s)                    231.553
time/total (s)                   7113.26
Epoch                              30
-----------------------------  ---------------
2023-08-31 13:58:06.717833 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 31 finished
-----------------------------  ----------------
replay_buffer/size             161000
trainer/QF1 Loss                    0.162401
trainer/QF2 Loss                    0.153395
trainer/Policy Loss               -62.8043
trainer/Q1 Predictions Mean        74.811
trainer/Q1 Predictions Std          4.80498
trainer/Q1 Predictions Max         81.4558
trainer/Q1 Predictions Min         44.6631
trainer/Q2 Predictions Mean        74.7659
trainer/Q2 Predictions Std          4.80191
trainer/Q2 Predictions Max         81.3188
trainer/Q2 Predictions Min         44.7362
trainer/Q Targets Mean             74.7849
trainer/Q Targets Std               4.81105
trainer/Q Targets Max              81.4614
trainer/Q Targets Min              44.702
trainer/Log Pis Mean               12.0806
trainer/Log Pis Std                 8.73333
trainer/Log Pis Max                43.7189
trainer/Log Pis Min                -5.99196
trainer/Policy mu Mean             -0.0130972
trainer/Policy mu Std               1.72137
trainer/Policy mu Max               4.86824
trainer/Policy mu Min              -7.10105
trainer/Policy log std Mean        -0.357381
trainer/Policy log std Std          0.144297
trainer/Policy log std Max          0.183431
trainer/Policy log std Min         -1.08617
trainer/Alpha                       0.00349886
trainer/Alpha Loss                  0.4556
exploration/num steps total    161000
exploration/num paths total       322
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.518506
exploration/Rewards Std             0.0699885
exploration/Rewards Max             0.708635
exploration/Rewards Min             0.281618
exploration/Returns Mean          259.253
exploration/Returns Std             5.06178
exploration/Returns Max           267.871
exploration/Returns Min           252.979
exploration/Actions Mean            0.0251331
exploration/Actions Std             0.722387
exploration/Actions Max             0.99998
exploration/Actions Min            -0.99997
exploration/Num Paths              10
exploration/Average Returns       259.253
evaluation/num steps total     160000
evaluation/num paths total        320
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.524817
evaluation/Rewards Std              0.0811101
evaluation/Rewards Max              0.704546
evaluation/Rewards Min              0.250181
evaluation/Returns Mean           262.408
evaluation/Returns Std             16.313
evaluation/Returns Max            287.739
evaluation/Returns Min            232.512
evaluation/ExplReturns Mean       262.408
evaluation/ExplReturns Std         16.313
evaluation/ExplReturns Max        287.739
evaluation/ExplReturns Min        232.512
evaluation/Actions Mean             0.000173788
evaluation/Actions Std              0.642912
evaluation/Actions Max              0.999579
evaluation/Actions Min             -0.999433
evaluation/Num Paths               10
evaluation/Average Returns        262.408
time/data storing (s)               0.0314676
time/evaluation sampling (s)      106.264
time/exploration sampling (s)     109.952
time/logging (s)                    0.0277816
time/saving (s)                     0.0658607
time/training (s)                  10.3967
time/epoch (s)                    226.738
time/total (s)                   7340
Epoch                              31
-----------------------------  ----------------
2023-08-31 14:02:01.065720 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 32 finished
-----------------------------  ---------------
replay_buffer/size             166000
trainer/QF1 Loss                    0.158189
trainer/QF2 Loss                    0.153113
trainer/Policy Loss               -61.5546
trainer/Q1 Predictions Mean        74.0746
trainer/Q1 Predictions Std          5.0604
trainer/Q1 Predictions Max         81.183
trainer/Q1 Predictions Min         53.6383
trainer/Q2 Predictions Mean        74.0841
trainer/Q2 Predictions Std          5.08748
trainer/Q2 Predictions Max         81.2847
trainer/Q2 Predictions Min         53.5348
trainer/Q Targets Mean             74.0759
trainer/Q Targets Std               5.08579
trainer/Q Targets Max              81.1155
trainer/Q Targets Min              53.1504
trainer/Log Pis Mean               12.6385
trainer/Log Pis Std                 8.59533
trainer/Log Pis Max                43.8899
trainer/Log Pis Min                -9.05663
trainer/Policy mu Mean             -0.0338054
trainer/Policy mu Std               1.7681
trainer/Policy mu Max               5.53856
trainer/Policy mu Min              -5.10982
trainer/Policy log std Mean        -0.374476
trainer/Policy log std Std          0.143493
trainer/Policy log std Max          0.131706
trainer/Policy log std Min         -0.871519
trainer/Alpha                       0.00345101
trainer/Alpha Loss                  3.61982
exploration/num steps total    166000
exploration/num paths total       332
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.610569
exploration/Rewards Std             0.0781838
exploration/Rewards Max             0.736961
exploration/Rewards Min             0.347852
exploration/Returns Mean          305.284
exploration/Returns Std            10.0611
exploration/Returns Max           315.973
exploration/Returns Min           279.541
exploration/Actions Mean           -0.012187
exploration/Actions Std             0.737713
exploration/Actions Max             0.999979
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns       305.284
evaluation/num steps total     165000
evaluation/num paths total        330
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.565337
evaluation/Rewards Std              0.0858401
evaluation/Rewards Max              0.934868
evaluation/Rewards Min              0.202391
evaluation/Returns Mean           282.669
evaluation/Returns Std             19.0482
evaluation/Returns Max            299.077
evaluation/Returns Min            233.544
evaluation/ExplReturns Mean       282.669
evaluation/ExplReturns Std         19.0482
evaluation/ExplReturns Max        299.077
evaluation/ExplReturns Min        233.544
evaluation/Actions Mean             0.0133556
evaluation/Actions Std              0.690994
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.999985
evaluation/Num Paths               10
evaluation/Average Returns        282.669
time/data storing (s)               0.0312554
time/evaluation sampling (s)      108.974
time/exploration sampling (s)     115.061
time/logging (s)                    0.0268787
time/saving (s)                     0.0737437
time/training (s)                  10.1771
time/epoch (s)                    234.343
time/total (s)                   7574.34
Epoch                              32
-----------------------------  ---------------
2023-08-31 14:05:50.410407 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 33 finished
-----------------------------  ---------------
replay_buffer/size             171000
trainer/QF1 Loss                    0.22768
trainer/QF2 Loss                    0.186113
trainer/Policy Loss               -62.0157
trainer/Q1 Predictions Mean        72.6346
trainer/Q1 Predictions Std          6.02076
trainer/Q1 Predictions Max         80.7556
trainer/Q1 Predictions Min         45.1599
trainer/Q2 Predictions Mean        72.6939
trainer/Q2 Predictions Std          6.07001
trainer/Q2 Predictions Max         80.9531
trainer/Q2 Predictions Min         45.2269
trainer/Q Targets Mean             72.7055
trainer/Q Targets Std               6.14768
trainer/Q Targets Max              81.0298
trainer/Q Targets Min              44.8899
trainer/Log Pis Mean               10.7516
trainer/Log Pis Std                10.2097
trainer/Log Pis Max                61.492
trainer/Log Pis Min               -12.1813
trainer/Policy mu Mean             -0.123037
trainer/Policy mu Std               1.70583
trainer/Policy mu Max               6.41853
trainer/Policy mu Min              -6.03881
trainer/Policy log std Mean        -0.335802
trainer/Policy log std Std          0.152576
trainer/Policy log std Max          0.29047
trainer/Policy log std Min         -1.01659
trainer/Alpha                       0.00337645
trainer/Alpha Loss                 -7.10406
exploration/num steps total    171000
exploration/num paths total       342
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.522265
exploration/Rewards Std             0.101547
exploration/Rewards Max             0.717979
exploration/Rewards Min             0.165361
exploration/Returns Mean          261.132
exploration/Returns Std            31.7934
exploration/Returns Max           292.913
exploration/Returns Min           180.106
exploration/Actions Mean           -0.035562
exploration/Actions Std             0.727928
exploration/Actions Max             0.999993
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       261.132
evaluation/num steps total     170000
evaluation/num paths total        340
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.50248
evaluation/Rewards Std              0.104981
evaluation/Rewards Max              0.714668
evaluation/Rewards Min              0.13697
evaluation/Returns Mean           251.24
evaluation/Returns Std             21.0807
evaluation/Returns Max            277.372
evaluation/Returns Min            209.378
evaluation/ExplReturns Mean       251.24
evaluation/ExplReturns Std         21.0807
evaluation/ExplReturns Max        277.372
evaluation/ExplReturns Min        209.378
evaluation/Actions Mean            -0.0310211
evaluation/Actions Std              0.69399
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.999995
evaluation/Num Paths               10
evaluation/Average Returns        251.24
time/data storing (s)               0.0310597
time/evaluation sampling (s)      106.761
time/exploration sampling (s)     111.946
time/logging (s)                    0.0263517
time/saving (s)                     0.0691246
time/training (s)                  10.507
time/epoch (s)                    229.341
time/total (s)                   7803.69
Epoch                              33
-----------------------------  ---------------
2023-08-31 14:09:45.260081 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 34 finished
-----------------------------  ---------------
replay_buffer/size             176000
trainer/QF1 Loss                    0.120839
trainer/QF2 Loss                    0.114294
trainer/Policy Loss               -61.4004
trainer/Q1 Predictions Mean        72.7266
trainer/Q1 Predictions Std          4.53765
trainer/Q1 Predictions Max         79.0261
trainer/Q1 Predictions Min         45.2511
trainer/Q2 Predictions Mean        72.7203
trainer/Q2 Predictions Std          4.5441
trainer/Q2 Predictions Max         78.939
trainer/Q2 Predictions Min         45.2579
trainer/Q Targets Mean             72.7296
trainer/Q Targets Std               4.535
trainer/Q Targets Max              79.101
trainer/Q Targets Min              45.2776
trainer/Log Pis Mean               11.4212
trainer/Log Pis Std                 7.72236
trainer/Log Pis Max                36.8844
trainer/Log Pis Min                -8.84154
trainer/Policy mu Mean              0.0391465
trainer/Policy mu Std               1.69761
trainer/Policy mu Max               5.13391
trainer/Policy mu Min              -4.82637
trainer/Policy log std Mean        -0.35755
trainer/Policy log std Std          0.13791
trainer/Policy log std Max          0.199246
trainer/Policy log std Min         -0.921185
trainer/Alpha                       0.00347238
trainer/Alpha Loss                 -3.27799
exploration/num steps total    176000
exploration/num paths total       352
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.602927
exploration/Rewards Std             0.0958156
exploration/Rewards Max             0.973309
exploration/Rewards Min             0.239045
exploration/Returns Mean          301.464
exploration/Returns Std            22.1244
exploration/Returns Max           332.482
exploration/Returns Min           249.513
exploration/Actions Mean            0.0192372
exploration/Actions Std             0.745871
exploration/Actions Max             0.999989
exploration/Actions Min            -0.99999
exploration/Num Paths              10
exploration/Average Returns       301.464
evaluation/num steps total     175000
evaluation/num paths total        350
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.594682
evaluation/Rewards Std              0.0855074
evaluation/Rewards Max              0.956523
evaluation/Rewards Min              0.167417
evaluation/Returns Mean           297.341
evaluation/Returns Std             20.3006
evaluation/Returns Max            315.689
evaluation/Returns Min            259.88
evaluation/ExplReturns Mean       297.341
evaluation/ExplReturns Std         20.3006
evaluation/ExplReturns Max        315.689
evaluation/ExplReturns Min        259.88
evaluation/Actions Mean             0.0344161
evaluation/Actions Std              0.686417
evaluation/Actions Max              0.999725
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns        297.341
time/data storing (s)               0.0313863
time/evaluation sampling (s)      109.229
time/exploration sampling (s)     115.199
time/logging (s)                    0.0262179
time/saving (s)                     0.0809919
time/training (s)                  10.2797
time/epoch (s)                    234.846
time/total (s)                   8038.53
Epoch                              34
-----------------------------  ---------------
2023-08-31 14:13:38.185879 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             181000
trainer/QF1 Loss                    0.177554
trainer/QF2 Loss                    0.169974
trainer/Policy Loss               -58.3211
trainer/Q1 Predictions Mean        71.2154
trainer/Q1 Predictions Std          4.38112
trainer/Q1 Predictions Max         77.6335
trainer/Q1 Predictions Min         46.8322
trainer/Q2 Predictions Mean        71.2224
trainer/Q2 Predictions Std          4.39964
trainer/Q2 Predictions Max         77.713
trainer/Q2 Predictions Min         47.4807
trainer/Q Targets Mean             71.3358
trainer/Q Targets Std               4.40998
trainer/Q Targets Max              77.8543
trainer/Q Targets Min              47.3445
trainer/Log Pis Mean               13.0094
trainer/Log Pis Std                 9.12592
trainer/Log Pis Max                46.983
trainer/Log Pis Min                -3.52347
trainer/Policy mu Mean             -0.0278569
trainer/Policy mu Std               1.79342
trainer/Policy mu Max               5.15065
trainer/Policy mu Min              -6.02148
trainer/Policy log std Mean        -0.377936
trainer/Policy log std Std          0.147039
trainer/Policy log std Max          0.137197
trainer/Policy log std Min         -0.955922
trainer/Alpha                       0.0033541
trainer/Alpha Loss                  5.75164
exploration/num steps total    181000
exploration/num paths total       362
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.611447
exploration/Rewards Std             0.075003
exploration/Rewards Max             0.970745
exploration/Rewards Min             0.336348
exploration/Returns Mean          305.724
exploration/Returns Std            16.9068
exploration/Returns Max           328.598
exploration/Returns Min           268.144
exploration/Actions Mean           -0.0134461
exploration/Actions Std             0.759092
exploration/Actions Max             0.99998
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns       305.724
evaluation/num steps total     180000
evaluation/num paths total        360
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.622328
evaluation/Rewards Std              0.0732087
evaluation/Rewards Max              0.93277
evaluation/Rewards Min              0.314228
evaluation/Returns Mean           311.164
evaluation/Returns Std             12.0166
evaluation/Returns Max            321.922
evaluation/Returns Min            280.189
evaluation/ExplReturns Mean       311.164
evaluation/ExplReturns Std         12.0166
evaluation/ExplReturns Max        321.922
evaluation/ExplReturns Min        280.189
evaluation/Actions Mean             0.0378318
evaluation/Actions Std              0.723186
evaluation/Actions Max              0.999822
evaluation/Actions Min             -0.999871
evaluation/Num Paths               10
evaluation/Average Returns        311.164
time/data storing (s)               0.0313569
time/evaluation sampling (s)      106.385
time/exploration sampling (s)     112.991
time/logging (s)                    0.0263709
time/saving (s)                     0.0838363
time/training (s)                  13.4048
time/epoch (s)                    232.922
time/total (s)                   8271.46
Epoch                              35
-----------------------------  --------------
2023-08-31 14:17:32.229198 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 36 finished
-----------------------------  ---------------
replay_buffer/size             186000
trainer/QF1 Loss                    0.160635
trainer/QF2 Loss                    0.147878
trainer/Policy Loss               -58.6462
trainer/Q1 Predictions Mean        70.6278
trainer/Q1 Predictions Std          4.53493
trainer/Q1 Predictions Max         77.7473
trainer/Q1 Predictions Min         50.137
trainer/Q2 Predictions Mean        70.5222
trainer/Q2 Predictions Std          4.54706
trainer/Q2 Predictions Max         77.5659
trainer/Q2 Predictions Min         50.2523
trainer/Q Targets Mean             70.6224
trainer/Q Targets Std               4.55664
trainer/Q Targets Max              77.7642
trainer/Q Targets Min              49.8535
trainer/Log Pis Mean               12.0668
trainer/Log Pis Std                 8.93048
trainer/Log Pis Max                52.5609
trainer/Log Pis Min                -7.12542
trainer/Policy mu Mean              0.0566082
trainer/Policy mu Std               1.729
trainer/Policy mu Max               5.34986
trainer/Policy mu Min              -4.5691
trainer/Policy log std Mean        -0.370757
trainer/Policy log std Std          0.145324
trainer/Policy log std Max          0.15056
trainer/Policy log std Min         -0.918334
trainer/Alpha                       0.00331107
trainer/Alpha Loss                  0.381306
exploration/num steps total    186000
exploration/num paths total       372
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.53979
exploration/Rewards Std             0.109187
exploration/Rewards Max             0.949109
exploration/Rewards Min             0.130252
exploration/Returns Mean          269.895
exploration/Returns Std            34.668
exploration/Returns Max           306.565
exploration/Returns Min           187.575
exploration/Actions Mean            0.072134
exploration/Actions Std             0.758263
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns       269.895
evaluation/num steps total     185000
evaluation/num paths total        370
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.609254
evaluation/Rewards Std              0.109924
evaluation/Rewards Max              0.978262
evaluation/Rewards Min              0.24643
evaluation/Returns Mean           304.627
evaluation/Returns Std             21.8228
evaluation/Returns Max            340.497
evaluation/Returns Min            259.28
evaluation/ExplReturns Mean       304.627
evaluation/ExplReturns Std         21.8228
evaluation/ExplReturns Max        340.497
evaluation/ExplReturns Min        259.28
evaluation/Actions Mean             0.03144
evaluation/Actions Std              0.737558
evaluation/Actions Max              0.999904
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns        304.627
time/data storing (s)               0.0313021
time/evaluation sampling (s)      107.277
time/exploration sampling (s)     113.639
time/logging (s)                    0.0269399
time/saving (s)                     0.0683466
time/training (s)                  12.9978
time/epoch (s)                    234.04
time/total (s)                   8505.5
Epoch                              36
-----------------------------  ---------------
2023-08-31 14:21:21.522978 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 37 finished
-----------------------------  ---------------
replay_buffer/size             191000
trainer/QF1 Loss                    0.166139
trainer/QF2 Loss                    0.141752
trainer/Policy Loss               -58.7277
trainer/Q1 Predictions Mean        70.5786
trainer/Q1 Predictions Std          3.7735
trainer/Q1 Predictions Max         76.124
trainer/Q1 Predictions Min         53.4798
trainer/Q2 Predictions Mean        70.5355
trainer/Q2 Predictions Std          3.80851
trainer/Q2 Predictions Max         76.2157
trainer/Q2 Predictions Min         54.2765
trainer/Q Targets Mean             70.51
trainer/Q Targets Std               3.87593
trainer/Q Targets Max              76.2946
trainer/Q Targets Min              53.8381
trainer/Log Pis Mean               11.9313
trainer/Log Pis Std                 7.9061
trainer/Log Pis Max                40.5015
trainer/Log Pis Min                -3.66082
trainer/Policy mu Mean              0.0358368
trainer/Policy mu Std               1.74416
trainer/Policy mu Max               4.72987
trainer/Policy mu Min              -5.18135
trainer/Policy log std Mean        -0.384407
trainer/Policy log std Std          0.14594
trainer/Policy log std Max          0.129798
trainer/Policy log std Min         -0.952262
trainer/Alpha                       0.00320659
trainer/Alpha Loss                 -0.394736
exploration/num steps total    191000
exploration/num paths total       382
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.601462
exploration/Rewards Std             0.062367
exploration/Rewards Max             0.714312
exploration/Rewards Min             0.289641
exploration/Returns Mean          300.731
exploration/Returns Std            10.367
exploration/Returns Max           313.679
exploration/Returns Min           275.506
exploration/Actions Mean            0.00953687
exploration/Actions Std             0.75803
exploration/Actions Max             0.999921
exploration/Actions Min            -0.999934
exploration/Num Paths              10
exploration/Average Returns       300.731
evaluation/num steps total     190000
evaluation/num paths total        380
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.626715
evaluation/Rewards Std              0.0594506
evaluation/Rewards Max              0.947516
evaluation/Rewards Min              0.355526
evaluation/Returns Mean           313.357
evaluation/Returns Std              7.03926
evaluation/Returns Max            323.361
evaluation/Returns Min            302.318
evaluation/ExplReturns Mean       313.357
evaluation/ExplReturns Std          7.03926
evaluation/ExplReturns Max        323.361
evaluation/ExplReturns Min        302.318
evaluation/Actions Mean             0.0540304
evaluation/Actions Std              0.741938
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.99971
evaluation/Num Paths               10
evaluation/Average Returns        313.357
time/data storing (s)               0.0317432
time/evaluation sampling (s)      106.819
time/exploration sampling (s)     112.355
time/logging (s)                    0.0260732
time/saving (s)                     0.0915078
time/training (s)                   9.96617
time/epoch (s)                    229.289
time/total (s)                   8734.79
Epoch                              37
-----------------------------  ---------------
2023-08-31 14:25:12.734183 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 38 finished
-----------------------------  ---------------
replay_buffer/size             196000
trainer/QF1 Loss                    0.157833
trainer/QF2 Loss                    0.158493
trainer/Policy Loss               -59.5566
trainer/Q1 Predictions Mean        69.9018
trainer/Q1 Predictions Std          4.41528
trainer/Q1 Predictions Max         75.695
trainer/Q1 Predictions Min         47.0274
trainer/Q2 Predictions Mean        69.9228
trainer/Q2 Predictions Std          4.39792
trainer/Q2 Predictions Max         75.8082
trainer/Q2 Predictions Min         46.6895
trainer/Q Targets Mean             70.0158
trainer/Q Targets Std               4.41899
trainer/Q Targets Max              75.9121
trainer/Q Targets Min              47.1799
trainer/Log Pis Mean               10.4678
trainer/Log Pis Std                 9.13853
trainer/Log Pis Max                46.8701
trainer/Log Pis Min                -6.19545
trainer/Policy mu Mean              0.040249
trainer/Policy mu Std               1.65024
trainer/Policy mu Max               5.00155
trainer/Policy mu Min              -4.87533
trainer/Policy log std Mean        -0.353094
trainer/Policy log std Std          0.142789
trainer/Policy log std Max          0.18261
trainer/Policy log std Min         -0.866157
trainer/Alpha                       0.00313823
trainer/Alpha Loss                 -8.83168
exploration/num steps total    196000
exploration/num paths total       392
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.596709
exploration/Rewards Std             0.0646433
exploration/Rewards Max             0.92867
exploration/Rewards Min             0.300596
exploration/Returns Mean          298.354
exploration/Returns Std            15.9697
exploration/Returns Max           315.582
exploration/Returns Min           253.886
exploration/Actions Mean            0.00361515
exploration/Actions Std             0.716003
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999993
exploration/Num Paths              10
exploration/Average Returns       298.354
evaluation/num steps total     195000
evaluation/num paths total        390
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.615196
evaluation/Rewards Std              0.0852529
evaluation/Rewards Max              0.962245
evaluation/Rewards Min              0.36154
evaluation/Returns Mean           307.598
evaluation/Returns Std             19.0472
evaluation/Returns Max            361.352
evaluation/Returns Min            290.822
evaluation/ExplReturns Mean       307.598
evaluation/ExplReturns Std         19.0472
evaluation/ExplReturns Max        361.352
evaluation/ExplReturns Min        290.822
evaluation/Actions Mean             0.0396382
evaluation/Actions Std              0.680753
evaluation/Actions Max              0.999934
evaluation/Actions Min             -0.999549
evaluation/Num Paths               10
evaluation/Average Returns        307.598
time/data storing (s)               0.0312017
time/evaluation sampling (s)      108.462
time/exploration sampling (s)     111.914
time/logging (s)                    0.0259456
time/saving (s)                     0.0699148
time/training (s)                  10.7045
time/epoch (s)                    231.208
time/total (s)                   8966
Epoch                              38
-----------------------------  ---------------
2023-08-31 14:29:03.848211 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 39 finished
-----------------------------  ---------------
replay_buffer/size             201000
trainer/QF1 Loss                    0.145697
trainer/QF2 Loss                    0.129685
trainer/Policy Loss               -57.2726
trainer/Q1 Predictions Mean        69.6813
trainer/Q1 Predictions Std          3.85643
trainer/Q1 Predictions Max         75.1008
trainer/Q1 Predictions Min         47.6269
trainer/Q2 Predictions Mean        69.7579
trainer/Q2 Predictions Std          3.82807
trainer/Q2 Predictions Max         74.9761
trainer/Q2 Predictions Min         48.0457
trainer/Q Targets Mean             69.795
trainer/Q Targets Std               3.84777
trainer/Q Targets Max              75.4351
trainer/Q Targets Min              47.2465
trainer/Log Pis Mean               12.5479
trainer/Log Pis Std                 9.13555
trainer/Log Pis Max                61.8655
trainer/Log Pis Min                -6.93664
trainer/Policy mu Mean             -0.0264707
trainer/Policy mu Std               1.7983
trainer/Policy mu Max               6.36068
trainer/Policy mu Min              -9.00193
trainer/Policy log std Mean        -0.382499
trainer/Policy log std Std          0.142177
trainer/Policy log std Max          0.072915
trainer/Policy log std Min         -0.967788
trainer/Alpha                       0.00313452
trainer/Alpha Loss                  3.15876
exploration/num steps total    201000
exploration/num paths total       402
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.625844
exploration/Rewards Std             0.0949816
exploration/Rewards Max             0.948766
exploration/Rewards Min             0.228134
exploration/Returns Mean          312.922
exploration/Returns Std            22.539
exploration/Returns Max           339.539
exploration/Returns Min           260.693
exploration/Actions Mean            0.00161344
exploration/Actions Std             0.742819
exploration/Actions Max             0.999932
exploration/Actions Min            -0.99998
exploration/Num Paths              10
exploration/Average Returns       312.922
evaluation/num steps total     200000
evaluation/num paths total        400
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.638474
evaluation/Rewards Std              0.0740781
evaluation/Rewards Max              0.976506
evaluation/Rewards Min              0.299126
evaluation/Returns Mean           319.237
evaluation/Returns Std             15.203
evaluation/Returns Max            345.506
evaluation/Returns Min            294.888
evaluation/ExplReturns Mean       319.237
evaluation/ExplReturns Std         15.203
evaluation/ExplReturns Max        345.506
evaluation/ExplReturns Min        294.888
evaluation/Actions Mean             0.00337628
evaluation/Actions Std              0.70584
evaluation/Actions Max              0.999123
evaluation/Actions Min             -0.999856
evaluation/Num Paths               10
evaluation/Average Returns        319.237
time/data storing (s)               0.0315456
time/evaluation sampling (s)      107.879
time/exploration sampling (s)     113.083
time/logging (s)                    0.0266653
time/saving (s)                     0.0776391
time/training (s)                  10.0134
time/epoch (s)                    231.111
time/total (s)                   9197.12
Epoch                              39
-----------------------------  ---------------
2023-08-31 14:33:04.936676 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 40 finished
-----------------------------  ---------------
replay_buffer/size             206000
trainer/QF1 Loss                    0.11329
trainer/QF2 Loss                    0.107741
trainer/Policy Loss               -56.2729
trainer/Q1 Predictions Mean        68.3006
trainer/Q1 Predictions Std          4.70652
trainer/Q1 Predictions Max         74.6217
trainer/Q1 Predictions Min         43.0469
trainer/Q2 Predictions Mean        68.3782
trainer/Q2 Predictions Std          4.72849
trainer/Q2 Predictions Max         74.7338
trainer/Q2 Predictions Min         42.5689
trainer/Q Targets Mean             68.3852
trainer/Q Targets Std               4.7544
trainer/Q Targets Max              74.9923
trainer/Q Targets Min              42.6214
trainer/Log Pis Mean               12.1738
trainer/Log Pis Std                 7.80896
trainer/Log Pis Max                41.8477
trainer/Log Pis Min                -6.83428
trainer/Policy mu Mean              0.00829119
trainer/Policy mu Std               1.73624
trainer/Policy mu Max               5.70515
trainer/Policy mu Min              -5.13965
trainer/Policy log std Mean        -0.368934
trainer/Policy log std Std          0.147893
trainer/Policy log std Max          0.140467
trainer/Policy log std Min         -0.915458
trainer/Alpha                       0.00317819
trainer/Alpha Loss                  0.999837
exploration/num steps total    206000
exploration/num paths total       412
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.629983
exploration/Rewards Std             0.0694184
exploration/Rewards Max             0.968112
exploration/Rewards Min             0.407124
exploration/Returns Mean          314.992
exploration/Returns Std            14.0776
exploration/Returns Max           338.166
exploration/Returns Min           282.497
exploration/Actions Mean            0.0109807
exploration/Actions Std             0.741686
exploration/Actions Max             0.999994
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       314.992
evaluation/num steps total     205000
evaluation/num paths total        410
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.624249
evaluation/Rewards Std              0.0766568
evaluation/Rewards Max              0.944723
evaluation/Rewards Min              0.335732
evaluation/Returns Mean           312.124
evaluation/Returns Std             12.3974
evaluation/Returns Max            332.214
evaluation/Returns Min            292.89
evaluation/ExplReturns Mean       312.124
evaluation/ExplReturns Std         12.3974
evaluation/ExplReturns Max        332.214
evaluation/ExplReturns Min        292.89
evaluation/Actions Mean             0.0237937
evaluation/Actions Std              0.701792
evaluation/Actions Max              0.999956
evaluation/Actions Min             -0.999961
evaluation/Num Paths               10
evaluation/Average Returns        312.124
time/data storing (s)               0.0314047
time/evaluation sampling (s)      109.822
time/exploration sampling (s)     114.431
time/logging (s)                    0.0261248
time/saving (s)                     0.0726652
time/training (s)                  16.7006
time/epoch (s)                    241.084
time/total (s)                   9438.21
Epoch                              40
-----------------------------  ---------------
2023-08-31 14:36:55.249018 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 41 finished
-----------------------------  ---------------
replay_buffer/size             211000
trainer/QF1 Loss                    0.162537
trainer/QF2 Loss                    0.128708
trainer/Policy Loss               -55.87
trainer/Q1 Predictions Mean        67.8967
trainer/Q1 Predictions Std          4.81698
trainer/Q1 Predictions Max         75.6666
trainer/Q1 Predictions Min         44.0989
trainer/Q2 Predictions Mean        67.7887
trainer/Q2 Predictions Std          4.82021
trainer/Q2 Predictions Max         75.7112
trainer/Q2 Predictions Min         42.3238
trainer/Q Targets Mean             67.8453
trainer/Q Targets Std               4.86395
trainer/Q Targets Max              75.8064
trainer/Q Targets Min              42.0313
trainer/Log Pis Mean               12.0574
trainer/Log Pis Std                 9.17317
trainer/Log Pis Max                60.4637
trainer/Log Pis Min                -7.95211
trainer/Policy mu Mean              0.148484
trainer/Policy mu Std               1.76519
trainer/Policy mu Max               8.38163
trainer/Policy mu Min              -6.28524
trainer/Policy log std Mean        -0.357129
trainer/Policy log std Std          0.137576
trainer/Policy log std Max          0.155881
trainer/Policy log std Min         -0.882386
trainer/Alpha                       0.00304393
trainer/Alpha Loss                  0.332866
exploration/num steps total    211000
exploration/num paths total       422
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.540992
exploration/Rewards Std             0.11215
exploration/Rewards Max             0.94734
exploration/Rewards Min             0.108608
exploration/Returns Mean          270.496
exploration/Returns Std            30.2869
exploration/Returns Max           297.319
exploration/Returns Min           190.76
exploration/Actions Mean            0.0237
exploration/Actions Std             0.744072
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       270.496
evaluation/num steps total     210000
evaluation/num paths total        420
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.530691
evaluation/Rewards Std              0.109995
evaluation/Rewards Max              0.724516
evaluation/Rewards Min              0.135843
evaluation/Returns Mean           265.345
evaluation/Returns Std             37.1049
evaluation/Returns Max            309.976
evaluation/Returns Min            196.755
evaluation/ExplReturns Mean       265.345
evaluation/ExplReturns Std         37.1049
evaluation/ExplReturns Max        309.976
evaluation/ExplReturns Min        196.755
evaluation/Actions Mean             0.066872
evaluation/Actions Std              0.727837
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns        265.345
time/data storing (s)               0.0313436
time/evaluation sampling (s)      106.878
time/exploration sampling (s)     113.362
time/logging (s)                    0.0261828
time/saving (s)                     0.0849899
time/training (s)                   9.92666
time/epoch (s)                    230.309
time/total (s)                   9668.52
Epoch                              41
-----------------------------  ---------------
2023-08-31 14:40:44.542359 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 42 finished
-----------------------------  ---------------
replay_buffer/size             216000
trainer/QF1 Loss                    0.177132
trainer/QF2 Loss                    0.127019
trainer/Policy Loss               -55.7164
trainer/Q1 Predictions Mean        68.0868
trainer/Q1 Predictions Std          3.93353
trainer/Q1 Predictions Max         73.9147
trainer/Q1 Predictions Min         50.4431
trainer/Q2 Predictions Mean        67.9668
trainer/Q2 Predictions Std          3.92872
trainer/Q2 Predictions Max         73.7079
trainer/Q2 Predictions Min         49.891
trainer/Q Targets Mean             67.8968
trainer/Q Targets Std               3.88943
trainer/Q Targets Max              73.464
trainer/Q Targets Min              49.949
trainer/Log Pis Mean               12.4294
trainer/Log Pis Std                 7.95349
trainer/Log Pis Max                44.1541
trainer/Log Pis Min                -4.66214
trainer/Policy mu Mean             -0.0419196
trainer/Policy mu Std               1.74487
trainer/Policy mu Max               5.29021
trainer/Policy mu Min              -5.5391
trainer/Policy log std Mean        -0.360567
trainer/Policy log std Std          0.1347
trainer/Policy log std Max          0.134438
trainer/Policy log std Min         -0.848766
trainer/Alpha                       0.00309332
trainer/Alpha Loss                  2.48115
exploration/num steps total    216000
exploration/num paths total       432
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.595776
exploration/Rewards Std             0.0852946
exploration/Rewards Max             0.960891
exploration/Rewards Min             0.164076
exploration/Returns Mean          297.888
exploration/Returns Std             9.55299
exploration/Returns Max           315.365
exploration/Returns Min           277.341
exploration/Actions Mean            0.0834816
exploration/Actions Std             0.75366
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999986
exploration/Num Paths              10
exploration/Average Returns       297.888
evaluation/num steps total     215000
evaluation/num paths total        430
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.594426
evaluation/Rewards Std              0.0755665
evaluation/Rewards Max              0.928555
evaluation/Rewards Min              0.250167
evaluation/Returns Mean           297.213
evaluation/Returns Std              9.13735
evaluation/Returns Max            310.127
evaluation/Returns Min            283.778
evaluation/ExplReturns Mean       297.213
evaluation/ExplReturns Std          9.13735
evaluation/ExplReturns Max        310.127
evaluation/ExplReturns Min        283.778
evaluation/Actions Mean             0.0841099
evaluation/Actions Std              0.732996
evaluation/Actions Max              0.999801
evaluation/Actions Min             -0.999879
evaluation/Num Paths               10
evaluation/Average Returns        297.213
time/data storing (s)               0.0309353
time/evaluation sampling (s)      105.554
time/exploration sampling (s)     110.761
time/logging (s)                    0.0259972
time/saving (s)                     0.0689133
time/training (s)                  12.8494
time/epoch (s)                    229.29
time/total (s)                   9897.81
Epoch                              42
-----------------------------  ---------------
2023-08-31 14:44:31.736944 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size             221000
trainer/QF1 Loss                    0.159542
trainer/QF2 Loss                    0.151557
trainer/Policy Loss               -55.0007
trainer/Q1 Predictions Mean        66.7503
trainer/Q1 Predictions Std          4.20331
trainer/Q1 Predictions Max         73.1607
trainer/Q1 Predictions Min         46.0746
trainer/Q2 Predictions Mean        66.7224
trainer/Q2 Predictions Std          4.1659
trainer/Q2 Predictions Max         73.1357
trainer/Q2 Predictions Min         46.3108
trainer/Q Targets Mean             66.8707
trainer/Q Targets Std               4.21039
trainer/Q Targets Max              72.8532
trainer/Q Targets Min              45.9765
trainer/Log Pis Mean               11.8412
trainer/Log Pis Std                 8.77081
trainer/Log Pis Max                45.312
trainer/Log Pis Min                -8.20233
trainer/Policy mu Mean             -0.0551665
trainer/Policy mu Std               1.74118
trainer/Policy mu Max               5.45715
trainer/Policy mu Min              -6.5347
trainer/Policy log std Mean        -0.352732
trainer/Policy log std Std          0.137451
trainer/Policy log std Max          0.143836
trainer/Policy log std Min         -0.893593
trainer/Alpha                       0.00314081
trainer/Alpha Loss                 -0.914929
exploration/num steps total    221000
exploration/num paths total       442
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.602126
exploration/Rewards Std             0.0766122
exploration/Rewards Max             0.932619
exploration/Rewards Min             0.259073
exploration/Returns Mean          301.063
exploration/Returns Std            19.1223
exploration/Returns Max           322.417
exploration/Returns Min           269.97
exploration/Actions Mean            0.0130023
exploration/Actions Std             0.715599
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999992
exploration/Num Paths              10
exploration/Average Returns       301.063
evaluation/num steps total     220000
evaluation/num paths total        440
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.564707
evaluation/Rewards Std              0.0938233
evaluation/Rewards Max              0.955461
evaluation/Rewards Min              0.238032
evaluation/Returns Mean           282.354
evaluation/Returns Std             15.8268
evaluation/Returns Max            315.131
evaluation/Returns Min            258.899
evaluation/ExplReturns Mean       282.354
evaluation/ExplReturns Std         15.8268
evaluation/ExplReturns Max        315.131
evaluation/ExplReturns Min        258.899
evaluation/Actions Mean             0.0227074
evaluation/Actions Std              0.706746
evaluation/Actions Max              0.999915
evaluation/Actions Min             -0.999994
evaluation/Num Paths               10
evaluation/Average Returns        282.354
time/data storing (s)               0.0312777
time/evaluation sampling (s)      105.417
time/exploration sampling (s)     111.645
time/logging (s)                    0.0263655
time/saving (s)                     0.0594004
time/training (s)                  10.0119
time/epoch (s)                    227.191
time/total (s)                  10125
Epoch                              43
-----------------------------  ---------------
2023-08-31 14:48:23.583236 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 44 finished
-----------------------------  ---------------
replay_buffer/size             226000
trainer/QF1 Loss                    0.13751
trainer/QF2 Loss                    0.14534
trainer/Policy Loss               -54.5424
trainer/Q1 Predictions Mean        66.9752
trainer/Q1 Predictions Std          4.57446
trainer/Q1 Predictions Max         73.6169
trainer/Q1 Predictions Min         41.8578
trainer/Q2 Predictions Mean        67.0832
trainer/Q2 Predictions Std          4.59054
trainer/Q2 Predictions Max         73.6361
trainer/Q2 Predictions Min         41.7058
trainer/Q Targets Mean             66.978
trainer/Q Targets Std               4.59267
trainer/Q Targets Max              73.3427
trainer/Q Targets Min              41.7836
trainer/Log Pis Mean               12.5998
trainer/Log Pis Std                 8.29046
trainer/Log Pis Max                45.2332
trainer/Log Pis Min                -3.2491
trainer/Policy mu Mean             -0.163762
trainer/Policy mu Std               1.76814
trainer/Policy mu Max               5.70853
trainer/Policy mu Min              -6.65846
trainer/Policy log std Mean        -0.370562
trainer/Policy log std Std          0.132348
trainer/Policy log std Max          0.119416
trainer/Policy log std Min         -1.01697
trainer/Alpha                       0.00331755
trainer/Alpha Loss                  3.42427
exploration/num steps total    226000
exploration/num paths total       452
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.586148
exploration/Rewards Std             0.0978522
exploration/Rewards Max             0.969514
exploration/Rewards Min             0.277199
exploration/Returns Mean          293.074
exploration/Returns Std            31.6759
exploration/Returns Max           350.006
exploration/Returns Min           249.132
exploration/Actions Mean            0.0196155
exploration/Actions Std             0.755967
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999995
exploration/Num Paths              10
exploration/Average Returns       293.074
evaluation/num steps total     225000
evaluation/num paths total        450
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.561865
evaluation/Rewards Std              0.111192
evaluation/Rewards Max              0.968251
evaluation/Rewards Min              0.275074
evaluation/Returns Mean           280.932
evaluation/Returns Std             28.9478
evaluation/Returns Max            313.979
evaluation/Returns Min            214.175
evaluation/ExplReturns Mean       280.932
evaluation/ExplReturns Std         28.9478
evaluation/ExplReturns Max        313.979
evaluation/ExplReturns Min        214.175
evaluation/Actions Mean             0.0134141
evaluation/Actions Std              0.737889
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999977
evaluation/Num Paths               10
evaluation/Average Returns        280.932
time/data storing (s)               0.0313569
time/evaluation sampling (s)      107.818
time/exploration sampling (s)     112.425
time/logging (s)                    0.0264646
time/saving (s)                     0.0737524
time/training (s)                  11.4684
time/epoch (s)                    231.843
time/total (s)                  10356.8
Epoch                              44
-----------------------------  ---------------
2023-08-31 14:52:11.092100 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size             231000
trainer/QF1 Loss                    0.127413
trainer/QF2 Loss                    0.128809
trainer/Policy Loss               -54.8258
trainer/Q1 Predictions Mean        66.5712
trainer/Q1 Predictions Std          4.0997
trainer/Q1 Predictions Max         72.9877
trainer/Q1 Predictions Min         47.8766
trainer/Q2 Predictions Mean        66.5498
trainer/Q2 Predictions Std          4.09515
trainer/Q2 Predictions Max         72.6417
trainer/Q2 Predictions Min         48.1128
trainer/Q Targets Mean             66.5089
trainer/Q Targets Std               4.11628
trainer/Q Targets Max              72.8296
trainer/Q Targets Min              48.4027
trainer/Log Pis Mean               11.863
trainer/Log Pis Std                 8.03396
trainer/Log Pis Max                49.2419
trainer/Log Pis Min                -7.32575
trainer/Policy mu Mean             -0.113832
trainer/Policy mu Std               1.72417
trainer/Policy mu Max               5.13089
trainer/Policy mu Min              -5.01291
trainer/Policy log std Mean        -0.369551
trainer/Policy log std Std          0.123792
trainer/Policy log std Max          0.205029
trainer/Policy log std Min         -0.826806
trainer/Alpha                       0.00351597
trainer/Alpha Loss                 -0.773932
exploration/num steps total    231000
exploration/num paths total       462
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.560141
exploration/Rewards Std             0.0532518
exploration/Rewards Max             0.713895
exploration/Rewards Min             0.37744
exploration/Returns Mean          280.071
exploration/Returns Std             7.70522
exploration/Returns Max           289.153
exploration/Returns Min           262.124
exploration/Actions Mean            0.0144969
exploration/Actions Std             0.73478
exploration/Actions Max             0.99996
exploration/Actions Min            -0.999901
exploration/Num Paths              10
exploration/Average Returns       280.071
evaluation/num steps total     230000
evaluation/num paths total        460
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.57475
evaluation/Rewards Std              0.0558054
evaluation/Rewards Max              0.929915
evaluation/Rewards Min              0.393108
evaluation/Returns Mean           287.375
evaluation/Returns Std              6.19435
evaluation/Returns Max            300.496
evaluation/Returns Min            275.252
evaluation/ExplReturns Mean       287.375
evaluation/ExplReturns Std          6.19435
evaluation/ExplReturns Max        300.496
evaluation/ExplReturns Min        275.252
evaluation/Actions Mean             0.0398323
evaluation/Actions Std              0.733222
evaluation/Actions Max              0.999644
evaluation/Actions Min             -0.999866
evaluation/Num Paths               10
evaluation/Average Returns        287.375
time/data storing (s)               0.0309681
time/evaluation sampling (s)      105.41
time/exploration sampling (s)     111.596
time/logging (s)                    0.0262453
time/saving (s)                     0.0773092
time/training (s)                  10.3639
time/epoch (s)                    227.505
time/total (s)                  10584.4
Epoch                              45
-----------------------------  ---------------
2023-08-31 14:56:12.660911 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 46 finished
-----------------------------  ---------------
replay_buffer/size             236000
trainer/QF1 Loss                    0.11475
trainer/QF2 Loss                    0.109204
trainer/Policy Loss               -54.3724
trainer/Q1 Predictions Mean        66.7897
trainer/Q1 Predictions Std          4.13188
trainer/Q1 Predictions Max         72.2719
trainer/Q1 Predictions Min         44.6488
trainer/Q2 Predictions Mean        66.8213
trainer/Q2 Predictions Std          4.13378
trainer/Q2 Predictions Max         72.5036
trainer/Q2 Predictions Min         45.1439
trainer/Q Targets Mean             66.7744
trainer/Q Targets Std               4.15325
trainer/Q Targets Max              72.8872
trainer/Q Targets Min              44.4543
trainer/Log Pis Mean               12.5652
trainer/Log Pis Std                 7.26115
trainer/Log Pis Max                40.322
trainer/Log Pis Min                -7.75739
trainer/Policy mu Mean             -0.0744212
trainer/Policy mu Std               1.76684
trainer/Policy mu Max               5.02976
trainer/Policy mu Min              -4.95383
trainer/Policy log std Mean        -0.365991
trainer/Policy log std Std          0.136019
trainer/Policy log std Max          0.135711
trainer/Policy log std Min         -0.838548
trainer/Alpha                       0.00348842
trainer/Alpha Loss                  3.19808
exploration/num steps total    236000
exploration/num paths total       472
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.655612
exploration/Rewards Std             0.0589264
exploration/Rewards Max             0.95534
exploration/Rewards Min             0.381334
exploration/Returns Mean          327.806
exploration/Returns Std             8.97867
exploration/Returns Max           344.183
exploration/Returns Min           308.589
exploration/Actions Mean           -0.0698045
exploration/Actions Std             0.739552
exploration/Actions Max             0.999981
exploration/Actions Min            -0.999992
exploration/Num Paths              10
exploration/Average Returns       327.806
evaluation/num steps total     235000
evaluation/num paths total        470
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.663123
evaluation/Rewards Std              0.0578126
evaluation/Rewards Max              0.967515
evaluation/Rewards Min              0.358261
evaluation/Returns Mean           331.561
evaluation/Returns Std              6.86609
evaluation/Returns Max            347.762
evaluation/Returns Min            323.335
evaluation/ExplReturns Mean       331.561
evaluation/ExplReturns Std          6.86609
evaluation/ExplReturns Max        347.762
evaluation/ExplReturns Min        323.335
evaluation/Actions Mean            -0.0747557
evaluation/Actions Std              0.702876
evaluation/Actions Max              0.999892
evaluation/Actions Min             -0.999788
evaluation/Num Paths               10
evaluation/Average Returns        331.561
time/data storing (s)               0.0313211
time/evaluation sampling (s)      111.361
time/exploration sampling (s)     114.759
time/logging (s)                    0.0268814
time/saving (s)                     0.0674427
time/training (s)                  15.3199
time/epoch (s)                    241.566
time/total (s)                  10825.9
Epoch                              46
-----------------------------  ---------------
2023-08-31 15:00:07.786938 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 47 finished
-----------------------------  ---------------
replay_buffer/size             241000
trainer/QF1 Loss                    0.150257
trainer/QF2 Loss                    0.157726
trainer/Policy Loss               -54.873
trainer/Q1 Predictions Mean        65.8915
trainer/Q1 Predictions Std          4.28436
trainer/Q1 Predictions Max         73.1353
trainer/Q1 Predictions Min         44.5199
trainer/Q2 Predictions Mean        65.8862
trainer/Q2 Predictions Std          4.26291
trainer/Q2 Predictions Max         72.6717
trainer/Q2 Predictions Min         44.2871
trainer/Q Targets Mean             65.8488
trainer/Q Targets Std               4.27085
trainer/Q Targets Max              72.9896
trainer/Q Targets Min              44.1303
trainer/Log Pis Mean               11.1424
trainer/Log Pis Std                 7.50499
trainer/Log Pis Max                32.5835
trainer/Log Pis Min                -6.8197
trainer/Policy mu Mean             -0.00149046
trainer/Policy mu Std               1.69547
trainer/Policy mu Max               5.22274
trainer/Policy mu Min              -4.9728
trainer/Policy log std Mean        -0.369746
trainer/Policy log std Std          0.135134
trainer/Policy log std Max          0.164746
trainer/Policy log std Min         -0.915037
trainer/Alpha                       0.00335244
trainer/Alpha Loss                 -4.88664
exploration/num steps total    241000
exploration/num paths total       482
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.670471
exploration/Rewards Std             0.0533138
exploration/Rewards Max             0.972066
exploration/Rewards Min             0.41581
exploration/Returns Mean          335.235
exploration/Returns Std             5.1126
exploration/Returns Max           343.638
exploration/Returns Min           326.038
exploration/Actions Mean           -0.00320975
exploration/Actions Std             0.7511
exploration/Actions Max             0.999954
exploration/Actions Min            -0.999904
exploration/Num Paths              10
exploration/Average Returns       335.235
evaluation/num steps total     240000
evaluation/num paths total        480
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.663891
evaluation/Rewards Std              0.0593114
evaluation/Rewards Max              0.971812
evaluation/Rewards Min              0.419545
evaluation/Returns Mean           331.945
evaluation/Returns Std              7.31108
evaluation/Returns Max            349.417
evaluation/Returns Min            324.164
evaluation/ExplReturns Mean       331.945
evaluation/ExplReturns Std          7.31108
evaluation/ExplReturns Max        349.417
evaluation/ExplReturns Min        324.164
evaluation/Actions Mean            -0.00442808
evaluation/Actions Std              0.743361
evaluation/Actions Max              0.998803
evaluation/Actions Min             -0.998554
evaluation/Num Paths               10
evaluation/Average Returns        331.945
time/data storing (s)               0.031149
time/evaluation sampling (s)      109.437
time/exploration sampling (s)     115.284
time/logging (s)                    0.0266501
time/saving (s)                     0.0728031
time/training (s)                  10.2701
time/epoch (s)                    235.122
time/total (s)                  11061
Epoch                              47
-----------------------------  ---------------
2023-08-31 15:03:59.820038 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 48 finished
-----------------------------  ---------------
replay_buffer/size             246000
trainer/QF1 Loss                    0.106601
trainer/QF2 Loss                    0.12871
trainer/Policy Loss               -54.682
trainer/Q1 Predictions Mean        65.9227
trainer/Q1 Predictions Std          4.43757
trainer/Q1 Predictions Max         72.181
trainer/Q1 Predictions Min         45.97
trainer/Q2 Predictions Mean        65.8336
trainer/Q2 Predictions Std          4.43399
trainer/Q2 Predictions Max         72.1168
trainer/Q2 Predictions Min         45.9486
trainer/Q Targets Mean             65.863
trainer/Q Targets Std               4.43041
trainer/Q Targets Max              71.9694
trainer/Q Targets Min              46.2338
trainer/Log Pis Mean               11.3112
trainer/Log Pis Std                 7.5206
trainer/Log Pis Max                37.4557
trainer/Log Pis Min                -5.1299
trainer/Policy mu Mean             -0.0683548
trainer/Policy mu Std               1.71454
trainer/Policy mu Max               4.81874
trainer/Policy mu Min              -7.32799
trainer/Policy log std Mean        -0.375489
trainer/Policy log std Std          0.128417
trainer/Policy log std Max          0.289989
trainer/Policy log std Min         -0.953203
trainer/Alpha                       0.00340219
trainer/Alpha Loss                 -3.91492
exploration/num steps total    246000
exploration/num paths total       492
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.657916
exploration/Rewards Std             0.0618138
exploration/Rewards Max             0.963467
exploration/Rewards Min             0.377908
exploration/Returns Mean          328.958
exploration/Returns Std             6.29026
exploration/Returns Max           341.214
exploration/Returns Min           317.814
exploration/Actions Mean            0.0151173
exploration/Actions Std             0.752582
exploration/Actions Max             0.999962
exploration/Actions Min            -0.99993
exploration/Num Paths              10
exploration/Average Returns       328.958
evaluation/num steps total     245000
evaluation/num paths total        490
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.647868
evaluation/Rewards Std              0.0613241
evaluation/Rewards Max              0.945309
evaluation/Rewards Min              0.407525
evaluation/Returns Mean           323.934
evaluation/Returns Std              6.17191
evaluation/Returns Max            333.796
evaluation/Returns Min            315.248
evaluation/ExplReturns Mean       323.934
evaluation/ExplReturns Std          6.17191
evaluation/ExplReturns Max        333.796
evaluation/ExplReturns Min        315.248
evaluation/Actions Mean             0.0207501
evaluation/Actions Std              0.741388
evaluation/Actions Max              0.999894
evaluation/Actions Min             -0.999388
evaluation/Num Paths               10
evaluation/Average Returns        323.934
time/data storing (s)               0.0311753
time/evaluation sampling (s)      107.134
time/exploration sampling (s)     112.327
time/logging (s)                    0.0261778
time/saving (s)                     0.0743646
time/training (s)                  12.4367
time/epoch (s)                    232.029
time/total (s)                  11293.1
Epoch                              48
-----------------------------  ---------------
2023-08-31 15:07:53.388447 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 49 finished
-----------------------------  ---------------
replay_buffer/size             251000
trainer/QF1 Loss                    0.0977727
trainer/QF2 Loss                    0.106033
trainer/Policy Loss               -53.1116
trainer/Q1 Predictions Mean        65.6482
trainer/Q1 Predictions Std          3.9431
trainer/Q1 Predictions Max         71.9616
trainer/Q1 Predictions Min         47.7978
trainer/Q2 Predictions Mean        65.6291
trainer/Q2 Predictions Std          3.92934
trainer/Q2 Predictions Max         72.0318
trainer/Q2 Predictions Min         48.1192
trainer/Q Targets Mean             65.6687
trainer/Q Targets Std               3.94617
trainer/Q Targets Max              71.8696
trainer/Q Targets Min              47.653
trainer/Log Pis Mean               12.6728
trainer/Log Pis Std                 8.51523
trainer/Log Pis Max                35.5363
trainer/Log Pis Min                -5.79875
trainer/Policy mu Mean              0.00664848
trainer/Policy mu Std               1.8119
trainer/Policy mu Max               6.00831
trainer/Policy mu Min              -6.86528
trainer/Policy log std Mean        -0.37067
trainer/Policy log std Std          0.142485
trainer/Policy log std Max          0.174943
trainer/Policy log std Min         -1.04151
trainer/Alpha                       0.00341743
trainer/Alpha Loss                  3.821
exploration/num steps total    251000
exploration/num paths total       502
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.666852
exploration/Rewards Std             0.0763928
exploration/Rewards Max             0.97054
exploration/Rewards Min             0.335956
exploration/Returns Mean          333.426
exploration/Returns Std             9.71443
exploration/Returns Max           344.993
exploration/Returns Min           309.113
exploration/Actions Mean           -0.0163272
exploration/Actions Std             0.764332
exploration/Actions Max             0.999974
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns       333.426
evaluation/num steps total     250000
evaluation/num paths total        500
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.652317
evaluation/Rewards Std              0.0690754
evaluation/Rewards Max              0.977859
evaluation/Rewards Min              0.387009
evaluation/Returns Mean           326.159
evaluation/Returns Std              6.88162
evaluation/Returns Max            334.287
evaluation/Returns Min            309.875
evaluation/ExplReturns Mean       326.159
evaluation/ExplReturns Std          6.88162
evaluation/ExplReturns Max        334.287
evaluation/ExplReturns Min        309.875
evaluation/Actions Mean            -0.0314444
evaluation/Actions Std              0.741718
evaluation/Actions Max              0.999789
evaluation/Actions Min             -0.999949
evaluation/Num Paths               10
evaluation/Average Returns        326.159
time/data storing (s)               0.0314801
time/evaluation sampling (s)      109.341
time/exploration sampling (s)     113.8
time/logging (s)                    0.0264364
time/saving (s)                     0.0420707
time/training (s)                  10.3239
time/epoch (s)                    233.565
time/total (s)                  11526.6
Epoch                              49
-----------------------------  ---------------
2023-08-31 15:11:49.861149 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 50 finished
-----------------------------  ----------------
replay_buffer/size             256000
trainer/QF1 Loss                    0.126942
trainer/QF2 Loss                    0.112083
trainer/Policy Loss               -55.2238
trainer/Q1 Predictions Mean        66.2585
trainer/Q1 Predictions Std          3.3028
trainer/Q1 Predictions Max         72.4828
trainer/Q1 Predictions Min         52.5818
trainer/Q2 Predictions Mean        66.2072
trainer/Q2 Predictions Std          3.27684
trainer/Q2 Predictions Max         72.682
trainer/Q2 Predictions Min         52.0404
trainer/Q Targets Mean             66.2629
trainer/Q Targets Std               3.27365
trainer/Q Targets Max              71.9733
trainer/Q Targets Min              52.6738
trainer/Log Pis Mean               11.139
trainer/Log Pis Std                 7.37055
trainer/Log Pis Max                36.7985
trainer/Log Pis Min                -7.78952
trainer/Policy mu Mean              0.105139
trainer/Policy mu Std               1.71149
trainer/Policy mu Max               5.36556
trainer/Policy mu Min              -4.37023
trainer/Policy log std Mean        -0.360137
trainer/Policy log std Std          0.130497
trainer/Policy log std Max          0.133353
trainer/Policy log std Min         -0.863486
trainer/Alpha                       0.00342778
trainer/Alpha Loss                 -4.88684
exploration/num steps total    256000
exploration/num paths total       512
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.646896
exploration/Rewards Std             0.077669
exploration/Rewards Max             0.972857
exploration/Rewards Min             0.31948
exploration/Returns Mean          323.448
exploration/Returns Std            15.7495
exploration/Returns Max           342.165
exploration/Returns Min           288.484
exploration/Actions Mean            1.85055e-05
exploration/Actions Std             0.769928
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999939
exploration/Num Paths              10
exploration/Average Returns       323.448
evaluation/num steps total     255000
evaluation/num paths total        510
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.618954
evaluation/Rewards Std              0.06829
evaluation/Rewards Max              0.946107
evaluation/Rewards Min              0.308947
evaluation/Returns Mean           309.477
evaluation/Returns Std             12.9653
evaluation/Returns Max            322.759
evaluation/Returns Min            275.422
evaluation/ExplReturns Mean       309.477
evaluation/ExplReturns Std         12.9653
evaluation/ExplReturns Max        322.759
evaluation/ExplReturns Min        275.422
evaluation/Actions Mean            -0.0319203
evaluation/Actions Std              0.733404
evaluation/Actions Max              0.999933
evaluation/Actions Min             -0.999909
evaluation/Num Paths               10
evaluation/Average Returns        309.477
time/data storing (s)               0.0313129
time/evaluation sampling (s)      109.417
time/exploration sampling (s)     113.899
time/logging (s)                    0.0261909
time/saving (s)                     0.0696089
time/training (s)                  13.0253
time/epoch (s)                    236.469
time/total (s)                  11763.1
Epoch                              50
-----------------------------  ----------------
2023-08-31 15:15:49.224192 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size             261000
trainer/QF1 Loss                    0.0964926
trainer/QF2 Loss                    0.103885
trainer/Policy Loss               -53.0008
trainer/Q1 Predictions Mean        65.4389
trainer/Q1 Predictions Std          4.32766
trainer/Q1 Predictions Max         71.7025
trainer/Q1 Predictions Min         45.8681
trainer/Q2 Predictions Mean        65.4593
trainer/Q2 Predictions Std          4.32041
trainer/Q2 Predictions Max         71.7412
trainer/Q2 Predictions Min         46.2885
trainer/Q Targets Mean             65.4783
trainer/Q Targets Std               4.29526
trainer/Q Targets Max              71.9295
trainer/Q Targets Min              45.902
trainer/Log Pis Mean               12.5954
trainer/Log Pis Std                 8.10084
trainer/Log Pis Max                46.5159
trainer/Log Pis Min                -4.19913
trainer/Policy mu Mean             -0.150773
trainer/Policy mu Std               1.77493
trainer/Policy mu Max               5.4665
trainer/Policy mu Min              -6.55937
trainer/Policy log std Mean        -0.360697
trainer/Policy log std Std          0.138983
trainer/Policy log std Max          0.228059
trainer/Policy log std Min         -0.933443
trainer/Alpha                       0.00331396
trainer/Alpha Loss                  3.39966
exploration/num steps total    261000
exploration/num paths total       522
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.663162
exploration/Rewards Std             0.0566488
exploration/Rewards Max             0.954317
exploration/Rewards Min             0.394284
exploration/Returns Mean          331.581
exploration/Returns Std             5.51901
exploration/Returns Max           340.773
exploration/Returns Min           320.089
exploration/Actions Mean           -0.126309
exploration/Actions Std             0.744168
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999967
exploration/Num Paths              10
exploration/Average Returns       331.581
evaluation/num steps total     260000
evaluation/num paths total        520
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.644475
evaluation/Rewards Std              0.0550025
evaluation/Rewards Max              0.935795
evaluation/Rewards Min              0.3851
evaluation/Returns Mean           322.237
evaluation/Returns Std             14.3191
evaluation/Returns Max            336.501
evaluation/Returns Min            285.108
evaluation/ExplReturns Mean       322.237
evaluation/ExplReturns Std         14.3191
evaluation/ExplReturns Max        336.501
evaluation/ExplReturns Min        285.108
evaluation/Actions Mean            -0.144097
evaluation/Actions Std              0.717231
evaluation/Actions Max              0.999568
evaluation/Actions Min             -0.999523
evaluation/Num Paths               10
evaluation/Average Returns        322.237
time/data storing (s)               0.0313992
time/evaluation sampling (s)      110.572
time/exploration sampling (s)     116.091
time/logging (s)                    0.0259833
time/saving (s)                     0.0684108
time/training (s)                  12.5697
time/epoch (s)                    239.359
time/total (s)                  12002.5
Epoch                              51
-----------------------------  ---------------
2023-08-31 15:19:42.759586 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             266000
trainer/QF1 Loss                    0.149796
trainer/QF2 Loss                    0.121656
trainer/Policy Loss               -53.3062
trainer/Q1 Predictions Mean        65.7824
trainer/Q1 Predictions Std          3.70183
trainer/Q1 Predictions Max         71.7617
trainer/Q1 Predictions Min         47.4292
trainer/Q2 Predictions Mean        65.7452
trainer/Q2 Predictions Std          3.69658
trainer/Q2 Predictions Max         71.6517
trainer/Q2 Predictions Min         47.6078
trainer/Q Targets Mean             65.6055
trainer/Q Targets Std               3.69008
trainer/Q Targets Max              71.4276
trainer/Q Targets Min              47.5229
trainer/Log Pis Mean               12.5853
trainer/Log Pis Std                 7.64791
trainer/Log Pis Max                43.3953
trainer/Log Pis Min                -3.54541
trainer/Policy mu Mean              0.0363342
trainer/Policy mu Std               1.75004
trainer/Policy mu Max               5.03652
trainer/Policy mu Min              -6.46624
trainer/Policy log std Mean        -0.378561
trainer/Policy log std Std          0.146503
trainer/Policy log std Max          0.0544671
trainer/Policy log std Min         -1.03147
trainer/Alpha                       0.00333811
trainer/Alpha Loss                  3.33756
exploration/num steps total    266000
exploration/num paths total       532
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.674669
exploration/Rewards Std             0.0493891
exploration/Rewards Max             0.965737
exploration/Rewards Min             0.410542
exploration/Returns Mean          337.334
exploration/Returns Std             5.14237
exploration/Returns Max           345.983
exploration/Returns Min           326.66
exploration/Actions Mean           -0.0670448
exploration/Actions Std             0.751988
exploration/Actions Max             0.999976
exploration/Actions Min            -0.999945
exploration/Num Paths              10
exploration/Average Returns       337.334
evaluation/num steps total     265000
evaluation/num paths total        530
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.671577
evaluation/Rewards Std              0.0818304
evaluation/Rewards Max              0.969649
evaluation/Rewards Min              0.241456
evaluation/Returns Mean           335.788
evaluation/Returns Std             14.4463
evaluation/Returns Max            369.899
evaluation/Returns Min            321.546
evaluation/ExplReturns Mean       335.788
evaluation/ExplReturns Std         14.4463
evaluation/ExplReturns Max        369.899
evaluation/ExplReturns Min        321.546
evaluation/Actions Mean            -0.0835212
evaluation/Actions Std              0.722223
evaluation/Actions Max              0.999161
evaluation/Actions Min             -0.9997
evaluation/Num Paths               10
evaluation/Average Returns        335.788
time/data storing (s)               0.0309915
time/evaluation sampling (s)      108.629
time/exploration sampling (s)     114.186
time/logging (s)                    0.0271482
time/saving (s)                     0.0738683
time/training (s)                  10.5863
time/epoch (s)                    233.533
time/total (s)                  12236
Epoch                              52
-----------------------------  ---------------
2023-08-31 15:23:32.472291 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 53 finished
-----------------------------  ---------------
replay_buffer/size             271000
trainer/QF1 Loss                    0.110154
trainer/QF2 Loss                    0.112922
trainer/Policy Loss               -54.1551
trainer/Q1 Predictions Mean        65.5464
trainer/Q1 Predictions Std          3.70394
trainer/Q1 Predictions Max         71.2193
trainer/Q1 Predictions Min         52.1679
trainer/Q2 Predictions Mean        65.56
trainer/Q2 Predictions Std          3.74485
trainer/Q2 Predictions Max         71.2459
trainer/Q2 Predictions Min         51.9684
trainer/Q Targets Mean             65.6314
trainer/Q Targets Std               3.68638
trainer/Q Targets Max              71.246
trainer/Q Targets Min              52.3393
trainer/Log Pis Mean               11.5213
trainer/Log Pis Std                 7.64382
trainer/Log Pis Max                35.4626
trainer/Log Pis Min                -5.74716
trainer/Policy mu Mean             -0.0506438
trainer/Policy mu Std               1.75513
trainer/Policy mu Max               4.90749
trainer/Policy mu Min              -4.86106
trainer/Policy log std Mean        -0.359115
trainer/Policy log std Std          0.140545
trainer/Policy log std Max          0.119599
trainer/Policy log std Min         -0.932441
trainer/Alpha                       0.00336909
trainer/Alpha Loss                 -2.72513
exploration/num steps total    271000
exploration/num paths total       542
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.669826
exploration/Rewards Std             0.0664794
exploration/Rewards Max             0.952869
exploration/Rewards Min             0.359671
exploration/Returns Mean          334.913
exploration/Returns Std            10.8193
exploration/Returns Max           347.877
exploration/Returns Min           308.543
exploration/Actions Mean           -0.0472743
exploration/Actions Std             0.744814
exploration/Actions Max             0.99997
exploration/Actions Min            -0.999938
exploration/Num Paths              10
exploration/Average Returns       334.913
evaluation/num steps total     270000
evaluation/num paths total        540
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.679722
evaluation/Rewards Std              0.081982
evaluation/Rewards Max              0.974131
evaluation/Rewards Min              0.389391
evaluation/Returns Mean           339.861
evaluation/Returns Std             16.5774
evaluation/Returns Max            376.782
evaluation/Returns Min            319.183
evaluation/ExplReturns Mean       339.861
evaluation/ExplReturns Std         16.5774
evaluation/ExplReturns Max        376.782
evaluation/ExplReturns Min        319.183
evaluation/Actions Mean            -0.0194265
evaluation/Actions Std              0.718856
evaluation/Actions Max              0.999647
evaluation/Actions Min             -0.999291
evaluation/Num Paths               10
evaluation/Average Returns        339.861
time/data storing (s)               0.0313183
time/evaluation sampling (s)      106.703
time/exploration sampling (s)     112.244
time/logging (s)                    0.0258408
time/saving (s)                     0.0726824
time/training (s)                  10.6307
time/epoch (s)                    229.708
time/total (s)                  12465.7
Epoch                              53
-----------------------------  ---------------
2023-08-31 15:27:21.520599 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size             276000
trainer/QF1 Loss                    0.125352
trainer/QF2 Loss                    0.109063
trainer/Policy Loss               -53.4458
trainer/Q1 Predictions Mean        65.2623
trainer/Q1 Predictions Std          4.39574
trainer/Q1 Predictions Max         71.027
trainer/Q1 Predictions Min         42.6216
trainer/Q2 Predictions Mean        65.3067
trainer/Q2 Predictions Std          4.40085
trainer/Q2 Predictions Max         70.9942
trainer/Q2 Predictions Min         42.6396
trainer/Q Targets Mean             65.3394
trainer/Q Targets Std               4.39007
trainer/Q Targets Max              71.2046
trainer/Q Targets Min              43.014
trainer/Log Pis Mean               11.9608
trainer/Log Pis Std                 7.53815
trainer/Log Pis Max                35.0389
trainer/Log Pis Min                -2.78672
trainer/Policy mu Mean             -0.00937657
trainer/Policy mu Std               1.7465
trainer/Policy mu Max               5.02529
trainer/Policy mu Min              -5.33283
trainer/Policy log std Mean        -0.376465
trainer/Policy log std Std          0.14121
trainer/Policy log std Max          0.147302
trainer/Policy log std Min         -0.955414
trainer/Alpha                       0.00330456
trainer/Alpha Loss                 -0.223875
exploration/num steps total    276000
exploration/num paths total       552
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.65969
exploration/Rewards Std             0.060428
exploration/Rewards Max             0.969483
exploration/Rewards Min             0.427575
exploration/Returns Mean          329.845
exploration/Returns Std            11.74
exploration/Returns Max           360.126
exploration/Returns Min           318.235
exploration/Actions Mean            0.0328604
exploration/Actions Std             0.751295
exploration/Actions Max             0.999983
exploration/Actions Min            -0.999932
exploration/Num Paths              10
exploration/Average Returns       329.845
evaluation/num steps total     275000
evaluation/num paths total        550
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.661985
evaluation/Rewards Std              0.082978
evaluation/Rewards Max              0.964502
evaluation/Rewards Min              0.325917
evaluation/Returns Mean           330.992
evaluation/Returns Std             18.6882
evaluation/Returns Max            366.236
evaluation/Returns Min            292.07
evaluation/ExplReturns Mean       330.992
evaluation/ExplReturns Std         18.6882
evaluation/ExplReturns Max        366.236
evaluation/ExplReturns Min        292.07
evaluation/Actions Mean             0.0462919
evaluation/Actions Std              0.726305
evaluation/Actions Max              0.999857
evaluation/Actions Min             -0.999645
evaluation/Num Paths               10
evaluation/Average Returns        330.992
time/data storing (s)               0.0313018
time/evaluation sampling (s)      106.563
time/exploration sampling (s)     112.094
time/logging (s)                    0.0264045
time/saving (s)                     0.0155146
time/training (s)                  10.3157
time/epoch (s)                    229.045
time/total (s)                  12694.8
Epoch                              54
-----------------------------  ---------------
2023-08-31 15:31:08.941520 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size             281000
trainer/QF1 Loss                    0.120745
trainer/QF2 Loss                    0.122167
trainer/Policy Loss               -53.5542
trainer/Q1 Predictions Mean        65.7401
trainer/Q1 Predictions Std          3.87207
trainer/Q1 Predictions Max         72.7295
trainer/Q1 Predictions Min         49.0983
trainer/Q2 Predictions Mean        65.6933
trainer/Q2 Predictions Std          3.91451
trainer/Q2 Predictions Max         72.7427
trainer/Q2 Predictions Min         48.802
trainer/Q Targets Mean             65.8009
trainer/Q Targets Std               3.91776
trainer/Q Targets Max              72.7241
trainer/Q Targets Min              48.3839
trainer/Log Pis Mean               12.285
trainer/Log Pis Std                 7.26498
trainer/Log Pis Max                34.5296
trainer/Log Pis Min                -8.25271
trainer/Policy mu Mean             -0.172515
trainer/Policy mu Std               1.70956
trainer/Policy mu Max               6.10845
trainer/Policy mu Min              -5.06709
trainer/Policy log std Mean        -0.380911
trainer/Policy log std Std          0.141708
trainer/Policy log std Max          0.118669
trainer/Policy log std Min         -0.996561
trainer/Alpha                       0.00329793
trainer/Alpha Loss                  1.62869
exploration/num steps total    281000
exploration/num paths total       562
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.648648
exploration/Rewards Std             0.0550285
exploration/Rewards Max             0.95238
exploration/Rewards Min             0.280889
exploration/Returns Mean          324.324
exploration/Returns Std             9.74877
exploration/Returns Max           335.014
exploration/Returns Min           298.11
exploration/Actions Mean            0.00683182
exploration/Actions Std             0.738617
exploration/Actions Max             0.99995
exploration/Actions Min            -0.999978
exploration/Num Paths              10
exploration/Average Returns       324.324
evaluation/num steps total     280000
evaluation/num paths total        560
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.647529
evaluation/Rewards Std              0.0475878
evaluation/Rewards Max              0.952719
evaluation/Rewards Min              0.469937
evaluation/Returns Mean           323.764
evaluation/Returns Std              3.29421
evaluation/Returns Max            331.807
evaluation/Returns Min            318.622
evaluation/ExplReturns Mean       323.764
evaluation/ExplReturns Std          3.29421
evaluation/ExplReturns Max        331.807
evaluation/ExplReturns Min        318.622
evaluation/Actions Mean             0.0238503
evaluation/Actions Std              0.709391
evaluation/Actions Max              0.999221
evaluation/Actions Min             -0.999615
evaluation/Num Paths               10
evaluation/Average Returns        323.764
time/data storing (s)               0.0312541
time/evaluation sampling (s)      105.446
time/exploration sampling (s)     111.375
time/logging (s)                    0.0268635
time/saving (s)                     0.0703022
time/training (s)                  10.4674
time/epoch (s)                    227.418
time/total (s)                  12922.2
Epoch                              55
-----------------------------  ---------------
2023-08-31 15:34:57.949203 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 56 finished
-----------------------------  ---------------
replay_buffer/size             286000
trainer/QF1 Loss                    0.120254
trainer/QF2 Loss                    0.114465
trainer/Policy Loss               -53.2536
trainer/Q1 Predictions Mean        64.9481
trainer/Q1 Predictions Std          4.41473
trainer/Q1 Predictions Max         70.4018
trainer/Q1 Predictions Min         44.7913
trainer/Q2 Predictions Mean        65.0196
trainer/Q2 Predictions Std          4.43425
trainer/Q2 Predictions Max         70.656
trainer/Q2 Predictions Min         44.4669
trainer/Q Targets Mean             65.0036
trainer/Q Targets Std               4.42356
trainer/Q Targets Max              70.3163
trainer/Q Targets Min              44.1633
trainer/Log Pis Mean               11.8531
trainer/Log Pis Std                 7.3222
trainer/Log Pis Max                37.6089
trainer/Log Pis Min                -5.56337
trainer/Policy mu Mean             -0.134306
trainer/Policy mu Std               1.70034
trainer/Policy mu Max               4.87771
trainer/Policy mu Min              -4.25867
trainer/Policy log std Mean        -0.394669
trainer/Policy log std Std          0.146211
trainer/Policy log std Max          0.18608
trainer/Policy log std Min         -0.966265
trainer/Alpha                       0.00341815
trainer/Alpha Loss                 -0.834201
exploration/num steps total    286000
exploration/num paths total       572
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.673271
exploration/Rewards Std             0.0563112
exploration/Rewards Max             0.956031
exploration/Rewards Min             0.312832
exploration/Returns Mean          336.636
exploration/Returns Std             4.12402
exploration/Returns Max           342.934
exploration/Returns Min           331.082
exploration/Actions Mean           -0.0467137
exploration/Actions Std             0.74653
exploration/Actions Max             0.9999
exploration/Actions Min            -0.999794
exploration/Num Paths              10
exploration/Average Returns       336.636
evaluation/num steps total     285000
evaluation/num paths total        570
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.668016
evaluation/Rewards Std              0.0817519
evaluation/Rewards Max              0.960009
evaluation/Rewards Min              0.272594
evaluation/Returns Mean           334.008
evaluation/Returns Std              7.86093
evaluation/Returns Max            346.182
evaluation/Returns Min            318.599
evaluation/ExplReturns Mean       334.008
evaluation/ExplReturns Std          7.86093
evaluation/ExplReturns Max        346.182
evaluation/ExplReturns Min        318.599
evaluation/Actions Mean            -0.06129
evaluation/Actions Std              0.729558
evaluation/Actions Max              0.999814
evaluation/Actions Min             -0.999797
evaluation/Num Paths               10
evaluation/Average Returns        334.008
time/data storing (s)               0.0312931
time/evaluation sampling (s)      106.186
time/exploration sampling (s)     112.592
time/logging (s)                    0.0268079
time/saving (s)                     0.0780838
time/training (s)                  10.09
time/epoch (s)                    229.004
time/total (s)                  13151.2
Epoch                              56
-----------------------------  ---------------
2023-08-31 15:38:50.530813 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 57 finished
-----------------------------  ---------------
replay_buffer/size             291000
trainer/QF1 Loss                    0.122157
trainer/QF2 Loss                    0.128692
trainer/Policy Loss               -53.6286
trainer/Q1 Predictions Mean        65.5826
trainer/Q1 Predictions Std          3.77037
trainer/Q1 Predictions Max         70.729
trainer/Q1 Predictions Min         42.7961
trainer/Q2 Predictions Mean        65.5849
trainer/Q2 Predictions Std          3.7211
trainer/Q2 Predictions Max         70.6487
trainer/Q2 Predictions Min         42.794
trainer/Q Targets Mean             65.4949
trainer/Q Targets Std               3.79133
trainer/Q Targets Max              70.836
trainer/Q Targets Min              42.8044
trainer/Log Pis Mean               12.0754
trainer/Log Pis Std                 7.44477
trainer/Log Pis Max                31.2318
trainer/Log Pis Min                -7.97487
trainer/Policy mu Mean             -0.161385
trainer/Policy mu Std               1.72888
trainer/Policy mu Max               4.97033
trainer/Policy mu Min              -5.25102
trainer/Policy log std Mean        -0.368723
trainer/Policy log std Std          0.149505
trainer/Policy log std Max          0.243795
trainer/Policy log std Min         -0.902074
trainer/Alpha                       0.00324267
trainer/Alpha Loss                  0.431967
exploration/num steps total    291000
exploration/num paths total       582
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.635309
exploration/Rewards Std             0.078846
exploration/Rewards Max             0.923562
exploration/Rewards Min             0.225532
exploration/Returns Mean          317.654
exploration/Returns Std            20.4011
exploration/Returns Max           336.273
exploration/Returns Min           266.408
exploration/Actions Mean           -0.0544551
exploration/Actions Std             0.743483
exploration/Actions Max             0.999987
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns       317.654
evaluation/num steps total     290000
evaluation/num paths total        580
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.621421
evaluation/Rewards Std              0.0952173
evaluation/Rewards Max              0.9503
evaluation/Rewards Min              0.189318
evaluation/Returns Mean           310.711
evaluation/Returns Std             25.0285
evaluation/Returns Max            332.887
evaluation/Returns Min            259.383
evaluation/ExplReturns Mean       310.711
evaluation/ExplReturns Std         25.0285
evaluation/ExplReturns Max        332.887
evaluation/ExplReturns Min        259.383
evaluation/Actions Mean            -0.0543148
evaluation/Actions Std              0.696149
evaluation/Actions Max              0.999961
evaluation/Actions Min             -0.999973
evaluation/Num Paths               10
evaluation/Average Returns        310.711
time/data storing (s)               0.0314808
time/evaluation sampling (s)      108.225
time/exploration sampling (s)     113.906
time/logging (s)                    0.0264702
time/saving (s)                     0.088567
time/training (s)                  10.2993
time/epoch (s)                    232.578
time/total (s)                  13383.8
Epoch                              57
-----------------------------  ---------------
2023-08-31 15:42:47.124229 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size             296000
trainer/QF1 Loss                    0.0993535
trainer/QF2 Loss                    0.0850251
trainer/Policy Loss               -53.2678
trainer/Q1 Predictions Mean        65.5135
trainer/Q1 Predictions Std          3.96602
trainer/Q1 Predictions Max         70.8809
trainer/Q1 Predictions Min         45.5912
trainer/Q2 Predictions Mean        65.4421
trainer/Q2 Predictions Std          3.9242
trainer/Q2 Predictions Max         70.8059
trainer/Q2 Predictions Min         45.6682
trainer/Q Targets Mean             65.3788
trainer/Q Targets Std               3.91693
trainer/Q Targets Max              70.3569
trainer/Q Targets Min              45.6763
trainer/Log Pis Mean               12.3497
trainer/Log Pis Std                 8.17948
trainer/Log Pis Max                45.2524
trainer/Log Pis Min                -3.81429
trainer/Policy mu Mean              0.00749257
trainer/Policy mu Std               1.74187
trainer/Policy mu Max               5.13237
trainer/Policy mu Min              -4.89095
trainer/Policy log std Mean        -0.389402
trainer/Policy log std Std          0.13532
trainer/Policy log std Max          0.0881509
trainer/Policy log std Min         -0.991633
trainer/Alpha                       0.00324528
trainer/Alpha Loss                  2.00373
exploration/num steps total    296000
exploration/num paths total       592
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.633602
exploration/Rewards Std             0.0603581
exploration/Rewards Max             0.936379
exploration/Rewards Min             0.336555
exploration/Returns Mean          316.801
exploration/Returns Std            17.3038
exploration/Returns Max           337.479
exploration/Returns Min           283.033
exploration/Actions Mean           -0.0185009
exploration/Actions Std             0.742648
exploration/Actions Max             0.999925
exploration/Actions Min            -0.999903
exploration/Num Paths              10
exploration/Average Returns       316.801
evaluation/num steps total     295000
evaluation/num paths total        590
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.609609
evaluation/Rewards Std              0.0831954
evaluation/Rewards Max              0.964733
evaluation/Rewards Min              0.396849
evaluation/Returns Mean           304.805
evaluation/Returns Std             27.5943
evaluation/Returns Max            351.083
evaluation/Returns Min            259.155
evaluation/ExplReturns Mean       304.805
evaluation/ExplReturns Std         27.5943
evaluation/ExplReturns Max        351.083
evaluation/ExplReturns Min        259.155
evaluation/Actions Mean            -0.0203798
evaluation/Actions Std              0.699513
evaluation/Actions Max              0.999105
evaluation/Actions Min             -0.999277
evaluation/Num Paths               10
evaluation/Average Returns        304.805
time/data storing (s)               0.0313635
time/evaluation sampling (s)      109.015
time/exploration sampling (s)     115.167
time/logging (s)                    0.0262937
time/saving (s)                     0.0668677
time/training (s)                  12.2833
time/epoch (s)                    236.589
time/total (s)                  13620.4
Epoch                              58
-----------------------------  ---------------
2023-08-31 15:46:40.336791 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size             301000
trainer/QF1 Loss                    0.0933169
trainer/QF2 Loss                    0.0810082
trainer/Policy Loss               -52.684
trainer/Q1 Predictions Mean        65.0817
trainer/Q1 Predictions Std          3.77125
trainer/Q1 Predictions Max         70.2798
trainer/Q1 Predictions Min         47.8225
trainer/Q2 Predictions Mean        65.01
trainer/Q2 Predictions Std          3.74018
trainer/Q2 Predictions Max         70.0072
trainer/Q2 Predictions Min         47.4362
trainer/Q Targets Mean             65.0651
trainer/Q Targets Std               3.73442
trainer/Q Targets Max              70.4004
trainer/Q Targets Min              47.4708
trainer/Log Pis Mean               12.4976
trainer/Log Pis Std                 7.53887
trainer/Log Pis Max                39.1266
trainer/Log Pis Min                -6.34286
trainer/Policy mu Mean              0.0285595
trainer/Policy mu Std               1.77522
trainer/Policy mu Max               6.21652
trainer/Policy mu Min              -4.26385
trainer/Policy log std Mean        -0.377991
trainer/Policy log std Std          0.137149
trainer/Policy log std Max          0.174852
trainer/Policy log std Min         -0.879726
trainer/Alpha                       0.00320484
trainer/Alpha Loss                  2.85816
exploration/num steps total    301000
exploration/num paths total       602
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.676048
exploration/Rewards Std             0.0394643
exploration/Rewards Max             0.939349
exploration/Rewards Min             0.44573
exploration/Returns Mean          338.024
exploration/Returns Std             5.27639
exploration/Returns Max           343.632
exploration/Returns Min           326.622
exploration/Actions Mean           -0.0340334
exploration/Actions Std             0.752266
exploration/Actions Max             0.999964
exploration/Actions Min            -0.999956
exploration/Num Paths              10
exploration/Average Returns       338.024
evaluation/num steps total     300000
evaluation/num paths total        600
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.663881
evaluation/Rewards Std              0.0517279
evaluation/Rewards Max              0.936839
evaluation/Rewards Min              0.314578
evaluation/Returns Mean           331.94
evaluation/Returns Std              5.36471
evaluation/Returns Max            339.918
evaluation/Returns Min            322.945
evaluation/ExplReturns Mean       331.94
evaluation/ExplReturns Std          5.36471
evaluation/ExplReturns Max        339.918
evaluation/ExplReturns Min        322.945
evaluation/Actions Mean            -0.0399234
evaluation/Actions Std              0.736867
evaluation/Actions Max              0.999438
evaluation/Actions Min             -0.998446
evaluation/Num Paths               10
evaluation/Average Returns        331.94
time/data storing (s)               0.0312862
time/evaluation sampling (s)      108.428
time/exploration sampling (s)     114.355
time/logging (s)                    0.0262733
time/saving (s)                     0.0179336
time/training (s)                  10.3501
time/epoch (s)                    233.209
time/total (s)                  13853.6
Epoch                              59
-----------------------------  ---------------
2023-08-31 15:50:37.324866 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size             306000
trainer/QF1 Loss                    0.0953853
trainer/QF2 Loss                    0.107879
trainer/Policy Loss               -53.9691
trainer/Q1 Predictions Mean        65.5931
trainer/Q1 Predictions Std          3.44497
trainer/Q1 Predictions Max         69.9766
trainer/Q1 Predictions Min         50.5976
trainer/Q2 Predictions Mean        65.6198
trainer/Q2 Predictions Std          3.42722
trainer/Q2 Predictions Max         69.8389
trainer/Q2 Predictions Min         50.8323
trainer/Q Targets Mean             65.6608
trainer/Q Targets Std               3.45476
trainer/Q Targets Max              69.9005
trainer/Q Targets Min              50.8832
trainer/Log Pis Mean               11.7538
trainer/Log Pis Std                 7.71196
trainer/Log Pis Max                44.9399
trainer/Log Pis Min                -4.59341
trainer/Policy mu Mean             -0.0367018
trainer/Policy mu Std               1.71114
trainer/Policy mu Max               4.89154
trainer/Policy mu Min              -4.97291
trainer/Policy log std Mean        -0.38149
trainer/Policy log std Std          0.13131
trainer/Policy log std Max          0.100578
trainer/Policy log std Min         -0.892344
trainer/Alpha                       0.00325084
trainer/Alpha Loss                 -1.41018
exploration/num steps total    306000
exploration/num paths total       612
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.674438
exploration/Rewards Std             0.0288808
exploration/Rewards Max             0.727842
exploration/Rewards Min             0.482992
exploration/Returns Mean          337.219
exploration/Returns Std             2.8832
exploration/Returns Max           344.147
exploration/Returns Min           333.38
exploration/Actions Mean           -0.044483
exploration/Actions Std             0.740531
exploration/Actions Max             0.99994
exploration/Actions Min            -0.999812
exploration/Num Paths              10
exploration/Average Returns       337.219
evaluation/num steps total     305000
evaluation/num paths total        610
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.665407
evaluation/Rewards Std              0.0387833
evaluation/Rewards Max              0.729038
evaluation/Rewards Min              0.312788
evaluation/Returns Mean           332.704
evaluation/Returns Std              5.19892
evaluation/Returns Max            339.92
evaluation/Returns Min            320.682
evaluation/ExplReturns Mean       332.704
evaluation/ExplReturns Std          5.19892
evaluation/ExplReturns Max        339.92
evaluation/ExplReturns Min        320.682
evaluation/Actions Mean            -0.0614464
evaluation/Actions Std              0.711898
evaluation/Actions Max              0.999645
evaluation/Actions Min             -0.999009
evaluation/Num Paths               10
evaluation/Average Returns        332.704
time/data storing (s)               0.0312714
time/evaluation sampling (s)      111.054
time/exploration sampling (s)     115.281
time/logging (s)                    0.0261994
time/saving (s)                     0.0826067
time/training (s)                  10.5087
time/epoch (s)                    236.984
time/total (s)                  14090.6
Epoch                              60
-----------------------------  ---------------
2023-08-31 15:54:30.158367 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             311000
trainer/QF1 Loss                    0.153547
trainer/QF2 Loss                    0.109672
trainer/Policy Loss               -53.1191
trainer/Q1 Predictions Mean        65.1218
trainer/Q1 Predictions Std          3.26868
trainer/Q1 Predictions Max         69.9124
trainer/Q1 Predictions Min         53.6041
trainer/Q2 Predictions Mean        65.2387
trainer/Q2 Predictions Std          3.27416
trainer/Q2 Predictions Max         70.0159
trainer/Q2 Predictions Min         53.4949
trainer/Q Targets Mean             65.3201
trainer/Q Targets Std               3.31954
trainer/Q Targets Max              70.2937
trainer/Q Targets Min              53.6515
trainer/Log Pis Mean               12.1365
trainer/Log Pis Std                 8.04486
trainer/Log Pis Max                43.0474
trainer/Log Pis Min                -6.13571
trainer/Policy mu Mean             -0.238743
trainer/Policy mu Std               1.71192
trainer/Policy mu Max               4.61841
trainer/Policy mu Min              -5.06613
trainer/Policy log std Mean        -0.380507
trainer/Policy log std Std          0.141806
trainer/Policy log std Max          0.0979516
trainer/Policy log std Min         -1.03628
trainer/Alpha                       0.00308467
trainer/Alpha Loss                  0.788971
exploration/num steps total    311000
exploration/num paths total       622
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.66467
exploration/Rewards Std             0.054154
exploration/Rewards Max             0.945455
exploration/Rewards Min             0.411914
exploration/Returns Mean          332.335
exploration/Returns Std            12.9979
exploration/Returns Max           342.149
exploration/Returns Min           294.846
exploration/Actions Mean           -0.0874963
exploration/Actions Std             0.743639
exploration/Actions Max             0.999934
exploration/Actions Min            -0.999948
exploration/Num Paths              10
exploration/Average Returns       332.335
evaluation/num steps total     310000
evaluation/num paths total        620
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.705773
evaluation/Rewards Std              0.104426
evaluation/Rewards Max              0.975602
evaluation/Rewards Min              0.30934
evaluation/Returns Mean           352.887
evaluation/Returns Std             28.1615
evaluation/Returns Max            405.61
evaluation/Returns Min            308.082
evaluation/ExplReturns Mean       352.887
evaluation/ExplReturns Std         28.1615
evaluation/ExplReturns Max        405.61
evaluation/ExplReturns Min        308.082
evaluation/Actions Mean            -0.0432763
evaluation/Actions Std              0.703152
evaluation/Actions Max              0.999449
evaluation/Actions Min             -0.999788
evaluation/Num Paths               10
evaluation/Average Returns        352.887
time/data storing (s)               0.0310277
time/evaluation sampling (s)      108.645
time/exploration sampling (s)     113.705
time/logging (s)                    0.0266319
time/saving (s)                     0.0721402
time/training (s)                  10.3507
time/epoch (s)                    232.83
time/total (s)                  14323.4
Epoch                              61
-----------------------------  ---------------
2023-08-31 15:58:19.032834 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size             316000
trainer/QF1 Loss                    0.0862459
trainer/QF2 Loss                    0.0921256
trainer/Policy Loss               -53.2097
trainer/Q1 Predictions Mean        65.1953
trainer/Q1 Predictions Std          3.86769
trainer/Q1 Predictions Max         70.1814
trainer/Q1 Predictions Min         44.3515
trainer/Q2 Predictions Mean        65.2553
trainer/Q2 Predictions Std          3.87856
trainer/Q2 Predictions Max         70.3278
trainer/Q2 Predictions Min         43.9838
trainer/Q Targets Mean             65.2306
trainer/Q Targets Std               3.85555
trainer/Q Targets Max              70.2819
trainer/Q Targets Min              43.9682
trainer/Log Pis Mean               12.1352
trainer/Log Pis Std                 7.61122
trainer/Log Pis Max                40.6446
trainer/Log Pis Min                -3.79103
trainer/Policy mu Mean             -0.0285433
trainer/Policy mu Std               1.7327
trainer/Policy mu Max               4.68814
trainer/Policy mu Min              -4.86946
trainer/Policy log std Mean        -0.388188
trainer/Policy log std Std          0.149947
trainer/Policy log std Max          0.14086
trainer/Policy log std Min         -1.00896
trainer/Alpha                       0.00307946
trainer/Alpha Loss                  0.782005
exploration/num steps total    316000
exploration/num paths total       632
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.714973
exploration/Rewards Std             0.088224
exploration/Rewards Max             0.976504
exploration/Rewards Min             0.463368
exploration/Returns Mean          357.487
exploration/Returns Std            18.1902
exploration/Returns Max           394.289
exploration/Returns Min           334.866
exploration/Actions Mean            0.00787907
exploration/Actions Std             0.755897
exploration/Actions Max             0.999885
exploration/Actions Min            -0.999899
exploration/Num Paths              10
exploration/Average Returns       357.487
evaluation/num steps total     315000
evaluation/num paths total        630
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.747392
evaluation/Rewards Std              0.120566
evaluation/Rewards Max              0.978249
evaluation/Rewards Min              0.37347
evaluation/Returns Mean           373.696
evaluation/Returns Std             32.7806
evaluation/Returns Max            423.285
evaluation/Returns Min            316.44
evaluation/ExplReturns Mean       373.696
evaluation/ExplReturns Std         32.7806
evaluation/ExplReturns Max        423.285
evaluation/ExplReturns Min        316.44
evaluation/Actions Mean             0.0154515
evaluation/Actions Std              0.728008
evaluation/Actions Max              0.998714
evaluation/Actions Min             -0.999867
evaluation/Num Paths               10
evaluation/Average Returns        373.696
time/data storing (s)               0.0312827
time/evaluation sampling (s)      107.526
time/exploration sampling (s)     110.908
time/logging (s)                    0.0258697
time/saving (s)                     0.0686515
time/training (s)                  10.3093
time/epoch (s)                    228.87
time/total (s)                  14552.3
Epoch                              62
-----------------------------  ---------------
2023-08-31 16:02:07.417059 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             321000
trainer/QF1 Loss                    0.0807922
trainer/QF2 Loss                    0.0913527
trainer/Policy Loss               -53.5804
trainer/Q1 Predictions Mean        65.4019
trainer/Q1 Predictions Std          3.57678
trainer/Q1 Predictions Max         70.0448
trainer/Q1 Predictions Min         47.0569
trainer/Q2 Predictions Mean        65.3661
trainer/Q2 Predictions Std          3.54443
trainer/Q2 Predictions Max         70.7945
trainer/Q2 Predictions Min         46.6962
trainer/Q Targets Mean             65.3924
trainer/Q Targets Std               3.57837
trainer/Q Targets Max              71.1995
trainer/Q Targets Min              46.7244
trainer/Log Pis Mean               11.9241
trainer/Log Pis Std                 8.49808
trainer/Log Pis Max                53.2769
trainer/Log Pis Min                -3.73386
trainer/Policy mu Mean             -0.0918412
trainer/Policy mu Std               1.73246
trainer/Policy mu Max               5.3229
trainer/Policy mu Min              -5.24931
trainer/Policy log std Mean        -0.387347
trainer/Policy log std Std          0.148937
trainer/Policy log std Max          0.156467
trainer/Policy log std Min         -1.0914
trainer/Alpha                       0.00298147
trainer/Alpha Loss                 -0.44125
exploration/num steps total    321000
exploration/num paths total       642
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.673895
exploration/Rewards Std             0.105681
exploration/Rewards Max             0.978338
exploration/Rewards Min             0.242942
exploration/Returns Mean          336.948
exploration/Returns Std            37.02
exploration/Returns Max           398.666
exploration/Returns Min           244.841
exploration/Actions Mean           -0.00937457
exploration/Actions Std             0.754335
exploration/Actions Max             0.999963
exploration/Actions Min            -0.999951
exploration/Num Paths              10
exploration/Average Returns       336.948
evaluation/num steps total     320000
evaluation/num paths total        640
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.671129
evaluation/Rewards Std              0.0633298
evaluation/Rewards Max              0.974661
evaluation/Rewards Min              0.246169
evaluation/Returns Mean           335.565
evaluation/Returns Std              6.70264
evaluation/Returns Max            347.286
evaluation/Returns Min            323.255
evaluation/ExplReturns Mean       335.565
evaluation/ExplReturns Std          6.70264
evaluation/ExplReturns Max        347.286
evaluation/ExplReturns Min        323.255
evaluation/Actions Mean            -0.0158611
evaluation/Actions Std              0.713277
evaluation/Actions Max              0.999535
evaluation/Actions Min             -0.999107
evaluation/Num Paths               10
evaluation/Average Returns        335.565
time/data storing (s)               0.0307351
time/evaluation sampling (s)      106.292
time/exploration sampling (s)     111.939
time/logging (s)                    0.0257131
time/saving (s)                     0.0728643
time/training (s)                  10.0201
time/epoch (s)                    228.38
time/total (s)                  14780.7
Epoch                              63
-----------------------------  ---------------
2023-08-31 16:05:59.557640 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size             326000
trainer/QF1 Loss                    0.0969919
trainer/QF2 Loss                    0.129476
trainer/Policy Loss               -55.9084
trainer/Q1 Predictions Mean        65.6406
trainer/Q1 Predictions Std          3.32228
trainer/Q1 Predictions Max         74.3295
trainer/Q1 Predictions Min         54.2838
trainer/Q2 Predictions Mean        65.8126
trainer/Q2 Predictions Std          3.31164
trainer/Q2 Predictions Max         74.8523
trainer/Q2 Predictions Min         54.3903
trainer/Q Targets Mean             65.6523
trainer/Q Targets Std               3.30795
trainer/Q Targets Max              74.5856
trainer/Q Targets Min              53.9578
trainer/Log Pis Mean                9.891
trainer/Log Pis Std                 7.07558
trainer/Log Pis Max                31.1861
trainer/Log Pis Min                -7.45053
trainer/Policy mu Mean             -0.10639
trainer/Policy mu Std               1.62954
trainer/Policy mu Max               4.98122
trainer/Policy mu Min              -4.17342
trainer/Policy log std Mean        -0.372725
trainer/Policy log std Std          0.145929
trainer/Policy log std Max          0.131152
trainer/Policy log std Min         -1.19702
trainer/Alpha                       0.00299777
trainer/Alpha Loss                -12.2522
exploration/num steps total    326000
exploration/num paths total       652
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.68342
exploration/Rewards Std             0.0657477
exploration/Rewards Max             0.973314
exploration/Rewards Min             0.269001
exploration/Returns Mean          341.71
exploration/Returns Std            11.7949
exploration/Returns Max           371.235
exploration/Returns Min           327.582
exploration/Actions Mean           -0.0200365
exploration/Actions Std             0.741167
exploration/Actions Max             0.999926
exploration/Actions Min            -0.999901
exploration/Num Paths              10
exploration/Average Returns       341.71
evaluation/num steps total     325000
evaluation/num paths total        650
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.693884
evaluation/Rewards Std              0.0789244
evaluation/Rewards Max              0.969086
evaluation/Rewards Min              0.335185
evaluation/Returns Mean           346.942
evaluation/Returns Std             15.3239
evaluation/Returns Max            363.741
evaluation/Returns Min            316.669
evaluation/ExplReturns Mean       346.942
evaluation/ExplReturns Std         15.3239
evaluation/ExplReturns Max        363.741
evaluation/ExplReturns Min        316.669
evaluation/Actions Mean            -0.00774939
evaluation/Actions Std              0.702915
evaluation/Actions Max              0.99887
evaluation/Actions Min             -0.998126
evaluation/Num Paths               10
evaluation/Average Returns        346.942
time/data storing (s)               0.0312748
time/evaluation sampling (s)      108.177
time/exploration sampling (s)     113.464
time/logging (s)                    0.0256796
time/saving (s)                     0.0654276
time/training (s)                  10.373
time/epoch (s)                    232.137
time/total (s)                  15012.8
Epoch                              64
-----------------------------  ---------------
2023-08-31 16:09:53.843205 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size             331000
trainer/QF1 Loss                    0.080772
trainer/QF2 Loss                    0.0798826
trainer/Policy Loss               -53.1608
trainer/Q1 Predictions Mean        65.4161
trainer/Q1 Predictions Std          3.6777
trainer/Q1 Predictions Max         76.537
trainer/Q1 Predictions Min         47.101
trainer/Q2 Predictions Mean        65.3771
trainer/Q2 Predictions Std          3.63524
trainer/Q2 Predictions Max         76.284
trainer/Q2 Predictions Min         47.9464
trainer/Q Targets Mean             65.3922
trainer/Q Targets Std               3.68419
trainer/Q Targets Max              76.2559
trainer/Q Targets Min              47.649
trainer/Log Pis Mean               12.347
trainer/Log Pis Std                 7.19544
trainer/Log Pis Max                39.6429
trainer/Log Pis Min                -7.73228
trainer/Policy mu Mean             -0.167352
trainer/Policy mu Std               1.71001
trainer/Policy mu Max               5.40524
trainer/Policy mu Min              -5.26038
trainer/Policy log std Mean        -0.399006
trainer/Policy log std Std          0.150996
trainer/Policy log std Max          0.139498
trainer/Policy log std Min         -1.00614
trainer/Alpha                       0.00290536
trainer/Alpha Loss                  2.02695
exploration/num steps total    331000
exploration/num paths total       662
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.695281
exploration/Rewards Std             0.0644689
exploration/Rewards Max             0.97864
exploration/Rewards Min             0.494794
exploration/Returns Mean          347.641
exploration/Returns Std            12.4355
exploration/Returns Max           362.29
exploration/Returns Min           314.291
exploration/Actions Mean            0.0134875
exploration/Actions Std             0.753505
exploration/Actions Max             0.999983
exploration/Actions Min            -0.999932
exploration/Num Paths              10
exploration/Average Returns       347.641
evaluation/num steps total     330000
evaluation/num paths total        660
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.679561
evaluation/Rewards Std              0.0608273
evaluation/Rewards Max              0.977909
evaluation/Rewards Min              0.43623
evaluation/Returns Mean           339.781
evaluation/Returns Std             14.065
evaluation/Returns Max            358.093
evaluation/Returns Min            321.395
evaluation/ExplReturns Mean       339.781
evaluation/ExplReturns Std         14.065
evaluation/ExplReturns Max        358.093
evaluation/ExplReturns Min        321.395
evaluation/Actions Mean            -0.0280343
evaluation/Actions Std              0.71852
evaluation/Actions Max              0.999318
evaluation/Actions Min             -0.999307
evaluation/Num Paths               10
evaluation/Average Returns        339.781
time/data storing (s)               0.0310099
time/evaluation sampling (s)      109.611
time/exploration sampling (s)     114.024
time/logging (s)                    0.0265016
time/saving (s)                     0.0705005
time/training (s)                  10.5195
time/epoch (s)                    234.283
time/total (s)                  15247.1
Epoch                              65
-----------------------------  ---------------
2023-08-31 16:13:42.477598 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size             336000
trainer/QF1 Loss                    0.111517
trainer/QF2 Loss                    0.0964869
trainer/Policy Loss               -52.7816
trainer/Q1 Predictions Mean        64.7708
trainer/Q1 Predictions Std          4.16945
trainer/Q1 Predictions Max         69.8721
trainer/Q1 Predictions Min         44.5105
trainer/Q2 Predictions Mean        64.91
trainer/Q2 Predictions Std          4.16504
trainer/Q2 Predictions Max         70.0309
trainer/Q2 Predictions Min         44.5963
trainer/Q Targets Mean             64.8792
trainer/Q Targets Std               4.14796
trainer/Q Targets Max              70.3387
trainer/Q Targets Min              44.4559
trainer/Log Pis Mean               12.1685
trainer/Log Pis Std                 7.41127
trainer/Log Pis Max                41.9787
trainer/Log Pis Min                -4.00412
trainer/Policy mu Mean             -0.185707
trainer/Policy mu Std               1.71607
trainer/Policy mu Max               5.01837
trainer/Policy mu Min              -5.68711
trainer/Policy log std Mean        -0.405964
trainer/Policy log std Std          0.158098
trainer/Policy log std Max          0.0432628
trainer/Policy log std Min         -1.06866
trainer/Alpha                       0.00283014
trainer/Alpha Loss                  0.988549
exploration/num steps total    336000
exploration/num paths total       672
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.690039
exploration/Rewards Std             0.0860994
exploration/Rewards Max             0.976278
exploration/Rewards Min             0.438762
exploration/Returns Mean          345.019
exploration/Returns Std            27.436
exploration/Returns Max           422.564
exploration/Returns Min           319.03
exploration/Actions Mean           -0.0776595
exploration/Actions Std             0.733393
exploration/Actions Max             0.999888
exploration/Actions Min            -0.99996
exploration/Num Paths              10
exploration/Average Returns       345.019
evaluation/num steps total     335000
evaluation/num paths total        670
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.692508
evaluation/Rewards Std              0.0998297
evaluation/Rewards Max              0.97854
evaluation/Rewards Min              0.494009
evaluation/Returns Mean           346.254
evaluation/Returns Std             37.6144
evaluation/Returns Max            426.083
evaluation/Returns Min            320.944
evaluation/ExplReturns Mean       346.254
evaluation/ExplReturns Std         37.6144
evaluation/ExplReturns Max        426.083
evaluation/ExplReturns Min        320.944
evaluation/Actions Mean            -0.0438001
evaluation/Actions Std              0.681101
evaluation/Actions Max              0.997075
evaluation/Actions Min             -0.999684
evaluation/Num Paths               10
evaluation/Average Returns        346.254
time/data storing (s)               0.031143
time/evaluation sampling (s)      106.606
time/exploration sampling (s)     111.696
time/logging (s)                    0.0264374
time/saving (s)                     0.0650744
time/training (s)                  10.2061
time/epoch (s)                    228.631
time/total (s)                  15475.7
Epoch                              66
-----------------------------  ---------------
2023-08-31 16:17:35.194558 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size             341000
trainer/QF1 Loss                    0.0976517
trainer/QF2 Loss                    0.107401
trainer/Policy Loss               -54.379
trainer/Q1 Predictions Mean        65.7932
trainer/Q1 Predictions Std          3.78588
trainer/Q1 Predictions Max         82.5492
trainer/Q1 Predictions Min         47.191
trainer/Q2 Predictions Mean        65.6538
trainer/Q2 Predictions Std          3.76721
trainer/Q2 Predictions Max         82.5734
trainer/Q2 Predictions Min         47.1473
trainer/Q Targets Mean             65.6621
trainer/Q Targets Std               3.76423
trainer/Q Targets Max              82.2722
trainer/Q Targets Min              47.5042
trainer/Log Pis Mean               11.429
trainer/Log Pis Std                 7.89043
trainer/Log Pis Max                46.1157
trainer/Log Pis Min                -4.44323
trainer/Policy mu Mean             -0.0276805
trainer/Policy mu Std               1.69766
trainer/Policy mu Max               7.48119
trainer/Policy mu Min              -4.84184
trainer/Policy log std Mean        -0.414191
trainer/Policy log std Std          0.150802
trainer/Policy log std Max          0.284584
trainer/Policy log std Min         -1.20991
trainer/Alpha                       0.00283462
trainer/Alpha Loss                 -3.34956
exploration/num steps total    341000
exploration/num paths total       682
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.651019
exploration/Rewards Std             0.155177
exploration/Rewards Max             0.978582
exploration/Rewards Min             0.145631
exploration/Returns Mean          325.509
exploration/Returns Std            59.1735
exploration/Returns Max           400.409
exploration/Returns Min           209.261
exploration/Actions Mean           -0.00142686
exploration/Actions Std             0.757856
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       325.509
evaluation/num steps total     340000
evaluation/num paths total        680
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.706402
evaluation/Rewards Std              0.107751
evaluation/Rewards Max              0.978922
evaluation/Rewards Min              0.431061
evaluation/Returns Mean           353.201
evaluation/Returns Std             30.3334
evaluation/Returns Max            402.883
evaluation/Returns Min            320.904
evaluation/ExplReturns Mean       353.201
evaluation/ExplReturns Std         30.3334
evaluation/ExplReturns Max        402.883
evaluation/ExplReturns Min        320.904
evaluation/Actions Mean             0.0185587
evaluation/Actions Std              0.717478
evaluation/Actions Max              0.999591
evaluation/Actions Min             -0.998641
evaluation/Num Paths               10
evaluation/Average Returns        353.201
time/data storing (s)               0.0310029
time/evaluation sampling (s)      107.258
time/exploration sampling (s)     111.293
time/logging (s)                    0.0261319
time/saving (s)                     0.074695
time/training (s)                  14.0297
time/epoch (s)                    232.713
time/total (s)                  15708.4
Epoch                              67
-----------------------------  ---------------
2023-08-31 16:21:29.721155 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size             346000
trainer/QF1 Loss                    0.104561
trainer/QF2 Loss                    0.119753
trainer/Policy Loss               -54.2932
trainer/Q1 Predictions Mean        65.4416
trainer/Q1 Predictions Std          3.35955
trainer/Q1 Predictions Max         71.8722
trainer/Q1 Predictions Min         50.4672
trainer/Q2 Predictions Mean        65.318
trainer/Q2 Predictions Std          3.35161
trainer/Q2 Predictions Max         71.88
trainer/Q2 Predictions Min         51.1181
trainer/Q Targets Mean             65.4085
trainer/Q Targets Std               3.41694
trainer/Q Targets Max              71.3787
trainer/Q Targets Min              50.3808
trainer/Log Pis Mean               11.1624
trainer/Log Pis Std                 7.39466
trainer/Log Pis Max                44.2749
trainer/Log Pis Min                -6.6037
trainer/Policy mu Mean              0.0262751
trainer/Policy mu Std               1.68423
trainer/Policy mu Max               5.55729
trainer/Policy mu Min              -5.45783
trainer/Policy log std Mean        -0.396852
trainer/Policy log std Std          0.136619
trainer/Policy log std Max          0.299816
trainer/Policy log std Min         -1.20342
trainer/Alpha                       0.00285574
trainer/Alpha Loss                 -4.90711
exploration/num steps total    346000
exploration/num paths total       692
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.579988
exploration/Rewards Std             0.105905
exploration/Rewards Max             0.936697
exploration/Rewards Min             0.189713
exploration/Returns Mean          289.994
exploration/Returns Std            28.2636
exploration/Returns Max           324.103
exploration/Returns Min           232.457
exploration/Actions Mean           -0.0275982
exploration/Actions Std             0.73721
exploration/Actions Max             1
exploration/Actions Min            -0.999997
exploration/Num Paths              10
exploration/Average Returns       289.994
evaluation/num steps total     345000
evaluation/num paths total        690
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.605464
evaluation/Rewards Std              0.0714417
evaluation/Rewards Max              0.939313
evaluation/Rewards Min              0.309025
evaluation/Returns Mean           302.732
evaluation/Returns Std             18.2281
evaluation/Returns Max            317.415
evaluation/Returns Min            262.809
evaluation/ExplReturns Mean       302.732
evaluation/ExplReturns Std         18.2281
evaluation/ExplReturns Max        317.415
evaluation/ExplReturns Min        262.809
evaluation/Actions Mean            -0.0154913
evaluation/Actions Std              0.67595
evaluation/Actions Max              1
evaluation/Actions Min             -0.999994
evaluation/Num Paths               10
evaluation/Average Returns        302.732
time/data storing (s)               0.0310103
time/evaluation sampling (s)      109.364
time/exploration sampling (s)     114.973
time/logging (s)                    0.0269436
time/saving (s)                     0.0693845
time/training (s)                  10.059
time/epoch (s)                    234.524
time/total (s)                  15943
Epoch                              68
-----------------------------  ---------------
2023-08-31 16:25:22.639780 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             351000
trainer/QF1 Loss                    0.103908
trainer/QF2 Loss                    0.108062
trainer/Policy Loss               -52.322
trainer/Q1 Predictions Mean        65.2847
trainer/Q1 Predictions Std          3.23737
trainer/Q1 Predictions Max         73.5012
trainer/Q1 Predictions Min         54.4533
trainer/Q2 Predictions Mean        65.3356
trainer/Q2 Predictions Std          3.26681
trainer/Q2 Predictions Max         73.1778
trainer/Q2 Predictions Min         54.0074
trainer/Q Targets Mean             65.3422
trainer/Q Targets Std               3.25452
trainer/Q Targets Max              74.0371
trainer/Q Targets Min              54.3081
trainer/Log Pis Mean               13.0898
trainer/Log Pis Std                 7.33113
trainer/Log Pis Max                49.6351
trainer/Log Pis Min                -4.39861
trainer/Policy mu Mean              0.114788
trainer/Policy mu Std               1.76911
trainer/Policy mu Max               5.90222
trainer/Policy mu Min              -7.91589
trainer/Policy log std Mean        -0.407847
trainer/Policy log std Std          0.152765
trainer/Policy log std Max          0.0405141
trainer/Policy log std Min         -1.14732
trainer/Alpha                       0.0028457
trainer/Alpha Loss                  6.38862
exploration/num steps total    351000
exploration/num paths total       702
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.74584
exploration/Rewards Std             0.11472
exploration/Rewards Max             0.978597
exploration/Rewards Min             0.338698
exploration/Returns Mean          372.92
exploration/Returns Std            24.5886
exploration/Returns Max           398.722
exploration/Returns Min           330.203
exploration/Actions Mean            0.0411357
exploration/Actions Std             0.756611
exploration/Actions Max             0.999974
exploration/Actions Min            -0.999924
exploration/Num Paths              10
exploration/Average Returns       372.92
evaluation/num steps total     350000
evaluation/num paths total        700
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.696692
evaluation/Rewards Std              0.0720545
evaluation/Rewards Max              0.979176
evaluation/Rewards Min              0.446169
evaluation/Returns Mean           348.346
evaluation/Returns Std             14.8604
evaluation/Returns Max            374.21
evaluation/Returns Min            324.544
evaluation/ExplReturns Mean       348.346
evaluation/ExplReturns Std         14.8604
evaluation/ExplReturns Max        374.21
evaluation/ExplReturns Min        324.544
evaluation/Actions Mean             0.070024
evaluation/Actions Std              0.69644
evaluation/Actions Max              0.998587
evaluation/Actions Min             -0.998533
evaluation/Num Paths               10
evaluation/Average Returns        348.346
time/data storing (s)               0.0310282
time/evaluation sampling (s)      108.121
time/exploration sampling (s)     112.783
time/logging (s)                    0.0261766
time/saving (s)                     0.082434
time/training (s)                  11.8698
time/epoch (s)                    232.914
time/total (s)                  16175.9
Epoch                              69
-----------------------------  --------------
2023-08-31 16:29:16.107233 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size             356000
trainer/QF1 Loss                    0.0898498
trainer/QF2 Loss                    0.0807494
trainer/Policy Loss               -53.6526
trainer/Q1 Predictions Mean        65.3037
trainer/Q1 Predictions Std          3.51587
trainer/Q1 Predictions Max         70.2818
trainer/Q1 Predictions Min         48.49
trainer/Q2 Predictions Mean        65.367
trainer/Q2 Predictions Std          3.50569
trainer/Q2 Predictions Max         70.4755
trainer/Q2 Predictions Min         48.6307
trainer/Q Targets Mean             65.3232
trainer/Q Targets Std               3.57419
trainer/Q Targets Max              70.7895
trainer/Q Targets Min              48.4132
trainer/Log Pis Mean               11.7861
trainer/Log Pis Std                 7.56129
trainer/Log Pis Max                44.0415
trainer/Log Pis Min                -6.04129
trainer/Policy mu Mean              0.185445
trainer/Policy mu Std               1.68214
trainer/Policy mu Max               5.41663
trainer/Policy mu Min              -4.35645
trainer/Policy log std Mean        -0.413647
trainer/Policy log std Std          0.133341
trainer/Policy log std Max          0.214277
trainer/Policy log std Min         -1.14875
trainer/Alpha                       0.00289323
trainer/Alpha Loss                 -1.2506
exploration/num steps total    356000
exploration/num paths total       712
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.766851
exploration/Rewards Std             0.130466
exploration/Rewards Max             0.97781
exploration/Rewards Min             0.36893
exploration/Returns Mean          383.425
exploration/Returns Std            19.4976
exploration/Returns Max           405.098
exploration/Returns Min           352.639
exploration/Actions Mean            0.0796958
exploration/Actions Std             0.749507
exploration/Actions Max             0.999929
exploration/Actions Min            -0.99989
exploration/Num Paths              10
exploration/Average Returns       383.425
evaluation/num steps total     355000
evaluation/num paths total        710
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.641855
evaluation/Rewards Std              0.119312
evaluation/Rewards Max              0.977117
evaluation/Rewards Min              0.124732
evaluation/Returns Mean           320.927
evaluation/Returns Std             29.3995
evaluation/Returns Max            364.234
evaluation/Returns Min            251.721
evaluation/ExplReturns Mean       320.927
evaluation/ExplReturns Std         29.3995
evaluation/ExplReturns Max        364.234
evaluation/ExplReturns Min        251.721
evaluation/Actions Mean             0.027685
evaluation/Actions Std              0.737329
evaluation/Actions Max              0.999966
evaluation/Actions Min             -0.999964
evaluation/Num Paths               10
evaluation/Average Returns        320.927
time/data storing (s)               0.0311098
time/evaluation sampling (s)      108.459
time/exploration sampling (s)     115.054
time/logging (s)                    0.0263283
time/saving (s)                     0.0660217
time/training (s)                   9.82806
time/epoch (s)                    233.464
time/total (s)                  16409.3
Epoch                              70
-----------------------------  ---------------
2023-08-31 16:33:09.114490 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size             361000
trainer/QF1 Loss                    0.0912944
trainer/QF2 Loss                    0.0784969
trainer/Policy Loss               -52.9622
trainer/Q1 Predictions Mean        65.5556
trainer/Q1 Predictions Std          3.62805
trainer/Q1 Predictions Max         74.0394
trainer/Q1 Predictions Min         48.5736
trainer/Q2 Predictions Mean        65.4996
trainer/Q2 Predictions Std          3.64048
trainer/Q2 Predictions Max         74.0916
trainer/Q2 Predictions Min         48.4064
trainer/Q Targets Mean             65.489
trainer/Q Targets Std               3.63162
trainer/Q Targets Max              74.858
trainer/Q Targets Min              48.4188
trainer/Log Pis Mean               12.6703
trainer/Log Pis Std                 8.04645
trainer/Log Pis Max                43.9648
trainer/Log Pis Min                -2.37625
trainer/Policy mu Mean             -0.048256
trainer/Policy mu Std               1.74293
trainer/Policy mu Max               7.33663
trainer/Policy mu Min              -5.31454
trainer/Policy log std Mean        -0.400492
trainer/Policy log std Std          0.143155
trainer/Policy log std Max          0.365666
trainer/Policy log std Min         -1.45262
trainer/Alpha                       0.00290967
trainer/Alpha Loss                  3.91428
exploration/num steps total    361000
exploration/num paths total       722
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.612875
exploration/Rewards Std             0.101888
exploration/Rewards Max             0.975067
exploration/Rewards Min             0.26146
exploration/Returns Mean          306.437
exploration/Returns Std            31.1172
exploration/Returns Max           343.073
exploration/Returns Min           242.17
exploration/Actions Mean            0.00342951
exploration/Actions Std             0.741021
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       306.437
evaluation/num steps total     360000
evaluation/num paths total        720
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.554362
evaluation/Rewards Std              0.112231
evaluation/Rewards Max              0.945282
evaluation/Rewards Min              0.216566
evaluation/Returns Mean           277.181
evaluation/Returns Std             38.3751
evaluation/Returns Max            354.724
evaluation/Returns Min            233.055
evaluation/ExplReturns Mean       277.181
evaluation/ExplReturns Std         38.3751
evaluation/ExplReturns Max        354.724
evaluation/ExplReturns Min        233.055
evaluation/Actions Mean             0.0231197
evaluation/Actions Std              0.70543
evaluation/Actions Max              0.999999
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns        277.181
time/data storing (s)               0.0309349
time/evaluation sampling (s)      107.486
time/exploration sampling (s)     114.646
time/logging (s)                    0.0262865
time/saving (s)                     0.0734793
time/training (s)                  10.7412
time/epoch (s)                    233.003
time/total (s)                  16642.4
Epoch                              71
-----------------------------  ---------------
2023-08-31 16:37:01.016105 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size             366000
trainer/QF1 Loss                    0.100186
trainer/QF2 Loss                    0.0933554
trainer/Policy Loss               -53.7486
trainer/Q1 Predictions Mean        65.6844
trainer/Q1 Predictions Std          3.68075
trainer/Q1 Predictions Max         76.0518
trainer/Q1 Predictions Min         49.5501
trainer/Q2 Predictions Mean        65.6445
trainer/Q2 Predictions Std          3.66112
trainer/Q2 Predictions Max         76.0467
trainer/Q2 Predictions Min         49.5739
trainer/Q Targets Mean             65.7165
trainer/Q Targets Std               3.70037
trainer/Q Targets Max              76.094
trainer/Q Targets Min              49.5097
trainer/Log Pis Mean               12.0244
trainer/Log Pis Std                 7.71552
trainer/Log Pis Max                43.4655
trainer/Log Pis Min                -5.20534
trainer/Policy mu Mean             -0.0398064
trainer/Policy mu Std               1.71692
trainer/Policy mu Max               4.71012
trainer/Policy mu Min              -7.19876
trainer/Policy log std Mean        -0.422487
trainer/Policy log std Std          0.137648
trainer/Policy log std Max         -0.0112197
trainer/Policy log std Min         -1.0686
trainer/Alpha                       0.00287863
trainer/Alpha Loss                  0.142927
exploration/num steps total    366000
exploration/num paths total       732
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.710807
exploration/Rewards Std             0.0934338
exploration/Rewards Max             0.976526
exploration/Rewards Min             0.346648
exploration/Returns Mean          355.404
exploration/Returns Std            23.9284
exploration/Returns Max           377.306
exploration/Returns Min           298.469
exploration/Actions Mean            0.0572695
exploration/Actions Std             0.756415
exploration/Actions Max             0.999992
exploration/Actions Min            -0.999833
exploration/Num Paths              10
exploration/Average Returns       355.404
evaluation/num steps total     365000
evaluation/num paths total        730
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.709815
evaluation/Rewards Std              0.0800362
evaluation/Rewards Max              0.967884
evaluation/Rewards Min              0.407789
evaluation/Returns Mean           354.907
evaluation/Returns Std             15.7314
evaluation/Returns Max            380.896
evaluation/Returns Min            329.429
evaluation/ExplReturns Mean       354.907
evaluation/ExplReturns Std         15.7314
evaluation/ExplReturns Max        380.896
evaluation/ExplReturns Min        329.429
evaluation/Actions Mean             0.0486839
evaluation/Actions Std              0.736761
evaluation/Actions Max              0.997869
evaluation/Actions Min             -0.999605
evaluation/Num Paths               10
evaluation/Average Returns        354.907
time/data storing (s)               0.0311992
time/evaluation sampling (s)      108.39
time/exploration sampling (s)     113.389
time/logging (s)                    0.0262629
time/saving (s)                     0.0811138
time/training (s)                   9.97977
time/epoch (s)                    231.898
time/total (s)                  16874.3
Epoch                              72
-----------------------------  ---------------
2023-08-31 16:40:53.057565 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size             371000
trainer/QF1 Loss                    0.130086
trainer/QF2 Loss                    0.0996722
trainer/Policy Loss               -53.1341
trainer/Q1 Predictions Mean        65.5795
trainer/Q1 Predictions Std          3.93929
trainer/Q1 Predictions Max         73.8854
trainer/Q1 Predictions Min         46.0112
trainer/Q2 Predictions Mean        65.4425
trainer/Q2 Predictions Std          3.9078
trainer/Q2 Predictions Max         73.972
trainer/Q2 Predictions Min         45.7666
trainer/Q Targets Mean             65.4327
trainer/Q Targets Std               3.96357
trainer/Q Targets Max              73.9019
trainer/Q Targets Min              45.9845
trainer/Log Pis Mean               12.4861
trainer/Log Pis Std                 8.00203
trainer/Log Pis Max                52.5006
trainer/Log Pis Min                -2.8689
trainer/Policy mu Mean              0.194166
trainer/Policy mu Std               1.70777
trainer/Policy mu Max               6.03903
trainer/Policy mu Min              -6.15787
trainer/Policy log std Mean        -0.422746
trainer/Policy log std Std          0.137381
trainer/Policy log std Max          0.243901
trainer/Policy log std Min         -0.96964
trainer/Alpha                       0.00295467
trainer/Alpha Loss                  2.83102
exploration/num steps total    371000
exploration/num paths total       742
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.659891
exploration/Rewards Std             0.0530144
exploration/Rewards Max             0.942976
exploration/Rewards Min             0.216828
exploration/Returns Mean          329.945
exploration/Returns Std            12.4169
exploration/Returns Max           340.525
exploration/Returns Min           293.891
exploration/Actions Mean            0.0665367
exploration/Actions Std             0.744095
exploration/Actions Max             0.999897
exploration/Actions Min            -0.999719
exploration/Num Paths              10
exploration/Average Returns       329.945
evaluation/num steps total     370000
evaluation/num paths total        740
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.677411
evaluation/Rewards Std              0.0362386
evaluation/Rewards Max              0.972836
evaluation/Rewards Min              0.501511
evaluation/Returns Mean           338.706
evaluation/Returns Std              4.67318
evaluation/Returns Max            350.535
evaluation/Returns Min            333.746
evaluation/ExplReturns Mean       338.706
evaluation/ExplReturns Std          4.67318
evaluation/ExplReturns Max        350.535
evaluation/ExplReturns Min        333.746
evaluation/Actions Mean             0.10373
evaluation/Actions Std              0.711878
evaluation/Actions Max              0.998636
evaluation/Actions Min             -0.995622
evaluation/Num Paths               10
evaluation/Average Returns        338.706
time/data storing (s)               0.0312489
time/evaluation sampling (s)      108.323
time/exploration sampling (s)     111.337
time/logging (s)                    0.0268347
time/saving (s)                     0.0778542
time/training (s)                  12.2419
time/epoch (s)                    232.038
time/total (s)                  17106.3
Epoch                              73
-----------------------------  ---------------
2023-08-31 16:44:41.386943 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_08_31_11_55_47_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size             376000
trainer/QF1 Loss                    0.139646
trainer/QF2 Loss                    0.105252
trainer/Policy Loss               -52.7509
trainer/Q1 Predictions Mean        65.251
trainer/Q1 Predictions Std          3.59064
trainer/Q1 Predictions Max         71.0494
trainer/Q1 Predictions Min         51.5248
trainer/Q2 Predictions Mean        65.1041
trainer/Q2 Predictions Std          3.58046
trainer/Q2 Predictions Max         70.6697
trainer/Q2 Predictions Min         52.0484
trainer/Q Targets Mean             65.1545
trainer/Q Targets Std               3.65478
trainer/Q Targets Max              71.1391
trainer/Q Targets Min              52.0685
trainer/Log Pis Mean               12.5329
trainer/Log Pis Std                 7.57423
trainer/Log Pis Max                32.0048
trainer/Log Pis Min                -7.53632
trainer/Policy mu Mean             -0.0254665
trainer/Policy mu Std               1.73729
trainer/Policy mu Max               4.65322
trainer/Policy mu Min              -5.79209
trainer/Policy log std Mean        -0.422122
trainer/Policy log std Std          0.13418
trainer/Policy log std Max          0.284921
trainer/Policy log std Min         -1.00249
trainer/Alpha                       0.00297746
trainer/Alpha Loss                  3.09977
exploration/num steps total    376000
exploration/num paths total       752
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.74525
exploration/Rewards Std             0.117712
exploration/Rewards Max             0.978466
exploration/Rewards Min             0.507618
exploration/Returns Mean          372.625
exploration/Returns Std            32.0709
exploration/Returns Max           433.491
exploration/Returns Min           338.728
exploration/Actions Mean            0.0282186
exploration/Actions Std             0.749186
exploration/Actions Max             0.999851
exploration/Actions Min            -0.99975
exploration/Num Paths              10
exploration/Average Returns       372.625
evaluation/num steps total     375000
evaluation/num paths total        750
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.668653
evaluation/Rewards Std              0.15053
evaluation/Rewards Max              0.977047
evaluation/Rewards Min              0.0646293
evaluation/Returns Mean           334.327
evaluation/Returns Std             64.4059
evaluation/Returns Max            380.047
evaluation/Returns Min            145.029
evaluation/ExplReturns Mean       334.327
evaluation/ExplReturns Std         64.4059
evaluation/ExplReturns Max        380.047
evaluation/ExplReturns Min        145.029
evaluation/Actions Mean             0.00826959
evaluation/Actions Std              0.7271
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.999988
evaluation/Num Paths               10
evaluation/Average Returns        334.327
time/data storing (s)               0.0309178
time/evaluation sampling (s)      106.405
time/exploration sampling (s)     111.223
time/logging (s)                    0.0257832
time/saving (s)                     0.0740332
time/training (s)                  10.5656
time/epoch (s)                    228.324
time/total (s)                  17334.6
Epoch                              74
-----------------------------  ---------------
