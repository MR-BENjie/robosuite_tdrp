2023-08-31 11:59:00.567810 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size             6000
trainer/QF1 Loss                 15.7954
trainer/QF2 Loss                 15.8279
trainer/Policy Loss              -4.0056
trainer/Q1 Predictions Mean       0.00549057
trainer/Q1 Predictions Std        0.00119887
trainer/Q1 Predictions Max        0.00847493
trainer/Q1 Predictions Min        0.00170063
trainer/Q2 Predictions Mean       0.00131975
trainer/Q2 Predictions Std        0.00122536
trainer/Q2 Predictions Max        0.00437034
trainer/Q2 Predictions Min       -0.00290494
trainer/Q Targets Mean            3.90428
trainer/Q Targets Std             0.771133
trainer/Q Targets Max             5.19071
trainer/Q Targets Min            -0.281611
trainer/Log Pis Mean             -4.00422
trainer/Log Pis Std               0.537548
trainer/Log Pis Max              -2.06134
trainer/Log Pis Min              -5.41554
trainer/Policy mu Mean           -0.000135463
trainer/Policy mu Std             0.000819179
trainer/Policy mu Max             0.00184489
trainer/Policy mu Min            -0.00244384
trainer/Policy log std Mean      -0.000129579
trainer/Policy log std Std        0.00176654
trainer/Policy log std Max        0.00354502
trainer/Policy log std Min       -0.00309831
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total    6000
exploration/num paths total     106
exploration/path length Mean     60.9756
exploration/path length Std      53.5626
exploration/path length Max     286
exploration/path length Min       3
exploration/Rewards Mean          0.0133177
exploration/Rewards Std           0.0531052
exploration/Rewards Max           0.110761
exploration/Rewards Min          -0.510235
exploration/Returns Mean          0.812055
exploration/Returns Std           1.54366
exploration/Returns Max           9.57669
exploration/Returns Min          -1.58343
exploration/Actions Mean          0.000559073
exploration/Actions Std           0.62763
exploration/Actions Max           0.999408
exploration/Actions Min          -0.999341
exploration/Num Paths            82
exploration/Average Returns       0.812055
evaluation/num steps total     5000
evaluation/num paths total       10
evaluation/path length Mean     500
evaluation/path length Std        0
evaluation/path length Max      500
evaluation/path length Min      500
evaluation/Rewards Mean           0.0228731
evaluation/Rewards Std            0.00883011
evaluation/Rewards Max            0.0377033
evaluation/Rewards Min            0.0116081
evaluation/Returns Mean          11.4366
evaluation/Returns Std            4.41399
evaluation/Returns Max           18.5373
evaluation/Returns Min            5.83841
evaluation/ExplReturns Mean      11.4366
evaluation/ExplReturns Std        4.41399
evaluation/ExplReturns Max       18.5373
evaluation/ExplReturns Min        5.83841
evaluation/Actions Mean          -0.000237346
evaluation/Actions Std            0.0007342
evaluation/Actions Max            0.000823484
evaluation/Actions Min           -0.00159348
evaluation/Num Paths             10
evaluation/Average Returns       11.4366
time/data storing (s)             0.0292221
time/evaluation sampling (s)     68.3442
time/exploration sampling (s)    75.0024
time/logging (s)                  0.0260161
time/saving (s)                   0.014929
time/training (s)                12.7719
time/epoch (s)                  156.189
time/total (s)                  177.768
Epoch                             0
-----------------------------  --------------
2023-08-31 12:01:33.721769 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                   4.78235
trainer/QF2 Loss                   4.84486
trainer/Policy Loss              -18.7151
trainer/Q1 Predictions Mean       14.6282
trainer/Q1 Predictions Std         0.999335
trainer/Q1 Predictions Max        17.277
trainer/Q1 Predictions Min        11.5588
trainer/Q2 Predictions Mean       14.6318
trainer/Q2 Predictions Std         1.00555
trainer/Q2 Predictions Max        17.3073
trainer/Q2 Predictions Min        11.5805
trainer/Q Targets Mean            14.1543
trainer/Q Targets Std              2.33134
trainer/Q Targets Max             16.3763
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean              -4.1105
trainer/Log Pis Std                0.323514
trainer/Log Pis Max               -3.38986
trainer/Log Pis Min               -5.68702
trainer/Policy mu Mean            -0.0136023
trainer/Policy mu Std              0.0581832
trainer/Policy mu Max              0.0787752
trainer/Policy mu Min             -0.144569
trainer/Policy log std Mean       -0.135941
trainer/Policy log std Std         0.00856731
trainer/Policy log std Max        -0.11011
trainer/Policy log std Min        -0.157088
trainer/Alpha                      0.740601
trainer/Alpha Loss                -3.03308
exploration/num steps total    11000
exploration/num paths total      201
exploration/path length Mean      52.6316
exploration/path length Std       42.8903
exploration/path length Max      228
exploration/path length Min        9
exploration/Rewards Mean           0.0163548
exploration/Rewards Std            0.0762284
exploration/Rewards Max            4.29266
exploration/Rewards Min           -0.509294
exploration/Returns Mean           0.86078
exploration/Returns Std            1.551
exploration/Returns Max            9.64815
exploration/Returns Min           -0.687002
exploration/Actions Mean          -0.0144564
exploration/Actions Std            0.585259
exploration/Actions Max            0.998863
exploration/Actions Min           -0.997515
exploration/Num Paths             95
exploration/Average Returns        0.86078
evaluation/num steps total      9929
evaluation/num paths total       105
evaluation/path length Mean       51.8842
evaluation/path length Std         8.47518
evaluation/path length Max        76
evaluation/path length Min        36
evaluation/Rewards Mean            0.0141836
evaluation/Rewards Std             0.0420376
evaluation/Rewards Max             0.0448578
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            0.735906
evaluation/Returns Std             0.299482
evaluation/Returns Max             1.53219
evaluation/Returns Min             0.167827
evaluation/ExplReturns Mean        0.735906
evaluation/ExplReturns Std         0.299482
evaluation/ExplReturns Max         1.53219
evaluation/ExplReturns Min         0.167827
evaluation/Actions Mean           -0.0200513
evaluation/Actions Std             0.0548469
evaluation/Actions Max             0.0657985
evaluation/Actions Min            -0.140541
evaluation/Num Paths              95
evaluation/Average Returns         0.735906
time/data storing (s)              0.029379
time/evaluation sampling (s)      68.8199
time/exploration sampling (s)     74.0348
time/logging (s)                   0.0261713
time/saving (s)                    0.0681661
time/training (s)                 10.1723
time/epoch (s)                   153.151
time/total (s)                   330.921
Epoch                              1
-----------------------------  --------------
2023-08-31 12:04:07.462038 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                   2.63747
trainer/QF2 Loss                   2.54849
trainer/Policy Loss              -26.3193
trainer/Q1 Predictions Mean       22.3962
trainer/Q1 Predictions Std         3.11031
trainer/Q1 Predictions Max        29.033
trainer/Q1 Predictions Min         9.4032
trainer/Q2 Predictions Mean       22.4249
trainer/Q2 Predictions Std         3.1202
trainer/Q2 Predictions Max        29.1599
trainer/Q2 Predictions Min        10.3635
trainer/Q Targets Mean            22.6859
trainer/Q Targets Std              3.37095
trainer/Q Targets Max             28.3664
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean              -3.84404
trainer/Log Pis Std                0.714187
trainer/Log Pis Max               -2.06095
trainer/Log Pis Min               -7.35268
trainer/Policy mu Mean             0.0534695
trainer/Policy mu Std              0.227535
trainer/Policy mu Max              0.738247
trainer/Policy mu Min             -0.623896
trainer/Policy log std Mean       -0.112819
trainer/Policy log std Std         0.0255092
trainer/Policy log std Max        -0.0574972
trainer/Policy log std Min        -0.220186
trainer/Alpha                      0.549555
trainer/Alpha Loss                -5.89019
exploration/num steps total    16000
exploration/num paths total      279
exploration/path length Mean      64.1026
exploration/path length Std       46.4784
exploration/path length Max      218
exploration/path length Min       15
exploration/Rewards Mean           0.0076562
exploration/Rewards Std            0.0432026
exploration/Rewards Max            1.317
exploration/Rewards Min           -0.42473
exploration/Returns Mean           0.490782
exploration/Returns Std            0.601989
exploration/Returns Max            3.14537
exploration/Returns Min           -0.170242
exploration/Actions Mean           0.0522713
exploration/Actions Std            0.605638
exploration/Actions Max            0.999715
exploration/Actions Min           -0.99985
exploration/Num Paths             78
exploration/Average Returns        0.490782
evaluation/num steps total     14913
evaluation/num paths total       196
evaluation/path length Mean       54.7692
evaluation/path length Std         3.6316
evaluation/path length Max        72
evaluation/path length Min        51
evaluation/Rewards Mean            0.00527458
evaluation/Rewards Std             0.0399887
evaluation/Rewards Max             0.0394676
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            0.288885
evaluation/Returns Std             0.200806
evaluation/Returns Max             0.695949
evaluation/Returns Min            -0.0862197
evaluation/ExplReturns Mean        0.288885
evaluation/ExplReturns Std         0.200806
evaluation/ExplReturns Max         0.695949
evaluation/ExplReturns Min        -0.0862197
evaluation/Actions Mean            0.156745
evaluation/Actions Std             0.270695
evaluation/Actions Max             0.652136
evaluation/Actions Min            -0.423887
evaluation/Num Paths              91
evaluation/Average Returns         0.288885
time/data storing (s)              0.0290496
time/evaluation sampling (s)      68.8959
time/exploration sampling (s)     74.5263
time/logging (s)                   0.0266829
time/saving (s)                    0.0653517
time/training (s)                 10.194
time/epoch (s)                   153.737
time/total (s)                   484.661
Epoch                              2
-----------------------------  --------------
2023-08-31 12:06:43.136018 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 3 finished
-----------------------------  --------------
replay_buffer/size             21000
trainer/QF1 Loss                   9.43039
trainer/QF2 Loss                   9.45583
trainer/Policy Loss              -31.9121
trainer/Q1 Predictions Mean       28.2791
trainer/Q1 Predictions Std         4.63267
trainer/Q1 Predictions Max        36.4708
trainer/Q1 Predictions Min        10.3721
trainer/Q2 Predictions Mean       28.2654
trainer/Q2 Predictions Std         4.68866
trainer/Q2 Predictions Max        36.193
trainer/Q2 Predictions Min        10.1517
trainer/Q Targets Mean            27.8988
trainer/Q Targets Std              5.88603
trainer/Q Targets Max             36.5361
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean              -3.47322
trainer/Log Pis Std                1.03324
trainer/Log Pis Max               -0.771886
trainer/Log Pis Min               -6.44581
trainer/Policy mu Mean             0.0954159
trainer/Policy mu Std              0.353342
trainer/Policy mu Max              1.15402
trainer/Policy mu Min             -1.30624
trainer/Policy log std Mean       -0.0943394
trainer/Policy log std Std         0.0542961
trainer/Policy log std Max         0.0252952
trainer/Policy log std Min        -0.391088
trainer/Alpha                      0.409207
trainer/Alpha Loss                -8.46189
exploration/num steps total    21000
exploration/num paths total      342
exploration/path length Mean      79.3651
exploration/path length Std       42.4811
exploration/path length Max      200
exploration/path length Min       15
exploration/Rewards Mean           0.0128196
exploration/Rewards Std            0.0352011
exploration/Rewards Max            0.063732
exploration/Rewards Min           -0.281611
exploration/Returns Mean           1.01743
exploration/Returns Std            1.07273
exploration/Returns Max            4.52102
exploration/Returns Min           -0.15939
exploration/Actions Mean           0.066156
exploration/Actions Std            0.619367
exploration/Actions Max            0.998887
exploration/Actions Min           -0.997573
exploration/Num Paths             63
exploration/Average Returns        1.01743
evaluation/num steps total     19894
evaluation/num paths total       233
evaluation/path length Mean      134.622
evaluation/path length Std        89.245
evaluation/path length Max       225
evaluation/path length Min        35
evaluation/Rewards Mean            0.00672429
evaluation/Rewards Std             0.0271498
evaluation/Rewards Max             0.0463949
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            0.905235
evaluation/Returns Std             0.563551
evaluation/Returns Max             1.83087
evaluation/Returns Min             0.0971342
evaluation/ExplReturns Mean        0.905235
evaluation/ExplReturns Std         0.563551
evaluation/ExplReturns Max         1.83087
evaluation/ExplReturns Min         0.0971342
evaluation/Actions Mean            0.126494
evaluation/Actions Std             0.210396
evaluation/Actions Max             0.71073
evaluation/Actions Min            -0.848138
evaluation/Num Paths              37
evaluation/Average Returns         0.905235
time/data storing (s)              0.0291315
time/evaluation sampling (s)      68.5783
time/exploration sampling (s)     74.3901
time/logging (s)                   0.0258897
time/saving (s)                    0.0593636
time/training (s)                 12.5868
time/epoch (s)                   155.67
time/total (s)                   640.334
Epoch                              3
-----------------------------  --------------
2023-08-31 12:09:16.903126 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size             26000
trainer/QF1 Loss                   7.23501
trainer/QF2 Loss                   6.85232
trainer/Policy Loss              -35.7889
trainer/Q1 Predictions Mean       32.3444
trainer/Q1 Predictions Std         6.30679
trainer/Q1 Predictions Max        44.2034
trainer/Q1 Predictions Min        10.8807
trainer/Q2 Predictions Mean       32.4122
trainer/Q2 Predictions Std         6.23128
trainer/Q2 Predictions Max        43.4659
trainer/Q2 Predictions Min        10.9228
trainer/Q Targets Mean            32.0245
trainer/Q Targets Std              6.73384
trainer/Q Targets Max             42.4897
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean              -2.97323
trainer/Log Pis Std                1.55614
trainer/Log Pis Max                1.61264
trainer/Log Pis Min               -8.29307
trainer/Policy mu Mean             0.113279
trainer/Policy mu Std              0.524736
trainer/Policy mu Max              1.8443
trainer/Policy mu Min             -1.52849
trainer/Policy log std Mean       -0.112049
trainer/Policy log std Std         0.0876592
trainer/Policy log std Max         0.138249
trainer/Policy log std Min        -0.626583
trainer/Alpha                      0.306746
trainer/Alpha Loss               -10.6014
exploration/num steps total    26000
exploration/num paths total      369
exploration/path length Mean     185.185
exploration/path length Std       93.325
exploration/path length Max      405
exploration/path length Min       36
exploration/Rewards Mean           0.0211154
exploration/Rewards Std            0.167724
exploration/Rewards Max            9.53403
exploration/Rewards Min           -0.45358
exploration/Returns Mean           3.91025
exploration/Returns Std            4.91959
exploration/Returns Max           25.6938
exploration/Returns Min           -1.11181
exploration/Actions Mean           0.0107819
exploration/Actions Std            0.622609
exploration/Actions Max            0.999486
exploration/Actions Min           -0.999588
exploration/Num Paths             27
exploration/Average Returns        3.91025
evaluation/num steps total     24872
evaluation/num paths total       259
evaluation/path length Mean      191.462
evaluation/path length Std        10.5182
evaluation/path length Max       215
evaluation/path length Min       170
evaluation/Rewards Mean            0.00669325
evaluation/Rewards Std             0.0224643
evaluation/Rewards Max             0.0401404
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            1.2815
evaluation/Returns Std             0.307016
evaluation/Returns Max             1.89741
evaluation/Returns Min             0.656134
evaluation/ExplReturns Mean        1.2815
evaluation/ExplReturns Std         0.307016
evaluation/ExplReturns Max         1.89741
evaluation/ExplReturns Min         0.656134
evaluation/Actions Mean            0.0356535
evaluation/Actions Std             0.210321
evaluation/Actions Max             0.934014
evaluation/Actions Min            -0.844965
evaluation/Num Paths              26
evaluation/Average Returns         1.2815
time/data storing (s)              0.0290956
time/evaluation sampling (s)      68.6219
time/exploration sampling (s)     74.625
time/logging (s)                   0.0253099
time/saving (s)                    0.0628641
time/training (s)                 10.399
time/epoch (s)                   153.763
time/total (s)                   794.1
Epoch                              4
-----------------------------  --------------
2023-08-31 12:11:54.436737 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size             31000
trainer/QF1 Loss                   6.70314
trainer/QF2 Loss                   7.15195
trainer/Policy Loss              -36.1004
trainer/Q1 Predictions Mean       33.2143
trainer/Q1 Predictions Std         9.09183
trainer/Q1 Predictions Max        46.6031
trainer/Q1 Predictions Min         1.29616
trainer/Q2 Predictions Mean       33.2244
trainer/Q2 Predictions Std         8.92786
trainer/Q2 Predictions Max        46.603
trainer/Q2 Predictions Min         2.39882
trainer/Q Targets Mean            33.1799
trainer/Q Targets Std              9.75519
trainer/Q Targets Max             47.1262
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean              -2.27026
trainer/Log Pis Std                2.0045
trainer/Log Pis Max                4.62524
trainer/Log Pis Min               -7.40132
trainer/Policy mu Mean             0.0595041
trainer/Policy mu Std              0.686806
trainer/Policy mu Max              2.05001
trainer/Policy mu Min             -2.06136
trainer/Policy log std Mean       -0.113471
trainer/Policy log std Std         0.116537
trainer/Policy log std Max         0.244818
trainer/Policy log std Min        -0.660164
trainer/Alpha                      0.231966
trainer/Alpha Loss               -12.0819
exploration/num steps total    31000
exploration/num paths total      393
exploration/path length Mean     208.333
exploration/path length Std       69.1
exploration/path length Max      306
exploration/path length Min       44
exploration/Rewards Mean           0.00488388
exploration/Rewards Std            0.0217452
exploration/Rewards Max            0.0539628
exploration/Rewards Min           -0.281611
exploration/Returns Mean           1.01748
exploration/Returns Std            0.808466
exploration/Returns Max            3.99473
exploration/Returns Min            0.118663
exploration/Actions Mean          -0.0288813
exploration/Actions Std            0.638423
exploration/Actions Max            0.999471
exploration/Actions Min           -0.999702
exploration/Num Paths             24
exploration/Average Returns        1.01748
evaluation/num steps total     29837
evaluation/num paths total       284
evaluation/path length Mean      198.6
evaluation/path length Std        25.6265
evaluation/path length Max       319
evaluation/path length Min       170
evaluation/Rewards Mean            0.00135731
evaluation/Rewards Std             0.020971
evaluation/Rewards Max             0.0419313
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            0.269561
evaluation/Returns Std             0.169816
evaluation/Returns Max             0.588968
evaluation/Returns Min             0.0733061
evaluation/ExplReturns Mean        0.269561
evaluation/ExplReturns Std         0.169816
evaluation/ExplReturns Max         0.588968
evaluation/ExplReturns Min         0.0733061
evaluation/Actions Mean           -0.00509581
evaluation/Actions Std             0.285769
evaluation/Actions Max             0.994091
evaluation/Actions Min            -0.979973
evaluation/Num Paths              25
evaluation/Average Returns         0.269561
time/data storing (s)              0.0287466
time/evaluation sampling (s)      68.6973
time/exploration sampling (s)     74.8069
time/logging (s)                   0.0248297
time/saving (s)                    0.0626264
time/training (s)                 13.9093
time/epoch (s)                   157.53
time/total (s)                   951.632
Epoch                              5
-----------------------------  --------------
2023-08-31 12:14:28.845108 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             36000
trainer/QF1 Loss                   5.82942
trainer/QF2 Loss                   6.1695
trainer/Policy Loss              -37.7773
trainer/Q1 Predictions Mean       35.4583
trainer/Q1 Predictions Std         9.54072
trainer/Q1 Predictions Max        56.3832
trainer/Q1 Predictions Min        -0.291158
trainer/Q2 Predictions Mean       35.5443
trainer/Q2 Predictions Std         9.57502
trainer/Q2 Predictions Max        56.4647
trainer/Q2 Predictions Min        -1.4511
trainer/Q Targets Mean            35.7238
trainer/Q Targets Std             10.0673
trainer/Q Targets Max             55.3129
trainer/Q Targets Min             -2.9504
trainer/Log Pis Mean              -1.38161
trainer/Log Pis Std                2.32554
trainer/Log Pis Max                4.79687
trainer/Log Pis Min               -7.10684
trainer/Policy mu Mean             0.0862262
trainer/Policy mu Std              0.826075
trainer/Policy mu Max              2.43182
trainer/Policy mu Min             -2.29055
trainer/Policy log std Mean       -0.132184
trainer/Policy log std Std         0.150272
trainer/Policy log std Max         0.228565
trainer/Policy log std Min        -0.835
trainer/Alpha                      0.176543
trainer/Alpha Loss               -12.7992
exploration/num steps total    36000
exploration/num paths total      410
exploration/path length Mean     294.118
exploration/path length Std      132.209
exploration/path length Max      500
exploration/path length Min      133
exploration/Rewards Mean           0.020368
exploration/Rewards Std            0.106573
exploration/Rewards Max            5.67237
exploration/Rewards Min           -0.387505
exploration/Returns Mean           5.9906
exploration/Returns Std            4.7273
exploration/Returns Max           17.4261
exploration/Returns Min           -0.43879
exploration/Actions Mean           0.0174845
exploration/Actions Std            0.645617
exploration/Actions Max            0.999864
exploration/Actions Min           -0.999452
exploration/Num Paths             17
exploration/Average Returns        5.9906
evaluation/num steps total     34807
evaluation/num paths total       336
evaluation/path length Mean       95.5769
evaluation/path length Std        11.3635
evaluation/path length Max       128
evaluation/path length Min        80
evaluation/Rewards Mean            0.0105584
evaluation/Rewards Std             0.0312317
evaluation/Rewards Max             0.046842
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            1.00914
evaluation/Returns Std             0.303306
evaluation/Returns Max             1.66892
evaluation/Returns Min             0.407924
evaluation/ExplReturns Mean        1.00914
evaluation/ExplReturns Std         0.303306
evaluation/ExplReturns Max         1.66892
evaluation/ExplReturns Min         0.407924
evaluation/Actions Mean            0.0702201
evaluation/Actions Std             0.28734
evaluation/Actions Max             0.92798
evaluation/Actions Min            -0.833448
evaluation/Num Paths              52
evaluation/Average Returns         1.00914
time/data storing (s)              0.0287552
time/evaluation sampling (s)      68.8139
time/exploration sampling (s)     74.8914
time/logging (s)                   0.0249548
time/saving (s)                    0.0671771
time/training (s)                 10.5789
time/epoch (s)                   154.405
time/total (s)                  1106.04
Epoch                              6
-----------------------------  -------------
2023-08-31 12:17:01.582530 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size             41000
trainer/QF1 Loss                   5.36789
trainer/QF2 Loss                   5.68299
trainer/Policy Loss              -41.2729
trainer/Q1 Predictions Mean       39.5063
trainer/Q1 Predictions Std         9.6385
trainer/Q1 Predictions Max        54.804
trainer/Q1 Predictions Min        -3.22689
trainer/Q2 Predictions Mean       39.4742
trainer/Q2 Predictions Std         9.63317
trainer/Q2 Predictions Max        55.2846
trainer/Q2 Predictions Min        -1.8896
trainer/Q Targets Mean            39.0287
trainer/Q Targets Std              9.80263
trainer/Q Targets Max             56.2054
trainer/Q Targets Min             -2.78303
trainer/Log Pis Mean              -0.804622
trainer/Log Pis Std                2.79021
trainer/Log Pis Max                7.27052
trainer/Log Pis Min               -6.77835
trainer/Policy mu Mean             0.062137
trainer/Policy mu Std              0.944533
trainer/Policy mu Max              3.17648
trainer/Policy mu Min             -2.4995
trainer/Policy log std Mean       -0.175925
trainer/Policy log std Std         0.163601
trainer/Policy log std Max         0.148416
trainer/Policy log std Min        -0.734024
trainer/Alpha                      0.13537
trainer/Alpha Loss               -13.6057
exploration/num steps total    41000
exploration/num paths total      430
exploration/path length Mean     250
exploration/path length Std      127.921
exploration/path length Max      500
exploration/path length Min       52
exploration/Rewards Mean           0.00570002
exploration/Rewards Std            0.019636
exploration/Rewards Max            0.0663279
exploration/Rewards Min           -0.281611
exploration/Returns Mean           1.42501
exploration/Returns Std            1.10139
exploration/Returns Max            4.18464
exploration/Returns Min            0.303208
exploration/Actions Mean           0.0275561
exploration/Actions Std            0.658811
exploration/Actions Max            0.999597
exploration/Actions Min           -0.99976
exploration/Num Paths             20
exploration/Average Returns        1.42501
evaluation/num steps total     39715
evaluation/num paths total       391
evaluation/path length Mean       89.2364
evaluation/path length Std         9.01507
evaluation/path length Max       122
evaluation/path length Min        76
evaluation/Rewards Mean            0.00344013
evaluation/Rewards Std             0.0315744
evaluation/Rewards Max             0.0466935
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            0.306985
evaluation/Returns Std             0.196202
evaluation/Returns Max             1.09321
evaluation/Returns Min             0.0133602
evaluation/ExplReturns Mean        0.306985
evaluation/ExplReturns Std         0.196202
evaluation/ExplReturns Max         1.09321
evaluation/ExplReturns Min         0.0133602
evaluation/Actions Mean            0.159891
evaluation/Actions Std             0.355162
evaluation/Actions Max             0.979788
evaluation/Actions Min            -0.987812
evaluation/Num Paths              55
evaluation/Average Returns         0.306985
time/data storing (s)              0.0289648
time/evaluation sampling (s)      69.4126
time/exploration sampling (s)     72.9926
time/logging (s)                   0.0253544
time/saving (s)                    0.0523643
time/training (s)                 10.2224
time/epoch (s)                   152.734
time/total (s)                  1258.78
Epoch                              7
-----------------------------  --------------
2023-08-31 12:19:35.287866 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size             46000
trainer/QF1 Loss                   4.42686
trainer/QF2 Loss                   4.17302
trainer/Policy Loss              -41.0395
trainer/Q1 Predictions Mean       40.5603
trainer/Q1 Predictions Std         9.56408
trainer/Q1 Predictions Max        60.0455
trainer/Q1 Predictions Min         2.94571
trainer/Q2 Predictions Mean       40.6042
trainer/Q2 Predictions Std         9.63179
trainer/Q2 Predictions Max        61.6422
trainer/Q2 Predictions Min         2.94362
trainer/Q Targets Mean            40.5851
trainer/Q Targets Std              9.85342
trainer/Q Targets Max             62.7871
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               0.791767
trainer/Log Pis Std                3.22587
trainer/Log Pis Max               11.7977
trainer/Log Pis Min              -10.859
trainer/Policy mu Mean             0.11098
trainer/Policy mu Std              1.12767
trainer/Policy mu Max              2.49487
trainer/Policy mu Min             -2.91544
trainer/Policy log std Mean       -0.254741
trainer/Policy log std Std         0.187841
trainer/Policy log std Max         0.127253
trainer/Policy log std Min        -0.874603
trainer/Alpha                      0.104804
trainer/Alpha Loss               -11.7467
exploration/num steps total    46000
exploration/num paths total      447
exploration/path length Mean     294.118
exploration/path length Std       98.4837
exploration/path length Max      500
exploration/path length Min       67
exploration/Rewards Mean           0.00674729
exploration/Rewards Std            0.0191634
exploration/Rewards Max            0.0660079
exploration/Rewards Min           -0.281611
exploration/Returns Mean           1.9845
exploration/Returns Std            1.2525
exploration/Returns Max            5.86098
exploration/Returns Min            0.478116
exploration/Actions Mean           0.0620512
exploration/Actions Std            0.643511
exploration/Actions Max            0.999667
exploration/Actions Min           -0.999483
exploration/Num Paths             17
exploration/Average Returns        1.9845
evaluation/num steps total     44648
evaluation/num paths total       419
evaluation/path length Mean      176.179
evaluation/path length Std        10.7473
evaluation/path length Max       217
evaluation/path length Min       165
evaluation/Rewards Mean            0.00579633
evaluation/Rewards Std             0.0238485
evaluation/Rewards Max             0.0490976
evaluation/Rewards Min            -0.281611
evaluation/Returns Mean            1.02119
evaluation/Returns Std             0.356841
evaluation/Returns Max             1.65642
evaluation/Returns Min             0.346714
evaluation/ExplReturns Mean        1.02119
evaluation/ExplReturns Std         0.356841
evaluation/ExplReturns Max         1.65642
evaluation/ExplReturns Min         0.346714
evaluation/Actions Mean            0.105043
evaluation/Actions Std             0.302584
evaluation/Actions Max             0.943773
evaluation/Actions Min            -0.988214
evaluation/Num Paths              28
evaluation/Average Returns         1.02119
time/data storing (s)              0.0286154
time/evaluation sampling (s)      69.16
time/exploration sampling (s)     74.3451
time/logging (s)                   0.0246561
time/saving (s)                    0.0704757
time/training (s)                 10.0723
time/epoch (s)                   153.701
time/total (s)                  1412.48
Epoch                              8
-----------------------------  --------------
2023-08-31 12:22:10.149223 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 9 finished
-----------------------------  ---------------
replay_buffer/size             51000
trainer/QF1 Loss                   9.02058
trainer/QF2 Loss                   9.08588
trainer/Policy Loss              -43.2991
trainer/Q1 Predictions Mean       43.1755
trainer/Q1 Predictions Std         8.57241
trainer/Q1 Predictions Max        61.1713
trainer/Q1 Predictions Min        10.8251
trainer/Q2 Predictions Mean       43.1621
trainer/Q2 Predictions Std         8.56544
trainer/Q2 Predictions Max        59.8776
trainer/Q2 Predictions Min        10.2971
trainer/Q Targets Mean            43.0688
trainer/Q Targets Std              9.55633
trainer/Q Targets Max             59.5944
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               1.22361
trainer/Log Pis Std                3.3784
trainer/Log Pis Max               12.7452
trainer/Log Pis Min               -6.57924
trainer/Policy mu Mean             0.0598492
trainer/Policy mu Std              1.15693
trainer/Policy mu Max              3.20711
trainer/Policy mu Min             -2.70188
trainer/Policy log std Mean       -0.284609
trainer/Policy log std Std         0.204556
trainer/Policy log std Max         0.20841
trainer/Policy log std Min        -0.892253
trainer/Alpha                      0.0819516
trainer/Alpha Loss               -11.9476
exploration/num steps total    51000
exploration/num paths total      457
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0275972
exploration/Rewards Std            0.20691
exploration/Rewards Max            8.51982
exploration/Rewards Min           -0.334236
exploration/Returns Mean          13.7986
exploration/Returns Std           14.0773
exploration/Returns Max           40.3242
exploration/Returns Min           -0.394935
exploration/Actions Mean           0.0104402
exploration/Actions Std            0.643983
exploration/Actions Max            0.999658
exploration/Actions Min           -0.999845
exploration/Num Paths             10
exploration/Average Returns       13.7986
evaluation/num steps total     49648
evaluation/num paths total       429
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00163846
evaluation/Rewards Std             0.00508306
evaluation/Rewards Max             0.0542307
evaluation/Rewards Min             0.000116757
evaluation/Returns Mean            0.819232
evaluation/Returns Std             0.419047
evaluation/Returns Max             1.40983
evaluation/Returns Min             0.307617
evaluation/ExplReturns Mean        0.819232
evaluation/ExplReturns Std         0.419047
evaluation/ExplReturns Max         1.40983
evaluation/ExplReturns Min         0.307617
evaluation/Actions Mean           -0.0212381
evaluation/Actions Std             0.250545
evaluation/Actions Max             0.965761
evaluation/Actions Min            -0.984101
evaluation/Num Paths              10
evaluation/Average Returns         0.819232
time/data storing (s)              0.0284903
time/evaluation sampling (s)      68.8444
time/exploration sampling (s)     75.3117
time/logging (s)                   0.0247396
time/saving (s)                    0.0633189
time/training (s)                 10.5853
time/epoch (s)                   154.858
time/total (s)                  1567.34
Epoch                              9
-----------------------------  ---------------
2023-08-31 12:24:45.940576 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 10 finished
-----------------------------  ---------------
replay_buffer/size             56000
trainer/QF1 Loss                  10.4559
trainer/QF2 Loss                  10.015
trainer/Policy Loss              -44.9453
trainer/Q1 Predictions Mean       46.1399
trainer/Q1 Predictions Std        11.0009
trainer/Q1 Predictions Max        69.0358
trainer/Q1 Predictions Min        -1.61334
trainer/Q2 Predictions Mean       46.1659
trainer/Q2 Predictions Std        10.9222
trainer/Q2 Predictions Max        69.9201
trainer/Q2 Predictions Min        -2.28506
trainer/Q Targets Mean            45.522
trainer/Q Targets Std             11.2062
trainer/Q Targets Max             67.594
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               2.57089
trainer/Log Pis Std                4.14055
trainer/Log Pis Max               13.3989
trainer/Log Pis Min               -6.96738
trainer/Policy mu Mean             0.0950609
trainer/Policy mu Std              1.32806
trainer/Policy mu Max              3.25154
trainer/Policy mu Min             -3.68614
trainer/Policy log std Mean       -0.401918
trainer/Policy log std Std         0.234081
trainer/Policy log std Max         0.144068
trainer/Policy log std Min        -1.22014
trainer/Alpha                      0.0644867
trainer/Alpha Loss                -9.39947
exploration/num steps total    56000
exploration/num paths total      467
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00398182
exploration/Rewards Std            0.00558543
exploration/Rewards Max            0.042587
exploration/Rewards Min            0.000307348
exploration/Returns Mean           1.99091
exploration/Returns Std            0.309129
exploration/Returns Max            2.40157
exploration/Returns Min            1.44835
exploration/Actions Mean          -0.0050873
exploration/Actions Std            0.588764
exploration/Actions Max            0.998657
exploration/Actions Min           -0.998473
exploration/Num Paths             10
exploration/Average Returns        1.99091
evaluation/num steps total     54648
evaluation/num paths total       439
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00288313
evaluation/Rewards Std             0.0053833
evaluation/Rewards Max             0.0531257
evaluation/Rewards Min             0.000915293
evaluation/Returns Mean            1.44157
evaluation/Returns Std             0.325105
evaluation/Returns Max             1.82517
evaluation/Returns Min             0.926698
evaluation/ExplReturns Mean        1.44157
evaluation/ExplReturns Std         0.325105
evaluation/ExplReturns Max         1.82517
evaluation/ExplReturns Min         0.926698
evaluation/Actions Mean           -0.0559631
evaluation/Actions Std             0.312991
evaluation/Actions Max             0.980465
evaluation/Actions Min            -0.958064
evaluation/Num Paths              10
evaluation/Average Returns         1.44157
time/data storing (s)              0.0285714
time/evaluation sampling (s)      69.0895
time/exploration sampling (s)     73.1101
time/logging (s)                   0.0259622
time/saving (s)                    0.0327104
time/training (s)                 13.5023
time/epoch (s)                   155.789
time/total (s)                  1723.13
Epoch                             10
-----------------------------  ---------------
2023-08-31 12:27:19.241443 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size             61000
trainer/QF1 Loss                   2.31852
trainer/QF2 Loss                   2.58163
trainer/Policy Loss              -47.1055
trainer/Q1 Predictions Mean       49.7309
trainer/Q1 Predictions Std        10.0873
trainer/Q1 Predictions Max        69.1822
trainer/Q1 Predictions Min         8.47651
trainer/Q2 Predictions Mean       49.3976
trainer/Q2 Predictions Std        10.0924
trainer/Q2 Predictions Max        70.476
trainer/Q2 Predictions Min         7.78014
trainer/Q Targets Mean            49.9264
trainer/Q Targets Std             10.166
trainer/Q Targets Max             69.7459
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               3.78133
trainer/Log Pis Std                4.19119
trainer/Log Pis Max               26.9967
trainer/Log Pis Min               -6.4717
trainer/Policy mu Mean             0.18849
trainer/Policy mu Std              1.38196
trainer/Policy mu Max              3.43512
trainer/Policy mu Min             -3.92052
trainer/Policy log std Mean       -0.518137
trainer/Policy log std Std         0.294625
trainer/Policy log std Max         0.0709738
trainer/Policy log std Min        -1.54288
trainer/Alpha                      0.052022
trainer/Alpha Loss                -6.55819
exploration/num steps total    61000
exploration/num paths total      477
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0093935
exploration/Rewards Std            0.00826577
exploration/Rewards Max            0.0629796
exploration/Rewards Min            0.00119284
exploration/Returns Mean           4.69675
exploration/Returns Std            1.02467
exploration/Returns Max            5.98505
exploration/Returns Min            2.54464
exploration/Actions Mean           0.0108697
exploration/Actions Std            0.55027
exploration/Actions Max            0.998795
exploration/Actions Min           -0.996604
exploration/Num Paths             10
exploration/Average Returns        4.69675
evaluation/num steps total     59648
evaluation/num paths total       449
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00723398
evaluation/Rewards Std             0.00668048
evaluation/Rewards Max             0.0488496
evaluation/Rewards Min             0.00272304
evaluation/Returns Mean            3.61699
evaluation/Returns Std             1.00722
evaluation/Returns Max             4.57778
evaluation/Returns Min             1.96679
evaluation/ExplReturns Mean        3.61699
evaluation/ExplReturns Std         1.00722
evaluation/ExplReturns Max         4.57778
evaluation/ExplReturns Min         1.96679
evaluation/Actions Mean            0.00463827
evaluation/Actions Std             0.165519
evaluation/Actions Max             0.987216
evaluation/Actions Min            -0.975514
evaluation/Num Paths              10
evaluation/Average Returns         3.61699
time/data storing (s)              0.0285613
time/evaluation sampling (s)      68.9934
time/exploration sampling (s)     73.6327
time/logging (s)                   0.025724
time/saving (s)                    0.0673441
time/training (s)                 10.5493
time/epoch (s)                   153.297
time/total (s)                  1876.43
Epoch                             11
-----------------------------  --------------
2023-08-31 12:29:55.042025 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size             66000
trainer/QF1 Loss                  11.8385
trainer/QF2 Loss                  11.043
trainer/Policy Loss              -49.5074
trainer/Q1 Predictions Mean       52.0786
trainer/Q1 Predictions Std        10.1718
trainer/Q1 Predictions Max        77.135
trainer/Q1 Predictions Min         2.1541
trainer/Q2 Predictions Mean       52.3297
trainer/Q2 Predictions Std        10.2567
trainer/Q2 Predictions Max        77.335
trainer/Q2 Predictions Min         6.48596
trainer/Q Targets Mean            52.0025
trainer/Q Targets Std             11.0021
trainer/Q Targets Max             73.1851
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               4.07305
trainer/Log Pis Std                4.45036
trainer/Log Pis Max               20.6489
trainer/Log Pis Min               -6.90834
trainer/Policy mu Mean             0.211615
trainer/Policy mu Std              1.4192
trainer/Policy mu Max              4.99716
trainer/Policy mu Min             -3.6857
trainer/Policy log std Mean       -0.548095
trainer/Policy log std Std         0.323517
trainer/Policy log std Max         0.0770528
trainer/Policy log std Min        -1.83046
trainer/Alpha                      0.0431092
trainer/Alpha Loss                -6.058
exploration/num steps total    66000
exploration/num paths total      487
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0478971
exploration/Rewards Std            0.192106
exploration/Rewards Max            5.70346
exploration/Rewards Min           -0.318035
exploration/Returns Mean          23.9485
exploration/Returns Std           13.5501
exploration/Returns Max           50.8926
exploration/Returns Min            7.79429
exploration/Actions Mean           0.0144329
exploration/Actions Std            0.588247
exploration/Actions Max            0.999392
exploration/Actions Min           -0.999172
exploration/Num Paths             10
exploration/Average Returns       23.9485
evaluation/num steps total     64648
evaluation/num paths total       459
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.030098
evaluation/Rewards Std             0.0217167
evaluation/Rewards Max             0.0923171
evaluation/Rewards Min            -0.125231
evaluation/Returns Mean           15.049
evaluation/Returns Std             9.78224
evaluation/Returns Max            28.8054
evaluation/Returns Min             3.92832
evaluation/ExplReturns Mean       15.049
evaluation/ExplReturns Std         9.78224
evaluation/ExplReturns Max        28.8054
evaluation/ExplReturns Min         3.92832
evaluation/Actions Mean           -0.00791611
evaluation/Actions Std             0.250418
evaluation/Actions Max             0.960233
evaluation/Actions Min            -0.981219
evaluation/Num Paths              10
evaluation/Average Returns        15.049
time/data storing (s)              0.0290634
time/evaluation sampling (s)      69.7409
time/exploration sampling (s)     75.0999
time/logging (s)                   0.0249762
time/saving (s)                    0.0655659
time/training (s)                 10.836
time/epoch (s)                   155.796
time/total (s)                  2032.23
Epoch                             12
-----------------------------  --------------
2023-08-31 12:32:26.892369 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 13 finished
-----------------------------  ---------------
replay_buffer/size             71000
trainer/QF1 Loss                   7.12806
trainer/QF2 Loss                   6.36247
trainer/Policy Loss              -53.1042
trainer/Q1 Predictions Mean       56.5853
trainer/Q1 Predictions Std         9.19732
trainer/Q1 Predictions Max        74.6478
trainer/Q1 Predictions Min        29.5645
trainer/Q2 Predictions Mean       56.2915
trainer/Q2 Predictions Std         9.38517
trainer/Q2 Predictions Max        73.6733
trainer/Q2 Predictions Min        29.5916
trainer/Q Targets Mean            55.8989
trainer/Q Targets Std              9.63892
trainer/Q Targets Max             70.9538
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               4.6019
trainer/Log Pis Std                4.58941
trainer/Log Pis Max               26.0153
trainer/Log Pis Min               -7.268
trainer/Policy mu Mean             0.0270494
trainer/Policy mu Std              1.46181
trainer/Policy mu Max              3.85501
trainer/Policy mu Min             -3.46093
trainer/Policy log std Mean       -0.594619
trainer/Policy log std Std         0.358319
trainer/Policy log std Max         0.0438205
trainer/Policy log std Min        -2.184
trainer/Alpha                      0.0369399
trainer/Alpha Loss                -4.61136
exploration/num steps total    71000
exploration/num paths total      497
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0186105
exploration/Rewards Std            0.0160187
exploration/Rewards Max            0.074678
exploration/Rewards Min            0.000609435
exploration/Returns Mean           9.30526
exploration/Returns Std            7.12419
exploration/Returns Max           20.2194
exploration/Returns Min            1.57479
exploration/Actions Mean           0.0282174
exploration/Actions Std            0.632194
exploration/Actions Max            0.999583
exploration/Actions Min           -0.999297
exploration/Num Paths             10
exploration/Average Returns        9.30526
evaluation/num steps total     69648
evaluation/num paths total       469
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00562158
evaluation/Rewards Std             0.00465253
evaluation/Rewards Max             0.0339215
evaluation/Rewards Min             0.000449324
evaluation/Returns Mean            2.81079
evaluation/Returns Std             1.51602
evaluation/Returns Max             4.96591
evaluation/Returns Min             0.787654
evaluation/ExplReturns Mean        2.81079
evaluation/ExplReturns Std         1.51602
evaluation/ExplReturns Max         4.96591
evaluation/ExplReturns Min         0.787654
evaluation/Actions Mean           -0.156506
evaluation/Actions Std             0.488283
evaluation/Actions Max             0.983937
evaluation/Actions Min            -0.980278
evaluation/Num Paths              10
evaluation/Average Returns         2.81079
time/data storing (s)              0.0293423
time/evaluation sampling (s)      68.3695
time/exploration sampling (s)     72.7208
time/logging (s)                   0.0262264
time/saving (s)                    0.063354
time/training (s)                 10.6389
time/epoch (s)                   151.848
time/total (s)                  2184.08
Epoch                             13
-----------------------------  ---------------
2023-08-31 12:35:04.387492 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size             76000
trainer/QF1 Loss                  16.6355
trainer/QF2 Loss                  16.2725
trainer/Policy Loss              -54.3683
trainer/Q1 Predictions Mean       57.9396
trainer/Q1 Predictions Std         9.08109
trainer/Q1 Predictions Max        74.8573
trainer/Q1 Predictions Min        16.9746
trainer/Q2 Predictions Mean       57.8823
trainer/Q2 Predictions Std         9.05482
trainer/Q2 Predictions Max        74.3502
trainer/Q2 Predictions Min        18.9503
trainer/Q Targets Mean            57.6887
trainer/Q Targets Std              9.24627
trainer/Q Targets Max             72.9171
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               5.08583
trainer/Log Pis Std                4.57813
trainer/Log Pis Max               23.6537
trainer/Log Pis Min               -3.7987
trainer/Policy mu Mean             0.162664
trainer/Policy mu Std              1.51764
trainer/Policy mu Max              4.37919
trainer/Policy mu Min             -4.05092
trainer/Policy log std Mean       -0.608988
trainer/Policy log std Std         0.426477
trainer/Policy log std Max         0.398056
trainer/Policy log std Min        -2.30813
trainer/Alpha                      0.0316473
trainer/Alpha Loss                -3.15661
exploration/num steps total    76000
exploration/num paths total      507
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0490324
exploration/Rewards Std            0.247555
exploration/Rewards Max            8.18419
exploration/Rewards Min           -0.329447
exploration/Returns Mean          24.5162
exploration/Returns Std           19.7843
exploration/Returns Max           75.5952
exploration/Returns Min            7.75441
exploration/Actions Mean           0.00921843
exploration/Actions Std            0.594872
exploration/Actions Max            0.999732
exploration/Actions Min           -0.999718
exploration/Num Paths             10
exploration/Average Returns       24.5162
evaluation/num steps total     74648
evaluation/num paths total       479
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0542311
evaluation/Rewards Std             0.128158
evaluation/Rewards Max             5.7266
evaluation/Rewards Min            -0.142379
evaluation/Returns Mean           27.1155
evaluation/Returns Std            16.7123
evaluation/Returns Max            59.7572
evaluation/Returns Min             8.87756
evaluation/ExplReturns Mean       27.1155
evaluation/ExplReturns Std        16.7123
evaluation/ExplReturns Max        59.7572
evaluation/ExplReturns Min         8.87756
evaluation/Actions Mean           -0.0134743
evaluation/Actions Std             0.409216
evaluation/Actions Max             0.983786
evaluation/Actions Min            -0.975047
evaluation/Num Paths              10
evaluation/Average Returns        27.1155
time/data storing (s)              0.028922
time/evaluation sampling (s)      71.0435
time/exploration sampling (s)     75.9656
time/logging (s)                   0.0249248
time/saving (s)                    0.0616555
time/training (s)                 10.3658
time/epoch (s)                   157.49
time/total (s)                  2341.58
Epoch                             14
-----------------------------  --------------
2023-08-31 12:37:38.507512 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size             81000
trainer/QF1 Loss                  14.3481
trainer/QF2 Loss                  13.8025
trainer/Policy Loss              -55.3753
trainer/Q1 Predictions Mean       59.3444
trainer/Q1 Predictions Std         9.26743
trainer/Q1 Predictions Max        75.0878
trainer/Q1 Predictions Min        18.8317
trainer/Q2 Predictions Mean       59.1941
trainer/Q2 Predictions Std         9.18483
trainer/Q2 Predictions Max        75.3179
trainer/Q2 Predictions Min        18.0991
trainer/Q Targets Mean            58.9018
trainer/Q Targets Std             11.0556
trainer/Q Targets Max             75.7053
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               5.13026
trainer/Log Pis Std                4.82807
trainer/Log Pis Max               30.1611
trainer/Log Pis Min               -6.40799
trainer/Policy mu Mean             0.294985
trainer/Policy mu Std              1.49244
trainer/Policy mu Max              4.3192
trainer/Policy mu Min             -3.82731
trainer/Policy log std Mean       -0.570043
trainer/Policy log std Std         0.425559
trainer/Policy log std Max         0.24456
trainer/Policy log std Min        -2.313
trainer/Alpha                      0.0293168
trainer/Alpha Loss                -3.06971
exploration/num steps total    81000
exploration/num paths total      517
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0306297
exploration/Rewards Std            0.0136015
exploration/Rewards Max            0.0949033
exploration/Rewards Min            0.00575292
exploration/Returns Mean          15.3149
exploration/Returns Std            4.95541
exploration/Returns Max           26.1296
exploration/Returns Min            9.78341
exploration/Actions Mean           0.0456202
exploration/Actions Std            0.606738
exploration/Actions Max            0.999692
exploration/Actions Min           -0.999472
exploration/Num Paths             10
exploration/Average Returns       15.3149
evaluation/num steps total     79648
evaluation/num paths total       489
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0264242
evaluation/Rewards Std             0.0124997
evaluation/Rewards Max             0.0678366
evaluation/Rewards Min             0.00512117
evaluation/Returns Mean           13.2121
evaluation/Returns Std             5.62386
evaluation/Returns Max            22.6448
evaluation/Returns Min             6.50571
evaluation/ExplReturns Mean       13.2121
evaluation/ExplReturns Std         5.62386
evaluation/ExplReturns Max        22.6448
evaluation/ExplReturns Min         6.50571
evaluation/Actions Mean            0.0331696
evaluation/Actions Std             0.416094
evaluation/Actions Max             0.985676
evaluation/Actions Min            -0.973248
evaluation/Num Paths              10
evaluation/Average Returns        13.2121
time/data storing (s)              0.02884
time/evaluation sampling (s)      68.7147
time/exploration sampling (s)     74.3565
time/logging (s)                   0.0258369
time/saving (s)                    0.0781908
time/training (s)                 10.9136
time/epoch (s)                   154.118
time/total (s)                  2495.7
Epoch                             15
-----------------------------  --------------
2023-08-31 12:40:11.209042 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size             86000
trainer/QF1 Loss                   2.61782
trainer/QF2 Loss                   2.22275
trainer/Policy Loss              -55.6175
trainer/Q1 Predictions Mean       59.4314
trainer/Q1 Predictions Std         8.14843
trainer/Q1 Predictions Max        71.3361
trainer/Q1 Predictions Min        13.074
trainer/Q2 Predictions Mean       59.6512
trainer/Q2 Predictions Std         8.28383
trainer/Q2 Predictions Max        72.003
trainer/Q2 Predictions Min        14.5868
trainer/Q Targets Mean            59.977
trainer/Q Targets Std              7.95032
trainer/Q Targets Max             72.4059
trainer/Q Targets Min             18.5629
trainer/Log Pis Mean               5.07593
trainer/Log Pis Std                4.93866
trainer/Log Pis Max               21.0015
trainer/Log Pis Min               -5.03082
trainer/Policy mu Mean             0.0154886
trainer/Policy mu Std              1.5337
trainer/Policy mu Max              3.94281
trainer/Policy mu Min             -4.08463
trainer/Policy log std Mean       -0.584162
trainer/Policy log std Std         0.439365
trainer/Policy log std Max         0.290625
trainer/Policy log std Min        -2.27327
trainer/Alpha                      0.0281288
trainer/Alpha Loss                -3.29948
exploration/num steps total    86000
exploration/num paths total      531
exploration/path length Mean     357.143
exploration/path length Std      118.757
exploration/path length Max      500
exploration/path length Min      165
exploration/Rewards Mean           0.022132
exploration/Rewards Std            0.0203156
exploration/Rewards Max            0.0861082
exploration/Rewards Min           -0.281611
exploration/Returns Mean           7.90427
exploration/Returns Std            5.04152
exploration/Returns Max           21.4517
exploration/Returns Min            2.30196
exploration/Actions Mean           0.0257852
exploration/Actions Std            0.583439
exploration/Actions Max            0.999455
exploration/Actions Min           -0.999657
exploration/Num Paths             14
exploration/Average Returns        7.90427
evaluation/num steps total     84648
evaluation/num paths total       499
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0162682
evaluation/Rewards Std             0.012412
evaluation/Rewards Max             0.0671999
evaluation/Rewards Min             0.00369105
evaluation/Returns Mean            8.13409
evaluation/Returns Std             5.54673
evaluation/Returns Max            19.392
evaluation/Returns Min             2.52865
evaluation/ExplReturns Mean        8.13409
evaluation/ExplReturns Std         5.54673
evaluation/ExplReturns Max        19.392
evaluation/ExplReturns Min         2.52865
evaluation/Actions Mean            0.000741916
evaluation/Actions Std             0.391597
evaluation/Actions Max             0.988087
evaluation/Actions Min            -0.953772
evaluation/Num Paths              10
evaluation/Average Returns         8.13409
time/data storing (s)              0.0291287
time/evaluation sampling (s)      68.8019
time/exploration sampling (s)     72.9077
time/logging (s)                   0.0253891
time/saving (s)                    0.0680589
time/training (s)                 10.8655
time/epoch (s)                   152.698
time/total (s)                  2648.4
Epoch                             16
-----------------------------  ---------------
2023-08-31 12:42:44.938128 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size             91000
trainer/QF1 Loss                   6.12178
trainer/QF2 Loss                   5.99073
trainer/Policy Loss              -57.2458
trainer/Q1 Predictions Mean       61.5276
trainer/Q1 Predictions Std         7.39261
trainer/Q1 Predictions Max        79.7154
trainer/Q1 Predictions Min        19.935
trainer/Q2 Predictions Mean       61.972
trainer/Q2 Predictions Std         7.44174
trainer/Q2 Predictions Max        81.361
trainer/Q2 Predictions Min        18.189
trainer/Q Targets Mean            61.8055
trainer/Q Targets Std              8.40621
trainer/Q Targets Max             80.2962
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               5.73674
trainer/Log Pis Std                4.81568
trainer/Log Pis Max               24.3283
trainer/Log Pis Min               -5.03126
trainer/Policy mu Mean             0.0521015
trainer/Policy mu Std              1.57908
trainer/Policy mu Max              4.04725
trainer/Policy mu Min             -6.89542
trainer/Policy log std Mean       -0.643224
trainer/Policy log std Std         0.464065
trainer/Policy log std Max         1.05079
trainer/Policy log std Min        -2.56305
trainer/Alpha                      0.0263973
trainer/Alpha Loss                -0.956811
exploration/num steps total    91000
exploration/num paths total      541
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0168458
exploration/Rewards Std            0.00835372
exploration/Rewards Max            0.0557792
exploration/Rewards Min            0.00232369
exploration/Returns Mean           8.4229
exploration/Returns Std            3.26782
exploration/Returns Max           13.1822
exploration/Returns Min            2.92267
exploration/Actions Mean          -0.00428599
exploration/Actions Std            0.603171
exploration/Actions Max            0.999381
exploration/Actions Min           -0.999372
exploration/Num Paths             10
exploration/Average Returns        8.4229
evaluation/num steps total     89648
evaluation/num paths total       509
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0170262
evaluation/Rewards Std             0.00810211
evaluation/Rewards Max             0.038705
evaluation/Rewards Min             0.00250165
evaluation/Returns Mean            8.51312
evaluation/Returns Std             3.49584
evaluation/Returns Max            13.2956
evaluation/Returns Min             2.79479
evaluation/ExplReturns Mean        8.51312
evaluation/ExplReturns Std         3.49584
evaluation/ExplReturns Max        13.2956
evaluation/ExplReturns Min         2.79479
evaluation/Actions Mean            0.00810858
evaluation/Actions Std             0.521429
evaluation/Actions Max             0.97105
evaluation/Actions Min            -0.964932
evaluation/Num Paths              10
evaluation/Average Returns         8.51312
time/data storing (s)              0.0289872
time/evaluation sampling (s)      69.0849
time/exploration sampling (s)     74.1147
time/logging (s)                   0.0253518
time/saving (s)                    0.0629567
time/training (s)                 10.4086
time/epoch (s)                   153.725
time/total (s)                  2802.13
Epoch                             17
-----------------------------  --------------
2023-08-31 12:45:19.206601 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 18 finished
-----------------------------  ---------------
replay_buffer/size             96000
trainer/QF1 Loss                   2.36588
trainer/QF2 Loss                   2.8629
trainer/Policy Loss              -58.5833
trainer/Q1 Predictions Mean       62.9172
trainer/Q1 Predictions Std         6.82688
trainer/Q1 Predictions Max        77.2168
trainer/Q1 Predictions Min        14.1115
trainer/Q2 Predictions Mean       62.7175
trainer/Q2 Predictions Std         6.91997
trainer/Q2 Predictions Max        76.017
trainer/Q2 Predictions Min        13.7796
trainer/Q Targets Mean            62.6458
trainer/Q Targets Std              7.0433
trainer/Q Targets Max             79.8203
trainer/Q Targets Min             -0.281611
trainer/Log Pis Mean               5.45669
trainer/Log Pis Std                4.45597
trainer/Log Pis Max               19.2448
trainer/Log Pis Min               -6.50742
trainer/Policy mu Mean             0.0600055
trainer/Policy mu Std              1.55855
trainer/Policy mu Max              3.72221
trainer/Policy mu Min             -4.35156
trainer/Policy log std Mean       -0.656839
trainer/Policy log std Std         0.394564
trainer/Policy log std Max         0.0797194
trainer/Policy log std Min        -2.54342
trainer/Alpha                      0.0246868
trainer/Alpha Loss                -2.01108
exploration/num steps total    96000
exploration/num paths total      551
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0140173
exploration/Rewards Std            0.00745409
exploration/Rewards Max            0.0544629
exploration/Rewards Min            0.000210831
exploration/Returns Mean           7.00865
exploration/Returns Std            1.97663
exploration/Returns Max           10.1212
exploration/Returns Min            3.9128
exploration/Actions Mean           8.10248e-06
exploration/Actions Std            0.588551
exploration/Actions Max            0.999469
exploration/Actions Min           -0.999305
exploration/Num Paths             10
exploration/Average Returns        7.00865
evaluation/num steps total     94648
evaluation/num paths total       519
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0166674
evaluation/Rewards Std             0.00888547
evaluation/Rewards Max             0.0435066
evaluation/Rewards Min             0.000229128
evaluation/Returns Mean            8.33371
evaluation/Returns Std             3.83604
evaluation/Returns Max            11.4144
evaluation/Returns Min             1.16452
evaluation/ExplReturns Mean        8.33371
evaluation/ExplReturns Std         3.83604
evaluation/ExplReturns Max        11.4144
evaluation/ExplReturns Min         1.16452
evaluation/Actions Mean            0.0429189
evaluation/Actions Std             0.458202
evaluation/Actions Max             0.998831
evaluation/Actions Min            -0.994488
evaluation/Num Paths              10
evaluation/Average Returns         8.33371
time/data storing (s)              0.0289358
time/evaluation sampling (s)      68.5356
time/exploration sampling (s)     74.9089
time/logging (s)                   0.0251672
time/saving (s)                    0.0689532
time/training (s)                 10.6973
time/epoch (s)                   154.265
time/total (s)                  2956.39
Epoch                             18
-----------------------------  ---------------
2023-08-31 12:47:53.952871 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 19 finished
-----------------------------  ---------------
replay_buffer/size             101000
trainer/QF1 Loss                   32.0514
trainer/QF2 Loss                   33.2702
trainer/Policy Loss               -58.633
trainer/Q1 Predictions Mean        63.6065
trainer/Q1 Predictions Std          7.5545
trainer/Q1 Predictions Max         82.3716
trainer/Q1 Predictions Min          2.83114
trainer/Q2 Predictions Mean        63.7385
trainer/Q2 Predictions Std          7.57082
trainer/Q2 Predictions Max         83.0349
trainer/Q2 Predictions Min          1.14717
trainer/Q Targets Mean             62.9022
trainer/Q Targets Std              10.7648
trainer/Q Targets Max              81.4299
trainer/Q Targets Min              -3.11728
trainer/Log Pis Mean                6.21733
trainer/Log Pis Std                 4.7009
trainer/Log Pis Max                23.153
trainer/Log Pis Min                -5.0005
trainer/Policy mu Mean              0.181499
trainer/Policy mu Std               1.61465
trainer/Policy mu Max               5.75053
trainer/Policy mu Min              -4.22973
trainer/Policy log std Mean        -0.680148
trainer/Policy log std Std          0.334792
trainer/Policy log std Max          0.0521544
trainer/Policy log std Min         -2.2102
trainer/Alpha                       0.0275618
trainer/Alpha Loss                  0.780566
exploration/num steps total    101000
exploration/num paths total       653
exploration/path length Mean       49.0196
exploration/path length Std        45.312
exploration/path length Max       500
exploration/path length Min         1
exploration/Rewards Mean            0.00832099
exploration/Rewards Std             0.0435824
exploration/Rewards Max             0.080966
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.407892
exploration/Returns Std             0.268631
exploration/Returns Max             1.0059
exploration/Returns Min            -0.0315953
exploration/Actions Mean            0.140074
exploration/Actions Std             0.695087
exploration/Actions Max             0.999903
exploration/Actions Min            -0.998891
exploration/Num Paths             102
exploration/Average Returns         0.407892
evaluation/num steps total      99622
evaluation/num paths total        641
evaluation/path length Mean        40.7705
evaluation/path length Std          1.31066
evaluation/path length Max         44
evaluation/path length Min         37
evaluation/Rewards Mean             0.00956559
evaluation/Rewards Std              0.0479428
evaluation/Rewards Max              0.0807967
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.389994
evaluation/Returns Std              0.240697
evaluation/Returns Max              0.981588
evaluation/Returns Min             -0.00168623
evaluation/ExplReturns Mean         0.389994
evaluation/ExplReturns Std          0.240697
evaluation/ExplReturns Max          0.981588
evaluation/ExplReturns Min         -0.00168623
evaluation/Actions Mean             0.16186
evaluation/Actions Std              0.673872
evaluation/Actions Max              0.998802
evaluation/Actions Min             -0.987939
evaluation/Num Paths              122
evaluation/Average Returns          0.389994
time/data storing (s)               0.0295062
time/evaluation sampling (s)       68.7503
time/exploration sampling (s)      74.5972
time/logging (s)                    0.0270456
time/saving (s)                     0.065876
time/training (s)                  11.2746
time/epoch (s)                    154.745
time/total (s)                   3111.14
Epoch                              19
-----------------------------  ---------------
2023-08-31 12:50:30.763298 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 20 finished
-----------------------------  ----------------
replay_buffer/size             106000
trainer/QF1 Loss                    5.00066
trainer/QF2 Loss                    5.92273
trainer/Policy Loss               -59.8747
trainer/Q1 Predictions Mean        64.044
trainer/Q1 Predictions Std          8.09441
trainer/Q1 Predictions Max         80.8085
trainer/Q1 Predictions Min          4.2125
trainer/Q2 Predictions Mean        64.3905
trainer/Q2 Predictions Std          8.19604
trainer/Q2 Predictions Max         81.209
trainer/Q2 Predictions Min          3.65504
trainer/Q Targets Mean             64.0084
trainer/Q Targets Std               8.73228
trainer/Q Targets Max              79.8213
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.67153
trainer/Log Pis Std                 4.74746
trainer/Log Pis Max                28.4857
trainer/Log Pis Min                -5.60023
trainer/Policy mu Mean             -0.0162579
trainer/Policy mu Std               1.6157
trainer/Policy mu Max               4.52619
trainer/Policy mu Min              -4.37816
trainer/Policy log std Mean        -0.639323
trainer/Policy log std Std          0.285982
trainer/Policy log std Max         -0.00513413
trainer/Policy log std Min         -2.07421
trainer/Alpha                       0.0314993
trainer/Alpha Loss                 -1.13582
exploration/num steps total    106000
exploration/num paths total       677
exploration/path length Mean      208.333
exploration/path length Std        91.9201
exploration/path length Max       431
exploration/path length Min        74
exploration/Rewards Mean            0.00620307
exploration/Rewards Std             0.0247245
exploration/Rewards Max             0.084611
exploration/Rewards Min            -0.407948
exploration/Returns Mean            1.29231
exploration/Returns Std             0.505427
exploration/Returns Max             3.16083
exploration/Returns Min             0.650442
exploration/Actions Mean            0.00682239
exploration/Actions Std             0.607274
exploration/Actions Max             0.99995
exploration/Actions Min            -0.999998
exploration/Num Paths              24
exploration/Average Returns         1.29231
evaluation/num steps total     104622
evaluation/num paths total        651
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00478388
evaluation/Rewards Std              0.00844692
evaluation/Rewards Max              0.0696759
evaluation/Rewards Min              0.000895165
evaluation/Returns Mean             2.39194
evaluation/Returns Std              0.338911
evaluation/Returns Max              2.75915
evaluation/Returns Min              1.54385
evaluation/ExplReturns Mean         2.39194
evaluation/ExplReturns Std          0.338911
evaluation/ExplReturns Max          2.75915
evaluation/ExplReturns Min          1.54385
evaluation/Actions Mean             0.00466036
evaluation/Actions Std              0.223293
evaluation/Actions Max              0.997567
evaluation/Actions Min             -0.98253
evaluation/Num Paths               10
evaluation/Average Returns          2.39194
time/data storing (s)               0.0291976
time/evaluation sampling (s)       67.9811
time/exploration sampling (s)      74.8281
time/logging (s)                    0.0253213
time/saving (s)                     0.0617723
time/training (s)                  13.8793
time/epoch (s)                    156.805
time/total (s)                   3267.95
Epoch                              20
-----------------------------  ----------------
2023-08-31 12:53:05.457507 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 21 finished
-----------------------------  ---------------
replay_buffer/size             111000
trainer/QF1 Loss                    2.33265
trainer/QF2 Loss                    2.56796
trainer/Policy Loss               -60.1864
trainer/Q1 Predictions Mean        64.5579
trainer/Q1 Predictions Std          8.07727
trainer/Q1 Predictions Max         84.137
trainer/Q1 Predictions Min          5.48914
trainer/Q2 Predictions Mean        64.7219
trainer/Q2 Predictions Std          8.06828
trainer/Q2 Predictions Max         83.8996
trainer/Q2 Predictions Min          7.49858
trainer/Q Targets Mean             64.9016
trainer/Q Targets Std               7.90711
trainer/Q Targets Max              85.0133
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.70331
trainer/Log Pis Std                 4.26582
trainer/Log Pis Max                19.6986
trainer/Log Pis Min                -5.47088
trainer/Policy mu Mean             -0.0456032
trainer/Policy mu Std               1.56143
trainer/Policy mu Max               3.71462
trainer/Policy mu Min              -3.57609
trainer/Policy log std Mean        -0.669052
trainer/Policy log std Std          0.269877
trainer/Policy log std Max         -0.0313304
trainer/Policy log std Min         -2.46103
trainer/Alpha                       0.0318833
trainer/Alpha Loss                 -1.02234
exploration/num steps total    111000
exploration/num paths total       687
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.023441
exploration/Rewards Std             0.0256056
exploration/Rewards Max             0.134568
exploration/Rewards Min            -0.296818
exploration/Returns Mean           11.7205
exploration/Returns Std             4.72101
exploration/Returns Max            24.576
exploration/Returns Min             6.9326
exploration/Actions Mean            0.00698538
exploration/Actions Std             0.552536
exploration/Actions Max             0.999399
exploration/Actions Min            -0.999868
exploration/Num Paths              10
exploration/Average Returns        11.7205
evaluation/num steps total     109622
evaluation/num paths total        661
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.038881
evaluation/Rewards Std              0.0256824
evaluation/Rewards Max              0.114454
evaluation/Rewards Min              0.00380379
evaluation/Returns Mean            19.4405
evaluation/Returns Std              5.25352
evaluation/Returns Max             28.1301
evaluation/Returns Min             11.7895
evaluation/ExplReturns Mean        19.4405
evaluation/ExplReturns Std          5.25352
evaluation/ExplReturns Max         28.1301
evaluation/ExplReturns Min         11.7895
evaluation/Actions Mean             0.0180842
evaluation/Actions Std              0.368445
evaluation/Actions Max              0.998562
evaluation/Actions Min             -0.985061
evaluation/Num Paths               10
evaluation/Average Returns         19.4405
time/data storing (s)               0.0288958
time/evaluation sampling (s)       68.9336
time/exploration sampling (s)      74.7504
time/logging (s)                    0.0250986
time/saving (s)                     0.0645313
time/training (s)                  10.888
time/epoch (s)                    154.69
time/total (s)                   3422.64
Epoch                              21
-----------------------------  ---------------
2023-08-31 12:55:38.909354 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             116000
trainer/QF1 Loss                    3.17491
trainer/QF2 Loss                    2.56965
trainer/Policy Loss               -62.2289
trainer/Q1 Predictions Mean        66.1758
trainer/Q1 Predictions Std          9.51686
trainer/Q1 Predictions Max         83.1289
trainer/Q1 Predictions Min          2.51346
trainer/Q2 Predictions Mean        66.1553
trainer/Q2 Predictions Std          9.74546
trainer/Q2 Predictions Max         84.8541
trainer/Q2 Predictions Min          0.948424
trainer/Q Targets Mean             66.4071
trainer/Q Targets Std               9.51998
trainer/Q Targets Max              85.8982
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.40225
trainer/Log Pis Std                 4.89258
trainer/Log Pis Max                23.7079
trainer/Log Pis Min                -8.17558
trainer/Policy mu Mean             -0.0256143
trainer/Policy mu Std               1.52256
trainer/Policy mu Max               4.30166
trainer/Policy mu Min              -7.00174
trainer/Policy log std Mean        -0.654338
trainer/Policy log std Std          0.293269
trainer/Policy log std Max          0.505485
trainer/Policy log std Min         -2.19082
trainer/Alpha                       0.0307561
trainer/Alpha Loss                 -2.08095
exploration/num steps total    116000
exploration/num paths total       697
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0229068
exploration/Rewards Std             0.0157286
exploration/Rewards Max             0.0708196
exploration/Rewards Min            -0.227682
exploration/Returns Mean           11.4534
exploration/Returns Std             4.74104
exploration/Returns Max            17.8992
exploration/Returns Min             5.26813
exploration/Actions Mean            0.0101508
exploration/Actions Std             0.529578
exploration/Actions Max             0.999783
exploration/Actions Min            -0.999245
exploration/Num Paths              10
exploration/Average Returns        11.4534
evaluation/num steps total     114278
evaluation/num paths total        671
evaluation/path length Mean       465.6
evaluation/path length Std        103.2
evaluation/path length Max        500
evaluation/path length Min        156
evaluation/Rewards Mean             0.0165223
evaluation/Rewards Std              0.0154044
evaluation/Rewards Max              0.0693697
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             7.69278
evaluation/Returns Std              4.18507
evaluation/Returns Max             19.5281
evaluation/Returns Min              2.85104
evaluation/ExplReturns Mean         7.69278
evaluation/ExplReturns Std          4.18507
evaluation/ExplReturns Max         19.5281
evaluation/ExplReturns Min          2.85104
evaluation/Actions Mean             0.0117702
evaluation/Actions Std              0.394206
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.999907
evaluation/Num Paths               10
evaluation/Average Returns          7.69278
time/data storing (s)               0.0292481
time/evaluation sampling (s)       68.5225
time/exploration sampling (s)      74.4329
time/logging (s)                    0.0246923
time/saving (s)                     0.0661707
time/training (s)                  10.3725
time/epoch (s)                    153.448
time/total (s)                   3576.09
Epoch                              22
-----------------------------  --------------
2023-08-31 12:58:13.334846 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 23 finished
-----------------------------  ---------------
replay_buffer/size             121000
trainer/QF1 Loss                   23.3237
trainer/QF2 Loss                   23.7053
trainer/Policy Loss               -63.6504
trainer/Q1 Predictions Mean        68.2537
trainer/Q1 Predictions Std          8.66709
trainer/Q1 Predictions Max         85.5483
trainer/Q1 Predictions Min         -2.93359
trainer/Q2 Predictions Mean        68.2877
trainer/Q2 Predictions Std          8.72751
trainer/Q2 Predictions Max         87.8779
trainer/Q2 Predictions Min         -3.84497
trainer/Q Targets Mean             67.3963
trainer/Q Targets Std              10.1729
trainer/Q Targets Max              87.708
trainer/Q Targets Min              -3.29468
trainer/Log Pis Mean                6.2781
trainer/Log Pis Std                 4.17235
trainer/Log Pis Max                22.856
trainer/Log Pis Min                -5.13566
trainer/Policy mu Mean              0.0241942
trainer/Policy mu Std               1.59458
trainer/Policy mu Max               3.72902
trainer/Policy mu Min              -4.33094
trainer/Policy log std Mean        -0.699617
trainer/Policy log std Std          0.280114
trainer/Policy log std Max         -0.0714871
trainer/Policy log std Min         -1.95182
trainer/Alpha                       0.0306081
trainer/Alpha Loss                  0.969591
exploration/num steps total    121000
exploration/num paths total       709
exploration/path length Mean      416.667
exploration/path length Std       122.152
exploration/path length Max       500
exploration/path length Min       165
exploration/Rewards Mean            0.00456487
exploration/Rewards Std             0.0112263
exploration/Rewards Max             0.0507143
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.90203
exploration/Returns Std             1.19892
exploration/Returns Max             4.30784
exploration/Returns Min             0.527367
exploration/Actions Mean            0.0171363
exploration/Actions Std             0.606069
exploration/Actions Max             1
exploration/Actions Min            -0.999995
exploration/Num Paths              12
exploration/Average Returns         1.90203
evaluation/num steps total     118996
evaluation/num paths total        682
evaluation/path length Mean       428.909
evaluation/path length Std        150.893
evaluation/path length Max        500
evaluation/path length Min         97
evaluation/Rewards Mean             0.00937517
evaluation/Rewards Std              0.0114248
evaluation/Rewards Max              0.0614227
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             4.0211
evaluation/Returns Std              4.22463
evaluation/Returns Max             15.6017
evaluation/Returns Min             -0.059
evaluation/ExplReturns Mean         4.0211
evaluation/ExplReturns Std          4.22463
evaluation/ExplReturns Max         15.6017
evaluation/ExplReturns Min         -0.059
evaluation/Actions Mean             0.0075122
evaluation/Actions Std              0.425004
evaluation/Actions Max              0.999668
evaluation/Actions Min             -0.999983
evaluation/Num Paths               11
evaluation/Average Returns          4.0211
time/data storing (s)               0.0291859
time/evaluation sampling (s)       69.2372
time/exploration sampling (s)      75.0144
time/logging (s)                    0.0242974
time/saving (s)                     0.0724236
time/training (s)                  10.0441
time/epoch (s)                    154.422
time/total (s)                   3730.52
Epoch                              23
-----------------------------  ---------------
2023-08-31 13:00:53.637759 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 24 finished
-----------------------------  ----------------
replay_buffer/size             126000
trainer/QF1 Loss                    4.43509
trainer/QF2 Loss                    4.45359
trainer/Policy Loss               -64.425
trainer/Q1 Predictions Mean        68.5803
trainer/Q1 Predictions Std         10.6608
trainer/Q1 Predictions Max        123.098
trainer/Q1 Predictions Min          5.21997
trainer/Q2 Predictions Mean        68.8505
trainer/Q2 Predictions Std         10.8255
trainer/Q2 Predictions Max        128.341
trainer/Q2 Predictions Min          5.71591
trainer/Q Targets Mean             68.7049
trainer/Q Targets Std              10.9437
trainer/Q Targets Max             128.517
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.46544
trainer/Log Pis Std                 4.32692
trainer/Log Pis Max                26.8057
trainer/Log Pis Min                -4.41091
trainer/Policy mu Mean              0.0244659
trainer/Policy mu Std               1.50366
trainer/Policy mu Max               6.55915
trainer/Policy mu Min              -4.39074
trainer/Policy log std Mean        -0.764133
trainer/Policy log std Std          0.32652
trainer/Policy log std Max          0.0571324
trainer/Policy log std Min         -2.29817
trainer/Alpha                       0.0265753
trainer/Alpha Loss                 -1.93919
exploration/num steps total    126000
exploration/num paths total       720
exploration/path length Mean      454.545
exploration/path length Std        97.3843
exploration/path length Max       500
exploration/path length Min       218
exploration/Rewards Mean            0.00967877
exploration/Rewards Std             0.0132454
exploration/Rewards Max             0.086271
exploration/Rewards Min            -0.281611
exploration/Returns Mean            4.39944
exploration/Returns Std             2.19291
exploration/Returns Max             9.32452
exploration/Returns Min             1.99609
exploration/Actions Mean           -0.00387658
exploration/Actions Std             0.56937
exploration/Actions Max             0.999602
exploration/Actions Min            -0.99985
exploration/Num Paths              11
exploration/Average Returns         4.39944
evaluation/num steps total     123996
evaluation/num paths total        692
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00789572
evaluation/Rewards Std              0.010162
evaluation/Rewards Max              0.0693583
evaluation/Rewards Min              0.000521089
evaluation/Returns Mean             3.94786
evaluation/Returns Std              2.86094
evaluation/Returns Max             12.39
evaluation/Returns Min              1.88412
evaluation/ExplReturns Mean         3.94786
evaluation/ExplReturns Std          2.86094
evaluation/ExplReturns Max         12.39
evaluation/ExplReturns Min          1.88412
evaluation/Actions Mean            -0.0149088
evaluation/Actions Std              0.42556
evaluation/Actions Max              0.986952
evaluation/Actions Min             -0.996161
evaluation/Num Paths               10
evaluation/Average Returns          3.94786
time/data storing (s)               0.028684
time/evaluation sampling (s)       69.0925
time/exploration sampling (s)      75.651
time/logging (s)                    0.0250005
time/saving (s)                     0.0836217
time/training (s)                  15.4194
time/epoch (s)                    160.3
time/total (s)                   3890.82
Epoch                              24
-----------------------------  ----------------
2023-08-31 13:03:26.359190 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 25 finished
-----------------------------  ---------------
replay_buffer/size             131000
trainer/QF1 Loss                    2.13666
trainer/QF2 Loss                    2.25947
trainer/Policy Loss               -64.6798
trainer/Q1 Predictions Mean        69.4746
trainer/Q1 Predictions Std          7.68864
trainer/Q1 Predictions Max        124.436
trainer/Q1 Predictions Min         36.0204
trainer/Q2 Predictions Mean        69.58
trainer/Q2 Predictions Std          7.90063
trainer/Q2 Predictions Max        128.525
trainer/Q2 Predictions Min         32.8566
trainer/Q Targets Mean             69.785
trainer/Q Targets Std               7.68844
trainer/Q Targets Max             125.437
trainer/Q Targets Min              34.1735
trainer/Log Pis Mean                5.74787
trainer/Log Pis Std                 4.42865
trainer/Log Pis Max                26.0052
trainer/Log Pis Min                -5.37465
trainer/Policy mu Mean              0.0191681
trainer/Policy mu Std               1.54654
trainer/Policy mu Max               5.71354
trainer/Policy mu Min              -3.79255
trainer/Policy log std Mean        -0.757983
trainer/Policy log std Std          0.32397
trainer/Policy log std Max          0.0743093
trainer/Policy log std Min         -2.69938
trainer/Alpha                       0.0250681
trainer/Alpha Loss                 -0.929372
exploration/num steps total    131000
exploration/num paths total       730
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0305939
exploration/Rewards Std             0.0147408
exploration/Rewards Max             0.0694019
exploration/Rewards Min             0.00644331
exploration/Returns Mean           15.297
exploration/Returns Std             6.95332
exploration/Returns Max            27.1095
exploration/Returns Min             6.293
exploration/Actions Mean            0.0665653
exploration/Actions Std             0.510064
exploration/Actions Max             0.997728
exploration/Actions Min            -0.996482
exploration/Num Paths              10
exploration/Average Returns        15.297
evaluation/num steps total     128996
evaluation/num paths total        702
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0310637
evaluation/Rewards Std              0.0141337
evaluation/Rewards Max              0.0829373
evaluation/Rewards Min              0.00603743
evaluation/Returns Mean            15.5318
evaluation/Returns Std              6.90844
evaluation/Returns Max             26.7825
evaluation/Returns Min              6.87158
evaluation/ExplReturns Mean        15.5318
evaluation/ExplReturns Std          6.90844
evaluation/ExplReturns Max         26.7825
evaluation/ExplReturns Min          6.87158
evaluation/Actions Mean             0.0384483
evaluation/Actions Std              0.257834
evaluation/Actions Max              0.959714
evaluation/Actions Min             -0.968786
evaluation/Num Paths               10
evaluation/Average Returns         15.5318
time/data storing (s)               0.0289752
time/evaluation sampling (s)       69.1458
time/exploration sampling (s)      74.0851
time/logging (s)                    0.0252799
time/saving (s)                     0.0659054
time/training (s)                   9.3672
time/epoch (s)                    152.718
time/total (s)                   4043.54
Epoch                              25
-----------------------------  ---------------
2023-08-31 13:05:59.192108 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 26 finished
-----------------------------  ---------------
replay_buffer/size             136000
trainer/QF1 Loss                    2.2747
trainer/QF2 Loss                    2.22127
trainer/Policy Loss               -66.0391
trainer/Q1 Predictions Mean        70.1747
trainer/Q1 Predictions Std          9.03443
trainer/Q1 Predictions Max        121.314
trainer/Q1 Predictions Min         -7.65704
trainer/Q2 Predictions Mean        70.0996
trainer/Q2 Predictions Std          9.07622
trainer/Q2 Predictions Max        123.899
trainer/Q2 Predictions Min         -6.4918
trainer/Q Targets Mean             70.5173
trainer/Q Targets Std               8.33319
trainer/Q Targets Max             120.153
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.11023
trainer/Log Pis Std                 4.15711
trainer/Log Pis Max                22.6869
trainer/Log Pis Min                -7.82522
trainer/Policy mu Mean             -0.153385
trainer/Policy mu Std               1.4659
trainer/Policy mu Max               4.41032
trainer/Policy mu Min              -6.27348
trainer/Policy log std Mean        -0.763243
trainer/Policy log std Std          0.336182
trainer/Policy log std Max          0.0163761
trainer/Policy log std Min         -1.99013
trainer/Alpha                       0.0237445
trainer/Alpha Loss                 -3.32794
exploration/num steps total    136000
exploration/num paths total       740
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00732828
exploration/Rewards Std             0.0122496
exploration/Rewards Max             0.103001
exploration/Rewards Min            -0.118582
exploration/Returns Mean            3.66414
exploration/Returns Std             3.36658
exploration/Returns Max            10.3823
exploration/Returns Min             0.858018
exploration/Actions Mean            0.00118106
exploration/Actions Std             0.502016
exploration/Actions Max             0.997859
exploration/Actions Min            -0.999974
exploration/Num Paths              10
exploration/Average Returns         3.66414
evaluation/num steps total     133622
evaluation/num paths total        714
evaluation/path length Mean       385.5
evaluation/path length Std        198.328
evaluation/path length Max        500
evaluation/path length Min         37
evaluation/Rewards Mean             0.00522498
evaluation/Rewards Std              0.00911571
evaluation/Rewards Max              0.0532035
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             2.01423
evaluation/Returns Std              1.69588
evaluation/Returns Max              5.64477
evaluation/Returns Min             -0.158348
evaluation/ExplReturns Mean         2.01423
evaluation/ExplReturns Std          1.69588
evaluation/ExplReturns Max          5.64477
evaluation/ExplReturns Min         -0.158348
evaluation/Actions Mean            -0.00293516
evaluation/Actions Std              0.360924
evaluation/Actions Max              0.999525
evaluation/Actions Min             -0.999855
evaluation/Num Paths               12
evaluation/Average Returns          2.01423
time/data storing (s)               0.0291437
time/evaluation sampling (s)       68.2124
time/exploration sampling (s)      74.3411
time/logging (s)                    0.0242628
time/saving (s)                     0.0650309
time/training (s)                  10.1565
time/epoch (s)                    152.828
time/total (s)                   4196.37
Epoch                              26
-----------------------------  ---------------
2023-08-31 13:08:35.903880 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 27 finished
-----------------------------  ----------------
replay_buffer/size             141000
trainer/QF1 Loss                    7.32496
trainer/QF2 Loss                    8.00384
trainer/Policy Loss               -64.0405
trainer/Q1 Predictions Mean        69.7086
trainer/Q1 Predictions Std          8.4297
trainer/Q1 Predictions Max         85.3248
trainer/Q1 Predictions Min        -10.5995
trainer/Q2 Predictions Mean        69.561
trainer/Q2 Predictions Std          8.44097
trainer/Q2 Predictions Max         85.7979
trainer/Q2 Predictions Min         -7.52325
trainer/Q Targets Mean             69.9141
trainer/Q Targets Std               8.86958
trainer/Q Targets Max              84.6674
trainer/Q Targets Min              -7.3038
trainer/Log Pis Mean                6.77173
trainer/Log Pis Std                 5.32618
trainer/Log Pis Max                28.5358
trainer/Log Pis Min                -9.14278
trainer/Policy mu Mean             -0.320671
trainer/Policy mu Std               1.62746
trainer/Policy mu Max               5.28964
trainer/Policy mu Min              -6.20164
trainer/Policy log std Mean        -0.760721
trainer/Policy log std Std          0.310234
trainer/Policy log std Max          0.131247
trainer/Policy log std Min         -2.31806
trainer/Alpha                       0.0247394
trainer/Alpha Loss                  2.85509
exploration/num steps total    141000
exploration/num paths total       751
exploration/path length Mean      454.545
exploration/path length Std        96.484
exploration/path length Max       500
exploration/path length Min       242
exploration/Rewards Mean            0.00098713
exploration/Rewards Std             0.00506254
exploration/Rewards Max             0.0385666
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.448696
exploration/Returns Std             0.213044
exploration/Returns Max             0.868903
exploration/Returns Min             0.205096
exploration/Actions Mean           -0.0127302
exploration/Actions Std             0.495613
exploration/Actions Max             0.999637
exploration/Actions Min            -0.999177
exploration/Num Paths              11
exploration/Average Returns         0.448696
evaluation/num steps total     138322
evaluation/num paths total        724
evaluation/path length Mean       470
evaluation/path length Std         90
evaluation/path length Max        500
evaluation/path length Min        200
evaluation/Rewards Mean             0.000834804
evaluation/Rewards Std              0.00527358
evaluation/Rewards Max              0.0431379
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.392358
evaluation/Returns Std              0.161424
evaluation/Returns Max              0.609512
evaluation/Returns Min              0.0277911
evaluation/ExplReturns Mean         0.392358
evaluation/ExplReturns Std          0.161424
evaluation/ExplReturns Max          0.609512
evaluation/ExplReturns Min          0.0277911
evaluation/Actions Mean            -0.000798238
evaluation/Actions Std              0.203892
evaluation/Actions Max              0.996007
evaluation/Actions Min             -0.999981
evaluation/Num Paths               10
evaluation/Average Returns          0.392358
time/data storing (s)               0.0288879
time/evaluation sampling (s)       68.549
time/exploration sampling (s)      74.6381
time/logging (s)                    0.0243967
time/saving (s)                     0.0671609
time/training (s)                  13.4008
time/epoch (s)                    156.708
time/total (s)                   4353.08
Epoch                              27
-----------------------------  ----------------
2023-08-31 13:11:09.417434 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 28 finished
-----------------------------  ----------------
replay_buffer/size             146000
trainer/QF1 Loss                    9.12226
trainer/QF2 Loss                    8.52172
trainer/Policy Loss               -65.5504
trainer/Q1 Predictions Mean        70.3456
trainer/Q1 Predictions Std          8.10746
trainer/Q1 Predictions Max         92.555
trainer/Q1 Predictions Min         32.1629
trainer/Q2 Predictions Mean        70.4138
trainer/Q2 Predictions Std          7.99049
trainer/Q2 Predictions Max         92.2925
trainer/Q2 Predictions Min         35.8765
trainer/Q Targets Mean             70.4525
trainer/Q Targets Std               8.4609
trainer/Q Targets Max              88.9751
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.93248
trainer/Log Pis Std                 4.78349
trainer/Log Pis Max                27.3128
trainer/Log Pis Min                -3.55213
trainer/Policy mu Mean             -0.176179
trainer/Policy mu Std               1.5628
trainer/Policy mu Max               4.86256
trainer/Policy mu Min              -5.00379
trainer/Policy log std Mean        -0.758243
trainer/Policy log std Std          0.32312
trainer/Policy log std Max         -0.0353664
trainer/Policy log std Min         -1.9488
trainer/Alpha                       0.0256676
trainer/Alpha Loss                 -0.247326
exploration/num steps total    146000
exploration/num paths total       762
exploration/path length Mean      454.545
exploration/path length Std       130.722
exploration/path length Max       500
exploration/path length Min        43
exploration/Rewards Mean            0.00488723
exploration/Rewards Std             0.00530259
exploration/Rewards Max             0.0282756
exploration/Rewards Min            -0.281611
exploration/Returns Mean            2.22147
exploration/Returns Std             1.04254
exploration/Returns Max             3.54865
exploration/Returns Min            -0.0165261
exploration/Actions Mean            0.0037423
exploration/Actions Std             0.497597
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999999
exploration/Num Paths              11
exploration/Average Returns         2.22147
evaluation/num steps total     143322
evaluation/num paths total        734
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00291202
evaluation/Rewards Std              0.0029365
evaluation/Rewards Max              0.0270292
evaluation/Rewards Min              0.000828745
evaluation/Returns Mean             1.45601
evaluation/Returns Std              0.787223
evaluation/Returns Max              2.8603
evaluation/Returns Min              0.611921
evaluation/ExplReturns Mean         1.45601
evaluation/ExplReturns Std          0.787223
evaluation/ExplReturns Max          2.8603
evaluation/ExplReturns Min          0.611921
evaluation/Actions Mean             0.00323061
evaluation/Actions Std              0.292128
evaluation/Actions Max              0.996431
evaluation/Actions Min             -0.999568
evaluation/Num Paths               10
evaluation/Average Returns          1.45601
time/data storing (s)               0.0287989
time/evaluation sampling (s)       68.5817
time/exploration sampling (s)      74.4291
time/logging (s)                    0.0257719
time/saving (s)                     0.0684847
time/training (s)                  10.3775
time/epoch (s)                    153.511
time/total (s)                   4506.6
Epoch                              28
-----------------------------  ----------------
2023-08-31 13:13:45.870533 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 29 finished
-----------------------------  ----------------
replay_buffer/size             151000
trainer/QF1 Loss                    1.64865
trainer/QF2 Loss                    1.627
trainer/Policy Loss               -66.4516
trainer/Q1 Predictions Mean        70.9779
trainer/Q1 Predictions Std          9.06406
trainer/Q1 Predictions Max         88.026
trainer/Q1 Predictions Min          3.58161
trainer/Q2 Predictions Mean        70.944
trainer/Q2 Predictions Std          9.19929
trainer/Q2 Predictions Max         89.6959
trainer/Q2 Predictions Min          3.55432
trainer/Q Targets Mean             70.8128
trainer/Q Targets Std               8.8699
trainer/Q Targets Max              90.727
trainer/Q Targets Min               4.3951
trainer/Log Pis Mean                5.45022
trainer/Log Pis Std                 3.93809
trainer/Log Pis Max                21.585
trainer/Log Pis Min                -4.12678
trainer/Policy mu Mean              0.0757629
trainer/Policy mu Std               1.4592
trainer/Policy mu Max               4.12797
trainer/Policy mu Min              -3.55723
trainer/Policy log std Mean        -0.790859
trainer/Policy log std Std          0.321842
trainer/Policy log std Max         -0.174426
trainer/Policy log std Min         -2.06316
trainer/Alpha                       0.0254046
trainer/Alpha Loss                 -2.01914
exploration/num steps total    151000
exploration/num paths total       772
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00383144
exploration/Rewards Std             0.00383692
exploration/Rewards Max             0.0396666
exploration/Rewards Min             0.000379401
exploration/Returns Mean            1.91572
exploration/Returns Std             0.75626
exploration/Returns Max             3.17338
exploration/Returns Min             0.550933
exploration/Actions Mean            0.00248654
exploration/Actions Std             0.49763
exploration/Actions Max             0.998938
exploration/Actions Min            -0.999313
exploration/Num Paths              10
exploration/Average Returns         1.91572
evaluation/num steps total     148322
evaluation/num paths total        744
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0026481
evaluation/Rewards Std              0.00325251
evaluation/Rewards Max              0.035622
evaluation/Rewards Min              0.000707849
evaluation/Returns Mean             1.32405
evaluation/Returns Std              0.730151
evaluation/Returns Max              2.91571
evaluation/Returns Min              0.553109
evaluation/ExplReturns Mean         1.32405
evaluation/ExplReturns Std          0.730151
evaluation/ExplReturns Max          2.91571
evaluation/ExplReturns Min          0.553109
evaluation/Actions Mean            -0.0164961
evaluation/Actions Std              0.335451
evaluation/Actions Max              0.984294
evaluation/Actions Min             -0.992282
evaluation/Num Paths               10
evaluation/Average Returns          1.32405
time/data storing (s)               0.0286834
time/evaluation sampling (s)       68.5108
time/exploration sampling (s)      74.3838
time/logging (s)                    0.0250674
time/saving (s)                     0.0620568
time/training (s)                  13.4385
time/epoch (s)                    156.449
time/total (s)                   4663.05
Epoch                              29
-----------------------------  ----------------
2023-08-31 13:16:21.183624 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 30 finished
-----------------------------  ---------------
replay_buffer/size             156000
trainer/QF1 Loss                    3.3457
trainer/QF2 Loss                    3.45811
trainer/Policy Loss               -65.6895
trainer/Q1 Predictions Mean        71.0467
trainer/Q1 Predictions Std          7.94629
trainer/Q1 Predictions Max         89.3591
trainer/Q1 Predictions Min         17.9641
trainer/Q2 Predictions Mean        71.2147
trainer/Q2 Predictions Std          8.02455
trainer/Q2 Predictions Max         89.2922
trainer/Q2 Predictions Min         15.3814
trainer/Q Targets Mean             70.3925
trainer/Q Targets Std               8.47967
trainer/Q Targets Max              87.3984
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.67818
trainer/Log Pis Std                 5.17224
trainer/Log Pis Max                33.127
trainer/Log Pis Min                -3.21865
trainer/Policy mu Mean             -0.0549312
trainer/Policy mu Std               1.61854
trainer/Policy mu Max               6.25609
trainer/Policy mu Min              -4.47727
trainer/Policy log std Mean        -0.806336
trainer/Policy log std Std          0.353515
trainer/Policy log std Max          0.213395
trainer/Policy log std Min         -2.2904
trainer/Alpha                       0.0241222
trainer/Alpha Loss                  2.52607
exploration/num steps total    156000
exploration/num paths total       782
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00966177
exploration/Rewards Std             0.00644721
exploration/Rewards Max             0.0438484
exploration/Rewards Min             0.00155824
exploration/Returns Mean            4.83088
exploration/Returns Std             2.87245
exploration/Returns Max            10.5692
exploration/Returns Min             1.71706
exploration/Actions Mean            0.00977497
exploration/Actions Std             0.51944
exploration/Actions Max             0.996191
exploration/Actions Min            -0.997961
exploration/Num Paths              10
exploration/Average Returns         4.83088
evaluation/num steps total     153322
evaluation/num paths total        754
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0119587
evaluation/Rewards Std              0.00509115
evaluation/Rewards Max              0.0385722
evaluation/Rewards Min              0.0016027
evaluation/Returns Mean             5.97933
evaluation/Returns Std              2.37149
evaluation/Returns Max              9.28134
evaluation/Returns Min              1.61381
evaluation/ExplReturns Mean         5.97933
evaluation/ExplReturns Std          2.37149
evaluation/ExplReturns Max          9.28134
evaluation/ExplReturns Min          1.61381
evaluation/Actions Mean             0.00150181
evaluation/Actions Std              0.383641
evaluation/Actions Max              0.983149
evaluation/Actions Min             -0.974461
evaluation/Num Paths               10
evaluation/Average Returns          5.97933
time/data storing (s)               0.0285095
time/evaluation sampling (s)       68.7442
time/exploration sampling (s)      74.8049
time/logging (s)                    0.0251168
time/saving (s)                     0.077595
time/training (s)                  11.6292
time/epoch (s)                    155.31
time/total (s)                   4818.36
Epoch                              30
-----------------------------  ---------------
2023-08-31 13:18:53.917915 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 31 finished
-----------------------------  ---------------
replay_buffer/size             161000
trainer/QF1 Loss                    7.09881
trainer/QF2 Loss                    8.2918
trainer/Policy Loss               -67.2983
trainer/Q1 Predictions Mean        71.6195
trainer/Q1 Predictions Std          6.58084
trainer/Q1 Predictions Max         87.8877
trainer/Q1 Predictions Min         36.5643
trainer/Q2 Predictions Mean        71.7164
trainer/Q2 Predictions Std          6.38706
trainer/Q2 Predictions Max         87.989
trainer/Q2 Predictions Min         39.1083
trainer/Q Targets Mean             71.2368
trainer/Q Targets Std               7.18476
trainer/Q Targets Max              87.6104
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.49501
trainer/Log Pis Std                 4.14818
trainer/Log Pis Max                25.818
trainer/Log Pis Min                -3.67788
trainer/Policy mu Mean              0.0788477
trainer/Policy mu Std               1.46345
trainer/Policy mu Max               4.0838
trainer/Policy mu Min              -5.04759
trainer/Policy log std Mean        -0.83407
trainer/Policy log std Std          0.350475
trainer/Policy log std Max          0.109451
trainer/Policy log std Min         -2.30834
trainer/Alpha                       0.0232413
trainer/Alpha Loss                 -1.89965
exploration/num steps total    161000
exploration/num paths total       792
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0117806
exploration/Rewards Std             0.0039325
exploration/Rewards Max             0.0386018
exploration/Rewards Min             0.00197874
exploration/Returns Mean            5.89032
exploration/Returns Std             1.31673
exploration/Returns Max             7.80654
exploration/Returns Min             3.16503
exploration/Actions Mean            0.0168469
exploration/Actions Std             0.490535
exploration/Actions Max             0.999185
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns         5.89032
evaluation/num steps total     158322
evaluation/num paths total        764
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0109869
evaluation/Rewards Std              0.00289646
evaluation/Rewards Max              0.041378
evaluation/Rewards Min              0.00153189
evaluation/Returns Mean             5.49343
evaluation/Returns Std              1.15677
evaluation/Returns Max              7.01951
evaluation/Returns Min              3.34355
evaluation/ExplReturns Mean         5.49343
evaluation/ExplReturns Std          1.15677
evaluation/ExplReturns Max          7.01951
evaluation/ExplReturns Min          3.34355
evaluation/Actions Mean             0.00658776
evaluation/Actions Std              0.273536
evaluation/Actions Max              0.987104
evaluation/Actions Min             -0.999471
evaluation/Num Paths               10
evaluation/Average Returns          5.49343
time/data storing (s)               0.0289993
time/evaluation sampling (s)       68.1255
time/exploration sampling (s)      73.7518
time/logging (s)                    0.0253489
time/saving (s)                     0.071653
time/training (s)                  10.7277
time/epoch (s)                    152.731
time/total (s)                   4971.09
Epoch                              31
-----------------------------  ---------------
2023-08-31 13:21:26.730184 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 32 finished
-----------------------------  ----------------
replay_buffer/size             166000
trainer/QF1 Loss                   12.4794
trainer/QF2 Loss                   14.2978
trainer/Policy Loss               -65.6316
trainer/Q1 Predictions Mean        69.8513
trainer/Q1 Predictions Std          6.88761
trainer/Q1 Predictions Max         87.6237
trainer/Q1 Predictions Min         25.3802
trainer/Q2 Predictions Mean        70.2977
trainer/Q2 Predictions Std          6.84423
trainer/Q2 Predictions Max         88.9349
trainer/Q2 Predictions Min         25.0505
trainer/Q Targets Mean             70.175
trainer/Q Targets Std               7.88402
trainer/Q Targets Max              88.5478
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.28143
trainer/Log Pis Std                 4.879
trainer/Log Pis Max                29.9972
trainer/Log Pis Min                -4.60844
trainer/Policy mu Mean              0.0337458
trainer/Policy mu Std               1.48643
trainer/Policy mu Max               4.5938
trainer/Policy mu Min              -4.52868
trainer/Policy log std Mean        -0.833989
trainer/Policy log std Std          0.37165
trainer/Policy log std Max         -0.0159554
trainer/Policy log std Min         -2.28811
trainer/Alpha                       0.0231883
trainer/Alpha Loss                 -2.70459
exploration/num steps total    166000
exploration/num paths total       802
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0229274
exploration/Rewards Std             0.00769109
exploration/Rewards Max             0.0451349
exploration/Rewards Min             0.0063093
exploration/Returns Mean           11.4637
exploration/Returns Std             3.07209
exploration/Returns Max            15.3638
exploration/Returns Min             5.94454
exploration/Actions Mean            0.0244012
exploration/Actions Std             0.513557
exploration/Actions Max             0.995943
exploration/Actions Min            -0.998485
exploration/Num Paths              10
exploration/Average Returns        11.4637
evaluation/num steps total     163322
evaluation/num paths total        774
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0184651
evaluation/Rewards Std              0.00786672
evaluation/Rewards Max              0.0389319
evaluation/Rewards Min              0.00464548
evaluation/Returns Mean             9.23253
evaluation/Returns Std              3.56061
evaluation/Returns Max             16.0137
evaluation/Returns Min              4.1635
evaluation/ExplReturns Mean         9.23253
evaluation/ExplReturns Std          3.56061
evaluation/ExplReturns Max         16.0137
evaluation/ExplReturns Min          4.1635
evaluation/Actions Mean             0.000614991
evaluation/Actions Std              0.373047
evaluation/Actions Max              0.98058
evaluation/Actions Min             -0.995742
evaluation/Num Paths               10
evaluation/Average Returns          9.23253
time/data storing (s)               0.0290239
time/evaluation sampling (s)       68.4705
time/exploration sampling (s)      74.1875
time/logging (s)                    0.0250151
time/saving (s)                     0.0628604
time/training (s)                  10.0334
time/epoch (s)                    152.808
time/total (s)                   5123.91
Epoch                              32
-----------------------------  ----------------
2023-08-31 13:24:00.441866 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 33 finished
-----------------------------  ---------------
replay_buffer/size             171000
trainer/QF1 Loss                    1.97649
trainer/QF2 Loss                    1.86383
trainer/Policy Loss               -65.4869
trainer/Q1 Predictions Mean        69.8797
trainer/Q1 Predictions Std          8.36585
trainer/Q1 Predictions Max         91.0644
trainer/Q1 Predictions Min          3.90903
trainer/Q2 Predictions Mean        69.889
trainer/Q2 Predictions Std          8.2871
trainer/Q2 Predictions Max         89.8016
trainer/Q2 Predictions Min          6.14076
trainer/Q Targets Mean             70.172
trainer/Q Targets Std               7.97257
trainer/Q Targets Max              90.781
trainer/Q Targets Min               7.3375
trainer/Log Pis Mean                5.33702
trainer/Log Pis Std                 4.55292
trainer/Log Pis Max                24.6107
trainer/Log Pis Min                -3.15903
trainer/Policy mu Mean              0.0930608
trainer/Policy mu Std               1.46056
trainer/Policy mu Max               4.3324
trainer/Policy mu Min              -7.25171
trainer/Policy log std Mean        -0.802655
trainer/Policy log std Std          0.33454
trainer/Policy log std Max          0.587373
trainer/Policy log std Min         -2.12473
trainer/Alpha                       0.023231
trainer/Alpha Loss                 -2.49408
exploration/num steps total    171000
exploration/num paths total       812
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0132271
exploration/Rewards Std             0.00436955
exploration/Rewards Max             0.0422584
exploration/Rewards Min             0.00177207
exploration/Returns Mean            6.61355
exploration/Returns Std             1.25007
exploration/Returns Max             8.8333
exploration/Returns Min             5.08546
exploration/Actions Mean            0.00968979
exploration/Actions Std             0.518445
exploration/Actions Max             0.99844
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns         6.61355
evaluation/num steps total     168322
evaluation/num paths total        784
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0146879
evaluation/Rewards Std              0.00461252
evaluation/Rewards Max              0.0459903
evaluation/Rewards Min              0.00720535
evaluation/Returns Mean             7.34396
evaluation/Returns Std              1.61037
evaluation/Returns Max              9.30563
evaluation/Returns Min              4.36453
evaluation/ExplReturns Mean         7.34396
evaluation/ExplReturns Std          1.61037
evaluation/ExplReturns Max          9.30563
evaluation/ExplReturns Min          4.36453
evaluation/Actions Mean             0.0134767
evaluation/Actions Std              0.302542
evaluation/Actions Max              0.993697
evaluation/Actions Min             -0.999235
evaluation/Num Paths               10
evaluation/Average Returns          7.34396
time/data storing (s)               0.0290164
time/evaluation sampling (s)       68.5293
time/exploration sampling (s)      75.0336
time/logging (s)                    0.0250881
time/saving (s)                     0.0493507
time/training (s)                  10.0418
time/epoch (s)                    153.708
time/total (s)                   5277.62
Epoch                              33
-----------------------------  ---------------
2023-08-31 13:26:35.872021 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 34 finished
-----------------------------  ----------------
replay_buffer/size             176000
trainer/QF1 Loss                    3.61212
trainer/QF2 Loss                    3.49577
trainer/Policy Loss               -64.9459
trainer/Q1 Predictions Mean        69.3388
trainer/Q1 Predictions Std          7.77694
trainer/Q1 Predictions Max         85.8381
trainer/Q1 Predictions Min         19.9625
trainer/Q2 Predictions Mean        69.5723
trainer/Q2 Predictions Std          7.73477
trainer/Q2 Predictions Max         87.7874
trainer/Q2 Predictions Min         20.0756
trainer/Q Targets Mean             69.0503
trainer/Q Targets Std               8.28277
trainer/Q Targets Max              86.2753
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.53717
trainer/Log Pis Std                 4.70223
trainer/Log Pis Max                31.1179
trainer/Log Pis Min                -3.39516
trainer/Policy mu Mean              0.075855
trainer/Policy mu Std               1.49212
trainer/Policy mu Max               6.1927
trainer/Policy mu Min              -4.23655
trainer/Policy log std Mean        -0.810418
trainer/Policy log std Std          0.358038
trainer/Policy log std Max          0.245278
trainer/Policy log std Min         -2.34798
trainer/Alpha                       0.0225219
trainer/Alpha Loss                 -1.7556
exploration/num steps total    176000
exploration/num paths total       823
exploration/path length Mean      454.545
exploration/path length Std       130.148
exploration/path length Max       500
exploration/path length Min        45
exploration/Rewards Mean            0.0203151
exploration/Rewards Std             0.0124133
exploration/Rewards Max             0.0613153
exploration/Rewards Min            -0.281611
exploration/Returns Mean            9.23412
exploration/Returns Std             5.83973
exploration/Returns Max            15.974
exploration/Returns Min             0.0534721
exploration/Actions Mean            0.0103482
exploration/Actions Std             0.559324
exploration/Actions Max             0.999736
exploration/Actions Min            -0.99994
exploration/Num Paths              11
exploration/Average Returns         9.23412
evaluation/num steps total     173322
evaluation/num paths total        794
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0180924
evaluation/Rewards Std              0.00756541
evaluation/Rewards Max              0.0355738
evaluation/Rewards Min              0.000568968
evaluation/Returns Mean             9.04619
evaluation/Returns Std              3.59492
evaluation/Returns Max             13.0885
evaluation/Returns Min              3.2227
evaluation/ExplReturns Mean         9.04619
evaluation/ExplReturns Std          3.59492
evaluation/ExplReturns Max         13.0885
evaluation/ExplReturns Min          3.2227
evaluation/Actions Mean             0.00564451
evaluation/Actions Std              0.366663
evaluation/Actions Max              0.983587
evaluation/Actions Min             -0.997038
evaluation/Num Paths               10
evaluation/Average Returns          9.04619
time/data storing (s)               0.0287359
time/evaluation sampling (s)       69.229
time/exploration sampling (s)      74.8239
time/logging (s)                    0.0253382
time/saving (s)                     0.0684064
time/training (s)                  11.2514
time/epoch (s)                    155.427
time/total (s)                   5433.05
Epoch                              34
-----------------------------  ----------------
2023-08-31 13:29:07.145201 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 35 finished
-----------------------------  ---------------
replay_buffer/size             181000
trainer/QF1 Loss                    1.72754
trainer/QF2 Loss                    2.99591
trainer/Policy Loss               -65.1005
trainer/Q1 Predictions Mean        70.4507
trainer/Q1 Predictions Std          7.71138
trainer/Q1 Predictions Max         93.3193
trainer/Q1 Predictions Min         21.0084
trainer/Q2 Predictions Mean        70.2792
trainer/Q2 Predictions Std          7.84518
trainer/Q2 Predictions Max         91.8109
trainer/Q2 Predictions Min         18.1002
trainer/Q Targets Mean             70.3069
trainer/Q Targets Std               7.53826
trainer/Q Targets Max              90.7445
trainer/Q Targets Min              29.4333
trainer/Log Pis Mean                6.1051
trainer/Log Pis Std                 4.65971
trainer/Log Pis Max                32.4421
trainer/Log Pis Min                -5.60715
trainer/Policy mu Mean              0.283208
trainer/Policy mu Std               1.53077
trainer/Policy mu Max               5.40508
trainer/Policy mu Min              -4.36482
trainer/Policy log std Mean        -0.797405
trainer/Policy log std Std          0.337703
trainer/Policy log std Max         -0.0944627
trainer/Policy log std Min         -2.17308
trainer/Alpha                       0.0214125
trainer/Alpha Loss                  0.403984
exploration/num steps total    181000
exploration/num paths total       835
exploration/path length Mean      416.667
exploration/path length Std       157.129
exploration/path length Max       500
exploration/path length Min        70
exploration/Rewards Mean            0.00348286
exploration/Rewards Std             0.0108337
exploration/Rewards Max             0.0559865
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.45119
exploration/Returns Std             0.748217
exploration/Returns Max             2.76756
exploration/Returns Min            -0.0853944
exploration/Actions Mean           -0.0182914
exploration/Actions Std             0.496366
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999813
exploration/Num Paths              12
exploration/Average Returns         1.45119
evaluation/num steps total     178012
evaluation/num paths total        806
evaluation/path length Mean       390.833
evaluation/path length Std        189.108
evaluation/path length Max        500
evaluation/path length Min         55
evaluation/Rewards Mean             0.00852002
evaluation/Rewards Std              0.0186729
evaluation/Rewards Max              0.08606
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             3.32991
evaluation/Returns Std              6.53327
evaluation/Returns Max             24.5541
evaluation/Returns Min              0.449268
evaluation/ExplReturns Mean         3.32991
evaluation/ExplReturns Std          6.53327
evaluation/ExplReturns Max         24.5541
evaluation/ExplReturns Min          0.449268
evaluation/Actions Mean            -0.0039696
evaluation/Actions Std              0.322986
evaluation/Actions Max              0.998639
evaluation/Actions Min             -0.999316
evaluation/Num Paths               12
evaluation/Average Returns          3.32991
time/data storing (s)               0.0290551
time/evaluation sampling (s)       68.0597
time/exploration sampling (s)      72.9705
time/logging (s)                    0.0243133
time/saving (s)                     0.0707601
time/training (s)                  10.1142
time/epoch (s)                    151.269
time/total (s)                   5584.32
Epoch                              35
-----------------------------  ---------------
2023-08-31 13:31:40.524921 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 36 finished
-----------------------------  ----------------
replay_buffer/size             186000
trainer/QF1 Loss                    5.81843
trainer/QF2 Loss                    5.92158
trainer/Policy Loss               -63.4935
trainer/Q1 Predictions Mean        68.7833
trainer/Q1 Predictions Std          9.08597
trainer/Q1 Predictions Max         90.8312
trainer/Q1 Predictions Min         28.2074
trainer/Q2 Predictions Mean        68.5401
trainer/Q2 Predictions Std          9.13828
trainer/Q2 Predictions Max         91.258
trainer/Q2 Predictions Min         22.5903
trainer/Q Targets Mean             68.9221
trainer/Q Targets Std               9.66804
trainer/Q Targets Max              91.2103
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.03886
trainer/Log Pis Std                 4.57022
trainer/Log Pis Max                26.2356
trainer/Log Pis Min                -6.56222
trainer/Policy mu Mean              0.144122
trainer/Policy mu Std               1.52362
trainer/Policy mu Max               5.51723
trainer/Policy mu Min              -4.93903
trainer/Policy log std Mean        -0.77473
trainer/Policy log std Std          0.332862
trainer/Policy log std Max          0.163001
trainer/Policy log std Min         -1.96132
trainer/Alpha                       0.0209697
trainer/Alpha Loss                  0.150164
exploration/num steps total    186000
exploration/num paths total       846
exploration/path length Mean      454.545
exploration/path length Std       127.045
exploration/path length Max       500
exploration/path length Min        56
exploration/Rewards Mean            0.000808126
exploration/Rewards Std             0.00549498
exploration/Rewards Max             0.0446198
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.36733
exploration/Returns Std             0.130073
exploration/Returns Max             0.633133
exploration/Returns Min             0.183778
exploration/Actions Mean           -0.000258891
exploration/Actions Std             0.490586
exploration/Actions Max             0.999671
exploration/Actions Min            -0.99936
exploration/Num Paths              11
exploration/Average Returns         0.36733
evaluation/num steps total     182933
evaluation/num paths total        816
evaluation/path length Mean       492.1
evaluation/path length Std         20.8732
evaluation/path length Max        500
evaluation/path length Min        430
evaluation/Rewards Mean             0.000566229
evaluation/Rewards Std              0.00635997
evaluation/Rewards Max              0.0363333
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.278641
evaluation/Returns Std              0.0977758
evaluation/Returns Max              0.446897
evaluation/Returns Min              0.11452
evaluation/ExplReturns Mean         0.278641
evaluation/ExplReturns Std          0.0977758
evaluation/ExplReturns Max          0.446897
evaluation/ExplReturns Min          0.11452
evaluation/Actions Mean             0.00468589
evaluation/Actions Std              0.407444
evaluation/Actions Max              0.990737
evaluation/Actions Min             -0.978758
evaluation/Num Paths               10
evaluation/Average Returns          0.278641
time/data storing (s)               0.0290738
time/evaluation sampling (s)       68.6412
time/exploration sampling (s)      74.3748
time/logging (s)                    0.024861
time/saving (s)                     0.0674318
time/training (s)                  10.2393
time/epoch (s)                    153.377
time/total (s)                   5737.7
Epoch                              36
-----------------------------  ----------------
2023-08-31 13:34:15.411210 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 37 finished
-----------------------------  ---------------
replay_buffer/size             191000
trainer/QF1 Loss                    5.76367
trainer/QF2 Loss                    5.99908
trainer/Policy Loss               -64.2392
trainer/Q1 Predictions Mean        69.8897
trainer/Q1 Predictions Std         10.4308
trainer/Q1 Predictions Max        103.487
trainer/Q1 Predictions Min         28.1687
trainer/Q2 Predictions Mean        69.6365
trainer/Q2 Predictions Std         10.6527
trainer/Q2 Predictions Max        102.598
trainer/Q2 Predictions Min         25.0215
trainer/Q Targets Mean             70.3841
trainer/Q Targets Std               9.78031
trainer/Q Targets Max             101.633
trainer/Q Targets Min              44.6998
trainer/Log Pis Mean                6.6761
trainer/Log Pis Std                 5.5132
trainer/Log Pis Max                33.2531
trainer/Log Pis Min                -3.68575
trainer/Policy mu Mean             -0.156688
trainer/Policy mu Std               1.65514
trainer/Policy mu Max               5.07977
trainer/Policy mu Min              -4.67436
trainer/Policy log std Mean        -0.700021
trainer/Policy log std Std          0.347489
trainer/Policy log std Max          0.409823
trainer/Policy log std Min         -2.04389
trainer/Alpha                       0.0225417
trainer/Alpha Loss                  2.56407
exploration/num steps total    191000
exploration/num paths total       868
exploration/path length Mean      227.273
exploration/path length Std        45.3954
exploration/path length Max       303
exploration/path length Min       153
exploration/Rewards Mean            0.00227282
exploration/Rewards Std             0.0195482
exploration/Rewards Max             0.0393703
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.516551
exploration/Returns Std             0.144017
exploration/Returns Max             0.770486
exploration/Returns Min             0.242639
exploration/Actions Mean           -0.0910401
exploration/Actions Std             0.54857
exploration/Actions Max             0.999965
exploration/Actions Min            -0.998806
exploration/Num Paths              22
exploration/Average Returns         0.516551
evaluation/num steps total     187732
evaluation/num paths total        836
evaluation/path length Mean       239.95
evaluation/path length Std         39.2179
evaluation/path length Max        298
evaluation/path length Min        146
evaluation/Rewards Mean             0.00192684
evaluation/Rewards Std              0.0193478
evaluation/Rewards Max              0.041955
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.462345
evaluation/Returns Std              0.161654
evaluation/Returns Max              0.665487
evaluation/Returns Min              0.0954292
evaluation/ExplReturns Mean         0.462345
evaluation/ExplReturns Std          0.161654
evaluation/ExplReturns Max          0.665487
evaluation/ExplReturns Min          0.0954292
evaluation/Actions Mean            -0.101701
evaluation/Actions Std              0.473478
evaluation/Actions Max              0.999982
evaluation/Actions Min             -0.996006
evaluation/Num Paths               20
evaluation/Average Returns          0.462345
time/data storing (s)               0.0287934
time/evaluation sampling (s)       69.2723
time/exploration sampling (s)      75.1147
time/logging (s)                    0.0244837
time/saving (s)                     0.0682238
time/training (s)                  10.3738
time/epoch (s)                    154.882
time/total (s)                   5892.58
Epoch                              37
-----------------------------  ---------------
2023-08-31 13:36:48.395204 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 38 finished
-----------------------------  ----------------
replay_buffer/size             196000
trainer/QF1 Loss                    3.03407
trainer/QF2 Loss                    3.57261
trainer/Policy Loss               -64.3351
trainer/Q1 Predictions Mean        69.1265
trainer/Q1 Predictions Std          9.30707
trainer/Q1 Predictions Max        102.518
trainer/Q1 Predictions Min         17.8797
trainer/Q2 Predictions Mean        69.1492
trainer/Q2 Predictions Std          9.35097
trainer/Q2 Predictions Max        104.155
trainer/Q2 Predictions Min         17.3623
trainer/Q Targets Mean             69.0942
trainer/Q Targets Std               9.75826
trainer/Q Targets Max             104.695
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.7405
trainer/Log Pis Std                 4.81564
trainer/Log Pis Max                27.3917
trainer/Log Pis Min                -3.70514
trainer/Policy mu Mean              0.0526191
trainer/Policy mu Std               1.55074
trainer/Policy mu Max               4.94015
trainer/Policy mu Min              -5.90276
trainer/Policy log std Mean        -0.740283
trainer/Policy log std Std          0.347405
trainer/Policy log std Max          0.103409
trainer/Policy log std Min         -2.20944
trainer/Alpha                       0.0219134
trainer/Alpha Loss                 -0.991403
exploration/num steps total    196000
exploration/num paths total       878
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00173813
exploration/Rewards Std             0.00394646
exploration/Rewards Max             0.0349599
exploration/Rewards Min             3.54065e-05
exploration/Returns Mean            0.869066
exploration/Returns Std             0.232194
exploration/Returns Max             1.41236
exploration/Returns Min             0.581288
exploration/Actions Mean           -0.0104095
exploration/Actions Std             0.562868
exploration/Actions Max             0.999304
exploration/Actions Min            -0.999187
exploration/Num Paths              10
exploration/Average Returns         0.869066
evaluation/num steps total     192732
evaluation/num paths total        846
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00190708
evaluation/Rewards Std              0.00460144
evaluation/Rewards Max              0.0425208
evaluation/Rewards Min              0.000258932
evaluation/Returns Mean             0.953539
evaluation/Returns Std              0.182885
evaluation/Returns Max              1.20846
evaluation/Returns Min              0.724488
evaluation/ExplReturns Mean         0.953539
evaluation/ExplReturns Std          0.182885
evaluation/ExplReturns Max          1.20846
evaluation/ExplReturns Min          0.724488
evaluation/Actions Mean             0.00770203
evaluation/Actions Std              0.338385
evaluation/Actions Max              0.987736
evaluation/Actions Min             -0.982991
evaluation/Num Paths               10
evaluation/Average Returns          0.953539
time/data storing (s)               0.0294272
time/evaluation sampling (s)       68.8412
time/exploration sampling (s)      73.9907
time/logging (s)                    0.0251429
time/saving (s)                     0.0684074
time/training (s)                  10.0261
time/epoch (s)                    152.981
time/total (s)                   6045.57
Epoch                              38
-----------------------------  ----------------
2023-08-31 13:39:20.306653 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 39 finished
-----------------------------  ----------------
replay_buffer/size             201000
trainer/QF1 Loss                    5.28874
trainer/QF2 Loss                    4.65877
trainer/Policy Loss               -62.9582
trainer/Q1 Predictions Mean        67.6602
trainer/Q1 Predictions Std          8.56084
trainer/Q1 Predictions Max         96.4033
trainer/Q1 Predictions Min         31.7546
trainer/Q2 Predictions Mean        67.6001
trainer/Q2 Predictions Std          8.74762
trainer/Q2 Predictions Max         96.5207
trainer/Q2 Predictions Min         30.1208
trainer/Q Targets Mean             67.6353
trainer/Q Targets Std               9.15661
trainer/Q Targets Max              95.4786
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.44812
trainer/Log Pis Std                 3.95026
trainer/Log Pis Max                20.3149
trainer/Log Pis Min                -4.62119
trainer/Policy mu Mean              0.0553223
trainer/Policy mu Std               1.52505
trainer/Policy mu Max               4.77786
trainer/Policy mu Min              -3.83065
trainer/Policy log std Mean        -0.745975
trainer/Policy log std Std          0.331053
trainer/Policy log std Max          0.109189
trainer/Policy log std Min         -2.00825
trainer/Alpha                       0.0232321
trainer/Alpha Loss                 -2.07634
exploration/num steps total    201000
exploration/num paths total       888
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00238368
exploration/Rewards Std             0.00476226
exploration/Rewards Max             0.0375037
exploration/Rewards Min             9.52183e-06
exploration/Returns Mean            1.19184
exploration/Returns Std             0.685812
exploration/Returns Max             2.43711
exploration/Returns Min             0.49646
exploration/Actions Mean           -0.027634
exploration/Actions Std             0.492996
exploration/Actions Max             0.998892
exploration/Actions Min            -0.998021
exploration/Num Paths              10
exploration/Average Returns         1.19184
evaluation/num steps total     197732
evaluation/num paths total        856
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00243319
evaluation/Rewards Std              0.00510014
evaluation/Rewards Max              0.0418281
evaluation/Rewards Min              6.45657e-05
evaluation/Returns Mean             1.2166
evaluation/Returns Std              0.683348
evaluation/Returns Max              2.66153
evaluation/Returns Min              0.565627
evaluation/ExplReturns Mean         1.2166
evaluation/ExplReturns Std          0.683348
evaluation/ExplReturns Max          2.66153
evaluation/ExplReturns Min          0.565627
evaluation/Actions Mean            -0.0124495
evaluation/Actions Std              0.295286
evaluation/Actions Max              0.991206
evaluation/Actions Min             -0.979555
evaluation/Num Paths               10
evaluation/Average Returns          1.2166
time/data storing (s)               0.0289352
time/evaluation sampling (s)       68.118
time/exploration sampling (s)      73.5469
time/logging (s)                    0.0253893
time/saving (s)                     0.0701325
time/training (s)                  10.1188
time/epoch (s)                    151.908
time/total (s)                   6197.48
Epoch                              39
-----------------------------  ----------------
2023-08-31 13:41:53.399798 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 40 finished
-----------------------------  ---------------
replay_buffer/size             206000
trainer/QF1 Loss                    5.69159
trainer/QF2 Loss                    6.40729
trainer/Policy Loss               -62.9029
trainer/Q1 Predictions Mean        68.7938
trainer/Q1 Predictions Std          9.78565
trainer/Q1 Predictions Max         89.3016
trainer/Q1 Predictions Min         -0.541274
trainer/Q2 Predictions Mean        68.1563
trainer/Q2 Predictions Std          9.39796
trainer/Q2 Predictions Max         89.0938
trainer/Q2 Predictions Min          7.62556
trainer/Q Targets Mean             68.9386
trainer/Q Targets Std              10.119
trainer/Q Targets Max              90.208
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.44472
trainer/Log Pis Std                 5.38178
trainer/Log Pis Max                23.1292
trainer/Log Pis Min                -3.57125
trainer/Policy mu Mean              0.169436
trainer/Policy mu Std               1.62435
trainer/Policy mu Max               4.68449
trainer/Policy mu Min              -5.63291
trainer/Policy log std Mean        -0.756483
trainer/Policy log std Std          0.314826
trainer/Policy log std Max          0.282807
trainer/Policy log std Min         -2.12853
trainer/Alpha                       0.0229722
trainer/Alpha Loss                  1.67828
exploration/num steps total    206000
exploration/num paths total       907
exploration/path length Mean      263.158
exploration/path length Std       182.894
exploration/path length Max       500
exploration/path length Min        70
exploration/Rewards Mean            0.00195152
exploration/Rewards Std             0.0242831
exploration/Rewards Max             0.0868656
exploration/Rewards Min            -0.286628
exploration/Returns Mean            0.513558
exploration/Returns Std             1.18697
exploration/Returns Max             2.79363
exploration/Returns Min            -2.19998
exploration/Actions Mean           -0.00805285
exploration/Actions Std             0.46907
exploration/Actions Max             0.997707
exploration/Actions Min            -0.999906
exploration/Num Paths              19
exploration/Average Returns         0.513558
evaluation/num steps total     202687
evaluation/num paths total        870
evaluation/path length Mean       353.929
evaluation/path length Std        186.222
evaluation/path length Max        500
evaluation/path length Min         69
evaluation/Rewards Mean             0.0013252
evaluation/Rewards Std              0.0188094
evaluation/Rewards Max              0.0481985
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.469025
evaluation/Returns Std              1.2327
evaluation/Returns Max              1.85623
evaluation/Returns Min             -2.47437
evaluation/ExplReturns Mean         0.469025
evaluation/ExplReturns Std          1.2327
evaluation/ExplReturns Max          1.85623
evaluation/ExplReturns Min         -2.47437
evaluation/Actions Mean            -0.00547592
evaluation/Actions Std              0.317959
evaluation/Actions Max              0.988923
evaluation/Actions Min             -0.995104
evaluation/Num Paths               14
evaluation/Average Returns          0.469025
time/data storing (s)               0.0290422
time/evaluation sampling (s)       68.8719
time/exploration sampling (s)      73.6369
time/logging (s)                    0.0250952
time/saving (s)                     0.0712397
time/training (s)                  10.4551
time/epoch (s)                    153.089
time/total (s)                   6350.57
Epoch                              40
-----------------------------  ---------------
2023-08-31 13:44:24.517342 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 41 finished
-----------------------------  ---------------
replay_buffer/size             211000
trainer/QF1 Loss                    1.56111
trainer/QF2 Loss                    1.52839
trainer/Policy Loss               -64.2477
trainer/Q1 Predictions Mean        69.5405
trainer/Q1 Predictions Std          8.45726
trainer/Q1 Predictions Max         92.6952
trainer/Q1 Predictions Min         32.3387
trainer/Q2 Predictions Mean        69.3382
trainer/Q2 Predictions Std          8.73241
trainer/Q2 Predictions Max         93.4035
trainer/Q2 Predictions Min         30.6362
trainer/Q Targets Mean             69.4677
trainer/Q Targets Std               8.38199
trainer/Q Targets Max              92.264
trainer/Q Targets Min              31.6497
trainer/Log Pis Mean                6.38872
trainer/Log Pis Std                 5.25215
trainer/Log Pis Max                44.6331
trainer/Log Pis Min                -4.69003
trainer/Policy mu Mean              0.44879
trainer/Policy mu Std               1.58961
trainer/Policy mu Max              11.698
trainer/Policy mu Min              -8.13257
trainer/Policy log std Mean        -0.738608
trainer/Policy log std Std          0.316962
trainer/Policy log std Max          1.01441
trainer/Policy log std Min         -2.252
trainer/Alpha                       0.0264686
trainer/Alpha Loss                  1.41181
exploration/num steps total    211000
exploration/num paths total       918
exploration/path length Mean      454.545
exploration/path length Std        92.441
exploration/path length Max       500
exploration/path length Min       241
exploration/Rewards Mean            0.00286671
exploration/Rewards Std             0.00907923
exploration/Rewards Max             0.0510309
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.30305
exploration/Returns Std             0.523427
exploration/Returns Max             2.48906
exploration/Returns Min             0.488218
exploration/Actions Mean            0.0344512
exploration/Actions Std             0.520386
exploration/Actions Max             0.999962
exploration/Actions Min            -0.998628
exploration/Num Paths              11
exploration/Average Returns         1.30305
evaluation/num steps total     207271
evaluation/num paths total        880
evaluation/path length Mean       458.4
evaluation/path length Std         83.6794
evaluation/path length Max        500
evaluation/path length Min        272
evaluation/Rewards Mean             0.00208138
evaluation/Rewards Std              0.00829565
evaluation/Rewards Max              0.0413396
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.954107
evaluation/Returns Std              0.367692
evaluation/Returns Max              1.60606
evaluation/Returns Min              0.201409
evaluation/ExplReturns Mean         0.954107
evaluation/ExplReturns Std          0.367692
evaluation/ExplReturns Max          1.60606
evaluation/ExplReturns Min          0.201409
evaluation/Actions Mean             0.0332994
evaluation/Actions Std              0.317255
evaluation/Actions Max              0.999986
evaluation/Actions Min             -0.999972
evaluation/Num Paths               10
evaluation/Average Returns          0.954107
time/data storing (s)               0.029247
time/evaluation sampling (s)       68.8565
time/exploration sampling (s)      72.144
time/logging (s)                    0.0240092
time/saving (s)                     0.0652086
time/training (s)                   9.99387
time/epoch (s)                    151.113
time/total (s)                   6501.68
Epoch                              41
-----------------------------  ---------------
2023-08-31 13:46:58.677224 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 42 finished
-----------------------------  ----------------
replay_buffer/size             216000
trainer/QF1 Loss                    1.35542
trainer/QF2 Loss                    1.45835
trainer/Policy Loss               -67.0691
trainer/Q1 Predictions Mean        70.9395
trainer/Q1 Predictions Std          6.57166
trainer/Q1 Predictions Max         90.2502
trainer/Q1 Predictions Min         39.1565
trainer/Q2 Predictions Mean        71.074
trainer/Q2 Predictions Std          6.58628
trainer/Q2 Predictions Max         91.2483
trainer/Q2 Predictions Min         43.115
trainer/Q Targets Mean             70.5399
trainer/Q Targets Std               6.45837
trainer/Q Targets Max              89.7165
trainer/Q Targets Min              42.6339
trainer/Log Pis Mean                5.10723
trainer/Log Pis Std                 4.0802
trainer/Log Pis Max                27.2616
trainer/Log Pis Min                -5.4218
trainer/Policy mu Mean              0.356919
trainer/Policy mu Std               1.42254
trainer/Policy mu Max               5.00057
trainer/Policy mu Min              -4.01167
trainer/Policy log std Mean        -0.805228
trainer/Policy log std Std          0.324808
trainer/Policy log std Max          0.0194264
trainer/Policy log std Min         -2.08833
trainer/Alpha                       0.0255783
trainer/Alpha Loss                 -3.2725
exploration/num steps total    216000
exploration/num paths total       928
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0030686
exploration/Rewards Std             0.0076083
exploration/Rewards Max             0.0499932
exploration/Rewards Min             0.000217398
exploration/Returns Mean            1.5343
exploration/Returns Std             0.485982
exploration/Returns Max             2.28786
exploration/Returns Min             0.868338
exploration/Actions Mean            0.00382424
exploration/Actions Std             0.536407
exploration/Actions Max             0.999571
exploration/Actions Min            -0.999212
exploration/Num Paths              10
exploration/Average Returns         1.5343
evaluation/num steps total     212271
evaluation/num paths total        890
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00228781
evaluation/Rewards Std              0.0055115
evaluation/Rewards Max              0.0412912
evaluation/Rewards Min              0.000373776
evaluation/Returns Mean             1.1439
evaluation/Returns Std              0.24009
evaluation/Returns Max              1.51164
evaluation/Returns Min              0.7706
evaluation/ExplReturns Mean         1.1439
evaluation/ExplReturns Std          0.24009
evaluation/ExplReturns Max          1.51164
evaluation/ExplReturns Min          0.7706
evaluation/Actions Mean             0.0211896
evaluation/Actions Std              0.25886
evaluation/Actions Max              0.988512
evaluation/Actions Min             -0.990074
evaluation/Num Paths               10
evaluation/Average Returns          1.1439
time/data storing (s)               0.0289577
time/evaluation sampling (s)       69.222
time/exploration sampling (s)      74.7674
time/logging (s)                    0.0252868
time/saving (s)                     0.0692451
time/training (s)                  10.0447
time/epoch (s)                    154.158
time/total (s)                   6655.84
Epoch                              42
-----------------------------  ----------------
2023-08-31 13:49:30.191545 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 43 finished
-----------------------------  ----------------
replay_buffer/size             221000
trainer/QF1 Loss                    8.57966
trainer/QF2 Loss                   10.2987
trainer/Policy Loss               -67.1516
trainer/Q1 Predictions Mean        71.4265
trainer/Q1 Predictions Std          7.24003
trainer/Q1 Predictions Max         84.8249
trainer/Q1 Predictions Min         27.7956
trainer/Q2 Predictions Mean        71.9078
trainer/Q2 Predictions Std          7.14476
trainer/Q2 Predictions Max         84.72
trainer/Q2 Predictions Min         31.8354
trainer/Q Targets Mean             71.0293
trainer/Q Targets Std               8.73194
trainer/Q Targets Max              84.1168
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.86879
trainer/Log Pis Std                 4.38727
trainer/Log Pis Max                27.8297
trainer/Log Pis Min                -5.00885
trainer/Policy mu Mean              0.323325
trainer/Policy mu Std               1.49873
trainer/Policy mu Max               5.78585
trainer/Policy mu Min              -4.02833
trainer/Policy log std Mean        -0.868347
trainer/Policy log std Std          0.351333
trainer/Policy log std Max         -0.0808919
trainer/Policy log std Min         -2.48267
trainer/Alpha                       0.0244121
trainer/Alpha Loss                 -0.487152
exploration/num steps total    221000
exploration/num paths total       938
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00239691
exploration/Rewards Std             0.00624699
exploration/Rewards Max             0.0453596
exploration/Rewards Min             8.75827e-05
exploration/Returns Mean            1.19846
exploration/Returns Std             0.358101
exploration/Returns Max             1.96968
exploration/Returns Min             0.839554
exploration/Actions Mean           -0.0125634
exploration/Actions Std             0.535824
exploration/Actions Max             0.99937
exploration/Actions Min            -0.999066
exploration/Num Paths              10
exploration/Average Returns         1.19846
evaluation/num steps total     217271
evaluation/num paths total        900
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00144808
evaluation/Rewards Std              0.00439806
evaluation/Rewards Max              0.0332498
evaluation/Rewards Min              6.98075e-05
evaluation/Returns Mean             0.72404
evaluation/Returns Std              0.2059
evaluation/Returns Max              1.24362
evaluation/Returns Min              0.414552
evaluation/ExplReturns Mean         0.72404
evaluation/ExplReturns Std          0.2059
evaluation/ExplReturns Max          1.24362
evaluation/ExplReturns Min          0.414552
evaluation/Actions Mean            -0.0336024
evaluation/Actions Std              0.337841
evaluation/Actions Max              0.989475
evaluation/Actions Min             -0.989573
evaluation/Num Paths               10
evaluation/Average Returns          0.72404
time/data storing (s)               0.0296462
time/evaluation sampling (s)       67.8237
time/exploration sampling (s)      73.2467
time/logging (s)                    0.0252437
time/saving (s)                     0.0669313
time/training (s)                  10.3184
time/epoch (s)                    151.511
time/total (s)                   6807.36
Epoch                              43
-----------------------------  ----------------
2023-08-31 13:52:01.847593 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             226000
trainer/QF1 Loss                    2.30642
trainer/QF2 Loss                    1.88103
trainer/Policy Loss               -69.6757
trainer/Q1 Predictions Mean        74.0021
trainer/Q1 Predictions Std          7.09348
trainer/Q1 Predictions Max         87.9037
trainer/Q1 Predictions Min         24.9675
trainer/Q2 Predictions Mean        74.0694
trainer/Q2 Predictions Std          6.92335
trainer/Q2 Predictions Max         88.3372
trainer/Q2 Predictions Min         33.7796
trainer/Q Targets Mean             74.2994
trainer/Q Targets Std               6.51574
trainer/Q Targets Max              88.2476
trainer/Q Targets Min              34.6827
trainer/Log Pis Mean                5.57999
trainer/Log Pis Std                 3.67437
trainer/Log Pis Max                19.4616
trainer/Log Pis Min                -6.22227
trainer/Policy mu Mean              0.241148
trainer/Policy mu Std               1.405
trainer/Policy mu Max               3.51135
trainer/Policy mu Min              -4.76338
trainer/Policy log std Mean        -0.891649
trainer/Policy log std Std          0.37381
trainer/Policy log std Max         -0.0158253
trainer/Policy log std Min         -2.35791
trainer/Alpha                       0.0236065
trainer/Alpha Loss                 -1.57338
exploration/num steps total    226000
exploration/num paths total       956
exploration/path length Mean      277.778
exploration/path length Std       150.69
exploration/path length Max       500
exploration/path length Min       144
exploration/Rewards Mean            0.0119184
exploration/Rewards Std             0.027772
exploration/Rewards Max             0.12608
exploration/Rewards Min            -0.281611
exploration/Returns Mean            3.31066
exploration/Returns Std             1.29738
exploration/Returns Max             5.95484
exploration/Returns Min             1.45316
exploration/Actions Mean           -0.0287745
exploration/Actions Std             0.540709
exploration/Actions Max             0.999833
exploration/Actions Min            -0.999999
exploration/Num Paths              18
exploration/Average Returns         3.31066
evaluation/num steps total     222084
evaluation/num paths total        915
evaluation/path length Mean       320.867
evaluation/path length Std        170.076
evaluation/path length Max        500
evaluation/path length Min        113
evaluation/Rewards Mean             0.0100209
evaluation/Rewards Std              0.0233517
evaluation/Rewards Max              0.127592
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             3.21536
evaluation/Returns Std              1.84765
evaluation/Returns Max              9.02342
evaluation/Returns Min              1.11098
evaluation/ExplReturns Mean         3.21536
evaluation/ExplReturns Std          1.84765
evaluation/ExplReturns Max          9.02342
evaluation/ExplReturns Min          1.11098
evaluation/Actions Mean            -0.0141571
evaluation/Actions Std              0.373814
evaluation/Actions Max              0.996303
evaluation/Actions Min             -0.999916
evaluation/Num Paths               15
evaluation/Average Returns          3.21536
time/data storing (s)               0.0290754
time/evaluation sampling (s)       68.4784
time/exploration sampling (s)      73.0963
time/logging (s)                    0.024572
time/saving (s)                     0.071618
time/training (s)                   9.95174
time/epoch (s)                    151.652
time/total (s)                   6959.01
Epoch                              44
-----------------------------  --------------
2023-08-31 13:54:34.077355 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size             231000
trainer/QF1 Loss                    2.11247
trainer/QF2 Loss                    2.19562
trainer/Policy Loss               -68.1695
trainer/Q1 Predictions Mean        73.8549
trainer/Q1 Predictions Std          8.42051
trainer/Q1 Predictions Max        104.299
trainer/Q1 Predictions Min         30.4295
trainer/Q2 Predictions Mean        73.0766
trainer/Q2 Predictions Std          8.35933
trainer/Q2 Predictions Max        103.704
trainer/Q2 Predictions Min         27.7529
trainer/Q Targets Mean             73.6065
trainer/Q Targets Std               8.12756
trainer/Q Targets Max             103.987
trainer/Q Targets Min              26.9954
trainer/Log Pis Mean                6.35264
trainer/Log Pis Std                 4.89684
trainer/Log Pis Max                26.7506
trainer/Log Pis Min                -4.28873
trainer/Policy mu Mean              0.484552
trainer/Policy mu Std               1.48366
trainer/Policy mu Max               4.95413
trainer/Policy mu Min              -5.90581
trainer/Policy log std Mean        -0.880813
trainer/Policy log std Std          0.376482
trainer/Policy log std Max          0.298805
trainer/Policy log std Min         -2.76607
trainer/Alpha                       0.0213749
trainer/Alpha Loss                  1.35615
exploration/num steps total    231000
exploration/num paths total       975
exploration/path length Mean      263.158
exploration/path length Std       203.784
exploration/path length Max       500
exploration/path length Min        62
exploration/Rewards Mean            0.0101855
exploration/Rewards Std             0.0204838
exploration/Rewards Max             0.0975209
exploration/Rewards Min            -0.281611
exploration/Returns Mean            2.68039
exploration/Returns Std             2.00863
exploration/Returns Max             6.54105
exploration/Returns Min             0.169622
exploration/Actions Mean            0.0298559
exploration/Actions Std             0.550215
exploration/Actions Max             0.999973
exploration/Actions Min            -0.998174
exploration/Num Paths              19
exploration/Average Returns         2.68039
evaluation/num steps total     226590
evaluation/num paths total        929
evaluation/path length Mean       321.857
evaluation/path length Std        205.773
evaluation/path length Max        500
evaluation/path length Min         74
evaluation/Rewards Mean             0.00607126
evaluation/Rewards Std              0.0160982
evaluation/Rewards Max              0.0844731
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.95408
evaluation/Returns Std              1.05776
evaluation/Returns Max              4.23393
evaluation/Returns Min              0.739635
evaluation/ExplReturns Mean         1.95408
evaluation/ExplReturns Std          1.05776
evaluation/ExplReturns Max          4.23393
evaluation/ExplReturns Min          0.739635
evaluation/Actions Mean             0.026556
evaluation/Actions Std              0.354246
evaluation/Actions Max              0.995064
evaluation/Actions Min             -0.971738
evaluation/Num Paths               14
evaluation/Average Returns          1.95408
time/data storing (s)               0.0292754
time/evaluation sampling (s)       68.0464
time/exploration sampling (s)      74.1414
time/logging (s)                    0.0241823
time/saving (s)                     0.0633919
time/training (s)                   9.92108
time/epoch (s)                    152.226
time/total (s)                   7111.24
Epoch                              45
-----------------------------  ---------------
2023-08-31 13:57:08.370500 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 46 finished
-----------------------------  ---------------
replay_buffer/size             236000
trainer/QF1 Loss                    1.09754
trainer/QF2 Loss                    1.37139
trainer/Policy Loss               -68.0254
trainer/Q1 Predictions Mean        73.4221
trainer/Q1 Predictions Std          8.21411
trainer/Q1 Predictions Max         93.2897
trainer/Q1 Predictions Min         35.724
trainer/Q2 Predictions Mean        73.6393
trainer/Q2 Predictions Std          8.17379
trainer/Q2 Predictions Max         93.216
trainer/Q2 Predictions Min         33.248
trainer/Q Targets Mean             73.1755
trainer/Q Targets Std               8.32543
trainer/Q Targets Max              92.9904
trainer/Q Targets Min              33.8366
trainer/Log Pis Mean                6.33074
trainer/Log Pis Std                 4.59251
trainer/Log Pis Max                37.1446
trainer/Log Pis Min                -7.51591
trainer/Policy mu Mean              0.232376
trainer/Policy mu Std               1.56075
trainer/Policy mu Max               8.48793
trainer/Policy mu Min              -5.5723
trainer/Policy log std Mean        -0.789138
trainer/Policy log std Std          0.348353
trainer/Policy log std Max          0.911547
trainer/Policy log std Min         -2.35346
trainer/Alpha                       0.0218727
trainer/Alpha Loss                  1.26432
exploration/num steps total    236000
exploration/num paths total       985
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00678518
exploration/Rewards Std             0.00352179
exploration/Rewards Max             0.0439209
exploration/Rewards Min             0.00278041
exploration/Returns Mean            3.39259
exploration/Returns Std             0.676209
exploration/Returns Max             4.48461
exploration/Returns Min             2.41341
exploration/Actions Mean           -0.00512113
exploration/Actions Std             0.544103
exploration/Actions Max             0.999931
exploration/Actions Min            -0.99681
exploration/Num Paths              10
exploration/Average Returns         3.39259
evaluation/num steps total     231590
evaluation/num paths total        939
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00791857
evaluation/Rewards Std              0.00300745
evaluation/Rewards Max              0.0381457
evaluation/Rewards Min              0.0049878
evaluation/Returns Mean             3.95929
evaluation/Returns Std              0.398848
evaluation/Returns Max              4.45702
evaluation/Returns Min              3.01619
evaluation/ExplReturns Mean         3.95929
evaluation/ExplReturns Std          0.398848
evaluation/ExplReturns Max          4.45702
evaluation/ExplReturns Min          3.01619
evaluation/Actions Mean             0.0120634
evaluation/Actions Std              0.296398
evaluation/Actions Max              0.998597
evaluation/Actions Min             -0.986989
evaluation/Num Paths               10
evaluation/Average Returns          3.95929
time/data storing (s)               0.0287449
time/evaluation sampling (s)       68.7806
time/exploration sampling (s)      75.4458
time/logging (s)                    0.0249783
time/saving (s)                     0.0171512
time/training (s)                   9.99305
time/epoch (s)                    154.29
time/total (s)                   7265.53
Epoch                              46
-----------------------------  ---------------
2023-08-31 13:59:42.762105 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 47 finished
-----------------------------  ---------------
replay_buffer/size             241000
trainer/QF1 Loss                    1.89781
trainer/QF2 Loss                    2.38192
trainer/Policy Loss               -67.4546
trainer/Q1 Predictions Mean        72.6125
trainer/Q1 Predictions Std          9.58065
trainer/Q1 Predictions Max         89.3321
trainer/Q1 Predictions Min         13.8772
trainer/Q2 Predictions Mean        72.3857
trainer/Q2 Predictions Std          9.48444
trainer/Q2 Predictions Max         90.0318
trainer/Q2 Predictions Min         13.3316
trainer/Q Targets Mean             72.8214
trainer/Q Targets Std               8.944
trainer/Q Targets Max              89.7507
trainer/Q Targets Min              22.1449
trainer/Log Pis Mean                6.07351
trainer/Log Pis Std                 4.36645
trainer/Log Pis Max                25.5157
trainer/Log Pis Min                -2.89586
trainer/Policy mu Mean              0.295399
trainer/Policy mu Std               1.48641
trainer/Policy mu Max               4.23085
trainer/Policy mu Min              -5.33396
trainer/Policy log std Mean        -0.81124
trainer/Policy log std Std          0.328434
trainer/Policy log std Max          0.0806798
trainer/Policy log std Min         -2.05736
trainer/Alpha                       0.0216692
trainer/Alpha Loss                  0.281668
exploration/num steps total    241000
exploration/num paths total       995
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00879162
exploration/Rewards Std             0.00417963
exploration/Rewards Max             0.0338281
exploration/Rewards Min             0.00259475
exploration/Returns Mean            4.39581
exploration/Returns Std             1.12206
exploration/Returns Max             6.5889
exploration/Returns Min             2.99888
exploration/Actions Mean           -0.0096786
exploration/Actions Std             0.601129
exploration/Actions Max             0.999914
exploration/Actions Min            -0.999402
exploration/Num Paths              10
exploration/Average Returns         4.39581
evaluation/num steps total     236590
evaluation/num paths total        949
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0114525
evaluation/Rewards Std              0.00258495
evaluation/Rewards Max              0.0353755
evaluation/Rewards Min              0.00815109
evaluation/Returns Mean             5.72626
evaluation/Returns Std              0.525781
evaluation/Returns Max              6.48658
evaluation/Returns Min              4.76561
evaluation/ExplReturns Mean         5.72626
evaluation/ExplReturns Std          0.525781
evaluation/ExplReturns Max          6.48658
evaluation/ExplReturns Min          4.76561
evaluation/Actions Mean            -0.0304169
evaluation/Actions Std              0.298782
evaluation/Actions Max              0.995023
evaluation/Actions Min             -0.988562
evaluation/Num Paths               10
evaluation/Average Returns          5.72626
time/data storing (s)               0.0294177
time/evaluation sampling (s)       68.6985
time/exploration sampling (s)      74.1025
time/logging (s)                    0.0250852
time/saving (s)                     0.0818479
time/training (s)                  11.4506
time/epoch (s)                    154.388
time/total (s)                   7419.92
Epoch                              47
-----------------------------  ---------------
2023-08-31 14:02:16.664865 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 48 finished
-----------------------------  ----------------
replay_buffer/size             246000
trainer/QF1 Loss                    3.55762
trainer/QF2 Loss                    4.213
trainer/Policy Loss               -68.9977
trainer/Q1 Predictions Mean        74.1019
trainer/Q1 Predictions Std          9.57432
trainer/Q1 Predictions Max         92.3787
trainer/Q1 Predictions Min         -1.3427
trainer/Q2 Predictions Mean        73.7774
trainer/Q2 Predictions Std          9.4372
trainer/Q2 Predictions Max         92.5854
trainer/Q2 Predictions Min         -0.825804
trainer/Q Targets Mean             73.5988
trainer/Q Targets Std               9.84645
trainer/Q Targets Max              91.7263
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.81143
trainer/Log Pis Std                 4.21513
trainer/Log Pis Max                33.9287
trainer/Log Pis Min                -3.08602
trainer/Policy mu Mean              0.270079
trainer/Policy mu Std               1.44273
trainer/Policy mu Max               4.3892
trainer/Policy mu Min              -5.78363
trainer/Policy log std Mean        -0.924978
trainer/Policy log std Std          0.352111
trainer/Policy log std Max          0.135097
trainer/Policy log std Min         -2.32595
trainer/Alpha                       0.0186317
trainer/Alpha Loss                 -0.751063
exploration/num steps total    246000
exploration/num paths total      1005
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00831793
exploration/Rewards Std             0.0050845
exploration/Rewards Max             0.0375421
exploration/Rewards Min             0.000902036
exploration/Returns Mean            4.15897
exploration/Returns Std             1.71181
exploration/Returns Max             6.41301
exploration/Returns Min             1.89687
exploration/Actions Mean            0.00977095
exploration/Actions Std             0.585236
exploration/Actions Max             0.999191
exploration/Actions Min            -0.997113
exploration/Num Paths              10
exploration/Average Returns         4.15897
evaluation/num steps total     241590
evaluation/num paths total        959
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00994793
evaluation/Rewards Std              0.00605833
evaluation/Rewards Max              0.0386754
evaluation/Rewards Min              0.00110559
evaluation/Returns Mean             4.97396
evaluation/Returns Std              2.46605
evaluation/Returns Max              8.02785
evaluation/Returns Min              1.46805
evaluation/ExplReturns Mean         4.97396
evaluation/ExplReturns Std          2.46605
evaluation/ExplReturns Max          8.02785
evaluation/ExplReturns Min          1.46805
evaluation/Actions Mean             0.0214615
evaluation/Actions Std              0.441879
evaluation/Actions Max              0.994639
evaluation/Actions Min             -0.983348
evaluation/Num Paths               10
evaluation/Average Returns          4.97396
time/data storing (s)               0.0290534
time/evaluation sampling (s)       69.0368
time/exploration sampling (s)      74.8185
time/logging (s)                    0.0253405
time/saving (s)                     0.0627359
time/training (s)                   9.92698
time/epoch (s)                    153.899
time/total (s)                   7573.83
Epoch                              48
-----------------------------  ----------------
2023-08-31 14:04:49.817663 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 49 finished
-----------------------------  ----------------
replay_buffer/size             251000
trainer/QF1 Loss                   19.2091
trainer/QF2 Loss                   17.5484
trainer/Policy Loss               -67.0738
trainer/Q1 Predictions Mean        72.023
trainer/Q1 Predictions Std          8.81948
trainer/Q1 Predictions Max        104.371
trainer/Q1 Predictions Min         -9.28013
trainer/Q2 Predictions Mean        72.1014
trainer/Q2 Predictions Std          8.68699
trainer/Q2 Predictions Max        104.19
trainer/Q2 Predictions Min         -5.71639
trainer/Q Targets Mean             71.8291
trainer/Q Targets Std               9.60591
trainer/Q Targets Max             104.686
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.76317
trainer/Log Pis Std                 4.5389
trainer/Log Pis Max                32.1891
trainer/Log Pis Min                -5.88851
trainer/Policy mu Mean              0.194465
trainer/Policy mu Std               1.41836
trainer/Policy mu Max               5.36322
trainer/Policy mu Min              -5.22614
trainer/Policy log std Mean        -0.988399
trainer/Policy log std Std          0.382307
trainer/Policy log std Max         -0.00321269
trainer/Policy log std Min         -2.57776
trainer/Alpha                       0.0164586
trainer/Alpha Loss                 -0.972626
exploration/num steps total    251000
exploration/num paths total      1015
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00857162
exploration/Rewards Std             0.00578274
exploration/Rewards Max             0.0489054
exploration/Rewards Min             0.00105042
exploration/Returns Mean            4.28581
exploration/Returns Std             1.63863
exploration/Returns Max             6.51414
exploration/Returns Min             1.3863
exploration/Actions Mean            0.00102416
exploration/Actions Std             0.561689
exploration/Actions Max             0.999196
exploration/Actions Min            -0.999379
exploration/Num Paths              10
exploration/Average Returns         4.28581
evaluation/num steps total     246590
evaluation/num paths total        969
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0063349
evaluation/Rewards Std              0.0049144
evaluation/Rewards Max              0.0422702
evaluation/Rewards Min              0.00130131
evaluation/Returns Mean             3.16745
evaluation/Returns Std              1.34554
evaluation/Returns Max              5.3523
evaluation/Returns Min              1.273
evaluation/ExplReturns Mean         3.16745
evaluation/ExplReturns Std          1.34554
evaluation/ExplReturns Max          5.3523
evaluation/ExplReturns Min          1.273
evaluation/Actions Mean            -0.000999877
evaluation/Actions Std              0.408337
evaluation/Actions Max              0.992212
evaluation/Actions Min             -0.977207
evaluation/Num Paths               10
evaluation/Average Returns          3.16745
time/data storing (s)               0.0292642
time/evaluation sampling (s)       68.9638
time/exploration sampling (s)      73.7825
time/logging (s)                    0.0251262
time/saving (s)                     0.048005
time/training (s)                  10.3002
time/epoch (s)                    153.149
time/total (s)                   7726.98
Epoch                              49
-----------------------------  ----------------
2023-08-31 14:07:23.205972 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size             256000
trainer/QF1 Loss                    1.17026
trainer/QF2 Loss                    1.36046
trainer/Policy Loss               -66.9514
trainer/Q1 Predictions Mean        72.0307
trainer/Q1 Predictions Std          7.74381
trainer/Q1 Predictions Max         95.3983
trainer/Q1 Predictions Min         34.9148
trainer/Q2 Predictions Mean        72.0583
trainer/Q2 Predictions Std          7.81322
trainer/Q2 Predictions Max         95.4496
trainer/Q2 Predictions Min         34.9348
trainer/Q Targets Mean             71.8692
trainer/Q Targets Std               7.93979
trainer/Q Targets Max              94.9528
trainer/Q Targets Min              30.6773
trainer/Log Pis Mean                5.90414
trainer/Log Pis Std                 3.84326
trainer/Log Pis Max                18.2744
trainer/Log Pis Min                -4.83947
trainer/Policy mu Mean              0.215557
trainer/Policy mu Std               1.41202
trainer/Policy mu Max               4.20272
trainer/Policy mu Min              -4.54888
trainer/Policy log std Mean        -1.01253
trainer/Policy log std Std          0.394063
trainer/Policy log std Max         -0.20699
trainer/Policy log std Min         -2.48536
trainer/Alpha                       0.0157679
trainer/Alpha Loss                 -0.397801
exploration/num steps total    256000
exploration/num paths total      1025
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0120123
exploration/Rewards Std             0.00799167
exploration/Rewards Max             0.0597701
exploration/Rewards Min             0.00192126
exploration/Returns Mean            6.00616
exploration/Returns Std             0.896485
exploration/Returns Max             7.90749
exploration/Returns Min             5.21123
exploration/Actions Mean            0.0141235
exploration/Actions Std             0.600206
exploration/Actions Max             0.999851
exploration/Actions Min            -0.999866
exploration/Num Paths              10
exploration/Average Returns         6.00616
evaluation/num steps total     251590
evaluation/num paths total        979
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0135254
evaluation/Rewards Std              0.00719258
evaluation/Rewards Max              0.0536698
evaluation/Rewards Min              0.00319827
evaluation/Returns Mean             6.76269
evaluation/Returns Std              0.98132
evaluation/Returns Max              8.45532
evaluation/Returns Min              5.05477
evaluation/ExplReturns Mean         6.76269
evaluation/ExplReturns Std          0.98132
evaluation/ExplReturns Max          8.45532
evaluation/ExplReturns Min          5.05477
evaluation/Actions Mean             0.024944
evaluation/Actions Std              0.494132
evaluation/Actions Max              0.98917
evaluation/Actions Min             -0.994662
evaluation/Num Paths               10
evaluation/Average Returns          6.76269
time/data storing (s)               0.0288418
time/evaluation sampling (s)       69.1765
time/exploration sampling (s)      74.0677
time/logging (s)                    0.0256258
time/saving (s)                     0.0623626
time/training (s)                  10.0242
time/epoch (s)                    153.385
time/total (s)                   7880.37
Epoch                              50
-----------------------------  ---------------
2023-08-31 14:09:58.711747 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size             261000
trainer/QF1 Loss                    7.97327
trainer/QF2 Loss                   10.3695
trainer/Policy Loss               -65.5202
trainer/Q1 Predictions Mean        70.3652
trainer/Q1 Predictions Std          6.66305
trainer/Q1 Predictions Max         88.7888
trainer/Q1 Predictions Min         41.7033
trainer/Q2 Predictions Mean        70.5312
trainer/Q2 Predictions Std          6.58165
trainer/Q2 Predictions Max         89.0416
trainer/Q2 Predictions Min         45.5913
trainer/Q Targets Mean             70.1279
trainer/Q Targets Std               7.60084
trainer/Q Targets Max              88.5192
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.57972
trainer/Log Pis Std                 4.30299
trainer/Log Pis Max                20.922
trainer/Log Pis Min                -5.38567
trainer/Policy mu Mean              0.184112
trainer/Policy mu Std               1.37983
trainer/Policy mu Max               4.72866
trainer/Policy mu Min              -4.32001
trainer/Policy log std Mean        -1.00141
trainer/Policy log std Std          0.395606
trainer/Policy log std Max         -0.110212
trainer/Policy log std Min         -2.72823
trainer/Alpha                       0.0149582
trainer/Alpha Loss                 -1.76624
exploration/num steps total    261000
exploration/num paths total      1035
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00604202
exploration/Rewards Std             0.00392026
exploration/Rewards Max             0.0497207
exploration/Rewards Min             0.00216548
exploration/Returns Mean            3.02101
exploration/Returns Std             0.723845
exploration/Returns Max             4.22746
exploration/Returns Min             2.0179
exploration/Actions Mean            0.0142963
exploration/Actions Std             0.453639
exploration/Actions Max             0.998732
exploration/Actions Min            -0.994537
exploration/Num Paths              10
exploration/Average Returns         3.02101
evaluation/num steps total     256590
evaluation/num paths total        989
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00567063
evaluation/Rewards Std              0.00391812
evaluation/Rewards Max              0.0491907
evaluation/Rewards Min              0.00282056
evaluation/Returns Mean             2.83531
evaluation/Returns Std              0.685022
evaluation/Returns Max              4.01684
evaluation/Returns Min              1.65812
evaluation/ExplReturns Mean         2.83531
evaluation/ExplReturns Std          0.685022
evaluation/ExplReturns Max          4.01684
evaluation/ExplReturns Min          1.65812
evaluation/Actions Mean            -0.00525405
evaluation/Actions Std              0.225747
evaluation/Actions Max              0.987596
evaluation/Actions Min             -0.96538
evaluation/Num Paths               10
evaluation/Average Returns          2.83531
time/data storing (s)               0.0287629
time/evaluation sampling (s)       69.0322
time/exploration sampling (s)      76.2065
time/logging (s)                    0.0251709
time/saving (s)                     0.0721237
time/training (s)                  10.1368
time/epoch (s)                    155.502
time/total (s)                   8035.87
Epoch                              51
-----------------------------  ---------------
2023-08-31 14:12:33.227462 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             266000
trainer/QF1 Loss                   19.4062
trainer/QF2 Loss                   18.6387
trainer/Policy Loss               -63.8826
trainer/Q1 Predictions Mean        69.4674
trainer/Q1 Predictions Std          8.45837
trainer/Q1 Predictions Max         89.0489
trainer/Q1 Predictions Min         -2.63
trainer/Q2 Predictions Mean        69.1278
trainer/Q2 Predictions Std          8.32656
trainer/Q2 Predictions Max         90.8267
trainer/Q2 Predictions Min          0.405377
trainer/Q Targets Mean             68.8141
trainer/Q Targets Std               9.80481
trainer/Q Targets Max              91.2409
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.08882
trainer/Log Pis Std                 4.94039
trainer/Log Pis Max                30.8313
trainer/Log Pis Min                -6.56099
trainer/Policy mu Mean             -0.0103179
trainer/Policy mu Std               1.49689
trainer/Policy mu Max               4.922
trainer/Policy mu Min              -6.13953
trainer/Policy log std Mean        -0.961835
trainer/Policy log std Std          0.40291
trainer/Policy log std Max          0.339589
trainer/Policy log std Min         -2.30762
trainer/Alpha                       0.0149631
trainer/Alpha Loss                  0.373266
exploration/num steps total    266000
exploration/num paths total      1047
exploration/path length Mean      416.667
exploration/path length Std       161.114
exploration/path length Max       500
exploration/path length Min        59
exploration/Rewards Mean            0.0100104
exploration/Rewards Std             0.00711184
exploration/Rewards Max             0.0392521
exploration/Rewards Min            -0.281611
exploration/Returns Mean            4.17098
exploration/Returns Std             2.15309
exploration/Returns Max             6.36724
exploration/Returns Min            -0.0772695
exploration/Actions Mean            0.00931007
exploration/Actions Std             0.468849
exploration/Actions Max             0.998283
exploration/Actions Min            -0.998634
exploration/Num Paths              12
exploration/Average Returns         4.17098
evaluation/num steps total     261590
evaluation/num paths total        999
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00892207
evaluation/Rewards Std              0.00376673
evaluation/Rewards Max              0.044147
evaluation/Rewards Min              0.00477189
evaluation/Returns Mean             4.46104
evaluation/Returns Std              1.12989
evaluation/Returns Max              5.88888
evaluation/Returns Min              2.81974
evaluation/ExplReturns Mean         4.46104
evaluation/ExplReturns Std          1.12989
evaluation/ExplReturns Max          5.88888
evaluation/ExplReturns Min          2.81974
evaluation/Actions Mean             0.00203235
evaluation/Actions Std              0.226749
evaluation/Actions Max              0.994456
evaluation/Actions Min             -0.963783
evaluation/Num Paths               10
evaluation/Average Returns          4.46104
time/data storing (s)               0.0288193
time/evaluation sampling (s)       69.3111
time/exploration sampling (s)      74.59
time/logging (s)                    0.0251957
time/saving (s)                     0.075118
time/training (s)                  10.4819
time/epoch (s)                    154.512
time/total (s)                   8190.38
Epoch                              52
-----------------------------  ---------------
2023-08-31 14:15:05.891933 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 53 finished
-----------------------------  ---------------
replay_buffer/size             271000
trainer/QF1 Loss                    1.09051
trainer/QF2 Loss                    0.901069
trainer/Policy Loss               -63.0019
trainer/Q1 Predictions Mean        68.4556
trainer/Q1 Predictions Std          6.29834
trainer/Q1 Predictions Max         94.5766
trainer/Q1 Predictions Min         43.5694
trainer/Q2 Predictions Mean        68.766
trainer/Q2 Predictions Std          6.24567
trainer/Q2 Predictions Max         95.3604
trainer/Q2 Predictions Min         46.0275
trainer/Q Targets Mean             68.9843
trainer/Q Targets Std               6.35913
trainer/Q Targets Max              95.4241
trainer/Q Targets Min              45.5278
trainer/Log Pis Mean                6.4411
trainer/Log Pis Std                 3.99412
trainer/Log Pis Max                19.5064
trainer/Log Pis Min                -2.46643
trainer/Policy mu Mean              0.0499526
trainer/Policy mu Std               1.54308
trainer/Policy mu Max               5.55905
trainer/Policy mu Min              -4.29317
trainer/Policy log std Mean        -0.912846
trainer/Policy log std Std          0.371195
trainer/Policy log std Max          0.0828225
trainer/Policy log std Min         -2.41011
trainer/Alpha                       0.01607
trainer/Alpha Loss                  1.82225
exploration/num steps total    271000
exploration/num paths total      1064
exploration/path length Mean      294.118
exploration/path length Std       218.373
exploration/path length Max       500
exploration/path length Min        49
exploration/Rewards Mean            0.00657545
exploration/Rewards Std             0.0129633
exploration/Rewards Max             0.0566682
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.93395
exploration/Returns Std             1.75574
exploration/Returns Max             4.23213
exploration/Returns Min            -0.0905577
exploration/Actions Mean            0.017335
exploration/Actions Std             0.483502
exploration/Actions Max             0.999317
exploration/Actions Min            -0.999365
exploration/Num Paths              17
exploration/Average Returns         1.93395
evaluation/num steps total     266537
evaluation/num paths total       1016
evaluation/path length Mean       291
evaluation/path length Std        221.73
evaluation/path length Max        500
evaluation/path length Min         52
evaluation/Rewards Mean             0.006725
evaluation/Rewards Std              0.0129484
evaluation/Rewards Max              0.0566674
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.95697
evaluation/Returns Std              1.8848
evaluation/Returns Max              4.52646
evaluation/Returns Min             -0.12277
evaluation/ExplReturns Mean         1.95697
evaluation/ExplReturns Std          1.8848
evaluation/ExplReturns Max          4.52646
evaluation/ExplReturns Min         -0.12277
evaluation/Actions Mean             0.0127665
evaluation/Actions Std              0.265181
evaluation/Actions Max              0.995941
evaluation/Actions Min             -0.998288
evaluation/Num Paths               17
evaluation/Average Returns          1.95697
time/data storing (s)               0.029138
time/evaluation sampling (s)       68.9204
time/exploration sampling (s)      73.1783
time/logging (s)                    0.0256653
time/saving (s)                     0.0625685
time/training (s)                  10.4452
time/epoch (s)                    152.661
time/total (s)                   8343.05
Epoch                              53
-----------------------------  ---------------
2023-08-31 14:17:42.800668 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size             276000
trainer/QF1 Loss                    3.49348
trainer/QF2 Loss                    3.57996
trainer/Policy Loss               -64.5632
trainer/Q1 Predictions Mean        69.9197
trainer/Q1 Predictions Std          9.2304
trainer/Q1 Predictions Max        111.261
trainer/Q1 Predictions Min         21.4501
trainer/Q2 Predictions Mean        69.7856
trainer/Q2 Predictions Std          9.02102
trainer/Q2 Predictions Max        108.006
trainer/Q2 Predictions Min         25.4037
trainer/Q Targets Mean             69.4845
trainer/Q Targets Std               9.46916
trainer/Q Targets Max             105.048
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.28423
trainer/Log Pis Std                 4.73356
trainer/Log Pis Max                25.3724
trainer/Log Pis Min                -1.91465
trainer/Policy mu Mean              0.045302
trainer/Policy mu Std               1.51167
trainer/Policy mu Max               4.89274
trainer/Policy mu Min              -4.42518
trainer/Policy log std Mean        -0.89389
trainer/Policy log std Std          0.375405
trainer/Policy log std Max          0.16423
trainer/Policy log std Min         -2.36754
trainer/Alpha                       0.0174321
trainer/Alpha Loss                  1.15095
exploration/num steps total    276000
exploration/num paths total      1096
exploration/path length Mean      156.25
exploration/path length Std        82.3487
exploration/path length Max       433
exploration/path length Min        93
exploration/Rewards Mean            0.00177134
exploration/Rewards Std             0.0238103
exploration/Rewards Max             0.0528967
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.276772
exploration/Returns Std             0.226059
exploration/Returns Max             0.761186
exploration/Returns Min            -0.118117
exploration/Actions Mean           -0.0506097
exploration/Actions Std             0.520188
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999855
exploration/Num Paths              32
exploration/Average Returns         0.276772
evaluation/num steps total     271512
evaluation/num paths total       1057
evaluation/path length Mean       121.341
evaluation/path length Std         53.0957
evaluation/path length Max        327
evaluation/path length Min         93
evaluation/Rewards Mean             0.00157281
evaluation/Rewards Std              0.0270715
evaluation/Rewards Max              0.0562341
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.190847
evaluation/Returns Std              0.222483
evaluation/Returns Max              0.639051
evaluation/Returns Min             -0.162554
evaluation/ExplReturns Mean         0.190847
evaluation/ExplReturns Std          0.222483
evaluation/ExplReturns Max          0.639051
evaluation/ExplReturns Min         -0.162554
evaluation/Actions Mean            -0.079358
evaluation/Actions Std              0.506404
evaluation/Actions Max              0.99998
evaluation/Actions Min             -0.999416
evaluation/Num Paths               41
evaluation/Average Returns          0.190847
time/data storing (s)               0.0289351
time/evaluation sampling (s)       69.0939
time/exploration sampling (s)      73.796
time/logging (s)                    0.0261022
time/saving (s)                     0.0731493
time/training (s)                  13.8874
time/epoch (s)                    156.905
time/total (s)                   8499.96
Epoch                              54
-----------------------------  ---------------
2023-08-31 14:20:16.583156 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 55 finished
-----------------------------  ----------------
replay_buffer/size             281000
trainer/QF1 Loss                    3.12764
trainer/QF2 Loss                    2.79161
trainer/Policy Loss               -64.4268
trainer/Q1 Predictions Mean        70.1026
trainer/Q1 Predictions Std          9.5132
trainer/Q1 Predictions Max        100.922
trainer/Q1 Predictions Min         25.6325
trainer/Q2 Predictions Mean        69.7103
trainer/Q2 Predictions Std          9.72661
trainer/Q2 Predictions Max        100.687
trainer/Q2 Predictions Min         26.8227
trainer/Q Targets Mean             69.8073
trainer/Q Targets Std               9.68637
trainer/Q Targets Max             101.517
trainer/Q Targets Min              28.7237
trainer/Log Pis Mean                6.70678
trainer/Log Pis Std                 4.46189
trainer/Log Pis Max                29.2348
trainer/Log Pis Min                -7.48064
trainer/Policy mu Mean             -0.0262403
trainer/Policy mu Std               1.59805
trainer/Policy mu Max               4.36922
trainer/Policy mu Min              -5.57192
trainer/Policy log std Mean        -0.863238
trainer/Policy log std Std          0.385711
trainer/Policy log std Max         -0.00540495
trainer/Policy log std Min         -2.61793
trainer/Alpha                       0.0203057
trainer/Alpha Loss                  2.75436
exploration/num steps total    281000
exploration/num paths total      1134
exploration/path length Mean      131.579
exploration/path length Std       126.867
exploration/path length Max       500
exploration/path length Min        56
exploration/Rewards Mean            0.00184293
exploration/Rewards Std             0.0253337
exploration/Rewards Max             0.0709682
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.242491
exploration/Returns Std             0.214957
exploration/Returns Max             0.823313
exploration/Returns Min            -0.119489
exploration/Actions Mean            0.0786426
exploration/Actions Std             0.519486
exploration/Actions Max             0.999873
exploration/Actions Min            -0.999552
exploration/Num Paths              38
exploration/Average Returns         0.242491
evaluation/num steps total     276333
evaluation/num paths total       1077
evaluation/path length Mean       241.05
evaluation/path length Std        211.54
evaluation/path length Max        500
evaluation/path length Min         60
evaluation/Rewards Mean             0.000991419
evaluation/Rewards Std              0.0153703
evaluation/Rewards Max              0.0607626
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.238982
evaluation/Returns Std              0.301827
evaluation/Returns Max              0.67753
evaluation/Returns Min             -0.166129
evaluation/ExplReturns Mean         0.238982
evaluation/ExplReturns Std          0.301827
evaluation/ExplReturns Max          0.67753
evaluation/ExplReturns Min         -0.166129
evaluation/Actions Mean             0.0369677
evaluation/Actions Std              0.391403
evaluation/Actions Max              0.99884
evaluation/Actions Min             -0.998498
evaluation/Num Paths               20
evaluation/Average Returns          0.238982
time/data storing (s)               0.0291819
time/evaluation sampling (s)       68.3038
time/exploration sampling (s)      73.6919
time/logging (s)                    0.0249105
time/saving (s)                     0.064892
time/training (s)                  11.6628
time/epoch (s)                    153.778
time/total (s)                   8653.74
Epoch                              55
-----------------------------  ----------------
2023-08-31 14:22:53.282599 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             286000
trainer/QF1 Loss                    2.38684
trainer/QF2 Loss                    2.59368
trainer/Policy Loss               -66.199
trainer/Q1 Predictions Mean        70.9673
trainer/Q1 Predictions Std          9.84871
trainer/Q1 Predictions Max        105.114
trainer/Q1 Predictions Min         14.6202
trainer/Q2 Predictions Mean        70.6283
trainer/Q2 Predictions Std         10.0064
trainer/Q2 Predictions Max        103.92
trainer/Q2 Predictions Min         11.62
trainer/Q Targets Mean             70.9368
trainer/Q Targets Std               9.80155
trainer/Q Targets Max             104.575
trainer/Q Targets Min               9.49601
trainer/Log Pis Mean                6.23591
trainer/Log Pis Std                 4.11018
trainer/Log Pis Max                19.281
trainer/Log Pis Min                -4.94811
trainer/Policy mu Mean              0.0996927
trainer/Policy mu Std               1.55327
trainer/Policy mu Max               4.87404
trainer/Policy mu Min              -4.42607
trainer/Policy log std Mean        -0.795281
trainer/Policy log std Std          0.341264
trainer/Policy log std Max          0.175013
trainer/Policy log std Min         -2.21043
trainer/Alpha                       0.0242869
trainer/Alpha Loss                  0.877052
exploration/num steps total    286000
exploration/num paths total      1178
exploration/path length Mean      113.636
exploration/path length Std        31.3123
exploration/path length Max       216
exploration/path length Min        38
exploration/Rewards Mean            0.0030227
exploration/Rewards Std             0.0289391
exploration/Rewards Max             0.0772382
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.343489
exploration/Returns Std             0.204464
exploration/Returns Max             0.813617
exploration/Returns Min            -0.053687
exploration/Actions Mean            0.0236414
exploration/Actions Std             0.571413
exploration/Actions Max             1
exploration/Actions Min            -0.999999
exploration/Num Paths              44
exploration/Average Returns         0.343489
evaluation/num steps total     281322
evaluation/num paths total       1121
evaluation/path length Mean       113.386
evaluation/path length Std         39.3136
evaluation/path length Max        322
evaluation/path length Min         86
evaluation/Rewards Mean             0.0025698
evaluation/Rewards Std              0.0289963
evaluation/Rewards Max              0.0774238
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.29138
evaluation/Returns Std              0.222816
evaluation/Returns Max              0.726749
evaluation/Returns Min             -0.0775444
evaluation/ExplReturns Mean         0.29138
evaluation/ExplReturns Std          0.222816
evaluation/ExplReturns Max          0.726749
evaluation/ExplReturns Min         -0.0775444
evaluation/Actions Mean             0.0402348
evaluation/Actions Std              0.52301
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               44
evaluation/Average Returns          0.29138
time/data storing (s)               0.0285696
time/evaluation sampling (s)       68.4509
time/exploration sampling (s)      73.4859
time/logging (s)                    0.025456
time/saving (s)                     0.0668307
time/training (s)                  14.6386
time/epoch (s)                    156.696
time/total (s)                   8810.44
Epoch                              56
-----------------------------  --------------
2023-08-31 14:25:25.799416 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 57 finished
-----------------------------  ----------------
replay_buffer/size             291000
trainer/QF1 Loss                    2.80225
trainer/QF2 Loss                    3.04588
trainer/Policy Loss               -70.279
trainer/Q1 Predictions Mean        74.4975
trainer/Q1 Predictions Std         10.1398
trainer/Q1 Predictions Max        104.683
trainer/Q1 Predictions Min         32.2208
trainer/Q2 Predictions Mean        74.4562
trainer/Q2 Predictions Std         10.119
trainer/Q2 Predictions Max        103.513
trainer/Q2 Predictions Min         33.7416
trainer/Q Targets Mean             74.3418
trainer/Q Targets Std               9.87977
trainer/Q Targets Max             103.457
trainer/Q Targets Min              42.3419
trainer/Log Pis Mean                5.68444
trainer/Log Pis Std                 3.86117
trainer/Log Pis Max                20.9799
trainer/Log Pis Min                -2.74862
trainer/Policy mu Mean             -0.0471216
trainer/Policy mu Std               1.51578
trainer/Policy mu Max               6.2114
trainer/Policy mu Min              -5.18353
trainer/Policy log std Mean        -0.758788
trainer/Policy log std Std          0.331001
trainer/Policy log std Max          0.503438
trainer/Policy log std Min         -2.62763
trainer/Alpha                       0.0296081
trainer/Alpha Loss                 -1.11067
exploration/num steps total    291000
exploration/num paths total      1190
exploration/path length Mean      416.667
exploration/path length Std       155.035
exploration/path length Max       500
exploration/path length Min        53
exploration/Rewards Mean            0.00127315
exploration/Rewards Std             0.00926239
exploration/Rewards Max             0.0601847
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.530477
exploration/Returns Std             0.275752
exploration/Returns Max             0.919982
exploration/Returns Min             0.0444862
exploration/Actions Mean           -0.00197643
exploration/Actions Std             0.51374
exploration/Actions Max             1
exploration/Actions Min            -0.999998
exploration/Num Paths              12
exploration/Average Returns         0.530477
evaluation/num steps total     286322
evaluation/num paths total       1131
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00100441
evaluation/Rewards Std              0.00467453
evaluation/Rewards Max              0.0556354
evaluation/Rewards Min              1.05318e-05
evaluation/Returns Mean             0.502206
evaluation/Returns Std              0.179205
evaluation/Returns Max              0.84133
evaluation/Returns Min              0.210016
evaluation/ExplReturns Mean         0.502206
evaluation/ExplReturns Std          0.179205
evaluation/ExplReturns Max          0.84133
evaluation/ExplReturns Min          0.210016
evaluation/Actions Mean             0.00278913
evaluation/Actions Std              0.487982
evaluation/Actions Max              0.999534
evaluation/Actions Min             -0.992947
evaluation/Num Paths               10
evaluation/Average Returns          0.502206
time/data storing (s)               0.0289905
time/evaluation sampling (s)       68.0134
time/exploration sampling (s)      73.9407
time/logging (s)                    0.0260865
time/saving (s)                     0.0600984
time/training (s)                  10.4443
time/epoch (s)                    152.514
time/total (s)                   8962.95
Epoch                              57
-----------------------------  ----------------
2023-08-31 14:27:58.449767 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size             296000
trainer/QF1 Loss                   11.628
trainer/QF2 Loss                   14.6492
trainer/Policy Loss               -71.7562
trainer/Q1 Predictions Mean        76.3298
trainer/Q1 Predictions Std         10.2281
trainer/Q1 Predictions Max        102.444
trainer/Q1 Predictions Min         15.6091
trainer/Q2 Predictions Mean        76.1689
trainer/Q2 Predictions Std         10.1931
trainer/Q2 Predictions Max        102.423
trainer/Q2 Predictions Min         13.8236
trainer/Q Targets Mean             75.7957
trainer/Q Targets Std              11.1901
trainer/Q Targets Max             101.39
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.15084
trainer/Log Pis Std                 3.53754
trainer/Log Pis Max                22.5611
trainer/Log Pis Min                -3.50102
trainer/Policy mu Mean             -0.112415
trainer/Policy mu Std               1.5203
trainer/Policy mu Max               3.68261
trainer/Policy mu Min              -4.60121
trainer/Policy log std Mean        -0.785397
trainer/Policy log std Std          0.327643
trainer/Policy log std Max          0.11669
trainer/Policy log std Min         -2.25794
trainer/Alpha                       0.0291745
trainer/Alpha Loss                  0.533175
exploration/num steps total    296000
exploration/num paths total      1201
exploration/path length Mean      454.545
exploration/path length Std       123.774
exploration/path length Max       500
exploration/path length Min        68
exploration/Rewards Mean            0.00131291
exploration/Rewards Std             0.00672457
exploration/Rewards Max             0.0615592
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.596778
exploration/Returns Std             0.281739
exploration/Returns Max             1.31828
exploration/Returns Min             0.254825
exploration/Actions Mean            0.0013796
exploration/Actions Std             0.446223
exploration/Actions Max             0.998526
exploration/Actions Min            -0.999576
exploration/Num Paths              11
exploration/Average Returns         0.596778
evaluation/num steps total     291077
evaluation/num paths total       1141
evaluation/path length Mean       475.5
evaluation/path length Std         73.5
evaluation/path length Max        500
evaluation/path length Min        255
evaluation/Rewards Mean             0.00132298
evaluation/Rewards Std              0.00698478
evaluation/Rewards Max              0.0613858
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.629075
evaluation/Returns Std              0.32999
evaluation/Returns Max              1.18623
evaluation/Returns Min             -0.00123275
evaluation/ExplReturns Mean         0.629075
evaluation/ExplReturns Std          0.32999
evaluation/ExplReturns Max          1.18623
evaluation/ExplReturns Min         -0.00123275
evaluation/Actions Mean             0.00230298
evaluation/Actions Std              0.39278
evaluation/Actions Max              0.999603
evaluation/Actions Min             -0.994078
evaluation/Num Paths               10
evaluation/Average Returns          0.629075
time/data storing (s)               0.0290078
time/evaluation sampling (s)       68.5129
time/exploration sampling (s)      73.1821
time/logging (s)                    0.0244478
time/saving (s)                     0.070019
time/training (s)                  10.8265
time/epoch (s)                    152.645
time/total (s)                   9115.6
Epoch                              58
-----------------------------  ---------------
2023-08-31 14:30:30.273085 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size             301000
trainer/QF1 Loss                    1.45736
trainer/QF2 Loss                    1.54926
trainer/Policy Loss               -74.1353
trainer/Q1 Predictions Mean        79.0187
trainer/Q1 Predictions Std         10.5662
trainer/Q1 Predictions Max        101.535
trainer/Q1 Predictions Min          0.833969
trainer/Q2 Predictions Mean        79.0159
trainer/Q2 Predictions Std         10.4193
trainer/Q2 Predictions Max        100.952
trainer/Q2 Predictions Min          0.804415
trainer/Q Targets Mean             79.2839
trainer/Q Targets Std              10.4644
trainer/Q Targets Max             100.564
trainer/Q Targets Min               0.0457079
trainer/Log Pis Mean                6.31484
trainer/Log Pis Std                 4.60275
trainer/Log Pis Max                25.5143
trainer/Log Pis Min                -5.37894
trainer/Policy mu Mean              0.148283
trainer/Policy mu Std               1.57258
trainer/Policy mu Max               5.32221
trainer/Policy mu Min              -5.30601
trainer/Policy log std Mean        -0.79552
trainer/Policy log std Std          0.349721
trainer/Policy log std Max          0.21383
trainer/Policy log std Min         -2.4374
trainer/Alpha                       0.0282212
trainer/Alpha Loss                  1.12329
exploration/num steps total    301000
exploration/num paths total      1222
exploration/path length Mean      238.095
exploration/path length Std        61.0027
exploration/path length Max       392
exploration/path length Min       119
exploration/Rewards Mean            0.00333817
exploration/Rewards Std             0.0197447
exploration/Rewards Max             0.0441265
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.794803
exploration/Returns Std             0.550883
exploration/Returns Max             2.08808
exploration/Returns Min             0.194884
exploration/Actions Mean           -0.02067
exploration/Actions Std             0.517475
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              21
exploration/Average Returns         0.794803
evaluation/num steps total     296056
evaluation/num paths total       1163
evaluation/path length Mean       226.318
evaluation/path length Std         56.2691
evaluation/path length Max        369
evaluation/path length Min        162
evaluation/Rewards Mean             0.00311235
evaluation/Rewards Std              0.0203954
evaluation/Rewards Max              0.0499327
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.704382
evaluation/Returns Std              0.325402
evaluation/Returns Max              1.34631
evaluation/Returns Min              0.198396
evaluation/ExplReturns Mean         0.704382
evaluation/ExplReturns Std          0.325402
evaluation/ExplReturns Max          1.34631
evaluation/ExplReturns Min          0.198396
evaluation/Actions Mean            -0.0227086
evaluation/Actions Std              0.392124
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               22
evaluation/Average Returns          0.704382
time/data storing (s)               0.0288869
time/evaluation sampling (s)       68.2142
time/exploration sampling (s)      73.0968
time/logging (s)                    0.0249685
time/saving (s)                     0.067503
time/training (s)                  10.3878
time/epoch (s)                    151.82
time/total (s)                   9267.42
Epoch                              59
-----------------------------  ---------------
2023-08-31 14:33:08.386583 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 60 finished
-----------------------------  ----------------
replay_buffer/size             306000
trainer/QF1 Loss                    1.72739
trainer/QF2 Loss                    1.44261
trainer/Policy Loss               -75.4736
trainer/Q1 Predictions Mean        80.0737
trainer/Q1 Predictions Std          9.05995
trainer/Q1 Predictions Max         97.8743
trainer/Q1 Predictions Min         39.1655
trainer/Q2 Predictions Mean        80.2442
trainer/Q2 Predictions Std          9.03584
trainer/Q2 Predictions Max         98.783
trainer/Q2 Predictions Min         39.3243
trainer/Q Targets Mean             80.4025
trainer/Q Targets Std               9.3051
trainer/Q Targets Max              99.6955
trainer/Q Targets Min              37.2669
trainer/Log Pis Mean                5.79652
trainer/Log Pis Std                 3.85062
trainer/Log Pis Max                21.751
trainer/Log Pis Min                -3.17642
trainer/Policy mu Mean              0.0908982
trainer/Policy mu Std               1.523
trainer/Policy mu Max               5.56257
trainer/Policy mu Min              -5.22269
trainer/Policy log std Mean        -0.805446
trainer/Policy log std Std          0.351162
trainer/Policy log std Max          0.399054
trainer/Policy log std Min         -2.18517
trainer/Alpha                       0.0270518
trainer/Alpha Loss                 -0.734508
exploration/num steps total    306000
exploration/num paths total      1240
exploration/path length Mean      277.778
exploration/path length Std       111.484
exploration/path length Max       500
exploration/path length Min       107
exploration/Rewards Mean            0.0011971
exploration/Rewards Std             0.017225
exploration/Rewards Max             0.0534836
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.332529
exploration/Returns Std             0.158479
exploration/Returns Max             0.685686
exploration/Returns Min             0.0416559
exploration/Actions Mean           -0.025124
exploration/Actions Std             0.47892
exploration/Actions Max             0.999871
exploration/Actions Min            -0.999805
exploration/Num Paths              18
exploration/Average Returns         0.332529
evaluation/num steps total     301056
evaluation/num paths total       1173
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00200519
evaluation/Rewards Std              0.00475756
evaluation/Rewards Max              0.0586376
evaluation/Rewards Min              1.21178e-06
evaluation/Returns Mean             1.0026
evaluation/Returns Std              0.417121
evaluation/Returns Max              1.58065
evaluation/Returns Min              0.331052
evaluation/ExplReturns Mean         1.0026
evaluation/ExplReturns Std          0.417121
evaluation/ExplReturns Max          1.58065
evaluation/ExplReturns Min          0.331052
evaluation/Actions Mean             0.00854658
evaluation/Actions Std              0.189307
evaluation/Actions Max              0.993679
evaluation/Actions Min             -0.978763
evaluation/Num Paths               10
evaluation/Average Returns          1.0026
time/data storing (s)               0.0289126
time/evaluation sampling (s)       68.5541
time/exploration sampling (s)      74.0757
time/logging (s)                    0.0251054
time/saving (s)                     0.0629795
time/training (s)                  15.363
time/epoch (s)                    158.11
time/total (s)                   9425.53
Epoch                              60
-----------------------------  ----------------
2023-08-31 14:35:40.472658 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 61 finished
-----------------------------  ----------------
replay_buffer/size             311000
trainer/QF1 Loss                    1.75218
trainer/QF2 Loss                    1.87353
trainer/Policy Loss               -78.4563
trainer/Q1 Predictions Mean        82.6073
trainer/Q1 Predictions Std          9.40706
trainer/Q1 Predictions Max         99.3471
trainer/Q1 Predictions Min          2.69913
trainer/Q2 Predictions Mean        83.0059
trainer/Q2 Predictions Std          9.38222
trainer/Q2 Predictions Max         99.3482
trainer/Q2 Predictions Min          0.715572
trainer/Q Targets Mean             82.5473
trainer/Q Targets Std               9.30144
trainer/Q Targets Max              98.1887
trainer/Q Targets Min               1.872
trainer/Log Pis Mean                5.33425
trainer/Log Pis Std                 3.5503
trainer/Log Pis Max                16.5308
trainer/Log Pis Min                -5.54656
trainer/Policy mu Mean              0.0706238
trainer/Policy mu Std               1.44069
trainer/Policy mu Max               3.64652
trainer/Policy mu Min              -4.95415
trainer/Policy log std Mean        -0.863519
trainer/Policy log std Std          0.367913
trainer/Policy log std Max          0.102595
trainer/Policy log std Min         -2.26226
trainer/Alpha                       0.0245397
trainer/Alpha Loss                 -2.46808
exploration/num steps total    311000
exploration/num paths total      1250
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00137137
exploration/Rewards Std             0.00416942
exploration/Rewards Max             0.0528885
exploration/Rewards Min             3.22342e-05
exploration/Returns Mean            0.685685
exploration/Returns Std             0.227556
exploration/Returns Max             1.13221
exploration/Returns Min             0.334854
exploration/Actions Mean           -0.0014754
exploration/Actions Std             0.463976
exploration/Actions Max             0.996308
exploration/Actions Min            -0.995552
exploration/Num Paths              10
exploration/Average Returns         0.685685
evaluation/num steps total     306056
evaluation/num paths total       1183
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00159972
evaluation/Rewards Std              0.00371722
evaluation/Rewards Max              0.0455231
evaluation/Rewards Min              0.000201632
evaluation/Returns Mean             0.799858
evaluation/Returns Std              0.293223
evaluation/Returns Max              1.29744
evaluation/Returns Min              0.386542
evaluation/ExplReturns Mean         0.799858
evaluation/ExplReturns Std          0.293223
evaluation/ExplReturns Max          1.29744
evaluation/ExplReturns Min          0.386542
evaluation/Actions Mean            -0.000809093
evaluation/Actions Std              0.172825
evaluation/Actions Max              0.988342
evaluation/Actions Min             -0.952724
evaluation/Num Paths               10
evaluation/Average Returns          0.799858
time/data storing (s)               0.0290119
time/evaluation sampling (s)       68.249
time/exploration sampling (s)      72.9698
time/logging (s)                    0.0260955
time/saving (s)                     0.0647047
time/training (s)                  10.7447
time/epoch (s)                    152.083
time/total (s)                   9577.62
Epoch                              61
-----------------------------  ----------------
2023-08-31 14:38:12.115231 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size             316000
trainer/QF1 Loss                    2.04956
trainer/QF2 Loss                    2.3148
trainer/Policy Loss               -78.0012
trainer/Q1 Predictions Mean        82.6383
trainer/Q1 Predictions Std          9.45541
trainer/Q1 Predictions Max         97.6013
trainer/Q1 Predictions Min         -6.40583
trainer/Q2 Predictions Mean        82.5556
trainer/Q2 Predictions Std          9.19538
trainer/Q2 Predictions Max         97.0795
trainer/Q2 Predictions Min          0.726601
trainer/Q Targets Mean             82.3986
trainer/Q Targets Std               9.70357
trainer/Q Targets Max              97.1537
trainer/Q Targets Min             -15.5673
trainer/Log Pis Mean                5.72877
trainer/Log Pis Std                 3.79695
trainer/Log Pis Max                20.1009
trainer/Log Pis Min                -5.07102
trainer/Policy mu Mean              0.0584296
trainer/Policy mu Std               1.44572
trainer/Policy mu Max               4.02697
trainer/Policy mu Min              -5.82992
trainer/Policy log std Mean        -0.895034
trainer/Policy log std Std          0.371967
trainer/Policy log std Max          0.354149
trainer/Policy log std Min         -2.47426
trainer/Alpha                       0.0227996
trainer/Alpha Loss                 -1.02551
exploration/num steps total    316000
exploration/num paths total      1261
exploration/path length Mean      454.545
exploration/path length Std       100.938
exploration/path length Max       500
exploration/path length Min       180
exploration/Rewards Mean            0.00137403
exploration/Rewards Std             0.00648357
exploration/Rewards Max             0.050424
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.624559
exploration/Returns Std             0.126284
exploration/Returns Max             0.864688
exploration/Returns Min             0.398846
exploration/Actions Mean           -0.00364233
exploration/Actions Std             0.39068
exploration/Actions Max             0.99995
exploration/Actions Min            -0.999001
exploration/Num Paths              11
exploration/Average Returns         0.624559
evaluation/num steps total     310830
evaluation/num paths total       1193
evaluation/path length Mean       477.4
evaluation/path length Std         67.8
evaluation/path length Max        500
evaluation/path length Min        274
evaluation/Rewards Mean             0.00119191
evaluation/Rewards Std              0.00616771
evaluation/Rewards Max              0.051244
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.569019
evaluation/Returns Std              0.170271
evaluation/Returns Max              0.895822
evaluation/Returns Min              0.347502
evaluation/ExplReturns Mean         0.569019
evaluation/ExplReturns Std          0.170271
evaluation/ExplReturns Max          0.895822
evaluation/ExplReturns Min          0.347502
evaluation/Actions Mean             0.00527829
evaluation/Actions Std              0.221782
evaluation/Actions Max              0.99994
evaluation/Actions Min             -0.997133
evaluation/Num Paths               10
evaluation/Average Returns          0.569019
time/data storing (s)               0.0290405
time/evaluation sampling (s)       68.2477
time/exploration sampling (s)      72.7748
time/logging (s)                    0.0246124
time/saving (s)                     0.0700173
time/training (s)                  10.4912
time/epoch (s)                    151.637
time/total (s)                   9729.26
Epoch                              62
-----------------------------  ---------------
2023-08-31 14:40:47.980955 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             321000
trainer/QF1 Loss                    2.24185
trainer/QF2 Loss                    2.98104
trainer/Policy Loss               -76.3404
trainer/Q1 Predictions Mean        81.8358
trainer/Q1 Predictions Std          8.88246
trainer/Q1 Predictions Max         94.3987
trainer/Q1 Predictions Min         13.0471
trainer/Q2 Predictions Mean        81.3383
trainer/Q2 Predictions Std          9.37568
trainer/Q2 Predictions Max         93.722
trainer/Q2 Predictions Min          2.14478
trainer/Q Targets Mean             82.0093
trainer/Q Targets Std               9.4404
trainer/Q Targets Max              95.6406
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.29583
trainer/Log Pis Std                 4.0172
trainer/Log Pis Max                28.1747
trainer/Log Pis Min                -4.34652
trainer/Policy mu Mean             -0.0365195
trainer/Policy mu Std               1.5315
trainer/Policy mu Max               5.46131
trainer/Policy mu Min              -5.10834
trainer/Policy log std Mean        -0.873236
trainer/Policy log std Std          0.390496
trainer/Policy log std Max          0.540857
trainer/Policy log std Min         -2.74254
trainer/Alpha                       0.0214407
trainer/Alpha Loss                  1.13674
exploration/num steps total    321000
exploration/num paths total      1273
exploration/path length Mean      416.667
exploration/path length Std       107.378
exploration/path length Max       500
exploration/path length Min       176
exploration/Rewards Mean            0.00144399
exploration/Rewards Std             0.00987462
exploration/Rewards Max             0.0499545
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.601664
exploration/Returns Std             0.337846
exploration/Returns Max             1.16851
exploration/Returns Min             0.155365
exploration/Actions Mean           -0.0658391
exploration/Actions Std             0.458116
exploration/Actions Max             0.999397
exploration/Actions Min            -0.999956
exploration/Num Paths              12
exploration/Average Returns         0.601664
evaluation/num steps total     315479
evaluation/num paths total       1204
evaluation/path length Mean       422.636
evaluation/path length Std        118.086
evaluation/path length Max        500
evaluation/path length Min        200
evaluation/Rewards Mean             0.00154581
evaluation/Rewards Std              0.0104428
evaluation/Rewards Max              0.0544462
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.653315
evaluation/Returns Std              0.312736
evaluation/Returns Max              1.11139
evaluation/Returns Min              0.0933608
evaluation/ExplReturns Mean         0.653315
evaluation/ExplReturns Std          0.312736
evaluation/ExplReturns Max          1.11139
evaluation/ExplReturns Min          0.0933608
evaluation/Actions Mean            -0.0661067
evaluation/Actions Std              0.40819
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               11
evaluation/Average Returns          0.653315
time/data storing (s)               0.0291111
time/evaluation sampling (s)       68.4263
time/exploration sampling (s)      74.243
time/logging (s)                    0.0241894
time/saving (s)                     0.0672069
time/training (s)                  13.0718
time/epoch (s)                    155.862
time/total (s)                   9885.13
Epoch                              63
-----------------------------  ---------------
2023-08-31 14:43:24.180587 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 64 finished
-----------------------------  ----------------
replay_buffer/size             326000
trainer/QF1 Loss                    4.0475
trainer/QF2 Loss                    6.88366
trainer/Policy Loss               -76.5684
trainer/Q1 Predictions Mean        81.1557
trainer/Q1 Predictions Std          8.69235
trainer/Q1 Predictions Max         91.8471
trainer/Q1 Predictions Min        -10.4671
trainer/Q2 Predictions Mean        81.5314
trainer/Q2 Predictions Std          8.67157
trainer/Q2 Predictions Max         91.0124
trainer/Q2 Predictions Min        -12.0231
trainer/Q Targets Mean             81.3767
trainer/Q Targets Std               9.01418
trainer/Q Targets Max              91.5075
trainer/Q Targets Min              -3.63093
trainer/Log Pis Mean                5.52578
trainer/Log Pis Std                 4.31444
trainer/Log Pis Max                37.2578
trainer/Log Pis Min                -5.78646
trainer/Policy mu Mean             -0.0347233
trainer/Policy mu Std               1.44227
trainer/Policy mu Max               5.44577
trainer/Policy mu Min              -5.55868
trainer/Policy log std Mean        -0.900566
trainer/Policy log std Std          0.434887
trainer/Policy log std Max          0.223572
trainer/Policy log std Min         -2.97397
trainer/Alpha                       0.0210304
trainer/Alpha Loss                 -1.83135
exploration/num steps total    326000
exploration/num paths total      1283
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0037569
exploration/Rewards Std             0.00616681
exploration/Rewards Max             0.0426725
exploration/Rewards Min             3.27617e-07
exploration/Returns Mean            1.87845
exploration/Returns Std             1.07341
exploration/Returns Max             4.41064
exploration/Returns Min             0.914649
exploration/Actions Mean           -0.0131129
exploration/Actions Std             0.456959
exploration/Actions Max             0.999415
exploration/Actions Min            -0.999589
exploration/Num Paths              10
exploration/Average Returns         1.87845
evaluation/num steps total     320479
evaluation/num paths total       1214
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0182699
evaluation/Rewards Std              0.0106179
evaluation/Rewards Max              0.0455812
evaluation/Rewards Min              0.00508571
evaluation/Returns Mean             9.13493
evaluation/Returns Std              4.19107
evaluation/Returns Max             16.0402
evaluation/Returns Min              3.32543
evaluation/ExplReturns Mean         9.13493
evaluation/ExplReturns Std          4.19107
evaluation/ExplReturns Max         16.0402
evaluation/ExplReturns Min          3.32543
evaluation/Actions Mean             0.00116939
evaluation/Actions Std              0.201225
evaluation/Actions Max              0.98242
evaluation/Actions Min             -0.979479
evaluation/Num Paths               10
evaluation/Average Returns          9.13493
time/data storing (s)               0.0288228
time/evaluation sampling (s)       68.5267
time/exploration sampling (s)      73.7978
time/logging (s)                    0.0255288
time/saving (s)                     0.0773617
time/training (s)                  13.7409
time/epoch (s)                    156.197
time/total (s)                  10041.3
Epoch                              64
-----------------------------  ----------------
2023-08-31 14:45:56.302421 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 65 finished
-----------------------------  ----------------
replay_buffer/size             331000
trainer/QF1 Loss                    1.08641
trainer/QF2 Loss                    1.09985
trainer/Policy Loss               -77.2967
trainer/Q1 Predictions Mean        82.2723
trainer/Q1 Predictions Std          4.32351
trainer/Q1 Predictions Max         92.8477
trainer/Q1 Predictions Min         59.0708
trainer/Q2 Predictions Mean        81.7182
trainer/Q2 Predictions Std          4.29336
trainer/Q2 Predictions Max         91.8534
trainer/Q2 Predictions Min         62.9996
trainer/Q Targets Mean             81.808
trainer/Q Targets Std               4.12432
trainer/Q Targets Max              92.3446
trainer/Q Targets Min              62.7384
trainer/Log Pis Mean                5.60312
trainer/Log Pis Std                 4.19031
trainer/Log Pis Max                22.5621
trainer/Log Pis Min                -6.31266
trainer/Policy mu Mean             -0.0153388
trainer/Policy mu Std               1.43799
trainer/Policy mu Max               5.23215
trainer/Policy mu Min              -3.97785
trainer/Policy log std Mean        -0.905477
trainer/Policy log std Std          0.405123
trainer/Policy log std Max          0.478696
trainer/Policy log std Min         -2.56636
trainer/Alpha                       0.0186032
trainer/Alpha Loss                 -1.58128
exploration/num steps total    331000
exploration/num paths total      1293
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00212386
exploration/Rewards Std             0.00443118
exploration/Rewards Max             0.0513948
exploration/Rewards Min             6.85931e-05
exploration/Returns Mean            1.06193
exploration/Returns Std             0.502409
exploration/Returns Max             2.06507
exploration/Returns Min             0.573573
exploration/Actions Mean            0.00826051
exploration/Actions Std             0.472668
exploration/Actions Max             0.998266
exploration/Actions Min            -0.998927
exploration/Num Paths              10
exploration/Average Returns         1.06193
evaluation/num steps total     325479
evaluation/num paths total       1224
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00282911
evaluation/Rewards Std              0.00537849
evaluation/Rewards Max              0.0457553
evaluation/Rewards Min              0.000926339
evaluation/Returns Mean             1.41456
evaluation/Returns Std              0.378678
evaluation/Returns Max              1.99023
evaluation/Returns Min              0.806134
evaluation/ExplReturns Mean         1.41456
evaluation/ExplReturns Std          0.378678
evaluation/ExplReturns Max          1.99023
evaluation/ExplReturns Min          0.806134
evaluation/Actions Mean             0.00710501
evaluation/Actions Std              0.22363
evaluation/Actions Max              0.992555
evaluation/Actions Min             -0.997196
evaluation/Num Paths               10
evaluation/Average Returns          1.41456
time/data storing (s)               0.0286262
time/evaluation sampling (s)       68.447
time/exploration sampling (s)      73.3509
time/logging (s)                    0.0252618
time/saving (s)                     0.0512538
time/training (s)                  10.2148
time/epoch (s)                    152.118
time/total (s)                  10193.4
Epoch                              65
-----------------------------  ----------------
2023-08-31 14:48:31.176026 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size             336000
trainer/QF1 Loss                    7.03255
trainer/QF2 Loss                    7.32336
trainer/Policy Loss               -74.2784
trainer/Q1 Predictions Mean        79.5163
trainer/Q1 Predictions Std          8.08915
trainer/Q1 Predictions Max         94.0835
trainer/Q1 Predictions Min          5.87602
trainer/Q2 Predictions Mean        79.5131
trainer/Q2 Predictions Std          8.1165
trainer/Q2 Predictions Max         92.5263
trainer/Q2 Predictions Min          9.30417
trainer/Q Targets Mean             79.3456
trainer/Q Targets Std               8.1713
trainer/Q Targets Max              92.3349
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.96785
trainer/Log Pis Std                 4.40017
trainer/Log Pis Max                26.6866
trainer/Log Pis Min                -4.64388
trainer/Policy mu Mean             -0.102997
trainer/Policy mu Std               1.46587
trainer/Policy mu Max               6.38623
trainer/Policy mu Min              -4.22058
trainer/Policy log std Mean        -0.906155
trainer/Policy log std Std          0.429241
trainer/Policy log std Max         -0.0603232
trainer/Policy log std Min         -2.65032
trainer/Alpha                       0.0172711
trainer/Alpha Loss                 -0.130499
exploration/num steps total    336000
exploration/num paths total      1311
exploration/path length Mean      277.778
exploration/path length Std       145.177
exploration/path length Max       500
exploration/path length Min       119
exploration/Rewards Mean            0.00991368
exploration/Rewards Std             0.018313
exploration/Rewards Max             0.0617871
exploration/Rewards Min            -0.281611
exploration/Returns Mean            2.7538
exploration/Returns Std             1.81042
exploration/Returns Max             8.16609
exploration/Returns Min             0.784578
exploration/Actions Mean            0.038178
exploration/Actions Std             0.537821
exploration/Actions Max             0.999776
exploration/Actions Min            -0.999848
exploration/Num Paths              18
exploration/Average Returns         2.7538
evaluation/num steps total     330473
evaluation/num paths total       1242
evaluation/path length Mean       277.444
evaluation/path length Std        178.008
evaluation/path length Max        500
evaluation/path length Min        112
evaluation/Rewards Mean             0.00851476
evaluation/Rewards Std              0.0157522
evaluation/Rewards Max              0.0498488
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             2.36237
evaluation/Returns Std              1.50621
evaluation/Returns Max              7.52753
evaluation/Returns Min              0.847194
evaluation/ExplReturns Mean         2.36237
evaluation/ExplReturns Std          1.50621
evaluation/ExplReturns Max          7.52753
evaluation/ExplReturns Min          0.847194
evaluation/Actions Mean             0.0167439
evaluation/Actions Std              0.377832
evaluation/Actions Max              0.9988
evaluation/Actions Min             -0.998661
evaluation/Num Paths               18
evaluation/Average Returns          2.36237
time/data storing (s)               0.0289371
time/evaluation sampling (s)       68.4484
time/exploration sampling (s)      74.7528
time/logging (s)                    0.0250369
time/saving (s)                     0.0640694
time/training (s)                  11.5503
time/epoch (s)                    154.87
time/total (s)                  10348.3
Epoch                              66
-----------------------------  ---------------
2023-08-31 14:51:03.796156 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 67 finished
-----------------------------  ----------------
replay_buffer/size             341000
trainer/QF1 Loss                    0.876465
trainer/QF2 Loss                    1.46066
trainer/Policy Loss               -72.9465
trainer/Q1 Predictions Mean        78.2148
trainer/Q1 Predictions Std          6.05475
trainer/Q1 Predictions Max         93.4106
trainer/Q1 Predictions Min         26.0563
trainer/Q2 Predictions Mean        78.2672
trainer/Q2 Predictions Std          5.99792
trainer/Q2 Predictions Max         94.1622
trainer/Q2 Predictions Min         31.7687
trainer/Q Targets Mean             78.5033
trainer/Q Targets Std               5.76678
trainer/Q Targets Max              94.0816
trainer/Q Targets Min              31.3098
trainer/Log Pis Mean                6.06954
trainer/Log Pis Std                 4.19962
trainer/Log Pis Max                30.6965
trainer/Log Pis Min                -4.65694
trainer/Policy mu Mean             -0.248719
trainer/Policy mu Std               1.46469
trainer/Policy mu Max               4.67293
trainer/Policy mu Min              -5.51499
trainer/Policy log std Mean        -0.914111
trainer/Policy log std Std          0.430237
trainer/Policy log std Max          0.182251
trainer/Policy log std Min         -2.40844
trainer/Alpha                       0.0168069
trainer/Alpha Loss                  0.284127
exploration/num steps total    341000
exploration/num paths total      1321
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00256319
exploration/Rewards Std             0.00589361
exploration/Rewards Max             0.0671553
exploration/Rewards Min             5.30589e-05
exploration/Returns Mean            1.2816
exploration/Returns Std             0.642716
exploration/Returns Max             2.46708
exploration/Returns Min             0.487596
exploration/Actions Mean            0.00415002
exploration/Actions Std             0.493584
exploration/Actions Max             0.999845
exploration/Actions Min            -0.999714
exploration/Num Paths              10
exploration/Average Returns         1.2816
evaluation/num steps total     335473
evaluation/num paths total       1252
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00268869
evaluation/Rewards Std              0.00618985
evaluation/Rewards Max              0.0577794
evaluation/Rewards Min              5.64268e-05
evaluation/Returns Mean             1.34435
evaluation/Returns Std              0.685277
evaluation/Returns Max              2.46859
evaluation/Returns Min              0.378908
evaluation/ExplReturns Mean         1.34435
evaluation/ExplReturns Std          0.685277
evaluation/ExplReturns Max          2.46859
evaluation/ExplReturns Min          0.378908
evaluation/Actions Mean            -0.00216045
evaluation/Actions Std              0.224863
evaluation/Actions Max              0.998554
evaluation/Actions Min             -0.993679
evaluation/Num Paths               10
evaluation/Average Returns          1.34435
time/data storing (s)               0.0287628
time/evaluation sampling (s)       68.3128
time/exploration sampling (s)      73.7802
time/logging (s)                    0.0253928
time/saving (s)                     0.0585036
time/training (s)                  10.411
time/epoch (s)                    152.617
time/total (s)                  10500.9
Epoch                              67
-----------------------------  ----------------
2023-08-31 14:53:38.585954 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 68 finished
-----------------------------  ----------------
replay_buffer/size             346000
trainer/QF1 Loss                    1.32147
trainer/QF2 Loss                    1.55306
trainer/Policy Loss               -71.5028
trainer/Q1 Predictions Mean        76.7374
trainer/Q1 Predictions Std          6.72833
trainer/Q1 Predictions Max         90.6028
trainer/Q1 Predictions Min          9.32993
trainer/Q2 Predictions Mean        77.2588
trainer/Q2 Predictions Std          6.82274
trainer/Q2 Predictions Max         91.7115
trainer/Q2 Predictions Min          6.58181
trainer/Q Targets Mean             76.7382
trainer/Q Targets Std               7.17871
trainer/Q Targets Max              90.3865
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.1852
trainer/Log Pis Std                 3.98401
trainer/Log Pis Max                21.3139
trainer/Log Pis Min                -6.09934
trainer/Policy mu Mean             -0.290021
trainer/Policy mu Std               1.45521
trainer/Policy mu Max               4.01538
trainer/Policy mu Min              -5.38296
trainer/Policy log std Mean        -0.923767
trainer/Policy log std Std          0.446182
trainer/Policy log std Max          0.0574778
trainer/Policy log std Min         -2.61661
trainer/Alpha                       0.0184242
trainer/Alpha Loss                  0.739688
exploration/num steps total    346000
exploration/num paths total      1331
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0021453
exploration/Rewards Std             0.00457372
exploration/Rewards Max             0.0435812
exploration/Rewards Min             0.000114627
exploration/Returns Mean            1.07265
exploration/Returns Std             0.390209
exploration/Returns Max             1.94341
exploration/Returns Min             0.536859
exploration/Actions Mean           -0.00190823
exploration/Actions Std             0.532547
exploration/Actions Max             0.999967
exploration/Actions Min            -0.999931
exploration/Num Paths              10
exploration/Average Returns         1.07265
evaluation/num steps total     340473
evaluation/num paths total       1262
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00249699
evaluation/Rewards Std              0.00586329
evaluation/Rewards Max              0.0558414
evaluation/Rewards Min              0.000131661
evaluation/Returns Mean             1.2485
evaluation/Returns Std              1.00286
evaluation/Returns Max              4.13863
evaluation/Returns Min              0.536307
evaluation/ExplReturns Mean         1.2485
evaluation/ExplReturns Std          1.00286
evaluation/ExplReturns Max          4.13863
evaluation/ExplReturns Min          0.536307
evaluation/Actions Mean             0.0101638
evaluation/Actions Std              0.379342
evaluation/Actions Max              0.996111
evaluation/Actions Min             -0.999712
evaluation/Num Paths               10
evaluation/Average Returns          1.2485
time/data storing (s)               0.0287809
time/evaluation sampling (s)       68.001
time/exploration sampling (s)      74.3659
time/logging (s)                    0.0264108
time/saving (s)                     0.0881588
time/training (s)                  12.2768
time/epoch (s)                    154.787
time/total (s)                  10655.7
Epoch                              68
-----------------------------  ----------------
2023-08-31 14:56:18.806228 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 69 finished
-----------------------------  ----------------
replay_buffer/size             351000
trainer/QF1 Loss                    1.8353
trainer/QF2 Loss                    1.75752
trainer/Policy Loss               -70.3702
trainer/Q1 Predictions Mean        75.274
trainer/Q1 Predictions Std          8.05025
trainer/Q1 Predictions Max         92.4153
trainer/Q1 Predictions Min          1.01788
trainer/Q2 Predictions Mean        75.8432
trainer/Q2 Predictions Std          7.85898
trainer/Q2 Predictions Max         94.5767
trainer/Q2 Predictions Min          7.76111
trainer/Q Targets Mean             75.9914
trainer/Q Targets Std               8.0892
trainer/Q Targets Max              93.0577
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.94918
trainer/Log Pis Std                 4.47424
trainer/Log Pis Max                25.8987
trainer/Log Pis Min                -6.47856
trainer/Policy mu Mean             -0.140578
trainer/Policy mu Std               1.49213
trainer/Policy mu Max               4.57768
trainer/Policy mu Min              -6.67117
trainer/Policy log std Mean        -0.897345
trainer/Policy log std Std          0.402761
trainer/Policy log std Max          0.434412
trainer/Policy log std Min         -2.87928
trainer/Alpha                       0.0168091
trainer/Alpha Loss                 -0.207656
exploration/num steps total    351000
exploration/num paths total      1341
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.029261
exploration/Rewards Std             0.0140578
exploration/Rewards Max             0.0905771
exploration/Rewards Min             0.00424431
exploration/Returns Mean           14.6305
exploration/Returns Std             5.99834
exploration/Returns Max            26.8816
exploration/Returns Min             8.14843
exploration/Actions Mean            0.0047667
exploration/Actions Std             0.492143
exploration/Actions Max             0.999051
exploration/Actions Min            -0.997627
exploration/Num Paths              10
exploration/Average Returns        14.6305
evaluation/num steps total     345473
evaluation/num paths total       1272
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0300063
evaluation/Rewards Std              0.0158066
evaluation/Rewards Max              0.0903992
evaluation/Rewards Min              0.00221863
evaluation/Returns Mean            15.0032
evaluation/Returns Std              6.53288
evaluation/Returns Max             26.3087
evaluation/Returns Min              5.57518
evaluation/ExplReturns Mean        15.0032
evaluation/ExplReturns Std          6.53288
evaluation/ExplReturns Max         26.3087
evaluation/ExplReturns Min          5.57518
evaluation/Actions Mean             0.000943013
evaluation/Actions Std              0.30872
evaluation/Actions Max              0.996796
evaluation/Actions Min             -0.993439
evaluation/Num Paths               10
evaluation/Average Returns         15.0032
time/data storing (s)               0.0292789
time/evaluation sampling (s)       68.0101
time/exploration sampling (s)      75.1888
time/logging (s)                    0.0259745
time/saving (s)                     0.0640138
time/training (s)                  16.8978
time/epoch (s)                    160.216
time/total (s)                  10815.9
Epoch                              69
-----------------------------  ----------------
2023-08-31 14:58:56.408789 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size             356000
trainer/QF1 Loss                    2.83026
trainer/QF2 Loss                    2.52011
trainer/Policy Loss               -68.5706
trainer/Q1 Predictions Mean        73.963
trainer/Q1 Predictions Std          8.43569
trainer/Q1 Predictions Max         90.1722
trainer/Q1 Predictions Min          5.99884
trainer/Q2 Predictions Mean        74.3526
trainer/Q2 Predictions Std          8.54039
trainer/Q2 Predictions Max         90.1208
trainer/Q2 Predictions Min          5.00645
trainer/Q Targets Mean             74.2514
trainer/Q Targets Std               8.33184
trainer/Q Targets Max              90.6111
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.44356
trainer/Log Pis Std                 4.94459
trainer/Log Pis Max                26.2827
trainer/Log Pis Min                -5.26964
trainer/Policy mu Mean              0.0812574
trainer/Policy mu Std               1.55934
trainer/Policy mu Max               4.93075
trainer/Policy mu Min              -4.53935
trainer/Policy log std Mean        -0.898444
trainer/Policy log std Std          0.412708
trainer/Policy log std Max          0.144084
trainer/Policy log std Min         -2.71467
trainer/Alpha                       0.0186988
trainer/Alpha Loss                  1.76511
exploration/num steps total    356000
exploration/num paths total      1351
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.011259
exploration/Rewards Std             0.0107422
exploration/Rewards Max             0.055827
exploration/Rewards Min             7.95822e-05
exploration/Returns Mean            5.62951
exploration/Returns Std             4.23548
exploration/Returns Max            12.6697
exploration/Returns Min             0.428972
exploration/Actions Mean            0.0195958
exploration/Actions Std             0.452215
exploration/Actions Max             0.999514
exploration/Actions Min            -0.998481
exploration/Num Paths              10
exploration/Average Returns         5.62951
evaluation/num steps total     350473
evaluation/num paths total       1282
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00416681
evaluation/Rewards Std              0.00729837
evaluation/Rewards Max              0.0412892
evaluation/Rewards Min              7.84733e-05
evaluation/Returns Mean             2.08341
evaluation/Returns Std              2.53034
evaluation/Returns Max              9.16543
evaluation/Returns Min              0.537257
evaluation/ExplReturns Mean         2.08341
evaluation/ExplReturns Std          2.53034
evaluation/ExplReturns Max          9.16543
evaluation/ExplReturns Min          0.537257
evaluation/Actions Mean             0.0208786
evaluation/Actions Std              0.200658
evaluation/Actions Max              0.986092
evaluation/Actions Min             -0.987501
evaluation/Num Paths               10
evaluation/Average Returns          2.08341
time/data storing (s)               0.0290184
time/evaluation sampling (s)       68.2848
time/exploration sampling (s)      73.797
time/logging (s)                    0.0274154
time/saving (s)                     0.104285
time/training (s)                  15.3577
time/epoch (s)                    157.6
time/total (s)                  10973.5
Epoch                              70
-----------------------------  ----------------
2023-08-31 15:01:30.516285 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 71 finished
-----------------------------  ----------------
replay_buffer/size             361000
trainer/QF1 Loss                    1.85765
trainer/QF2 Loss                    1.84912
trainer/Policy Loss               -68.5237
trainer/Q1 Predictions Mean        73.7913
trainer/Q1 Predictions Std          6.9111
trainer/Q1 Predictions Max         83.2601
trainer/Q1 Predictions Min         32.6659
trainer/Q2 Predictions Mean        73.8983
trainer/Q2 Predictions Std          6.70782
trainer/Q2 Predictions Max         84.3875
trainer/Q2 Predictions Min         34.3445
trainer/Q Targets Mean             73.9126
trainer/Q Targets Std               6.69702
trainer/Q Targets Max              83.9328
trainer/Q Targets Min              27.241
trainer/Log Pis Mean                6.30612
trainer/Log Pis Std                 4.46806
trainer/Log Pis Max                20.9535
trainer/Log Pis Min                -6.77607
trainer/Policy mu Mean              0.0253236
trainer/Policy mu Std               1.50551
trainer/Policy mu Max               4.77701
trainer/Policy mu Min              -4.17781
trainer/Policy log std Mean        -0.911011
trainer/Policy log std Std          0.358871
trainer/Policy log std Max         -0.0605215
trainer/Policy log std Min         -2.25177
trainer/Alpha                       0.0184164
trainer/Alpha Loss                  1.22282
exploration/num steps total    361000
exploration/num paths total      1361
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00379271
exploration/Rewards Std             0.00512162
exploration/Rewards Max             0.0491094
exploration/Rewards Min             0.000888212
exploration/Returns Mean            1.89636
exploration/Returns Std             0.444898
exploration/Returns Max             2.81873
exploration/Returns Min             1.22703
exploration/Actions Mean            0.0177988
exploration/Actions Std             0.535885
exploration/Actions Max             0.99977
exploration/Actions Min            -0.999689
exploration/Num Paths              10
exploration/Average Returns         1.89636
evaluation/num steps total     355473
evaluation/num paths total       1292
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00359713
evaluation/Rewards Std              0.00480772
evaluation/Rewards Max              0.0465356
evaluation/Rewards Min              0.00169725
evaluation/Returns Mean             1.79856
evaluation/Returns Std              0.334272
evaluation/Returns Max              2.34973
evaluation/Returns Min              1.31514
evaluation/ExplReturns Mean         1.79856
evaluation/ExplReturns Std          0.334272
evaluation/ExplReturns Max          2.34973
evaluation/ExplReturns Min          1.31514
evaluation/Actions Mean             0.0115758
evaluation/Actions Std              0.203369
evaluation/Actions Max              0.997993
evaluation/Actions Min             -0.996456
evaluation/Num Paths               10
evaluation/Average Returns          1.79856
time/data storing (s)               0.0290426
time/evaluation sampling (s)       68.4536
time/exploration sampling (s)      74.5148
time/logging (s)                    0.0253035
time/saving (s)                     0.0784671
time/training (s)                  11.0003
time/epoch (s)                    154.102
time/total (s)                  11127.7
Epoch                              71
-----------------------------  ----------------
2023-08-31 15:04:06.190700 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 72 finished
-----------------------------  ----------------
replay_buffer/size             366000
trainer/QF1 Loss                    1.73256
trainer/QF2 Loss                    1.35528
trainer/Policy Loss               -68.5429
trainer/Q1 Predictions Mean        73.9518
trainer/Q1 Predictions Std          6.89496
trainer/Q1 Predictions Max         89.5076
trainer/Q1 Predictions Min         14.4977
trainer/Q2 Predictions Mean        73.8744
trainer/Q2 Predictions Std          6.69167
trainer/Q2 Predictions Max         88.9564
trainer/Q2 Predictions Min         21.5634
trainer/Q Targets Mean             73.7386
trainer/Q Targets Std               6.32412
trainer/Q Targets Max              89.1767
trainer/Q Targets Min              23.307
trainer/Log Pis Mean                6.05064
trainer/Log Pis Std                 4.55372
trainer/Log Pis Max                33.1086
trainer/Log Pis Min                -5.32733
trainer/Policy mu Mean             -0.122663
trainer/Policy mu Std               1.52762
trainer/Policy mu Max               4.85511
trainer/Policy mu Min              -9.22077
trainer/Policy log std Mean        -0.845995
trainer/Policy log std Std          0.361294
trainer/Policy log std Max          0.69886
trainer/Policy log std Min         -2.22447
trainer/Alpha                       0.0190003
trainer/Alpha Loss                  0.200695
exploration/num steps total    366000
exploration/num paths total      1371
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00115314
exploration/Rewards Std             0.00403119
exploration/Rewards Max             0.038969
exploration/Rewards Min             0.000115451
exploration/Returns Mean            0.57657
exploration/Returns Std             0.160342
exploration/Returns Max             0.748472
exploration/Returns Min             0.294207
exploration/Actions Mean            0.00190354
exploration/Actions Std             0.390375
exploration/Actions Max             0.999951
exploration/Actions Min            -0.999996
exploration/Num Paths              10
exploration/Average Returns         0.57657
evaluation/num steps total     360473
evaluation/num paths total       1302
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00130698
evaluation/Rewards Std              0.00474506
evaluation/Rewards Max              0.0469455
evaluation/Rewards Min              0.000165958
evaluation/Returns Mean             0.653492
evaluation/Returns Std              0.128698
evaluation/Returns Max              0.898349
evaluation/Returns Min              0.446974
evaluation/ExplReturns Mean         0.653492
evaluation/ExplReturns Std          0.128698
evaluation/ExplReturns Max          0.898349
evaluation/ExplReturns Min          0.446974
evaluation/Actions Mean             0.00634522
evaluation/Actions Std              0.22394
evaluation/Actions Max              0.999346
evaluation/Actions Min             -0.999712
evaluation/Num Paths               10
evaluation/Average Returns          0.653492
time/data storing (s)               0.0288531
time/evaluation sampling (s)       68.1154
time/exploration sampling (s)      75.9493
time/logging (s)                    0.0251876
time/saving (s)                     0.0677636
time/training (s)                  11.4839
time/epoch (s)                    155.67
time/total (s)                  11283.3
Epoch                              72
-----------------------------  ----------------
2023-08-31 15:06:39.420982 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 73 finished
-----------------------------  ----------------
replay_buffer/size             371000
trainer/QF1 Loss                    1.01883
trainer/QF2 Loss                    1.22312
trainer/Policy Loss               -67.2599
trainer/Q1 Predictions Mean        72.6914
trainer/Q1 Predictions Std          7.04303
trainer/Q1 Predictions Max         87.6
trainer/Q1 Predictions Min         23.8515
trainer/Q2 Predictions Mean        72.6323
trainer/Q2 Predictions Std          7.03949
trainer/Q2 Predictions Max         86.1448
trainer/Q2 Predictions Min         23.1623
trainer/Q Targets Mean             72.754
trainer/Q Targets Std               6.91195
trainer/Q Targets Max              86.8804
trainer/Q Targets Min              24.5574
trainer/Log Pis Mean                6.26858
trainer/Log Pis Std                 4.45501
trainer/Log Pis Max                35.1183
trainer/Log Pis Min                -4.87485
trainer/Policy mu Mean             -0.0457974
trainer/Policy mu Std               1.50337
trainer/Policy mu Max               5.42125
trainer/Policy mu Min              -5.25236
trainer/Policy log std Mean        -0.917245
trainer/Policy log std Std          0.384384
trainer/Policy log std Max          0.18125
trainer/Policy log std Min         -2.93347
trainer/Alpha                       0.0170224
trainer/Alpha Loss                  1.09396
exploration/num steps total    371000
exploration/num paths total      1384
exploration/path length Mean      384.615
exploration/path length Std       182.124
exploration/path length Max       500
exploration/path length Min        65
exploration/Rewards Mean            0.00439431
exploration/Rewards Std             0.00924777
exploration/Rewards Max             0.053139
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.69012
exploration/Returns Std             0.824431
exploration/Returns Max             2.80713
exploration/Returns Min             0.299185
exploration/Actions Mean            0.00104997
exploration/Actions Std             0.559575
exploration/Actions Max             0.99988
exploration/Actions Min            -0.999991
exploration/Num Paths              13
exploration/Average Returns         1.69012
evaluation/num steps total     365215
evaluation/num paths total       1315
evaluation/path length Mean       364.769
evaluation/path length Std        202.847
evaluation/path length Max        500
evaluation/path length Min         59
evaluation/Rewards Mean             0.00449162
evaluation/Rewards Std              0.0107845
evaluation/Rewards Max              0.057156
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.63841
evaluation/Returns Std              0.74195
evaluation/Returns Max              2.76765
evaluation/Returns Min              0.528214
evaluation/ExplReturns Mean         1.63841
evaluation/ExplReturns Std          0.74195
evaluation/ExplReturns Max          2.76765
evaluation/ExplReturns Min          0.528214
evaluation/Actions Mean            -0.000499985
evaluation/Actions Std              0.36728
evaluation/Actions Max              0.999734
evaluation/Actions Min             -0.999701
evaluation/Num Paths               13
evaluation/Average Returns          1.63841
time/data storing (s)               0.0293536
time/evaluation sampling (s)       68.2849
time/exploration sampling (s)      74.2958
time/logging (s)                    0.0250699
time/saving (s)                     0.0613625
time/training (s)                  10.5298
time/epoch (s)                    153.226
time/total (s)                  11436.6
Epoch                              73
-----------------------------  ----------------
2023-08-31 15:09:12.160442 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 74 finished
-----------------------------  ----------------
replay_buffer/size             376000
trainer/QF1 Loss                    3.01912
trainer/QF2 Loss                    4.57415
trainer/Policy Loss               -66.46
trainer/Q1 Predictions Mean        71.3724
trainer/Q1 Predictions Std          8.9185
trainer/Q1 Predictions Max         90.3661
trainer/Q1 Predictions Min         -5.31248
trainer/Q2 Predictions Mean        71.5663
trainer/Q2 Predictions Std          8.75145
trainer/Q2 Predictions Max         91.0335
trainer/Q2 Predictions Min         -4.20181
trainer/Q Targets Mean             71.5434
trainer/Q Targets Std               9.32991
trainer/Q Targets Max              90.8558
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.85837
trainer/Log Pis Std                 3.46891
trainer/Log Pis Max                18.5387
trainer/Log Pis Min                -3.13863
trainer/Policy mu Mean             -0.0547479
trainer/Policy mu Std               1.41546
trainer/Policy mu Max               4.32414
trainer/Policy mu Min              -3.79389
trainer/Policy log std Mean        -0.959716
trainer/Policy log std Std          0.37163
trainer/Policy log std Max         -0.134423
trainer/Policy log std Min         -2.47232
trainer/Alpha                       0.0158835
trainer/Alpha Loss                 -0.586678
exploration/num steps total    376000
exploration/num paths total      1394
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00587358
exploration/Rewards Std             0.00481833
exploration/Rewards Max             0.051433
exploration/Rewards Min             0.000175408
exploration/Returns Mean            2.93679
exploration/Returns Std             0.775353
exploration/Returns Max             3.97295
exploration/Returns Min             1.60719
exploration/Actions Mean            0.00411203
exploration/Actions Std             0.527115
exploration/Actions Max             0.999971
exploration/Actions Min            -0.999935
exploration/Num Paths              10
exploration/Average Returns         2.93679
evaluation/num steps total     370215
evaluation/num paths total       1325
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00454003
evaluation/Rewards Std              0.00421274
evaluation/Rewards Max              0.0452538
evaluation/Rewards Min              0.00016312
evaluation/Returns Mean             2.27001
evaluation/Returns Std              0.557307
evaluation/Returns Max              3.33988
evaluation/Returns Min              1.6858
evaluation/ExplReturns Mean         2.27001
evaluation/ExplReturns Std          0.557307
evaluation/ExplReturns Max          3.33988
evaluation/ExplReturns Min          1.6858
evaluation/Actions Mean            -0.00450937
evaluation/Actions Std              0.319918
evaluation/Actions Max              0.999958
evaluation/Actions Min             -0.999473
evaluation/Num Paths               10
evaluation/Average Returns          2.27001
time/data storing (s)               0.028961
time/evaluation sampling (s)       68.8809
time/exploration sampling (s)      73.5187
time/logging (s)                    0.0257354
time/saving (s)                     0.0655454
time/training (s)                  10.2164
time/epoch (s)                    152.736
time/total (s)                  11589.3
Epoch                              74
-----------------------------  ----------------
2023-08-31 15:11:47.838971 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 75 finished
-----------------------------  ----------------
replay_buffer/size             381000
trainer/QF1 Loss                    0.781509
trainer/QF2 Loss                    0.948138
trainer/Policy Loss               -66.0977
trainer/Q1 Predictions Mean        71.3901
trainer/Q1 Predictions Std          5.49102
trainer/Q1 Predictions Max         85.8821
trainer/Q1 Predictions Min         42.9559
trainer/Q2 Predictions Mean        70.9967
trainer/Q2 Predictions Std          5.39727
trainer/Q2 Predictions Max         85.3882
trainer/Q2 Predictions Min         44.1292
trainer/Q Targets Mean             71.2697
trainer/Q Targets Std               5.43855
trainer/Q Targets Max              86.4616
trainer/Q Targets Min              40.6959
trainer/Log Pis Mean                5.76021
trainer/Log Pis Std                 4.32191
trainer/Log Pis Max                26.6184
trainer/Log Pis Min                -4.75924
trainer/Policy mu Mean             -0.080447
trainer/Policy mu Std               1.40492
trainer/Policy mu Max               4.76332
trainer/Policy mu Min              -5.03062
trainer/Policy log std Mean        -1.01496
trainer/Policy log std Std          0.382586
trainer/Policy log std Max         -0.0311868
trainer/Policy log std Min         -2.32899
trainer/Alpha                       0.0138805
trainer/Alpha Loss                 -1.02561
exploration/num steps total    381000
exploration/num paths total      1404
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00825334
exploration/Rewards Std             0.00629535
exploration/Rewards Max             0.054038
exploration/Rewards Min             0.00142765
exploration/Returns Mean            4.12667
exploration/Returns Std             1.32024
exploration/Returns Max             6.34212
exploration/Returns Min             2.57589
exploration/Actions Mean            0.000600979
exploration/Actions Std             0.532293
exploration/Actions Max             0.999977
exploration/Actions Min            -0.999993
exploration/Num Paths              10
exploration/Average Returns         4.12667
evaluation/num steps total     375215
evaluation/num paths total       1335
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00884191
evaluation/Rewards Std              0.00727341
evaluation/Rewards Max              0.0704907
evaluation/Rewards Min              0.00176589
evaluation/Returns Mean             4.42095
evaluation/Returns Std              1.24519
evaluation/Returns Max              6.35026
evaluation/Returns Min              2.83237
evaluation/ExplReturns Mean         4.42095
evaluation/ExplReturns Std          1.24519
evaluation/ExplReturns Max          6.35026
evaluation/ExplReturns Min          2.83237
evaluation/Actions Mean             0.00532268
evaluation/Actions Std              0.373888
evaluation/Actions Max              0.998359
evaluation/Actions Min             -0.99951
evaluation/Num Paths               10
evaluation/Average Returns          4.42095
time/data storing (s)               0.0285721
time/evaluation sampling (s)       68.4262
time/exploration sampling (s)      73.6702
time/logging (s)                    0.0251004
time/saving (s)                     0.0663859
time/training (s)                  13.4576
time/epoch (s)                    155.674
time/total (s)                  11745
Epoch                              75
-----------------------------  ----------------
2023-08-31 15:14:19.947916 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 76 finished
-----------------------------  ----------------
replay_buffer/size             386000
trainer/QF1 Loss                    2.99473
trainer/QF2 Loss                    2.68706
trainer/Policy Loss               -63.9048
trainer/Q1 Predictions Mean        69.4695
trainer/Q1 Predictions Std          6.55532
trainer/Q1 Predictions Max         87.7393
trainer/Q1 Predictions Min         22.7088
trainer/Q2 Predictions Mean        69.3069
trainer/Q2 Predictions Std          6.85155
trainer/Q2 Predictions Max         87.7434
trainer/Q2 Predictions Min         21.2909
trainer/Q Targets Mean             69.4937
trainer/Q Targets Std               7.40861
trainer/Q Targets Max              86.828
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.13765
trainer/Log Pis Std                 4.37307
trainer/Log Pis Max                30.3885
trainer/Log Pis Min                -3.30617
trainer/Policy mu Mean              0.0342176
trainer/Policy mu Std               1.44956
trainer/Policy mu Max               5.04187
trainer/Policy mu Min              -6.15368
trainer/Policy log std Mean        -1.03862
trainer/Policy log std Std          0.407662
trainer/Policy log std Max          0.0917113
trainer/Policy log std Min         -2.69182
trainer/Alpha                       0.0131851
trainer/Alpha Loss                  0.595858
exploration/num steps total    386000
exploration/num paths total      1414
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0036736
exploration/Rewards Std             0.00694266
exploration/Rewards Max             0.0567568
exploration/Rewards Min             0.000276403
exploration/Returns Mean            1.8368
exploration/Returns Std             0.493653
exploration/Returns Max             2.69573
exploration/Returns Min             1.00015
exploration/Actions Mean            0.00322055
exploration/Actions Std             0.47866
exploration/Actions Max             0.999862
exploration/Actions Min            -0.999324
exploration/Num Paths              10
exploration/Average Returns         1.8368
evaluation/num steps total     380215
evaluation/num paths total       1345
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00286212
evaluation/Rewards Std              0.00568431
evaluation/Rewards Max              0.0518576
evaluation/Rewards Min              0.000376159
evaluation/Returns Mean             1.43106
evaluation/Returns Std              0.37949
evaluation/Returns Max              1.98045
evaluation/Returns Min              0.980226
evaluation/ExplReturns Mean         1.43106
evaluation/ExplReturns Std          0.37949
evaluation/ExplReturns Max          1.98045
evaluation/ExplReturns Min          0.980226
evaluation/Actions Mean             0.00484275
evaluation/Actions Std              0.319845
evaluation/Actions Max              0.999593
evaluation/Actions Min             -0.994846
evaluation/Num Paths               10
evaluation/Average Returns          1.43106
time/data storing (s)               0.0288661
time/evaluation sampling (s)       68.1798
time/exploration sampling (s)      73.5375
time/logging (s)                    0.0253739
time/saving (s)                     0.0700333
time/training (s)                  10.2637
time/epoch (s)                    152.105
time/total (s)                  11897.1
Epoch                              76
-----------------------------  ----------------
2023-08-31 15:16:53.128832 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 77 finished
-----------------------------  ----------------
replay_buffer/size             391000
trainer/QF1 Loss                    0.745328
trainer/QF2 Loss                    0.894387
trainer/Policy Loss               -64.2806
trainer/Q1 Predictions Mean        69.4519
trainer/Q1 Predictions Std          5.44073
trainer/Q1 Predictions Max         86.195
trainer/Q1 Predictions Min         42.5128
trainer/Q2 Predictions Mean        69.6502
trainer/Q2 Predictions Std          5.5054
trainer/Q2 Predictions Max         85.9202
trainer/Q2 Predictions Min         43.2992
trainer/Q Targets Mean             69.4918
trainer/Q Targets Std               5.32929
trainer/Q Targets Max              84.9835
trainer/Q Targets Min              42.2789
trainer/Log Pis Mean                5.8687
trainer/Log Pis Std                 4.54765
trainer/Log Pis Max                34.7641
trainer/Log Pis Min                -4.25272
trainer/Policy mu Mean             -0.152173
trainer/Policy mu Std               1.44143
trainer/Policy mu Max               6.06668
trainer/Policy mu Min              -6.68654
trainer/Policy log std Mean        -0.991236
trainer/Policy log std Std          0.392467
trainer/Policy log std Max          0.0231609
trainer/Policy log std Min         -2.47213
trainer/Alpha                       0.0137453
trainer/Alpha Loss                 -0.562918
exploration/num steps total    391000
exploration/num paths total      1424
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00713387
exploration/Rewards Std             0.00614067
exploration/Rewards Max             0.0482604
exploration/Rewards Min             0.000666285
exploration/Returns Mean            3.56694
exploration/Returns Std             1.45853
exploration/Returns Max             6.05879
exploration/Returns Min             1.06677
exploration/Actions Mean           -0.0127778
exploration/Actions Std             0.477235
exploration/Actions Max             0.999928
exploration/Actions Min            -0.999768
exploration/Num Paths              10
exploration/Average Returns         3.56694
evaluation/num steps total     385215
evaluation/num paths total       1355
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00691687
evaluation/Rewards Std              0.00690718
evaluation/Rewards Max              0.0605005
evaluation/Rewards Min              0.000816448
evaluation/Returns Mean             3.45843
evaluation/Returns Std              2.67923
evaluation/Returns Max              9.36293
evaluation/Returns Min              1.03052
evaluation/ExplReturns Mean         3.45843
evaluation/ExplReturns Std          2.67923
evaluation/ExplReturns Max          9.36293
evaluation/ExplReturns Min          1.03052
evaluation/Actions Mean            -0.00790298
evaluation/Actions Std              0.272166
evaluation/Actions Max              0.999839
evaluation/Actions Min             -0.998966
evaluation/Num Paths               10
evaluation/Average Returns          3.45843
time/data storing (s)               0.0289934
time/evaluation sampling (s)       68.6558
time/exploration sampling (s)      74.0815
time/logging (s)                    0.0258264
time/saving (s)                     0.070796
time/training (s)                  10.3145
time/epoch (s)                    153.177
time/total (s)                  12050.3
Epoch                              77
-----------------------------  ----------------
2023-08-31 15:19:25.428533 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 78 finished
-----------------------------  ----------------
replay_buffer/size             396000
trainer/QF1 Loss                    1.03527
trainer/QF2 Loss                    1.60194
trainer/Policy Loss               -62.2505
trainer/Q1 Predictions Mean        67.2118
trainer/Q1 Predictions Std          9.14401
trainer/Q1 Predictions Max         88.9499
trainer/Q1 Predictions Min          2.15087
trainer/Q2 Predictions Mean        67.4212
trainer/Q2 Predictions Std          9.22839
trainer/Q2 Predictions Max         89.0911
trainer/Q2 Predictions Min          3.41063
trainer/Q Targets Mean             67.324
trainer/Q Targets Std               8.86469
trainer/Q Targets Max              88.5386
trainer/Q Targets Min               5.23748
trainer/Log Pis Mean                5.94338
trainer/Log Pis Std                 5.06229
trainer/Log Pis Max                29.0403
trainer/Log Pis Min                -4.44702
trainer/Policy mu Mean              0.241107
trainer/Policy mu Std               1.48094
trainer/Policy mu Max               6.45057
trainer/Policy mu Min              -4.98069
trainer/Policy log std Mean        -0.968311
trainer/Policy log std Std          0.401398
trainer/Policy log std Max          0.195429
trainer/Policy log std Min         -2.39372
trainer/Alpha                       0.0154588
trainer/Alpha Loss                 -0.236086
exploration/num steps total    396000
exploration/num paths total      1437
exploration/path length Mean      384.615
exploration/path length Std       179.838
exploration/path length Max       500
exploration/path length Min        37
exploration/Rewards Mean            0.0148065
exploration/Rewards Std             0.0184731
exploration/Rewards Max             0.060329
exploration/Rewards Min            -0.317691
exploration/Returns Mean            5.69479
exploration/Returns Std             5.84005
exploration/Returns Max            16.3469
exploration/Returns Min            -0.307894
exploration/Actions Mean           -0.00741319
exploration/Actions Std             0.480091
exploration/Actions Max             0.99965
exploration/Actions Min            -0.998624
exploration/Num Paths              13
exploration/Average Returns         5.69479
evaluation/num steps total     390215
evaluation/num paths total       1365
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0134091
evaluation/Rewards Std              0.00998593
evaluation/Rewards Max              0.0594555
evaluation/Rewards Min              0.000151894
evaluation/Returns Mean             6.70453
evaluation/Returns Std              3.93242
evaluation/Returns Max             14.5496
evaluation/Returns Min              1.32546
evaluation/ExplReturns Mean         6.70453
evaluation/ExplReturns Std          3.93242
evaluation/ExplReturns Max         14.5496
evaluation/ExplReturns Min          1.32546
evaluation/Actions Mean            -0.0334475
evaluation/Actions Std              0.382699
evaluation/Actions Max              0.998242
evaluation/Actions Min             -0.988823
evaluation/Num Paths               10
evaluation/Average Returns          6.70453
time/data storing (s)               0.029233
time/evaluation sampling (s)       68.6829
time/exploration sampling (s)      73.139
time/logging (s)                    0.0255228
time/saving (s)                     0.0779665
time/training (s)                  10.3408
time/epoch (s)                    152.295
time/total (s)                  12202.6
Epoch                              78
-----------------------------  ----------------
2023-08-31 15:21:59.076413 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size             401000
trainer/QF1 Loss                    1.14028
trainer/QF2 Loss                    0.754725
trainer/Policy Loss               -62.9256
trainer/Q1 Predictions Mean        67.8408
trainer/Q1 Predictions Std          6.7979
trainer/Q1 Predictions Max         82.9287
trainer/Q1 Predictions Min         41.0764
trainer/Q2 Predictions Mean        67.9521
trainer/Q2 Predictions Std          6.88215
trainer/Q2 Predictions Max         82.4769
trainer/Q2 Predictions Min         41.3385
trainer/Q Targets Mean             67.8338
trainer/Q Targets Std               6.77823
trainer/Q Targets Max              81.8102
trainer/Q Targets Min              41.2219
trainer/Log Pis Mean                5.73103
trainer/Log Pis Std                 3.93537
trainer/Log Pis Max                17.4513
trainer/Log Pis Min                -5.09302
trainer/Policy mu Mean              0.293274
trainer/Policy mu Std               1.40468
trainer/Policy mu Max               4.24854
trainer/Policy mu Min              -3.77449
trainer/Policy log std Mean        -0.948745
trainer/Policy log std Std          0.372377
trainer/Policy log std Max          0.16694
trainer/Policy log std Min         -2.11713
trainer/Alpha                       0.0165973
trainer/Alpha Loss                 -1.10235
exploration/num steps total    401000
exploration/num paths total      1451
exploration/path length Mean      357.143
exploration/path length Std       206.811
exploration/path length Max       500
exploration/path length Min        33
exploration/Rewards Mean            0.00434215
exploration/Rewards Std             0.0162825
exploration/Rewards Max             0.062042
exploration/Rewards Min            -0.329367
exploration/Returns Mean            1.55077
exploration/Returns Std             1.98436
exploration/Returns Max             7.17538
exploration/Returns Min            -0.916134
exploration/Actions Mean           -0.0172356
exploration/Actions Std             0.468737
exploration/Actions Max             0.999712
exploration/Actions Min            -0.999994
exploration/Num Paths              14
exploration/Average Returns         1.55077
evaluation/num steps total     394793
evaluation/num paths total       1376
evaluation/path length Mean       416.182
evaluation/path length Std        177.81
evaluation/path length Max        500
evaluation/path length Min         36
evaluation/Rewards Mean             0.00292941
evaluation/Rewards Std              0.0129053
evaluation/Rewards Max              0.0489943
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.21917
evaluation/Returns Std              1.19939
evaluation/Returns Max              3.21666
evaluation/Returns Min             -0.567437
evaluation/ExplReturns Mean         1.21917
evaluation/ExplReturns Std          1.19939
evaluation/ExplReturns Max          3.21666
evaluation/ExplReturns Min         -0.567437
evaluation/Actions Mean            -0.00805937
evaluation/Actions Std              0.363182
evaluation/Actions Max              0.999964
evaluation/Actions Min             -0.999821
evaluation/Num Paths               11
evaluation/Average Returns          1.21917
time/data storing (s)               0.0294764
time/evaluation sampling (s)       68.7546
time/exploration sampling (s)      74.7007
time/logging (s)                    0.0239699
time/saving (s)                     0.0633908
time/training (s)                  10.0703
time/epoch (s)                    153.642
time/total (s)                  12356.2
Epoch                              79
-----------------------------  ---------------
2023-08-31 15:24:31.853019 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 80 finished
-----------------------------  ----------------
replay_buffer/size             406000
trainer/QF1 Loss                    1.18246
trainer/QF2 Loss                    1.04773
trainer/Policy Loss               -61.9349
trainer/Q1 Predictions Mean        66.6637
trainer/Q1 Predictions Std          8.78182
trainer/Q1 Predictions Max         84.7187
trainer/Q1 Predictions Min         32.3469
trainer/Q2 Predictions Mean        66.7792
trainer/Q2 Predictions Std          8.92637
trainer/Q2 Predictions Max         84.6481
trainer/Q2 Predictions Min         28.5641
trainer/Q Targets Mean             66.5782
trainer/Q Targets Std               8.71578
trainer/Q Targets Max              84.5498
trainer/Q Targets Min              29.4728
trainer/Log Pis Mean                5.62676
trainer/Log Pis Std                 3.90438
trainer/Log Pis Max                23.7531
trainer/Log Pis Min                -2.73648
trainer/Policy mu Mean              0.226047
trainer/Policy mu Std               1.41261
trainer/Policy mu Max               4.82054
trainer/Policy mu Min              -3.82037
trainer/Policy log std Mean        -0.934873
trainer/Policy log std Std          0.391289
trainer/Policy log std Max          0.000156164
trainer/Policy log std Min         -2.35601
trainer/Alpha                       0.017191
trainer/Alpha Loss                 -1.5165
exploration/num steps total    406000
exploration/num paths total      1461
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0012346
exploration/Rewards Std             0.00374191
exploration/Rewards Max             0.0401598
exploration/Rewards Min             1.38762e-05
exploration/Returns Mean            0.6173
exploration/Returns Std             0.0918108
exploration/Returns Max             0.780409
exploration/Returns Min             0.465099
exploration/Actions Mean           -0.0102911
exploration/Actions Std             0.389933
exploration/Actions Max             0.999962
exploration/Actions Min            -0.998995
exploration/Num Paths              10
exploration/Average Returns         0.6173
evaluation/num steps total     399793
evaluation/num paths total       1386
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00109711
evaluation/Rewards Std              0.00333449
evaluation/Rewards Max              0.0389272
evaluation/Rewards Min              1.49149e-05
evaluation/Returns Mean             0.548554
evaluation/Returns Std              0.0652822
evaluation/Returns Max              0.66387
evaluation/Returns Min              0.419085
evaluation/ExplReturns Mean         0.548554
evaluation/ExplReturns Std          0.0652822
evaluation/ExplReturns Max          0.66387
evaluation/ExplReturns Min          0.419085
evaluation/Actions Mean            -0.00416086
evaluation/Actions Std              0.217778
evaluation/Actions Max              0.999324
evaluation/Actions Min             -0.988943
evaluation/Num Paths               10
evaluation/Average Returns          0.548554
time/data storing (s)               0.0289298
time/evaluation sampling (s)       68.3956
time/exploration sampling (s)      74.2525
time/logging (s)                    0.025317
time/saving (s)                     0.0723395
time/training (s)                   9.99949
time/epoch (s)                    152.774
time/total (s)                  12509
Epoch                              80
-----------------------------  ----------------
2023-08-31 15:27:04.564569 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 81 finished
-----------------------------  ----------------
replay_buffer/size             411000
trainer/QF1 Loss                    1.27807
trainer/QF2 Loss                    1.09822
trainer/Policy Loss               -61.3094
trainer/Q1 Predictions Mean        66.9734
trainer/Q1 Predictions Std         10.5658
trainer/Q1 Predictions Max         84.2133
trainer/Q1 Predictions Min         -1.25175
trainer/Q2 Predictions Mean        66.7242
trainer/Q2 Predictions Std         10.4191
trainer/Q2 Predictions Max         84.0042
trainer/Q2 Predictions Min          2.17979
trainer/Q Targets Mean             66.7802
trainer/Q Targets Std              10.1205
trainer/Q Targets Max              83.2085
trainer/Q Targets Min               3.40226
trainer/Log Pis Mean                6.3426
trainer/Log Pis Std                 4.57821
trainer/Log Pis Max                33.1753
trainer/Log Pis Min                -3.00868
trainer/Policy mu Mean              0.076494
trainer/Policy mu Std               1.49806
trainer/Policy mu Max               5.51028
trainer/Policy mu Min              -5.54939
trainer/Policy log std Mean        -0.951825
trainer/Policy log std Std          0.35486
trainer/Policy log std Max          0.00785452
trainer/Policy log std Min         -2.48134
trainer/Alpha                       0.0163508
trainer/Alpha Loss                  1.40934
exploration/num steps total    411000
exploration/num paths total      1471
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00169418
exploration/Rewards Std             0.00415662
exploration/Rewards Max             0.0505634
exploration/Rewards Min             0.000197785
exploration/Returns Mean            0.847089
exploration/Returns Std             0.148122
exploration/Returns Max             1.11766
exploration/Returns Min             0.633824
exploration/Actions Mean           -0.025605
exploration/Actions Std             0.417334
exploration/Actions Max             0.999583
exploration/Actions Min            -0.99469
exploration/Num Paths              10
exploration/Average Returns         0.847089
evaluation/num steps total     404793
evaluation/num paths total       1396
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00194605
evaluation/Rewards Std              0.00332949
evaluation/Rewards Max              0.0398837
evaluation/Rewards Min              0.000280546
evaluation/Returns Mean             0.973027
evaluation/Returns Std              0.156294
evaluation/Returns Max              1.2392
evaluation/Returns Min              0.68999
evaluation/ExplReturns Mean         0.973027
evaluation/ExplReturns Std          0.156294
evaluation/ExplReturns Max          1.2392
evaluation/ExplReturns Min          0.68999
evaluation/Actions Mean            -0.0140884
evaluation/Actions Std              0.229896
evaluation/Actions Max              0.999029
evaluation/Actions Min             -0.988489
evaluation/Num Paths               10
evaluation/Average Returns          0.973027
time/data storing (s)               0.0288726
time/evaluation sampling (s)       68.4429
time/exploration sampling (s)      73.7153
time/logging (s)                    0.0255646
time/saving (s)                     0.0656465
time/training (s)                  10.4296
time/epoch (s)                    152.708
time/total (s)                  12661.7
Epoch                              81
-----------------------------  ----------------
2023-08-31 15:29:36.513044 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size             416000
trainer/QF1 Loss                    0.681867
trainer/QF2 Loss                    0.930664
trainer/Policy Loss               -61.2491
trainer/Q1 Predictions Mean        66.3706
trainer/Q1 Predictions Std          9.76995
trainer/Q1 Predictions Max         84.6129
trainer/Q1 Predictions Min          0.667601
trainer/Q2 Predictions Mean        66.2428
trainer/Q2 Predictions Std          9.69111
trainer/Q2 Predictions Max         85.0943
trainer/Q2 Predictions Min          3.76204
trainer/Q Targets Mean             66.3997
trainer/Q Targets Std               9.82068
trainer/Q Targets Max              85.0019
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.1941
trainer/Log Pis Std                 4.06326
trainer/Log Pis Max                27.4985
trainer/Log Pis Min                -4.5349
trainer/Policy mu Mean              0.0819379
trainer/Policy mu Std               1.53326
trainer/Policy mu Max               6.34897
trainer/Policy mu Min              -4.93325
trainer/Policy log std Mean        -0.873747
trainer/Policy log std Std          0.354007
trainer/Policy log std Max          0.333254
trainer/Policy log std Min         -2.1653
trainer/Alpha                       0.0179543
trainer/Alpha Loss                  0.780299
exploration/num steps total    416000
exploration/num paths total      1481
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0161082
exploration/Rewards Std             0.0108706
exploration/Rewards Max             0.059109
exploration/Rewards Min             0.00381694
exploration/Returns Mean            8.05409
exploration/Returns Std             3.54674
exploration/Returns Max            12.6386
exploration/Returns Min             3.44837
exploration/Actions Mean            0.0133876
exploration/Actions Std             0.474904
exploration/Actions Max             0.999545
exploration/Actions Min            -0.999366
exploration/Num Paths              10
exploration/Average Returns         8.05409
evaluation/num steps total     409793
evaluation/num paths total       1406
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0145452
evaluation/Rewards Std              0.00814025
evaluation/Rewards Max              0.0565939
evaluation/Rewards Min              0.00561546
evaluation/Returns Mean             7.2726
evaluation/Returns Std              2.72584
evaluation/Returns Max             11.2895
evaluation/Returns Min              3.87123
evaluation/ExplReturns Mean         7.2726
evaluation/ExplReturns Std          2.72584
evaluation/ExplReturns Max         11.2895
evaluation/ExplReturns Min          3.87123
evaluation/Actions Mean             0.00629354
evaluation/Actions Std              0.240518
evaluation/Actions Max              0.997359
evaluation/Actions Min             -0.99131
evaluation/Num Paths               10
evaluation/Average Returns          7.2726
time/data storing (s)               0.0292017
time/evaluation sampling (s)       68.3238
time/exploration sampling (s)      72.9857
time/logging (s)                    0.025701
time/saving (s)                     0.0731087
time/training (s)                  10.5072
time/epoch (s)                    151.945
time/total (s)                  12813.6
Epoch                              82
-----------------------------  ---------------
2023-08-31 15:32:09.879450 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 83 finished
-----------------------------  --------------
replay_buffer/size             421000
trainer/QF1 Loss                    5.98751
trainer/QF2 Loss                    5.0745
trainer/Policy Loss               -61.4343
trainer/Q1 Predictions Mean        66.7043
trainer/Q1 Predictions Std          9.0119
trainer/Q1 Predictions Max         81.8942
trainer/Q1 Predictions Min         28.3094
trainer/Q2 Predictions Mean        66.6013
trainer/Q2 Predictions Std          8.93185
trainer/Q2 Predictions Max         83.3721
trainer/Q2 Predictions Min         30.4841
trainer/Q Targets Mean             66.5379
trainer/Q Targets Std               9.7368
trainer/Q Targets Max              81.7937
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.0786
trainer/Log Pis Std                 4.13841
trainer/Log Pis Max                27.5307
trainer/Log Pis Min                -7.5888
trainer/Policy mu Mean              0.188123
trainer/Policy mu Std               1.53505
trainer/Policy mu Max               4.43009
trainer/Policy mu Min              -5.87659
trainer/Policy log std Mean        -0.838064
trainer/Policy log std Std          0.356554
trainer/Policy log std Max          0.176276
trainer/Policy log std Min         -2.3788
trainer/Alpha                       0.0197043
trainer/Alpha Loss                  0.308675
exploration/num steps total    421000
exploration/num paths total      1495
exploration/path length Mean      357.143
exploration/path length Std       158.668
exploration/path length Max       500
exploration/path length Min        99
exploration/Rewards Mean            0.0143502
exploration/Rewards Std             0.0154073
exploration/Rewards Max             0.0908899
exploration/Rewards Min            -0.281611
exploration/Returns Mean            5.12506
exploration/Returns Std             2.94504
exploration/Returns Max             9.18117
exploration/Returns Min             1.11607
exploration/Actions Mean            0.0236225
exploration/Actions Std             0.545203
exploration/Actions Max             0.999887
exploration/Actions Min            -0.999865
exploration/Num Paths              14
exploration/Average Returns         5.12506
evaluation/num steps total     414594
evaluation/num paths total       1416
evaluation/path length Mean       480.1
evaluation/path length Std         46.438
evaluation/path length Max        500
evaluation/path length Min        347
evaluation/Rewards Mean             0.0135927
evaluation/Rewards Std              0.0128563
evaluation/Rewards Max              0.104467
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             6.52587
evaluation/Returns Std              2.15015
evaluation/Returns Max              9.32894
evaluation/Returns Min              1.95057
evaluation/ExplReturns Mean         6.52587
evaluation/ExplReturns Std          2.15015
evaluation/ExplReturns Max          9.32894
evaluation/ExplReturns Min          1.95057
evaluation/Actions Mean             0.0168841
evaluation/Actions Std              0.401413
evaluation/Actions Max              0.999687
evaluation/Actions Min             -0.999827
evaluation/Num Paths               10
evaluation/Average Returns          6.52587
time/data storing (s)               0.0293515
time/evaluation sampling (s)       68.8112
time/exploration sampling (s)      74.3821
time/logging (s)                    0.0247607
time/saving (s)                     0.057171
time/training (s)                  10.0569
time/epoch (s)                    153.362
time/total (s)                  12967
Epoch                              83
-----------------------------  --------------
2023-08-31 15:34:43.917269 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size             426000
trainer/QF1 Loss                    1.2968
trainer/QF2 Loss                    0.975035
trainer/Policy Loss               -61.8709
trainer/Q1 Predictions Mean        66.8394
trainer/Q1 Predictions Std          9.5723
trainer/Q1 Predictions Max         82.6078
trainer/Q1 Predictions Min         15.734
trainer/Q2 Predictions Mean        66.8742
trainer/Q2 Predictions Std          9.54382
trainer/Q2 Predictions Max         82.1002
trainer/Q2 Predictions Min         16.8899
trainer/Q Targets Mean             66.9709
trainer/Q Targets Std               9.43327
trainer/Q Targets Max              81.9934
trainer/Q Targets Min              16.1045
trainer/Log Pis Mean                5.92333
trainer/Log Pis Std                 4.23653
trainer/Log Pis Max                27.3907
trainer/Log Pis Min                -5.95888
trainer/Policy mu Mean              0.158777
trainer/Policy mu Std               1.46992
trainer/Policy mu Max               5.76605
trainer/Policy mu Min              -4.35262
trainer/Policy log std Mean        -0.869975
trainer/Policy log std Std          0.338579
trainer/Policy log std Max          0.106807
trainer/Policy log std Min         -2.42491
trainer/Alpha                       0.0180252
trainer/Alpha Loss                 -0.307884
exploration/num steps total    426000
exploration/num paths total      1505
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0111614
exploration/Rewards Std             0.00683454
exploration/Rewards Max             0.0815245
exploration/Rewards Min             0.0038554
exploration/Returns Mean            5.58072
exploration/Returns Std             1.49785
exploration/Returns Max             7.74412
exploration/Returns Min             3.55728
exploration/Actions Mean            0.0134673
exploration/Actions Std             0.462332
exploration/Actions Max             0.998125
exploration/Actions Min            -0.999369
exploration/Num Paths              10
exploration/Average Returns         5.58072
evaluation/num steps total     419594
evaluation/num paths total       1426
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.013619
evaluation/Rewards Std              0.00503006
evaluation/Rewards Max              0.0676938
evaluation/Rewards Min              0.00786296
evaluation/Returns Mean             6.80948
evaluation/Returns Std              0.867054
evaluation/Returns Max              7.87951
evaluation/Returns Min              5.42508
evaluation/ExplReturns Mean         6.80948
evaluation/ExplReturns Std          0.867054
evaluation/ExplReturns Max          7.87951
evaluation/ExplReturns Min          5.42508
evaluation/Actions Mean             0.0112442
evaluation/Actions Std              0.21783
evaluation/Actions Max              0.992293
evaluation/Actions Min             -0.996061
evaluation/Num Paths               10
evaluation/Average Returns          6.80948
time/data storing (s)               0.0290122
time/evaluation sampling (s)       68.266
time/exploration sampling (s)      75.3583
time/logging (s)                    0.0252259
time/saving (s)                     0.0800919
time/training (s)                  10.2758
time/epoch (s)                    154.034
time/total (s)                  13121
Epoch                              84
-----------------------------  ---------------
2023-08-31 15:37:19.956410 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size             431000
trainer/QF1 Loss                    1.54364
trainer/QF2 Loss                    2.36274
trainer/Policy Loss               -61.9793
trainer/Q1 Predictions Mean        67.3031
trainer/Q1 Predictions Std          8.22387
trainer/Q1 Predictions Max         79.5001
trainer/Q1 Predictions Min         21.6621
trainer/Q2 Predictions Mean        67.8862
trainer/Q2 Predictions Std          8.09634
trainer/Q2 Predictions Max         80.0737
trainer/Q2 Predictions Min         23.8806
trainer/Q Targets Mean             67.5141
trainer/Q Targets Std               8.49038
trainer/Q Targets Max              80.0921
trainer/Q Targets Min              21.4386
trainer/Log Pis Mean                6.22703
trainer/Log Pis Std                 4.01065
trainer/Log Pis Max                20.1828
trainer/Log Pis Min                -3.03465
trainer/Policy mu Mean              0.188092
trainer/Policy mu Std               1.47087
trainer/Policy mu Max               3.8674
trainer/Policy mu Min              -5.72903
trainer/Policy log std Mean        -0.924691
trainer/Policy log std Std          0.329122
trainer/Policy log std Max         -0.174784
trainer/Policy log std Min         -2.34073
trainer/Alpha                       0.016701
trainer/Alpha Loss                  0.929161
exploration/num steps total    431000
exploration/num paths total      1515
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00982104
exploration/Rewards Std             0.00763951
exploration/Rewards Max             0.0768453
exploration/Rewards Min             0.00276323
exploration/Returns Mean            4.91052
exploration/Returns Std             1.66308
exploration/Returns Max             7.02444
exploration/Returns Min             2.64429
exploration/Actions Mean           -0.00304451
exploration/Actions Std             0.426235
exploration/Actions Max             0.992724
exploration/Actions Min            -0.997663
exploration/Num Paths              10
exploration/Average Returns         4.91052
evaluation/num steps total     424594
evaluation/num paths total       1436
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.012763
evaluation/Rewards Std              0.00711919
evaluation/Rewards Max              0.0762057
evaluation/Rewards Min              0.00361165
evaluation/Returns Mean             6.38148
evaluation/Returns Std              1.45654
evaluation/Returns Max              8.33545
evaluation/Returns Min              4.49008
evaluation/ExplReturns Mean         6.38148
evaluation/ExplReturns Std          1.45654
evaluation/ExplReturns Max          8.33545
evaluation/ExplReturns Min          4.49008
evaluation/Actions Mean             0.00221962
evaluation/Actions Std              0.172227
evaluation/Actions Max              0.986123
evaluation/Actions Min             -0.989818
evaluation/Num Paths               10
evaluation/Average Returns          6.38148
time/data storing (s)               0.0298005
time/evaluation sampling (s)       68.1049
time/exploration sampling (s)      72.9296
time/logging (s)                    0.0255389
time/saving (s)                     0.0572733
time/training (s)                  14.8884
time/epoch (s)                    156.036
time/total (s)                  13277.1
Epoch                              85
-----------------------------  ---------------
2023-08-31 15:39:52.392616 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size             436000
trainer/QF1 Loss                    5.44437
trainer/QF2 Loss                    5.69902
trainer/Policy Loss               -61.8046
trainer/Q1 Predictions Mean        66.8212
trainer/Q1 Predictions Std          7.62066
trainer/Q1 Predictions Max         76.5472
trainer/Q1 Predictions Min         25.3702
trainer/Q2 Predictions Mean        66.7894
trainer/Q2 Predictions Std          7.34619
trainer/Q2 Predictions Max         76.4632
trainer/Q2 Predictions Min         32.43
trainer/Q Targets Mean             67.273
trainer/Q Targets Std               8.08383
trainer/Q Targets Max              77.3329
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.93326
trainer/Log Pis Std                 3.94931
trainer/Log Pis Max                21.72
trainer/Log Pis Min                -4.58889
trainer/Policy mu Mean              0.349222
trainer/Policy mu Std               1.41711
trainer/Policy mu Max               4.01703
trainer/Policy mu Min              -3.62344
trainer/Policy log std Mean        -0.911639
trainer/Policy log std Std          0.320244
trainer/Policy log std Max         -0.021786
trainer/Policy log std Min         -2.1576
trainer/Alpha                       0.0146247
trainer/Alpha Loss                 -0.281958
exploration/num steps total    436000
exploration/num paths total      1528
exploration/path length Mean      384.615
exploration/path length Std       171.708
exploration/path length Max       500
exploration/path length Min        69
exploration/Rewards Mean            0.00390909
exploration/Rewards Std             0.0112479
exploration/Rewards Max             0.0912202
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.5035
exploration/Returns Std             0.577075
exploration/Returns Max             2.55537
exploration/Returns Min             0.383682
exploration/Actions Mean           -0.0170485
exploration/Actions Std             0.415639
exploration/Actions Max             0.996977
exploration/Actions Min            -0.999251
exploration/Num Paths              13
exploration/Average Returns         1.5035
evaluation/num steps total     429572
evaluation/num paths total       1454
evaluation/path length Mean       276.556
evaluation/path length Std        178.496
evaluation/path length Max        500
evaluation/path length Min        120
evaluation/Rewards Mean             0.00455954
evaluation/Rewards Std              0.0162903
evaluation/Rewards Max              0.079527
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.26097
evaluation/Returns Std              0.649483
evaluation/Returns Max              2.46256
evaluation/Returns Min              0.500959
evaluation/ExplReturns Mean         1.26097
evaluation/ExplReturns Std          0.649483
evaluation/ExplReturns Max          2.46256
evaluation/ExplReturns Min          0.500959
evaluation/Actions Mean            -0.0230946
evaluation/Actions Std              0.317797
evaluation/Actions Max              0.970292
evaluation/Actions Min             -0.994858
evaluation/Num Paths               18
evaluation/Average Returns          1.26097
time/data storing (s)               0.0289181
time/evaluation sampling (s)       68.1992
time/exploration sampling (s)      72.9054
time/logging (s)                    0.0251061
time/saving (s)                     0.0697328
time/training (s)                  11.2034
time/epoch (s)                    152.432
time/total (s)                  13429.5
Epoch                              86
-----------------------------  ---------------
2023-08-31 15:42:24.627701 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size             441000
trainer/QF1 Loss                    0.728091
trainer/QF2 Loss                    0.581451
trainer/Policy Loss               -60.8804
trainer/Q1 Predictions Mean        65.8537
trainer/Q1 Predictions Std          6.65074
trainer/Q1 Predictions Max         77.6237
trainer/Q1 Predictions Min         42.7736
trainer/Q2 Predictions Mean        65.5527
trainer/Q2 Predictions Std          6.65224
trainer/Q2 Predictions Max         77.8718
trainer/Q2 Predictions Min         41.0975
trainer/Q Targets Mean             65.7008
trainer/Q Targets Std               6.68969
trainer/Q Targets Max              77.4438
trainer/Q Targets Min              41.8157
trainer/Log Pis Mean                5.45299
trainer/Log Pis Std                 3.79815
trainer/Log Pis Max                24.5211
trainer/Log Pis Min                -7.20172
trainer/Policy mu Mean              0.123112
trainer/Policy mu Std               1.37118
trainer/Policy mu Max               3.9118
trainer/Policy mu Min              -4.23172
trainer/Policy log std Mean        -1.01664
trainer/Policy log std Std          0.377829
trainer/Policy log std Max          0.0554885
trainer/Policy log std Min         -2.47545
trainer/Alpha                       0.0126832
trainer/Alpha Loss                 -2.38894
exploration/num steps total    441000
exploration/num paths total      1538
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00576767
exploration/Rewards Std             0.00583686
exploration/Rewards Max             0.0493827
exploration/Rewards Min             0.00189025
exploration/Returns Mean            2.88383
exploration/Returns Std             0.380574
exploration/Returns Max             3.8339
exploration/Returns Min             2.48541
exploration/Actions Mean           -0.00484959
exploration/Actions Std             0.420913
exploration/Actions Max             0.990729
exploration/Actions Min            -0.996345
exploration/Num Paths              10
exploration/Average Returns         2.88383
evaluation/num steps total     434572
evaluation/num paths total       1464
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00595816
evaluation/Rewards Std              0.00621693
evaluation/Rewards Max              0.0462567
evaluation/Rewards Min              0.00207685
evaluation/Returns Mean             2.97908
evaluation/Returns Std              0.181637
evaluation/Returns Max              3.14155
evaluation/Returns Min              2.47879
evaluation/ExplReturns Mean         2.97908
evaluation/ExplReturns Std          0.181637
evaluation/ExplReturns Max          3.14155
evaluation/ExplReturns Min          2.47879
evaluation/Actions Mean            -0.0155688
evaluation/Actions Std              0.293605
evaluation/Actions Max              0.960661
evaluation/Actions Min             -0.984637
evaluation/Num Paths               10
evaluation/Average Returns          2.97908
time/data storing (s)               0.0289256
time/evaluation sampling (s)       68.1872
time/exploration sampling (s)      73.2978
time/logging (s)                    0.0250741
time/saving (s)                     0.0642705
time/training (s)                  10.6278
time/epoch (s)                    152.231
time/total (s)                  13581.7
Epoch                              87
-----------------------------  ---------------
2023-08-31 15:44:57.381039 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 88 finished
-----------------------------  ----------------
replay_buffer/size             446000
trainer/QF1 Loss                    1.04871
trainer/QF2 Loss                    1.0927
trainer/Policy Loss               -59.139
trainer/Q1 Predictions Mean        65.374
trainer/Q1 Predictions Std          7.00177
trainer/Q1 Predictions Max         74.8213
trainer/Q1 Predictions Min         27.1712
trainer/Q2 Predictions Mean        65.3686
trainer/Q2 Predictions Std          7.11634
trainer/Q2 Predictions Max         75.1883
trainer/Q2 Predictions Min         23.1939
trainer/Q Targets Mean             65.512
trainer/Q Targets Std               6.62728
trainer/Q Targets Max              75.1893
trainer/Q Targets Min              27.8671
trainer/Log Pis Mean                6.70038
trainer/Log Pis Std                 4.50562
trainer/Log Pis Max                27.4651
trainer/Log Pis Min                -4.55867
trainer/Policy mu Mean              0.23793
trainer/Policy mu Std               1.47206
trainer/Policy mu Max               4.91719
trainer/Policy mu Min              -4.6829
trainer/Policy log std Mean        -1.01318
trainer/Policy log std Std          0.376283
trainer/Policy log std Max          0.320727
trainer/Policy log std Min         -2.58681
trainer/Alpha                       0.0113915
trainer/Alpha Loss                  3.13447
exploration/num steps total    446000
exploration/num paths total      1606
exploration/path length Mean       73.5294
exploration/path length Std        14.4002
exploration/path length Max       114
exploration/path length Min         5
exploration/Rewards Mean            0.0162841
exploration/Rewards Std             0.0362251
exploration/Rewards Max             0.0551189
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.19736
exploration/Returns Std             0.500106
exploration/Returns Max             2.26621
exploration/Returns Min             0.0656887
exploration/Actions Mean            0.0434609
exploration/Actions Std             0.555519
exploration/Actions Max             0.997782
exploration/Actions Min            -0.998973
exploration/Num Paths              68
exploration/Average Returns         1.19736
evaluation/num steps total     439149
evaluation/num paths total       1509
evaluation/path length Mean       101.711
evaluation/path length Std         95.945
evaluation/path length Max        500
evaluation/path length Min         60
evaluation/Rewards Mean             0.0119261
evaluation/Rewards Std              0.0303145
evaluation/Rewards Max              0.0477605
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.21301
evaluation/Returns Std              1.2704
evaluation/Returns Max              6.74067
evaluation/Returns Min              0.247287
evaluation/ExplReturns Mean         1.21301
evaluation/ExplReturns Std          1.2704
evaluation/ExplReturns Max          6.74067
evaluation/ExplReturns Min          0.247287
evaluation/Actions Mean             0.000746016
evaluation/Actions Std              0.509765
evaluation/Actions Max              0.9942
evaluation/Actions Min             -0.996687
evaluation/Num Paths               45
evaluation/Average Returns          1.21301
time/data storing (s)               0.029124
time/evaluation sampling (s)       68.623
time/exploration sampling (s)      73.3754
time/logging (s)                    0.0248403
time/saving (s)                     0.0644297
time/training (s)                  10.6324
time/epoch (s)                    152.749
time/total (s)                  13734.5
Epoch                              88
-----------------------------  ----------------
2023-08-31 15:47:29.839176 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size             451000
trainer/QF1 Loss                    2.66016
trainer/QF2 Loss                    3.35023
trainer/Policy Loss               -58.0882
trainer/Q1 Predictions Mean        63.9
trainer/Q1 Predictions Std          8.41399
trainer/Q1 Predictions Max         77.4402
trainer/Q1 Predictions Min          9.32038
trainer/Q2 Predictions Mean        64.1254
trainer/Q2 Predictions Std          8.2909
trainer/Q2 Predictions Max         77.1149
trainer/Q2 Predictions Min         15.0542
trainer/Q Targets Mean             63.7137
trainer/Q Targets Std               8.92868
trainer/Q Targets Max              76.7468
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.65999
trainer/Log Pis Std                 5.04493
trainer/Log Pis Max                28.8014
trainer/Log Pis Min                -5.01389
trainer/Policy mu Mean              0.109232
trainer/Policy mu Std               1.49067
trainer/Policy mu Max               5.02963
trainer/Policy mu Min              -5.21606
trainer/Policy log std Mean        -1.05162
trainer/Policy log std Std          0.394918
trainer/Policy log std Max         -0.0187615
trainer/Policy log std Min         -3.00618
trainer/Alpha                       0.0108948
trainer/Alpha Loss                  2.98292
exploration/num steps total    451000
exploration/num paths total      1616
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00438843
exploration/Rewards Std             0.00986272
exploration/Rewards Max             0.0744514
exploration/Rewards Min             0.000141912
exploration/Returns Mean            2.19422
exploration/Returns Std             0.696897
exploration/Returns Max             3.60595
exploration/Returns Min             1.22623
exploration/Actions Mean           -0.00241349
exploration/Actions Std             0.492955
exploration/Actions Max             0.999944
exploration/Actions Min            -0.999987
exploration/Num Paths              10
exploration/Average Returns         2.19422
evaluation/num steps total     444149
evaluation/num paths total       1519
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00327609
evaluation/Rewards Std              0.00832408
evaluation/Rewards Max              0.0768126
evaluation/Rewards Min              0.000188676
evaluation/Returns Mean             1.63804
evaluation/Returns Std              0.376666
evaluation/Returns Max              2.25811
evaluation/Returns Min              0.817138
evaluation/ExplReturns Mean         1.63804
evaluation/ExplReturns Std          0.376666
evaluation/ExplReturns Max          2.25811
evaluation/ExplReturns Min          0.817138
evaluation/Actions Mean            -0.00834478
evaluation/Actions Std              0.355959
evaluation/Actions Max              0.994578
evaluation/Actions Min             -0.998526
evaluation/Num Paths               10
evaluation/Average Returns          1.63804
time/data storing (s)               0.0291143
time/evaluation sampling (s)       68.3334
time/exploration sampling (s)      73.4774
time/logging (s)                    0.025609
time/saving (s)                     0.0598157
time/training (s)                  10.5296
time/epoch (s)                    152.455
time/total (s)                  13887
Epoch                              89
-----------------------------  ----------------
2023-08-31 15:50:02.143806 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 90 finished
-----------------------------  ----------------
replay_buffer/size             456000
trainer/QF1 Loss                    0.902686
trainer/QF2 Loss                    0.712316
trainer/Policy Loss               -58.2412
trainer/Q1 Predictions Mean        63.6259
trainer/Q1 Predictions Std          5.96482
trainer/Q1 Predictions Max         74.0207
trainer/Q1 Predictions Min         12.9233
trainer/Q2 Predictions Mean        63.3562
trainer/Q2 Predictions Std          6.0606
trainer/Q2 Predictions Max         74.4006
trainer/Q2 Predictions Min         12.0802
trainer/Q Targets Mean             63.3982
trainer/Q Targets Std               5.80126
trainer/Q Targets Max              72.6895
trainer/Q Targets Min              16.5706
trainer/Log Pis Mean                5.77885
trainer/Log Pis Std                 3.83498
trainer/Log Pis Max                25.6656
trainer/Log Pis Min                -7.17414
trainer/Policy mu Mean              0.0590796
trainer/Policy mu Std               1.35558
trainer/Policy mu Max               4.356
trainer/Policy mu Min              -4.43285
trainer/Policy log std Mean        -1.07624
trainer/Policy log std Std          0.38608
trainer/Policy log std Max         -0.0446153
trainer/Policy log std Min         -2.51524
trainer/Alpha                       0.0101799
trainer/Alpha Loss                 -1.01446
exploration/num steps total    456000
exploration/num paths total      1626
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00585059
exploration/Rewards Std             0.00929549
exploration/Rewards Max             0.0710121
exploration/Rewards Min            -0.0553056
exploration/Returns Mean            2.9253
exploration/Returns Std             0.74203
exploration/Returns Max             4.3883
exploration/Returns Min             1.75141
exploration/Actions Mean           -0.039719
exploration/Actions Std             0.430462
exploration/Actions Max             0.996646
exploration/Actions Min            -0.998497
exploration/Num Paths              10
exploration/Average Returns         2.9253
evaluation/num steps total     449149
evaluation/num paths total       1529
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0048243
evaluation/Rewards Std              0.00867361
evaluation/Rewards Max              0.0765743
evaluation/Rewards Min              0.000647969
evaluation/Returns Mean             2.41215
evaluation/Returns Std              0.657725
evaluation/Returns Max              3.30281
evaluation/Returns Min              1.27795
evaluation/ExplReturns Mean         2.41215
evaluation/ExplReturns Std          0.657725
evaluation/ExplReturns Max          3.30281
evaluation/ExplReturns Min          1.27795
evaluation/Actions Mean            -0.0882363
evaluation/Actions Std              0.358577
evaluation/Actions Max              0.968738
evaluation/Actions Min             -0.987182
evaluation/Num Paths               10
evaluation/Average Returns          2.41215
time/data storing (s)               0.0287054
time/evaluation sampling (s)       68.3411
time/exploration sampling (s)      73.1058
time/logging (s)                    0.0250852
time/saving (s)                     0.0699891
time/training (s)                  10.7295
time/epoch (s)                    152.3
time/total (s)                  14039.3
Epoch                              90
-----------------------------  ----------------
2023-08-31 15:52:32.655548 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size             461000
trainer/QF1 Loss                    1.62862
trainer/QF2 Loss                    0.934254
trainer/Policy Loss               -55.9562
trainer/Q1 Predictions Mean        61.9045
trainer/Q1 Predictions Std          6.12931
trainer/Q1 Predictions Max         70.3038
trainer/Q1 Predictions Min         23.3249
trainer/Q2 Predictions Mean        61.8709
trainer/Q2 Predictions Std          5.85076
trainer/Q2 Predictions Max         72.0165
trainer/Q2 Predictions Min         26.3128
trainer/Q Targets Mean             61.8399
trainer/Q Targets Std               5.5916
trainer/Q Targets Max              70.4931
trainer/Q Targets Min              26.9668
trainer/Log Pis Mean                6.39863
trainer/Log Pis Std                 4.34818
trainer/Log Pis Max                22.043
trainer/Log Pis Min                -3.55489
trainer/Policy mu Mean              0.272002
trainer/Policy mu Std               1.44848
trainer/Policy mu Max               5.24036
trainer/Policy mu Min              -5.37661
trainer/Policy log std Mean        -1.05325
trainer/Policy log std Std          0.386394
trainer/Policy log std Max          0.484586
trainer/Policy log std Min         -2.55216
trainer/Alpha                       0.010284
trainer/Alpha Loss                  1.82482
exploration/num steps total    461000
exploration/num paths total      1642
exploration/path length Mean      312.5
exploration/path length Std       137.229
exploration/path length Max       500
exploration/path length Min        95
exploration/Rewards Mean            0.00421312
exploration/Rewards Std             0.0163026
exploration/Rewards Max             0.0577009
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.3166
exploration/Returns Std             0.53622
exploration/Returns Max             2.50665
exploration/Returns Min             0.280166
exploration/Actions Mean            0.0270182
exploration/Actions Std             0.496266
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              16
exploration/Average Returns         1.3166
evaluation/num steps total     453904
evaluation/num paths total       1540
evaluation/path length Mean       432.273
evaluation/path length Std         91.5782
evaluation/path length Max        500
evaluation/path length Min        282
evaluation/Rewards Mean             0.00285883
evaluation/Rewards Std              0.010934
evaluation/Rewards Max              0.0441317
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             1.2358
evaluation/Returns Std              0.616088
evaluation/Returns Max              2.2826
evaluation/Returns Min              0.360039
evaluation/ExplReturns Mean         1.2358
evaluation/ExplReturns Std          0.616088
evaluation/ExplReturns Max          2.2826
evaluation/ExplReturns Min          0.360039
evaluation/Actions Mean             0.0181755
evaluation/Actions Std              0.354862
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               11
evaluation/Average Returns          1.2358
time/data storing (s)               0.0289007
time/evaluation sampling (s)       67.8471
time/exploration sampling (s)      72.0773
time/logging (s)                    0.0247963
time/saving (s)                     0.060602
time/training (s)                  10.4686
time/epoch (s)                    150.507
time/total (s)                  14189.8
Epoch                              91
-----------------------------  ---------------
2023-08-31 15:55:04.495530 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 92 finished
-----------------------------  ----------------
replay_buffer/size             466000
trainer/QF1 Loss                    4.45713
trainer/QF2 Loss                    5.2234
trainer/Policy Loss               -55.3136
trainer/Q1 Predictions Mean        60.4847
trainer/Q1 Predictions Std          7.55978
trainer/Q1 Predictions Max         68.5145
trainer/Q1 Predictions Min         -6.49477
trainer/Q2 Predictions Mean        60.6853
trainer/Q2 Predictions Std          7.27911
trainer/Q2 Predictions Max         68.4385
trainer/Q2 Predictions Min         -1.9377
trainer/Q Targets Mean             60.471
trainer/Q Targets Std               7.98943
trainer/Q Targets Max              68.3876
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.66296
trainer/Log Pis Std                 4.43064
trainer/Log Pis Max                32.4885
trainer/Log Pis Min                -3.87549
trainer/Policy mu Mean              0.189117
trainer/Policy mu Std               1.37259
trainer/Policy mu Max               4.48539
trainer/Policy mu Min              -6.25944
trainer/Policy log std Mean        -1.03627
trainer/Policy log std Std          0.397678
trainer/Policy log std Max          0.0652412
trainer/Policy log std Min         -3.66745
trainer/Alpha                       0.0105207
trainer/Alpha Loss                 -1.53501
exploration/num steps total    466000
exploration/num paths total      1652
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00302891
exploration/Rewards Std             0.00822183
exploration/Rewards Max             0.0454954
exploration/Rewards Min             1.56881e-05
exploration/Returns Mean            1.51445
exploration/Returns Std             0.314886
exploration/Returns Max             1.91538
exploration/Returns Min             0.942539
exploration/Actions Mean            0.00828906
exploration/Actions Std             0.465557
exploration/Actions Max             0.997612
exploration/Actions Min            -0.998775
exploration/Num Paths              10
exploration/Average Returns         1.51445
evaluation/num steps total     458904
evaluation/num paths total       1550
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00252581
evaluation/Rewards Std              0.00700944
evaluation/Rewards Max              0.0592634
evaluation/Rewards Min              1.85996e-05
evaluation/Returns Mean             1.26291
evaluation/Returns Std              0.346285
evaluation/Returns Max              2.12296
evaluation/Returns Min              0.888101
evaluation/ExplReturns Mean         1.26291
evaluation/ExplReturns Std          0.346285
evaluation/ExplReturns Max          2.12296
evaluation/ExplReturns Min          0.888101
evaluation/Actions Mean             0.0147983
evaluation/Actions Std              0.358364
evaluation/Actions Max              0.980333
evaluation/Actions Min             -0.996554
evaluation/Num Paths               10
evaluation/Average Returns          1.26291
time/data storing (s)               0.0288017
time/evaluation sampling (s)       68.0277
time/exploration sampling (s)      73.2607
time/logging (s)                    0.0258704
time/saving (s)                     0.0783212
time/training (s)                  10.4157
time/epoch (s)                    151.837
time/total (s)                  14341.6
Epoch                              92
-----------------------------  ----------------
2023-08-31 15:57:36.638193 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size             471000
trainer/QF1 Loss                    0.366755
trainer/QF2 Loss                    0.466034
trainer/Policy Loss               -54.4034
trainer/Q1 Predictions Mean        59.8209
trainer/Q1 Predictions Std          3.8909
trainer/Q1 Predictions Max         71.9678
trainer/Q1 Predictions Min         42.722
trainer/Q2 Predictions Mean        59.5505
trainer/Q2 Predictions Std          3.82543
trainer/Q2 Predictions Max         72.4172
trainer/Q2 Predictions Min         42.8626
trainer/Q Targets Mean             59.7661
trainer/Q Targets Std               3.71998
trainer/Q Targets Max              71.271
trainer/Q Targets Min              43.6709
trainer/Log Pis Mean                5.58751
trainer/Log Pis Std                 4.49099
trainer/Log Pis Max                22.2289
trainer/Log Pis Min                -4.34203
trainer/Policy mu Mean              0.0630338
trainer/Policy mu Std               1.42451
trainer/Policy mu Max               4.26504
trainer/Policy mu Min              -4.50668
trainer/Policy log std Mean        -0.963736
trainer/Policy log std Std          0.405494
trainer/Policy log std Max          0.0989149
trainer/Policy log std Min         -2.58594
trainer/Alpha                       0.0106704
trainer/Alpha Loss                 -1.87281
exploration/num steps total    471000
exploration/num paths total      1662
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00439822
exploration/Rewards Std             0.0401155
exploration/Rewards Max             1.51355
exploration/Rewards Min            -0.273474
exploration/Returns Mean            2.19911
exploration/Returns Std             1.97304
exploration/Returns Max             6.89433
exploration/Returns Min             0.326187
exploration/Actions Mean           -0.00856627
exploration/Actions Std             0.403119
exploration/Actions Max             0.995882
exploration/Actions Min            -0.998668
exploration/Num Paths              10
exploration/Average Returns         2.19911
evaluation/num steps total     463904
evaluation/num paths total       1560
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00366262
evaluation/Rewards Std              0.0151316
evaluation/Rewards Max              0.091952
evaluation/Rewards Min             -0.242544
evaluation/Returns Mean             1.83131
evaluation/Returns Std              0.623844
evaluation/Returns Max              3.05735
evaluation/Returns Min              0.878098
evaluation/ExplReturns Mean         1.83131
evaluation/ExplReturns Std          0.623844
evaluation/ExplReturns Max          3.05735
evaluation/ExplReturns Min          0.878098
evaluation/Actions Mean            -0.00782472
evaluation/Actions Std              0.300996
evaluation/Actions Max              0.981395
evaluation/Actions Min             -0.994547
evaluation/Num Paths               10
evaluation/Average Returns          1.83131
time/data storing (s)               0.0287629
time/evaluation sampling (s)       68.5091
time/exploration sampling (s)      72.7294
time/logging (s)                    0.0255964
time/saving (s)                     0.0690359
time/training (s)                  10.7765
time/epoch (s)                    152.138
time/total (s)                  14493.7
Epoch                              93
-----------------------------  ---------------
2023-08-31 16:00:07.459049 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size             476000
trainer/QF1 Loss                    5.81389
trainer/QF2 Loss                    6.63865
trainer/Policy Loss               -52.7842
trainer/Q1 Predictions Mean        58.4719
trainer/Q1 Predictions Std          5.63298
trainer/Q1 Predictions Max         65.7756
trainer/Q1 Predictions Min         -6.16521
trainer/Q2 Predictions Mean        58.5348
trainer/Q2 Predictions Std          5.30641
trainer/Q2 Predictions Max         65.7492
trainer/Q2 Predictions Min          0.9788
trainer/Q Targets Mean             58.0995
trainer/Q Targets Std               6.34422
trainer/Q Targets Max              65.8723
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.45493
trainer/Log Pis Std                 4.46094
trainer/Log Pis Max                29.6221
trainer/Log Pis Min                -4.38776
trainer/Policy mu Mean             -0.0452874
trainer/Policy mu Std               1.5171
trainer/Policy mu Max               4.10802
trainer/Policy mu Min              -5.0906
trainer/Policy log std Mean        -0.92538
trainer/Policy log std Std          0.400778
trainer/Policy log std Max          0.00553608
trainer/Policy log std Min         -2.40116
trainer/Alpha                       0.0107182
trainer/Alpha Loss                  2.0635
exploration/num steps total    476000
exploration/num paths total      1672
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00920185
exploration/Rewards Std             0.0181514
exploration/Rewards Max             0.0950316
exploration/Rewards Min            -0.293247
exploration/Returns Mean            4.60092
exploration/Returns Std             2.21654
exploration/Returns Max             8.05201
exploration/Returns Min             1.45654
exploration/Actions Mean           -0.0171892
exploration/Actions Std             0.475203
exploration/Actions Max             0.999552
exploration/Actions Min            -0.999485
exploration/Num Paths              10
exploration/Average Returns         4.60092
evaluation/num steps total     468904
evaluation/num paths total       1570
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0137531
evaluation/Rewards Std              0.015807
evaluation/Rewards Max              0.0833004
evaluation/Rewards Min             -0.169754
evaluation/Returns Mean             6.87655
evaluation/Returns Std              2.83222
evaluation/Returns Max             11.042
evaluation/Returns Min              1.16235
evaluation/ExplReturns Mean         6.87655
evaluation/ExplReturns Std          2.83222
evaluation/ExplReturns Max         11.042
evaluation/ExplReturns Min          1.16235
evaluation/Actions Mean            -0.0390509
evaluation/Actions Std              0.408578
evaluation/Actions Max              0.999698
evaluation/Actions Min             -0.992207
evaluation/Num Paths               10
evaluation/Average Returns          6.87655
time/data storing (s)               0.0291676
time/evaluation sampling (s)       68.3397
time/exploration sampling (s)      71.9593
time/logging (s)                    0.0253132
time/saving (s)                     0.0606511
time/training (s)                  10.4024
time/epoch (s)                    150.817
time/total (s)                  14644.6
Epoch                              94
-----------------------------  ---------------
2023-08-31 16:02:40.944393 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 95 finished
-----------------------------  ----------------
replay_buffer/size             481000
trainer/QF1 Loss                    0.800927
trainer/QF2 Loss                    1.62263
trainer/Policy Loss               -51.1173
trainer/Q1 Predictions Mean        56.3134
trainer/Q1 Predictions Std          7.01118
trainer/Q1 Predictions Max         65.1847
trainer/Q1 Predictions Min         -3.53421
trainer/Q2 Predictions Mean        56.2464
trainer/Q2 Predictions Std          6.47601
trainer/Q2 Predictions Max         64.8919
trainer/Q2 Predictions Min          4.73333
trainer/Q Targets Mean             56.5489
trainer/Q Targets Std               6.798
trainer/Q Targets Max              64.776
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.55424
trainer/Log Pis Std                 3.94043
trainer/Log Pis Max                21.6178
trainer/Log Pis Min                -3.68025
trainer/Policy mu Mean              0.073703
trainer/Policy mu Std               1.42735
trainer/Policy mu Max               5.5921
trainer/Policy mu Min              -6.0465
trainer/Policy log std Mean        -0.943158
trainer/Policy log std Std          0.389771
trainer/Policy log std Max          0.162692
trainer/Policy log std Min         -2.26256
trainer/Alpha                       0.0110279
trainer/Alpha Loss                 -2.00907
exploration/num steps total    481000
exploration/num paths total      1683
exploration/path length Mean      454.545
exploration/path length Std       127.323
exploration/path length Max       500
exploration/path length Min        55
exploration/Rewards Mean            0.0123789
exploration/Rewards Std             0.0111916
exploration/Rewards Max             0.0719823
exploration/Rewards Min            -0.281611
exploration/Returns Mean            5.62677
exploration/Returns Std             2.7537
exploration/Returns Max            10.3772
exploration/Returns Min             0.1665
exploration/Actions Mean           -0.000266322
exploration/Actions Std             0.591403
exploration/Actions Max             0.999985
exploration/Actions Min            -0.999968
exploration/Num Paths              11
exploration/Average Returns         5.62677
evaluation/num steps total     473738
evaluation/num paths total       1580
evaluation/path length Mean       483.4
evaluation/path length Std         49.8
evaluation/path length Max        500
evaluation/path length Min        334
evaluation/Rewards Mean             0.0178348
evaluation/Rewards Std              0.0165382
evaluation/Rewards Max              0.096331
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             8.62132
evaluation/Returns Std              4.18149
evaluation/Returns Max             18.8931
evaluation/Returns Min              3.96446
evaluation/ExplReturns Mean         8.62132
evaluation/ExplReturns Std          4.18149
evaluation/ExplReturns Max         18.8931
evaluation/ExplReturns Min          3.96446
evaluation/Actions Mean             0.000595226
evaluation/Actions Std              0.503524
evaluation/Actions Max              0.999888
evaluation/Actions Min             -0.999464
evaluation/Num Paths               10
evaluation/Average Returns          8.62132
time/data storing (s)               0.0296538
time/evaluation sampling (s)       68.7354
time/exploration sampling (s)      74.4565
time/logging (s)                    0.0254803
time/saving (s)                     0.0697835
time/training (s)                  10.1645
time/epoch (s)                    153.481
time/total (s)                  14798.1
Epoch                              95
-----------------------------  ----------------
2023-08-31 16:05:14.517438 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size             486000
trainer/QF1 Loss                    0.506616
trainer/QF2 Loss                    0.551532
trainer/Policy Loss               -50.9167
trainer/Q1 Predictions Mean        55.8181
trainer/Q1 Predictions Std          5.86014
trainer/Q1 Predictions Max         65.0302
trainer/Q1 Predictions Min         -1.16602
trainer/Q2 Predictions Mean        55.8642
trainer/Q2 Predictions Std          6.08103
trainer/Q2 Predictions Max         65.3955
trainer/Q2 Predictions Min         -6.75049
trainer/Q Targets Mean             55.8085
trainer/Q Targets Std               5.65216
trainer/Q Targets Max              64.7414
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.38505
trainer/Log Pis Std                 4.18364
trainer/Log Pis Max                22.8048
trainer/Log Pis Min                -3.83406
trainer/Policy mu Mean              0.199651
trainer/Policy mu Std               1.39507
trainer/Policy mu Max               5.18075
trainer/Policy mu Min              -5.68009
trainer/Policy log std Mean        -1.03034
trainer/Policy log std Std          0.405157
trainer/Policy log std Max          0.116212
trainer/Policy log std Min         -2.48137
trainer/Alpha                       0.00967675
trainer/Alpha Loss                 -2.85211
exploration/num steps total    486000
exploration/num paths total      1693
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0166777
exploration/Rewards Std             0.0124452
exploration/Rewards Max             0.0665902
exploration/Rewards Min             0.00137987
exploration/Returns Mean            8.33886
exploration/Returns Std             4.4334
exploration/Returns Max            19.3529
exploration/Returns Min             3.75143
exploration/Actions Mean            0.00595413
exploration/Actions Std             0.49265
exploration/Actions Max             0.999921
exploration/Actions Min            -0.999911
exploration/Num Paths              10
exploration/Average Returns         8.33886
evaluation/num steps total     478738
evaluation/num paths total       1590
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0281721
evaluation/Rewards Std              0.0169512
evaluation/Rewards Max              0.0591476
evaluation/Rewards Min              0.00177709
evaluation/Returns Mean            14.0861
evaluation/Returns Std              7.22562
evaluation/Returns Max             25.2653
evaluation/Returns Min              3.26782
evaluation/ExplReturns Mean        14.0861
evaluation/ExplReturns Std          7.22562
evaluation/ExplReturns Max         25.2653
evaluation/ExplReturns Min          3.26782
evaluation/Actions Mean             0.0114157
evaluation/Actions Std              0.275761
evaluation/Actions Max              0.999253
evaluation/Actions Min             -0.998379
evaluation/Num Paths               10
evaluation/Average Returns         14.0861
time/data storing (s)               0.0296765
time/evaluation sampling (s)       68.5333
time/exploration sampling (s)      74.3964
time/logging (s)                    0.0259521
time/saving (s)                     0.0936513
time/training (s)                  10.4905
time/epoch (s)                    153.569
time/total (s)                  14951.6
Epoch                              96
-----------------------------  ---------------
2023-08-31 16:07:47.037444 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size             491000
trainer/QF1 Loss                    4.88856
trainer/QF2 Loss                    7.89712
trainer/Policy Loss               -49.2229
trainer/Q1 Predictions Mean        54.6398
trainer/Q1 Predictions Std          4.60004
trainer/Q1 Predictions Max         64.6496
trainer/Q1 Predictions Min         32.1139
trainer/Q2 Predictions Mean        54.3809
trainer/Q2 Predictions Std          4.54785
trainer/Q2 Predictions Max         64.2278
trainer/Q2 Predictions Min         32.3101
trainer/Q Targets Mean             54.1988
trainer/Q Targets Std               5.52583
trainer/Q Targets Max              65.8345
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.66652
trainer/Log Pis Std                 3.58505
trainer/Log Pis Max                17.8209
trainer/Log Pis Min                -4.36627
trainer/Policy mu Mean              0.220315
trainer/Policy mu Std               1.36098
trainer/Policy mu Max               3.7183
trainer/Policy mu Min              -3.63452
trainer/Policy log std Mean        -1.03366
trainer/Policy log std Std          0.379152
trainer/Policy log std Max         -0.0829081
trainer/Policy log std Min         -2.42719
trainer/Alpha                       0.00956402
trainer/Alpha Loss                 -1.55064
exploration/num steps total    491000
exploration/num paths total      1703
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0245209
exploration/Rewards Std             0.0150902
exploration/Rewards Max             0.0974681
exploration/Rewards Min             0.0021607
exploration/Returns Mean           12.2605
exploration/Returns Std             5.39512
exploration/Returns Max            22.2718
exploration/Returns Min             6.48188
exploration/Actions Mean            0.0261238
exploration/Actions Std             0.468274
exploration/Actions Max             0.999494
exploration/Actions Min            -0.99966
exploration/Num Paths              10
exploration/Average Returns        12.2605
evaluation/num steps total     483738
evaluation/num paths total       1600
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0270609
evaluation/Rewards Std              0.00911864
evaluation/Rewards Max              0.0637425
evaluation/Rewards Min              0.00935623
evaluation/Returns Mean            13.5304
evaluation/Returns Std              4.05195
evaluation/Returns Max             21.0578
evaluation/Returns Min              7.00695
evaluation/ExplReturns Mean        13.5304
evaluation/ExplReturns Std          4.05195
evaluation/ExplReturns Max         21.0578
evaluation/ExplReturns Min          7.00695
evaluation/Actions Mean             0.0300874
evaluation/Actions Std              0.346865
evaluation/Actions Max              0.99768
evaluation/Actions Min             -0.999566
evaluation/Num Paths               10
evaluation/Average Returns         13.5304
time/data storing (s)               0.0291129
time/evaluation sampling (s)       68.8008
time/exploration sampling (s)      73.3766
time/logging (s)                    0.0251103
time/saving (s)                     0.0564163
time/training (s)                  10.2264
time/epoch (s)                    152.514
time/total (s)                  15104.1
Epoch                              97
-----------------------------  ---------------
2023-08-31 16:10:19.749334 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 98 finished
-----------------------------  ----------------
replay_buffer/size             496000
trainer/QF1 Loss                    0.990363
trainer/QF2 Loss                    0.419353
trainer/Policy Loss               -46.4329
trainer/Q1 Predictions Mean        52.9067
trainer/Q1 Predictions Std          5.24106
trainer/Q1 Predictions Max         63.1064
trainer/Q1 Predictions Min         16.8742
trainer/Q2 Predictions Mean        52.9326
trainer/Q2 Predictions Std          5.06436
trainer/Q2 Predictions Max         63.759
trainer/Q2 Predictions Min         17.4141
trainer/Q Targets Mean             52.9916
trainer/Q Targets Std               4.95941
trainer/Q Targets Max              63.9302
trainer/Q Targets Min              19.9852
trainer/Log Pis Mean                6.94969
trainer/Log Pis Std                 4.92218
trainer/Log Pis Max                39.9267
trainer/Log Pis Min                -5.07946
trainer/Policy mu Mean              0.369491
trainer/Policy mu Std               1.47385
trainer/Policy mu Max               6.85617
trainer/Policy mu Min              -4.35828
trainer/Policy log std Mean        -1.05128
trainer/Policy log std Std          0.380798
trainer/Policy log std Max          0.573128
trainer/Policy log std Min         -2.42282
trainer/Alpha                       0.00864602
trainer/Alpha Loss                  4.51194
exploration/num steps total    496000
exploration/num paths total      1714
exploration/path length Mean      454.545
exploration/path length Std        96.6534
exploration/path length Max       500
exploration/path length Min       200
exploration/Rewards Mean            0.00805243
exploration/Rewards Std             0.0164508
exploration/Rewards Max             0.102004
exploration/Rewards Min            -0.281611
exploration/Returns Mean            3.66019
exploration/Returns Std             3.35325
exploration/Returns Max            13.5448
exploration/Returns Min             1.05295
exploration/Actions Mean            0.0452671
exploration/Actions Std             0.452572
exploration/Actions Max             1
exploration/Actions Min            -0.999947
exploration/Num Paths              11
exploration/Average Returns         3.66019
evaluation/num steps total     488738
evaluation/num paths total       1610
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.017681
evaluation/Rewards Std              0.0161367
evaluation/Rewards Max              0.0815024
evaluation/Rewards Min              1.96566e-05
evaluation/Returns Mean             8.84052
evaluation/Returns Std              5.59945
evaluation/Returns Max             16.6139
evaluation/Returns Min              1.06143
evaluation/ExplReturns Mean         8.84052
evaluation/ExplReturns Std          5.59945
evaluation/ExplReturns Max         16.6139
evaluation/ExplReturns Min          1.06143
evaluation/Actions Mean             0.0233689
evaluation/Actions Std              0.271469
evaluation/Actions Max              0.989675
evaluation/Actions Min             -0.999598
evaluation/Num Paths               10
evaluation/Average Returns          8.84052
time/data storing (s)               0.0292088
time/evaluation sampling (s)       68.4706
time/exploration sampling (s)      73.7504
time/logging (s)                    0.0253359
time/saving (s)                     0.0657422
time/training (s)                  10.3667
time/epoch (s)                    152.708
time/total (s)                  15256.9
Epoch                              98
-----------------------------  ----------------
2023-08-31 16:12:52.276850 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 99 finished
-----------------------------  ----------------
replay_buffer/size             501000
trainer/QF1 Loss                    3.31961
trainer/QF2 Loss                    3.96204
trainer/Policy Loss               -46.6999
trainer/Q1 Predictions Mean        51.9463
trainer/Q1 Predictions Std          4.66859
trainer/Q1 Predictions Max         64.4971
trainer/Q1 Predictions Min         23.9723
trainer/Q2 Predictions Mean        51.9177
trainer/Q2 Predictions Std          4.69082
trainer/Q2 Predictions Max         64.7215
trainer/Q2 Predictions Min         24.2182
trainer/Q Targets Mean             52.0037
trainer/Q Targets Std               5.32651
trainer/Q Targets Max              64.1697
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.7463
trainer/Log Pis Std                 4.43874
trainer/Log Pis Max                25.1541
trainer/Log Pis Min                -3.04908
trainer/Policy mu Mean              0.17307
trainer/Policy mu Std               1.3616
trainer/Policy mu Max               5.30576
trainer/Policy mu Min              -5.91546
trainer/Policy log std Mean        -1.10016
trainer/Policy log std Std          0.380405
trainer/Policy log std Max          0.0836216
trainer/Policy log std Min         -2.76521
trainer/Alpha                       0.00798852
trainer/Alpha Loss                 -1.22526
exploration/num steps total    501000
exploration/num paths total      1724
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00417536
exploration/Rewards Std             0.00926514
exploration/Rewards Max             0.0637327
exploration/Rewards Min             9.07786e-06
exploration/Returns Mean            2.08768
exploration/Returns Std             0.404362
exploration/Returns Max             2.61889
exploration/Returns Min             1.26585
exploration/Actions Mean            0.0366088
exploration/Actions Std             0.418378
exploration/Actions Max             0.99837
exploration/Actions Min            -0.999922
exploration/Num Paths              10
exploration/Average Returns         2.08768
evaluation/num steps total     493738
evaluation/num paths total       1620
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00311437
evaluation/Rewards Std              0.00825381
evaluation/Rewards Max              0.0716888
evaluation/Rewards Min              7.65524e-06
evaluation/Returns Mean             1.55718
evaluation/Returns Std              0.433075
evaluation/Returns Max              2.35745
evaluation/Returns Min              1.04633
evaluation/ExplReturns Mean         1.55718
evaluation/ExplReturns Std          0.433075
evaluation/ExplReturns Max          2.35745
evaluation/ExplReturns Min          1.04633
evaluation/Actions Mean             0.0298872
evaluation/Actions Std              0.199178
evaluation/Actions Max              0.990001
evaluation/Actions Min             -0.999618
evaluation/Num Paths               10
evaluation/Average Returns          1.55718
time/data storing (s)               0.0293346
time/evaluation sampling (s)       68.4192
time/exploration sampling (s)      73.5544
time/logging (s)                    0.0251532
time/saving (s)                     0.06529
time/training (s)                  10.43
time/epoch (s)                    152.523
time/total (s)                  15409.4
Epoch                              99
-----------------------------  ----------------
2023-08-31 16:15:25.896483 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size             506000
trainer/QF1 Loss                    0.279774
trainer/QF2 Loss                    0.420472
trainer/Policy Loss               -45.598
trainer/Q1 Predictions Mean        50.5578
trainer/Q1 Predictions Std          4.39219
trainer/Q1 Predictions Max         60.4581
trainer/Q1 Predictions Min         21.9214
trainer/Q2 Predictions Mean        50.525
trainer/Q2 Predictions Std          4.34049
trainer/Q2 Predictions Max         60.2782
trainer/Q2 Predictions Min         24.4132
trainer/Q Targets Mean             50.6469
trainer/Q Targets Std               4.51967
trainer/Q Targets Max              60.54
trainer/Q Targets Min              19.6004
trainer/Log Pis Mean                5.23576
trainer/Log Pis Std                 4.26667
trainer/Log Pis Max                30.339
trainer/Log Pis Min                -3.8795
trainer/Policy mu Mean              0.310334
trainer/Policy mu Std               1.24176
trainer/Policy mu Max               5.23986
trainer/Policy mu Min              -4.32964
trainer/Policy log std Mean        -1.16615
trainer/Policy log std Std          0.385106
trainer/Policy log std Max          0.337944
trainer/Policy log std Min         -2.64164
trainer/Alpha                       0.00782572
trainer/Alpha Loss                 -3.70661
exploration/num steps total    506000
exploration/num paths total      1734
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0312213
exploration/Rewards Std             0.0146942
exploration/Rewards Max             0.0632761
exploration/Rewards Min             0.0073829
exploration/Returns Mean           15.6106
exploration/Returns Std             6.92276
exploration/Returns Max            26.2084
exploration/Returns Min             6.1327
exploration/Actions Mean            0.0159838
exploration/Actions Std             0.342598
exploration/Actions Max             0.997925
exploration/Actions Min            -0.995739
exploration/Num Paths              10
exploration/Average Returns        15.6106
evaluation/num steps total     498738
evaluation/num paths total       1630
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0354693
evaluation/Rewards Std              0.0129284
evaluation/Rewards Max              0.0561828
evaluation/Rewards Min              0.0103205
evaluation/Returns Mean            17.7347
evaluation/Returns Std              6.31516
evaluation/Returns Max             23.6184
evaluation/Returns Min              7.16848
evaluation/ExplReturns Mean        17.7347
evaluation/ExplReturns Std          6.31516
evaluation/ExplReturns Max         23.6184
evaluation/ExplReturns Min          7.16848
evaluation/Actions Mean             0.00378365
evaluation/Actions Std              0.118081
evaluation/Actions Max              0.989666
evaluation/Actions Min             -0.986631
evaluation/Num Paths               10
evaluation/Average Returns         17.7347
time/data storing (s)               0.0296789
time/evaluation sampling (s)       68.4884
time/exploration sampling (s)      74.8694
time/logging (s)                    0.025436
time/saving (s)                     0.0678946
time/training (s)                  10.135
time/epoch (s)                    153.616
time/total (s)                  15563
Epoch                             100
-----------------------------  ---------------
2023-08-31 16:18:01.364588 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size             511000
trainer/QF1 Loss                    0.318851
trainer/QF2 Loss                    0.335447
trainer/Policy Loss               -44.1021
trainer/Q1 Predictions Mean        49.7243
trainer/Q1 Predictions Std          5.31308
trainer/Q1 Predictions Max         66.4607
trainer/Q1 Predictions Min          4.99391
trainer/Q2 Predictions Mean        49.7242
trainer/Q2 Predictions Std          5.39444
trainer/Q2 Predictions Max         65.9899
trainer/Q2 Predictions Min          5.24513
trainer/Q Targets Mean             49.7666
trainer/Q Targets Std               5.51913
trainer/Q Targets Max              66.1779
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.9626
trainer/Log Pis Std                 4.20064
trainer/Log Pis Max                26.6603
trainer/Log Pis Min                -5.23189
trainer/Policy mu Mean              0.406595
trainer/Policy mu Std               1.31511
trainer/Policy mu Max               4.91208
trainer/Policy mu Min              -4.19501
trainer/Policy log std Mean        -1.12383
trainer/Policy log std Std          0.403166
trainer/Policy log std Max         -0.0427432
trainer/Policy log std Min         -2.45036
trainer/Alpha                       0.00797661
trainer/Alpha Loss                 -0.180708
exploration/num steps total    511000
exploration/num paths total      1744
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0122779
exploration/Rewards Std             0.00571063
exploration/Rewards Max             0.0447865
exploration/Rewards Min             0.0029074
exploration/Returns Mean            6.13893
exploration/Returns Std             1.971
exploration/Returns Max             9.00296
exploration/Returns Min             2.59729
exploration/Actions Mean            0.0414348
exploration/Actions Std             0.392955
exploration/Actions Max             0.99244
exploration/Actions Min            -0.979098
exploration/Num Paths              10
exploration/Average Returns         6.13893
evaluation/num steps total     503738
evaluation/num paths total       1640
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0119599
evaluation/Rewards Std              0.00551875
evaluation/Rewards Max              0.0477065
evaluation/Rewards Min              0.00348829
evaluation/Returns Mean             5.97997
evaluation/Returns Std              1.97124
evaluation/Returns Max              9.76277
evaluation/Returns Min              2.53176
evaluation/ExplReturns Mean         5.97997
evaluation/ExplReturns Std          1.97124
evaluation/ExplReturns Max          9.76277
evaluation/ExplReturns Min          2.53176
evaluation/Actions Mean             0.03265
evaluation/Actions Std              0.271717
evaluation/Actions Max              0.966117
evaluation/Actions Min             -0.911616
evaluation/Num Paths               10
evaluation/Average Returns          5.97997
time/data storing (s)               0.0298566
time/evaluation sampling (s)       68.6171
time/exploration sampling (s)      76.4525
time/logging (s)                    0.0254858
time/saving (s)                     0.022421
time/training (s)                  10.3167
time/epoch (s)                    155.464
time/total (s)                  15718.5
Epoch                             101
-----------------------------  ---------------
2023-08-31 16:20:35.608374 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size             516000
trainer/QF1 Loss                    0.339422
trainer/QF2 Loss                    0.265342
trainer/Policy Loss               -43.3339
trainer/Q1 Predictions Mean        48.5456
trainer/Q1 Predictions Std          3.93997
trainer/Q1 Predictions Max         56.6053
trainer/Q1 Predictions Min         19.8254
trainer/Q2 Predictions Mean        48.6348
trainer/Q2 Predictions Std          3.95872
trainer/Q2 Predictions Max         57.1839
trainer/Q2 Predictions Min         19.4864
trainer/Q Targets Mean             48.799
trainer/Q Targets Std               3.92653
trainer/Q Targets Max              56.5156
trainer/Q Targets Min              18.0636
trainer/Log Pis Mean                5.56147
trainer/Log Pis Std                 4.06631
trainer/Log Pis Max                20.2692
trainer/Log Pis Min                -5.54857
trainer/Policy mu Mean              0.29896
trainer/Policy mu Std               1.31771
trainer/Policy mu Max               5.08414
trainer/Policy mu Min              -5.38148
trainer/Policy log std Mean        -1.11736
trainer/Policy log std Std          0.39956
trainer/Policy log std Max          0.00975954
trainer/Policy log std Min         -2.69927
trainer/Alpha                       0.00740088
trainer/Alpha Loss                 -2.15137
exploration/num steps total    516000
exploration/num paths total      1754
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0121218
exploration/Rewards Std             0.00319427
exploration/Rewards Max             0.0321335
exploration/Rewards Min             0.00415502
exploration/Returns Mean            6.06089
exploration/Returns Std             0.961926
exploration/Returns Max             7.63764
exploration/Returns Min             3.80887
exploration/Actions Mean            0.0297034
exploration/Actions Std             0.380483
exploration/Actions Max             0.978166
exploration/Actions Min            -0.963806
exploration/Num Paths              10
exploration/Average Returns         6.06089
evaluation/num steps total     508738
evaluation/num paths total       1650
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0112204
evaluation/Rewards Std              0.00458079
evaluation/Rewards Max              0.0366491
evaluation/Rewards Min              0.00478591
evaluation/Returns Mean             5.61021
evaluation/Returns Std              1.97099
evaluation/Returns Max              9.00589
evaluation/Returns Min              2.63149
evaluation/ExplReturns Mean         5.61021
evaluation/ExplReturns Std          1.97099
evaluation/ExplReturns Max          9.00589
evaluation/ExplReturns Min          2.63149
evaluation/Actions Mean             0.0163288
evaluation/Actions Std              0.178067
evaluation/Actions Max              0.892346
evaluation/Actions Min             -0.869186
evaluation/Num Paths               10
evaluation/Average Returns          5.61021
time/data storing (s)               0.0293982
time/evaluation sampling (s)       68.9223
time/exploration sampling (s)      74.6399
time/logging (s)                    0.0253067
time/saving (s)                     0.0664193
time/training (s)                  10.5563
time/epoch (s)                    154.24
time/total (s)                  15872.7
Epoch                             102
-----------------------------  ---------------
2023-08-31 16:23:08.460586 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 103 finished
-----------------------------  ----------------
replay_buffer/size             521000
trainer/QF1 Loss                    0.74084
trainer/QF2 Loss                    0.545999
trainer/Policy Loss               -41.2566
trainer/Q1 Predictions Mean        47.2393
trainer/Q1 Predictions Std          4.31315
trainer/Q1 Predictions Max         54.1006
trainer/Q1 Predictions Min         15.739
trainer/Q2 Predictions Mean        47.3434
trainer/Q2 Predictions Std          4.36782
trainer/Q2 Predictions Max         54.2926
trainer/Q2 Predictions Min         14.8289
trainer/Q Targets Mean             47.1959
trainer/Q Targets Std               4.30518
trainer/Q Targets Max              54.0482
trainer/Q Targets Min              17.1676
trainer/Log Pis Mean                6.27395
trainer/Log Pis Std                 4.83678
trainer/Log Pis Max                22.0379
trainer/Log Pis Min                -8.72667
trainer/Policy mu Mean              0.238356
trainer/Policy mu Std               1.47082
trainer/Policy mu Max               5.84107
trainer/Policy mu Min              -6.61195
trainer/Policy log std Mean        -1.05483
trainer/Policy log std Std          0.398238
trainer/Policy log std Max          0.806804
trainer/Policy log std Min         -3.04807
trainer/Alpha                       0.00763738
trainer/Alpha Loss                  1.33545
exploration/num steps total    521000
exploration/num paths total      1764
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0131419
exploration/Rewards Std             0.00930433
exploration/Rewards Max             0.060712
exploration/Rewards Min             7.38755e-05
exploration/Returns Mean            6.57095
exploration/Returns Std             2.3486
exploration/Returns Max            10.5739
exploration/Returns Min             3.2272
exploration/Actions Mean            0.0546331
exploration/Actions Std             0.446964
exploration/Actions Max             0.993537
exploration/Actions Min            -0.988725
exploration/Num Paths              10
exploration/Average Returns         6.57095
evaluation/num steps total     513738
evaluation/num paths total       1660
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00952705
evaluation/Rewards Std              0.00683397
evaluation/Rewards Max              0.0540261
evaluation/Rewards Min              0.000552874
evaluation/Returns Mean             4.76352
evaluation/Returns Std              1.89095
evaluation/Returns Max              7.59458
evaluation/Returns Min              1.17107
evaluation/ExplReturns Mean         4.76352
evaluation/ExplReturns Std          1.89095
evaluation/ExplReturns Max          7.59458
evaluation/ExplReturns Min          1.17107
evaluation/Actions Mean             0.0371162
evaluation/Actions Std              0.293761
evaluation/Actions Max              0.97589
evaluation/Actions Min             -0.96319
evaluation/Num Paths               10
evaluation/Average Returns          4.76352
time/data storing (s)               0.0291097
time/evaluation sampling (s)       68.6315
time/exploration sampling (s)      74.0002
time/logging (s)                    0.0250133
time/saving (s)                     0.0233564
time/training (s)                  10.1387
time/epoch (s)                    152.848
time/total (s)                  16025.6
Epoch                             103
-----------------------------  ----------------
2023-08-31 16:25:46.182035 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size             526000
trainer/QF1 Loss                    1.10834
trainer/QF2 Loss                    1.12624
trainer/Policy Loss               -40.5657
trainer/Q1 Predictions Mean        45.8652
trainer/Q1 Predictions Std          6.40592
trainer/Q1 Predictions Max         56.5739
trainer/Q1 Predictions Min         -6.09041
trainer/Q2 Predictions Mean        46.0344
trainer/Q2 Predictions Std          6.33217
trainer/Q2 Predictions Max         56.8898
trainer/Q2 Predictions Min        -15.725
trainer/Q Targets Mean             46.0635
trainer/Q Targets Std               6.09303
trainer/Q Targets Max              56.5033
trainer/Q Targets Min              -6.61645
trainer/Log Pis Mean                5.83715
trainer/Log Pis Std                 4.84019
trainer/Log Pis Max                40.6668
trainer/Log Pis Min                -2.47843
trainer/Policy mu Mean              0.376919
trainer/Policy mu Std               1.34549
trainer/Policy mu Max               7.95307
trainer/Policy mu Min              -5.55307
trainer/Policy log std Mean        -1.06033
trainer/Policy log std Std          0.392484
trainer/Policy log std Max          0.544224
trainer/Policy log std Min         -2.52754
trainer/Alpha                       0.00763672
trainer/Alpha Loss                 -0.793826
exploration/num steps total    526000
exploration/num paths total      1774
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00940864
exploration/Rewards Std             0.005713
exploration/Rewards Max             0.0461142
exploration/Rewards Min             0.00151718
exploration/Returns Mean            4.70432
exploration/Returns Std             1.68001
exploration/Returns Max             6.99428
exploration/Returns Min             1.84491
exploration/Actions Mean            0.0408335
exploration/Actions Std             0.459085
exploration/Actions Max             0.989922
exploration/Actions Min            -0.994814
exploration/Num Paths              10
exploration/Average Returns         4.70432
evaluation/num steps total     518738
evaluation/num paths total       1670
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00807616
evaluation/Rewards Std              0.00617707
evaluation/Rewards Max              0.0416266
evaluation/Rewards Min              0.00135775
evaluation/Returns Mean             4.03808
evaluation/Returns Std              1.54387
evaluation/Returns Max              6.12367
evaluation/Returns Min              1.76439
evaluation/ExplReturns Mean         4.03808
evaluation/ExplReturns Std          1.54387
evaluation/ExplReturns Max          6.12367
evaluation/ExplReturns Min          1.76439
evaluation/Actions Mean             0.0181868
evaluation/Actions Std              0.313998
evaluation/Actions Max              0.95365
evaluation/Actions Min             -0.947081
evaluation/Num Paths               10
evaluation/Average Returns          4.03808
time/data storing (s)               0.0288666
time/evaluation sampling (s)       68.7169
time/exploration sampling (s)      75.7851
time/logging (s)                    0.0251712
time/saving (s)                     0.0675863
time/training (s)                  13.0939
time/epoch (s)                    157.717
time/total (s)                  16183.3
Epoch                             104
-----------------------------  ---------------
2023-08-31 16:28:24.933739 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 105 finished
-----------------------------  ----------------
replay_buffer/size             531000
trainer/QF1 Loss                    5.31687
trainer/QF2 Loss                    5.16254
trainer/Policy Loss               -39.842
trainer/Q1 Predictions Mean        45.1819
trainer/Q1 Predictions Std          5.06373
trainer/Q1 Predictions Max         56.3064
trainer/Q1 Predictions Min          2.70233
trainer/Q2 Predictions Mean        45.2469
trainer/Q2 Predictions Std          4.86916
trainer/Q2 Predictions Max         55.949
trainer/Q2 Predictions Min          7.01764
trainer/Q Targets Mean             45.0372
trainer/Q Targets Std               5.73815
trainer/Q Targets Max              55.5211
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.81864
trainer/Log Pis Std                 4.13916
trainer/Log Pis Max                21.9007
trainer/Log Pis Min                -2.60333
trainer/Policy mu Mean              0.380032
trainer/Policy mu Std               1.3314
trainer/Policy mu Max               4.35052
trainer/Policy mu Min              -4.23405
trainer/Policy log std Mean        -1.04006
trainer/Policy log std Std          0.370707
trainer/Policy log std Max          0.135276
trainer/Policy log std Min         -2.47697
trainer/Alpha                       0.00782577
trainer/Alpha Loss                 -0.879636
exploration/num steps total    531000
exploration/num paths total      1786
exploration/path length Mean      416.667
exploration/path length Std       149.094
exploration/path length Max       500
exploration/path length Min        84
exploration/Rewards Mean            0.00554844
exploration/Rewards Std             0.00977314
exploration/Rewards Max             0.0430505
exploration/Rewards Min            -0.281611
exploration/Returns Mean            2.31185
exploration/Returns Std             1.91322
exploration/Returns Max             6.92646
exploration/Returns Min             0.350213
exploration/Actions Mean            0.0293516
exploration/Actions Std             0.444695
exploration/Actions Max             0.998725
exploration/Actions Min            -0.999912
exploration/Num Paths              12
exploration/Average Returns         2.31185
evaluation/num steps total     523738
evaluation/num paths total       1680
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0094609
evaluation/Rewards Std              0.0101178
evaluation/Rewards Max              0.0468786
evaluation/Rewards Min              0.000296375
evaluation/Returns Mean             4.73045
evaluation/Returns Std              4.2071
evaluation/Returns Max             14.3446
evaluation/Returns Min              0.978483
evaluation/ExplReturns Mean         4.73045
evaluation/ExplReturns Std          4.2071
evaluation/ExplReturns Max         14.3446
evaluation/ExplReturns Min          0.978483
evaluation/Actions Mean             0.00769342
evaluation/Actions Std              0.294697
evaluation/Actions Max              0.97926
evaluation/Actions Min             -0.975451
evaluation/Num Paths               10
evaluation/Average Returns          4.73045
time/data storing (s)               0.0289035
time/evaluation sampling (s)       68.6806
time/exploration sampling (s)      75.4952
time/logging (s)                    0.0258331
time/saving (s)                     0.0746097
time/training (s)                  14.4432
time/epoch (s)                    158.748
time/total (s)                  16342
Epoch                             105
-----------------------------  ----------------
2023-08-31 16:31:02.422130 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size             536000
trainer/QF1 Loss                    0.70402
trainer/QF2 Loss                    0.998448
trainer/Policy Loss               -39.8862
trainer/Q1 Predictions Mean        44.7792
trainer/Q1 Predictions Std          4.33658
trainer/Q1 Predictions Max         58.6063
trainer/Q1 Predictions Min          9.78167
trainer/Q2 Predictions Mean        44.8003
trainer/Q2 Predictions Std          4.24211
trainer/Q2 Predictions Max         58.3466
trainer/Q2 Predictions Min         13.2112
trainer/Q Targets Mean             44.9722
trainer/Q Targets Std               4.66705
trainer/Q Targets Max              58.6402
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                5.27607
trainer/Log Pis Std                 4.56939
trainer/Log Pis Max                20.4004
trainer/Log Pis Min                -4.38456
trainer/Policy mu Mean              0.172562
trainer/Policy mu Std               1.37859
trainer/Policy mu Max               4.3898
trainer/Policy mu Min              -5.25919
trainer/Policy log std Mean        -1.01655
trainer/Policy log std Std          0.372041
trainer/Policy log std Max          0.270031
trainer/Policy log std Min         -2.3838
trainer/Alpha                       0.00862614
trainer/Alpha Loss                 -3.44084
exploration/num steps total    536000
exploration/num paths total      1835
exploration/path length Mean      102.041
exploration/path length Std        16.7806
exploration/path length Max       136
exploration/path length Min        59
exploration/Rewards Mean            0.00949044
exploration/Rewards Std             0.0320904
exploration/Rewards Max             0.0704831
exploration/Rewards Min            -0.281611
exploration/Returns Mean            0.968412
exploration/Returns Std             0.687479
exploration/Returns Max             2.80763
exploration/Returns Min             0.102692
exploration/Actions Mean            0.106404
exploration/Actions Std             0.606483
exploration/Actions Max             0.999956
exploration/Actions Min            -0.999634
exploration/Num Paths              49
exploration/Average Returns         0.968412
evaluation/num steps total     528678
evaluation/num paths total       1727
evaluation/path length Mean       105.106
evaluation/path length Std          8.90191
evaluation/path length Max        120
evaluation/path length Min         62
evaluation/Rewards Mean             0.00857381
evaluation/Rewards Std              0.0318038
evaluation/Rewards Max              0.0749378
evaluation/Rewards Min             -0.281611
evaluation/Returns Mean             0.901162
evaluation/Returns Std              0.635457
evaluation/Returns Max              2.35369
evaluation/Returns Min              0.0477761
evaluation/ExplReturns Mean         0.901162
evaluation/ExplReturns Std          0.635457
evaluation/ExplReturns Max          2.35369
evaluation/ExplReturns Min          0.0477761
evaluation/Actions Mean             0.102834
evaluation/Actions Std              0.578183
evaluation/Actions Max              0.999656
evaluation/Actions Min             -0.997706
evaluation/Num Paths               47
evaluation/Average Returns          0.901162
time/data storing (s)               0.0291234
time/evaluation sampling (s)       69.4709
time/exploration sampling (s)      76.2081
time/logging (s)                    0.0257232
time/saving (s)                     0.0659685
time/training (s)                  11.6843
time/epoch (s)                    157.484
time/total (s)                  16499.5
Epoch                             106
-----------------------------  ---------------
2023-08-31 16:33:41.340403 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 107 finished
-----------------------------  ----------------
replay_buffer/size             541000
trainer/QF1 Loss                    1.43416
trainer/QF2 Loss                    1.41433
trainer/Policy Loss               -38.3796
trainer/Q1 Predictions Mean        44.0627
trainer/Q1 Predictions Std          4.78106
trainer/Q1 Predictions Max         57.4448
trainer/Q1 Predictions Min         14.6723
trainer/Q2 Predictions Mean        44.2075
trainer/Q2 Predictions Std          4.78817
trainer/Q2 Predictions Max         57.7285
trainer/Q2 Predictions Min         14.6697
trainer/Q Targets Mean             43.9931
trainer/Q Targets Std               5.30078
trainer/Q Targets Max              57.7521
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.10306
trainer/Log Pis Std                 4.32915
trainer/Log Pis Max                29.9331
trainer/Log Pis Min                -2.05226
trainer/Policy mu Mean              0.342833
trainer/Policy mu Std               1.39933
trainer/Policy mu Max               4.47363
trainer/Policy mu Min              -6.65867
trainer/Policy log std Mean        -1.05269
trainer/Policy log std Std          0.392798
trainer/Policy log std Max          0.0282315
trainer/Policy log std Min         -2.44224
trainer/Alpha                       0.00833642
trainer/Alpha Loss                  0.493382
exploration/num steps total    541000
exploration/num paths total      1851
exploration/path length Mean      312.5
exploration/path length Std       175.126
exploration/path length Max       500
exploration/path length Min        56
exploration/Rewards Mean            0.00438211
exploration/Rewards Std             0.0169671
exploration/Rewards Max             0.106288
exploration/Rewards Min            -0.281611
exploration/Returns Mean            1.36941
exploration/Returns Std             0.52873
exploration/Returns Max             2.63088
exploration/Returns Min             0.560454
exploration/Actions Mean            0.010508
exploration/Actions Std             0.473078
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999929
exploration/Num Paths              16
exploration/Average Returns         1.36941
evaluation/num steps total     533678
evaluation/num paths total       1737
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00251866
evaluation/Rewards Std              0.00855758
evaluation/Rewards Max              0.0628462
evaluation/Rewards Min              5.50587e-05
evaluation/Returns Mean             1.25933
evaluation/Returns Std              0.425602
evaluation/Returns Max              2.31654
evaluation/Returns Min              0.69133
evaluation/ExplReturns Mean         1.25933
evaluation/ExplReturns Std          0.425602
evaluation/ExplReturns Max          2.31654
evaluation/ExplReturns Min          0.69133
evaluation/Actions Mean            -0.0053418
evaluation/Actions Std              0.331671
evaluation/Actions Max              0.999163
evaluation/Actions Min             -0.978725
evaluation/Num Paths               10
evaluation/Average Returns          1.25933
time/data storing (s)               0.0299878
time/evaluation sampling (s)       69.3028
time/exploration sampling (s)      74.9767
time/logging (s)                    0.0254409
time/saving (s)                     0.0436324
time/training (s)                  14.5352
time/epoch (s)                    158.914
time/total (s)                  16658.4
Epoch                             107
-----------------------------  ----------------
2023-08-31 16:36:16.589066 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 108 finished
-----------------------------  ----------------
replay_buffer/size             546000
trainer/QF1 Loss                    0.323193
trainer/QF2 Loss                    0.282845
trainer/Policy Loss               -38.4675
trainer/Q1 Predictions Mean        43.9182
trainer/Q1 Predictions Std          3.99972
trainer/Q1 Predictions Max         56.6094
trainer/Q1 Predictions Min         28.2747
trainer/Q2 Predictions Mean        44.0828
trainer/Q2 Predictions Std          3.98242
trainer/Q2 Predictions Max         56.7446
trainer/Q2 Predictions Min         30.3619
trainer/Q Targets Mean             43.8514
trainer/Q Targets Std               3.96161
trainer/Q Targets Max              56.3079
trainer/Q Targets Min              30.4904
trainer/Log Pis Mean                5.82121
trainer/Log Pis Std                 3.86197
trainer/Log Pis Max                29.7644
trainer/Log Pis Min                -3.54836
trainer/Policy mu Mean              0.247629
trainer/Policy mu Std               1.41728
trainer/Policy mu Max               5.16922
trainer/Policy mu Min              -5.89006
trainer/Policy log std Mean        -0.987523
trainer/Policy log std Std          0.366501
trainer/Policy log std Max          0.290095
trainer/Policy log std Min         -2.4271
trainer/Alpha                       0.00842613
trainer/Alpha Loss                 -0.85398
exploration/num steps total    546000
exploration/num paths total      1861
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00429033
exploration/Rewards Std             0.00737738
exploration/Rewards Max             0.0698496
exploration/Rewards Min             0.000707956
exploration/Returns Mean            2.14517
exploration/Returns Std             0.399613
exploration/Returns Max             2.62784
exploration/Returns Min             1.27865
exploration/Actions Mean           -0.0172588
exploration/Actions Std             0.489007
exploration/Actions Max             0.999799
exploration/Actions Min            -0.987628
exploration/Num Paths              10
exploration/Average Returns         2.14517
evaluation/num steps total     538678
evaluation/num paths total       1747
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00243096
evaluation/Rewards Std              0.00828277
evaluation/Rewards Max              0.0647926
evaluation/Rewards Min              5.64431e-05
evaluation/Returns Mean             1.21548
evaluation/Returns Std              0.270886
evaluation/Returns Max              1.53439
evaluation/Returns Min              0.566889
evaluation/ExplReturns Mean         1.21548
evaluation/ExplReturns Std          0.270886
evaluation/ExplReturns Max          1.53439
evaluation/ExplReturns Min          0.566889
evaluation/Actions Mean            -0.0658371
evaluation/Actions Std              0.431982
evaluation/Actions Max              0.998399
evaluation/Actions Min             -0.957779
evaluation/Num Paths               10
evaluation/Average Returns          1.21548
time/data storing (s)               0.0289369
time/evaluation sampling (s)       68.891
time/exploration sampling (s)      75.8757
time/logging (s)                    0.025273
time/saving (s)                     0.0534311
time/training (s)                  10.37
time/epoch (s)                    155.244
time/total (s)                  16813.7
Epoch                             108
-----------------------------  ----------------
2023-08-31 16:38:54.925643 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size             551000
trainer/QF1 Loss                    1.846
trainer/QF2 Loss                    1.4074
trainer/Policy Loss               -37.8692
trainer/Q1 Predictions Mean        43.3991
trainer/Q1 Predictions Std          5.1985
trainer/Q1 Predictions Max         55.8118
trainer/Q1 Predictions Min         16.2501
trainer/Q2 Predictions Mean        43.5173
trainer/Q2 Predictions Std          5.15803
trainer/Q2 Predictions Max         56.1849
trainer/Q2 Predictions Min         13.9033
trainer/Q Targets Mean             43.3711
trainer/Q Targets Std               5.58224
trainer/Q Targets Max              55.8444
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.10192
trainer/Log Pis Std                 5.04449
trainer/Log Pis Max                37.9516
trainer/Log Pis Min                -5.84491
trainer/Policy mu Mean              0.157759
trainer/Policy mu Std               1.46569
trainer/Policy mu Max               5.47425
trainer/Policy mu Min              -5.31904
trainer/Policy log std Mean        -1.02443
trainer/Policy log std Std          0.374958
trainer/Policy log std Max          0.205996
trainer/Policy log std Min         -2.6752
trainer/Alpha                       0.00830484
trainer/Alpha Loss                  0.48831
exploration/num steps total    551000
exploration/num paths total      1871
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0139631
exploration/Rewards Std             0.00829047
exploration/Rewards Max             0.0947393
exploration/Rewards Min            -0.14073
exploration/Returns Mean            6.98155
exploration/Returns Std             2.46104
exploration/Returns Max            10.0579
exploration/Returns Min             3.33045
exploration/Actions Mean            0.00237755
exploration/Actions Std             0.417639
exploration/Actions Max             0.999923
exploration/Actions Min            -0.997003
exploration/Num Paths              10
exploration/Average Returns         6.98155
evaluation/num steps total     543678
evaluation/num paths total       1757
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0108396
evaluation/Rewards Std              0.00829881
evaluation/Rewards Max              0.0904063
evaluation/Rewards Min              0.00223065
evaluation/Returns Mean             5.41981
evaluation/Returns Std              2.12853
evaluation/Returns Max              9.0833
evaluation/Returns Min              2.27903
evaluation/ExplReturns Mean         5.41981
evaluation/ExplReturns Std          2.12853
evaluation/ExplReturns Max          9.0833
evaluation/ExplReturns Min          2.27903
evaluation/Actions Mean            -0.0842074
evaluation/Actions Std              0.352866
evaluation/Actions Max              0.998843
evaluation/Actions Min             -0.993444
evaluation/Num Paths               10
evaluation/Average Returns          5.41981
time/data storing (s)               0.0293093
time/evaluation sampling (s)       69.3279
time/exploration sampling (s)      75.1681
time/logging (s)                    0.0262784
time/saving (s)                     0.0621284
time/training (s)                  13.7197
time/epoch (s)                    158.333
time/total (s)                  16972
Epoch                             109
-----------------------------  ---------------
2023-08-31 16:41:30.150352 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 110 finished
-----------------------------  ----------------
replay_buffer/size             556000
trainer/QF1 Loss                    0.837599
trainer/QF2 Loss                    0.849133
trainer/Policy Loss               -36.7084
trainer/Q1 Predictions Mean        42.3353
trainer/Q1 Predictions Std          5.83967
trainer/Q1 Predictions Max         54.2075
trainer/Q1 Predictions Min         -0.261792
trainer/Q2 Predictions Mean        42.2583
trainer/Q2 Predictions Std          5.79645
trainer/Q2 Predictions Max         54.159
trainer/Q2 Predictions Min          2.99142
trainer/Q Targets Mean             42.2656
trainer/Q Targets Std               6.11322
trainer/Q Targets Max              53.9246
trainer/Q Targets Min              -0.281611
trainer/Log Pis Mean                6.08323
trainer/Log Pis Std                 4.67831
trainer/Log Pis Max                30.6435
trainer/Log Pis Min                -3.72142
trainer/Policy mu Mean              0.195258
trainer/Policy mu Std               1.49435
trainer/Policy mu Max               5.71148
trainer/Policy mu Min              -7.62364
trainer/Policy log std Mean        -0.979444
trainer/Policy log std Std          0.369485
trainer/Policy log std Max          0.0595361
trainer/Policy log std Min         -2.35186
trainer/Alpha                       0.00875163
trainer/Alpha Loss                  0.394365
exploration/num steps total    556000
exploration/num paths total      1881
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00166609
exploration/Rewards Std             0.00633019
exploration/Rewards Max             0.0665305
exploration/Rewards Min             6.26069e-05
exploration/Returns Mean            0.833047
exploration/Returns Std             0.221834
exploration/Returns Max             1.19739
exploration/Returns Min             0.493965
exploration/Actions Mean            0.0124626
exploration/Actions Std             0.394375
exploration/Actions Max             0.99973
exploration/Actions Min            -0.997299
exploration/Num Paths              10
exploration/Average Returns         0.833047
evaluation/num steps total     548678
evaluation/num paths total       1767
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00133546
evaluation/Rewards Std              0.00513442
evaluation/Rewards Max              0.050559
evaluation/Rewards Min              8.58801e-05
evaluation/Returns Mean             0.667729
evaluation/Returns Std              0.166229
evaluation/Returns Max              0.991995
evaluation/Returns Min              0.426276
evaluation/ExplReturns Mean         0.667729
evaluation/ExplReturns Std          0.166229
evaluation/ExplReturns Max          0.991995
evaluation/ExplReturns Min          0.426276
evaluation/Actions Mean             0.0198079
evaluation/Actions Std              0.207834
evaluation/Actions Max              0.998108
evaluation/Actions Min             -0.983773
evaluation/Num Paths               10
evaluation/Average Returns          0.667729
time/data storing (s)               0.0291698
time/evaluation sampling (s)       68.8737
time/exploration sampling (s)      75.9289
time/logging (s)                    0.0260152
time/saving (s)                     0.0690275
time/training (s)                  10.2934
time/epoch (s)                    155.22
time/total (s)                  17127.2
Epoch                             110
-----------------------------  ----------------
2023-08-31 16:44:04.225888 CST | [Wipe_Panda_OSC_POSE_SEED1_2023_08_31_11_56_03_0000--s-0] Epoch 111 finished
-----------------------------  ----------------
replay_buffer/size             561000
trainer/QF1 Loss                    0.214472
trainer/QF2 Loss                    0.281459
trainer/Policy Loss               -37.1162
trainer/Q1 Predictions Mean        42.1914
trainer/Q1 Predictions Std          4.51541
trainer/Q1 Predictions Max         53.4944
trainer/Q1 Predictions Min         22.016
trainer/Q2 Predictions Mean        42.2764
trainer/Q2 Predictions Std          4.50906
trainer/Q2 Predictions Max         53.4039
trainer/Q2 Predictions Min         22.9353
trainer/Q Targets Mean             42.0779
trainer/Q Targets Std               4.46666
trainer/Q Targets Max              53.1798
trainer/Q Targets Min              23.0762
trainer/Log Pis Mean                5.48453
trainer/Log Pis Std                 4.24179
trainer/Log Pis Max                26.1258
trainer/Log Pis Min                -3.82152
trainer/Policy mu Mean              0.203986
trainer/Policy mu Std               1.4077
trainer/Policy mu Max               5.14619
trainer/Policy mu Min              -4.92901
trainer/Policy log std Mean        -0.980768
trainer/Policy log std Std          0.36439
trainer/Policy log std Max          0.0294894
trainer/Policy log std Min         -2.30261
trainer/Alpha                       0.00953354
trainer/Alpha Loss                 -2.39841
exploration/num steps total    561000
exploration/num paths total      1891
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00172069
exploration/Rewards Std             0.00585897
exploration/Rewards Max             0.0684384
exploration/Rewards Min             0.000150929
exploration/Returns Mean            0.860347
exploration/Returns Std             0.273666
exploration/Returns Max             1.35721
exploration/Returns Min             0.547109
exploration/Actions Mean            0.0142446
exploration/Actions Std             0.396515
exploration/Actions Max             0.99968
exploration/Actions Min            -0.997727
exploration/Num Paths              10
exploration/Average Returns         0.860347
evaluation/num steps total     553678
evaluation/num paths total       1777
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00192048
evaluation/Rewards Std              0.00578855
evaluation/Rewards Max              0.0550349
evaluation/Rewards Min              0.000230199
evaluation/Returns Mean             0.96024
evaluation/Returns Std              0.19747
evaluation/Returns Max              1.31128
evaluation/Returns Min              0.678422
evaluation/ExplReturns Mean         0.96024
evaluation/ExplReturns Std          0.19747
evaluation/ExplReturns Max          1.31128
evaluation/ExplReturns Min          0.678422
evaluation/Actions Mean             0.016196
evaluation/Actions Std              0.25262
evaluation/Actions Max              0.997754
evaluation/Actions Min             -0.985529
evaluation/Num Paths               10
evaluation/Average Returns          0.96024
time/data storing (s)               0.0293421
time/evaluation sampling (s)       68.604
time/exploration sampling (s)      74.711
time/logging (s)                    0.0256068
time/saving (s)                     0.0678135
time/training (s)                  10.6332
time/epoch (s)                    154.071
time/total (s)                  17281.3
Epoch                             111
-----------------------------  ----------------
