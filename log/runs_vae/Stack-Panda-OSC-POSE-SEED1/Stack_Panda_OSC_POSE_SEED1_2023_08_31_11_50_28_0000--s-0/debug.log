2023-08-31 11:53:12.331125 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size             6000
trainer/QF1 Loss                 22.0909
trainer/QF2 Loss                 22.0254
trainer/Policy Loss              -4.64144
trainer/Q1 Predictions Mean      -0.00631832
trainer/Q1 Predictions Std        0.00125514
trainer/Q1 Predictions Max       -0.00342757
trainer/Q1 Predictions Min       -0.00979423
trainer/Q2 Predictions Mean       0.000704956
trainer/Q2 Predictions Std        0.00109496
trainer/Q2 Predictions Max        0.0040589
trainer/Q2 Predictions Min       -0.00220028
trainer/Q Targets Mean            4.65815
trainer/Q Targets Std             0.57756
trainer/Q Targets Max             6.72278
trainer/Q Targets Min             3.14101
trainer/Log Pis Mean             -4.64777
trainer/Log Pis Std               0.559641
trainer/Log Pis Max              -2.94545
trainer/Log Pis Min              -6.32504
trainer/Policy mu Mean           -0.000476372
trainer/Policy mu Std             0.00190186
trainer/Policy mu Max             0.00312296
trainer/Policy mu Min            -0.00412547
trainer/Policy log std Mean       0.000445173
trainer/Policy log std Std        0.00128305
trainer/Policy log std Max        0.00286552
trainer/Policy log std Min       -0.00267796
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total    6000
exploration/num paths total      12
exploration/path length Mean    500
exploration/path length Std       0
exploration/path length Max     500
exploration/path length Min     500
exploration/Rewards Mean          0.00381937
exploration/Rewards Std           0.00787111
exploration/Rewards Max           0.0821718
exploration/Rewards Min           1.1949e-09
exploration/Returns Mean          1.90969
exploration/Returns Std           1.41446
exploration/Returns Max           4.0647
exploration/Returns Min           0.0487905
exploration/Actions Mean          0.00120536
exploration/Actions Std           0.627347
exploration/Actions Max           0.999405
exploration/Actions Min          -0.999871
exploration/Num Paths            10
exploration/Average Returns       1.90969
evaluation/num steps total     5000
evaluation/num paths total       10
evaluation/path length Mean     500
evaluation/path length Std        0
evaluation/path length Max      500
evaluation/path length Min      500
evaluation/Rewards Mean           0.00357736
evaluation/Rewards Std            0.00136751
evaluation/Rewards Max            0.00646309
evaluation/Rewards Min            0.00155863
evaluation/Returns Mean           1.78868
evaluation/Returns Std            0.682144
evaluation/Returns Max            3.21563
evaluation/Returns Min            0.80562
evaluation/ExplReturns Mean       1.78868
evaluation/ExplReturns Std        0.682144
evaluation/ExplReturns Max        3.21563
evaluation/ExplReturns Min        0.80562
evaluation/Actions Mean          -0.000588499
evaluation/Actions Std            0.00194109
evaluation/Actions Max            0.00237825
evaluation/Actions Min           -0.00357589
evaluation/Num Paths             10
evaluation/Average Returns        1.78868
time/data storing (s)             0.0311469
time/evaluation sampling (s)     67.3388
time/exploration sampling (s)    67.3454
time/logging (s)                  0.0248548
time/saving (s)                   0.0160878
time/training (s)                 9.29898
time/epoch (s)                  144.055
time/total (s)                  169.646
Epoch                             0
-----------------------------  --------------
2023-08-31 11:55:35.728225 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 1 finished
-----------------------------  ---------------
replay_buffer/size             11000
trainer/QF1 Loss                   0.0654897
trainer/QF2 Loss                   0.0637122
trainer/Policy Loss              -22.0643
trainer/Q1 Predictions Mean       17.2879
trainer/Q1 Predictions Std         0.544483
trainer/Q1 Predictions Max        18.273
trainer/Q1 Predictions Min        14.4558
trainer/Q2 Predictions Mean       17.2971
trainer/Q2 Predictions Std         0.536817
trainer/Q2 Predictions Max        18.3624
trainer/Q2 Predictions Min        14.5576
trainer/Q Targets Mean            17.3017
trainer/Q Targets Std              0.484604
trainer/Q Targets Max             18.6254
trainer/Q Targets Min             14.9402
trainer/Log Pis Mean              -4.79197
trainer/Log Pis Std                0.314915
trainer/Log Pis Max               -3.9801
trainer/Log Pis Min               -6.47698
trainer/Policy mu Mean            -0.00283044
trainer/Policy mu Std              0.00542091
trainer/Policy mu Max              0.0129942
trainer/Policy mu Min             -0.016577
trainer/Policy log std Mean       -0.140094
trainer/Policy log std Std         0.00623518
trainer/Policy log std Max        -0.117962
trainer/Policy log std Min        -0.160704
trainer/Alpha                      0.740549
trainer/Alpha Loss                -3.53833
exploration/num steps total    11000
exploration/num paths total       22
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00490606
exploration/Rewards Std            0.0109351
exploration/Rewards Max            0.0946063
exploration/Rewards Min            1.4907e-07
exploration/Returns Mean           2.45303
exploration/Returns Std            2.56883
exploration/Returns Max            7.47284
exploration/Returns Min            0.202515
exploration/Actions Mean          -0.00597387
exploration/Actions Std            0.584219
exploration/Actions Max            0.998808
exploration/Actions Min           -0.99714
exploration/Num Paths             10
exploration/Average Returns        2.45303
evaluation/num steps total     10000
evaluation/num paths total        20
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00246088
evaluation/Rewards Std             0.0011456
evaluation/Rewards Max             0.00600789
evaluation/Rewards Min             0.000395568
evaluation/Returns Mean            1.23044
evaluation/Returns Std             0.417931
evaluation/Returns Max             2.00385
evaluation/Returns Min             0.389095
evaluation/ExplReturns Mean        1.23044
evaluation/ExplReturns Std         0.417931
evaluation/ExplReturns Max         2.00385
evaluation/ExplReturns Min         0.389095
evaluation/Actions Mean           -0.0031759
evaluation/Actions Std             0.00469992
evaluation/Actions Max             0.00570264
evaluation/Actions Min            -0.0131468
evaluation/Num Paths              10
evaluation/Average Returns         1.23044
time/data storing (s)              0.0313218
time/evaluation sampling (s)      64.8378
time/exploration sampling (s)     68.5221
time/logging (s)                   0.0249321
time/saving (s)                    0.0670873
time/training (s)                  9.91058
time/epoch (s)                   143.394
time/total (s)                   313.043
Epoch                              1
-----------------------------  ---------------
2023-08-31 11:58:04.871764 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 2 finished
-----------------------------  ---------------
replay_buffer/size             16000
trainer/QF1 Loss                   0.0292528
trainer/QF2 Loss                   0.0312677
trainer/Policy Loss              -34.441
trainer/Q1 Predictions Mean       29.6698
trainer/Q1 Predictions Std         0.693191
trainer/Q1 Predictions Max        31.0431
trainer/Q1 Predictions Min        27.2793
trainer/Q2 Predictions Mean       29.6884
trainer/Q2 Predictions Std         0.685743
trainer/Q2 Predictions Max        31.0755
trainer/Q2 Predictions Min        27.4905
trainer/Q Targets Mean            29.6382
trainer/Q Targets Std              0.673619
trainer/Q Targets Max             30.9764
trainer/Q Targets Min             27.339
trainer/Log Pis Mean              -4.78615
trainer/Log Pis Std                0.288302
trainer/Log Pis Max               -3.98776
trainer/Log Pis Min               -6.22875
trainer/Policy mu Mean            -0.00109431
trainer/Policy mu Std              0.00852861
trainer/Policy mu Max              0.0242582
trainer/Policy mu Min             -0.019045
trainer/Policy log std Mean       -0.131974
trainer/Policy log std Std         0.00671921
trainer/Policy log std Max        -0.111344
trainer/Policy log std Min        -0.149845
trainer/Alpha                      0.548616
trainer/Alpha Loss                -7.07236
exploration/num steps total    16000
exploration/num paths total       32
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00259941
exploration/Rewards Std            0.00822317
exploration/Rewards Max            0.0777652
exploration/Rewards Min            2.21668e-08
exploration/Returns Mean           1.29971
exploration/Returns Std            2.08512
exploration/Returns Max            7.26289
exploration/Returns Min            0.0293087
exploration/Actions Mean           0.00183512
exploration/Actions Std            0.59014
exploration/Actions Max            0.999559
exploration/Actions Min           -0.9997
exploration/Num Paths             10
exploration/Average Returns        1.29971
evaluation/num steps total     15000
evaluation/num paths total        30
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00203644
evaluation/Rewards Std             0.00119905
evaluation/Rewards Max             0.00590015
evaluation/Rewards Min             0.000569177
evaluation/Returns Mean            1.01822
evaluation/Returns Std             0.47176
evaluation/Returns Max             2.19525
evaluation/Returns Min             0.453955
evaluation/ExplReturns Mean        1.01822
evaluation/ExplReturns Std         0.47176
evaluation/ExplReturns Max         2.19525
evaluation/ExplReturns Min         0.453955
evaluation/Actions Mean           -0.000453055
evaluation/Actions Std             0.00684201
evaluation/Actions Max             0.0178993
evaluation/Actions Min            -0.0122654
evaluation/Num Paths              10
evaluation/Average Returns         1.01822
time/data storing (s)              0.0313812
time/evaluation sampling (s)      66.655
time/exploration sampling (s)     71.983
time/logging (s)                   0.0254525
time/saving (s)                    0.062514
time/training (s)                 10.3833
time/epoch (s)                   149.141
time/total (s)                   462.186
Epoch                              2
-----------------------------  ---------------
2023-08-31 12:00:34.837325 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 3 finished
-----------------------------  ---------------
replay_buffer/size             21000
trainer/QF1 Loss                   0.0278874
trainer/QF2 Loss                   0.0265104
trainer/Policy Loss              -42.8998
trainer/Q1 Predictions Mean       38.1748
trainer/Q1 Predictions Std         0.687906
trainer/Q1 Predictions Max        40.0981
trainer/Q1 Predictions Min        36.135
trainer/Q2 Predictions Mean       38.1687
trainer/Q2 Predictions Std         0.688478
trainer/Q2 Predictions Max        39.9253
trainer/Q2 Predictions Min        36.1724
trainer/Q Targets Mean            38.2206
trainer/Q Targets Std              0.669037
trainer/Q Targets Max             39.8157
trainer/Q Targets Min             36.2262
trainer/Log Pis Mean              -4.74899
trainer/Log Pis Std                0.276749
trainer/Log Pis Max               -4.05931
trainer/Log Pis Min               -5.68612
trainer/Policy mu Mean             0.00100839
trainer/Policy mu Std              0.0198292
trainer/Policy mu Max              0.0620329
trainer/Policy mu Min             -0.0440949
trainer/Policy log std Mean       -0.13172
trainer/Policy log std Std         0.00752375
trainer/Policy log std Max        -0.11235
trainer/Policy log std Min        -0.152648
trainer/Alpha                      0.406423
trainer/Alpha Loss               -10.5748
exploration/num steps total    21000
exploration/num paths total       42
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0027947
exploration/Rewards Std            0.00574101
exploration/Rewards Max            0.082565
exploration/Rewards Min            2.46631e-08
exploration/Returns Mean           1.39735
exploration/Returns Std            1.5541
exploration/Returns Max            4.41241
exploration/Returns Min            0.00739295
exploration/Actions Mean           0.000586316
exploration/Actions Std            0.589335
exploration/Actions Max            0.997331
exploration/Actions Min           -0.996385
exploration/Num Paths             10
exploration/Average Returns        1.39735
evaluation/num steps total     20000
evaluation/num paths total        40
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00220015
evaluation/Rewards Std             0.001016
evaluation/Rewards Max             0.00493215
evaluation/Rewards Min             0.00044772
evaluation/Returns Mean            1.10008
evaluation/Returns Std             0.267831
evaluation/Returns Max             1.50065
evaluation/Returns Min             0.685911
evaluation/ExplReturns Mean        1.10008
evaluation/ExplReturns Std         0.267831
evaluation/ExplReturns Max         1.50065
evaluation/ExplReturns Min         0.685911
evaluation/Actions Mean           -0.000294074
evaluation/Actions Std             0.0179725
evaluation/Actions Max             0.0319716
evaluation/Actions Min            -0.035589
evaluation/Num Paths              10
evaluation/Average Returns         1.10008
time/data storing (s)              0.0313016
time/evaluation sampling (s)      67.1631
time/exploration sampling (s)     72.5634
time/logging (s)                   0.0255708
time/saving (s)                    0.0992805
time/training (s)                 10.0796
time/epoch (s)                   149.962
time/total (s)                   612.151
Epoch                              3
-----------------------------  ---------------
2023-08-31 12:03:05.122975 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 4 finished
-----------------------------  ---------------
replay_buffer/size             26000
trainer/QF1 Loss                   0.0185737
trainer/QF2 Loss                   0.0174669
trainer/Policy Loss              -48.7245
trainer/Q1 Predictions Mean       43.9582
trainer/Q1 Predictions Std         0.688049
trainer/Q1 Predictions Max        45.9283
trainer/Q1 Predictions Min        41.0169
trainer/Q2 Predictions Mean       43.9642
trainer/Q2 Predictions Std         0.684724
trainer/Q2 Predictions Max        45.9324
trainer/Q2 Predictions Min        41.0547
trainer/Q Targets Mean            44.0316
trainer/Q Targets Std              0.682618
trainer/Q Targets Max             45.8119
trainer/Q Targets Min             41.5425
trainer/Log Pis Mean              -4.78668
trainer/Log Pis Std                0.303604
trainer/Log Pis Max               -3.98388
trainer/Log Pis Min               -6.18005
trainer/Policy mu Mean            -0.00782959
trainer/Policy mu Std              0.0280646
trainer/Policy mu Max              0.0991308
trainer/Policy mu Min             -0.136691
trainer/Policy log std Mean       -0.136544
trainer/Policy log std Std         0.00941256
trainer/Policy log std Max        -0.115908
trainer/Policy log std Min        -0.174824
trainer/Alpha                      0.301102
trainer/Alpha Loss               -14.1441
exploration/num steps total    26000
exploration/num paths total       52
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00329484
exploration/Rewards Std            0.00983732
exploration/Rewards Max            0.114139
exploration/Rewards Min            1.83058e-09
exploration/Returns Mean           1.64742
exploration/Returns Std            2.50605
exploration/Returns Max            7.70864
exploration/Returns Min            0.0251619
exploration/Actions Mean          -0.00538172
exploration/Actions Std            0.585854
exploration/Actions Max            0.999286
exploration/Actions Min           -0.998969
exploration/Num Paths             10
exploration/Average Returns        1.64742
evaluation/num steps total     25000
evaluation/num paths total        50
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0247838
evaluation/Rewards Std             0.0158829
evaluation/Rewards Max             0.0572307
evaluation/Rewards Min             0.00105083
evaluation/Returns Mean           12.3919
evaluation/Returns Std             3.67482
evaluation/Returns Max            18.4234
evaluation/Returns Min             8.59003
evaluation/ExplReturns Mean       12.3919
evaluation/ExplReturns Std         3.67482
evaluation/ExplReturns Max        18.4234
evaluation/ExplReturns Min         8.59003
evaluation/Actions Mean           -0.00598273
evaluation/Actions Std             0.0194183
evaluation/Actions Max             0.0433131
evaluation/Actions Min            -0.0512303
evaluation/Num Paths              10
evaluation/Average Returns        12.3919
time/data storing (s)              0.0312837
time/evaluation sampling (s)      66.9682
time/exploration sampling (s)     72.9438
time/logging (s)                   0.0257262
time/saving (s)                    0.0637479
time/training (s)                 10.2498
time/epoch (s)                   150.282
time/total (s)                   762.436
Epoch                              4
-----------------------------  ---------------
2023-08-31 12:05:35.291384 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 5 finished
-----------------------------  ---------------
replay_buffer/size             31000
trainer/QF1 Loss                   0.0114236
trainer/QF2 Loss                   0.0118096
trainer/Policy Loss              -52.126
trainer/Q1 Predictions Mean       47.3655
trainer/Q1 Predictions Std         0.760112
trainer/Q1 Predictions Max        49.4998
trainer/Q1 Predictions Min        44.574
trainer/Q2 Predictions Mean       47.4096
trainer/Q2 Predictions Std         0.758308
trainer/Q2 Predictions Max        49.5833
trainer/Q2 Predictions Min        44.5687
trainer/Q Targets Mean            47.371
trainer/Q Targets Std              0.762597
trainer/Q Targets Max             49.5735
trainer/Q Targets Min             44.2984
trainer/Log Pis Mean              -4.75924
trainer/Log Pis Std                0.303751
trainer/Log Pis Max               -3.81056
trainer/Log Pis Min               -5.92256
trainer/Policy mu Mean            -0.000880995
trainer/Policy mu Std              0.0413847
trainer/Policy mu Max              0.149704
trainer/Policy mu Min             -0.111221
trainer/Policy log std Mean       -0.127262
trainer/Policy log std Std         0.00861855
trainer/Policy log std Max        -0.100872
trainer/Policy log std Min        -0.154521
trainer/Alpha                      0.223074
trainer/Alpha Loss               -17.6383
exploration/num steps total    31000
exploration/num paths total       62
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00346627
exploration/Rewards Std            0.00740762
exploration/Rewards Max            0.0793554
exploration/Rewards Min            1.92857e-08
exploration/Returns Mean           1.73313
exploration/Returns Std            1.78242
exploration/Returns Max            5.04779
exploration/Returns Min            0.222148
exploration/Actions Mean          -0.00134228
exploration/Actions Std            0.590338
exploration/Actions Max            0.997681
exploration/Actions Min           -0.998525
exploration/Num Paths             10
exploration/Average Returns        1.73313
evaluation/num steps total     30000
evaluation/num paths total        60
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0213935
evaluation/Rewards Std             0.0137333
evaluation/Rewards Max             0.0500632
evaluation/Rewards Min             0.00122702
evaluation/Returns Mean           10.6968
evaluation/Returns Std             4.96443
evaluation/Returns Max            18.1251
evaluation/Returns Min             4.16285
evaluation/ExplReturns Mean       10.6968
evaluation/ExplReturns Std         4.96443
evaluation/ExplReturns Max        18.1251
evaluation/ExplReturns Min         4.16285
evaluation/Actions Mean           -0.00288687
evaluation/Actions Std             0.0272592
evaluation/Actions Max             0.0466468
evaluation/Actions Min            -0.0958268
evaluation/Num Paths              10
evaluation/Average Returns        10.6968
time/data storing (s)              0.0314999
time/evaluation sampling (s)      66.5943
time/exploration sampling (s)     71.9281
time/logging (s)                   0.0255426
time/saving (s)                    0.0780306
time/training (s)                 11.5073
time/epoch (s)                   150.165
time/total (s)                   912.604
Epoch                              5
-----------------------------  ---------------
2023-08-31 12:08:05.889620 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 6 finished
-----------------------------  ---------------
replay_buffer/size             36000
trainer/QF1 Loss                   0.00832798
trainer/QF2 Loss                   0.0106674
trainer/Policy Loss              -53.945
trainer/Q1 Predictions Mean       49.1726
trainer/Q1 Predictions Std         0.679632
trainer/Q1 Predictions Max        50.8149
trainer/Q1 Predictions Min        46.6962
trainer/Q2 Predictions Mean       49.22
trainer/Q2 Predictions Std         0.684079
trainer/Q2 Predictions Max        50.9007
trainer/Q2 Predictions Min        46.9016
trainer/Q Targets Mean            49.1694
trainer/Q Targets Std              0.68377
trainer/Q Targets Max             50.8564
trainer/Q Targets Min             46.8173
trainer/Log Pis Mean              -4.7751
trainer/Log Pis Std                0.346439
trainer/Log Pis Max               -3.914
trainer/Log Pis Min               -7.00112
trainer/Policy mu Mean            -0.00724852
trainer/Policy mu Std              0.0613401
trainer/Policy mu Max              0.206727
trainer/Policy mu Min             -0.264015
trainer/Policy log std Mean       -0.127691
trainer/Policy log std Std         0.00991789
trainer/Policy log std Max        -0.0874914
trainer/Policy log std Min        -0.160702
trainer/Alpha                      0.165281
trainer/Alpha Loss               -21.1929
exploration/num steps total    36000
exploration/num paths total       72
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00482448
exploration/Rewards Std            0.00953822
exploration/Rewards Max            0.0805285
exploration/Rewards Min            8.09605e-09
exploration/Returns Mean           2.41224
exploration/Returns Std            3.24884
exploration/Returns Max           10.408
exploration/Returns Min            0.067768
exploration/Actions Mean          -0.000125885
exploration/Actions Std            0.58866
exploration/Actions Max            0.999507
exploration/Actions Min           -0.997027
exploration/Num Paths             10
exploration/Average Returns        2.41224
evaluation/num steps total     35000
evaluation/num paths total        70
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0240122
evaluation/Rewards Std             0.017693
evaluation/Rewards Max             0.0740941
evaluation/Rewards Min             0.000935646
evaluation/Returns Mean           12.0061
evaluation/Returns Std             7.25556
evaluation/Returns Max            26.5818
evaluation/Returns Min             3.38046
evaluation/ExplReturns Mean       12.0061
evaluation/ExplReturns Std         7.25556
evaluation/ExplReturns Max        26.5818
evaluation/ExplReturns Min         3.38046
evaluation/Actions Mean           -0.00626814
evaluation/Actions Std             0.0282578
evaluation/Actions Max             0.0683213
evaluation/Actions Min            -0.159556
evaluation/Num Paths              10
evaluation/Average Returns        12.0061
time/data storing (s)              0.031521
time/evaluation sampling (s)      67.5546
time/exploration sampling (s)     72.2815
time/logging (s)                   0.0254663
time/saving (s)                    0.0952317
time/training (s)                 10.6065
time/epoch (s)                   150.595
time/total (s)                  1063.2
Epoch                              6
-----------------------------  ---------------
2023-08-31 12:10:35.468644 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 7 finished
-----------------------------  ---------------
replay_buffer/size             41000
trainer/QF1 Loss                   0.00756051
trainer/QF2 Loss                   0.00624947
trainer/Policy Loss              -54.5381
trainer/Q1 Predictions Mean       49.832
trainer/Q1 Predictions Std         0.649939
trainer/Q1 Predictions Max        51.4301
trainer/Q1 Predictions Min        47.9895
trainer/Q2 Predictions Mean       49.7855
trainer/Q2 Predictions Std         0.653037
trainer/Q2 Predictions Max        51.4583
trainer/Q2 Predictions Min        47.9086
trainer/Q Targets Mean            49.7817
trainer/Q Targets Std              0.653875
trainer/Q Targets Max             51.4894
trainer/Q Targets Min             47.8957
trainer/Log Pis Mean              -4.75094
trainer/Log Pis Std                0.426392
trainer/Log Pis Max               -3.7935
trainer/Log Pis Min               -6.47571
trainer/Policy mu Mean            -0.000952128
trainer/Policy mu Std              0.0754367
trainer/Policy mu Max              0.309294
trainer/Policy mu Min             -0.305432
trainer/Policy log std Mean       -0.120194
trainer/Policy log std Std         0.0109531
trainer/Policy log std Max        -0.0845672
trainer/Policy log std Min        -0.170578
trainer/Alpha                      0.122467
trainer/Alpha Loss               -24.6724
exploration/num steps total    41000
exploration/num paths total       82
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00662784
exploration/Rewards Std            0.0125934
exploration/Rewards Max            0.0814124
exploration/Rewards Min            2.90335e-08
exploration/Returns Mean           3.31392
exploration/Returns Std            3.26069
exploration/Returns Max           10.3694
exploration/Returns Min            0.134581
exploration/Actions Mean           0.000613755
exploration/Actions Std            0.59265
exploration/Actions Max            0.999001
exploration/Actions Min           -0.999704
exploration/Num Paths             10
exploration/Average Returns        3.31392
evaluation/num steps total     40000
evaluation/num paths total        80
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0260983
evaluation/Rewards Std             0.0159202
evaluation/Rewards Max             0.0650871
evaluation/Rewards Min             0.00133558
evaluation/Returns Mean           13.0491
evaluation/Returns Std             5.78609
evaluation/Returns Max            23.3288
evaluation/Returns Min             5.54542
evaluation/ExplReturns Mean       13.0491
evaluation/ExplReturns Std         5.78609
evaluation/ExplReturns Max        23.3288
evaluation/ExplReturns Min         5.54542
evaluation/Actions Mean           -0.00895375
evaluation/Actions Std             0.03005
evaluation/Actions Max             0.084961
evaluation/Actions Min            -0.168558
evaluation/Num Paths              10
evaluation/Average Returns        13.0491
time/data storing (s)              0.031377
time/evaluation sampling (s)      66.8126
time/exploration sampling (s)     71.8195
time/logging (s)                   0.025593
time/saving (s)                    0.0638968
time/training (s)                 10.8227
time/epoch (s)                   149.576
time/total (s)                  1212.78
Epoch                              7
-----------------------------  ---------------
2023-08-31 12:13:04.902821 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 8 finished
-----------------------------  ---------------
replay_buffer/size             46000
trainer/QF1 Loss                   0.00568409
trainer/QF2 Loss                   0.00585472
trainer/Policy Loss              -54.3883
trainer/Q1 Predictions Mean       49.6229
trainer/Q1 Predictions Std         0.658165
trainer/Q1 Predictions Max        51.0852
trainer/Q1 Predictions Min        47.3793
trainer/Q2 Predictions Mean       49.6098
trainer/Q2 Predictions Std         0.645919
trainer/Q2 Predictions Max        51.0146
trainer/Q2 Predictions Min        47.3453
trainer/Q Targets Mean            49.6192
trainer/Q Targets Std              0.648612
trainer/Q Targets Max             51.0453
trainer/Q Targets Min             47.3981
trainer/Log Pis Mean              -4.78727
trainer/Log Pis Std                0.471213
trainer/Log Pis Max               -3.33656
trainer/Log Pis Min               -6.43716
trainer/Policy mu Mean            -0.00390748
trainer/Policy mu Std              0.103198
trainer/Policy mu Max              0.329146
trainer/Policy mu Min             -0.464926
trainer/Policy log std Mean       -0.125
trainer/Policy log std Std         0.00946042
trainer/Policy log std Max        -0.0913141
trainer/Policy log std Min        -0.153203
trainer/Alpha                      0.0907569
trainer/Alpha Loss               -28.2809
exploration/num steps total    46000
exploration/num paths total       92
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00295285
exploration/Rewards Std            0.00764135
exploration/Rewards Max            0.0699375
exploration/Rewards Min            1.25033e-09
exploration/Returns Mean           1.47643
exploration/Returns Std            1.32802
exploration/Returns Max            4.08506
exploration/Returns Min            0.0278017
exploration/Actions Mean           0.000938534
exploration/Actions Std            0.59375
exploration/Actions Max            0.997982
exploration/Actions Min           -0.998575
exploration/Num Paths             10
exploration/Average Returns        1.47643
evaluation/num steps total     45000
evaluation/num paths total        90
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0228058
evaluation/Rewards Std             0.0142549
evaluation/Rewards Max             0.0656379
evaluation/Rewards Min             0.0013382
evaluation/Returns Mean           11.4029
evaluation/Returns Std             4.72176
evaluation/Returns Max            19.8406
evaluation/Returns Min             5.77305
evaluation/ExplReturns Mean       11.4029
evaluation/ExplReturns Std         4.72176
evaluation/ExplReturns Max        19.8406
evaluation/ExplReturns Min         5.77305
evaluation/Actions Mean           -0.00843363
evaluation/Actions Std             0.0316989
evaluation/Actions Max             0.131385
evaluation/Actions Min            -0.231914
evaluation/Num Paths              10
evaluation/Average Returns        11.4029
time/data storing (s)              0.0316267
time/evaluation sampling (s)      66.5858
time/exploration sampling (s)     72.5518
time/logging (s)                   0.0255048
time/saving (s)                    0.0751323
time/training (s)                 10.1608
time/epoch (s)                   149.431
time/total (s)                  1362.21
Epoch                              8
-----------------------------  ---------------
2023-08-31 12:15:36.333587 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 9 finished
-----------------------------  ---------------
replay_buffer/size             51000
trainer/QF1 Loss                   0.00540887
trainer/QF2 Loss                   0.00459187
trainer/Policy Loss              -53.671
trainer/Q1 Predictions Mean       48.917
trainer/Q1 Predictions Std         0.62739
trainer/Q1 Predictions Max        51.0272
trainer/Q1 Predictions Min        46.9555
trainer/Q2 Predictions Mean       48.9458
trainer/Q2 Predictions Std         0.623338
trainer/Q2 Predictions Max        51.0439
trainer/Q2 Predictions Min        47.0418
trainer/Q Targets Mean            48.9464
trainer/Q Targets Std              0.634851
trainer/Q Targets Max             51.0518
trainer/Q Targets Min             46.9242
trainer/Log Pis Mean              -4.75728
trainer/Log Pis Std                0.462377
trainer/Log Pis Max               -3.29844
trainer/Log Pis Min               -6.13241
trainer/Policy mu Mean            -0.00602725
trainer/Policy mu Std              0.130939
trainer/Policy mu Max              0.552597
trainer/Policy mu Min             -0.647911
trainer/Policy log std Mean       -0.121907
trainer/Policy log std Std         0.0128041
trainer/Policy log std Max        -0.0807059
trainer/Policy log std Min        -0.178223
trainer/Alpha                      0.0672701
trainer/Alpha Loss               -31.7298
exploration/num steps total    51000
exploration/num paths total      102
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.0051059
exploration/Rewards Std            0.0118738
exploration/Rewards Max            0.222254
exploration/Rewards Min            1.77405e-09
exploration/Returns Mean           2.55295
exploration/Returns Std            2.45672
exploration/Returns Max            7.17507
exploration/Returns Min            0.129417
exploration/Actions Mean          -0.00872692
exploration/Actions Std            0.596865
exploration/Actions Max            0.997857
exploration/Actions Min           -0.99914
exploration/Num Paths             10
exploration/Average Returns        2.55295
evaluation/num steps total     50000
evaluation/num paths total       100
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0267113
evaluation/Rewards Std             0.0186126
evaluation/Rewards Max             0.0855053
evaluation/Rewards Min             0.00138353
evaluation/Returns Mean           13.3557
evaluation/Returns Std             6.55755
evaluation/Returns Max            27.1079
evaluation/Returns Min             6.16724
evaluation/ExplReturns Mean       13.3557
evaluation/ExplReturns Std         6.55755
evaluation/ExplReturns Max        27.1079
evaluation/ExplReturns Min         6.16724
evaluation/Actions Mean           -0.00891063
evaluation/Actions Std             0.0358776
evaluation/Actions Max             0.167169
evaluation/Actions Min            -0.28101
evaluation/Num Paths              10
evaluation/Average Returns        13.3557
time/data storing (s)              0.0316737
time/evaluation sampling (s)      67.0539
time/exploration sampling (s)     74.1735
time/logging (s)                   0.0254742
time/saving (s)                    0.0755877
time/training (s)                 10.0671
time/epoch (s)                   151.427
time/total (s)                  1513.64
Epoch                              9
-----------------------------  ---------------
2023-08-31 12:18:06.051507 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 10 finished
-----------------------------  ---------------
replay_buffer/size             56000
trainer/QF1 Loss                   0.00508759
trainer/QF2 Loss                   0.00471873
trainer/Policy Loss              -52.448
trainer/Q1 Predictions Mean       47.8054
trainer/Q1 Predictions Std         0.686386
trainer/Q1 Predictions Max        49.9691
trainer/Q1 Predictions Min        45.4297
trainer/Q2 Predictions Mean       47.7992
trainer/Q2 Predictions Std         0.682771
trainer/Q2 Predictions Max        49.9572
trainer/Q2 Predictions Min        45.4343
trainer/Q Targets Mean            47.7888
trainer/Q Targets Std              0.677968
trainer/Q Targets Max             49.9617
trainer/Q Targets Min             45.5986
trainer/Log Pis Mean              -4.6547
trainer/Log Pis Std                0.576583
trainer/Log Pis Max               -2.72465
trainer/Log Pis Min               -5.95188
trainer/Policy mu Mean            -0.00281289
trainer/Policy mu Std              0.156348
trainer/Policy mu Max              0.550579
trainer/Policy mu Min             -0.730172
trainer/Policy log std Mean       -0.118557
trainer/Policy log std Std         0.0152834
trainer/Policy log std Max        -0.0670279
trainer/Policy log std Min        -0.175419
trainer/Alpha                      0.0498725
trainer/Alpha Loss               -34.9407
exploration/num steps total    56000
exploration/num paths total      112
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00245934
exploration/Rewards Std            0.00477428
exploration/Rewards Max            0.0397509
exploration/Rewards Min            1.35149e-09
exploration/Returns Mean           1.22967
exploration/Returns Std            1.48695
exploration/Returns Max            4.8329
exploration/Returns Min            0.0356861
exploration/Actions Mean           0.000594503
exploration/Actions Std            0.595477
exploration/Actions Max            0.999707
exploration/Actions Min           -0.998301
exploration/Num Paths             10
exploration/Average Returns        1.22967
evaluation/num steps total     55000
evaluation/num paths total       110
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0153869
evaluation/Rewards Std             0.0124961
evaluation/Rewards Max             0.0439968
evaluation/Rewards Min             7.89487e-05
evaluation/Returns Mean            7.69345
evaluation/Returns Std             3.75582
evaluation/Returns Max            14.7814
evaluation/Returns Min             3.76514
evaluation/ExplReturns Mean        7.69345
evaluation/ExplReturns Std         3.75582
evaluation/ExplReturns Max        14.7814
evaluation/ExplReturns Min         3.76514
evaluation/Actions Mean           -0.00762173
evaluation/Actions Std             0.0400942
evaluation/Actions Max             0.185207
evaluation/Actions Min            -0.311322
evaluation/Num Paths              10
evaluation/Average Returns         7.69345
time/data storing (s)              0.0313091
time/evaluation sampling (s)      66.4173
time/exploration sampling (s)     72.6943
time/logging (s)                   0.0255897
time/saving (s)                    0.0735345
time/training (s)                 10.4725
time/epoch (s)                   149.715
time/total (s)                  1663.36
Epoch                             10
-----------------------------  ---------------
2023-08-31 12:20:35.079830 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 11 finished
-----------------------------  ---------------
replay_buffer/size             61000
trainer/QF1 Loss                   0.00260469
trainer/QF2 Loss                   0.00459717
trainer/Policy Loss              -51.0184
trainer/Q1 Predictions Mean       46.4007
trainer/Q1 Predictions Std         0.599031
trainer/Q1 Predictions Max        48.912
trainer/Q1 Predictions Min        44.8055
trainer/Q2 Predictions Mean       46.4245
trainer/Q2 Predictions Std         0.59221
trainer/Q2 Predictions Max        48.9166
trainer/Q2 Predictions Min        44.8538
trainer/Q Targets Mean            46.3829
trainer/Q Targets Std              0.595349
trainer/Q Targets Max             48.8627
trainer/Q Targets Min             44.7922
trainer/Log Pis Mean              -4.61732
trainer/Log Pis Std                0.689443
trainer/Log Pis Max               -2.1242
trainer/Log Pis Min               -6.32636
trainer/Policy mu Mean             0.0086877
trainer/Policy mu Std              0.19688
trainer/Policy mu Max              0.735844
trainer/Policy mu Min             -1.14259
trainer/Policy log std Mean       -0.122227
trainer/Policy log std Std         0.0175206
trainer/Policy log std Max        -0.0584235
trainer/Policy log std Min        -0.275617
trainer/Alpha                      0.0369899
trainer/Alpha Loss               -38.3001
exploration/num steps total    61000
exploration/num paths total      122
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00266791
exploration/Rewards Std            0.00618598
exploration/Rewards Max            0.0755125
exploration/Rewards Min            5.14584e-10
exploration/Returns Mean           1.33395
exploration/Returns Std            1.01587
exploration/Returns Max            3.17091
exploration/Returns Min            0.120794
exploration/Actions Mean           0.00119985
exploration/Actions Std            0.595093
exploration/Actions Max            0.998655
exploration/Actions Min           -0.999325
exploration/Num Paths             10
exploration/Average Returns        1.33395
evaluation/num steps total     60000
evaluation/num paths total       120
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0198344
evaluation/Rewards Std             0.0175075
evaluation/Rewards Max             0.0580246
evaluation/Rewards Min             9.86442e-06
evaluation/Returns Mean            9.91721
evaluation/Returns Std             5.1915
evaluation/Returns Max            23.932
evaluation/Returns Min             4.51752
evaluation/ExplReturns Mean        9.91721
evaluation/ExplReturns Std         5.1915
evaluation/ExplReturns Max        23.932
evaluation/ExplReturns Min         4.51752
evaluation/Actions Mean           -0.00568985
evaluation/Actions Std             0.0499688
evaluation/Actions Max             0.208084
evaluation/Actions Min            -0.39359
evaluation/Num Paths              10
evaluation/Average Returns         9.91721
time/data storing (s)              0.0314671
time/evaluation sampling (s)      66.7672
time/exploration sampling (s)     71.9668
time/logging (s)                   0.0255871
time/saving (s)                    0.0700118
time/training (s)                 10.1638
time/epoch (s)                   149.025
time/total (s)                  1812.39
Epoch                             11
-----------------------------  ---------------
2023-08-31 12:23:04.922025 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 12 finished
-----------------------------  ---------------
replay_buffer/size             66000
trainer/QF1 Loss                   0.00461126
trainer/QF2 Loss                   0.0046508
trainer/Policy Loss              -49.3659
trainer/Q1 Predictions Mean       44.8544
trainer/Q1 Predictions Std         0.685237
trainer/Q1 Predictions Max        47.4379
trainer/Q1 Predictions Min        42.6749
trainer/Q2 Predictions Mean       44.8512
trainer/Q2 Predictions Std         0.684274
trainer/Q2 Predictions Max        47.4643
trainer/Q2 Predictions Min        42.679
trainer/Q Targets Mean            44.8093
trainer/Q Targets Std              0.683037
trainer/Q Targets Max             47.403
trainer/Q Targets Min             42.6365
trainer/Log Pis Mean              -4.51468
trainer/Log Pis Std                0.789712
trainer/Log Pis Max               -1.74416
trainer/Log Pis Min               -7.41375
trainer/Policy mu Mean            -0.00602438
trainer/Policy mu Std              0.246119
trainer/Policy mu Max              0.936872
trainer/Policy mu Min             -1.10372
trainer/Policy log std Mean       -0.119823
trainer/Policy log std Std         0.0237662
trainer/Policy log std Max        -0.0336315
trainer/Policy log std Min        -0.24863
trainer/Alpha                      0.027452
trainer/Alpha Loss               -41.3955
exploration/num steps total    66000
exploration/num paths total      132
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00289429
exploration/Rewards Std            0.00757289
exploration/Rewards Max            0.0649099
exploration/Rewards Min            3.40069e-11
exploration/Returns Mean           1.44714
exploration/Returns Std            1.49486
exploration/Returns Max            4.54621
exploration/Returns Min            0.21354
exploration/Actions Mean           0.00263485
exploration/Actions Std            0.599355
exploration/Actions Max            0.998507
exploration/Actions Min           -0.999227
exploration/Num Paths             10
exploration/Average Returns        1.44714
evaluation/num steps total     65000
evaluation/num paths total       130
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.0202721
evaluation/Rewards Std             0.0203016
evaluation/Rewards Max             0.0666461
evaluation/Rewards Min             4.41234e-10
evaluation/Returns Mean           10.136
evaluation/Returns Std             8.76144
evaluation/Returns Max            25.6102
evaluation/Returns Min             0.835734
evaluation/ExplReturns Mean       10.136
evaluation/ExplReturns Std         8.76144
evaluation/ExplReturns Max        25.6102
evaluation/ExplReturns Min         0.835734
evaluation/Actions Mean           -0.0150374
evaluation/Actions Std             0.0812033
evaluation/Actions Max             0.380964
evaluation/Actions Min            -0.609243
evaluation/Num Paths              10
evaluation/Average Returns        10.136
time/data storing (s)              0.0310724
time/evaluation sampling (s)      67.3615
time/exploration sampling (s)     72.2195
time/logging (s)                   0.0257319
time/saving (s)                    0.0678595
time/training (s)                 10.1332
time/epoch (s)                   149.839
time/total (s)                  1962.23
Epoch                             12
-----------------------------  ---------------
2023-08-31 12:25:35.919248 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 13 finished
-----------------------------  ---------------
replay_buffer/size             71000
trainer/QF1 Loss                   0.00210639
trainer/QF2 Loss                   0.00350318
trainer/Policy Loss              -47.4829
trainer/Q1 Predictions Mean       43.1446
trainer/Q1 Predictions Std         0.6874
trainer/Q1 Predictions Max        45.312
trainer/Q1 Predictions Min        41.4206
trainer/Q2 Predictions Mean       43.1841
trainer/Q2 Predictions Std         0.690753
trainer/Q2 Predictions Max        45.3751
trainer/Q2 Predictions Min        41.4559
trainer/Q Targets Mean            43.1451
trainer/Q Targets Std              0.68741
trainer/Q Targets Max             45.3152
trainer/Q Targets Min             41.4209
trainer/Log Pis Mean              -4.32519
trainer/Log Pis Std                1.05728
trainer/Log Pis Max               -1.13814
trainer/Log Pis Min               -7.95517
trainer/Policy mu Mean             0.0152116
trainer/Policy mu Std              0.304006
trainer/Policy mu Max              1.05826
trainer/Policy mu Min             -1.39709
trainer/Policy log std Mean       -0.138959
trainer/Policy log std Std         0.0321922
trainer/Policy log std Max        -0.024669
trainer/Policy log std Min        -0.35694
trainer/Alpha                      0.0203905
trainer/Alpha Loss               -44.082
exploration/num steps total    71000
exploration/num paths total      142
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00306651
exploration/Rewards Std            0.00667617
exploration/Rewards Max            0.0746135
exploration/Rewards Min            6.13033e-10
exploration/Returns Mean           1.53326
exploration/Returns Std            1.82262
exploration/Returns Max            5.96261
exploration/Returns Min            0.0513723
exploration/Actions Mean          -0.00435218
exploration/Actions Std            0.595121
exploration/Actions Max            0.99856
exploration/Actions Min           -0.998151
exploration/Num Paths             10
exploration/Average Returns        1.53326
evaluation/num steps total     70000
evaluation/num paths total       140
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00580674
evaluation/Rewards Std             0.00913738
evaluation/Rewards Max             0.0436308
evaluation/Rewards Min             1.59258e-10
evaluation/Returns Mean            2.90337
evaluation/Returns Std             1.52525
evaluation/Returns Max             5.52358
evaluation/Returns Min             0.709968
evaluation/ExplReturns Mean        2.90337
evaluation/ExplReturns Std         1.52525
evaluation/ExplReturns Max         5.52358
evaluation/ExplReturns Min         0.709968
evaluation/Actions Mean           -0.0103526
evaluation/Actions Std             0.135363
evaluation/Actions Max             0.787615
evaluation/Actions Min            -0.83905
evaluation/Num Paths              10
evaluation/Average Returns         2.90337
time/data storing (s)              0.0316548
time/evaluation sampling (s)      66.341
time/exploration sampling (s)     74.1359
time/logging (s)                   0.0258642
time/saving (s)                    0.0701922
time/training (s)                 10.3892
time/epoch (s)                   150.994
time/total (s)                  2113.23
Epoch                             13
-----------------------------  ---------------
2023-08-31 12:28:09.515681 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 14 finished
-----------------------------  ---------------
replay_buffer/size             76000
trainer/QF1 Loss                   0.00358168
trainer/QF2 Loss                   0.00724397
trainer/Policy Loss              -45.5525
trainer/Q1 Predictions Mean       41.4568
trainer/Q1 Predictions Std         0.653372
trainer/Q1 Predictions Max        44.1327
trainer/Q1 Predictions Min        40.0325
trainer/Q2 Predictions Mean       41.3642
trainer/Q2 Predictions Std         0.651434
trainer/Q2 Predictions Max        43.9834
trainer/Q2 Predictions Min        39.9327
trainer/Q Targets Mean            41.4288
trainer/Q Targets Std              0.648571
trainer/Q Targets Max             43.9278
trainer/Q Targets Min             39.9426
trainer/Log Pis Mean              -4.17082
trainer/Log Pis Std                1.20072
trainer/Log Pis Max                0.332077
trainer/Log Pis Min               -7.99078
trainer/Policy mu Mean             0.0109891
trainer/Policy mu Std              0.3655
trainer/Policy mu Max              1.25094
trainer/Policy mu Min             -1.34866
trainer/Policy log std Mean       -0.138426
trainer/Policy log std Std         0.0454724
trainer/Policy log std Max        -0.00960846
trainer/Policy log std Min        -0.343744
trainer/Alpha                      0.0151623
trainer/Alpha Loss               -46.7906
exploration/num steps total    76000
exploration/num paths total      152
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00409132
exploration/Rewards Std            0.00887964
exploration/Rewards Max            0.0825545
exploration/Rewards Min            3.3167e-10
exploration/Returns Mean           2.04566
exploration/Returns Std            1.61111
exploration/Returns Max            4.84665
exploration/Returns Min            0.201727
exploration/Actions Mean           0.00612058
exploration/Actions Std            0.606569
exploration/Actions Max            0.998753
exploration/Actions Min           -0.998662
exploration/Num Paths             10
exploration/Average Returns        2.04566
evaluation/num steps total     75000
evaluation/num paths total       150
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00276748
evaluation/Rewards Std             0.00775808
evaluation/Rewards Max             0.0739638
evaluation/Rewards Min             7.39852e-11
evaluation/Returns Mean            1.38374
evaluation/Returns Std             0.420711
evaluation/Returns Max             1.99133
evaluation/Returns Min             0.618114
evaluation/ExplReturns Mean        1.38374
evaluation/ExplReturns Std         0.420711
evaluation/ExplReturns Max         1.99133
evaluation/ExplReturns Min         0.618114
evaluation/Actions Mean           -0.0115183
evaluation/Actions Std             0.178948
evaluation/Actions Max             0.799234
evaluation/Actions Min            -0.921449
evaluation/Num Paths              10
evaluation/Average Returns         1.38374
time/data storing (s)              0.0312919
time/evaluation sampling (s)      66.8081
time/exploration sampling (s)     73.111
time/logging (s)                   0.0257644
time/saving (s)                    0.0863446
time/training (s)                 13.5304
time/epoch (s)                   153.593
time/total (s)                  2266.82
Epoch                             14
-----------------------------  ---------------
2023-08-31 12:30:40.022403 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 15 finished
-----------------------------  ---------------
replay_buffer/size             81000
trainer/QF1 Loss                   0.002121
trainer/QF2 Loss                   0.00214721
trainer/Policy Loss              -43.5491
trainer/Q1 Predictions Mean       39.7338
trainer/Q1 Predictions Std         0.709891
trainer/Q1 Predictions Max        41.8822
trainer/Q1 Predictions Min        37.3381
trainer/Q2 Predictions Mean       39.7499
trainer/Q2 Predictions Std         0.70818
trainer/Q2 Predictions Max        41.8768
trainer/Q2 Predictions Min        37.4382
trainer/Q Targets Mean            39.7359
trainer/Q Targets Std              0.710524
trainer/Q Targets Max             41.8853
trainer/Q Targets Min             37.2754
trainer/Log Pis Mean              -3.80529
trainer/Log Pis Std                1.44306
trainer/Log Pis Max                0.330383
trainer/Log Pis Min               -6.88851
trainer/Policy mu Mean             0.0319237
trainer/Policy mu Std              0.449526
trainer/Policy mu Max              1.26298
trainer/Policy mu Min             -1.55292
trainer/Policy log std Mean       -0.140966
trainer/Policy log std Std         0.0581737
trainer/Policy log std Max         0.0347112
trainer/Policy log std Min        -0.419846
trainer/Alpha                      0.0112903
trainer/Alpha Loss               -48.4457
exploration/num steps total    81000
exploration/num paths total      162
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00215092
exploration/Rewards Std            0.00557326
exploration/Rewards Max            0.0509244
exploration/Rewards Min            2.01325e-13
exploration/Returns Mean           1.07546
exploration/Returns Std            0.596684
exploration/Returns Max            2.04544
exploration/Returns Min            0.329798
exploration/Actions Mean           0.00489678
exploration/Actions Std            0.619098
exploration/Actions Max            0.998616
exploration/Actions Min           -0.999629
exploration/Num Paths             10
exploration/Average Returns        1.07546
evaluation/num steps total     80000
evaluation/num paths total       160
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00269009
evaluation/Rewards Std             0.00849958
evaluation/Rewards Max             0.0809723
evaluation/Rewards Min             1.0104e-12
evaluation/Returns Mean            1.34504
evaluation/Returns Std             0.398147
evaluation/Returns Max             1.87002
evaluation/Returns Min             0.817452
evaluation/ExplReturns Mean        1.34504
evaluation/ExplReturns Std         0.398147
evaluation/ExplReturns Max         1.87002
evaluation/ExplReturns Min         0.817452
evaluation/Actions Mean            0.0319686
evaluation/Actions Std             0.266165
evaluation/Actions Max             0.929562
evaluation/Actions Min            -0.957096
evaluation/Num Paths              10
evaluation/Average Returns         1.34504
time/data storing (s)              0.0312984
time/evaluation sampling (s)      66.9564
time/exploration sampling (s)     72.8341
time/logging (s)                   0.0257731
time/saving (s)                    0.0682839
time/training (s)                 10.5873
time/epoch (s)                   150.503
time/total (s)                  2417.33
Epoch                             15
-----------------------------  ---------------
2023-08-31 12:33:12.620120 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size             86000
trainer/QF1 Loss                   0.00455308
trainer/QF2 Loss                   0.00252396
trainer/Policy Loss              -41.4706
trainer/Q1 Predictions Mean       37.9731
trainer/Q1 Predictions Std         0.703273
trainer/Q1 Predictions Max        40.089
trainer/Q1 Predictions Min        35.0298
trainer/Q2 Predictions Mean       38.0202
trainer/Q2 Predictions Std         0.710738
trainer/Q2 Predictions Max        40.203
trainer/Q2 Predictions Min        34.8914
trainer/Q Targets Mean            38.0138
trainer/Q Targets Std              0.711523
trainer/Q Targets Max             40.1447
trainer/Q Targets Min             34.6086
trainer/Log Pis Mean              -3.47942
trainer/Log Pis Std                1.78638
trainer/Log Pis Max                1.77766
trainer/Log Pis Min               -8.54273
trainer/Policy mu Mean             0.0746732
trainer/Policy mu Std              0.527456
trainer/Policy mu Max              1.89404
trainer/Policy mu Min             -1.54492
trainer/Policy log std Mean       -0.152606
trainer/Policy log std Std         0.0712453
trainer/Policy log std Max         0.0574134
trainer/Policy log std Min        -0.539941
trainer/Alpha                      0.0084333
trainer/Alpha Loss               -50.0421
exploration/num steps total    86000
exploration/num paths total      172
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00243335
exploration/Rewards Std            0.00766386
exploration/Rewards Max            0.0886912
exploration/Rewards Min            1.83825e-13
exploration/Returns Mean           1.21667
exploration/Returns Std            1.33755
exploration/Returns Max            4.41178
exploration/Returns Min            0.0690124
exploration/Actions Mean           0.0199364
exploration/Actions Std            0.637611
exploration/Actions Max            0.999804
exploration/Actions Min           -0.999748
exploration/Num Paths             10
exploration/Average Returns        1.21667
evaluation/num steps total     85000
evaluation/num paths total       170
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00207886
evaluation/Rewards Std             0.00718788
evaluation/Rewards Max             0.0634738
evaluation/Rewards Min             6.92182e-13
evaluation/Returns Mean            1.03943
evaluation/Returns Std             0.328168
evaluation/Returns Max             1.83871
evaluation/Returns Min             0.762171
evaluation/ExplReturns Mean        1.03943
evaluation/ExplReturns Std         0.328168
evaluation/ExplReturns Max         1.83871
evaluation/ExplReturns Min         0.762171
evaluation/Actions Mean            0.002246
evaluation/Actions Std             0.368701
evaluation/Actions Max             0.972369
evaluation/Actions Min            -0.989387
evaluation/Num Paths              10
evaluation/Average Returns         1.03943
time/data storing (s)              0.0316227
time/evaluation sampling (s)      66.5824
time/exploration sampling (s)     72.3043
time/logging (s)                   0.0259316
time/saving (s)                    0.0677171
time/training (s)                 13.5824
time/epoch (s)                   152.594
time/total (s)                  2569.92
Epoch                             16
-----------------------------  ---------------
2023-08-31 12:35:44.076163 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 17 finished
-----------------------------  ---------------
replay_buffer/size             91000
trainer/QF1 Loss                   0.00263939
trainer/QF2 Loss                   0.00354797
trainer/Policy Loss              -38.9787
trainer/Q1 Predictions Mean       36.2233
trainer/Q1 Predictions Std         0.709918
trainer/Q1 Predictions Max        38.7345
trainer/Q1 Predictions Min        33.6069
trainer/Q2 Predictions Mean       36.2045
trainer/Q2 Predictions Std         0.708
trainer/Q2 Predictions Max        38.621
trainer/Q2 Predictions Min        33.5529
trainer/Q Targets Mean            36.234
trainer/Q Targets Std              0.709505
trainer/Q Targets Max             38.6442
trainer/Q Targets Min             33.5428
trainer/Log Pis Mean              -2.75366
trainer/Log Pis Std                2.23647
trainer/Log Pis Max                5.12273
trainer/Log Pis Min               -8.99442
trainer/Policy mu Mean             0.0451497
trainer/Policy mu Std              0.66866
trainer/Policy mu Max              2.59603
trainer/Policy mu Min             -2.22155
trainer/Policy log std Mean       -0.161374
trainer/Policy log std Std         0.089635
trainer/Policy log std Max         0.151254
trainer/Policy log std Min        -0.512154
trainer/Alpha                      0.00632557
trainer/Alpha Loss               -49.3816
exploration/num steps total    91000
exploration/num paths total      182
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.00199768
exploration/Rewards Std            0.00782709
exploration/Rewards Max            0.0758791
exploration/Rewards Min            2.41973e-13
exploration/Returns Mean           0.99884
exploration/Returns Std            0.732086
exploration/Returns Max            2.24322
exploration/Returns Min            0.176324
exploration/Actions Mean          -0.00293667
exploration/Actions Std            0.645348
exploration/Actions Max            0.999425
exploration/Actions Min           -0.999703
exploration/Num Paths             10
exploration/Average Returns        0.99884
evaluation/num steps total     90000
evaluation/num paths total       180
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00150674
evaluation/Rewards Std             0.00602698
evaluation/Rewards Max             0.063029
evaluation/Rewards Min             2.14134e-11
evaluation/Returns Mean            0.753371
evaluation/Returns Std             0.259499
evaluation/Returns Max             1.14295
evaluation/Returns Min             0.386754
evaluation/ExplReturns Mean        0.753371
evaluation/ExplReturns Std         0.259499
evaluation/ExplReturns Max         1.14295
evaluation/ExplReturns Min         0.386754
evaluation/Actions Mean            0.02541
evaluation/Actions Std             0.421434
evaluation/Actions Max             0.977517
evaluation/Actions Min            -0.980934
evaluation/Num Paths              10
evaluation/Average Returns         0.753371
time/data storing (s)              0.0313994
time/evaluation sampling (s)      65.8953
time/exploration sampling (s)     72.0523
time/logging (s)                   0.0258216
time/saving (s)                    0.0805638
time/training (s)                 13.367
time/epoch (s)                   151.452
time/total (s)                  2721.38
Epoch                             17
-----------------------------  ---------------
2023-08-31 12:38:19.020172 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 18 finished
-----------------------------  ---------------
replay_buffer/size             96000
trainer/QF1 Loss                   0.00220086
trainer/QF2 Loss                   0.00307487
trainer/Policy Loss              -36.6754
trainer/Q1 Predictions Mean       34.5162
trainer/Q1 Predictions Std         1.05243
trainer/Q1 Predictions Max        36.4873
trainer/Q1 Predictions Min        24.7375
trainer/Q2 Predictions Mean       34.5516
trainer/Q2 Predictions Std         1.05384
trainer/Q2 Predictions Max        36.486
trainer/Q2 Predictions Min        24.7301
trainer/Q Targets Mean            34.5223
trainer/Q Targets Std              1.04615
trainer/Q Targets Max             36.4382
trainer/Q Targets Min             24.8051
trainer/Log Pis Mean              -2.13604
trainer/Log Pis Std                2.40186
trainer/Log Pis Max                5.36106
trainer/Log Pis Min               -9.06795
trainer/Policy mu Mean             0.0652478
trainer/Policy mu Std              0.758604
trainer/Policy mu Max              2.3345
trainer/Policy mu Min             -2.29671
trainer/Policy log std Mean       -0.18267
trainer/Policy log std Std         0.106067
trainer/Policy log std Max         0.108717
trainer/Policy log std Min        -0.639771
trainer/Alpha                      0.00477587
trainer/Alpha Loss               -48.8221
exploration/num steps total    96000
exploration/num paths total      192
exploration/path length Mean     500
exploration/path length Std        0
exploration/path length Max      500
exploration/path length Min      500
exploration/Rewards Mean           0.000949611
exploration/Rewards Std            0.00372031
exploration/Rewards Max            0.0467816
exploration/Rewards Min            1.83464e-14
exploration/Returns Mean           0.474805
exploration/Returns Std            0.206014
exploration/Returns Max            0.813639
exploration/Returns Min            0.192387
exploration/Actions Mean          -0.0878605
exploration/Actions Std            0.666053
exploration/Actions Max            0.999656
exploration/Actions Min           -0.999742
exploration/Num Paths             10
exploration/Average Returns        0.474805
evaluation/num steps total     95000
evaluation/num paths total       190
evaluation/path length Mean      500
evaluation/path length Std         0
evaluation/path length Max       500
evaluation/path length Min       500
evaluation/Rewards Mean            0.00124882
evaluation/Rewards Std             0.00442049
evaluation/Rewards Max             0.0568765
evaluation/Rewards Min             1.51802e-11
evaluation/Returns Mean            0.62441
evaluation/Returns Std             0.218828
evaluation/Returns Max             1.08671
evaluation/Returns Min             0.371443
evaluation/ExplReturns Mean        0.62441
evaluation/ExplReturns Std         0.218828
evaluation/ExplReturns Max         1.08671
evaluation/ExplReturns Min         0.371443
evaluation/Actions Mean            0.0864846
evaluation/Actions Std             0.507904
evaluation/Actions Max             0.996609
evaluation/Actions Min            -0.996257
evaluation/Num Paths              10
evaluation/Average Returns         0.62441
time/data storing (s)              0.0315896
time/evaluation sampling (s)      66.6645
time/exploration sampling (s)     75.5201
time/logging (s)                   0.0255872
time/saving (s)                    0.0625615
time/training (s)                 12.6359
time/epoch (s)                   154.94
time/total (s)                  2876.32
Epoch                             18
-----------------------------  ---------------
2023-08-31 12:40:53.731694 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 19 finished
-----------------------------  ----------------
replay_buffer/size             101000
trainer/QF1 Loss                    0.00523306
trainer/QF2 Loss                    0.00323302
trainer/Policy Loss               -34.0044
trainer/Q1 Predictions Mean        32.8323
trainer/Q1 Predictions Std          1.20905
trainer/Q1 Predictions Max         34.7741
trainer/Q1 Predictions Min         24.9234
trainer/Q2 Predictions Mean        32.8599
trainer/Q2 Predictions Std          1.21208
trainer/Q2 Predictions Max         34.8383
trainer/Q2 Predictions Min         24.9882
trainer/Q Targets Mean             32.8812
trainer/Q Targets Std               1.2179
trainer/Q Targets Max              34.8258
trainer/Q Targets Min              25.0053
trainer/Log Pis Mean               -1.14512
trainer/Log Pis Std                 3.10137
trainer/Log Pis Max                15.4211
trainer/Log Pis Min                -7.14122
trainer/Policy mu Mean              0.11764
trainer/Policy mu Std               0.895966
trainer/Policy mu Max               3.50789
trainer/Policy mu Min              -3.51581
trainer/Policy log std Mean        -0.189097
trainer/Policy log std Std          0.129616
trainer/Policy log std Max          0.317823
trainer/Policy log std Min         -0.760112
trainer/Alpha                       0.00363045
trainer/Alpha Loss                -45.7603
exploration/num steps total    101000
exploration/num paths total       202
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00132972
exploration/Rewards Std             0.00501761
exploration/Rewards Max             0.0604854
exploration/Rewards Min             9.74221e-15
exploration/Returns Mean            0.664862
exploration/Returns Std             0.303537
exploration/Returns Max             1.27179
exploration/Returns Min             0.190489
exploration/Actions Mean            0.0451592
exploration/Actions Std             0.688383
exploration/Actions Max             0.999946
exploration/Actions Min            -0.999908
exploration/Num Paths              10
exploration/Average Returns         0.664862
evaluation/num steps total     100000
evaluation/num paths total        200
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000794029
evaluation/Rewards Std              0.00372669
evaluation/Rewards Max              0.0720869
evaluation/Rewards Min              9.85323e-16
evaluation/Returns Mean             0.397014
evaluation/Returns Std              0.120864
evaluation/Returns Max              0.649128
evaluation/Returns Min              0.239086
evaluation/ExplReturns Mean         0.397014
evaluation/ExplReturns Std          0.120864
evaluation/ExplReturns Max          0.649128
evaluation/ExplReturns Min          0.239086
evaluation/Actions Mean             0.0957192
evaluation/Actions Std              0.594493
evaluation/Actions Max              0.998495
evaluation/Actions Min             -0.998331
evaluation/Num Paths               10
evaluation/Average Returns          0.397014
time/data storing (s)               0.0311453
time/evaluation sampling (s)       69.7342
time/exploration sampling (s)      74.7746
time/logging (s)                    0.0255392
time/saving (s)                     0.0712963
time/training (s)                  10.0713
time/epoch (s)                    154.708
time/total (s)                   3031.03
Epoch                              19
-----------------------------  ----------------
2023-08-31 12:43:23.311016 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 20 finished
-----------------------------  ----------------
replay_buffer/size             106000
trainer/QF1 Loss                    0.00311025
trainer/QF2 Loss                    0.00305725
trainer/Policy Loss               -31.3223
trainer/Q1 Predictions Mean        31.3468
trainer/Q1 Predictions Std          1.26174
trainer/Q1 Predictions Max         33.1738
trainer/Q1 Predictions Min         23.0106
trainer/Q2 Predictions Mean        31.3451
trainer/Q2 Predictions Std          1.25867
trainer/Q2 Predictions Max         33.1562
trainer/Q2 Predictions Min         23.1459
trainer/Q Targets Mean             31.3171
trainer/Q Targets Std               1.24977
trainer/Q Targets Max              33.121
trainer/Q Targets Min              23.1118
trainer/Log Pis Mean                0.0404904
trainer/Log Pis Std                 3.84151
trainer/Log Pis Max                17.9364
trainer/Log Pis Min                -8.47741
trainer/Policy mu Mean              0.0884325
trainer/Policy mu Std               1.06022
trainer/Policy mu Max               3.35644
trainer/Policy mu Min              -2.92704
trainer/Policy log std Mean        -0.206682
trainer/Policy log std Std          0.152921
trainer/Policy log std Max          0.691393
trainer/Policy log std Min         -0.745795
trainer/Alpha                       0.00278811
trainer/Alpha Loss                -40.9367
exploration/num steps total    106000
exploration/num paths total       212
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000881306
exploration/Rewards Std             0.00377726
exploration/Rewards Max             0.041149
exploration/Rewards Min             4.46865e-15
exploration/Returns Mean            0.440653
exploration/Returns Std             0.20906
exploration/Returns Max             0.855413
exploration/Returns Min             0.186755
exploration/Actions Mean           -0.0672766
exploration/Actions Std             0.69078
exploration/Actions Max             0.999745
exploration/Actions Min            -0.9998
exploration/Num Paths              10
exploration/Average Returns         0.440653
evaluation/num steps total     105000
evaluation/num paths total        210
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000800911
evaluation/Rewards Std              0.00400928
evaluation/Rewards Max              0.0502124
evaluation/Rewards Min              7.23172e-14
evaluation/Returns Mean             0.400455
evaluation/Returns Std              0.278662
evaluation/Returns Max              1.12106
evaluation/Returns Min              0.179004
evaluation/ExplReturns Mean         0.400455
evaluation/ExplReturns Std          0.278662
evaluation/ExplReturns Max          1.12106
evaluation/ExplReturns Min          0.179004
evaluation/Actions Mean            -0.0995383
evaluation/Actions Std              0.525231
evaluation/Actions Max              0.995926
evaluation/Actions Min             -0.996945
evaluation/Num Paths               10
evaluation/Average Returns          0.400455
time/data storing (s)               0.0314623
time/evaluation sampling (s)       66.7921
time/exploration sampling (s)      72.7683
time/logging (s)                    0.0256096
time/saving (s)                     0.0654693
time/training (s)                   9.89297
time/epoch (s)                    149.576
time/total (s)                   3180.61
Epoch                              20
-----------------------------  ----------------
2023-08-31 12:45:55.776374 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 21 finished
-----------------------------  ----------------
replay_buffer/size             111000
trainer/QF1 Loss                    0.00499042
trainer/QF2 Loss                    0.0048875
trainer/Policy Loss               -29.1572
trainer/Q1 Predictions Mean        30.0925
trainer/Q1 Predictions Std          0.914273
trainer/Q1 Predictions Max         31.5532
trainer/Q1 Predictions Min         25.6799
trainer/Q2 Predictions Mean        30.0912
trainer/Q2 Predictions Std          0.910037
trainer/Q2 Predictions Max         31.5252
trainer/Q2 Predictions Min         25.7429
trainer/Q Targets Mean             30.0415
trainer/Q Targets Std               0.915141
trainer/Q Targets Max              31.5062
trainer/Q Targets Min              25.6041
trainer/Log Pis Mean                0.951124
trainer/Log Pis Std                 3.78703
trainer/Log Pis Max                18.5563
trainer/Log Pis Min                -9.43633
trainer/Policy mu Mean              0.0874881
trainer/Policy mu Std               1.13014
trainer/Policy mu Max               3.49525
trainer/Policy mu Min              -3.15175
trainer/Policy log std Mean        -0.242672
trainer/Policy log std Std          0.182023
trainer/Policy log std Max          0.62478
trainer/Policy log std Min         -0.81408
trainer/Alpha                       0.00216086
trainer/Alpha Loss                -37.122
exploration/num steps total    111000
exploration/num paths total       222
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000969202
exploration/Rewards Std             0.00470435
exploration/Rewards Max             0.0760239
exploration/Rewards Min             4.95161e-12
exploration/Returns Mean            0.484601
exploration/Returns Std             0.434475
exploration/Returns Max             1.5608
exploration/Returns Min             0.141067
exploration/Actions Mean            0.060966
exploration/Actions Std             0.662171
exploration/Actions Max             0.999561
exploration/Actions Min            -0.999811
exploration/Num Paths              10
exploration/Average Returns         0.484601
evaluation/num steps total     110000
evaluation/num paths total        220
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00108943
evaluation/Rewards Std              0.00453243
evaluation/Rewards Max              0.039691
evaluation/Rewards Min              1.15208e-10
evaluation/Returns Mean             0.544713
evaluation/Returns Std              0.335604
evaluation/Returns Max              1.12734
evaluation/Returns Min              0.0822549
evaluation/ExplReturns Mean         0.544713
evaluation/ExplReturns Std          0.335604
evaluation/ExplReturns Max          1.12734
evaluation/ExplReturns Min          0.0822549
evaluation/Actions Mean             0.0648784
evaluation/Actions Std              0.47305
evaluation/Actions Max              0.991563
evaluation/Actions Min             -0.989345
evaluation/Num Paths               10
evaluation/Average Returns          0.544713
time/data storing (s)               0.0314576
time/evaluation sampling (s)       68.4715
time/exploration sampling (s)      74.0534
time/logging (s)                    0.0256638
time/saving (s)                     0.0752401
time/training (s)                   9.80462
time/epoch (s)                    152.462
time/total (s)                   3333.08
Epoch                              21
-----------------------------  ----------------
2023-08-31 12:48:31.896735 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 22 finished
-----------------------------  ----------------
replay_buffer/size             116000
trainer/QF1 Loss                    0.00294195
trainer/QF2 Loss                    0.00223097
trainer/Policy Loss               -25.8953
trainer/Q1 Predictions Mean        28.658
trainer/Q1 Predictions Std          0.91309
trainer/Q1 Predictions Max         30.0419
trainer/Q1 Predictions Min         21.0914
trainer/Q2 Predictions Mean        28.6424
trainer/Q2 Predictions Std          0.91336
trainer/Q2 Predictions Max         30.0224
trainer/Q2 Predictions Min         21.0953
trainer/Q Targets Mean             28.633
trainer/Q Targets Std               0.92363
trainer/Q Targets Max              30.0298
trainer/Q Targets Min              21.0146
trainer/Log Pis Mean                2.77212
trainer/Log Pis Std                 4.84448
trainer/Log Pis Max                29.0178
trainer/Log Pis Min               -10.2455
trainer/Policy mu Mean              0.245084
trainer/Policy mu Std               1.30465
trainer/Policy mu Max               5.65631
trainer/Policy mu Min              -3.64443
trainer/Policy log std Mean        -0.287375
trainer/Policy log std Std          0.178827
trainer/Policy log std Max          0.305323
trainer/Policy log std Min         -1.24387
trainer/Alpha                       0.00169773
trainer/Alpha Loss                -26.9664
exploration/num steps total    116000
exploration/num paths total       232
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000846461
exploration/Rewards Std             0.00392218
exploration/Rewards Max             0.0636332
exploration/Rewards Min             7.24163e-10
exploration/Returns Mean            0.423231
exploration/Returns Std             0.3652
exploration/Returns Max             1.0773
exploration/Returns Min             0.0552021
exploration/Actions Mean            0.20855
exploration/Actions Std             0.655034
exploration/Actions Max             0.999827
exploration/Actions Min            -0.999411
exploration/Num Paths              10
exploration/Average Returns         0.423231
evaluation/num steps total     115000
evaluation/num paths total        230
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000616224
evaluation/Rewards Std              0.00271459
evaluation/Rewards Max              0.0340664
evaluation/Rewards Min              1.14559e-09
evaluation/Returns Mean             0.308112
evaluation/Returns Std              0.306531
evaluation/Returns Max              1.12206
evaluation/Returns Min              0.0598605
evaluation/ExplReturns Mean         0.308112
evaluation/ExplReturns Std          0.306531
evaluation/ExplReturns Max          1.12206
evaluation/ExplReturns Min          0.0598605
evaluation/Actions Mean             0.27098
evaluation/Actions Std              0.538887
evaluation/Actions Max              0.999539
evaluation/Actions Min             -0.997109
evaluation/Num Paths               10
evaluation/Average Returns          0.308112
time/data storing (s)               0.0313934
time/evaluation sampling (s)       70.6514
time/exploration sampling (s)      75.3742
time/logging (s)                    0.0256386
time/saving (s)                     0.0674756
time/training (s)                   9.96667
time/epoch (s)                    156.117
time/total (s)                   3489.2
Epoch                              22
-----------------------------  ----------------
2023-08-31 12:51:06.805744 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 23 finished
-----------------------------  ----------------
replay_buffer/size             121000
trainer/QF1 Loss                    0.00262232
trainer/QF2 Loss                    0.00168672
trainer/Policy Loss               -23.8464
trainer/Q1 Predictions Mean        27.2931
trainer/Q1 Predictions Std          1.01797
trainer/Q1 Predictions Max         28.9304
trainer/Q1 Predictions Min         21.0702
trainer/Q2 Predictions Mean        27.2863
trainer/Q2 Predictions Std          1.01884
trainer/Q2 Predictions Max         28.8961
trainer/Q2 Predictions Min         21.1617
trainer/Q Targets Mean             27.2838
trainer/Q Targets Std               1.02255
trainer/Q Targets Max              28.9362
trainer/Q Targets Min              21.1265
trainer/Log Pis Mean                3.46116
trainer/Log Pis Std                 4.99724
trainer/Log Pis Max                28.5231
trainer/Log Pis Min                -6.53172
trainer/Policy mu Mean              0.346668
trainer/Policy mu Std               1.35058
trainer/Policy mu Max               3.55529
trainer/Policy mu Min              -3.79567
trainer/Policy log std Mean        -0.311781
trainer/Policy log std Std          0.196278
trainer/Policy log std Max          0.435923
trainer/Policy log std Min         -1.03202
trainer/Alpha                       0.00134575
trainer/Alpha Loss                -23.3939
exploration/num steps total    121000
exploration/num paths total       242
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00050511
exploration/Rewards Std             0.00159185
exploration/Rewards Max             0.0206327
exploration/Rewards Min             3.23081e-09
exploration/Returns Mean            0.252555
exploration/Returns Std             0.217142
exploration/Returns Max             0.889215
exploration/Returns Min             0.0953632
exploration/Actions Mean            0.114997
exploration/Actions Std             0.703739
exploration/Actions Max             0.999982
exploration/Actions Min            -0.999967
exploration/Num Paths              10
exploration/Average Returns         0.252555
evaluation/num steps total     120000
evaluation/num paths total        240
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000327333
evaluation/Rewards Std              0.00113762
evaluation/Rewards Max              0.0242269
evaluation/Rewards Min              3.29684e-10
evaluation/Returns Mean             0.163666
evaluation/Returns Std              0.112135
evaluation/Returns Max              0.434885
evaluation/Returns Min              0.0466986
evaluation/ExplReturns Mean         0.163666
evaluation/ExplReturns Std          0.112135
evaluation/ExplReturns Max          0.434885
evaluation/ExplReturns Min          0.0466986
evaluation/Actions Mean             0.113584
evaluation/Actions Std              0.663834
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.999971
evaluation/Num Paths               10
evaluation/Average Returns          0.163666
time/data storing (s)               0.0312794
time/evaluation sampling (s)       68.483
time/exploration sampling (s)      75.9601
time/logging (s)                    0.0254814
time/saving (s)                     0.0727421
time/training (s)                  10.3328
time/epoch (s)                    154.905
time/total (s)                   3644.1
Epoch                              23
-----------------------------  ----------------
2023-08-31 12:53:37.350486 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 24 finished
-----------------------------  ----------------
replay_buffer/size             126000
trainer/QF1 Loss                    0.00190177
trainer/QF2 Loss                    0.00220782
trainer/Policy Loss               -21.3809
trainer/Q1 Predictions Mean        25.9693
trainer/Q1 Predictions Std          0.884207
trainer/Q1 Predictions Max         27.4751
trainer/Q1 Predictions Min         20.7953
trainer/Q2 Predictions Mean        25.9734
trainer/Q2 Predictions Std          0.882352
trainer/Q2 Predictions Max         27.4806
trainer/Q2 Predictions Min         20.8112
trainer/Q Targets Mean             25.9869
trainer/Q Targets Std               0.886402
trainer/Q Targets Max              27.4473
trainer/Q Targets Min              20.7122
trainer/Log Pis Mean                4.60582
trainer/Log Pis Std                 6.00284
trainer/Log Pis Max                25.9838
trainer/Log Pis Min                -6.20845
trainer/Policy mu Mean              0.356417
trainer/Policy mu Std               1.47501
trainer/Policy mu Max               4.78251
trainer/Policy mu Min              -3.6489
trainer/Policy log std Mean        -0.302534
trainer/Policy log std Std          0.206128
trainer/Policy log std Max          0.577393
trainer/Policy log std Min         -1.00375
trainer/Alpha                       0.00107513
trainer/Alpha Loss                -16.3645
exploration/num steps total    126000
exploration/num paths total       252
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000255942
exploration/Rewards Std             0.00113858
exploration/Rewards Max             0.0158229
exploration/Rewards Min             8.7669e-10
exploration/Returns Mean            0.127971
exploration/Returns Std             0.123718
exploration/Returns Max             0.46747
exploration/Returns Min             0.0448431
exploration/Actions Mean            0.0466599
exploration/Actions Std             0.687305
exploration/Actions Max             0.999941
exploration/Actions Min            -0.999987
exploration/Num Paths              10
exploration/Average Returns         0.127971
evaluation/num steps total     125000
evaluation/num paths total        250
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000221145
evaluation/Rewards Std              0.00101312
evaluation/Rewards Max              0.0153676
evaluation/Rewards Min              3.88578e-16
evaluation/Returns Mean             0.110573
evaluation/Returns Std              0.0586479
evaluation/Returns Max              0.226076
evaluation/Returns Min              0.030247
evaluation/ExplReturns Mean         0.110573
evaluation/ExplReturns Std          0.0586479
evaluation/ExplReturns Max          0.226076
evaluation/ExplReturns Min          0.030247
evaluation/Actions Mean             0.0975796
evaluation/Actions Std              0.640833
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.999996
evaluation/Num Paths               10
evaluation/Average Returns          0.110573
time/data storing (s)               0.0315582
time/evaluation sampling (s)       67.3518
time/exploration sampling (s)      73.1682
time/logging (s)                    0.0254803
time/saving (s)                     0.07289
time/training (s)                   9.89131
time/epoch (s)                    150.541
time/total (s)                   3794.65
Epoch                              24
-----------------------------  ----------------
2023-08-31 12:56:10.210282 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 25 finished
-----------------------------  ----------------
replay_buffer/size             131000
trainer/QF1 Loss                    0.00235947
trainer/QF2 Loss                    0.00183912
trainer/Policy Loss               -19.9415
trainer/Q1 Predictions Mean        24.8553
trainer/Q1 Predictions Std          0.915939
trainer/Q1 Predictions Max         25.9907
trainer/Q1 Predictions Min         20.063
trainer/Q2 Predictions Mean        24.8439
trainer/Q2 Predictions Std          0.915442
trainer/Q2 Predictions Max         25.9885
trainer/Q2 Predictions Min         20.0563
trainer/Q Targets Mean             24.826
trainer/Q Targets Std               0.913609
trainer/Q Targets Max              25.9604
trainer/Q Targets Min              20.0722
trainer/Log Pis Mean                4.9211
trainer/Log Pis Std                 6.30353
trainer/Log Pis Max                32.0555
trainer/Log Pis Min                -7.90945
trainer/Policy mu Mean              0.228339
trainer/Policy mu Std               1.56431
trainer/Policy mu Max               6.15292
trainer/Policy mu Min              -4.37785
trainer/Policy log std Mean        -0.333575
trainer/Policy log std Std          0.180644
trainer/Policy log std Max          0.329935
trainer/Policy log std Min         -1.11738
trainer/Alpha                       0.000890008
trainer/Alpha Loss                -14.6023
exploration/num steps total    131000
exploration/num paths total       262
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000197358
exploration/Rewards Std             0.000764563
exploration/Rewards Max             0.0081648
exploration/Rewards Min             4.4959e-10
exploration/Returns Mean            0.0986788
exploration/Returns Std             0.0619097
exploration/Returns Max             0.211173
exploration/Returns Min             0.0116748
exploration/Actions Mean            0.0557579
exploration/Actions Std             0.643239
exploration/Actions Max             0.999949
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns         0.0986788
evaluation/num steps total     130000
evaluation/num paths total        260
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00015268
evaluation/Rewards Std              0.000699011
evaluation/Rewards Max              0.0104782
evaluation/Rewards Min              8.31978e-12
evaluation/Returns Mean             0.0763398
evaluation/Returns Std              0.0379173
evaluation/Returns Max              0.155223
evaluation/Returns Min              0.0250623
evaluation/ExplReturns Mean         0.0763398
evaluation/ExplReturns Std          0.0379173
evaluation/ExplReturns Max          0.155223
evaluation/ExplReturns Min          0.0250623
evaluation/Actions Mean            -0.0452717
evaluation/Actions Std              0.53983
evaluation/Actions Max              0.999327
evaluation/Actions Min             -0.999125
evaluation/Num Paths               10
evaluation/Average Returns          0.0763398
time/data storing (s)               0.0312969
time/evaluation sampling (s)       68.5579
time/exploration sampling (s)      74.1364
time/logging (s)                    0.0254093
time/saving (s)                     0.0679824
time/training (s)                  10.0372
time/epoch (s)                    152.856
time/total (s)                   3947.51
Epoch                              25
-----------------------------  ----------------
2023-08-31 12:58:39.654691 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 26 finished
-----------------------------  ----------------
replay_buffer/size             136000
trainer/QF1 Loss                    0.00162634
trainer/QF2 Loss                    0.00158371
trainer/Policy Loss               -18.3256
trainer/Q1 Predictions Mean        23.6837
trainer/Q1 Predictions Std          0.77836
trainer/Q1 Predictions Max         24.6985
trainer/Q1 Predictions Min         19.3772
trainer/Q2 Predictions Mean        23.6909
trainer/Q2 Predictions Std          0.778294
trainer/Q2 Predictions Max         24.6892
trainer/Q2 Predictions Min         19.3631
trainer/Q Targets Mean             23.7018
trainer/Q Targets Std               0.780432
trainer/Q Targets Max              24.7255
trainer/Q Targets Min              19.4533
trainer/Log Pis Mean                5.37599
trainer/Log Pis Std                 6.28308
trainer/Log Pis Max                42.1763
trainer/Log Pis Min                -7.75738
trainer/Policy mu Mean              0.257216
trainer/Policy mu Std               1.59183
trainer/Policy mu Max               6.11652
trainer/Policy mu Min              -5.5565
trainer/Policy log std Mean        -0.320011
trainer/Policy log std Std          0.181762
trainer/Policy log std Max          0.825614
trainer/Policy log std Min         -1.04892
trainer/Alpha                       0.00074005
trainer/Alpha Loss                -11.707
exploration/num steps total    136000
exploration/num paths total       272
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000374987
exploration/Rewards Std             0.00239033
exploration/Rewards Max             0.0384986
exploration/Rewards Min             8.12281e-13
exploration/Returns Mean            0.187494
exploration/Returns Std             0.247527
exploration/Returns Max             0.922061
exploration/Returns Min             0.0580558
exploration/Actions Mean            0.121512
exploration/Actions Std             0.66426
exploration/Actions Max             0.999994
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns         0.187494
evaluation/num steps total     135000
evaluation/num paths total        270
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000433807
evaluation/Rewards Std              0.00222949
evaluation/Rewards Max              0.0279638
evaluation/Rewards Min              2.35922e-15
evaluation/Returns Mean             0.216904
evaluation/Returns Std              0.154068
evaluation/Returns Max              0.538276
evaluation/Returns Min              0.0509435
evaluation/ExplReturns Mean         0.216904
evaluation/ExplReturns Std          0.154068
evaluation/ExplReturns Max          0.538276
evaluation/ExplReturns Min          0.0509435
evaluation/Actions Mean             0.0530956
evaluation/Actions Std              0.571327
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999989
evaluation/Num Paths               10
evaluation/Average Returns          0.216904
time/data storing (s)               0.031851
time/evaluation sampling (s)       66.904
time/exploration sampling (s)      72.5995
time/logging (s)                    0.0256023
time/saving (s)                     0.0708825
time/training (s)                   9.80925
time/epoch (s)                    149.441
time/total (s)                   4096.95
Epoch                              26
-----------------------------  ----------------
2023-08-31 13:01:16.990518 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 27 finished
-----------------------------  ----------------
replay_buffer/size             141000
trainer/QF1 Loss                    0.00178392
trainer/QF2 Loss                    0.00271363
trainer/Policy Loss               -15.768
trainer/Q1 Predictions Mean        22.6961
trainer/Q1 Predictions Std          0.634112
trainer/Q1 Predictions Max         23.6995
trainer/Q1 Predictions Min         18.5468
trainer/Q2 Predictions Mean        22.7143
trainer/Q2 Predictions Std          0.636564
trainer/Q2 Predictions Max         23.7235
trainer/Q2 Predictions Min         18.5487
trainer/Q Targets Mean             22.6819
trainer/Q Targets Std               0.638399
trainer/Q Targets Max              23.6685
trainer/Q Targets Min              18.4873
trainer/Log Pis Mean                6.95187
trainer/Log Pis Std                 7.15639
trainer/Log Pis Max                42.9637
trainer/Log Pis Min                -8.4017
trainer/Policy mu Mean              0.428184
trainer/Policy mu Std               1.71245
trainer/Policy mu Max               5.52636
trainer/Policy mu Min              -5.93857
trainer/Policy log std Mean        -0.345386
trainer/Policy log std Std          0.188691
trainer/Policy log std Max          0.495357
trainer/Policy log std Min         -1.00881
trainer/Alpha                       0.00066252
trainer/Alpha Loss                 -0.352274
exploration/num steps total    141000
exploration/num paths total       282
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000361905
exploration/Rewards Std             0.00182056
exploration/Rewards Max             0.0337627
exploration/Rewards Min             1.61385e-13
exploration/Returns Mean            0.180952
exploration/Returns Std             0.129313
exploration/Returns Max             0.474067
exploration/Returns Min             0.0381618
exploration/Actions Mean            0.212531
exploration/Actions Std             0.716436
exploration/Actions Max             0.999998
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         0.180952
evaluation/num steps total     140000
evaluation/num paths total        280
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00025374
evaluation/Rewards Std              0.00132252
evaluation/Rewards Max              0.0140508
evaluation/Rewards Min              6.68909e-15
evaluation/Returns Mean             0.12687
evaluation/Returns Std              0.0792272
evaluation/Returns Max              0.286825
evaluation/Returns Min              0.0577946
evaluation/ExplReturns Mean         0.12687
evaluation/ExplReturns Std          0.0792272
evaluation/ExplReturns Max          0.286825
evaluation/ExplReturns Min          0.0577946
evaluation/Actions Mean             0.251637
evaluation/Actions Std              0.674952
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.999988
evaluation/Num Paths               10
evaluation/Average Returns          0.12687
time/data storing (s)               0.0313281
time/evaluation sampling (s)       69.8587
time/exploration sampling (s)      77.6031
time/logging (s)                    0.0256652
time/saving (s)                     0.0656844
time/training (s)                   9.74787
time/epoch (s)                    157.332
time/total (s)                   4254.29
Epoch                              27
-----------------------------  ----------------
2023-08-31 13:03:50.102667 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 28 finished
-----------------------------  ----------------
replay_buffer/size             146000
trainer/QF1 Loss                    0.00175864
trainer/QF2 Loss                    0.00193824
trainer/Policy Loss               -15.0794
trainer/Q1 Predictions Mean        21.7132
trainer/Q1 Predictions Std          0.501009
trainer/Q1 Predictions Max         22.8931
trainer/Q1 Predictions Min         18.6157
trainer/Q2 Predictions Mean        21.7178
trainer/Q2 Predictions Std          0.502362
trainer/Q2 Predictions Max         22.9109
trainer/Q2 Predictions Min         18.6827
trainer/Q Targets Mean             21.6895
trainer/Q Targets Std               0.500351
trainer/Q Targets Max              22.9014
trainer/Q Targets Min              18.6013
trainer/Log Pis Mean                6.6481
trainer/Log Pis Std                 5.78026
trainer/Log Pis Max                26.7887
trainer/Log Pis Min                -4.47607
trainer/Policy mu Mean              0.362844
trainer/Policy mu Std               1.66274
trainer/Policy mu Max               4.46681
trainer/Policy mu Min              -3.87369
trainer/Policy log std Mean        -0.349727
trainer/Policy log std Std          0.177779
trainer/Policy log std Max          0.333605
trainer/Policy log std Min         -0.948376
trainer/Alpha                       0.000635688
trainer/Alpha Loss                 -2.59025
exploration/num steps total    146000
exploration/num paths total       292
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000718821
exploration/Rewards Std             0.0032254
exploration/Rewards Max             0.0401848
exploration/Rewards Min             2.83326e-10
exploration/Returns Mean            0.359411
exploration/Returns Std             0.225641
exploration/Returns Max             0.724894
exploration/Returns Min             0.0841324
exploration/Actions Mean            0.0374196
exploration/Actions Std             0.675642
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999978
exploration/Num Paths              10
exploration/Average Returns         0.359411
evaluation/num steps total     145000
evaluation/num paths total        290
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00115797
evaluation/Rewards Std              0.00358433
evaluation/Rewards Max              0.0640362
evaluation/Rewards Min              2.2778e-12
evaluation/Returns Mean             0.578983
evaluation/Returns Std              0.946548
evaluation/Returns Max              3.34728
evaluation/Returns Min              0.0658462
evaluation/ExplReturns Mean         0.578983
evaluation/ExplReturns Std          0.946548
evaluation/ExplReturns Max          3.34728
evaluation/ExplReturns Min          0.0658462
evaluation/Actions Mean             0.0500343
evaluation/Actions Std              0.550558
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.999934
evaluation/Num Paths               10
evaluation/Average Returns          0.578983
time/data storing (s)               0.0307155
time/evaluation sampling (s)       69.2901
time/exploration sampling (s)      73.4553
time/logging (s)                    0.025516
time/saving (s)                     0.0705422
time/training (s)                  10.2362
time/epoch (s)                    153.108
time/total (s)                   4407.4
Epoch                              28
-----------------------------  ----------------
2023-08-31 13:06:23.911554 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 29 finished
-----------------------------  ----------------
replay_buffer/size             151000
trainer/QF1 Loss                    0.00113266
trainer/QF2 Loss                    0.00175161
trainer/Policy Loss               -14.407
trainer/Q1 Predictions Mean        20.6965
trainer/Q1 Predictions Std          0.509523
trainer/Q1 Predictions Max         21.763
trainer/Q1 Predictions Min         16.4614
trainer/Q2 Predictions Mean        20.7209
trainer/Q2 Predictions Std          0.506883
trainer/Q2 Predictions Max         21.7892
trainer/Q2 Predictions Min         16.5027
trainer/Q Targets Mean             20.6979
trainer/Q Targets Std               0.507137
trainer/Q Targets Max              21.7861
trainer/Q Targets Min              16.5923
trainer/Log Pis Mean                6.3067
trainer/Log Pis Std                 5.7053
trainer/Log Pis Max                32.8619
trainer/Log Pis Min                -9.64815
trainer/Policy mu Mean              0.442618
trainer/Policy mu Std               1.59016
trainer/Policy mu Max               5.25582
trainer/Policy mu Min              -4.39822
trainer/Policy log std Mean        -0.344948
trainer/Policy log std Std          0.163487
trainer/Policy log std Max          0.376685
trainer/Policy log std Min         -0.881629
trainer/Alpha                       0.000597824
trainer/Alpha Loss                 -5.14584
exploration/num steps total    151000
exploration/num paths total       302
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00104689
exploration/Rewards Std             0.0040954
exploration/Rewards Max             0.0651193
exploration/Rewards Min             3.14308e-08
exploration/Returns Mean            0.523445
exploration/Returns Std             0.293472
exploration/Returns Max             1.10828
exploration/Returns Min             0.171218
exploration/Actions Mean            0.0104896
exploration/Actions Std             0.6905
exploration/Actions Max             0.999991
exploration/Actions Min            -0.999963
exploration/Num Paths              10
exploration/Average Returns         0.523445
evaluation/num steps total     150000
evaluation/num paths total        300
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00290942
evaluation/Rewards Std              0.00649424
evaluation/Rewards Max              0.0631439
evaluation/Rewards Min              7.25736e-08
evaluation/Returns Mean             1.45471
evaluation/Returns Std              2.55899
evaluation/Returns Max              9.01701
evaluation/Returns Min              0.179648
evaluation/ExplReturns Mean         1.45471
evaluation/ExplReturns Std          2.55899
evaluation/ExplReturns Max          9.01701
evaluation/ExplReturns Min          0.179648
evaluation/Actions Mean             0.0695742
evaluation/Actions Std              0.622645
evaluation/Actions Max              0.999846
evaluation/Actions Min             -0.999143
evaluation/Num Paths               10
evaluation/Average Returns          1.45471
time/data storing (s)               0.031076
time/evaluation sampling (s)       70.0058
time/exploration sampling (s)      73.4858
time/logging (s)                    0.0254769
time/saving (s)                     0.0709517
time/training (s)                  10.1861
time/epoch (s)                    153.805
time/total (s)                   4561.21
Epoch                              29
-----------------------------  ----------------
2023-08-31 13:08:58.426307 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 30 finished
-----------------------------  ----------------
replay_buffer/size             156000
trainer/QF1 Loss                    0.00246395
trainer/QF2 Loss                    0.0011012
trainer/Policy Loss               -13.1018
trainer/Q1 Predictions Mean        19.7324
trainer/Q1 Predictions Std          0.57971
trainer/Q1 Predictions Max         20.8555
trainer/Q1 Predictions Min         16.859
trainer/Q2 Predictions Mean        19.6998
trainer/Q2 Predictions Std          0.579918
trainer/Q2 Predictions Max         20.8238
trainer/Q2 Predictions Min         16.8335
trainer/Q Targets Mean             19.6932
trainer/Q Targets Std               0.579591
trainer/Q Targets Max              20.8621
trainer/Q Targets Min              16.8234
trainer/Log Pis Mean                6.6159
trainer/Log Pis Std                 5.88383
trainer/Log Pis Max                26.2056
trainer/Log Pis Min                -6.60032
trainer/Policy mu Mean              0.47315
trainer/Policy mu Std               1.62264
trainer/Policy mu Max               5.27865
trainer/Policy mu Min              -4.38604
trainer/Policy log std Mean        -0.352846
trainer/Policy log std Std          0.173493
trainer/Policy log std Max          0.240905
trainer/Policy log std Min         -1.17565
trainer/Alpha                       0.00054139
trainer/Alpha Loss                 -2.889
exploration/num steps total    156000
exploration/num paths total       312
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00166149
exploration/Rewards Std             0.00444284
exploration/Rewards Max             0.0604707
exploration/Rewards Min             2.80027e-07
exploration/Returns Mean            0.830745
exploration/Returns Std             0.810343
exploration/Returns Max             2.74069
exploration/Returns Min             0.0711392
exploration/Actions Mean           -0.0160781
exploration/Actions Std             0.678916
exploration/Actions Max             0.99988
exploration/Actions Min            -0.999975
exploration/Num Paths              10
exploration/Average Returns         0.830745
evaluation/num steps total     155000
evaluation/num paths total        310
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00388357
evaluation/Rewards Std              0.00678088
evaluation/Rewards Max              0.0511264
evaluation/Rewards Min              1.35638e-07
evaluation/Returns Mean             1.94179
evaluation/Returns Std              2.17162
evaluation/Returns Max              7.2433
evaluation/Returns Min              0.112825
evaluation/ExplReturns Mean         1.94179
evaluation/ExplReturns Std          2.17162
evaluation/ExplReturns Max          7.2433
evaluation/ExplReturns Min          0.112825
evaluation/Actions Mean            -0.0264357
evaluation/Actions Std              0.571711
evaluation/Actions Max              0.999734
evaluation/Actions Min             -0.999091
evaluation/Num Paths               10
evaluation/Average Returns          1.94179
time/data storing (s)               0.031203
time/evaluation sampling (s)       69.5779
time/exploration sampling (s)      74.6835
time/logging (s)                    0.0256148
time/saving (s)                     0.0694651
time/training (s)                  10.1236
time/epoch (s)                    154.511
time/total (s)                   4715.72
Epoch                              30
-----------------------------  ----------------
2023-08-31 13:11:29.656821 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 31 finished
-----------------------------  ----------------
replay_buffer/size             161000
trainer/QF1 Loss                    0.000571324
trainer/QF2 Loss                    0.000716958
trainer/Policy Loss               -13.1621
trainer/Q1 Predictions Mean        18.8296
trainer/Q1 Predictions Std          0.433148
trainer/Q1 Predictions Max         19.6038
trainer/Q1 Predictions Min         16.4653
trainer/Q2 Predictions Mean        18.8211
trainer/Q2 Predictions Std          0.433331
trainer/Q2 Predictions Max         19.606
trainer/Q2 Predictions Min         16.4588
trainer/Q Targets Mean             18.8316
trainer/Q Targets Std               0.434043
trainer/Q Targets Max              19.6282
trainer/Q Targets Min              16.4542
trainer/Log Pis Mean                5.67507
trainer/Log Pis Std                 6.29494
trainer/Log Pis Max                31.409
trainer/Log Pis Min                -9.61572
trainer/Policy mu Mean              0.325907
trainer/Policy mu Std               1.61895
trainer/Policy mu Max               5.11114
trainer/Policy mu Min              -4.61411
trainer/Policy log std Mean        -0.314087
trainer/Policy log std Std          0.16239
trainer/Policy log std Max          0.310984
trainer/Policy log std Min         -0.858308
trainer/Alpha                       0.000481672
trainer/Alpha Loss                -10.1198
exploration/num steps total    161000
exploration/num paths total       322
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.000153278
exploration/Rewards Std             0.000701392
exploration/Rewards Max             0.00872298
exploration/Rewards Min             5.21004e-10
exploration/Returns Mean            0.0766392
exploration/Returns Std             0.0248747
exploration/Returns Max             0.122623
exploration/Returns Min             0.0420739
exploration/Actions Mean           -0.0846195
exploration/Actions Std             0.679638
exploration/Actions Max             0.999894
exploration/Actions Min            -0.999791
exploration/Num Paths              10
exploration/Average Returns         0.0766392
evaluation/num steps total     160000
evaluation/num paths total        320
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.000301794
evaluation/Rewards Std              0.0013273
evaluation/Rewards Max              0.0134633
evaluation/Rewards Min              4.69265e-08
evaluation/Returns Mean             0.150897
evaluation/Returns Std              0.0760649
evaluation/Returns Max              0.31779
evaluation/Returns Min              0.0471201
evaluation/ExplReturns Mean         0.150897
evaluation/ExplReturns Std          0.0760649
evaluation/ExplReturns Max          0.31779
evaluation/ExplReturns Min          0.0471201
evaluation/Actions Mean            -0.056029
evaluation/Actions Std              0.645855
evaluation/Actions Max              0.999168
evaluation/Actions Min             -0.999845
evaluation/Num Paths               10
evaluation/Average Returns          0.150897
time/data storing (s)               0.03122
time/evaluation sampling (s)       67.5884
time/exploration sampling (s)      73.2208
time/logging (s)                    0.0256143
time/saving (s)                     0.0720816
time/training (s)                  10.2888
time/epoch (s)                    151.227
time/total (s)                   4866.95
Epoch                              31
-----------------------------  ----------------
2023-08-31 13:14:05.154508 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 32 finished
-----------------------------  ----------------
replay_buffer/size             166000
trainer/QF1 Loss                    0.000762749
trainer/QF2 Loss                    0.000922605
trainer/Policy Loss               -10.7149
trainer/Q1 Predictions Mean        17.9799
trainer/Q1 Predictions Std          0.45502
trainer/Q1 Predictions Max         18.7691
trainer/Q1 Predictions Min         15.3896
trainer/Q2 Predictions Mean        17.9801
trainer/Q2 Predictions Std          0.457064
trainer/Q2 Predictions Max         18.7717
trainer/Q2 Predictions Min         15.3616
trainer/Q Targets Mean             17.973
trainer/Q Targets Std               0.455731
trainer/Q Targets Max              18.8069
trainer/Q Targets Min              15.3961
trainer/Log Pis Mean                7.27255
trainer/Log Pis Std                 7.29641
trainer/Log Pis Max                34.3731
trainer/Log Pis Min                -4.71207
trainer/Policy mu Mean              0.293784
trainer/Policy mu Std               1.7875
trainer/Policy mu Max               6.35098
trainer/Policy mu Min              -6.3131
trainer/Policy log std Mean        -0.370024
trainer/Policy log std Std          0.169109
trainer/Policy log std Max          0.217432
trainer/Policy log std Min         -1.25042
trainer/Alpha                       0.000440747
trainer/Alpha Loss                  2.10606
exploration/num steps total    166000
exploration/num paths total       332
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0021191
exploration/Rewards Std             0.00780235
exploration/Rewards Max             0.0719234
exploration/Rewards Min             1.41795e-11
exploration/Returns Mean            1.05955
exploration/Returns Std             1.72518
exploration/Returns Max             5.83355
exploration/Returns Min             0.037857
exploration/Actions Mean            0.091442
exploration/Actions Std             0.682014
exploration/Actions Max             0.99999
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns         1.05955
evaluation/num steps total     165000
evaluation/num paths total        330
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00201548
evaluation/Rewards Std              0.0059943
evaluation/Rewards Max              0.0821635
evaluation/Rewards Min              3.3946e-10
evaluation/Returns Mean             1.00774
evaluation/Returns Std              1.1486
evaluation/Returns Max              3.48136
evaluation/Returns Min              0.0967214
evaluation/ExplReturns Mean         1.00774
evaluation/ExplReturns Std          1.1486
evaluation/ExplReturns Max          3.48136
evaluation/ExplReturns Min          0.0967214
evaluation/Actions Mean             0.0151082
evaluation/Actions Std              0.550263
evaluation/Actions Max              0.999975
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns          1.00774
time/data storing (s)               0.0312004
time/evaluation sampling (s)       69.7117
time/exploration sampling (s)      75.4845
time/logging (s)                    0.0255479
time/saving (s)                     0.0793513
time/training (s)                  10.1618
time/epoch (s)                    155.494
time/total (s)                   5022.45
Epoch                              32
-----------------------------  ----------------
2023-08-31 13:16:40.028849 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 33 finished
-----------------------------  ----------------
replay_buffer/size             171000
trainer/QF1 Loss                    0.00113394
trainer/QF2 Loss                    0.000978137
trainer/Policy Loss               -10.0426
trainer/Q1 Predictions Mean        17.1619
trainer/Q1 Predictions Std          0.416987
trainer/Q1 Predictions Max         18.0228
trainer/Q1 Predictions Min         15.2179
trainer/Q2 Predictions Mean        17.155
trainer/Q2 Predictions Std          0.416209
trainer/Q2 Predictions Max         18.0032
trainer/Q2 Predictions Min         15.1999
trainer/Q Targets Mean             17.1407
trainer/Q Targets Std               0.41656
trainer/Q Targets Max              18.0075
trainer/Q Targets Min              15.2047
trainer/Log Pis Mean                7.11928
trainer/Log Pis Std                 7.7579
trainer/Log Pis Max                39.0721
trainer/Log Pis Min                -6.9531
trainer/Policy mu Mean              0.0797957
trainer/Policy mu Std               1.77584
trainer/Policy mu Max               5.78357
trainer/Policy mu Min              -6.11464
trainer/Policy log std Mean        -0.359036
trainer/Policy log std Std          0.163079
trainer/Policy log std Max          0.21858
trainer/Policy log std Min         -1.06716
trainer/Alpha                       0.000409244
trainer/Alpha Loss                  0.930531
exploration/num steps total    171000
exploration/num paths total       342
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00279145
exploration/Rewards Std             0.00916149
exploration/Rewards Max             0.209865
exploration/Rewards Min             4.31426e-09
exploration/Returns Mean            1.39572
exploration/Returns Std             1.99903
exploration/Returns Max             6.93715
exploration/Returns Min             0.121336
exploration/Actions Mean            0.00154966
exploration/Actions Std             0.689014
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns         1.39572
evaluation/num steps total     170000
evaluation/num paths total        340
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00165178
evaluation/Rewards Std              0.00459605
evaluation/Rewards Max              0.0478866
evaluation/Rewards Min              4.84768e-10
evaluation/Returns Mean             0.825888
evaluation/Returns Std              0.793704
evaluation/Returns Max              2.21871
evaluation/Returns Min              0.0611596
evaluation/ExplReturns Mean         0.825888
evaluation/ExplReturns Std          0.793704
evaluation/ExplReturns Max          2.21871
evaluation/ExplReturns Min          0.0611596
evaluation/Actions Mean            -0.005694
evaluation/Actions Std              0.597476
evaluation/Actions Max              0.999967
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          0.825888
time/data storing (s)               0.0310632
time/evaluation sampling (s)       69.4236
time/exploration sampling (s)      75.1603
time/logging (s)                    0.0256587
time/saving (s)                     0.0663217
time/training (s)                  10.1639
time/epoch (s)                    154.871
time/total (s)                   5177.32
Epoch                              33
-----------------------------  ----------------
2023-08-31 13:19:14.839403 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 34 finished
-----------------------------  ----------------
replay_buffer/size             176000
trainer/QF1 Loss                    0.000517425
trainer/QF2 Loss                    0.000525579
trainer/Policy Loss                -9.89128
trainer/Q1 Predictions Mean        16.3507
trainer/Q1 Predictions Std          0.346826
trainer/Q1 Predictions Max         17.2356
trainer/Q1 Predictions Min         14.4539
trainer/Q2 Predictions Mean        16.3529
trainer/Q2 Predictions Std          0.346089
trainer/Q2 Predictions Max         17.2241
trainer/Q2 Predictions Min         14.4941
trainer/Q Targets Mean             16.3542
trainer/Q Targets Std               0.346864
trainer/Q Targets Max              17.2401
trainer/Q Targets Min              14.4747
trainer/Log Pis Mean                6.46596
trainer/Log Pis Std                 6.07583
trainer/Log Pis Max                37.7308
trainer/Log Pis Min                -6.94779
trainer/Policy mu Mean              0.161645
trainer/Policy mu Std               1.69294
trainer/Policy mu Max               6.84029
trainer/Policy mu Min              -5.80801
trainer/Policy log std Mean        -0.335166
trainer/Policy log std Std          0.157749
trainer/Policy log std Max          0.293206
trainer/Policy log std Min         -0.933604
trainer/Alpha                       0.0003814
trainer/Alpha Loss                 -4.2037
exploration/num steps total    176000
exploration/num paths total       352
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0104027
exploration/Rewards Std             0.0148749
exploration/Rewards Max             0.103193
exploration/Rewards Min             7.14941e-08
exploration/Returns Mean            5.20135
exploration/Returns Std             4.00173
exploration/Returns Max            13.7463
exploration/Returns Min             1.11859
exploration/Actions Mean           -0.0343412
exploration/Actions Std             0.681192
exploration/Actions Max             0.999997
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns         5.20135
evaluation/num steps total     175000
evaluation/num paths total        350
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0146951
evaluation/Rewards Std              0.0284435
evaluation/Rewards Max              0.733301
evaluation/Rewards Min              1.00775e-11
evaluation/Returns Mean             7.34753
evaluation/Returns Std              6.32576
evaluation/Returns Max             19.1564
evaluation/Returns Min              0.140995
evaluation/ExplReturns Mean         7.34753
evaluation/ExplReturns Std          6.32576
evaluation/ExplReturns Max         19.1564
evaluation/ExplReturns Min          0.140995
evaluation/Actions Mean            -0.020181
evaluation/Actions Std              0.622171
evaluation/Actions Max              1
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns          7.34753
time/data storing (s)               0.0314963
time/evaluation sampling (s)       70.4739
time/exploration sampling (s)      73.7565
time/logging (s)                    0.0255596
time/saving (s)                     0.0763699
time/training (s)                  10.443
time/epoch (s)                    154.807
time/total (s)                   5332.13
Epoch                              34
-----------------------------  ----------------
2023-08-31 13:21:50.918083 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 35 finished
-----------------------------  ----------------
replay_buffer/size             181000
trainer/QF1 Loss                    0.000759561
trainer/QF2 Loss                    0.00196348
trainer/Policy Loss                -8.10988
trainer/Q1 Predictions Mean        15.5817
trainer/Q1 Predictions Std          0.346657
trainer/Q1 Predictions Max         16.1231
trainer/Q1 Predictions Min         13.7447
trainer/Q2 Predictions Mean        15.6016
trainer/Q2 Predictions Std          0.34888
trainer/Q2 Predictions Max         16.1619
trainer/Q2 Predictions Min         13.7218
trainer/Q Targets Mean             15.5642
trainer/Q Targets Std               0.349564
trainer/Q Targets Max              16.12
trainer/Q Targets Min              13.7019
trainer/Log Pis Mean                7.48704
trainer/Log Pis Std                 6.01851
trainer/Log Pis Max                32.6261
trainer/Log Pis Min                -9.88251
trainer/Policy mu Mean              0.204548
trainer/Policy mu Std               1.76718
trainer/Policy mu Max               5.3228
trainer/Policy mu Min              -5.99323
trainer/Policy log std Mean        -0.372995
trainer/Policy log std Std          0.152342
trainer/Policy log std Max          0.221984
trainer/Policy log std Min         -0.972239
trainer/Alpha                       0.000366743
trainer/Alpha Loss                  3.85299
exploration/num steps total    181000
exploration/num paths total       362
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00186298
exploration/Rewards Std             0.00645853
exploration/Rewards Max             0.0574733
exploration/Rewards Min             8.51147e-12
exploration/Returns Mean            0.931489
exploration/Returns Std             1.23971
exploration/Returns Max             3.56138
exploration/Returns Min             0.0287209
exploration/Actions Mean            0.0156345
exploration/Actions Std             0.775485
exploration/Actions Max             1
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns         0.931489
evaluation/num steps total     180000
evaluation/num paths total        360
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00823873
evaluation/Rewards Std              0.0171818
evaluation/Rewards Max              0.102299
evaluation/Rewards Min              2.81616e-11
evaluation/Returns Mean             4.11936
evaluation/Returns Std              6.26147
evaluation/Returns Max             21.7516
evaluation/Returns Min              0.0164474
evaluation/ExplReturns Mean         4.11936
evaluation/ExplReturns Std          6.26147
evaluation/ExplReturns Max         21.7516
evaluation/ExplReturns Min          0.0164474
evaluation/Actions Mean            -0.0743402
evaluation/Actions Std              0.74132
evaluation/Actions Max              1
evaluation/Actions Min             -0.999997
evaluation/Num Paths               10
evaluation/Average Returns          4.11936
time/data storing (s)               0.030773
time/evaluation sampling (s)       71.0813
time/exploration sampling (s)      75.0104
time/logging (s)                    0.0256537
time/saving (s)                     0.0760274
time/training (s)                   9.85097
time/epoch (s)                    156.075
time/total (s)                   5488.21
Epoch                              35
-----------------------------  ----------------
2023-08-31 13:24:24.070132 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 36 finished
-----------------------------  ----------------
replay_buffer/size             186000
trainer/QF1 Loss                    0.0012554
trainer/QF2 Loss                    0.00052604
trainer/Policy Loss                -7.17135
trainer/Q1 Predictions Mean        14.8565
trainer/Q1 Predictions Std          0.357704
trainer/Q1 Predictions Max         15.628
trainer/Q1 Predictions Min         13.1779
trainer/Q2 Predictions Mean        14.839
trainer/Q2 Predictions Std          0.360359
trainer/Q2 Predictions Max         15.5984
trainer/Q2 Predictions Min         13.1336
trainer/Q Targets Mean             14.832
trainer/Q Targets Std               0.366061
trainer/Q Targets Max              15.5988
trainer/Q Targets Min              13.0911
trainer/Log Pis Mean                7.68232
trainer/Log Pis Std                 7.17213
trainer/Log Pis Max                44.9997
trainer/Log Pis Min                -6.75434
trainer/Policy mu Mean             -0.0485489
trainer/Policy mu Std               1.80795
trainer/Policy mu Max               6.65143
trainer/Policy mu Min              -7.94221
trainer/Policy log std Mean        -0.351037
trainer/Policy log std Std          0.166629
trainer/Policy log std Max          0.38114
trainer/Policy log std Min         -1.09632
trainer/Alpha                       0.000339588
trainer/Alpha Loss                  5.45021
exploration/num steps total    186000
exploration/num paths total       372
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            4.44772e-05
exploration/Rewards Std             0.000316384
exploration/Rewards Max             0.00564993
exploration/Rewards Min             8.46545e-16
exploration/Returns Mean            0.0222386
exploration/Returns Std             0.0112011
exploration/Returns Max             0.044879
exploration/Returns Min             0.00983717
exploration/Actions Mean            0.0138453
exploration/Actions Std             0.891849
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         0.0222386
evaluation/num steps total     185000
evaluation/num paths total        370
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00208546
evaluation/Rewards Std              0.00641795
evaluation/Rewards Max              0.0500825
evaluation/Rewards Min              9.85323e-16
evaluation/Returns Mean             1.04273
evaluation/Returns Std              2.28215
evaluation/Returns Max              7.62778
evaluation/Returns Min              0.00671801
evaluation/ExplReturns Mean         1.04273
evaluation/ExplReturns Std          2.28215
evaluation/ExplReturns Max          7.62778
evaluation/ExplReturns Min          0.00671801
evaluation/Actions Mean             0.0742489
evaluation/Actions Std              0.853685
evaluation/Actions Max              0.999999
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          1.04273
time/data storing (s)               0.0308691
time/evaluation sampling (s)       69.1193
time/exploration sampling (s)      73.9196
time/logging (s)                    0.025572
time/saving (s)                     0.0738055
time/training (s)                   9.97918
time/epoch (s)                    153.148
time/total (s)                   5641.36
Epoch                              36
-----------------------------  ----------------
2023-08-31 13:27:00.282624 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 37 finished
-----------------------------  ----------------
replay_buffer/size             191000
trainer/QF1 Loss                    0.000893161
trainer/QF2 Loss                    0.000949827
trainer/Policy Loss                -7.45539
trainer/Q1 Predictions Mean        14.1225
trainer/Q1 Predictions Std          0.375028
trainer/Q1 Predictions Max         14.797
trainer/Q1 Predictions Min         12.3493
trainer/Q2 Predictions Mean        14.1238
trainer/Q2 Predictions Std          0.371013
trainer/Q2 Predictions Max         14.7956
trainer/Q2 Predictions Min         12.3557
trainer/Q Targets Mean             14.1085
trainer/Q Targets Std               0.373656
trainer/Q Targets Max              14.8138
trainer/Q Targets Min              12.3489
trainer/Log Pis Mean                6.67657
trainer/Log Pis Std                 6.05979
trainer/Log Pis Max                30.0947
trainer/Log Pis Min               -12.3779
trainer/Policy mu Mean              0.0721545
trainer/Policy mu Std               1.72726
trainer/Policy mu Max               5.86281
trainer/Policy mu Min              -5.52524
trainer/Policy log std Mean        -0.334445
trainer/Policy log std Std          0.184369
trainer/Policy log std Max          0.319869
trainer/Policy log std Min         -0.911354
trainer/Alpha                       0.000326201
trainer/Alpha Loss                 -2.5965
exploration/num steps total    191000
exploration/num paths total       382
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00399137
exploration/Rewards Std             0.00974179
exploration/Rewards Max             0.074335
exploration/Rewards Min             4.99555e-11
exploration/Returns Mean            1.99568
exploration/Returns Std             2.29118
exploration/Returns Max             6.63795
exploration/Returns Min             0.0193133
exploration/Actions Mean           -0.00197407
exploration/Actions Std             0.734513
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         1.99568
evaluation/num steps total     190000
evaluation/num paths total        380
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00182533
evaluation/Rewards Std              0.00436145
evaluation/Rewards Max              0.0495033
evaluation/Rewards Min              4.08007e-15
evaluation/Returns Mean             0.912663
evaluation/Returns Std              1.58176
evaluation/Returns Max              5.01782
evaluation/Returns Min              0.025204
evaluation/ExplReturns Mean         0.912663
evaluation/ExplReturns Std          1.58176
evaluation/ExplReturns Max          5.01782
evaluation/ExplReturns Min          0.025204
evaluation/Actions Mean             0.0288356
evaluation/Actions Std              0.685671
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          0.912663
time/data storing (s)               0.0315595
time/evaluation sampling (s)       69.0919
time/exploration sampling (s)      76.7637
time/logging (s)                    0.0255993
time/saving (s)                     0.0698543
time/training (s)                  10.2263
time/epoch (s)                    156.209
time/total (s)                   5797.57
Epoch                              37
-----------------------------  ----------------
2023-08-31 13:29:40.282216 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 38 finished
-----------------------------  ----------------
replay_buffer/size             196000
trainer/QF1 Loss                    0.000666302
trainer/QF2 Loss                    0.000519575
trainer/Policy Loss                -6.8689
trainer/Q1 Predictions Mean        13.4544
trainer/Q1 Predictions Std          0.323591
trainer/Q1 Predictions Max         14.2655
trainer/Q1 Predictions Min         11.7144
trainer/Q2 Predictions Mean        13.4737
trainer/Q2 Predictions Std          0.326507
trainer/Q2 Predictions Max         14.3232
trainer/Q2 Predictions Min         11.7204
trainer/Q Targets Mean             13.467
trainer/Q Targets Std               0.32749
trainer/Q Targets Max              14.2697
trainer/Q Targets Min              11.7034
trainer/Log Pis Mean                6.59878
trainer/Log Pis Std                 5.94089
trainer/Log Pis Max                29.9626
trainer/Log Pis Min                -5.44801
trainer/Policy mu Mean              0.133287
trainer/Policy mu Std               1.7294
trainer/Policy mu Max               6.26612
trainer/Policy mu Min              -5.18007
trainer/Policy log std Mean        -0.332872
trainer/Policy log std Std          0.167797
trainer/Policy log std Max          0.26773
trainer/Policy log std Min         -0.972146
trainer/Alpha                       0.000315119
trainer/Alpha Loss                 -3.23474
exploration/num steps total    196000
exploration/num paths total       392
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00759275
exploration/Rewards Std             0.0154947
exploration/Rewards Max             0.211776
exploration/Rewards Min             4.36244e-09
exploration/Returns Mean            3.79637
exploration/Returns Std             3.66862
exploration/Returns Max            12.4604
exploration/Returns Min             0.453016
exploration/Actions Mean            0.0683566
exploration/Actions Std             0.759205
exploration/Actions Max             1
exploration/Actions Min            -0.999986
exploration/Num Paths              10
exploration/Average Returns         3.79637
evaluation/num steps total     195000
evaluation/num paths total        390
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0032947
evaluation/Rewards Std              0.0199537
evaluation/Rewards Max              0.728522
evaluation/Rewards Min              3.63204e-11
evaluation/Returns Mean             1.64735
evaluation/Returns Std              1.70623
evaluation/Returns Max              6.1939
evaluation/Returns Min              0.0480553
evaluation/ExplReturns Mean         1.64735
evaluation/ExplReturns Std          1.70623
evaluation/ExplReturns Max          6.1939
evaluation/ExplReturns Min          0.0480553
evaluation/Actions Mean            -0.0573402
evaluation/Actions Std              0.698438
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.999962
evaluation/Num Paths               10
evaluation/Average Returns          1.64735
time/data storing (s)               0.0317682
time/evaluation sampling (s)       71.8919
time/exploration sampling (s)      77.4951
time/logging (s)                    0.0254639
time/saving (s)                     0.072549
time/training (s)                  10.4791
time/epoch (s)                    159.996
time/total (s)                   5957.57
Epoch                              38
-----------------------------  ----------------
2023-08-31 13:32:19.430191 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 39 finished
-----------------------------  ----------------
replay_buffer/size             201000
trainer/QF1 Loss                    0.000585
trainer/QF2 Loss                    0.000372798
trainer/Policy Loss                -6.70535
trainer/Q1 Predictions Mean        12.8421
trainer/Q1 Predictions Std          0.305103
trainer/Q1 Predictions Max         13.7426
trainer/Q1 Predictions Min         11.2517
trainer/Q2 Predictions Mean        12.8582
trainer/Q2 Predictions Std          0.304592
trainer/Q2 Predictions Max         13.7734
trainer/Q2 Predictions Min         11.2501
trainer/Q Targets Mean             12.8555
trainer/Q Targets Std               0.308329
trainer/Q Targets Max              13.7745
trainer/Q Targets Min              11.2761
trainer/Log Pis Mean                6.15293
trainer/Log Pis Std                 6.2468
trainer/Log Pis Max                28.2342
trainer/Log Pis Min                -8.61167
trainer/Policy mu Mean              0.0639585
trainer/Policy mu Std               1.67765
trainer/Policy mu Max               5.13239
trainer/Policy mu Min              -5.73481
trainer/Policy log std Mean        -0.324292
trainer/Policy log std Std          0.183384
trainer/Policy log std Max          0.468544
trainer/Policy log std Min         -0.915187
trainer/Alpha                       0.000314516
trainer/Alpha Loss                 -6.83107
exploration/num steps total    201000
exploration/num paths total       402
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0127555
exploration/Rewards Std             0.0176138
exploration/Rewards Max             0.0851855
exploration/Rewards Min             7.61446e-13
exploration/Returns Mean            6.37774
exploration/Returns Std             5.95875
exploration/Returns Max            19.8429
exploration/Returns Min             1.00117
exploration/Actions Mean            0.0622881
exploration/Actions Std             0.762755
exploration/Actions Max             0.999993
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         6.37774
evaluation/num steps total     200000
evaluation/num paths total        400
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0154687
evaluation/Rewards Std              0.0171853
evaluation/Rewards Max              0.0867627
evaluation/Rewards Min              2.16688e-13
evaluation/Returns Mean             7.73435
evaluation/Returns Std              7.89549
evaluation/Returns Max             24.2545
evaluation/Returns Min              0.848106
evaluation/ExplReturns Mean         7.73435
evaluation/ExplReturns Std          7.89549
evaluation/ExplReturns Max         24.2545
evaluation/ExplReturns Min          0.848106
evaluation/Actions Mean             0.13059
evaluation/Actions Std              0.751184
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns          7.73435
time/data storing (s)               0.0312543
time/evaluation sampling (s)       71.8053
time/exploration sampling (s)      77.0352
time/logging (s)                    0.0255679
time/saving (s)                     0.0744611
time/training (s)                  10.1727
time/epoch (s)                    159.145
time/total (s)                   6116.72
Epoch                              39
-----------------------------  ----------------
2023-08-31 13:34:57.731248 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 40 finished
-----------------------------  ----------------
replay_buffer/size             206000
trainer/QF1 Loss                    0.000553173
trainer/QF2 Loss                    0.000868942
trainer/Policy Loss                -5.96471
trainer/Q1 Predictions Mean        12.3215
trainer/Q1 Predictions Std          0.289423
trainer/Q1 Predictions Max         13.0376
trainer/Q1 Predictions Min         11.2894
trainer/Q2 Predictions Mean        12.2912
trainer/Q2 Predictions Std          0.289514
trainer/Q2 Predictions Max         13.0109
trainer/Q2 Predictions Min         11.2185
trainer/Q Targets Mean             12.3111
trainer/Q Targets Std               0.290185
trainer/Q Targets Max              13.0503
trainer/Q Targets Min              11.2643
trainer/Log Pis Mean                6.34022
trainer/Log Pis Std                 5.53064
trainer/Log Pis Max                34.7966
trainer/Log Pis Min                -5.1809
trainer/Policy mu Mean              0.0515706
trainer/Policy mu Std               1.68687
trainer/Policy mu Max               5.18721
trainer/Policy mu Min              -5.0398
trainer/Policy log std Mean        -0.336463
trainer/Policy log std Std          0.187386
trainer/Policy log std Max          0.409473
trainer/Policy log std Min         -0.927596
trainer/Alpha                       0.000298415
trainer/Alpha Loss                 -5.35548
exploration/num steps total    206000
exploration/num paths total       412
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00604546
exploration/Rewards Std             0.0193988
exploration/Rewards Max             0.701239
exploration/Rewards Min             4.3942e-10
exploration/Returns Mean            3.02273
exploration/Returns Std             2.15386
exploration/Returns Max             7.22161
exploration/Returns Min             0.505686
exploration/Actions Mean            0.0187154
exploration/Actions Std             0.798292
exploration/Actions Max             0.999999
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         3.02273
evaluation/num steps total     205000
evaluation/num paths total        410
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00778959
evaluation/Rewards Std              0.0150302
evaluation/Rewards Max              0.113237
evaluation/Rewards Min              1.48105e-10
evaluation/Returns Mean             3.89479
evaluation/Returns Std              3.56191
evaluation/Returns Max             12.5023
evaluation/Returns Min              0.318966
evaluation/ExplReturns Mean         3.89479
evaluation/ExplReturns Std          3.56191
evaluation/ExplReturns Max         12.5023
evaluation/ExplReturns Min          0.318966
evaluation/Actions Mean            -0.0242216
evaluation/Actions Std              0.730342
evaluation/Actions Max              0.999998
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          3.89479
time/data storing (s)               0.0311126
time/evaluation sampling (s)       71.9425
time/exploration sampling (s)      75.7094
time/logging (s)                    0.0255743
time/saving (s)                     0.0761204
time/training (s)                  10.5127
time/epoch (s)                    158.297
time/total (s)                   6275.02
Epoch                              40
-----------------------------  ----------------
2023-08-31 13:37:35.589183 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 41 finished
-----------------------------  ----------------
replay_buffer/size             211000
trainer/QF1 Loss                    0.000762658
trainer/QF2 Loss                    0.0019548
trainer/Policy Loss                -5.22547
trainer/Q1 Predictions Mean        11.6948
trainer/Q1 Predictions Std          0.314564
trainer/Q1 Predictions Max         12.4373
trainer/Q1 Predictions Min         10.1078
trainer/Q2 Predictions Mean        11.6743
trainer/Q2 Predictions Std          0.313725
trainer/Q2 Predictions Max         12.4176
trainer/Q2 Predictions Min         10.086
trainer/Q Targets Mean             11.7149
trainer/Q Targets Std               0.315097
trainer/Q Targets Max              12.448
trainer/Q Targets Min              10.119
trainer/Log Pis Mean                6.46274
trainer/Log Pis Std                 5.731
trainer/Log Pis Max                25.5717
trainer/Log Pis Min                -5.94748
trainer/Policy mu Mean              0.0641514
trainer/Policy mu Std               1.67548
trainer/Policy mu Max               4.11665
trainer/Policy mu Min              -4.55348
trainer/Policy log std Mean        -0.356745
trainer/Policy log std Std          0.198818
trainer/Policy log std Max          0.303579
trainer/Policy log std Min         -1.07475
trainer/Alpha                       0.00028548
trainer/Alpha Loss                 -4.38483
exploration/num steps total    211000
exploration/num paths total       422
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00586503
exploration/Rewards Std             0.0107176
exploration/Rewards Max             0.0967699
exploration/Rewards Min             1.08109e-10
exploration/Returns Mean            2.93251
exploration/Returns Std             1.66518
exploration/Returns Max             5.89669
exploration/Returns Min             0.947196
exploration/Actions Mean           -0.0547957
exploration/Actions Std             0.765785
exploration/Actions Max             1
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns         2.93251
evaluation/num steps total     210000
evaluation/num paths total        420
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00777956
evaluation/Rewards Std              0.0137298
evaluation/Rewards Max              0.106628
evaluation/Rewards Min              9.24997e-09
evaluation/Returns Mean             3.88978
evaluation/Returns Std              2.86503
evaluation/Returns Max              9.39924
evaluation/Returns Min              0.201157
evaluation/ExplReturns Mean         3.88978
evaluation/ExplReturns Std          2.86503
evaluation/ExplReturns Max          9.39924
evaluation/ExplReturns Min          0.201157
evaluation/Actions Mean            -0.0633384
evaluation/Actions Std              0.735059
evaluation/Actions Max              0.999979
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns          3.88978
time/data storing (s)               0.0310134
time/evaluation sampling (s)       71.1257
time/exploration sampling (s)      76.1871
time/logging (s)                    0.0257551
time/saving (s)                     0.0744787
time/training (s)                  10.4105
time/epoch (s)                    157.855
time/total (s)                   6432.87
Epoch                              41
-----------------------------  ----------------
2023-08-31 13:40:13.505825 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 42 finished
-----------------------------  ----------------
replay_buffer/size             216000
trainer/QF1 Loss                    0.000760807
trainer/QF2 Loss                    0.000626738
trainer/Policy Loss                -4.82349
trainer/Q1 Predictions Mean        11.1366
trainer/Q1 Predictions Std          0.311794
trainer/Q1 Predictions Max         11.9201
trainer/Q1 Predictions Min          9.65655
trainer/Q2 Predictions Mean        11.141
trainer/Q2 Predictions Std          0.310959
trainer/Q2 Predictions Max         11.9233
trainer/Q2 Predictions Min          9.67454
trainer/Q Targets Mean             11.1555
trainer/Q Targets Std               0.312148
trainer/Q Targets Max              11.9559
trainer/Q Targets Min               9.65359
trainer/Log Pis Mean                6.3179
trainer/Log Pis Std                 6.19999
trainer/Log Pis Max                34.1631
trainer/Log Pis Min                -6.70485
trainer/Policy mu Mean              0.0392516
trainer/Policy mu Std               1.69397
trainer/Policy mu Max               4.35816
trainer/Policy mu Min              -5.25978
trainer/Policy log std Mean        -0.358163
trainer/Policy log std Std          0.182588
trainer/Policy log std Max          0.323906
trainer/Policy log std Min         -0.938825
trainer/Alpha                       0.000298215
trainer/Alpha Loss                 -5.53696
exploration/num steps total    216000
exploration/num paths total       432
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00632399
exploration/Rewards Std             0.0133161
exploration/Rewards Max             0.217901
exploration/Rewards Min             6.28861e-10
exploration/Returns Mean            3.162
exploration/Returns Std             3.45734
exploration/Returns Max             9.98542
exploration/Returns Min             0.404507
exploration/Actions Mean           -0.00295756
exploration/Actions Std             0.759658
exploration/Actions Max             0.999999
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns         3.162
evaluation/num steps total     215000
evaluation/num paths total        430
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00378329
evaluation/Rewards Std              0.00730634
evaluation/Rewards Max              0.0684881
evaluation/Rewards Min              2.54638e-07
evaluation/Returns Mean             1.89165
evaluation/Returns Std              1.52997
evaluation/Returns Max              5.81061
evaluation/Returns Min              0.309615
evaluation/ExplReturns Mean         1.89165
evaluation/ExplReturns Std          1.52997
evaluation/ExplReturns Max          5.81061
evaluation/ExplReturns Min          0.309615
evaluation/Actions Mean            -0.0896709
evaluation/Actions Std              0.6657
evaluation/Actions Max              0.998781
evaluation/Actions Min             -0.999888
evaluation/Num Paths               10
evaluation/Average Returns          1.89165
time/data storing (s)               0.0315876
time/evaluation sampling (s)       71.0049
time/exploration sampling (s)      76.7186
time/logging (s)                    0.0256401
time/saving (s)                     0.0697958
time/training (s)                  10.0624
time/epoch (s)                    157.913
time/total (s)                   6590.79
Epoch                              42
-----------------------------  ----------------
2023-08-31 13:42:56.587081 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 43 finished
-----------------------------  ----------------
replay_buffer/size             221000
trainer/QF1 Loss                    0.000363847
trainer/QF2 Loss                    0.000400348
trainer/Policy Loss                -3.62313
trainer/Q1 Predictions Mean        10.6696
trainer/Q1 Predictions Std          0.333794
trainer/Q1 Predictions Max         11.3887
trainer/Q1 Predictions Min          9.32363
trainer/Q2 Predictions Mean        10.6735
trainer/Q2 Predictions Std          0.333988
trainer/Q2 Predictions Max         11.3968
trainer/Q2 Predictions Min          9.32309
trainer/Q Targets Mean             10.6695
trainer/Q Targets Std               0.33547
trainer/Q Targets Max              11.3889
trainer/Q Targets Min               9.33258
trainer/Log Pis Mean                7.05615
trainer/Log Pis Std                 6.16174
trainer/Log Pis Max                34.5956
trainer/Log Pis Min                -3.73599
trainer/Policy mu Mean              0.13025
trainer/Policy mu Std               1.74787
trainer/Policy mu Max               5.9111
trainer/Policy mu Min              -5.78962
trainer/Policy log std Mean        -0.350425
trainer/Policy log std Std          0.164649
trainer/Policy log std Max          0.264639
trainer/Policy log std Min         -0.876843
trainer/Alpha                       0.000309798
trainer/Alpha Loss                  0.453699
exploration/num steps total    221000
exploration/num paths total       442
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00364066
exploration/Rewards Std             0.0079057
exploration/Rewards Max             0.090951
exploration/Rewards Min             4.32398e-08
exploration/Returns Mean            1.82033
exploration/Returns Std             1.35597
exploration/Returns Max             4.72076
exploration/Returns Min             0.113458
exploration/Actions Mean            0.0274225
exploration/Actions Std             0.747332
exploration/Actions Max             1
exploration/Actions Min            -0.999992
exploration/Num Paths              10
exploration/Average Returns         1.82033
evaluation/num steps total     220000
evaluation/num paths total        440
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00702308
evaluation/Rewards Std              0.0257803
evaluation/Rewards Max              0.689909
evaluation/Rewards Min              2.90755e-05
evaluation/Returns Mean             3.51154
evaluation/Returns Std              3.91361
evaluation/Returns Max             12.5619
evaluation/Returns Min              0.491528
evaluation/ExplReturns Mean         3.51154
evaluation/ExplReturns Std          3.91361
evaluation/ExplReturns Max         12.5619
evaluation/ExplReturns Min          0.491528
evaluation/Actions Mean            -0.0849645
evaluation/Actions Std              0.64964
evaluation/Actions Max              0.999595
evaluation/Actions Min             -0.999634
evaluation/Num Paths               10
evaluation/Average Returns          3.51154
time/data storing (s)               0.0311505
time/evaluation sampling (s)       71.4419
time/exploration sampling (s)      76.6033
time/logging (s)                    0.0258572
time/saving (s)                     0.0864718
time/training (s)                  14.8892
time/epoch (s)                    163.078
time/total (s)                   6753.87
Epoch                              43
-----------------------------  ----------------
2023-08-31 13:45:35.401074 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 44 finished
-----------------------------  ----------------
replay_buffer/size             226000
trainer/QF1 Loss                    0.000384017
trainer/QF2 Loss                    0.000399477
trainer/Policy Loss                -3.42256
trainer/Q1 Predictions Mean        10.1788
trainer/Q1 Predictions Std          0.301181
trainer/Q1 Predictions Max         11.0097
trainer/Q1 Predictions Min          8.81051
trainer/Q2 Predictions Mean        10.191
trainer/Q2 Predictions Std          0.304063
trainer/Q2 Predictions Max         11.02
trainer/Q2 Predictions Min          8.77836
trainer/Q Targets Mean             10.1857
trainer/Q Targets Std               0.30139
trainer/Q Targets Max              11.0195
trainer/Q Targets Min               8.80478
trainer/Log Pis Mean                6.76785
trainer/Log Pis Std                 6.23138
trainer/Log Pis Max                31.8426
trainer/Log Pis Min                -5.27231
trainer/Policy mu Mean              0.0871961
trainer/Policy mu Std               1.7125
trainer/Policy mu Max               4.92145
trainer/Policy mu Min              -6.20449
trainer/Policy log std Mean        -0.364583
trainer/Policy log std Std          0.16249
trainer/Policy log std Max          0.270846
trainer/Policy log std Min         -1.0551
trainer/Alpha                       0.000293674
trainer/Alpha Loss                 -1.88806
exploration/num steps total    226000
exploration/num paths total       452
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00321252
exploration/Rewards Std             0.00662672
exploration/Rewards Max             0.0515283
exploration/Rewards Min             2.05563e-06
exploration/Returns Mean            1.60626
exploration/Returns Std             1.4789
exploration/Returns Max             5.30812
exploration/Returns Min             0.103057
exploration/Actions Mean           -0.00893982
exploration/Actions Std             0.742435
exploration/Actions Max             0.999923
exploration/Actions Min            -0.999996
exploration/Num Paths              10
exploration/Average Returns         1.60626
evaluation/num steps total     225000
evaluation/num paths total        450
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00562512
evaluation/Rewards Std              0.00963144
evaluation/Rewards Max              0.0630755
evaluation/Rewards Min              5.65441e-08
evaluation/Returns Mean             2.81256
evaluation/Returns Std              2.08993
evaluation/Returns Max              7.45741
evaluation/Returns Min              0.493225
evaluation/ExplReturns Mean         2.81256
evaluation/ExplReturns Std          2.08993
evaluation/ExplReturns Max          7.45741
evaluation/ExplReturns Min          0.493225
evaluation/Actions Mean            -0.0346807
evaluation/Actions Std              0.667796
evaluation/Actions Max              0.999977
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns          2.81256
time/data storing (s)               0.0304975
time/evaluation sampling (s)       71.4696
time/exploration sampling (s)      76.7092
time/logging (s)                    0.0256078
time/saving (s)                     0.0752194
time/training (s)                  10.4999
time/epoch (s)                    158.81
time/total (s)                   6912.68
Epoch                              44
-----------------------------  ----------------
2023-08-31 13:48:12.553106 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 45 finished
-----------------------------  ----------------
replay_buffer/size             231000
trainer/QF1 Loss                    0.000528696
trainer/QF2 Loss                    0.000452744
trainer/Policy Loss                -2.87245
trainer/Q1 Predictions Mean         9.71935
trainer/Q1 Predictions Std          0.331437
trainer/Q1 Predictions Max         11.3766
trainer/Q1 Predictions Min          8.46223
trainer/Q2 Predictions Mean         9.72654
trainer/Q2 Predictions Std          0.331388
trainer/Q2 Predictions Max         11.3879
trainer/Q2 Predictions Min          8.46586
trainer/Q Targets Mean              9.71787
trainer/Q Targets Std               0.330557
trainer/Q Targets Max              11.366
trainer/Q Targets Min               8.46994
trainer/Log Pis Mean                6.85708
trainer/Log Pis Std                 6.21639
trainer/Log Pis Max                30.3783
trainer/Log Pis Min                -5.05435
trainer/Policy mu Mean             -0.0921332
trainer/Policy mu Std               1.7404
trainer/Policy mu Max               5.18529
trainer/Policy mu Min              -6.44604
trainer/Policy log std Mean        -0.351582
trainer/Policy log std Std          0.168139
trainer/Policy log std Max          0.390267
trainer/Policy log std Min         -0.995078
trainer/Alpha                       0.000283954
trainer/Alpha Loss                 -1.16715
exploration/num steps total    231000
exploration/num paths total       462
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00596612
exploration/Rewards Std             0.00977894
exploration/Rewards Max             0.0634925
exploration/Rewards Min             1.15991e-06
exploration/Returns Mean            2.98306
exploration/Returns Std             2.40423
exploration/Returns Max             9.4554
exploration/Returns Min             0.312394
exploration/Actions Mean            0.00160206
exploration/Actions Std             0.710797
exploration/Actions Max             0.999926
exploration/Actions Min            -0.999961
exploration/Num Paths              10
exploration/Average Returns         2.98306
evaluation/num steps total     230000
evaluation/num paths total        460
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00336552
evaluation/Rewards Std              0.00647006
evaluation/Rewards Max              0.0599998
evaluation/Rewards Min              7.171e-09
evaluation/Returns Mean             1.68276
evaluation/Returns Std              1.44032
evaluation/Returns Max              5.19934
evaluation/Returns Min              0.196116
evaluation/ExplReturns Mean         1.68276
evaluation/ExplReturns Std          1.44032
evaluation/ExplReturns Max          5.19934
evaluation/ExplReturns Min          0.196116
evaluation/Actions Mean            -0.0900977
evaluation/Actions Std              0.697832
evaluation/Actions Max              0.999298
evaluation/Actions Min             -0.999245
evaluation/Num Paths               10
evaluation/Average Returns          1.68276
time/data storing (s)               0.0309807
time/evaluation sampling (s)       70.9414
time/exploration sampling (s)      75.4318
time/logging (s)                    0.0257879
time/saving (s)                     0.0663705
time/training (s)                  10.6522
time/epoch (s)                    157.149
time/total (s)                   7069.83
Epoch                              45
-----------------------------  ----------------
2023-08-31 13:50:51.915083 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 46 finished
-----------------------------  ----------------
replay_buffer/size             236000
trainer/QF1 Loss                    0.000354455
trainer/QF2 Loss                    0.000470605
trainer/Policy Loss                -2.14213
trainer/Q1 Predictions Mean         9.27733
trainer/Q1 Predictions Std          0.330536
trainer/Q1 Predictions Max         10.0545
trainer/Q1 Predictions Min          7.58284
trainer/Q2 Predictions Mean         9.28421
trainer/Q2 Predictions Std          0.329156
trainer/Q2 Predictions Max         10.0707
trainer/Q2 Predictions Min          7.56299
trainer/Q Targets Mean              9.27399
trainer/Q Targets Std               0.331278
trainer/Q Targets Max              10.0335
trainer/Q Targets Min               7.56425
trainer/Log Pis Mean                7.14537
trainer/Log Pis Std                 6.12768
trainer/Log Pis Max                32.3164
trainer/Log Pis Min                -7.01618
trainer/Policy mu Mean              0.0257854
trainer/Policy mu Std               1.75208
trainer/Policy mu Max               6.63327
trainer/Policy mu Min              -6.73578
trainer/Policy log std Mean        -0.36814
trainer/Policy log std Std          0.173393
trainer/Policy log std Max          0.45929
trainer/Policy log std Min         -0.987267
trainer/Alpha                       0.000282388
trainer/Alpha Loss                  1.18806
exploration/num steps total    236000
exploration/num paths total       472
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00564512
exploration/Rewards Std             0.0124862
exploration/Rewards Max             0.0841902
exploration/Rewards Min             5.23347e-07
exploration/Returns Mean            2.82256
exploration/Returns Std             3.58181
exploration/Returns Max            11.8856
exploration/Returns Min             0.132437
exploration/Actions Mean           -0.0817592
exploration/Actions Std             0.726621
exploration/Actions Max             0.999919
exploration/Actions Min            -0.999973
exploration/Num Paths              10
exploration/Average Returns         2.82256
evaluation/num steps total     235000
evaluation/num paths total        470
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0116192
evaluation/Rewards Std              0.0122824
evaluation/Rewards Max              0.0669928
evaluation/Rewards Min              6.01734e-06
evaluation/Returns Mean             5.80958
evaluation/Returns Std              4.9688
evaluation/Returns Max             15.4263
evaluation/Returns Min              0.208364
evaluation/ExplReturns Mean         5.80958
evaluation/ExplReturns Std          4.9688
evaluation/ExplReturns Max         15.4263
evaluation/ExplReturns Min          0.208364
evaluation/Actions Mean             0.00838731
evaluation/Actions Std              0.729915
evaluation/Actions Max              0.999281
evaluation/Actions Min             -0.999171
evaluation/Num Paths               10
evaluation/Average Returns          5.80958
time/data storing (s)               0.0317735
time/evaluation sampling (s)       72.1908
time/exploration sampling (s)      76.6788
time/logging (s)                    0.025765
time/saving (s)                     0.0706306
time/training (s)                  10.3604
time/epoch (s)                    159.358
time/total (s)                   7229.19
Epoch                              46
-----------------------------  ----------------
2023-08-31 13:53:32.566966 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 47 finished
-----------------------------  ----------------
replay_buffer/size             241000
trainer/QF1 Loss                    0.000399004
trainer/QF2 Loss                    0.000450409
trainer/Policy Loss                -1.97536
trainer/Q1 Predictions Mean         8.86494
trainer/Q1 Predictions Std          0.305056
trainer/Q1 Predictions Max          9.60779
trainer/Q1 Predictions Min          7.76324
trainer/Q2 Predictions Mean         8.86831
trainer/Q2 Predictions Std          0.305288
trainer/Q2 Predictions Max          9.62107
trainer/Q2 Predictions Min          7.76853
trainer/Q Targets Mean              8.86445
trainer/Q Targets Std               0.302629
trainer/Q Targets Max               9.65316
trainer/Q Targets Min               7.77297
trainer/Log Pis Mean                6.89957
trainer/Log Pis Std                 6.2407
trainer/Log Pis Max                30.4675
trainer/Log Pis Min                -6.26622
trainer/Policy mu Mean             -0.0873136
trainer/Policy mu Std               1.71887
trainer/Policy mu Max               4.21274
trainer/Policy mu Min              -6.3702
trainer/Policy log std Mean        -0.353914
trainer/Policy log std Std          0.172919
trainer/Policy log std Max          0.324812
trainer/Policy log std Min         -1.04244
trainer/Alpha                       0.000281478
trainer/Alpha Loss                 -0.821087
exploration/num steps total    241000
exploration/num paths total       482
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00479824
exploration/Rewards Std             0.00937648
exploration/Rewards Max             0.0895316
exploration/Rewards Min             1.60109e-08
exploration/Returns Mean            2.39912
exploration/Returns Std             2.00366
exploration/Returns Max             7.66243
exploration/Returns Min             0.175924
exploration/Actions Mean            0.0770586
exploration/Actions Std             0.745706
exploration/Actions Max             0.99999
exploration/Actions Min            -0.999973
exploration/Num Paths              10
exploration/Average Returns         2.39912
evaluation/num steps total     240000
evaluation/num paths total        480
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00932662
evaluation/Rewards Std              0.011445
evaluation/Rewards Max              0.0807155
evaluation/Rewards Min              8.64848e-08
evaluation/Returns Mean             4.66331
evaluation/Returns Std              4.33356
evaluation/Returns Max             13.1996
evaluation/Returns Min              0.265793
evaluation/ExplReturns Mean         4.66331
evaluation/ExplReturns Std          4.33356
evaluation/ExplReturns Max         13.1996
evaluation/ExplReturns Min          0.265793
evaluation/Actions Mean             0.0294198
evaluation/Actions Std              0.711085
evaluation/Actions Max              0.999949
evaluation/Actions Min             -0.999921
evaluation/Num Paths               10
evaluation/Average Returns          4.66331
time/data storing (s)               0.031253
time/evaluation sampling (s)       70.8096
time/exploration sampling (s)      76.5121
time/logging (s)                    0.0258203
time/saving (s)                     0.0644304
time/training (s)                  13.205
time/epoch (s)                    160.648
time/total (s)                   7389.84
Epoch                              47
-----------------------------  ----------------
2023-08-31 13:56:15.713920 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 48 finished
-----------------------------  ----------------
replay_buffer/size             246000
trainer/QF1 Loss                    0.000391771
trainer/QF2 Loss                    0.000381629
trainer/Policy Loss                -1.27727
trainer/Q1 Predictions Mean         8.46591
trainer/Q1 Predictions Std          0.300676
trainer/Q1 Predictions Max          9.25462
trainer/Q1 Predictions Min          7.31172
trainer/Q2 Predictions Mean         8.46086
trainer/Q2 Predictions Std          0.300243
trainer/Q2 Predictions Max          9.27751
trainer/Q2 Predictions Min          7.33406
trainer/Q Targets Mean              8.46123
trainer/Q Targets Std               0.299668
trainer/Q Targets Max               9.22367
trainer/Q Targets Min               7.3207
trainer/Log Pis Mean                7.19142
trainer/Log Pis Std                 6.31369
trainer/Log Pis Max                37.1756
trainer/Log Pis Min                -6.16375
trainer/Policy mu Mean             -0.0795208
trainer/Policy mu Std               1.76135
trainer/Policy mu Max               5.53634
trainer/Policy mu Min              -6.56675
trainer/Policy log std Mean        -0.361189
trainer/Policy log std Std          0.164049
trainer/Policy log std Max          0.497324
trainer/Policy log std Min         -0.923698
trainer/Alpha                       0.000285225
trainer/Alpha Loss                  1.56243
exploration/num steps total    246000
exploration/num paths total       492
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0109385
exploration/Rewards Std             0.0186335
exploration/Rewards Max             0.21281
exploration/Rewards Min             4.37948e-07
exploration/Returns Mean            5.46927
exploration/Returns Std             6.67769
exploration/Returns Max            18.6687
exploration/Returns Min             0.603726
exploration/Actions Mean           -0.0917081
exploration/Actions Std             0.707932
exploration/Actions Max             0.999943
exploration/Actions Min            -0.999929
exploration/Num Paths              10
exploration/Average Returns         5.46927
evaluation/num steps total     245000
evaluation/num paths total        490
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0165594
evaluation/Rewards Std              0.0167189
evaluation/Rewards Max              0.0841746
evaluation/Rewards Min              3.69779e-06
evaluation/Returns Mean             8.27972
evaluation/Returns Std              4.54547
evaluation/Returns Max             15.1163
evaluation/Returns Min              0.789534
evaluation/ExplReturns Mean         8.27972
evaluation/ExplReturns Std          4.54547
evaluation/ExplReturns Max         15.1163
evaluation/ExplReturns Min          0.789534
evaluation/Actions Mean            -0.0683664
evaluation/Actions Std              0.631281
evaluation/Actions Max              0.999873
evaluation/Actions Min             -0.999973
evaluation/Num Paths               10
evaluation/Average Returns          8.27972
time/data storing (s)               0.0305198
time/evaluation sampling (s)       71.9696
time/exploration sampling (s)      76.1383
time/logging (s)                    0.0255795
time/saving (s)                     0.0737612
time/training (s)                  14.9053
time/epoch (s)                    163.143
time/total (s)                   7552.99
Epoch                              48
-----------------------------  ----------------
2023-08-31 13:58:56.167863 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 49 finished
-----------------------------  ----------------
replay_buffer/size             251000
trainer/QF1 Loss                    0.000730779
trainer/QF2 Loss                    0.000517499
trainer/Policy Loss                -0.725945
trainer/Q1 Predictions Mean         8.11344
trainer/Q1 Predictions Std          0.289769
trainer/Q1 Predictions Max          9.91245
trainer/Q1 Predictions Min          7.10574
trainer/Q2 Predictions Mean         8.11949
trainer/Q2 Predictions Std          0.290809
trainer/Q2 Predictions Max          9.91426
trainer/Q2 Predictions Min          7.1326
trainer/Q Targets Mean              8.13239
trainer/Q Targets Std               0.28921
trainer/Q Targets Max               9.92151
trainer/Q Targets Min               7.12333
trainer/Log Pis Mean                7.397
trainer/Log Pis Std                 5.33012
trainer/Log Pis Max                27.9642
trainer/Log Pis Min                -4.24026
trainer/Policy mu Mean              0.0487185
trainer/Policy mu Std               1.74586
trainer/Policy mu Max               4.53161
trainer/Policy mu Min              -5.68149
trainer/Policy log std Mean        -0.391534
trainer/Policy log std Std          0.162207
trainer/Policy log std Max          0.280075
trainer/Policy log std Min         -0.916952
trainer/Alpha                       0.000268843
trainer/Alpha Loss                  3.26392
exploration/num steps total    251000
exploration/num paths total       502
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00949109
exploration/Rewards Std             0.0147666
exploration/Rewards Max             0.0882874
exploration/Rewards Min             1.86055e-06
exploration/Returns Mean            4.74555
exploration/Returns Std             4.11174
exploration/Returns Max            10.4975
exploration/Returns Min             0.0519783
exploration/Actions Mean            0.00256657
exploration/Actions Std             0.743937
exploration/Actions Max             0.999989
exploration/Actions Min            -0.999907
exploration/Num Paths              10
exploration/Average Returns         4.74555
evaluation/num steps total     250000
evaluation/num paths total        500
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00253654
evaluation/Rewards Std              0.00566314
evaluation/Rewards Max              0.0527381
evaluation/Rewards Min              9.8719e-07
evaluation/Returns Mean             1.26827
evaluation/Returns Std              1.04055
evaluation/Returns Max              3.00693
evaluation/Returns Min              0.226703
evaluation/ExplReturns Mean         1.26827
evaluation/ExplReturns Std          1.04055
evaluation/ExplReturns Max          3.00693
evaluation/ExplReturns Min          0.226703
evaluation/Actions Mean             0.132266
evaluation/Actions Std              0.674876
evaluation/Actions Max              0.999321
evaluation/Actions Min             -0.999835
evaluation/Num Paths               10
evaluation/Average Returns          1.26827
time/data storing (s)               0.0314576
time/evaluation sampling (s)       70.6839
time/exploration sampling (s)      79.398
time/logging (s)                    0.0259182
time/saving (s)                     0.0703572
time/training (s)                  10.241
time/epoch (s)                    160.451
time/total (s)                   7713.44
Epoch                              49
-----------------------------  ----------------
2023-08-31 14:01:32.535457 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 50 finished
-----------------------------  ----------------
replay_buffer/size             256000
trainer/QF1 Loss                    0.000339029
trainer/QF2 Loss                    0.000502622
trainer/Policy Loss                -0.391347
trainer/Q1 Predictions Mean         7.79287
trainer/Q1 Predictions Std          0.290291
trainer/Q1 Predictions Max          9.58995
trainer/Q1 Predictions Min          6.66184
trainer/Q2 Predictions Mean         7.8012
trainer/Q2 Predictions Std          0.290372
trainer/Q2 Predictions Max          9.60498
trainer/Q2 Predictions Min          6.64372
trainer/Q Targets Mean              7.78656
trainer/Q Targets Std               0.29119
trainer/Q Targets Max               9.58685
trainer/Q Targets Min               6.6066
trainer/Log Pis Mean                7.41253
trainer/Log Pis Std                 5.94553
trainer/Log Pis Max                35.1341
trainer/Log Pis Min                -3.09346
trainer/Policy mu Mean             -0.271365
trainer/Policy mu Std               1.7369
trainer/Policy mu Max               6.27945
trainer/Policy mu Min              -5.69849
trainer/Policy log std Mean        -0.355653
trainer/Policy log std Std          0.167199
trainer/Policy log std Max          0.199726
trainer/Policy log std Min         -0.93303
trainer/Alpha                       0.0002777
trainer/Alpha Loss                  3.37831
exploration/num steps total    256000
exploration/num paths total       512
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00445556
exploration/Rewards Std             0.00925792
exploration/Rewards Max             0.0650525
exploration/Rewards Min             9.40547e-07
exploration/Returns Mean            2.22778
exploration/Returns Std             2.35192
exploration/Returns Max             9.07
exploration/Returns Min             0.870828
exploration/Actions Mean           -0.0130197
exploration/Actions Std             0.717399
exploration/Actions Max             0.999973
exploration/Actions Min            -0.999983
exploration/Num Paths              10
exploration/Average Returns         2.22778
evaluation/num steps total     255000
evaluation/num paths total        510
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.00474998
evaluation/Rewards Std              0.0137959
evaluation/Rewards Max              0.0849068
evaluation/Rewards Min              1.206e-07
evaluation/Returns Mean             2.37499
evaluation/Returns Std              4.82777
evaluation/Returns Max             16.7152
evaluation/Returns Min              0.169456
evaluation/ExplReturns Mean         2.37499
evaluation/ExplReturns Std          4.82777
evaluation/ExplReturns Max         16.7152
evaluation/ExplReturns Min          0.169456
evaluation/Actions Mean             0.0423809
evaluation/Actions Std              0.592204
evaluation/Actions Max              0.99936
evaluation/Actions Min             -0.999763
evaluation/Num Paths               10
evaluation/Average Returns          2.37499
time/data storing (s)               0.03133
time/evaluation sampling (s)       70.4588
time/exploration sampling (s)      75.3999
time/logging (s)                    0.025687
time/saving (s)                     0.0725902
time/training (s)                  10.3753
time/epoch (s)                    156.364
time/total (s)                   7869.81
Epoch                              50
-----------------------------  ----------------
2023-08-31 14:04:10.786546 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 51 finished
-----------------------------  ----------------
replay_buffer/size             261000
trainer/QF1 Loss                    0.000377007
trainer/QF2 Loss                    0.00050017
trainer/Policy Loss                 0.156607
trainer/Q1 Predictions Mean         7.445
trainer/Q1 Predictions Std          0.32105
trainer/Q1 Predictions Max          9.09516
trainer/Q1 Predictions Min          6.40602
trainer/Q2 Predictions Mean         7.45491
trainer/Q2 Predictions Std          0.318778
trainer/Q2 Predictions Max          9.09985
trainer/Q2 Predictions Min          6.42158
trainer/Q Targets Mean              7.44541
trainer/Q Targets Std               0.318723
trainer/Q Targets Max               9.05836
trainer/Q Targets Min               6.41217
trainer/Log Pis Mean                7.61389
trainer/Log Pis Std                 5.59246
trainer/Log Pis Max                25.0579
trainer/Log Pis Min                -4.8738
trainer/Policy mu Mean             -0.0259798
trainer/Policy mu Std               1.76892
trainer/Policy mu Max               4.79455
trainer/Policy mu Min              -4.34054
trainer/Policy log std Mean        -0.377637
trainer/Policy log std Std          0.165209
trainer/Policy log std Max          0.184421
trainer/Policy log std Min         -1.12328
trainer/Alpha                       0.000285596
trainer/Alpha Loss                  5.00998
exploration/num steps total    261000
exploration/num paths total       522
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0165395
exploration/Rewards Std             0.0249535
exploration/Rewards Max             0.220344
exploration/Rewards Min             7.10395e-06
exploration/Returns Mean            8.26977
exploration/Returns Std             8.49816
exploration/Returns Max            25.62
exploration/Returns Min             0.637058
exploration/Actions Mean            0.0151458
exploration/Actions Std             0.732318
exploration/Actions Max             0.999952
exploration/Actions Min            -0.999945
exploration/Num Paths              10
exploration/Average Returns         8.26977
evaluation/num steps total     260000
evaluation/num paths total        520
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0178623
evaluation/Rewards Std              0.0203562
evaluation/Rewards Max              0.0967776
evaluation/Rewards Min              1.44634e-05
evaluation/Returns Mean             8.93116
evaluation/Returns Std              8.76641
evaluation/Returns Max             28.2898
evaluation/Returns Min              0.514006
evaluation/ExplReturns Mean         8.93116
evaluation/ExplReturns Std          8.76641
evaluation/ExplReturns Max         28.2898
evaluation/ExplReturns Min          0.514006
evaluation/Actions Mean            -0.0605982
evaluation/Actions Std              0.705973
evaluation/Actions Max              0.998827
evaluation/Actions Min             -0.999441
evaluation/Num Paths               10
evaluation/Average Returns          8.93116
time/data storing (s)               0.0308906
time/evaluation sampling (s)       71.3866
time/exploration sampling (s)      76.3999
time/logging (s)                    0.0256475
time/saving (s)                     0.0647873
time/training (s)                  10.3396
time/epoch (s)                    158.247
time/total (s)                   8028.06
Epoch                              51
-----------------------------  ----------------
2023-08-31 14:06:49.990623 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 52 finished
-----------------------------  ----------------
replay_buffer/size             266000
trainer/QF1 Loss                    0.000293458
trainer/QF2 Loss                    0.000344492
trainer/Policy Loss                -0.123209
trainer/Q1 Predictions Mean         7.11529
trainer/Q1 Predictions Std          0.28684
trainer/Q1 Predictions Max          8.38443
trainer/Q1 Predictions Min          6.165
trainer/Q2 Predictions Mean         7.11764
trainer/Q2 Predictions Std          0.28679
trainer/Q2 Predictions Max          8.38315
trainer/Q2 Predictions Min          6.16215
trainer/Q Targets Mean              7.1124
trainer/Q Targets Std               0.289217
trainer/Q Targets Max               8.44257
trainer/Q Targets Min               6.15973
trainer/Log Pis Mean                7.00301
trainer/Log Pis Std                 5.32427
trainer/Log Pis Max                29.9647
trainer/Log Pis Min                -6.21419
trainer/Policy mu Mean             -0.0696517
trainer/Policy mu Std               1.71832
trainer/Policy mu Max               4.71011
trainer/Policy mu Min              -4.87494
trainer/Policy log std Mean        -0.384096
trainer/Policy log std Std          0.157225
trainer/Policy log std Max          0.40166
trainer/Policy log std Min         -0.984403
trainer/Alpha                       0.000303723
trainer/Alpha Loss                  0.0243801
exploration/num steps total    266000
exploration/num paths total       532
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.00803456
exploration/Rewards Std             0.0162909
exploration/Rewards Max             0.208148
exploration/Rewards Min             2.53884e-07
exploration/Returns Mean            4.01728
exploration/Returns Std             4.3461
exploration/Returns Max            14.9968
exploration/Returns Min             0.365494
exploration/Actions Mean            0.095774
exploration/Actions Std             0.69298
exploration/Actions Max             0.999686
exploration/Actions Min            -0.999854
exploration/Num Paths              10
exploration/Average Returns         4.01728
evaluation/num steps total     265000
evaluation/num paths total        530
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0134023
evaluation/Rewards Std              0.0197769
evaluation/Rewards Max              0.22095
evaluation/Rewards Min              0.000195369
evaluation/Returns Mean             6.70113
evaluation/Returns Std              5.48841
evaluation/Returns Max             17.2327
evaluation/Returns Min              1.8376
evaluation/ExplReturns Mean         6.70113
evaluation/ExplReturns Std          5.48841
evaluation/ExplReturns Max         17.2327
evaluation/ExplReturns Min          1.8376
evaluation/Actions Mean            -0.055319
evaluation/Actions Std              0.625582
evaluation/Actions Max              0.997629
evaluation/Actions Min             -0.998908
evaluation/Num Paths               10
evaluation/Average Returns          6.70113
time/data storing (s)               0.0309637
time/evaluation sampling (s)       71.0971
time/exploration sampling (s)      77.8899
time/logging (s)                    0.025612
time/saving (s)                     0.0626494
time/training (s)                  10.0942
time/epoch (s)                    159.2
time/total (s)                   8187.26
Epoch                              52
-----------------------------  ----------------
2023-08-31 14:09:34.955788 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 53 finished
-----------------------------  ----------------
replay_buffer/size             271000
trainer/QF1 Loss                    0.000342355
trainer/QF2 Loss                    0.000481729
trainer/Policy Loss                 0.366915
trainer/Q1 Predictions Mean         6.81282
trainer/Q1 Predictions Std          0.292294
trainer/Q1 Predictions Max          7.64437
trainer/Q1 Predictions Min          5.48595
trainer/Q2 Predictions Mean         6.82022
trainer/Q2 Predictions Std          0.292903
trainer/Q2 Predictions Max          7.66662
trainer/Q2 Predictions Min          5.46773
trainer/Q Targets Mean              6.80829
trainer/Q Targets Std               0.291088
trainer/Q Targets Max               7.596
trainer/Q Targets Min               5.50507
trainer/Log Pis Mean                7.19115
trainer/Log Pis Std                 5.48551
trainer/Log Pis Max                30.5713
trainer/Log Pis Min                -3.26245
trainer/Policy mu Mean             -0.00758252
trainer/Policy mu Std               1.71368
trainer/Policy mu Max               4.42947
trainer/Policy mu Min              -4.70518
trainer/Policy log std Mean        -0.378145
trainer/Policy log std Std          0.159115
trainer/Policy log std Max          0.399973
trainer/Policy log std Min         -0.881883
trainer/Alpha                       0.000304388
trainer/Alpha Loss                  1.54778
exploration/num steps total    271000
exploration/num paths total       542
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0298857
exploration/Rewards Std             0.0343629
exploration/Rewards Max             0.23687
exploration/Rewards Min             0.000120882
exploration/Returns Mean           14.9429
exploration/Returns Std            11.422
exploration/Returns Max            35.8179
exploration/Returns Min             4.22161
exploration/Actions Mean           -0.0233209
exploration/Actions Std             0.681124
exploration/Actions Max             0.9998
exploration/Actions Min            -0.999795
exploration/Num Paths              10
exploration/Average Returns        14.9429
evaluation/num steps total     270000
evaluation/num paths total        540
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0286056
evaluation/Rewards Std              0.029193
evaluation/Rewards Max              0.215024
evaluation/Rewards Min              4.30374e-07
evaluation/Returns Mean            14.3028
evaluation/Returns Std              8.55868
evaluation/Returns Max             28.7223
evaluation/Returns Min              1.23584
evaluation/ExplReturns Mean        14.3028
evaluation/ExplReturns Std          8.55868
evaluation/ExplReturns Max         28.7223
evaluation/ExplReturns Min          1.23584
evaluation/Actions Mean            -0.0384216
evaluation/Actions Std              0.613696
evaluation/Actions Max              0.99913
evaluation/Actions Min             -0.998353
evaluation/Num Paths               10
evaluation/Average Returns         14.3028
time/data storing (s)               0.0313216
time/evaluation sampling (s)       71.7701
time/exploration sampling (s)      78.5895
time/logging (s)                    0.0259837
time/saving (s)                     0.0771609
time/training (s)                  14.4677
time/epoch (s)                    164.962
time/total (s)                   8352.23
Epoch                              53
-----------------------------  ----------------
2023-08-31 14:12:15.936889 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 54 finished
-----------------------------  ----------------
replay_buffer/size             276000
trainer/QF1 Loss                    0.000729315
trainer/QF2 Loss                    0.000573966
trainer/Policy Loss                 0.973767
trainer/Q1 Predictions Mean         6.56183
trainer/Q1 Predictions Std          0.307468
trainer/Q1 Predictions Max          8.38677
trainer/Q1 Predictions Min          5.53804
trainer/Q2 Predictions Mean         6.57369
trainer/Q2 Predictions Std          0.310445
trainer/Q2 Predictions Max          8.4028
trainer/Q2 Predictions Min          5.5817
trainer/Q Targets Mean              6.57543
trainer/Q Targets Std               0.308999
trainer/Q Targets Max               8.40715
trainer/Q Targets Min               5.57092
trainer/Log Pis Mean                7.54863
trainer/Log Pis Std                 5.60962
trainer/Log Pis Max                26.4731
trainer/Log Pis Min                -9.14365
trainer/Policy mu Mean             -0.0368605
trainer/Policy mu Std               1.73941
trainer/Policy mu Max               4.49225
trainer/Policy mu Min              -5.89626
trainer/Policy log std Mean        -0.417429
trainer/Policy log std Std          0.149392
trainer/Policy log std Max          0.540527
trainer/Policy log std Min         -0.89877
trainer/Alpha                       0.000333288
trainer/Alpha Loss                  4.39263
exploration/num steps total    276000
exploration/num paths total       552
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0163474
exploration/Rewards Std             0.0182637
exploration/Rewards Max             0.208063
exploration/Rewards Min             0.000306161
exploration/Returns Mean            8.17369
exploration/Returns Std             5.09882
exploration/Returns Max            14.5701
exploration/Returns Min             1.15731
exploration/Actions Mean            0.00752128
exploration/Actions Std             0.744787
exploration/Actions Max             0.999975
exploration/Actions Min            -0.999886
exploration/Num Paths              10
exploration/Average Returns         8.17369
evaluation/num steps total     275000
evaluation/num paths total        550
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.018339
evaluation/Rewards Std              0.0171555
evaluation/Rewards Max              0.219128
evaluation/Rewards Min              0.00205175
evaluation/Returns Mean             9.16952
evaluation/Returns Std              7.07592
evaluation/Returns Max             24.1707
evaluation/Returns Min              2.34279
evaluation/ExplReturns Mean         9.16952
evaluation/ExplReturns Std          7.07592
evaluation/ExplReturns Max         24.1707
evaluation/ExplReturns Min          2.34279
evaluation/Actions Mean            -0.0048554
evaluation/Actions Std              0.707868
evaluation/Actions Max              0.998554
evaluation/Actions Min             -0.999506
evaluation/Num Paths               10
evaluation/Average Returns          9.16952
time/data storing (s)               0.0307546
time/evaluation sampling (s)       72.4416
time/exploration sampling (s)      77.8264
time/logging (s)                    0.0256389
time/saving (s)                     0.0725364
time/training (s)                  10.5801
time/epoch (s)                    160.977
time/total (s)                   8513.21
Epoch                              54
-----------------------------  ----------------
2023-08-31 14:14:56.385972 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 55 finished
-----------------------------  ----------------
replay_buffer/size             281000
trainer/QF1 Loss                    0.000638844
trainer/QF2 Loss                    0.000499396
trainer/Policy Loss                 0.991206
trainer/Q1 Predictions Mean         6.25582
trainer/Q1 Predictions Std          0.340991
trainer/Q1 Predictions Max          7.28589
trainer/Q1 Predictions Min          5.0459
trainer/Q2 Predictions Mean         6.26619
trainer/Q2 Predictions Std          0.341085
trainer/Q2 Predictions Max          7.29194
trainer/Q2 Predictions Min          5.05713
trainer/Q Targets Mean              6.26838
trainer/Q Targets Std               0.341745
trainer/Q Targets Max               7.3028
trainer/Q Targets Min               5.06055
trainer/Log Pis Mean                7.26109
trainer/Log Pis Std                 5.22406
trainer/Log Pis Max                21.1912
trainer/Log Pis Min                -5.99061
trainer/Policy mu Mean             -0.0344771
trainer/Policy mu Std               1.71813
trainer/Policy mu Max               4.0764
trainer/Policy mu Min              -4.49953
trainer/Policy log std Mean        -0.402674
trainer/Policy log std Std          0.150955
trainer/Policy log std Max          0.197603
trainer/Policy log std Min         -0.794378
trainer/Alpha                       0.000353125
trainer/Alpha Loss                  2.07538
exploration/num steps total    281000
exploration/num paths total       562
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0201518
exploration/Rewards Std             0.0277242
exploration/Rewards Max             0.216144
exploration/Rewards Min             0.000240233
exploration/Returns Mean           10.0759
exploration/Returns Std            11.2719
exploration/Returns Max            40.0238
exploration/Returns Min             0.673176
exploration/Actions Mean           -0.0433492
exploration/Actions Std             0.721635
exploration/Actions Max             0.999799
exploration/Actions Min            -0.999881
exploration/Num Paths              10
exploration/Average Returns        10.0759
evaluation/num steps total     280000
evaluation/num paths total        560
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0115514
evaluation/Rewards Std              0.0111481
evaluation/Rewards Max              0.206517
evaluation/Rewards Min              0.00125208
evaluation/Returns Mean             5.77568
evaluation/Returns Std              2.85821
evaluation/Returns Max             10.5858
evaluation/Returns Min              1.63987
evaluation/ExplReturns Mean         5.77568
evaluation/ExplReturns Std          2.85821
evaluation/ExplReturns Max         10.5858
evaluation/ExplReturns Min          1.63987
evaluation/Actions Mean            -0.0217651
evaluation/Actions Std              0.701246
evaluation/Actions Max              0.999297
evaluation/Actions Min             -0.998724
evaluation/Num Paths               10
evaluation/Average Returns          5.77568
time/data storing (s)               0.030982
time/evaluation sampling (s)       72.0385
time/exploration sampling (s)      77.4745
time/logging (s)                    0.025664
time/saving (s)                     0.0643099
time/training (s)                  10.8114
time/epoch (s)                    160.445
time/total (s)                   8673.66
Epoch                              55
-----------------------------  ----------------
2023-08-31 14:17:40.085575 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 56 finished
-----------------------------  ----------------
replay_buffer/size             286000
trainer/QF1 Loss                    0.00043602
trainer/QF2 Loss                    0.000508827
trainer/Policy Loss                 0.877252
trainer/Q1 Predictions Mean         6.02884
trainer/Q1 Predictions Std          0.303611
trainer/Q1 Predictions Max          6.82637
trainer/Q1 Predictions Min          5.05501
trainer/Q2 Predictions Mean         6.03311
trainer/Q2 Predictions Std          0.303578
trainer/Q2 Predictions Max          6.82282
trainer/Q2 Predictions Min          5.04713
trainer/Q Targets Mean              6.0314
trainer/Q Targets Std               0.306621
trainer/Q Targets Max               6.79913
trainer/Q Targets Min               5.06223
trainer/Log Pis Mean                6.91962
trainer/Log Pis Std                 4.70681
trainer/Log Pis Max                20.8723
trainer/Log Pis Min                -7.97751
trainer/Policy mu Mean             -0.114632
trainer/Policy mu Std               1.67373
trainer/Policy mu Max               4.16144
trainer/Policy mu Min              -3.75029
trainer/Policy log std Mean        -0.399397
trainer/Policy log std Std          0.142582
trainer/Policy log std Max          0.379011
trainer/Policy log std Min         -0.782162
trainer/Alpha                       0.000387007
trainer/Alpha Loss                 -0.631543
exploration/num steps total    286000
exploration/num paths total       572
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0279218
exploration/Rewards Std             0.0170998
exploration/Rewards Max             0.102409
exploration/Rewards Min             0.000695285
exploration/Returns Mean           13.9609
exploration/Returns Std             4.57372
exploration/Returns Max            22.2914
exploration/Returns Min             7.35468
exploration/Actions Mean           -0.127359
exploration/Actions Std             0.715157
exploration/Actions Max             0.999742
exploration/Actions Min            -0.999986
exploration/Num Paths              10
exploration/Average Returns        13.9609
evaluation/num steps total     285000
evaluation/num paths total        570
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0284665
evaluation/Rewards Std              0.0248156
evaluation/Rewards Max              0.0874971
evaluation/Rewards Min              6.59019e-05
evaluation/Returns Mean            14.2332
evaluation/Returns Std              9.61346
evaluation/Returns Max             34.8753
evaluation/Returns Min              2.42889
evaluation/ExplReturns Mean        14.2332
evaluation/ExplReturns Std          9.61346
evaluation/ExplReturns Max         34.8753
evaluation/ExplReturns Min          2.42889
evaluation/Actions Mean            -0.194664
evaluation/Actions Std              0.568978
evaluation/Actions Max              0.999417
evaluation/Actions Min             -0.999991
evaluation/Num Paths               10
evaluation/Average Returns         14.2332
time/data storing (s)               0.0318345
time/evaluation sampling (s)       71.7798
time/exploration sampling (s)      76.5358
time/logging (s)                    0.0260224
time/saving (s)                     0.0638032
time/training (s)                  15.2589
time/epoch (s)                    163.696
time/total (s)                   8837.35
Epoch                              56
-----------------------------  ----------------
2023-08-31 14:20:24.269542 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 57 finished
-----------------------------  ----------------
replay_buffer/size             291000
trainer/QF1 Loss                    0.000349931
trainer/QF2 Loss                    0.000393788
trainer/Policy Loss                 0.783113
trainer/Q1 Predictions Mean         5.85817
trainer/Q1 Predictions Std          0.359584
trainer/Q1 Predictions Max          7.63574
trainer/Q1 Predictions Min          4.92866
trainer/Q2 Predictions Mean         5.84763
trainer/Q2 Predictions Std          0.358283
trainer/Q2 Predictions Max          7.63119
trainer/Q2 Predictions Min          4.89344
trainer/Q Targets Mean              5.85135
trainer/Q Targets Std               0.36112
trainer/Q Targets Max               7.62974
trainer/Q Targets Min               4.8928
trainer/Log Pis Mean                6.64706
trainer/Log Pis Std                 4.17894
trainer/Log Pis Max                19.8498
trainer/Log Pis Min                -4.55543
trainer/Policy mu Mean             -0.0887794
trainer/Policy mu Std               1.64559
trainer/Policy mu Max               3.66088
trainer/Policy mu Min              -3.97611
trainer/Policy log std Mean        -0.415255
trainer/Policy log std Std          0.138186
trainer/Policy log std Max          0.0803577
trainer/Policy log std Min         -0.788245
trainer/Alpha                       0.000413629
trainer/Alpha Loss                 -2.74951
exploration/num steps total    291000
exploration/num paths total       582
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0361716
exploration/Rewards Std             0.0244214
exploration/Rewards Max             0.231951
exploration/Rewards Min             0.000610935
exploration/Returns Mean           18.0858
exploration/Returns Std             6.06734
exploration/Returns Max            27.1609
exploration/Returns Min            10.5735
exploration/Actions Mean           -0.0510144
exploration/Actions Std             0.737139
exploration/Actions Max             0.999844
exploration/Actions Min            -0.999858
exploration/Num Paths              10
exploration/Average Returns        18.0858
evaluation/num steps total     290000
evaluation/num paths total        580
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0445806
evaluation/Rewards Std              0.0236157
evaluation/Rewards Max              0.219188
evaluation/Rewards Min              0.000708984
evaluation/Returns Mean            22.2903
evaluation/Returns Std              7.07427
evaluation/Returns Max             32.9573
evaluation/Returns Min             11.686
evaluation/ExplReturns Mean        22.2903
evaluation/ExplReturns Std          7.07427
evaluation/ExplReturns Max         32.9573
evaluation/ExplReturns Min         11.686
evaluation/Actions Mean            -0.0965269
evaluation/Actions Std              0.665984
evaluation/Actions Max              0.998089
evaluation/Actions Min             -0.999306
evaluation/Num Paths               10
evaluation/Average Returns         22.2903
time/data storing (s)               0.0310866
time/evaluation sampling (s)       74.9771
time/exploration sampling (s)      77.7147
time/logging (s)                    0.0263078
time/saving (s)                     0.0701512
time/training (s)                  11.3611
time/epoch (s)                    164.18
time/total (s)                   9001.54
Epoch                              57
-----------------------------  ----------------
2023-08-31 14:23:04.654610 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 58 finished
-----------------------------  ----------------
replay_buffer/size             296000
trainer/QF1 Loss                    0.000306372
trainer/QF2 Loss                    0.000444025
trainer/Policy Loss                 1.52355
trainer/Q1 Predictions Mean         5.62188
trainer/Q1 Predictions Std          0.367042
trainer/Q1 Predictions Max          6.83822
trainer/Q1 Predictions Min          4.68772
trainer/Q2 Predictions Mean         5.61931
trainer/Q2 Predictions Std          0.366404
trainer/Q2 Predictions Max          6.81785
trainer/Q2 Predictions Min          4.69162
trainer/Q Targets Mean              5.62605
trainer/Q Targets Std               0.366324
trainer/Q Targets Max               6.83591
trainer/Q Targets Min               4.69685
trainer/Log Pis Mean                7.15912
trainer/Log Pis Std                 4.01356
trainer/Log Pis Max                19.9998
trainer/Log Pis Min                -5.14571
trainer/Policy mu Mean             -0.0950452
trainer/Policy mu Std               1.63307
trainer/Policy mu Max               3.72713
trainer/Policy mu Min              -3.60104
trainer/Policy log std Mean        -0.435648
trainer/Policy log std Std          0.154252
trainer/Policy log std Max          0.316915
trainer/Policy log std Min         -0.838293
trainer/Alpha                       0.000442216
trainer/Alpha Loss                  1.229
exploration/num steps total    296000
exploration/num paths total       592
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0295985
exploration/Rewards Std             0.0357685
exploration/Rewards Max             0.683048
exploration/Rewards Min             8.06042e-09
exploration/Returns Mean           14.7993
exploration/Returns Std            10.8583
exploration/Returns Max            39.0274
exploration/Returns Min             1.60167
exploration/Actions Mean           -0.237647
exploration/Actions Std             0.660138
exploration/Actions Max             0.999765
exploration/Actions Min            -0.999956
exploration/Num Paths              10
exploration/Average Returns        14.7993
evaluation/num steps total     295000
evaluation/num paths total        590
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0481617
evaluation/Rewards Std              0.0588037
evaluation/Rewards Max              0.217013
evaluation/Rewards Min              1.92943e-13
evaluation/Returns Mean            24.0809
evaluation/Returns Std             27.2927
evaluation/Returns Max             99.74
evaluation/Returns Min              1.92602
evaluation/ExplReturns Mean        24.0809
evaluation/ExplReturns Std         27.2927
evaluation/ExplReturns Max         99.74
evaluation/ExplReturns Min          1.92602
evaluation/Actions Mean            -0.217914
evaluation/Actions Std              0.628634
evaluation/Actions Max              0.993942
evaluation/Actions Min             -0.999555
evaluation/Num Paths               10
evaluation/Average Returns         24.0809
time/data storing (s)               0.0316788
time/evaluation sampling (s)       71.8759
time/exploration sampling (s)      78.2657
time/logging (s)                    0.0257984
time/saving (s)                     0.0725459
time/training (s)                  10.1091
time/epoch (s)                    160.381
time/total (s)                   9161.92
Epoch                              58
-----------------------------  ----------------
2023-08-31 14:25:45.734872 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 59 finished
-----------------------------  ----------------
replay_buffer/size             301000
trainer/QF1 Loss                    0.000466672
trainer/QF2 Loss                    0.000491725
trainer/Policy Loss                 1.26744
trainer/Q1 Predictions Mean         5.42641
trainer/Q1 Predictions Std          0.374815
trainer/Q1 Predictions Max          6.53591
trainer/Q1 Predictions Min          4.47707
trainer/Q2 Predictions Mean         5.42397
trainer/Q2 Predictions Std          0.375813
trainer/Q2 Predictions Max          6.55068
trainer/Q2 Predictions Min          4.49457
trainer/Q Targets Mean              5.42762
trainer/Q Targets Std               0.378338
trainer/Q Targets Max               6.55719
trainer/Q Targets Min               4.49948
trainer/Log Pis Mean                6.70724
trainer/Log Pis Std                 4.02183
trainer/Log Pis Max                21.834
trainer/Log Pis Min                -3.94999
trainer/Policy mu Mean             -0.0750013
trainer/Policy mu Std               1.62485
trainer/Policy mu Max               4.08789
trainer/Policy mu Min              -4.15402
trainer/Policy log std Mean        -0.432832
trainer/Policy log std Std          0.14848
trainer/Policy log std Max          0.282962
trainer/Policy log std Min         -0.826449
trainer/Alpha                       0.000440144
trainer/Alpha Loss                 -2.26251
exploration/num steps total    301000
exploration/num paths total       602
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0310603
exploration/Rewards Std             0.0264812
exploration/Rewards Max             0.218386
exploration/Rewards Min             0.000205194
exploration/Returns Mean           15.5302
exploration/Returns Std             9.0966
exploration/Returns Max            34.2437
exploration/Returns Min             4.6554
exploration/Actions Mean           -0.190699
exploration/Actions Std             0.695174
exploration/Actions Max             0.999341
exploration/Actions Min            -0.999977
exploration/Num Paths              10
exploration/Average Returns        15.5302
evaluation/num steps total     300000
evaluation/num paths total        600
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0371935
evaluation/Rewards Std              0.0367841
evaluation/Rewards Max              0.218736
evaluation/Rewards Min              3.49081e-07
evaluation/Returns Mean            18.5967
evaluation/Returns Std             13.9611
evaluation/Returns Max             47.6399
evaluation/Returns Min              2.73198
evaluation/ExplReturns Mean        18.5967
evaluation/ExplReturns Std         13.9611
evaluation/ExplReturns Max         47.6399
evaluation/ExplReturns Min          2.73198
evaluation/Actions Mean            -0.167945
evaluation/Actions Std              0.584371
evaluation/Actions Max              0.999446
evaluation/Actions Min             -0.998728
evaluation/Num Paths               10
evaluation/Average Returns         18.5967
time/data storing (s)               0.0314144
time/evaluation sampling (s)       71.1852
time/exploration sampling (s)      79.4673
time/logging (s)                    0.0257451
time/saving (s)                     0.0720935
time/training (s)                  10.2947
time/epoch (s)                    161.076
time/total (s)                   9323
Epoch                              59
-----------------------------  ----------------
2023-08-31 14:28:28.804438 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 60 finished
-----------------------------  ----------------
replay_buffer/size             306000
trainer/QF1 Loss                    0.000565938
trainer/QF2 Loss                    0.000635354
trainer/Policy Loss                 1.45469
trainer/Q1 Predictions Mean         5.26453
trainer/Q1 Predictions Std          0.41264
trainer/Q1 Predictions Max          6.9381
trainer/Q1 Predictions Min          4.35886
trainer/Q2 Predictions Mean         5.27145
trainer/Q2 Predictions Std          0.412066
trainer/Q2 Predictions Max          6.94337
trainer/Q2 Predictions Min          4.36785
trainer/Q Targets Mean              5.26799
trainer/Q Targets Std               0.413455
trainer/Q Targets Max               6.90496
trainer/Q Targets Min               4.36044
trainer/Log Pis Mean                6.7381
trainer/Log Pis Std                 4.67447
trainer/Log Pis Max                20.0574
trainer/Log Pis Min                -5.66563
trainer/Policy mu Mean             -0.0115139
trainer/Policy mu Std               1.63862
trainer/Policy mu Max               3.82629
trainer/Policy mu Min              -3.71237
trainer/Policy log std Mean        -0.462832
trainer/Policy log std Std          0.136342
trainer/Policy log std Max          0.111457
trainer/Policy log std Min         -0.889954
trainer/Alpha                       0.000447778
trainer/Alpha Loss                 -2.01951
exploration/num steps total    306000
exploration/num paths total       612
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.034228
exploration/Rewards Std             0.0297609
exploration/Rewards Max             0.22923
exploration/Rewards Min             1.5449e-05
exploration/Returns Mean           17.114
exploration/Returns Std             8.8393
exploration/Returns Max            34.8414
exploration/Returns Min             6.2627
exploration/Actions Mean           -0.0811127
exploration/Actions Std             0.691404
exploration/Actions Max             0.99984
exploration/Actions Min            -0.999733
exploration/Num Paths              10
exploration/Average Returns        17.114
evaluation/num steps total     305000
evaluation/num paths total        610
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.054363
evaluation/Rewards Std              0.0431815
evaluation/Rewards Max              0.22414
evaluation/Rewards Min              0.00125167
evaluation/Returns Mean            27.1815
evaluation/Returns Std             17.5408
evaluation/Returns Max             73.1892
evaluation/Returns Min              9.65082
evaluation/ExplReturns Mean        27.1815
evaluation/ExplReturns Std         17.5408
evaluation/ExplReturns Max         73.1892
evaluation/ExplReturns Min          9.65082
evaluation/Actions Mean            -0.0168616
evaluation/Actions Std              0.730294
evaluation/Actions Max              0.999112
evaluation/Actions Min             -0.999702
evaluation/Num Paths               10
evaluation/Average Returns         27.1815
time/data storing (s)               0.0309588
time/evaluation sampling (s)       73.5346
time/exploration sampling (s)      78.894
time/logging (s)                    0.0255195
time/saving (s)                     0.0659623
time/training (s)                  10.5146
time/epoch (s)                    163.066
time/total (s)                   9486.07
Epoch                              60
-----------------------------  ----------------
2023-08-31 14:31:13.236192 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 61 finished
-----------------------------  ----------------
replay_buffer/size             311000
trainer/QF1 Loss                    0.000454698
trainer/QF2 Loss                    0.000529942
trainer/Policy Loss                 2.18913
trainer/Q1 Predictions Mean         5.12164
trainer/Q1 Predictions Std          0.422236
trainer/Q1 Predictions Max          6.69998
trainer/Q1 Predictions Min          4.04176
trainer/Q2 Predictions Mean         5.126
trainer/Q2 Predictions Std          0.422345
trainer/Q2 Predictions Max          6.69362
trainer/Q2 Predictions Min          4.02795
trainer/Q Targets Mean              5.11742
trainer/Q Targets Std               0.420314
trainer/Q Targets Max               6.6948
trainer/Q Targets Min               4.02315
trainer/Log Pis Mean                7.33049
trainer/Log Pis Std                 4.59022
trainer/Log Pis Max                20.9146
trainer/Log Pis Min                -3.61402
trainer/Policy mu Mean             -0.136513
trainer/Policy mu Std               1.68082
trainer/Policy mu Max               4.08036
trainer/Policy mu Min              -4.5353
trainer/Policy log std Mean        -0.483156
trainer/Policy log std Std          0.140672
trainer/Policy log std Max          0.10268
trainer/Policy log std Min         -0.813988
trainer/Alpha                       0.000451083
trainer/Alpha Loss                  2.54618
exploration/num steps total    311000
exploration/num paths total       622
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0379496
exploration/Rewards Std             0.0285192
exploration/Rewards Max             0.219892
exploration/Rewards Min             1.00447e-13
exploration/Returns Mean           18.9748
exploration/Returns Std             9.72268
exploration/Returns Max            36.9975
exploration/Returns Min             5.83533
exploration/Actions Mean           -0.0316554
exploration/Actions Std             0.717415
exploration/Actions Max             0.999971
exploration/Actions Min            -0.999746
exploration/Num Paths              10
exploration/Average Returns        18.9748
evaluation/num steps total     310000
evaluation/num paths total        620
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0669932
evaluation/Rewards Std              0.0496029
evaluation/Rewards Max              0.247393
evaluation/Rewards Min              0.000592723
evaluation/Returns Mean            33.4966
evaluation/Returns Std             16.127
evaluation/Returns Max             62.1926
evaluation/Returns Min              6.64937
evaluation/ExplReturns Mean        33.4966
evaluation/ExplReturns Std         16.127
evaluation/ExplReturns Max         62.1926
evaluation/ExplReturns Min          6.64937
evaluation/Actions Mean            -0.124246
evaluation/Actions Std              0.667946
evaluation/Actions Max              0.996159
evaluation/Actions Min             -0.994819
evaluation/Num Paths               10
evaluation/Average Returns         33.4966
time/data storing (s)               0.0310493
time/evaluation sampling (s)       73.0189
time/exploration sampling (s)      77.7406
time/logging (s)                    0.0256471
time/saving (s)                     0.0815776
time/training (s)                  13.5303
time/epoch (s)                    164.428
time/total (s)                   9650.5
Epoch                              61
-----------------------------  ----------------
2023-08-31 14:33:58.132917 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 62 finished
-----------------------------  ----------------
replay_buffer/size             316000
trainer/QF1 Loss                    0.000756382
trainer/QF2 Loss                    0.000828509
trainer/Policy Loss                 2.61025
trainer/Q1 Predictions Mean         5.0061
trainer/Q1 Predictions Std          0.490623
trainer/Q1 Predictions Max          6.53185
trainer/Q1 Predictions Min          3.89513
trainer/Q2 Predictions Mean         5.00893
trainer/Q2 Predictions Std          0.489296
trainer/Q2 Predictions Max          6.55151
trainer/Q2 Predictions Min          3.90923
trainer/Q Targets Mean              4.99647
trainer/Q Targets Std               0.490878
trainer/Q Targets Max               6.55528
trainer/Q Targets Min               3.90108
trainer/Log Pis Mean                7.63651
trainer/Log Pis Std                 4.35335
trainer/Log Pis Max                19.384
trainer/Log Pis Min                -4.70106
trainer/Policy mu Mean             -0.123415
trainer/Policy mu Std               1.67222
trainer/Policy mu Max               3.75402
trainer/Policy mu Min              -4.60113
trainer/Policy log std Mean        -0.488416
trainer/Policy log std Std          0.157886
trainer/Policy log std Max          0.0674225
trainer/Policy log std Min         -0.882691
trainer/Alpha                       0.000464621
trainer/Alpha Loss                  4.88491
exploration/num steps total    316000
exploration/num paths total       632
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0441322
exploration/Rewards Std             0.0270042
exploration/Rewards Max             0.221405
exploration/Rewards Min             6.32719e-06
exploration/Returns Mean           22.0661
exploration/Returns Std             8.48449
exploration/Returns Max            33.8043
exploration/Returns Min            10.0925
exploration/Actions Mean           -0.166782
exploration/Actions Std             0.672353
exploration/Actions Max             0.999804
exploration/Actions Min            -0.999672
exploration/Num Paths              10
exploration/Average Returns        22.0661
evaluation/num steps total     315000
evaluation/num paths total        630
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0657219
evaluation/Rewards Std              0.0264339
evaluation/Rewards Max              0.221511
evaluation/Rewards Min              0.00153028
evaluation/Returns Mean            32.8609
evaluation/Returns Std             10.6034
evaluation/Returns Max             51.6488
evaluation/Returns Min             15.9418
evaluation/ExplReturns Mean        32.8609
evaluation/ExplReturns Std         10.6034
evaluation/ExplReturns Max         51.6488
evaluation/ExplReturns Min         15.9418
evaluation/Actions Mean            -0.248518
evaluation/Actions Std              0.558081
evaluation/Actions Max              0.990033
evaluation/Actions Min             -0.996775
evaluation/Num Paths               10
evaluation/Average Returns         32.8609
time/data storing (s)               0.0315866
time/evaluation sampling (s)       73.3163
time/exploration sampling (s)      81.3916
time/logging (s)                    0.0260209
time/saving (s)                     0.0696973
time/training (s)                  10.0581
time/epoch (s)                    164.893
time/total (s)                   9815.4
Epoch                              62
-----------------------------  ----------------
2023-08-31 14:36:45.198405 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 63 finished
-----------------------------  ----------------
replay_buffer/size             321000
trainer/QF1 Loss                    0.00071946
trainer/QF2 Loss                    0.000794422
trainer/Policy Loss                 2.2394
trainer/Q1 Predictions Mean         4.86821
trainer/Q1 Predictions Std          0.497318
trainer/Q1 Predictions Max          6.47501
trainer/Q1 Predictions Min          3.68275
trainer/Q2 Predictions Mean         4.86491
trainer/Q2 Predictions Std          0.497143
trainer/Q2 Predictions Max          6.48865
trainer/Q2 Predictions Min          3.62591
trainer/Q Targets Mean              4.87877
trainer/Q Targets Std               0.498115
trainer/Q Targets Max               6.5025
trainer/Q Targets Min               3.66821
trainer/Log Pis Mean                7.12826
trainer/Log Pis Std                 3.99945
trainer/Log Pis Max                25.1492
trainer/Log Pis Min                -5.01825
trainer/Policy mu Mean             -0.0717801
trainer/Policy mu Std               1.64148
trainer/Policy mu Max               3.33982
trainer/Policy mu Min              -3.98443
trainer/Policy log std Mean        -0.512034
trainer/Policy log std Std          0.141677
trainer/Policy log std Max         -0.0301059
trainer/Policy log std Min         -0.866995
trainer/Alpha                       0.000490244
trainer/Alpha Loss                  0.977403
exploration/num steps total    321000
exploration/num paths total       642
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.067922
exploration/Rewards Std             0.0567032
exploration/Rewards Max             0.732747
exploration/Rewards Min             0.00136942
exploration/Returns Mean           33.961
exploration/Returns Std            26.0237
exploration/Returns Max           109.283
exploration/Returns Min            16.6556
exploration/Actions Mean           -0.056665
exploration/Actions Std             0.712358
exploration/Actions Max             0.999637
exploration/Actions Min            -0.999733
exploration/Num Paths              10
exploration/Average Returns        33.961
evaluation/num steps total     320000
evaluation/num paths total        640
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0621074
evaluation/Rewards Std              0.0406443
evaluation/Rewards Max              0.222543
evaluation/Rewards Min              0.00151817
evaluation/Returns Mean            31.0537
evaluation/Returns Std             14.237
evaluation/Returns Max             66.9605
evaluation/Returns Min             16.8129
evaluation/ExplReturns Mean        31.0537
evaluation/ExplReturns Std         14.237
evaluation/ExplReturns Max         66.9605
evaluation/ExplReturns Min         16.8129
evaluation/Actions Mean            -0.128095
evaluation/Actions Std              0.60138
evaluation/Actions Max              0.995103
evaluation/Actions Min             -0.998216
evaluation/Num Paths               10
evaluation/Average Returns         31.0537
time/data storing (s)               0.0314272
time/evaluation sampling (s)       75.2251
time/exploration sampling (s)      81.6262
time/logging (s)                    0.0256826
time/saving (s)                     0.0757413
time/training (s)                  10.0771
time/epoch (s)                    167.061
time/total (s)                   9982.46
Epoch                              63
-----------------------------  ----------------
2023-08-31 14:39:30.902989 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 64 finished
-----------------------------  ----------------
replay_buffer/size             326000
trainer/QF1 Loss                    0.000786013
trainer/QF2 Loss                    0.00100749
trainer/Policy Loss                 1.87654
trainer/Q1 Predictions Mean         4.81559
trainer/Q1 Predictions Std          0.538729
trainer/Q1 Predictions Max          6.37764
trainer/Q1 Predictions Min          3.43161
trainer/Q2 Predictions Mean         4.81498
trainer/Q2 Predictions Std          0.537536
trainer/Q2 Predictions Max          6.34803
trainer/Q2 Predictions Min          3.45198
trainer/Q Targets Mean              4.80081
trainer/Q Targets Std               0.536249
trainer/Q Targets Max               6.31299
trainer/Q Targets Min               3.43676
trainer/Log Pis Mean                6.71533
trainer/Log Pis Std                 4.06374
trainer/Log Pis Max                20.0459
trainer/Log Pis Min                -5.31467
trainer/Policy mu Mean             -0.0587526
trainer/Policy mu Std               1.61312
trainer/Policy mu Max               4.21123
trainer/Policy mu Min              -3.57576
trainer/Policy log std Mean        -0.53887
trainer/Policy log std Std          0.144816
trainer/Policy log std Max         -0.0658184
trainer/Policy log std Min         -1.09172
trainer/Alpha                       0.000526642
trainer/Alpha Loss                 -2.14891
exploration/num steps total    326000
exploration/num paths total       652
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0579233
exploration/Rewards Std             0.0243326
exploration/Rewards Max             0.226634
exploration/Rewards Min             0.00138834
exploration/Returns Mean           28.9617
exploration/Returns Std             6.84166
exploration/Returns Max            40.6468
exploration/Returns Min            19.0099
exploration/Actions Mean           -0.176543
exploration/Actions Std             0.657865
exploration/Actions Max             0.999413
exploration/Actions Min            -0.999494
exploration/Num Paths              10
exploration/Average Returns        28.9617
evaluation/num steps total     325000
evaluation/num paths total        650
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0741355
evaluation/Rewards Std              0.0215004
evaluation/Rewards Max              0.229619
evaluation/Rewards Min              0.00151315
evaluation/Returns Mean            37.0677
evaluation/Returns Std              5.55474
evaluation/Returns Max             47.9051
evaluation/Returns Min             29.0067
evaluation/ExplReturns Mean        37.0677
evaluation/ExplReturns Std          5.55474
evaluation/ExplReturns Max         47.9051
evaluation/ExplReturns Min         29.0067
evaluation/Actions Mean            -0.0484979
evaluation/Actions Std              0.607689
evaluation/Actions Max              0.994288
evaluation/Actions Min             -0.997701
evaluation/Num Paths               10
evaluation/Average Returns         37.0677
time/data storing (s)               0.0309088
time/evaluation sampling (s)       75.0306
time/exploration sampling (s)      79.9299
time/logging (s)                    0.0253811
time/saving (s)                     0.0705511
time/training (s)                  10.6131
time/epoch (s)                    165.7
time/total (s)                  10148.2
Epoch                              64
-----------------------------  ----------------
2023-08-31 14:42:15.991878 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 65 finished
-----------------------------  ----------------
replay_buffer/size             331000
trainer/QF1 Loss                    0.000887744
trainer/QF2 Loss                    0.000954613
trainer/Policy Loss                 1.98277
trainer/Q1 Predictions Mean         4.69441
trainer/Q1 Predictions Std          0.577351
trainer/Q1 Predictions Max          6.28366
trainer/Q1 Predictions Min          3.50285
trainer/Q2 Predictions Mean         4.70324
trainer/Q2 Predictions Std          0.577562
trainer/Q2 Predictions Max          6.31664
trainer/Q2 Predictions Min          3.48389
trainer/Q Targets Mean              4.70225
trainer/Q Targets Std               0.58036
trainer/Q Targets Max               6.35031
trainer/Q Targets Min               3.45034
trainer/Log Pis Mean                6.70528
trainer/Log Pis Std                 4.07301
trainer/Log Pis Max                19.7318
trainer/Log Pis Min                -4.29779
trainer/Policy mu Mean             -0.0566718
trainer/Policy mu Std               1.57813
trainer/Policy mu Max               3.02462
trainer/Policy mu Min              -3.96274
trainer/Policy log std Mean        -0.588156
trainer/Policy log std Std          0.147927
trainer/Policy log std Max         -0.106835
trainer/Policy log std Min         -1.11393
trainer/Alpha                       0.000538792
trainer/Alpha Loss                 -2.2181
exploration/num steps total    331000
exploration/num paths total       662
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0907717
exploration/Rewards Std             0.112268
exploration/Rewards Max             0.720328
exploration/Rewards Min             0.0015337
exploration/Returns Mean           45.3859
exploration/Returns Std            41.9327
exploration/Returns Max           154.818
exploration/Returns Min            13.6937
exploration/Actions Mean           -0.0755123
exploration/Actions Std             0.652982
exploration/Actions Max             0.998922
exploration/Actions Min            -0.998977
exploration/Num Paths              10
exploration/Average Returns        45.3859
evaluation/num steps total     330000
evaluation/num paths total        660
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0560025
evaluation/Rewards Std              0.0526686
evaluation/Rewards Max              0.234445
evaluation/Rewards Min              0.00117953
evaluation/Returns Mean            28.0012
evaluation/Returns Std             19.8142
evaluation/Returns Max             82.1622
evaluation/Returns Min              9.09467
evaluation/ExplReturns Mean        28.0012
evaluation/ExplReturns Std         19.8142
evaluation/ExplReturns Max         82.1622
evaluation/ExplReturns Min          9.09467
evaluation/Actions Mean             0.0907624
evaluation/Actions Std              0.634785
evaluation/Actions Max              0.996322
evaluation/Actions Min             -0.995766
evaluation/Num Paths               10
evaluation/Average Returns         28.0012
time/data storing (s)               0.0315775
time/evaluation sampling (s)       75.1537
time/exploration sampling (s)      79.4371
time/logging (s)                    0.0260337
time/saving (s)                     0.0767115
time/training (s)                  10.3606
time/epoch (s)                    165.086
time/total (s)                  10313.3
Epoch                              65
-----------------------------  ----------------
2023-08-31 14:45:03.841757 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 66 finished
-----------------------------  ----------------
replay_buffer/size             336000
trainer/QF1 Loss                    0.000946541
trainer/QF2 Loss                    0.000968361
trainer/Policy Loss                 2.87675
trainer/Q1 Predictions Mean         4.62043
trainer/Q1 Predictions Std          0.64014
trainer/Q1 Predictions Max          6.56487
trainer/Q1 Predictions Min          2.87923
trainer/Q2 Predictions Mean         4.61937
trainer/Q2 Predictions Std          0.639077
trainer/Q2 Predictions Max          6.56543
trainer/Q2 Predictions Min          2.90265
trainer/Q Targets Mean              4.62408
trainer/Q Targets Std               0.640828
trainer/Q Targets Max               6.67025
trainer/Q Targets Min               2.88959
trainer/Log Pis Mean                7.52255
trainer/Log Pis Std                 4.22783
trainer/Log Pis Max                19.7496
trainer/Log Pis Min                -6.08918
trainer/Policy mu Mean             -0.0746829
trainer/Policy mu Std               1.63048
trainer/Policy mu Max               3.33504
trainer/Policy mu Min              -3.51306
trainer/Policy log std Mean        -0.648304
trainer/Policy log std Std          0.158614
trainer/Policy log std Max         -0.138003
trainer/Policy log std Min         -1.16094
trainer/Alpha                       0.00056911
trainer/Alpha Loss                  3.90436
exploration/num steps total    336000
exploration/num paths total       672
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0594058
exploration/Rewards Std             0.0644877
exploration/Rewards Max             0.630788
exploration/Rewards Min             8.85006e-06
exploration/Returns Mean           29.7029
exploration/Returns Std            23.3178
exploration/Returns Max            92.8884
exploration/Returns Min             7.94634
exploration/Actions Mean            0.0117484
exploration/Actions Std             0.689995
exploration/Actions Max             0.999592
exploration/Actions Min            -0.99989
exploration/Num Paths              10
exploration/Average Returns        29.7029
evaluation/num steps total     335000
evaluation/num paths total        670
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0794896
evaluation/Rewards Std              0.0478701
evaluation/Rewards Max              0.232912
evaluation/Rewards Min              0.0015029
evaluation/Returns Mean            39.7448
evaluation/Returns Std             19.817
evaluation/Returns Max             96.8705
evaluation/Returns Min             24.9844
evaluation/ExplReturns Mean        39.7448
evaluation/ExplReturns Std         19.817
evaluation/ExplReturns Max         96.8705
evaluation/ExplReturns Min         24.9844
evaluation/Actions Mean            -0.0182114
evaluation/Actions Std              0.622797
evaluation/Actions Max              0.995171
evaluation/Actions Min             -0.995193
evaluation/Num Paths               10
evaluation/Average Returns         39.7448
time/data storing (s)               0.0313013
time/evaluation sampling (s)       75.7454
time/exploration sampling (s)      81.4289
time/logging (s)                    0.0257176
time/saving (s)                     0.0795643
time/training (s)                  10.5349
time/epoch (s)                    167.846
time/total (s)                  10481.1
Epoch                              66
-----------------------------  ----------------
2023-08-31 14:47:50.229459 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 67 finished
-----------------------------  ----------------
replay_buffer/size             341000
trainer/QF1 Loss                    0.0025793
trainer/QF2 Loss                    0.00243363
trainer/Policy Loss                 2.1239
trainer/Q1 Predictions Mean         4.60829
trainer/Q1 Predictions Std          0.748338
trainer/Q1 Predictions Max          7.8786
trainer/Q1 Predictions Min          2.83269
trainer/Q2 Predictions Mean         4.6071
trainer/Q2 Predictions Std          0.750626
trainer/Q2 Predictions Max          7.80336
trainer/Q2 Predictions Min          2.8463
trainer/Q Targets Mean              4.60118
trainer/Q Targets Std               0.752096
trainer/Q Targets Max               7.84771
trainer/Q Targets Min               2.85154
trainer/Log Pis Mean                6.75895
trainer/Log Pis Std                 4.20204
trainer/Log Pis Max                19.25
trainer/Log Pis Min                -4.98768
trainer/Policy mu Mean             -0.152577
trainer/Policy mu Std               1.55929
trainer/Policy mu Max               3.0965
trainer/Policy mu Min              -3.60806
trainer/Policy log std Mean        -0.636153
trainer/Policy log std Std          0.183525
trainer/Policy log std Max         -0.157917
trainer/Policy log std Min         -1.27968
trainer/Alpha                       0.000580233
trainer/Alpha Loss                 -1.79634
exploration/num steps total    341000
exploration/num paths total       682
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0617213
exploration/Rewards Std             0.041374
exploration/Rewards Max             0.222118
exploration/Rewards Min             0.000137961
exploration/Returns Mean           30.8606
exploration/Returns Std            15.1253
exploration/Returns Max            65.0953
exploration/Returns Min             9.72621
exploration/Actions Mean           -0.176782
exploration/Actions Std             0.634382
exploration/Actions Max             0.999502
exploration/Actions Min            -0.999659
exploration/Num Paths              10
exploration/Average Returns        30.8606
evaluation/num steps total     340000
evaluation/num paths total        680
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.064561
evaluation/Rewards Std              0.030889
evaluation/Rewards Max              0.237891
evaluation/Rewards Min              0.00125851
evaluation/Returns Mean            32.2805
evaluation/Returns Std              9.57307
evaluation/Returns Max             56.8494
evaluation/Returns Min             20.8977
evaluation/ExplReturns Mean        32.2805
evaluation/ExplReturns Std          9.57307
evaluation/ExplReturns Max         56.8494
evaluation/ExplReturns Min         20.8977
evaluation/Actions Mean            -0.116755
evaluation/Actions Std              0.620447
evaluation/Actions Max              0.997518
evaluation/Actions Min             -0.997298
evaluation/Num Paths               10
evaluation/Average Returns         32.2805
time/data storing (s)               0.0310209
time/evaluation sampling (s)       74.805
time/exploration sampling (s)      80.7293
time/logging (s)                    0.0256053
time/saving (s)                     0.064155
time/training (s)                  10.7287
time/epoch (s)                    166.384
time/total (s)                  10647.5
Epoch                              67
-----------------------------  ----------------
2023-08-31 14:50:35.596705 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 68 finished
-----------------------------  ----------------
replay_buffer/size             346000
trainer/QF1 Loss                    0.00133618
trainer/QF2 Loss                    0.00167336
trainer/Policy Loss                 2.91207
trainer/Q1 Predictions Mean         4.54662
trainer/Q1 Predictions Std          0.778119
trainer/Q1 Predictions Max          6.57542
trainer/Q1 Predictions Min          2.74868
trainer/Q2 Predictions Mean         4.56454
trainer/Q2 Predictions Std          0.776182
trainer/Q2 Predictions Max          6.59334
trainer/Q2 Predictions Min          2.86924
trainer/Q Targets Mean              4.5533
trainer/Q Targets Std               0.786096
trainer/Q Targets Max               6.61622
trainer/Q Targets Min               2.78342
trainer/Log Pis Mean                7.4974
trainer/Log Pis Std                 4.1168
trainer/Log Pis Max                20.1875
trainer/Log Pis Min                -3.91261
trainer/Policy mu Mean             -0.104902
trainer/Policy mu Std               1.57332
trainer/Policy mu Max               3.34642
trainer/Policy mu Min              -3.31915
trainer/Policy log std Mean        -0.710582
trainer/Policy log std Std          0.213458
trainer/Policy log std Max         -0.18602
trainer/Policy log std Min         -1.62603
trainer/Alpha                       0.000580963
trainer/Alpha Loss                  3.70615
exploration/num steps total    346000
exploration/num paths total       692
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.076686
exploration/Rewards Std             0.0543786
exploration/Rewards Max             0.241401
exploration/Rewards Min             0.00146333
exploration/Returns Mean           38.343
exploration/Returns Std            22.8489
exploration/Returns Max           104.437
exploration/Returns Min            18.4463
exploration/Actions Mean           -0.0758644
exploration/Actions Std             0.654377
exploration/Actions Max             0.999005
exploration/Actions Min            -0.999387
exploration/Num Paths              10
exploration/Average Returns        38.343
evaluation/num steps total     345000
evaluation/num paths total        690
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0552799
evaluation/Rewards Std              0.0330291
evaluation/Rewards Max              0.225888
evaluation/Rewards Min              0.00080383
evaluation/Returns Mean            27.6399
evaluation/Returns Std             12.134
evaluation/Returns Max             50.4696
evaluation/Returns Min              8.15345
evaluation/ExplReturns Mean        27.6399
evaluation/ExplReturns Std         12.134
evaluation/ExplReturns Max         50.4696
evaluation/ExplReturns Min          8.15345
evaluation/Actions Mean            -0.0929665
evaluation/Actions Std              0.66886
evaluation/Actions Max              0.992624
evaluation/Actions Min             -0.996953
evaluation/Num Paths               10
evaluation/Average Returns         27.6399
time/data storing (s)               0.03155
time/evaluation sampling (s)       73.6821
time/exploration sampling (s)      80.8326
time/logging (s)                    0.0259044
time/saving (s)                     0.067926
time/training (s)                  10.7237
time/epoch (s)                    165.364
time/total (s)                  10812.9
Epoch                              68
-----------------------------  ----------------
2023-08-31 14:53:25.702395 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 69 finished
-----------------------------  ----------------
replay_buffer/size             351000
trainer/QF1 Loss                    0.00155737
trainer/QF2 Loss                    0.00188706
trainer/Policy Loss                 2.34588
trainer/Q1 Predictions Mean         4.64718
trainer/Q1 Predictions Std          0.924207
trainer/Q1 Predictions Max         11.5978
trainer/Q1 Predictions Min          3.11344
trainer/Q2 Predictions Mean         4.63934
trainer/Q2 Predictions Std          0.919555
trainer/Q2 Predictions Max         11.5688
trainer/Q2 Predictions Min          3.11121
trainer/Q Targets Mean              4.64536
trainer/Q Targets Std               0.93002
trainer/Q Targets Max              11.7525
trainer/Q Targets Min               3.10813
trainer/Log Pis Mean                7.01868
trainer/Log Pis Std                 3.82449
trainer/Log Pis Max                18.0663
trainer/Log Pis Min                -1.80745
trainer/Policy mu Mean             -0.17019
trainer/Policy mu Std               1.52435
trainer/Policy mu Max               3.52477
trainer/Policy mu Min              -3.72409
trainer/Policy log std Mean        -0.73169
trainer/Policy log std Std          0.222517
trainer/Policy log std Max         -0.155344
trainer/Policy log std Min         -1.6081
trainer/Alpha                       0.000634551
trainer/Alpha Loss                  0.137565
exploration/num steps total    351000
exploration/num paths total       702
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0605008
exploration/Rewards Std             0.0248568
exploration/Rewards Max             0.239357
exploration/Rewards Min             0.00168245
exploration/Returns Mean           30.2504
exploration/Returns Std             5.00688
exploration/Returns Max            40.7889
exploration/Returns Min            24.5423
exploration/Actions Mean            0.0182439
exploration/Actions Std             0.657914
exploration/Actions Max             0.999467
exploration/Actions Min            -0.999173
exploration/Num Paths              10
exploration/Average Returns        30.2504
evaluation/num steps total     350000
evaluation/num paths total        700
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0635383
evaluation/Rewards Std              0.0286616
evaluation/Rewards Max              0.221746
evaluation/Rewards Min              0.00182435
evaluation/Returns Mean            31.7691
evaluation/Returns Std              8.9149
evaluation/Returns Max             45.018
evaluation/Returns Min             16.0794
evaluation/ExplReturns Mean        31.7691
evaluation/ExplReturns Std          8.9149
evaluation/ExplReturns Max         45.018
evaluation/ExplReturns Min         16.0794
evaluation/Actions Mean            -0.0545015
evaluation/Actions Std              0.610306
evaluation/Actions Max              0.993223
evaluation/Actions Min             -0.995109
evaluation/Num Paths               10
evaluation/Average Returns         31.7691
time/data storing (s)               0.0312948
time/evaluation sampling (s)       75.6654
time/exploration sampling (s)      81.6318
time/logging (s)                    0.0258204
time/saving (s)                     0.0755328
time/training (s)                  12.6719
time/epoch (s)                    170.102
time/total (s)                  10983
Epoch                              69
-----------------------------  ----------------
2023-08-31 14:56:17.619876 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size             356000
trainer/QF1 Loss                    0.00136389
trainer/QF2 Loss                    0.00142094
trainer/Policy Loss                 2.679
trainer/Q1 Predictions Mean         4.56066
trainer/Q1 Predictions Std          0.766748
trainer/Q1 Predictions Max          6.85907
trainer/Q1 Predictions Min          2.85553
trainer/Q2 Predictions Mean         4.55984
trainer/Q2 Predictions Std          0.772945
trainer/Q2 Predictions Max          6.86174
trainer/Q2 Predictions Min          2.78732
trainer/Q Targets Mean              4.56044
trainer/Q Targets Std               0.770509
trainer/Q Targets Max               6.86604
trainer/Q Targets Min               2.80519
trainer/Log Pis Mean                7.27977
trainer/Log Pis Std                 4.50791
trainer/Log Pis Max                21.9263
trainer/Log Pis Min                -3.97736
trainer/Policy mu Mean             -0.0664067
trainer/Policy mu Std               1.57959
trainer/Policy mu Max               4.48465
trainer/Policy mu Min              -3.39995
trainer/Policy log std Mean        -0.708545
trainer/Policy log std Std          0.22717
trainer/Policy log std Max         -0.0850141
trainer/Policy log std Min         -1.72226
trainer/Alpha                       0.000662717
trainer/Alpha Loss                  2.04771
exploration/num steps total    356000
exploration/num paths total       712
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0635179
exploration/Rewards Std             0.0375946
exploration/Rewards Max             0.239866
exploration/Rewards Min             1.95512e-05
exploration/Returns Mean           31.759
exploration/Returns Std            14.8149
exploration/Returns Max            50.036
exploration/Returns Min             3.10548
exploration/Actions Mean           -0.0896844
exploration/Actions Std             0.612626
exploration/Actions Max             0.999234
exploration/Actions Min            -0.999366
exploration/Num Paths              10
exploration/Average Returns        31.759
evaluation/num steps total     355000
evaluation/num paths total        710
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0611003
evaluation/Rewards Std              0.0395854
evaluation/Rewards Max              0.22225
evaluation/Rewards Min              3.08816e-07
evaluation/Returns Mean            30.5502
evaluation/Returns Std             11.3746
evaluation/Returns Max             44.4863
evaluation/Returns Min              8.44848
evaluation/ExplReturns Mean        30.5502
evaluation/ExplReturns Std         11.3746
evaluation/ExplReturns Max         44.4863
evaluation/ExplReturns Min          8.44848
evaluation/Actions Mean            -0.00258016
evaluation/Actions Std              0.571458
evaluation/Actions Max              0.995712
evaluation/Actions Min             -0.992197
evaluation/Num Paths               10
evaluation/Average Returns         30.5502
time/data storing (s)               0.0310269
time/evaluation sampling (s)       73.6769
time/exploration sampling (s)      81.0865
time/logging (s)                    0.0263818
time/saving (s)                     0.0759768
time/training (s)                  17.0174
time/epoch (s)                    171.914
time/total (s)                  11154.9
Epoch                              70
-----------------------------  ----------------
2023-08-31 14:59:04.534022 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 71 finished
-----------------------------  ----------------
replay_buffer/size             361000
trainer/QF1 Loss                    0.00228123
trainer/QF2 Loss                    0.00212371
trainer/Policy Loss                 2.05554
trainer/Q1 Predictions Mean         4.64155
trainer/Q1 Predictions Std          1.00386
trainer/Q1 Predictions Max         11.1699
trainer/Q1 Predictions Min          2.97092
trainer/Q2 Predictions Mean         4.64942
trainer/Q2 Predictions Std          1.00758
trainer/Q2 Predictions Max         11.1336
trainer/Q2 Predictions Min          3.0038
trainer/Q Targets Mean              4.64918
trainer/Q Targets Std               1.00896
trainer/Q Targets Max              11.1503
trainer/Q Targets Min               3.00131
trainer/Log Pis Mean                6.73568
trainer/Log Pis Std                 4.02864
trainer/Log Pis Max                18.2596
trainer/Log Pis Min                -2.1758
trainer/Policy mu Mean             -0.0588784
trainer/Policy mu Std               1.54358
trainer/Policy mu Max               4.53274
trainer/Policy mu Min              -3.89771
trainer/Policy log std Mean        -0.719056
trainer/Policy log std Std          0.233134
trainer/Policy log std Max         -0.112433
trainer/Policy log std Min         -1.70911
trainer/Alpha                       0.00071332
trainer/Alpha Loss                 -1.91516
exploration/num steps total    361000
exploration/num paths total       722
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0869262
exploration/Rewards Std             0.146805
exploration/Rewards Max             0.682153
exploration/Rewards Min             1.00834e-08
exploration/Returns Mean           43.4631
exploration/Returns Std            62.014
exploration/Returns Max           227.353
exploration/Returns Min             9.67279
exploration/Actions Mean            0.038631
exploration/Actions Std             0.631183
exploration/Actions Max             0.999777
exploration/Actions Min            -0.999932
exploration/Num Paths              10
exploration/Average Returns        43.4631
evaluation/num steps total     360000
evaluation/num paths total        720
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0560957
evaluation/Rewards Std              0.0320536
evaluation/Rewards Max              0.231431
evaluation/Rewards Min              0.00124007
evaluation/Returns Mean            28.0479
evaluation/Returns Std              9.17442
evaluation/Returns Max             46.7527
evaluation/Returns Min              8.52053
evaluation/ExplReturns Mean        28.0479
evaluation/ExplReturns Std          9.17442
evaluation/ExplReturns Max         46.7527
evaluation/ExplReturns Min          8.52053
evaluation/Actions Mean            -0.0706201
evaluation/Actions Std              0.583652
evaluation/Actions Max              0.990233
evaluation/Actions Min             -0.994681
evaluation/Num Paths               10
evaluation/Average Returns         28.0479
time/data storing (s)               0.0312235
time/evaluation sampling (s)       73.8959
time/exploration sampling (s)      81.2918
time/logging (s)                    0.0257045
time/saving (s)                     0.0737742
time/training (s)                  11.5911
time/epoch (s)                    166.91
time/total (s)                  11321.8
Epoch                              71
-----------------------------  ----------------
2023-08-31 15:01:48.680208 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 72 finished
-----------------------------  ----------------
replay_buffer/size             366000
trainer/QF1 Loss                    0.00265566
trainer/QF2 Loss                    0.00250975
trainer/Policy Loss                 2.17967
trainer/Q1 Predictions Mean         4.64202
trainer/Q1 Predictions Std          1.02855
trainer/Q1 Predictions Max         11.8183
trainer/Q1 Predictions Min          2.59573
trainer/Q2 Predictions Mean         4.6503
trainer/Q2 Predictions Std          1.0262
trainer/Q2 Predictions Max         11.7124
trainer/Q2 Predictions Min          2.61314
trainer/Q Targets Mean              4.6315
trainer/Q Targets Std               1.02026
trainer/Q Targets Max              11.5918
trainer/Q Targets Min               2.58233
trainer/Log Pis Mean                6.86261
trainer/Log Pis Std                 4.32534
trainer/Log Pis Max                22.0218
trainer/Log Pis Min                -5.31442
trainer/Policy mu Mean             -0.124206
trainer/Policy mu Std               1.58104
trainer/Policy mu Max               5.11755
trainer/Policy mu Min              -4.21764
trainer/Policy log std Mean        -0.677833
trainer/Policy log std Std          0.229523
trainer/Policy log std Max         -0.114574
trainer/Policy log std Min         -1.56541
trainer/Alpha                       0.000786916
trainer/Alpha Loss                 -0.981991
exploration/num steps total    366000
exploration/num paths total       732
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0921001
exploration/Rewards Std             0.14753
exploration/Rewards Max             0.749317
exploration/Rewards Min             6.30945e-11
exploration/Returns Mean           46.0501
exploration/Returns Std            55.3367
exploration/Returns Max           210.269
exploration/Returns Min            10.9522
exploration/Actions Mean            0.0572113
exploration/Actions Std             0.636363
exploration/Actions Max             0.999996
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns        46.0501
evaluation/num steps total     365000
evaluation/num paths total        730
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0642749
evaluation/Rewards Std              0.0283786
evaluation/Rewards Max              0.223366
evaluation/Rewards Min              0.00192458
evaluation/Returns Mean            32.1375
evaluation/Returns Std             10.484
evaluation/Returns Max             44.6198
evaluation/Returns Min              6.55973
evaluation/ExplReturns Mean        32.1375
evaluation/ExplReturns Std         10.484
evaluation/ExplReturns Max         44.6198
evaluation/ExplReturns Min          6.55973
evaluation/Actions Mean             0.0715421
evaluation/Actions Std              0.662
evaluation/Actions Max              0.99841
evaluation/Actions Min             -0.993829
evaluation/Num Paths               10
evaluation/Average Returns         32.1375
time/data storing (s)               0.0311154
time/evaluation sampling (s)       74.0293
time/exploration sampling (s)      80.054
time/logging (s)                    0.0254623
time/saving (s)                     0.0762679
time/training (s)                   9.92604
time/epoch (s)                    164.142
time/total (s)                  11485.9
Epoch                              72
-----------------------------  ----------------
2023-08-31 15:04:33.542686 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 73 finished
-----------------------------  ----------------
replay_buffer/size             371000
trainer/QF1 Loss                    0.00278041
trainer/QF2 Loss                    0.00341475
trainer/Policy Loss                 1.9245
trainer/Q1 Predictions Mean         4.65645
trainer/Q1 Predictions Std          1.32412
trainer/Q1 Predictions Max         16.1858
trainer/Q1 Predictions Min          2.4598
trainer/Q2 Predictions Mean         4.62871
trainer/Q2 Predictions Std          1.3149
trainer/Q2 Predictions Max         16.1159
trainer/Q2 Predictions Min          2.46856
trainer/Q Targets Mean              4.64786
trainer/Q Targets Std               1.31835
trainer/Q Targets Max              16.2189
trainer/Q Targets Min               2.46952
trainer/Log Pis Mean                6.6006
trainer/Log Pis Std                 3.9288
trainer/Log Pis Max                20.7526
trainer/Log Pis Min                -2.19805
trainer/Policy mu Mean             -0.154958
trainer/Policy mu Std               1.51268
trainer/Policy mu Max               4.02124
trainer/Policy mu Min              -3.99823
trainer/Policy log std Mean        -0.708469
trainer/Policy log std Std          0.228207
trainer/Policy log std Max         -0.202294
trainer/Policy log std Min         -1.71894
trainer/Alpha                       0.000827883
trainer/Alpha Loss                 -2.8343
exploration/num steps total    371000
exploration/num paths total       742
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0864657
exploration/Rewards Std             0.135895
exploration/Rewards Max             0.727436
exploration/Rewards Min             9.63118e-15
exploration/Returns Mean           43.2329
exploration/Returns Std            48.9562
exploration/Returns Max           184.527
exploration/Returns Min             4.03023
exploration/Actions Mean           -0.0748703
exploration/Actions Std             0.661256
exploration/Actions Max             0.99987
exploration/Actions Min            -0.999999
exploration/Num Paths              10
exploration/Average Returns        43.2329
evaluation/num steps total     370000
evaluation/num paths total        740
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0705715
evaluation/Rewards Std              0.0514079
evaluation/Rewards Max              0.22335
evaluation/Rewards Min              0.00163149
evaluation/Returns Mean            35.2858
evaluation/Returns Std             22.1341
evaluation/Returns Max             91.2771
evaluation/Returns Min              5.05799
evaluation/ExplReturns Mean        35.2858
evaluation/ExplReturns Std         22.1341
evaluation/ExplReturns Max         91.2771
evaluation/ExplReturns Min          5.05799
evaluation/Actions Mean            -0.0473251
evaluation/Actions Std              0.659187
evaluation/Actions Max              0.997299
evaluation/Actions Min             -0.994582
evaluation/Num Paths               10
evaluation/Average Returns         35.2858
time/data storing (s)               0.0313955
time/evaluation sampling (s)       73.3725
time/exploration sampling (s)      81.3914
time/logging (s)                    0.0258844
time/saving (s)                     0.0749511
time/training (s)                   9.96282
time/epoch (s)                    164.859
time/total (s)                  11650.8
Epoch                              73
-----------------------------  ----------------
2023-08-31 15:07:17.895943 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 74 finished
-----------------------------  ----------------
replay_buffer/size             376000
trainer/QF1 Loss                    0.00383606
trainer/QF2 Loss                    0.00344054
trainer/Policy Loss                 2.54058
trainer/Q1 Predictions Mean         4.70344
trainer/Q1 Predictions Std          1.2677
trainer/Q1 Predictions Max         15.5964
trainer/Q1 Predictions Min          2.08317
trainer/Q2 Predictions Mean         4.6859
trainer/Q2 Predictions Std          1.2589
trainer/Q2 Predictions Max         15.4302
trainer/Q2 Predictions Min          2.07719
trainer/Q Targets Mean              4.69492
trainer/Q Targets Std               1.27028
trainer/Q Targets Max              15.8005
trainer/Q Targets Min               2.10424
trainer/Log Pis Mean                7.27255
trainer/Log Pis Std                 4.24807
trainer/Log Pis Max                17.6594
trainer/Log Pis Min                -4.68074
trainer/Policy mu Mean             -0.196069
trainer/Policy mu Std               1.56308
trainer/Policy mu Max               3.68465
trainer/Policy mu Min              -4.46856
trainer/Policy log std Mean        -0.730605
trainer/Policy log std Std          0.247916
trainer/Policy log std Max         -0.0709693
trainer/Policy log std Min         -1.87778
trainer/Alpha                       0.000862902
trainer/Alpha Loss                  1.92294
exploration/num steps total    376000
exploration/num paths total       752
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0529366
exploration/Rewards Std             0.0637054
exploration/Rewards Max             0.730756
exploration/Rewards Min             6.93889e-17
exploration/Returns Mean           26.4683
exploration/Returns Std             8.34144
exploration/Returns Max            35.9834
exploration/Returns Min            12.837
exploration/Actions Mean           -0.0620668
exploration/Actions Std             0.636256
exploration/Actions Max             0.999999
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        26.4683
evaluation/num steps total     375000
evaluation/num paths total        750
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0560161
evaluation/Rewards Std              0.0751681
evaluation/Rewards Max              0.70592
evaluation/Rewards Min              0
evaluation/Returns Mean            28.008
evaluation/Returns Std             15.698
evaluation/Returns Max             61.1751
evaluation/Returns Min              7.30363
evaluation/ExplReturns Mean        28.008
evaluation/ExplReturns Std         15.698
evaluation/ExplReturns Max         61.1751
evaluation/ExplReturns Min          7.30363
evaluation/Actions Mean            -0.0694894
evaluation/Actions Std              0.622698
evaluation/Actions Max              0.999852
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns         28.008
time/data storing (s)               0.0311017
time/evaluation sampling (s)       72.1896
time/exploration sampling (s)      79.8936
time/logging (s)                    0.0255451
time/saving (s)                     0.0697882
time/training (s)                  12.1394
time/epoch (s)                    164.349
time/total (s)                  11815.1
Epoch                              74
-----------------------------  ----------------
2023-08-31 15:09:59.138539 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 75 finished
-----------------------------  ----------------
replay_buffer/size             381000
trainer/QF1 Loss                    0.00395848
trainer/QF2 Loss                    0.00323935
trainer/Policy Loss                 2.5706
trainer/Q1 Predictions Mean         4.65497
trainer/Q1 Predictions Std          1.19152
trainer/Q1 Predictions Max          8.4747
trainer/Q1 Predictions Min          1.19573
trainer/Q2 Predictions Mean         4.67952
trainer/Q2 Predictions Std          1.20969
trainer/Q2 Predictions Max          8.50926
trainer/Q2 Predictions Min          1.15048
trainer/Q Targets Mean              4.67501
trainer/Q Targets Std               1.21025
trainer/Q Targets Max               8.60324
trainer/Q Targets Min               1.21895
trainer/Log Pis Mean                7.27454
trainer/Log Pis Std                 4.08594
trainer/Log Pis Max                20.1001
trainer/Log Pis Min                -2.78153
trainer/Policy mu Mean             -0.109489
trainer/Policy mu Std               1.57977
trainer/Policy mu Max               3.37748
trainer/Policy mu Min              -4.20838
trainer/Policy log std Mean        -0.737245
trainer/Policy log std Std          0.257977
trainer/Policy log std Max          0.224755
trainer/Policy log std Min         -1.792
trainer/Alpha                       0.000923174
trainer/Alpha Loss                  1.91843
exploration/num steps total    381000
exploration/num paths total       762
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.049835
exploration/Rewards Std             0.0360738
exploration/Rewards Max             0.223359
exploration/Rewards Min             1.01125e-09
exploration/Returns Mean           24.9175
exploration/Returns Std            11.5944
exploration/Returns Max            40.3128
exploration/Returns Min             5.0537
exploration/Actions Mean           -0.0291478
exploration/Actions Std             0.666261
exploration/Actions Max             0.999277
exploration/Actions Min            -0.998837
exploration/Num Paths              10
exploration/Average Returns        24.9175
evaluation/num steps total     380000
evaluation/num paths total        760
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0646084
evaluation/Rewards Std              0.0584111
evaluation/Rewards Max              0.233779
evaluation/Rewards Min              5.84041e-12
evaluation/Returns Mean            32.3042
evaluation/Returns Std             24.3359
evaluation/Returns Max             96.4433
evaluation/Returns Min              6.43682
evaluation/ExplReturns Mean        32.3042
evaluation/ExplReturns Std         24.3359
evaluation/ExplReturns Max         96.4433
evaluation/ExplReturns Min          6.43682
evaluation/Actions Mean            -0.0534686
evaluation/Actions Std              0.627326
evaluation/Actions Max              0.999086
evaluation/Actions Min             -0.999942
evaluation/Num Paths               10
evaluation/Average Returns         32.3042
time/data storing (s)               0.030653
time/evaluation sampling (s)       72.5463
time/exploration sampling (s)      78.0282
time/logging (s)                    0.0256243
time/saving (s)                     0.0599568
time/training (s)                  10.548
time/epoch (s)                    161.239
time/total (s)                  11976.4
Epoch                              75
-----------------------------  ----------------
2023-08-31 15:12:42.127614 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 76 finished
-----------------------------  ----------------
replay_buffer/size             386000
trainer/QF1 Loss                    0.00693475
trainer/QF2 Loss                    0.00557518
trainer/Policy Loss                 2.05237
trainer/Q1 Predictions Mean         4.85781
trainer/Q1 Predictions Std          1.54663
trainer/Q1 Predictions Max         14.7367
trainer/Q1 Predictions Min          0.219626
trainer/Q2 Predictions Mean         4.87287
trainer/Q2 Predictions Std          1.55334
trainer/Q2 Predictions Max         14.7761
trainer/Q2 Predictions Min          0.204333
trainer/Q Targets Mean              4.90056
trainer/Q Targets Std               1.56494
trainer/Q Targets Max              15.2043
trainer/Q Targets Min               0.24173
trainer/Log Pis Mean                6.9637
trainer/Log Pis Std                 4.07869
trainer/Log Pis Max                19.4904
trainer/Log Pis Min                -6.38449
trainer/Policy mu Mean             -0.223924
trainer/Policy mu Std               1.52325
trainer/Policy mu Max               3.87598
trainer/Policy mu Min              -3.47391
trainer/Policy log std Mean        -0.734178
trainer/Policy log std Std          0.257441
trainer/Policy log std Max          0.112295
trainer/Policy log std Min         -1.80249
trainer/Alpha                       0.000977391
trainer/Alpha Loss                 -0.251577
exploration/num steps total    386000
exploration/num paths total       772
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0472092
exploration/Rewards Std             0.0399448
exploration/Rewards Max             0.23618
exploration/Rewards Min             0.000246865
exploration/Returns Mean           23.6046
exploration/Returns Std            15.5849
exploration/Returns Max            49.5697
exploration/Returns Min             5.06361
exploration/Actions Mean            0.00755192
exploration/Actions Std             0.670416
exploration/Actions Max             0.999039
exploration/Actions Min            -0.999883
exploration/Num Paths              10
exploration/Average Returns        23.6046
evaluation/num steps total     385000
evaluation/num paths total        770
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.057456
evaluation/Rewards Std              0.0267189
evaluation/Rewards Max              0.229985
evaluation/Rewards Min              9.46272e-05
evaluation/Returns Mean            28.728
evaluation/Returns Std             10.4
evaluation/Returns Max             45.8392
evaluation/Returns Min              9.39969
evaluation/ExplReturns Mean        28.728
evaluation/ExplReturns Std         10.4
evaluation/ExplReturns Max         45.8392
evaluation/ExplReturns Min          9.39969
evaluation/Actions Mean            -0.0890233
evaluation/Actions Std              0.620898
evaluation/Actions Max              0.997755
evaluation/Actions Min             -0.998778
evaluation/Num Paths               10
evaluation/Average Returns         28.728
time/data storing (s)               0.0314911
time/evaluation sampling (s)       73.3079
time/exploration sampling (s)      79.2444
time/logging (s)                    0.0257774
time/saving (s)                     0.0721947
time/training (s)                  10.3036
time/epoch (s)                    162.985
time/total (s)                  12139.4
Epoch                              76
-----------------------------  ----------------
2023-08-31 15:15:24.588454 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 77 finished
-----------------------------  ----------------
replay_buffer/size             391000
trainer/QF1 Loss                    0.00570797
trainer/QF2 Loss                    0.00576578
trainer/Policy Loss                 2.50441
trainer/Q1 Predictions Mean         4.80991
trainer/Q1 Predictions Std          1.95543
trainer/Q1 Predictions Max         22.5149
trainer/Q1 Predictions Min          0.470666
trainer/Q2 Predictions Mean         4.79858
trainer/Q2 Predictions Std          1.95574
trainer/Q2 Predictions Max         22.619
trainer/Q2 Predictions Min          0.496398
trainer/Q Targets Mean              4.81457
trainer/Q Targets Std               1.97427
trainer/Q Targets Max              22.6073
trainer/Q Targets Min               0.451465
trainer/Log Pis Mean                7.34458
trainer/Log Pis Std                 4.53113
trainer/Log Pis Max                27.0104
trainer/Log Pis Min                -5.64035
trainer/Policy mu Mean             -0.319834
trainer/Policy mu Std               1.56608
trainer/Policy mu Max               3.80652
trainer/Policy mu Min              -4.22114
trainer/Policy log std Mean        -0.730318
trainer/Policy log std Std          0.260829
trainer/Policy log std Max         -0.0396325
trainer/Policy log std Min         -1.90227
trainer/Alpha                       0.000997254
trainer/Alpha Loss                  2.38131
exploration/num steps total    391000
exploration/num paths total       782
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0594845
exploration/Rewards Std             0.0669458
exploration/Rewards Max             0.710142
exploration/Rewards Min             1.31081e-08
exploration/Returns Mean           29.7423
exploration/Returns Std            13.8104
exploration/Returns Max            59.1954
exploration/Returns Min             3.89711
exploration/Actions Mean           -0.0543482
exploration/Actions Std             0.641315
exploration/Actions Max             0.999901
exploration/Actions Min            -0.999762
exploration/Num Paths              10
exploration/Average Returns        29.7423
evaluation/num steps total     390000
evaluation/num paths total        780
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0761448
evaluation/Rewards Std              0.0568563
evaluation/Rewards Max              0.237638
evaluation/Rewards Min              0.00104724
evaluation/Returns Mean            38.0724
evaluation/Returns Std             25.2365
evaluation/Returns Max            106.142
evaluation/Returns Min             14.2687
evaluation/ExplReturns Mean        38.0724
evaluation/ExplReturns Std         25.2365
evaluation/ExplReturns Max        106.142
evaluation/ExplReturns Min         14.2687
evaluation/Actions Mean            -0.0321458
evaluation/Actions Std              0.573101
evaluation/Actions Max              0.994957
evaluation/Actions Min             -0.998682
evaluation/Num Paths               10
evaluation/Average Returns         38.0724
time/data storing (s)               0.0313958
time/evaluation sampling (s)       73.5475
time/exploration sampling (s)      78.492
time/logging (s)                    0.0255941
time/saving (s)                     0.0691202
time/training (s)                  10.2911
time/epoch (s)                    162.457
time/total (s)                  12301.8
Epoch                              77
-----------------------------  ----------------
2023-08-31 15:18:08.104176 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size             396000
trainer/QF1 Loss                    0.00715346
trainer/QF2 Loss                    0.00734703
trainer/Policy Loss                 1.70643
trainer/Q1 Predictions Mean         5.09531
trainer/Q1 Predictions Std          1.99284
trainer/Q1 Predictions Max         24.4562
trainer/Q1 Predictions Min          1.51833
trainer/Q2 Predictions Mean         5.08823
trainer/Q2 Predictions Std          1.99013
trainer/Q2 Predictions Max         24.3207
trainer/Q2 Predictions Min          1.5158
trainer/Q Targets Mean              5.07205
trainer/Q Targets Std               2.00504
trainer/Q Targets Max              24.6068
trainer/Q Targets Min               1.53457
trainer/Log Pis Mean                6.84338
trainer/Log Pis Std                 4.46359
trainer/Log Pis Max                22.4406
trainer/Log Pis Min                -4.18925
trainer/Policy mu Mean             -0.180685
trainer/Policy mu Std               1.57477
trainer/Policy mu Max               4.09989
trainer/Policy mu Min              -4.35337
trainer/Policy log std Mean        -0.738231
trainer/Policy log std Std          0.266904
trainer/Policy log std Max          0.0418982
trainer/Policy log std Min         -1.84406
trainer/Alpha                       0.00104979
trainer/Alpha Loss                 -1.07429
exploration/num steps total    396000
exploration/num paths total       792
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0899409
exploration/Rewards Std             0.130122
exploration/Rewards Max             0.716378
exploration/Rewards Min             0
exploration/Returns Mean           44.9704
exploration/Returns Std            40.2122
exploration/Returns Max           161.081
exploration/Returns Min            12.3983
exploration/Actions Mean           -0.0328126
exploration/Actions Std             0.660865
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999961
exploration/Num Paths              10
exploration/Average Returns        44.9704
evaluation/num steps total     395000
evaluation/num paths total        790
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0888968
evaluation/Rewards Std              0.14135
evaluation/Rewards Max              0.711846
evaluation/Rewards Min              0
evaluation/Returns Mean            44.4484
evaluation/Returns Std             53.604
evaluation/Returns Max            201.746
evaluation/Returns Min              4.74607
evaluation/ExplReturns Mean        44.4484
evaluation/ExplReturns Std         53.604
evaluation/ExplReturns Max        201.746
evaluation/ExplReturns Min          4.74607
evaluation/Actions Mean            -0.0595539
evaluation/Actions Std              0.608888
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns         44.4484
time/data storing (s)               0.0307905
time/evaluation sampling (s)       73.5978
time/exploration sampling (s)      79.2384
time/logging (s)                    0.0255688
time/saving (s)                     0.0600678
time/training (s)                  10.5592
time/epoch (s)                    163.512
time/total (s)                  12465.3
Epoch                              78
-----------------------------  ---------------
2023-08-31 15:20:56.533694 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 79 finished
-----------------------------  ----------------
replay_buffer/size             401000
trainer/QF1 Loss                    0.00517164
trainer/QF2 Loss                    0.00504228
trainer/Policy Loss                 1.3545
trainer/Q1 Predictions Mean         5.23552
trainer/Q1 Predictions Std          1.7789
trainer/Q1 Predictions Max         22.0924
trainer/Q1 Predictions Min         -0.108805
trainer/Q2 Predictions Mean         5.24393
trainer/Q2 Predictions Std          1.78709
trainer/Q2 Predictions Max         22.1364
trainer/Q2 Predictions Min         -0.0714003
trainer/Q Targets Mean              5.21425
trainer/Q Targets Std               1.78341
trainer/Q Targets Max              22.1745
trainer/Q Targets Min              -0.0697726
trainer/Log Pis Mean                6.64513
trainer/Log Pis Std                 3.89597
trainer/Log Pis Max                20.7477
trainer/Log Pis Min                -3.1769
trainer/Policy mu Mean             -0.231595
trainer/Policy mu Std               1.50824
trainer/Policy mu Max               4.00238
trainer/Policy mu Min              -3.80543
trainer/Policy log std Mean        -0.727199
trainer/Policy log std Std          0.266037
trainer/Policy log std Max         -0.0344832
trainer/Policy log std Min         -1.91239
trainer/Alpha                       0.00112892
trainer/Alpha Loss                 -2.40829
exploration/num steps total    401000
exploration/num paths total       802
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0677292
exploration/Rewards Std             0.047882
exploration/Rewards Max             0.720125
exploration/Rewards Min             0.000614941
exploration/Returns Mean           33.8646
exploration/Returns Std            18.5902
exploration/Returns Max            58.687
exploration/Returns Min             3.8377
exploration/Actions Mean            0.0379902
exploration/Actions Std             0.618991
exploration/Actions Max             0.999962
exploration/Actions Min            -0.999587
exploration/Num Paths              10
exploration/Average Returns        33.8646
evaluation/num steps total     400000
evaluation/num paths total        800
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.23625
evaluation/Rewards Std              0.231812
evaluation/Rewards Max              0.717454
evaluation/Rewards Min              3.7478e-06
evaluation/Returns Mean           118.125
evaluation/Returns Std            102.658
evaluation/Returns Max            304.23
evaluation/Returns Min             22.9578
evaluation/ExplReturns Mean       118.125
evaluation/ExplReturns Std        102.658
evaluation/ExplReturns Max        304.23
evaluation/ExplReturns Min         22.9578
evaluation/Actions Mean            -0.0276531
evaluation/Actions Std              0.602876
evaluation/Actions Max              0.999939
evaluation/Actions Min             -0.994603
evaluation/Num Paths               10
evaluation/Average Returns        118.125
time/data storing (s)               0.0314689
time/evaluation sampling (s)       75.2604
time/exploration sampling (s)      80.0254
time/logging (s)                    0.0260011
time/saving (s)                     0.0764917
time/training (s)                  13.0062
time/epoch (s)                    168.426
time/total (s)                  12633.8
Epoch                              79
-----------------------------  ----------------
2023-08-31 15:23:42.002897 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 80 finished
-----------------------------  ----------------
replay_buffer/size             406000
trainer/QF1 Loss                    0.00880448
trainer/QF2 Loss                    0.00522495
trainer/Policy Loss                 2.44515
trainer/Q1 Predictions Mean         5.32471
trainer/Q1 Predictions Std          2.68437
trainer/Q1 Predictions Max         33.473
trainer/Q1 Predictions Min          2.48288
trainer/Q2 Predictions Mean         5.30449
trainer/Q2 Predictions Std          2.66084
trainer/Q2 Predictions Max         33.3287
trainer/Q2 Predictions Min          2.40479
trainer/Q Targets Mean              5.29559
trainer/Q Targets Std               2.64028
trainer/Q Targets Max              33.0656
trainer/Q Targets Min               2.46886
trainer/Log Pis Mean                7.79888
trainer/Log Pis Std                 4.249
trainer/Log Pis Max                22.2711
trainer/Log Pis Min                -3.52998
trainer/Policy mu Mean             -0.301685
trainer/Policy mu Std               1.60255
trainer/Policy mu Max               4.75637
trainer/Policy mu Min              -4.43705
trainer/Policy log std Mean        -0.725585
trainer/Policy log std Std          0.24549
trainer/Policy log std Max         -0.0223126
trainer/Policy log std Min         -1.79337
trainer/Alpha                       0.00112182
trainer/Alpha Loss                  5.42676
exploration/num steps total    406000
exploration/num paths total       812
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.166064
exploration/Rewards Std             0.223816
exploration/Rewards Max             0.743679
exploration/Rewards Min             4.89016e-08
exploration/Returns Mean           83.032
exploration/Returns Std            92.1946
exploration/Returns Max           239.647
exploration/Returns Min             6.76925
exploration/Actions Mean            0.0420794
exploration/Actions Std             0.671552
exploration/Actions Max             1
exploration/Actions Min            -0.999805
exploration/Num Paths              10
exploration/Average Returns        83.032
evaluation/num steps total     405000
evaluation/num paths total        810
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.115116
evaluation/Rewards Std              0.167668
evaluation/Rewards Max              1
evaluation/Rewards Min              5.74737e-06
evaluation/Returns Mean            57.5579
evaluation/Returns Std             79.0298
evaluation/Returns Max            280.354
evaluation/Returns Min              2.6645
evaluation/ExplReturns Mean        57.5579
evaluation/ExplReturns Std         79.0298
evaluation/ExplReturns Max        280.354
evaluation/ExplReturns Min          2.6645
evaluation/Actions Mean             0.103773
evaluation/Actions Std              0.606567
evaluation/Actions Max              0.999983
evaluation/Actions Min             -0.999254
evaluation/Num Paths               10
evaluation/Average Returns         57.5579
time/data storing (s)               0.0311222
time/evaluation sampling (s)       73.6676
time/exploration sampling (s)      81.2286
time/logging (s)                    0.0256007
time/saving (s)                     0.0655852
time/training (s)                  10.4463
time/epoch (s)                    165.465
time/total (s)                  12799.2
Epoch                              80
-----------------------------  ----------------
2023-08-31 15:26:25.428191 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 81 finished
-----------------------------  ----------------
replay_buffer/size             411000
trainer/QF1 Loss                    0.00772004
trainer/QF2 Loss                    0.00786638
trainer/Policy Loss                 2.02194
trainer/Q1 Predictions Mean         5.11361
trainer/Q1 Predictions Std          2.24114
trainer/Q1 Predictions Max         31.8862
trainer/Q1 Predictions Min          1.25844
trainer/Q2 Predictions Mean         5.09987
trainer/Q2 Predictions Std          2.24277
trainer/Q2 Predictions Max         31.9202
trainer/Q2 Predictions Min          1.28878
trainer/Q Targets Mean              5.13158
trainer/Q Targets Std               2.22243
trainer/Q Targets Max              31.3669
trainer/Q Targets Min               1.30596
trainer/Log Pis Mean                7.17626
trainer/Log Pis Std                 4.26754
trainer/Log Pis Max                25.6162
trainer/Log Pis Min                -5.18336
trainer/Policy mu Mean             -0.151185
trainer/Policy mu Std               1.5876
trainer/Policy mu Max               4.1479
trainer/Policy mu Min              -4.12772
trainer/Policy log std Mean        -0.688814
trainer/Policy log std Std          0.269751
trainer/Policy log std Max          0.0808166
trainer/Policy log std Min         -1.84215
trainer/Alpha                       0.00127248
trainer/Alpha Loss                  1.17514
exploration/num steps total    411000
exploration/num paths total       822
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0590366
exploration/Rewards Std             0.0394906
exploration/Rewards Max             1
exploration/Rewards Min             9.0112e-10
exploration/Returns Mean           29.5183
exploration/Returns Std            10.876
exploration/Returns Max            45.5858
exploration/Returns Min             9.1523
exploration/Actions Mean           -0.0695181
exploration/Actions Std             0.633296
exploration/Actions Max             0.999939
exploration/Actions Min            -0.999723
exploration/Num Paths              10
exploration/Average Returns        29.5183
evaluation/num steps total     410000
evaluation/num paths total        820
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0767544
evaluation/Rewards Std              0.0712159
evaluation/Rewards Max              0.240719
evaluation/Rewards Min              8.22924e-05
evaluation/Returns Mean            38.3772
evaluation/Returns Std             30.4991
evaluation/Returns Max            115.005
evaluation/Returns Min              6.51434
evaluation/ExplReturns Mean        38.3772
evaluation/ExplReturns Std         30.4991
evaluation/ExplReturns Max        115.005
evaluation/ExplReturns Min          6.51434
evaluation/Actions Mean            -0.0700589
evaluation/Actions Std              0.555905
evaluation/Actions Max              0.998947
evaluation/Actions Min             -0.998244
evaluation/Num Paths               10
evaluation/Average Returns         38.3772
time/data storing (s)               0.0311894
time/evaluation sampling (s)       72.9387
time/exploration sampling (s)      79.7779
time/logging (s)                    0.0257496
time/saving (s)                     0.072113
time/training (s)                  10.5758
time/epoch (s)                    163.422
time/total (s)                  12962.7
Epoch                              81
-----------------------------  ----------------
2023-08-31 15:29:05.000596 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 82 finished
-----------------------------  ----------------
replay_buffer/size             416000
trainer/QF1 Loss                    0.00612222
trainer/QF2 Loss                    0.00509277
trainer/Policy Loss                 1.77379
trainer/Q1 Predictions Mean         5.15797
trainer/Q1 Predictions Std          2.04066
trainer/Q1 Predictions Max         28.7004
trainer/Q1 Predictions Min          0.468225
trainer/Q2 Predictions Mean         5.18451
trainer/Q2 Predictions Std          2.03965
trainer/Q2 Predictions Max         28.7151
trainer/Q2 Predictions Min          0.61019
trainer/Q Targets Mean              5.17915
trainer/Q Targets Std               2.04112
trainer/Q Targets Max              28.7523
trainer/Q Targets Min               0.648808
trainer/Log Pis Mean                6.9929
trainer/Log Pis Std                 4.00527
trainer/Log Pis Max                26.09
trainer/Log Pis Min                -3.13975
trainer/Policy mu Mean             -0.129246
trainer/Policy mu Std               1.55821
trainer/Policy mu Max               4.83357
trainer/Policy mu Min              -3.99038
trainer/Policy log std Mean        -0.694666
trainer/Policy log std Std          0.249637
trainer/Policy log std Max         -0.142778
trainer/Policy log std Min         -1.79436
trainer/Alpha                       0.00128662
trainer/Alpha Loss                 -0.0472721
exploration/num steps total    416000
exploration/num paths total       832
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0710065
exploration/Rewards Std             0.103094
exploration/Rewards Max             1
exploration/Rewards Min             6.99798e-08
exploration/Returns Mean           35.5032
exploration/Returns Std            31.809
exploration/Returns Max           122.132
exploration/Returns Min             1.56243
exploration/Actions Mean           -0.124986
exploration/Actions Std             0.609687
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        35.5032
evaluation/num steps total     415000
evaluation/num paths total        830
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0673388
evaluation/Rewards Std              0.0263147
evaluation/Rewards Max              0.224772
evaluation/Rewards Min              0.00163552
evaluation/Returns Mean            33.6694
evaluation/Returns Std             10.307
evaluation/Returns Max             49.0597
evaluation/Returns Min             12.0101
evaluation/ExplReturns Mean        33.6694
evaluation/ExplReturns Std         10.307
evaluation/ExplReturns Max         49.0597
evaluation/ExplReturns Min         12.0101
evaluation/Actions Mean            -0.11806
evaluation/Actions Std              0.573518
evaluation/Actions Max              0.997408
evaluation/Actions Min             -0.996519
evaluation/Num Paths               10
evaluation/Average Returns         33.6694
time/data storing (s)               0.0315997
time/evaluation sampling (s)       71.6873
time/exploration sampling (s)      77.6171
time/logging (s)                    0.0258277
time/saving (s)                     0.0611552
time/training (s)                  10.1454
time/epoch (s)                    159.568
time/total (s)                  13122.2
Epoch                              82
-----------------------------  ----------------
2023-08-31 15:31:50.907555 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 83 finished
-----------------------------  ----------------
replay_buffer/size             421000
trainer/QF1 Loss                    0.008998
trainer/QF2 Loss                    0.0102809
trainer/Policy Loss                 1.45244
trainer/Q1 Predictions Mean         5.27574
trainer/Q1 Predictions Std          2.2014
trainer/Q1 Predictions Max         23.9166
trainer/Q1 Predictions Min          1.12172
trainer/Q2 Predictions Mean         5.27029
trainer/Q2 Predictions Std          2.19188
trainer/Q2 Predictions Max         23.8985
trainer/Q2 Predictions Min          1.15376
trainer/Q Targets Mean              5.30115
trainer/Q Targets Std               2.21515
trainer/Q Targets Max              23.7878
trainer/Q Targets Min               1.14309
trainer/Log Pis Mean                6.77789
trainer/Log Pis Std                 4.62806
trainer/Log Pis Max                26.9811
trainer/Log Pis Min               -11.1152
trainer/Policy mu Mean             -0.0652977
trainer/Policy mu Std               1.56468
trainer/Policy mu Max               4.55261
trainer/Policy mu Min              -3.51491
trainer/Policy log std Mean        -0.671385
trainer/Policy log std Std          0.252572
trainer/Policy log std Max         -0.0368656
trainer/Policy log std Min         -1.81603
trainer/Alpha                       0.00131096
trainer/Alpha Loss                 -1.47406
exploration/num steps total    421000
exploration/num paths total       842
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0871174
exploration/Rewards Std             0.0451014
exploration/Rewards Max             0.240184
exploration/Rewards Min             0.00164257
exploration/Returns Mean           43.5587
exploration/Returns Std            16.1192
exploration/Returns Max            79.0497
exploration/Returns Min            20.6796
exploration/Actions Mean           -0.076374
exploration/Actions Std             0.604274
exploration/Actions Max             0.99963
exploration/Actions Min            -0.999146
exploration/Num Paths              10
exploration/Average Returns        43.5587
evaluation/num steps total     420000
evaluation/num paths total        840
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.141804
evaluation/Rewards Std              0.193977
evaluation/Rewards Max              0.698247
evaluation/Rewards Min              2.00043e-10
evaluation/Returns Mean            70.9021
evaluation/Returns Std             78.8181
evaluation/Returns Max            274.301
evaluation/Returns Min             14.8549
evaluation/ExplReturns Mean        70.9021
evaluation/ExplReturns Std         78.8181
evaluation/ExplReturns Max        274.301
evaluation/ExplReturns Min         14.8549
evaluation/Actions Mean             0.0781441
evaluation/Actions Std              0.642172
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.999355
evaluation/Num Paths               10
evaluation/Average Returns         70.9021
time/data storing (s)               0.0312642
time/evaluation sampling (s)       73.7151
time/exploration sampling (s)      81.9763
time/logging (s)                    0.0256376
time/saving (s)                     0.069658
time/training (s)                  10.0849
time/epoch (s)                    165.903
time/total (s)                  13288.1
Epoch                              83
-----------------------------  ----------------
2023-08-31 15:34:33.267125 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 84 finished
-----------------------------  ----------------
replay_buffer/size             426000
trainer/QF1 Loss                    0.00987265
trainer/QF2 Loss                    0.00910953
trainer/Policy Loss                 1.78086
trainer/Q1 Predictions Mean         5.71026
trainer/Q1 Predictions Std          3.05421
trainer/Q1 Predictions Max         34.836
trainer/Q1 Predictions Min          0.195283
trainer/Q2 Predictions Mean         5.73216
trainer/Q2 Predictions Std          3.05564
trainer/Q2 Predictions Max         34.8569
trainer/Q2 Predictions Min          0.277826
trainer/Q Targets Mean              5.70719
trainer/Q Targets Std               3.05437
trainer/Q Targets Max              34.6609
trainer/Q Targets Min               0.31922
trainer/Log Pis Mean                7.57398
trainer/Log Pis Std                 5.25618
trainer/Log Pis Max                27.1699
trainer/Log Pis Min                -6.41287
trainer/Policy mu Mean             -0.315454
trainer/Policy mu Std               1.60366
trainer/Policy mu Max               4.47137
trainer/Policy mu Min              -4.41143
trainer/Policy log std Mean        -0.674602
trainer/Policy log std Std          0.251572
trainer/Policy log std Max         -0.00609446
trainer/Policy log std Min         -1.79151
trainer/Alpha                       0.00145396
trainer/Alpha Loss                  3.7502
exploration/num steps total    426000
exploration/num paths total       852
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0515885
exploration/Rewards Std             0.0438799
exploration/Rewards Max             0.692482
exploration/Rewards Min             6.19786e-11
exploration/Returns Mean           25.7943
exploration/Returns Std            11.2679
exploration/Returns Max            43.9034
exploration/Returns Min             6.05094
exploration/Actions Mean           -0.15311
exploration/Actions Std             0.623599
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999954
exploration/Num Paths              10
exploration/Average Returns        25.7943
evaluation/num steps total     425000
evaluation/num paths total        850
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0768911
evaluation/Rewards Std              0.0851211
evaluation/Rewards Max              0.723044
evaluation/Rewards Min              0
evaluation/Returns Mean            38.4456
evaluation/Returns Std             13.3416
evaluation/Returns Max             66.9282
evaluation/Returns Min             17.9658
evaluation/ExplReturns Mean        38.4456
evaluation/ExplReturns Std         13.3416
evaluation/ExplReturns Max         66.9282
evaluation/ExplReturns Min         17.9658
evaluation/Actions Mean            -0.193821
evaluation/Actions Std              0.586494
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999989
evaluation/Num Paths               10
evaluation/Average Returns         38.4456
time/data storing (s)               0.030976
time/evaluation sampling (s)       71.1754
time/exploration sampling (s)      77.3561
time/logging (s)                    0.0255414
time/saving (s)                     0.0847337
time/training (s)                  13.6827
time/epoch (s)                    162.355
time/total (s)                  13450.5
Epoch                              84
-----------------------------  ----------------
2023-08-31 15:37:19.906630 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size             431000
trainer/QF1 Loss                    0.0125912
trainer/QF2 Loss                    0.0138237
trainer/Policy Loss                 1.83904
trainer/Q1 Predictions Mean         5.95491
trainer/Q1 Predictions Std          3.62189
trainer/Q1 Predictions Max         39.6013
trainer/Q1 Predictions Min          0.0888129
trainer/Q2 Predictions Mean         5.93452
trainer/Q2 Predictions Std          3.6304
trainer/Q2 Predictions Max         39.5127
trainer/Q2 Predictions Min          0.0565824
trainer/Q Targets Mean              5.94547
trainer/Q Targets Std               3.64708
trainer/Q Targets Max              39.8259
trainer/Q Targets Min               0.0324866
trainer/Log Pis Mean                7.8403
trainer/Log Pis Std                 4.90323
trainer/Log Pis Max                28.9049
trainer/Log Pis Min                -3.90807
trainer/Policy mu Mean             -0.442627
trainer/Policy mu Std               1.59884
trainer/Policy mu Max               4.0572
trainer/Policy mu Min              -5.44832
trainer/Policy log std Mean        -0.696427
trainer/Policy log std Std          0.255039
trainer/Policy log std Max         -0.0356261
trainer/Policy log std Min         -1.904
trainer/Alpha                       0.00145266
trainer/Alpha Loss                  5.49104
exploration/num steps total    431000
exploration/num paths total       862
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0528661
exploration/Rewards Std             0.0305024
exploration/Rewards Max             0.227168
exploration/Rewards Min             0.0018764
exploration/Returns Mean           26.433
exploration/Returns Std            12.5752
exploration/Returns Max            41.8363
exploration/Returns Min             5.97417
exploration/Actions Mean           -0.282342
exploration/Actions Std             0.608841
exploration/Actions Max             0.998785
exploration/Actions Min            -0.999943
exploration/Num Paths              10
exploration/Average Returns        26.433
evaluation/num steps total     430000
evaluation/num paths total        860
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0581588
evaluation/Rewards Std              0.0437268
evaluation/Rewards Max              0.234623
evaluation/Rewards Min              0.00141625
evaluation/Returns Mean            29.0794
evaluation/Returns Std             18.8216
evaluation/Returns Max             81.7791
evaluation/Returns Min              4.71176
evaluation/ExplReturns Mean        29.0794
evaluation/ExplReturns Std         18.8216
evaluation/ExplReturns Max         81.7791
evaluation/ExplReturns Min          4.71176
evaluation/Actions Mean            -0.241924
evaluation/Actions Std              0.568116
evaluation/Actions Max              0.995891
evaluation/Actions Min             -0.998873
evaluation/Num Paths               10
evaluation/Average Returns         29.0794
time/data storing (s)               0.0309993
time/evaluation sampling (s)       72.6951
time/exploration sampling (s)      78.7747
time/logging (s)                    0.0258456
time/saving (s)                     0.0677262
time/training (s)                  15.0415
time/epoch (s)                    166.636
time/total (s)                  13617.1
Epoch                              85
-----------------------------  ---------------
2023-08-31 15:40:01.099937 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 86 finished
-----------------------------  ----------------
replay_buffer/size             436000
trainer/QF1 Loss                    0.0119882
trainer/QF2 Loss                    0.00997138
trainer/Policy Loss                 1.37835
trainer/Q1 Predictions Mean         5.57139
trainer/Q1 Predictions Std          2.1737
trainer/Q1 Predictions Max         20.3892
trainer/Q1 Predictions Min          0.777965
trainer/Q2 Predictions Mean         5.55453
trainer/Q2 Predictions Std          2.16858
trainer/Q2 Predictions Max         20.3021
trainer/Q2 Predictions Min          0.830288
trainer/Q Targets Mean              5.53474
trainer/Q Targets Std               2.15554
trainer/Q Targets Max              19.9543
trainer/Q Targets Min               0.820559
trainer/Log Pis Mean                7.00546
trainer/Log Pis Std                 4.56695
trainer/Log Pis Max                24.9535
trainer/Log Pis Min                -3.898
trainer/Policy mu Mean             -0.150531
trainer/Policy mu Std               1.56104
trainer/Policy mu Max               4.99593
trainer/Policy mu Min              -4.30126
trainer/Policy log std Mean        -0.702987
trainer/Policy log std Std          0.258929
trainer/Policy log std Max          0.642979
trainer/Policy log std Min         -1.77932
trainer/Alpha                       0.00142806
trainer/Alpha Loss                  0.0357634
exploration/num steps total    436000
exploration/num paths total       872
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0765169
exploration/Rewards Std             0.104736
exploration/Rewards Max             0.737436
exploration/Rewards Min             0.000204991
exploration/Returns Mean           38.2584
exploration/Returns Std            30.1535
exploration/Returns Max           126.543
exploration/Returns Min            18.7396
exploration/Actions Mean           -0.125533
exploration/Actions Std             0.628473
exploration/Actions Max             0.999997
exploration/Actions Min            -0.99984
exploration/Num Paths              10
exploration/Average Returns        38.2584
evaluation/num steps total     435000
evaluation/num paths total        870
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.124809
evaluation/Rewards Std              0.170808
evaluation/Rewards Max              0.704606
evaluation/Rewards Min              0.000336172
evaluation/Returns Mean            62.4046
evaluation/Returns Std             77.2598
evaluation/Returns Max            277.254
evaluation/Returns Min             10.8988
evaluation/ExplReturns Mean        62.4046
evaluation/ExplReturns Std         77.2598
evaluation/ExplReturns Max        277.254
evaluation/ExplReturns Min         10.8988
evaluation/Actions Mean            -0.092604
evaluation/Actions Std              0.569245
evaluation/Actions Max              0.999991
evaluation/Actions Min             -0.998778
evaluation/Num Paths               10
evaluation/Average Returns         62.4046
time/data storing (s)               0.0316505
time/evaluation sampling (s)       72.5674
time/exploration sampling (s)      77.4593
time/logging (s)                    0.0259764
time/saving (s)                     0.071044
time/training (s)                  11.034
time/epoch (s)                    161.189
time/total (s)                  13778.3
Epoch                              86
-----------------------------  ----------------
2023-08-31 15:42:42.862192 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size             441000
trainer/QF1 Loss                    0.0869227
trainer/QF2 Loss                    0.0839252
trainer/Policy Loss                 1.18241
trainer/Q1 Predictions Mean         5.92479
trainer/Q1 Predictions Std          3.06585
trainer/Q1 Predictions Max         37.9359
trainer/Q1 Predictions Min          0.620937
trainer/Q2 Predictions Mean         5.92099
trainer/Q2 Predictions Std          3.05836
trainer/Q2 Predictions Max         37.943
trainer/Q2 Predictions Min          0.725785
trainer/Q Targets Mean              5.86978
trainer/Q Targets Std               2.96125
trainer/Q Targets Max              37.6958
trainer/Q Targets Min               0.652492
trainer/Log Pis Mean                7.1839
trainer/Log Pis Std                 5.42411
trainer/Log Pis Max                38.8524
trainer/Log Pis Min                -4.25279
trainer/Policy mu Mean             -0.153701
trainer/Policy mu Std               1.59921
trainer/Policy mu Max               5.60151
trainer/Policy mu Min              -5.5498
trainer/Policy log std Mean        -0.704327
trainer/Policy log std Std          0.272857
trainer/Policy log std Max          0.0602577
trainer/Policy log std Min         -2.18973
trainer/Alpha                       0.00143332
trainer/Alpha Loss                  1.20416
exploration/num steps total    441000
exploration/num paths total       882
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.105587
exploration/Rewards Std             0.168219
exploration/Rewards Max             0.739647
exploration/Rewards Min             0.00151949
exploration/Returns Mean           52.7933
exploration/Returns Std            79.7303
exploration/Returns Max           290.309
exploration/Returns Min             7.90903
exploration/Actions Mean           -0.11514
exploration/Actions Std             0.618864
exploration/Actions Max             0.999992
exploration/Actions Min            -0.99985
exploration/Num Paths              10
exploration/Average Returns        52.7933
evaluation/num steps total     440000
evaluation/num paths total        880
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0579037
evaluation/Rewards Std              0.0261087
evaluation/Rewards Max              0.216532
evaluation/Rewards Min              0.0015942
evaluation/Returns Mean            28.9519
evaluation/Returns Std              7.97208
evaluation/Returns Max             39.3462
evaluation/Returns Min             14.4691
evaluation/ExplReturns Mean        28.9519
evaluation/ExplReturns Std          7.97208
evaluation/ExplReturns Max         39.3462
evaluation/ExplReturns Min         14.4691
evaluation/Actions Mean            -0.0183694
evaluation/Actions Std              0.545026
evaluation/Actions Max              0.998849
evaluation/Actions Min             -0.99512
evaluation/Num Paths               10
evaluation/Average Returns         28.9519
time/data storing (s)               0.0315411
time/evaluation sampling (s)       71.7804
time/exploration sampling (s)      77.1324
time/logging (s)                    0.0256679
time/saving (s)                     0.0703415
time/training (s)                  12.7175
time/epoch (s)                    161.758
time/total (s)                  13940.1
Epoch                              87
-----------------------------  ---------------
2023-08-31 15:45:26.162771 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size             446000
trainer/QF1 Loss                    0.0151191
trainer/QF2 Loss                    0.012207
trainer/Policy Loss                 1.38813
trainer/Q1 Predictions Mean         5.64364
trainer/Q1 Predictions Std          2.91415
trainer/Q1 Predictions Max         40.2519
trainer/Q1 Predictions Min         -0.00737656
trainer/Q2 Predictions Mean         5.64635
trainer/Q2 Predictions Std          2.92059
trainer/Q2 Predictions Max         40.2754
trainer/Q2 Predictions Min          0.0246855
trainer/Q Targets Mean              5.62929
trainer/Q Targets Std               2.92537
trainer/Q Targets Max              40.024
trainer/Q Targets Min               0.0204729
trainer/Log Pis Mean                7.0902
trainer/Log Pis Std                 4.17084
trainer/Log Pis Max                24.0678
trainer/Log Pis Min                -4.01959
trainer/Policy mu Mean             -0.13075
trainer/Policy mu Std               1.56893
trainer/Policy mu Max               4.6009
trainer/Policy mu Min              -4.11496
trainer/Policy log std Mean        -0.694086
trainer/Policy log std Std          0.279629
trainer/Policy log std Max         -0.00352591
trainer/Policy log std Min         -1.90865
trainer/Alpha                       0.00150114
trainer/Alpha Loss                  0.586477
exploration/num steps total    446000
exploration/num paths total       892
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0527434
exploration/Rewards Std             0.0240925
exploration/Rewards Max             0.21741
exploration/Rewards Min             0.00130485
exploration/Returns Mean           26.3717
exploration/Returns Std             9.43542
exploration/Returns Max            39.1213
exploration/Returns Min            12.0863
exploration/Actions Mean           -0.089887
exploration/Actions Std             0.61123
exploration/Actions Max             0.999836
exploration/Actions Min            -0.99997
exploration/Num Paths              10
exploration/Average Returns        26.3717
evaluation/num steps total     445000
evaluation/num paths total        890
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0636649
evaluation/Rewards Std              0.017388
evaluation/Rewards Max              0.214366
evaluation/Rewards Min              0.00135784
evaluation/Returns Mean            31.8324
evaluation/Returns Std              6.77929
evaluation/Returns Max             44.6261
evaluation/Returns Min             20.2517
evaluation/ExplReturns Mean        31.8324
evaluation/ExplReturns Std          6.77929
evaluation/ExplReturns Max         44.6261
evaluation/ExplReturns Min         20.2517
evaluation/Actions Mean            -0.112234
evaluation/Actions Std              0.522273
evaluation/Actions Max              0.997915
evaluation/Actions Min             -0.99904
evaluation/Num Paths               10
evaluation/Average Returns         31.8324
time/data storing (s)               0.0313466
time/evaluation sampling (s)       74.1386
time/exploration sampling (s)      78.614
time/logging (s)                    0.0255951
time/saving (s)                     0.0708605
time/training (s)                  10.4161
time/epoch (s)                    163.296
time/total (s)                  14103.4
Epoch                              88
-----------------------------  ---------------
2023-08-31 15:48:09.991088 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size             451000
trainer/QF1 Loss                    0.0187297
trainer/QF2 Loss                    0.0193156
trainer/Policy Loss                 1.52922
trainer/Q1 Predictions Mean         5.87267
trainer/Q1 Predictions Std          3.27686
trainer/Q1 Predictions Max         41.4947
trainer/Q1 Predictions Min          0.957594
trainer/Q2 Predictions Mean         5.85625
trainer/Q2 Predictions Std          3.27586
trainer/Q2 Predictions Max         41.5796
trainer/Q2 Predictions Min          0.934311
trainer/Q Targets Mean              5.89171
trainer/Q Targets Std               3.27649
trainer/Q Targets Max              41.3664
trainer/Q Targets Min               0.978117
trainer/Log Pis Mean                7.44982
trainer/Log Pis Std                 5.10704
trainer/Log Pis Max                28.407
trainer/Log Pis Min                -3.45822
trainer/Policy mu Mean             -0.317312
trainer/Policy mu Std               1.60425
trainer/Policy mu Max               4.26431
trainer/Policy mu Min              -5.31468
trainer/Policy log std Mean        -0.701129
trainer/Policy log std Std          0.278833
trainer/Policy log std Max          0.0686262
trainer/Policy log std Min         -1.86798
trainer/Alpha                       0.00164044
trainer/Alpha Loss                  2.88459
exploration/num steps total    451000
exploration/num paths total       902
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0752338
exploration/Rewards Std             0.0939479
exploration/Rewards Max             0.719419
exploration/Rewards Min             1.12543e-06
exploration/Returns Mean           37.6169
exploration/Returns Std            19.1073
exploration/Returns Max            73.0852
exploration/Returns Min            13.8677
exploration/Actions Mean           -0.104072
exploration/Actions Std             0.61266
exploration/Actions Max             0.999991
exploration/Actions Min            -0.999983
exploration/Num Paths              10
exploration/Average Returns        37.6169
evaluation/num steps total     450000
evaluation/num paths total        900
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0742068
evaluation/Rewards Std              0.0804492
evaluation/Rewards Max              0.685878
evaluation/Rewards Min              7.78273e-05
evaluation/Returns Mean            37.1034
evaluation/Returns Std             16.232
evaluation/Returns Max             81.904
evaluation/Returns Min             21.1134
evaluation/ExplReturns Mean        37.1034
evaluation/ExplReturns Std         16.232
evaluation/ExplReturns Max         81.904
evaluation/ExplReturns Min         21.1134
evaluation/Actions Mean            -0.0863789
evaluation/Actions Std              0.568532
evaluation/Actions Max              0.999475
evaluation/Actions Min             -0.998583
evaluation/Num Paths               10
evaluation/Average Returns         37.1034
time/data storing (s)               0.0317772
time/evaluation sampling (s)       73.3373
time/exploration sampling (s)      80.1938
time/logging (s)                    0.0260094
time/saving (s)                     0.0740195
time/training (s)                  10.1618
time/epoch (s)                    163.825
time/total (s)                  14267.2
Epoch                              89
-----------------------------  ----------------
2023-08-31 15:50:50.333475 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 90 finished
-----------------------------  ----------------
replay_buffer/size             456000
trainer/QF1 Loss                    0.0185177
trainer/QF2 Loss                    0.0161199
trainer/Policy Loss                 0.68791
trainer/Q1 Predictions Mean         5.92464
trainer/Q1 Predictions Std          2.49539
trainer/Q1 Predictions Max         20.9574
trainer/Q1 Predictions Min          0.0206099
trainer/Q2 Predictions Mean         5.93539
trainer/Q2 Predictions Std          2.52053
trainer/Q2 Predictions Max         21.026
trainer/Q2 Predictions Min          0.117371
trainer/Q Targets Mean              5.94918
trainer/Q Targets Std               2.51709
trainer/Q Targets Max              21.1804
trainer/Q Targets Min               0.111716
trainer/Log Pis Mean                6.68615
trainer/Log Pis Std                 5.95016
trainer/Log Pis Max                47.2039
trainer/Log Pis Min                -4.18286
trainer/Policy mu Mean             -0.198145
trainer/Policy mu Std               1.539
trainer/Policy mu Max               7.56938
trainer/Policy mu Min              -5.3218
trainer/Policy log std Mean        -0.698916
trainer/Policy log std Std          0.272589
trainer/Policy log std Max          0.0869334
trainer/Policy log std Min         -2.00703
trainer/Alpha                       0.00165976
trainer/Alpha Loss                 -2.00903
exploration/num steps total    456000
exploration/num paths total       912
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0669349
exploration/Rewards Std             0.114081
exploration/Rewards Max             0.691664
exploration/Rewards Min             4.55053e-14
exploration/Returns Mean           33.4674
exploration/Returns Std            30.7472
exploration/Returns Max           122.092
exploration/Returns Min             4.92202
exploration/Actions Mean           -0.0514467
exploration/Actions Std             0.63056
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999985
exploration/Num Paths              10
exploration/Average Returns        33.4674
evaluation/num steps total     455000
evaluation/num paths total        910
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.038627
evaluation/Rewards Std              0.0220428
evaluation/Rewards Max              0.221848
evaluation/Rewards Min              0.00136014
evaluation/Returns Mean            19.3135
evaluation/Returns Std              8.37575
evaluation/Returns Max             36.2594
evaluation/Returns Min              7.79762
evaluation/ExplReturns Mean        19.3135
evaluation/ExplReturns Std          8.37575
evaluation/ExplReturns Max         36.2594
evaluation/ExplReturns Min          7.79762
evaluation/Actions Mean            -0.0328632
evaluation/Actions Std              0.57934
evaluation/Actions Max              0.998138
evaluation/Actions Min             -0.99798
evaluation/Num Paths               10
evaluation/Average Returns         19.3135
time/data storing (s)               0.0315008
time/evaluation sampling (s)       70.6983
time/exploration sampling (s)      79.2302
time/logging (s)                    0.0257071
time/saving (s)                     0.0754946
time/training (s)                  10.2769
time/epoch (s)                    160.338
time/total (s)                  14427.6
Epoch                              90
-----------------------------  ----------------
2023-08-31 15:53:30.769161 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 91 finished
-----------------------------  ----------------
replay_buffer/size             461000
trainer/QF1 Loss                    0.0236634
trainer/QF2 Loss                    0.0292264
trainer/Policy Loss                -0.119826
trainer/Q1 Predictions Mean         6.55298
trainer/Q1 Predictions Std          4.12659
trainer/Q1 Predictions Max         42.0132
trainer/Q1 Predictions Min          0.109352
trainer/Q2 Predictions Mean         6.5201
trainer/Q2 Predictions Std          4.13309
trainer/Q2 Predictions Max         42.5424
trainer/Q2 Predictions Min          0.022544
trainer/Q Targets Mean              6.51598
trainer/Q Targets Std               4.09311
trainer/Q Targets Max              41.7533
trainer/Q Targets Min               0.165258
trainer/Log Pis Mean                6.49904
trainer/Log Pis Std                 5.60321
trainer/Log Pis Max                33.0949
trainer/Log Pis Min                -6.72551
trainer/Policy mu Mean             -0.15657
trainer/Policy mu Std               1.5789
trainer/Policy mu Max               6.10276
trainer/Policy mu Min              -5.47695
trainer/Policy log std Mean        -0.686634
trainer/Policy log std Std          0.299362
trainer/Policy log std Max          0.133373
trainer/Policy log std Min         -2.35417
trainer/Alpha                       0.00186543
trainer/Alpha Loss                 -3.14816
exploration/num steps total    461000
exploration/num paths total       922
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0333577
exploration/Rewards Std             0.0285616
exploration/Rewards Max             0.730348
exploration/Rewards Min             0.000327722
exploration/Returns Mean           16.6789
exploration/Returns Std             6.74691
exploration/Returns Max            26.9296
exploration/Returns Min             4.88501
exploration/Actions Mean           -0.113077
exploration/Actions Std             0.625351
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        16.6789
evaluation/num steps total     460000
evaluation/num paths total        920
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0691596
evaluation/Rewards Std              0.116886
evaluation/Rewards Max              0.688205
evaluation/Rewards Min              2.87357e-07
evaluation/Returns Mean            34.5798
evaluation/Returns Std             33.0873
evaluation/Returns Max            130.303
evaluation/Returns Min             10.5038
evaluation/ExplReturns Mean        34.5798
evaluation/ExplReturns Std         33.0873
evaluation/ExplReturns Max        130.303
evaluation/ExplReturns Min         10.5038
evaluation/Actions Mean            -0.0586814
evaluation/Actions Std              0.573283
evaluation/Actions Max              1
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns         34.5798
time/data storing (s)               0.0309427
time/evaluation sampling (s)       72.8326
time/exploration sampling (s)      76.9861
time/logging (s)                    0.025468
time/saving (s)                     0.0719758
time/training (s)                  10.4845
time/epoch (s)                    160.431
time/total (s)                  14588
Epoch                              91
-----------------------------  ----------------
2023-08-31 15:56:13.636663 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 92 finished
-----------------------------  ----------------
replay_buffer/size             466000
trainer/QF1 Loss                    0.0187146
trainer/QF2 Loss                    0.0209689
trainer/Policy Loss                 0.0399405
trainer/Q1 Predictions Mean         6.56693
trainer/Q1 Predictions Std          6.23832
trainer/Q1 Predictions Max         58.3812
trainer/Q1 Predictions Min         -0.488736
trainer/Q2 Predictions Mean         6.59243
trainer/Q2 Predictions Std          6.22347
trainer/Q2 Predictions Max         58.0004
trainer/Q2 Predictions Min         -0.509726
trainer/Q Targets Mean              6.5798
trainer/Q Targets Std               6.24588
trainer/Q Targets Max              58.6397
trainer/Q Targets Min              -0.479711
trainer/Log Pis Mean                6.69149
trainer/Log Pis Std                 4.92431
trainer/Log Pis Max                23.6147
trainer/Log Pis Min                -7.335
trainer/Policy mu Mean             -0.196243
trainer/Policy mu Std               1.56288
trainer/Policy mu Max               3.57771
trainer/Policy mu Min              -3.94871
trainer/Policy log std Mean        -0.62781
trainer/Policy log std Std          0.292756
trainer/Policy log std Max          0.128038
trainer/Policy log std Min         -1.86586
trainer/Alpha                       0.00190552
trainer/Alpha Loss                 -1.93216
exploration/num steps total    466000
exploration/num paths total       932
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0438667
exploration/Rewards Std             0.0467557
exploration/Rewards Max             0.70344
exploration/Rewards Min             1.37014e-06
exploration/Returns Mean           21.9333
exploration/Returns Std             8.26692
exploration/Returns Max            31.3689
exploration/Returns Min             6.77646
exploration/Actions Mean           -0.131869
exploration/Actions Std             0.608496
exploration/Actions Max             0.999937
exploration/Actions Min            -0.999974
exploration/Num Paths              10
exploration/Average Returns        21.9333
evaluation/num steps total     465000
evaluation/num paths total        930
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0514607
evaluation/Rewards Std              0.0250274
evaluation/Rewards Max              0.227188
evaluation/Rewards Min              0.00119621
evaluation/Returns Mean            25.7304
evaluation/Returns Std             10.8783
evaluation/Returns Max             47.1914
evaluation/Returns Min              6.87347
evaluation/ExplReturns Mean        25.7304
evaluation/ExplReturns Std         10.8783
evaluation/ExplReturns Max         47.1914
evaluation/ExplReturns Min          6.87347
evaluation/Actions Mean            -0.104376
evaluation/Actions Std              0.599681
evaluation/Actions Max              0.998631
evaluation/Actions Min             -0.996416
evaluation/Num Paths               10
evaluation/Average Returns         25.7304
time/data storing (s)               0.0309349
time/evaluation sampling (s)       72.4571
time/exploration sampling (s)      76.3357
time/logging (s)                    0.0256033
time/saving (s)                     0.0700515
time/training (s)                  13.9443
time/epoch (s)                    162.864
time/total (s)                  14750.9
Epoch                              92
-----------------------------  ----------------
2023-08-31 15:58:55.112919 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 93 finished
-----------------------------  ----------------
replay_buffer/size             471000
trainer/QF1 Loss                    0.0454175
trainer/QF2 Loss                    0.0364724
trainer/Policy Loss                -0.761159
trainer/Q1 Predictions Mean         6.87717
trainer/Q1 Predictions Std          5.47323
trainer/Q1 Predictions Max         51.3417
trainer/Q1 Predictions Min         -0.0750524
trainer/Q2 Predictions Mean         6.88327
trainer/Q2 Predictions Std          5.46008
trainer/Q2 Predictions Max         51.3089
trainer/Q2 Predictions Min         -0.263996
trainer/Q Targets Mean              6.9183
trainer/Q Targets Std               5.43347
trainer/Q Targets Max              50.5386
trainer/Q Targets Min              -0.174526
trainer/Log Pis Mean                6.20092
trainer/Log Pis Std                 6.01017
trainer/Log Pis Max                37.6953
trainer/Log Pis Min                -4.16246
trainer/Policy mu Mean             -0.114148
trainer/Policy mu Std               1.53723
trainer/Policy mu Max               5.65074
trainer/Policy mu Min              -4.54145
trainer/Policy log std Mean        -0.664948
trainer/Policy log std Std          0.313118
trainer/Policy log std Max          0.0587361
trainer/Policy log std Min         -2.16722
trainer/Alpha                       0.00196737
trainer/Alpha Loss                 -4.97911
exploration/num steps total    471000
exploration/num paths total       942
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0411116
exploration/Rewards Std             0.0282725
exploration/Rewards Max             0.233613
exploration/Rewards Min             0.000201267
exploration/Returns Mean           20.5558
exploration/Returns Std             7.64508
exploration/Returns Max            32.909
exploration/Returns Min            10.724
exploration/Actions Mean           -0.101867
exploration/Actions Std             0.611423
exploration/Actions Max             0.999928
exploration/Actions Min            -0.999994
exploration/Num Paths              10
exploration/Average Returns        20.5558
evaluation/num steps total     470000
evaluation/num paths total        940
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0461528
evaluation/Rewards Std              0.0277632
evaluation/Rewards Max              0.212119
evaluation/Rewards Min              0.000234883
evaluation/Returns Mean            23.0764
evaluation/Returns Std             11.7167
evaluation/Returns Max             43.8325
evaluation/Returns Min              6.86517
evaluation/ExplReturns Mean        23.0764
evaluation/ExplReturns Std         11.7167
evaluation/ExplReturns Max         43.8325
evaluation/ExplReturns Min          6.86517
evaluation/Actions Mean             0.0162241
evaluation/Actions Std              0.586128
evaluation/Actions Max              1
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns         23.0764
time/data storing (s)               0.0309069
time/evaluation sampling (s)       72.2297
time/exploration sampling (s)      78.4353
time/logging (s)                    0.0256748
time/saving (s)                     0.0743548
time/training (s)                  10.6764
time/epoch (s)                    161.472
time/total (s)                  14912.3
Epoch                              93
-----------------------------  ----------------
2023-08-31 16:01:33.687845 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 94 finished
-----------------------------  ----------------
replay_buffer/size             476000
trainer/QF1 Loss                    0.0851362
trainer/QF2 Loss                    0.0786168
trainer/Policy Loss                -0.169577
trainer/Q1 Predictions Mean         7.10741
trainer/Q1 Predictions Std          5.03474
trainer/Q1 Predictions Max         53.7382
trainer/Q1 Predictions Min          0.360777
trainer/Q2 Predictions Mean         7.0955
trainer/Q2 Predictions Std          5.02153
trainer/Q2 Predictions Max         53.7038
trainer/Q2 Predictions Min          0.274798
trainer/Q Targets Mean              7.0283
trainer/Q Targets Std               5.03165
trainer/Q Targets Max              54.3826
trainer/Q Targets Min               0.277245
trainer/Log Pis Mean                7.03588
trainer/Log Pis Std                 8.6128
trainer/Log Pis Max                67.4955
trainer/Log Pis Min                -5.83821
trainer/Policy mu Mean             -0.0734027
trainer/Policy mu Std               1.69858
trainer/Policy mu Max               9.70175
trainer/Policy mu Min              -8.02205
trainer/Policy log std Mean        -0.6507
trainer/Policy log std Std          0.290698
trainer/Policy log std Max          0.076203
trainer/Policy log std Min         -2.03198
trainer/Alpha                       0.00222338
trainer/Alpha Loss                  0.219208
exploration/num steps total    476000
exploration/num paths total       952
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0184475
exploration/Rewards Std             0.0244274
exploration/Rewards Max             0.223643
exploration/Rewards Min             3.35654e-05
exploration/Returns Mean            9.22373
exploration/Returns Std             6.437
exploration/Returns Max            20.8518
exploration/Returns Min             1.11596
exploration/Actions Mean           -0.134568
exploration/Actions Std             0.602529
exploration/Actions Max             0.999998
exploration/Actions Min            -0.999933
exploration/Num Paths              10
exploration/Average Returns         9.22373
evaluation/num steps total     475000
evaluation/num paths total        950
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0160954
evaluation/Rewards Std              0.02042
evaluation/Rewards Max              0.218388
evaluation/Rewards Min              1.19227e-06
evaluation/Returns Mean             8.0477
evaluation/Returns Std              6.1374
evaluation/Returns Max             19.4671
evaluation/Returns Min              1.92587
evaluation/ExplReturns Mean         8.0477
evaluation/ExplReturns Std          6.1374
evaluation/ExplReturns Max         19.4671
evaluation/ExplReturns Min          1.92587
evaluation/Actions Mean            -0.0627089
evaluation/Actions Std              0.508136
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.999989
evaluation/Num Paths               10
evaluation/Average Returns          8.0477
time/data storing (s)               0.0311849
time/evaluation sampling (s)       69.5161
time/exploration sampling (s)      75.4014
time/logging (s)                    0.0256895
time/saving (s)                     0.0668053
time/training (s)                  13.5297
time/epoch (s)                    158.571
time/total (s)                  15070.9
Epoch                              94
-----------------------------  ----------------
2023-08-31 16:04:11.787815 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size             481000
trainer/QF1 Loss                    0.0651244
trainer/QF2 Loss                    0.0565422
trainer/Policy Loss                -0.841678
trainer/Q1 Predictions Mean         7.17793
trainer/Q1 Predictions Std          5.69139
trainer/Q1 Predictions Max         55.4804
trainer/Q1 Predictions Min          0.0558527
trainer/Q2 Predictions Mean         7.18864
trainer/Q2 Predictions Std          5.72056
trainer/Q2 Predictions Max         55.8488
trainer/Q2 Predictions Min          0.0637235
trainer/Q Targets Mean              7.22827
trainer/Q Targets Std               5.74049
trainer/Q Targets Max              55.6049
trainer/Q Targets Min               0.0677463
trainer/Log Pis Mean                6.42447
trainer/Log Pis Std                 5.52119
trainer/Log Pis Max                33.7963
trainer/Log Pis Min                -4.8769
trainer/Policy mu Mean             -0.0142948
trainer/Policy mu Std               1.60466
trainer/Policy mu Max               6.9495
trainer/Policy mu Min              -5.54337
trainer/Policy log std Mean        -0.621499
trainer/Policy log std Std          0.277968
trainer/Policy log std Max          0.149207
trainer/Policy log std Min         -1.81579
trainer/Alpha                       0.00221812
trainer/Alpha Loss                 -3.51698
exploration/num steps total    481000
exploration/num paths total       962
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0359881
exploration/Rewards Std             0.0656638
exploration/Rewards Max             0.690763
exploration/Rewards Min             3.8608e-14
exploration/Returns Mean           17.994
exploration/Returns Std            11.3982
exploration/Returns Max            34.4074
exploration/Returns Min             1.84763
exploration/Actions Mean           -0.219033
exploration/Actions Std             0.603599
exploration/Actions Max             1
exploration/Actions Min            -0.999996
exploration/Num Paths              10
exploration/Average Returns        17.994
evaluation/num steps total     480000
evaluation/num paths total        960
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0345618
evaluation/Rewards Std              0.0256058
evaluation/Rewards Max              0.217603
evaluation/Rewards Min              0.00128864
evaluation/Returns Mean            17.2809
evaluation/Returns Std              9.92074
evaluation/Returns Max             35.1377
evaluation/Returns Min              3.64714
evaluation/ExplReturns Mean        17.2809
evaluation/ExplReturns Std          9.92074
evaluation/ExplReturns Max         35.1377
evaluation/ExplReturns Min          3.64714
evaluation/Actions Mean            -0.0605839
evaluation/Actions Std              0.542779
evaluation/Actions Max              0.999474
evaluation/Actions Min             -0.999181
evaluation/Num Paths               10
evaluation/Average Returns         17.2809
time/data storing (s)               0.0309222
time/evaluation sampling (s)       70.5857
time/exploration sampling (s)      76.78
time/logging (s)                    0.0253453
time/saving (s)                     0.0703588
time/training (s)                  10.6034
time/epoch (s)                    158.096
time/total (s)                  15229
Epoch                              95
-----------------------------  ---------------
2023-08-31 16:06:52.879050 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size             486000
trainer/QF1 Loss                    0.0399367
trainer/QF2 Loss                    0.0308356
trainer/Policy Loss                -0.096119
trainer/Q1 Predictions Mean         7.63259
trainer/Q1 Predictions Std          5.76428
trainer/Q1 Predictions Max         52.105
trainer/Q1 Predictions Min          0.196259
trainer/Q2 Predictions Mean         7.65903
trainer/Q2 Predictions Std          5.77034
trainer/Q2 Predictions Max         52.0146
trainer/Q2 Predictions Min          0.284322
trainer/Q Targets Mean              7.63226
trainer/Q Targets Std               5.78146
trainer/Q Targets Max              52.1038
trainer/Q Targets Min               0.239955
trainer/Log Pis Mean                7.67894
trainer/Log Pis Std                 5.40512
trainer/Log Pis Max                25.3113
trainer/Log Pis Min                -4.59647
trainer/Policy mu Mean             -0.0623346
trainer/Policy mu Std               1.67706
trainer/Policy mu Max               5.12292
trainer/Policy mu Min              -4.21784
trainer/Policy log std Mean        -0.679015
trainer/Policy log std Std          0.331154
trainer/Policy log std Max          0.221421
trainer/Policy log std Min         -2.38161
trainer/Alpha                       0.00232149
trainer/Alpha Loss                  4.1182
exploration/num steps total    486000
exploration/num paths total       972
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0704801
exploration/Rewards Std             0.110151
exploration/Rewards Max             0.673458
exploration/Rewards Min             0.00125676
exploration/Returns Mean           35.24
exploration/Returns Std            45.3061
exploration/Returns Max           155.953
exploration/Returns Min             5.00642
exploration/Actions Mean           -0.0243781
exploration/Actions Std             0.627954
exploration/Actions Max             1
exploration/Actions Min            -0.9998
exploration/Num Paths              10
exploration/Average Returns        35.24
evaluation/num steps total     485000
evaluation/num paths total        970
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0390509
evaluation/Rewards Std              0.0255657
evaluation/Rewards Max              0.210449
evaluation/Rewards Min              0.00105767
evaluation/Returns Mean            19.5254
evaluation/Returns Std             11.9621
evaluation/Returns Max             38.896
evaluation/Returns Min              5.24096
evaluation/ExplReturns Mean        19.5254
evaluation/ExplReturns Std         11.9621
evaluation/ExplReturns Max         38.896
evaluation/ExplReturns Min          5.24096
evaluation/Actions Mean            -0.0167737
evaluation/Actions Std              0.584853
evaluation/Actions Max              0.99963
evaluation/Actions Min             -0.999521
evaluation/Num Paths               10
evaluation/Average Returns         19.5254
time/data storing (s)               0.0314506
time/evaluation sampling (s)       71.6675
time/exploration sampling (s)      78.9668
time/logging (s)                    0.0259677
time/saving (s)                     0.0683672
time/training (s)                  10.3278
time/epoch (s)                    161.088
time/total (s)                  15390.1
Epoch                              96
-----------------------------  ---------------
2023-08-31 16:09:32.969139 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 97 finished
-----------------------------  ----------------
replay_buffer/size             491000
trainer/QF1 Loss                    0.0371304
trainer/QF2 Loss                    0.0384327
trainer/Policy Loss                -0.614688
trainer/Q1 Predictions Mean         7.52301
trainer/Q1 Predictions Std          5.9365
trainer/Q1 Predictions Max         52.4695
trainer/Q1 Predictions Min          0.164046
trainer/Q2 Predictions Mean         7.46814
trainer/Q2 Predictions Std          5.92437
trainer/Q2 Predictions Max         52.3078
trainer/Q2 Predictions Min          0.233626
trainer/Q Targets Mean              7.46495
trainer/Q Targets Std               5.90167
trainer/Q Targets Max              52.208
trainer/Q Targets Min               0.194134
trainer/Log Pis Mean                6.97282
trainer/Log Pis Std                 5.02615
trainer/Log Pis Max                23.6914
trainer/Log Pis Min                -4.4732
trainer/Policy mu Mean             -0.077214
trainer/Policy mu Std               1.59221
trainer/Policy mu Max               4.8914
trainer/Policy mu Min              -4.00256
trainer/Policy log std Mean        -0.636816
trainer/Policy log std Std          0.298893
trainer/Policy log std Max          0.102919
trainer/Policy log std Min         -2.28394
trainer/Alpha                       0.00243752
trainer/Alpha Loss                 -0.163536
exploration/num steps total    491000
exploration/num paths total       982
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0391724
exploration/Rewards Std             0.0376713
exploration/Rewards Max             0.235243
exploration/Rewards Min             0.000414575
exploration/Returns Mean           19.5862
exploration/Returns Std            15.4978
exploration/Returns Max            45.4308
exploration/Returns Min             4.25107
exploration/Actions Mean           -0.131817
exploration/Actions Std             0.671205
exploration/Actions Max             0.999991
exploration/Actions Min            -0.999988
exploration/Num Paths              10
exploration/Average Returns        19.5862
evaluation/num steps total     490000
evaluation/num paths total        980
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0522747
evaluation/Rewards Std              0.0582377
evaluation/Rewards Max              0.224659
evaluation/Rewards Min              0.001673
evaluation/Returns Mean            26.1374
evaluation/Returns Std             27.9007
evaluation/Returns Max            107.105
evaluation/Returns Min              8.53091
evaluation/ExplReturns Mean        26.1374
evaluation/ExplReturns Std         27.9007
evaluation/ExplReturns Max        107.105
evaluation/ExplReturns Min          8.53091
evaluation/Actions Mean            -0.102215
evaluation/Actions Std              0.648485
evaluation/Actions Max              0.999505
evaluation/Actions Min             -0.998872
evaluation/Num Paths               10
evaluation/Average Returns         26.1374
time/data storing (s)               0.0308181
time/evaluation sampling (s)       72.0417
time/exploration sampling (s)      77.5962
time/logging (s)                    0.0255578
time/saving (s)                     0.0775926
time/training (s)                  10.3137
time/epoch (s)                    160.086
time/total (s)                  15550.2
Epoch                              97
-----------------------------  ----------------
2023-08-31 16:12:13.645047 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size             496000
trainer/QF1 Loss                    0.121261
trainer/QF2 Loss                    0.103733
trainer/Policy Loss                -1.26741
trainer/Q1 Predictions Mean         8.54944
trainer/Q1 Predictions Std          7.41722
trainer/Q1 Predictions Max         67.0556
trainer/Q1 Predictions Min         -0.0711452
trainer/Q2 Predictions Mean         8.5639
trainer/Q2 Predictions Std          7.42302
trainer/Q2 Predictions Max         67.2106
trainer/Q2 Predictions Min          0.0217427
trainer/Q Targets Mean              8.52161
trainer/Q Targets Std               7.43412
trainer/Q Targets Max              66.5236
trainer/Q Targets Min              -0.0315346
trainer/Log Pis Mean                7.40023
trainer/Log Pis Std                 5.87135
trainer/Log Pis Max                40.995
trainer/Log Pis Min                -5.82024
trainer/Policy mu Mean             -0.073093
trainer/Policy mu Std               1.63363
trainer/Policy mu Max               5.22577
trainer/Policy mu Min              -5.67605
trainer/Policy log std Mean        -0.662153
trainer/Policy log std Std          0.305431
trainer/Policy log std Max          0.0874271
trainer/Policy log std Min         -2.15434
trainer/Alpha                       0.00246766
trainer/Alpha Loss                  2.40323
exploration/num steps total    496000
exploration/num paths total       992
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0459103
exploration/Rewards Std             0.0383269
exploration/Rewards Max             0.230477
exploration/Rewards Min             0.00129707
exploration/Returns Mean           22.9551
exploration/Returns Std            13.8221
exploration/Returns Max            60.9457
exploration/Returns Min            11.0925
exploration/Actions Mean           -0.0511122
exploration/Actions Std             0.602347
exploration/Actions Max             0.999763
exploration/Actions Min            -0.999716
exploration/Num Paths              10
exploration/Average Returns        22.9551
evaluation/num steps total     495000
evaluation/num paths total        990
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0546377
evaluation/Rewards Std              0.0562789
evaluation/Rewards Max              0.22804
evaluation/Rewards Min              0.00015727
evaluation/Returns Mean            27.3189
evaluation/Returns Std             26.9652
evaluation/Returns Max            104.483
evaluation/Returns Min              7.81709
evaluation/ExplReturns Mean        27.3189
evaluation/ExplReturns Std         26.9652
evaluation/ExplReturns Max        104.483
evaluation/ExplReturns Min          7.81709
evaluation/Actions Mean            -0.101439
evaluation/Actions Std              0.569676
evaluation/Actions Max              0.999678
evaluation/Actions Min             -0.999781
evaluation/Num Paths               10
evaluation/Average Returns         27.3189
time/data storing (s)               0.0312062
time/evaluation sampling (s)       71.7771
time/exploration sampling (s)      78.0534
time/logging (s)                    0.0254632
time/saving (s)                     0.0751299
time/training (s)                  10.7094
time/epoch (s)                    160.672
time/total (s)                  15710.9
Epoch                              98
-----------------------------  ---------------
2023-08-31 16:14:54.718167 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size             501000
trainer/QF1 Loss                    0.0561895
trainer/QF2 Loss                    0.0413186
trainer/Policy Loss                -1.18664
trainer/Q1 Predictions Mean         7.99568
trainer/Q1 Predictions Std          5.17571
trainer/Q1 Predictions Max         50.295
trainer/Q1 Predictions Min         -0.432828
trainer/Q2 Predictions Mean         7.96623
trainer/Q2 Predictions Std          5.14721
trainer/Q2 Predictions Max         49.9274
trainer/Q2 Predictions Min         -0.499283
trainer/Q Targets Mean              7.96527
trainer/Q Targets Std               5.16242
trainer/Q Targets Max              50.4982
trainer/Q Targets Min              -0.26829
trainer/Log Pis Mean                6.91302
trainer/Log Pis Std                 5.69476
trainer/Log Pis Max                27.3908
trainer/Log Pis Min                -5.46398
trainer/Policy mu Mean             -0.0737011
trainer/Policy mu Std               1.63838
trainer/Policy mu Max               5.39837
trainer/Policy mu Min              -3.91902
trainer/Policy log std Mean        -0.64507
trainer/Policy log std Std          0.295707
trainer/Policy log std Max          0.305576
trainer/Policy log std Min         -2.02293
trainer/Alpha                       0.0026878
trainer/Alpha Loss                 -0.514858
exploration/num steps total    501000
exploration/num paths total      1002
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0278432
exploration/Rewards Std             0.0542347
exploration/Rewards Max             1
exploration/Rewards Min             0.00121623
exploration/Returns Mean           13.9216
exploration/Returns Std             9.30105
exploration/Returns Max            38.6854
exploration/Returns Min             4.28789
exploration/Actions Mean           -0.112614
exploration/Actions Std             0.579507
exploration/Actions Max             0.999842
exploration/Actions Min            -0.999873
exploration/Num Paths              10
exploration/Average Returns        13.9216
evaluation/num steps total     500000
evaluation/num paths total       1000
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0338529
evaluation/Rewards Std              0.022834
evaluation/Rewards Max              0.222229
evaluation/Rewards Min              0.00134127
evaluation/Returns Mean            16.9265
evaluation/Returns Std             10.0766
evaluation/Returns Max             35.6087
evaluation/Returns Min              6.37883
evaluation/ExplReturns Mean        16.9265
evaluation/ExplReturns Std         10.0766
evaluation/ExplReturns Max         35.6087
evaluation/ExplReturns Min          6.37883
evaluation/Actions Mean            -0.0918335
evaluation/Actions Std              0.56084
evaluation/Actions Max              0.999336
evaluation/Actions Min             -0.999968
evaluation/Num Paths               10
evaluation/Average Returns         16.9265
time/data storing (s)               0.0315036
time/evaluation sampling (s)       71.7411
time/exploration sampling (s)      76.0306
time/logging (s)                    0.025861
time/saving (s)                     0.0683568
time/training (s)                  13.172
time/epoch (s)                    161.069
time/total (s)                  15871.9
Epoch                              99
-----------------------------  ---------------
2023-08-31 16:17:36.898586 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size             506000
trainer/QF1 Loss                    0.0762362
trainer/QF2 Loss                    0.0679789
trainer/Policy Loss                -0.199592
trainer/Q1 Predictions Mean         7.91259
trainer/Q1 Predictions Std          5.66911
trainer/Q1 Predictions Max         57.1665
trainer/Q1 Predictions Min         -0.852448
trainer/Q2 Predictions Mean         7.89751
trainer/Q2 Predictions Std          5.65522
trainer/Q2 Predictions Max         56.926
trainer/Q2 Predictions Min         -0.878519
trainer/Q Targets Mean              8.01051
trainer/Q Targets Std               5.70629
trainer/Q Targets Max              56.4503
trainer/Q Targets Min              -0.819978
trainer/Log Pis Mean                7.80519
trainer/Log Pis Std                 4.81316
trainer/Log Pis Max                21.8836
trainer/Log Pis Min                -7.56819
trainer/Policy mu Mean             -0.172775
trainer/Policy mu Std               1.65323
trainer/Policy mu Max               4.2266
trainer/Policy mu Min              -4.07482
trainer/Policy log std Mean        -0.63293
trainer/Policy log std Std          0.279847
trainer/Policy log std Max          0.196857
trainer/Policy log std Min         -2.04524
trainer/Alpha                       0.00280082
trainer/Alpha Loss                  4.7329
exploration/num steps total    506000
exploration/num paths total      1012
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0319871
exploration/Rewards Std             0.0303051
exploration/Rewards Max             0.70346
exploration/Rewards Min             0.00126976
exploration/Returns Mean           15.9935
exploration/Returns Std            11.3174
exploration/Returns Max            44.251
exploration/Returns Min             5.1492
exploration/Actions Mean           -0.145177
exploration/Actions Std             0.642098
exploration/Actions Max             0.999739
exploration/Actions Min            -0.999977
exploration/Num Paths              10
exploration/Average Returns        15.9935
evaluation/num steps total     505000
evaluation/num paths total       1010
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.031683
evaluation/Rewards Std              0.019149
evaluation/Rewards Max              0.083398
evaluation/Rewards Min              0.00129763
evaluation/Returns Mean            15.8415
evaluation/Returns Std              8.72526
evaluation/Returns Max             29.8164
evaluation/Returns Min              1.19931
evaluation/ExplReturns Mean        15.8415
evaluation/ExplReturns Std          8.72526
evaluation/ExplReturns Max         29.8164
evaluation/ExplReturns Min          1.19931
evaluation/Actions Mean            -0.176674
evaluation/Actions Std              0.578172
evaluation/Actions Max              0.998842
evaluation/Actions Min             -0.999795
evaluation/Num Paths               10
evaluation/Average Returns         15.8415
time/data storing (s)               0.0311065
time/evaluation sampling (s)       70.2689
time/exploration sampling (s)      77.3549
time/logging (s)                    0.0254674
time/saving (s)                     0.0666018
time/training (s)                  14.4289
time/epoch (s)                    162.176
time/total (s)                  16034.1
Epoch                             100
-----------------------------  ---------------
2023-08-31 16:20:18.874647 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 101 finished
-----------------------------  ----------------
replay_buffer/size             511000
trainer/QF1 Loss                    0.05182
trainer/QF2 Loss                    0.0375716
trainer/Policy Loss                -1.72244
trainer/Q1 Predictions Mean         7.99572
trainer/Q1 Predictions Std          5.32895
trainer/Q1 Predictions Max         53.156
trainer/Q1 Predictions Min          0.0905399
trainer/Q2 Predictions Mean         7.9891
trainer/Q2 Predictions Std          5.28306
trainer/Q2 Predictions Max         53.0885
trainer/Q2 Predictions Min          0.0829039
trainer/Q Targets Mean              7.96395
trainer/Q Targets Std               5.28623
trainer/Q Targets Max              52.6686
trainer/Q Targets Min               0.164526
trainer/Log Pis Mean                6.38562
trainer/Log Pis Std                 4.83463
trainer/Log Pis Max                23.5247
trainer/Log Pis Min                -7.90228
trainer/Policy mu Mean             -0.244188
trainer/Policy mu Std               1.5438
trainer/Policy mu Max               3.75777
trainer/Policy mu Min              -4.19712
trainer/Policy log std Mean        -0.631622
trainer/Policy log std Std          0.285284
trainer/Policy log std Max          0.0665869
trainer/Policy log std Min         -2.19576
trainer/Alpha                       0.00292863
trainer/Alpha Loss                 -3.58382
exploration/num steps total    511000
exploration/num paths total      1022
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0703396
exploration/Rewards Std             0.145377
exploration/Rewards Max             0.737637
exploration/Rewards Min             1.73037e-05
exploration/Returns Mean           35.1698
exploration/Returns Std            54.8654
exploration/Returns Max           198.116
exploration/Returns Min             5.47901
exploration/Actions Mean            0.0127381
exploration/Actions Std             0.621718
exploration/Actions Max             0.999999
exploration/Actions Min            -0.999727
exploration/Num Paths              10
exploration/Average Returns        35.1698
evaluation/num steps total     510000
evaluation/num paths total       1020
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0350416
evaluation/Rewards Std              0.0256508
evaluation/Rewards Max              0.218401
evaluation/Rewards Min              5.24354e-05
evaluation/Returns Mean            17.5208
evaluation/Returns Std              9.04496
evaluation/Returns Max             36.1462
evaluation/Returns Min              2.80022
evaluation/ExplReturns Mean        17.5208
evaluation/ExplReturns Std          9.04496
evaluation/ExplReturns Max         36.1462
evaluation/ExplReturns Min          2.80022
evaluation/Actions Mean            -0.15515
evaluation/Actions Std              0.592213
evaluation/Actions Max              0.999909
evaluation/Actions Min             -0.999814
evaluation/Num Paths               10
evaluation/Average Returns         17.5208
time/data storing (s)               0.0313382
time/evaluation sampling (s)       72.9111
time/exploration sampling (s)      78.0947
time/logging (s)                    0.0260333
time/saving (s)                     0.073511
time/training (s)                  10.8358
time/epoch (s)                    161.973
time/total (s)                  16196.1
Epoch                             101
-----------------------------  ----------------
2023-08-31 16:22:57.716901 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size             516000
trainer/QF1 Loss                    0.073743
trainer/QF2 Loss                    0.084702
trainer/Policy Loss                -1.6963
trainer/Q1 Predictions Mean         8.85168
trainer/Q1 Predictions Std          5.37349
trainer/Q1 Predictions Max         31.596
trainer/Q1 Predictions Min          0.288429
trainer/Q2 Predictions Mean         8.83541
trainer/Q2 Predictions Std          5.34675
trainer/Q2 Predictions Max         31.8325
trainer/Q2 Predictions Min          0.0720003
trainer/Q Targets Mean              8.85084
trainer/Q Targets Std               5.34304
trainer/Q Targets Max              31.4887
trainer/Q Targets Min               0.0434867
trainer/Log Pis Mean                7.2847
trainer/Log Pis Std                 5.19295
trainer/Log Pis Max                26.4279
trainer/Log Pis Min                -7.21174
trainer/Policy mu Mean             -0.158074
trainer/Policy mu Std               1.63953
trainer/Policy mu Max               4.25234
trainer/Policy mu Min              -4.41498
trainer/Policy log std Mean        -0.614947
trainer/Policy log std Std          0.255596
trainer/Policy log std Max          0.280893
trainer/Policy log std Min         -1.90177
trainer/Alpha                       0.00331485
trainer/Alpha Loss                  1.62545
exploration/num steps total    516000
exploration/num paths total      1032
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0336073
exploration/Rewards Std             0.0279249
exploration/Rewards Max             0.728242
exploration/Rewards Min             0.00132339
exploration/Returns Mean           16.8036
exploration/Returns Std            10.0275
exploration/Returns Max            35.7352
exploration/Returns Min             5.2293
exploration/Actions Mean           -0.184488
exploration/Actions Std             0.637217
exploration/Actions Max             0.99983
exploration/Actions Min            -0.999992
exploration/Num Paths              10
exploration/Average Returns        16.8036
evaluation/num steps total     515000
evaluation/num paths total       1030
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0336982
evaluation/Rewards Std              0.0186204
evaluation/Rewards Max              0.0938421
evaluation/Rewards Min              0.00083742
evaluation/Returns Mean            16.8491
evaluation/Returns Std              7.7354
evaluation/Returns Max             30.9211
evaluation/Returns Min              5.98016
evaluation/ExplReturns Mean        16.8491
evaluation/ExplReturns Std          7.7354
evaluation/ExplReturns Max         30.9211
evaluation/ExplReturns Min          5.98016
evaluation/Actions Mean            -0.175099
evaluation/Actions Std              0.549198
evaluation/Actions Max              0.999946
evaluation/Actions Min             -0.999862
evaluation/Num Paths               10
evaluation/Average Returns         16.8491
time/data storing (s)               0.0311848
time/evaluation sampling (s)       71.3944
time/exploration sampling (s)      76.9318
time/logging (s)                    0.0255226
time/saving (s)                     0.0736512
time/training (s)                  10.3811
time/epoch (s)                    158.838
time/total (s)                  16354.9
Epoch                             102
-----------------------------  ---------------
2023-08-31 16:25:42.708079 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size             521000
trainer/QF1 Loss                    0.0766553
trainer/QF2 Loss                    0.0780888
trainer/Policy Loss                -2.86591
trainer/Q1 Predictions Mean         9.53204
trainer/Q1 Predictions Std          9.62928
trainer/Q1 Predictions Max         72.4235
trainer/Q1 Predictions Min         -0.0705019
trainer/Q2 Predictions Mean         9.56127
trainer/Q2 Predictions Std          9.65475
trainer/Q2 Predictions Max         72.2407
trainer/Q2 Predictions Min          0.0331254
trainer/Q Targets Mean              9.42459
trainer/Q Targets Std               9.65242
trainer/Q Targets Max              72.1658
trainer/Q Targets Min              -0.227005
trainer/Log Pis Mean                6.83297
trainer/Log Pis Std                 5.17107
trainer/Log Pis Max                24.5572
trainer/Log Pis Min                -6.00927
trainer/Policy mu Mean             -0.227502
trainer/Policy mu Std               1.62305
trainer/Policy mu Max               5.72448
trainer/Policy mu Min              -4.19519
trainer/Policy log std Mean        -0.61192
trainer/Policy log std Std          0.271666
trainer/Policy log std Max          0.0901631
trainer/Policy log std Min         -2.21737
trainer/Alpha                       0.00334507
trainer/Alpha Loss                 -0.952106
exploration/num steps total    521000
exploration/num paths total      1042
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0314379
exploration/Rewards Std             0.023491
exploration/Rewards Max             0.233795
exploration/Rewards Min             0.00110871
exploration/Returns Mean           15.7189
exploration/Returns Std             7.71855
exploration/Returns Max            28.4972
exploration/Returns Min             4.99386
exploration/Actions Mean           -0.153106
exploration/Actions Std             0.60046
exploration/Actions Max             0.999956
exploration/Actions Min            -0.999998
exploration/Num Paths              10
exploration/Average Returns        15.7189
evaluation/num steps total     520000
evaluation/num paths total       1040
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0416563
evaluation/Rewards Std              0.0379564
evaluation/Rewards Max              0.714783
evaluation/Rewards Min              0.00100983
evaluation/Returns Mean            20.8282
evaluation/Returns Std             10.9897
evaluation/Returns Max             39.4973
evaluation/Returns Min              3.55557
evaluation/ExplReturns Mean        20.8282
evaluation/ExplReturns Std         10.9897
evaluation/ExplReturns Max         39.4973
evaluation/ExplReturns Min          3.55557
evaluation/Actions Mean            -0.2491
evaluation/Actions Std              0.55081
evaluation/Actions Max              0.999969
evaluation/Actions Min             -0.999993
evaluation/Num Paths               10
evaluation/Average Returns         20.8282
time/data storing (s)               0.0309253
time/evaluation sampling (s)       72.8367
time/exploration sampling (s)      78.7961
time/logging (s)                    0.0261853
time/saving (s)                     0.0559237
time/training (s)                  13.2419
time/epoch (s)                    164.988
time/total (s)                  16519.9
Epoch                             103
-----------------------------  ---------------
2023-08-31 16:28:30.256785 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 104 finished
-----------------------------  ----------------
replay_buffer/size             526000
trainer/QF1 Loss                    0.0990246
trainer/QF2 Loss                    0.0993637
trainer/Policy Loss                -2.78389
trainer/Q1 Predictions Mean         9.47951
trainer/Q1 Predictions Std          5.93815
trainer/Q1 Predictions Max         49.007
trainer/Q1 Predictions Min          0.612922
trainer/Q2 Predictions Mean         9.52691
trainer/Q2 Predictions Std          5.94519
trainer/Q2 Predictions Max         48.9557
trainer/Q2 Predictions Min          0.550233
trainer/Q Targets Mean              9.54152
trainer/Q Targets Std               6.0053
trainer/Q Targets Max              49.332
trainer/Q Targets Min               0.556097
trainer/Log Pis Mean                6.85026
trainer/Log Pis Std                 5.62401
trainer/Log Pis Max                45.8515
trainer/Log Pis Min                -4.72849
trainer/Policy mu Mean             -0.110945
trainer/Policy mu Std               1.62185
trainer/Policy mu Max               5.67126
trainer/Policy mu Min              -5.94116
trainer/Policy log std Mean        -0.613455
trainer/Policy log std Std          0.253809
trainer/Policy log std Max          0.0284578
trainer/Policy log std Min         -2.03436
trainer/Alpha                       0.00349089
trainer/Alpha Loss                 -0.847144
exploration/num steps total    526000
exploration/num paths total      1052
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0289792
exploration/Rewards Std             0.0232713
exploration/Rewards Max             0.234904
exploration/Rewards Min             8.68699e-06
exploration/Returns Mean           14.4896
exploration/Returns Std             6.01645
exploration/Returns Max            21.4288
exploration/Returns Min             3.79463
exploration/Actions Mean           -0.0701898
exploration/Actions Std             0.63458
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        14.4896
evaluation/num steps total     525000
evaluation/num paths total       1050
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0368655
evaluation/Rewards Std              0.0267471
evaluation/Rewards Max              0.242132
evaluation/Rewards Min              0.00137207
evaluation/Returns Mean            18.4327
evaluation/Returns Std              9.54228
evaluation/Returns Max             33.218
evaluation/Returns Min              4.4718
evaluation/ExplReturns Mean        18.4327
evaluation/ExplReturns Std          9.54228
evaluation/ExplReturns Max         33.218
evaluation/ExplReturns Min          4.4718
evaluation/Actions Mean            -0.279073
evaluation/Actions Std              0.533595
evaluation/Actions Max              0.99998
evaluation/Actions Min             -0.999998
evaluation/Num Paths               10
evaluation/Average Returns         18.4327
time/data storing (s)               0.0316311
time/evaluation sampling (s)       71.5586
time/exploration sampling (s)      80.2032
time/logging (s)                    0.0256946
time/saving (s)                     0.0533029
time/training (s)                  15.6717
time/epoch (s)                    167.544
time/total (s)                  16687.5
Epoch                             104
-----------------------------  ----------------
2023-08-31 16:31:15.333977 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 105 finished
-----------------------------  ----------------
replay_buffer/size             531000
trainer/QF1 Loss                    0.125015
trainer/QF2 Loss                    0.0793063
trainer/Policy Loss                -2.74675
trainer/Q1 Predictions Mean         9.76034
trainer/Q1 Predictions Std          5.93282
trainer/Q1 Predictions Max         38.9231
trainer/Q1 Predictions Min          0.428671
trainer/Q2 Predictions Mean         9.80518
trainer/Q2 Predictions Std          5.98588
trainer/Q2 Predictions Max         39.062
trainer/Q2 Predictions Min          0.373217
trainer/Q Targets Mean              9.9236
trainer/Q Targets Std               6.02826
trainer/Q Targets Max              39.56
trainer/Q Targets Min               0.427105
trainer/Log Pis Mean                7.13895
trainer/Log Pis Std                 4.99471
trainer/Log Pis Max                21.9278
trainer/Log Pis Min                -5.61254
trainer/Policy mu Mean             -0.121613
trainer/Policy mu Std               1.61028
trainer/Policy mu Max               4.20461
trainer/Policy mu Min              -4.25244
trainer/Policy log std Mean        -0.62292
trainer/Policy log std Std          0.273885
trainer/Policy log std Max          0.0974283
trainer/Policy log std Min         -1.88196
trainer/Alpha                       0.00360727
trainer/Alpha Loss                  0.78156
exploration/num steps total    531000
exploration/num paths total      1062
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.037895
exploration/Rewards Std             0.0495463
exploration/Rewards Max             0.659448
exploration/Rewards Min             0.000612786
exploration/Returns Mean           18.9475
exploration/Returns Std            10.7743
exploration/Returns Max            42.8551
exploration/Returns Min             5.77505
exploration/Actions Mean           -0.10625
exploration/Actions Std             0.645807
exploration/Actions Max             0.999996
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        18.9475
evaluation/num steps total     530000
evaluation/num paths total       1060
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0394793
evaluation/Rewards Std              0.0255201
evaluation/Rewards Max              0.211606
evaluation/Rewards Min              0.00158355
evaluation/Returns Mean            19.7396
evaluation/Returns Std             10.1739
evaluation/Returns Max             29.9104
evaluation/Returns Min              3.59654
evaluation/ExplReturns Mean        19.7396
evaluation/ExplReturns Std         10.1739
evaluation/ExplReturns Max         29.9104
evaluation/ExplReturns Min          3.59654
evaluation/Actions Mean            -0.145179
evaluation/Actions Std              0.593731
evaluation/Actions Max              0.999384
evaluation/Actions Min             -0.999899
evaluation/Num Paths               10
evaluation/Average Returns         19.7396
time/data storing (s)               0.0310819
time/evaluation sampling (s)       71.625
time/exploration sampling (s)      79.2662
time/logging (s)                    0.0256303
time/saving (s)                     0.0619669
time/training (s)                  14.0631
time/epoch (s)                    165.073
time/total (s)                  16852.5
Epoch                             105
-----------------------------  ----------------
2023-08-31 16:33:55.690821 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 106 finished
-----------------------------  ----------------
replay_buffer/size             536000
trainer/QF1 Loss                    0.122898
trainer/QF2 Loss                    0.133386
trainer/Policy Loss                -2.82927
trainer/Q1 Predictions Mean         9.99332
trainer/Q1 Predictions Std          7.90106
trainer/Q1 Predictions Max         63.1366
trainer/Q1 Predictions Min         -0.626337
trainer/Q2 Predictions Mean         9.99514
trainer/Q2 Predictions Std          7.8505
trainer/Q2 Predictions Max         62.5866
trainer/Q2 Predictions Min         -0.323926
trainer/Q Targets Mean             10.0533
trainer/Q Targets Std               7.99357
trainer/Q Targets Max              65.5267
trainer/Q Targets Min              -0.424747
trainer/Log Pis Mean                7.3406
trainer/Log Pis Std                 5.49198
trainer/Log Pis Max                29.1054
trainer/Log Pis Min                -5.99799
trainer/Policy mu Mean             -0.247634
trainer/Policy mu Std               1.60723
trainer/Policy mu Max               5.29657
trainer/Policy mu Min              -4.88018
trainer/Policy log std Mean        -0.614298
trainer/Policy log std Std          0.288084
trainer/Policy log std Max          0.144366
trainer/Policy log std Min         -2.40343
trainer/Alpha                       0.0036679
trainer/Alpha Loss                  1.91011
exploration/num steps total    536000
exploration/num paths total      1072
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0256629
exploration/Rewards Std             0.0258231
exploration/Rewards Max             0.731988
exploration/Rewards Min             0.000213526
exploration/Returns Mean           12.8315
exploration/Returns Std             6.23302
exploration/Returns Max            22.7498
exploration/Returns Min             5.07478
exploration/Actions Mean           -0.164629
exploration/Actions Std             0.628643
exploration/Actions Max             0.999849
exploration/Actions Min            -0.999927
exploration/Num Paths              10
exploration/Average Returns        12.8315
evaluation/num steps total     535000
evaluation/num paths total       1070
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0304781
evaluation/Rewards Std              0.0241011
evaluation/Rewards Max              0.220962
evaluation/Rewards Min              0.000442892
evaluation/Returns Mean            15.2391
evaluation/Returns Std             10.0016
evaluation/Returns Max             31.5382
evaluation/Returns Min              3.01562
evaluation/ExplReturns Mean        15.2391
evaluation/ExplReturns Std         10.0016
evaluation/ExplReturns Max         31.5382
evaluation/ExplReturns Min          3.01562
evaluation/Actions Mean            -0.217434
evaluation/Actions Std              0.56155
evaluation/Actions Max              0.999588
evaluation/Actions Min             -0.999961
evaluation/Num Paths               10
evaluation/Average Returns         15.2391
time/data storing (s)               0.0315446
time/evaluation sampling (s)       71.5449
time/exploration sampling (s)      78.5708
time/logging (s)                    0.0258585
time/saving (s)                     0.091873
time/training (s)                  10.0879
time/epoch (s)                    160.353
time/total (s)                  17012.9
Epoch                             106
-----------------------------  ----------------
2023-08-31 16:36:35.960918 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 107 finished
-----------------------------  ----------------
replay_buffer/size             541000
trainer/QF1 Loss                    0.119988
trainer/QF2 Loss                    0.0915817
trainer/Policy Loss                -4.58121
trainer/Q1 Predictions Mean        10.9078
trainer/Q1 Predictions Std          7.34517
trainer/Q1 Predictions Max         59.6726
trainer/Q1 Predictions Min          0.892675
trainer/Q2 Predictions Mean        10.926
trainer/Q2 Predictions Std          7.33188
trainer/Q2 Predictions Max         59.8742
trainer/Q2 Predictions Min          0.767091
trainer/Q Targets Mean             10.9382
trainer/Q Targets Std               7.31226
trainer/Q Targets Max              59.7388
trainer/Q Targets Min               0.802618
trainer/Log Pis Mean                6.49661
trainer/Log Pis Std                 5.74441
trainer/Log Pis Max                33.5403
trainer/Log Pis Min                -6.6715
trainer/Policy mu Mean             -0.0667763
trainer/Policy mu Std               1.59706
trainer/Policy mu Max               6.00416
trainer/Policy mu Min              -5.82244
trainer/Policy log std Mean        -0.63233
trainer/Policy log std Std          0.272788
trainer/Policy log std Max          0.155154
trainer/Policy log std Min         -2.32146
trainer/Alpha                       0.00357174
trainer/Alpha Loss                 -2.8364
exploration/num steps total    541000
exploration/num paths total      1082
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0479242
exploration/Rewards Std             0.0294424
exploration/Rewards Max             0.23289
exploration/Rewards Min             0.00120159
exploration/Returns Mean           23.9621
exploration/Returns Std             8.46371
exploration/Returns Max            40.5428
exploration/Returns Min            10.9836
exploration/Actions Mean           -0.156216
exploration/Actions Std             0.650679
exploration/Actions Max             0.999987
exploration/Actions Min            -0.999986
exploration/Num Paths              10
exploration/Average Returns        23.9621
evaluation/num steps total     540000
evaluation/num paths total       1080
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0475063
evaluation/Rewards Std              0.0284511
evaluation/Rewards Max              0.722474
evaluation/Rewards Min              0.000118571
evaluation/Returns Mean            23.7532
evaluation/Returns Std              8.8543
evaluation/Returns Max             37.4373
evaluation/Returns Min              9.48807
evaluation/ExplReturns Mean        23.7532
evaluation/ExplReturns Std          8.8543
evaluation/ExplReturns Max         37.4373
evaluation/ExplReturns Min          9.48807
evaluation/Actions Mean            -0.068417
evaluation/Actions Std              0.521858
evaluation/Actions Max              1
evaluation/Actions Min             -0.999999
evaluation/Num Paths               10
evaluation/Average Returns         23.7532
time/data storing (s)               0.0312202
time/evaluation sampling (s)       71.0924
time/exploration sampling (s)      78.9124
time/logging (s)                    0.0256032
time/saving (s)                     0.0659432
time/training (s)                  10.1381
time/epoch (s)                    160.266
time/total (s)                  17173.2
Epoch                             107
-----------------------------  ----------------
2023-08-31 16:39:14.847165 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 108 finished
-----------------------------  ----------------
replay_buffer/size             546000
trainer/QF1 Loss                    0.227686
trainer/QF2 Loss                    0.213012
trainer/Policy Loss                -4.31504
trainer/Q1 Predictions Mean        11.1158
trainer/Q1 Predictions Std         10.1301
trainer/Q1 Predictions Max         86.9927
trainer/Q1 Predictions Min         -1.1018
trainer/Q2 Predictions Mean        11.1104
trainer/Q2 Predictions Std         10.138
trainer/Q2 Predictions Max         86.9627
trainer/Q2 Predictions Min         -1.22365
trainer/Q Targets Mean             11.2472
trainer/Q Targets Std              10.2211
trainer/Q Targets Max              87.315
trainer/Q Targets Min              -1.02431
trainer/Log Pis Mean                6.96321
trainer/Log Pis Std                 7.11042
trainer/Log Pis Max                53.8192
trainer/Log Pis Min                -6.44001
trainer/Policy mu Mean              0.0259728
trainer/Policy mu Std               1.66342
trainer/Policy mu Max               7.89782
trainer/Policy mu Min              -5.64396
trainer/Policy log std Mean        -0.622793
trainer/Policy log std Std          0.271572
trainer/Policy log std Max          0.0808843
trainer/Policy log std Min         -2.01875
trainer/Alpha                       0.0036152
trainer/Alpha Loss                 -0.206878
exploration/num steps total    546000
exploration/num paths total      1092
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0258028
exploration/Rewards Std             0.0233732
exploration/Rewards Max             0.108362
exploration/Rewards Min             3.4607e-10
exploration/Returns Mean           12.9014
exploration/Returns Std             9.32825
exploration/Returns Max            35.4781
exploration/Returns Min             3.94719
exploration/Actions Mean           -0.0062602
exploration/Actions Std             0.634949
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns        12.9014
evaluation/num steps total     545000
evaluation/num paths total       1090
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0258415
evaluation/Rewards Std              0.02557
evaluation/Rewards Max              0.212988
evaluation/Rewards Min              5.01102e-10
evaluation/Returns Mean            12.9207
evaluation/Returns Std             10.6905
evaluation/Returns Max             32.9222
evaluation/Returns Min              1.08211
evaluation/ExplReturns Mean        12.9207
evaluation/ExplReturns Std         10.6905
evaluation/ExplReturns Max         32.9222
evaluation/ExplReturns Min          1.08211
evaluation/Actions Mean             0.023176
evaluation/Actions Std              0.561979
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.999964
evaluation/Num Paths               10
evaluation/Average Returns         12.9207
time/data storing (s)               0.031006
time/evaluation sampling (s)       71.1181
time/exploration sampling (s)      77.3943
time/logging (s)                    0.025582
time/saving (s)                     0.0652147
time/training (s)                  10.2479
time/epoch (s)                    158.882
time/total (s)                  17332.1
Epoch                             108
-----------------------------  ----------------
2023-08-31 16:41:53.727466 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 109 finished
-----------------------------  ----------------
replay_buffer/size             551000
trainer/QF1 Loss                    0.268514
trainer/QF2 Loss                    0.241178
trainer/Policy Loss                -4.72601
trainer/Q1 Predictions Mean        11.0983
trainer/Q1 Predictions Std          6.36824
trainer/Q1 Predictions Max         48.7119
trainer/Q1 Predictions Min         -0.453006
trainer/Q2 Predictions Mean        11.0405
trainer/Q2 Predictions Std          6.32499
trainer/Q2 Predictions Max         48.5789
trainer/Q2 Predictions Min         -0.679172
trainer/Q Targets Mean             10.9511
trainer/Q Targets Std               6.18363
trainer/Q Targets Max              42.8797
trainer/Q Targets Min              -0.823451
trainer/Log Pis Mean                6.48986
trainer/Log Pis Std                 5.1806
trainer/Log Pis Max                25.2832
trainer/Log Pis Min                -7.35173
trainer/Policy mu Mean             -0.0846974
trainer/Policy mu Std               1.55987
trainer/Policy mu Max               4.59043
trainer/Policy mu Min              -4.25912
trainer/Policy log std Mean        -0.644331
trainer/Policy log std Std          0.265584
trainer/Policy log std Max          0.102914
trainer/Policy log std Min         -2.56398
trainer/Alpha                       0.00370074
trainer/Alpha Loss                 -2.85635
exploration/num steps total    551000
exploration/num paths total      1102
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0283224
exploration/Rewards Std             0.0296759
exploration/Rewards Max             0.220736
exploration/Rewards Min             3.3001e-07
exploration/Returns Mean           14.1612
exploration/Returns Std             6.37244
exploration/Returns Max            25.6375
exploration/Returns Min             5.83309
exploration/Actions Mean           -0.0384759
exploration/Actions Std             0.632363
exploration/Actions Max             0.999995
exploration/Actions Min            -0.999988
exploration/Num Paths              10
exploration/Average Returns        14.1612
evaluation/num steps total     550000
evaluation/num paths total       1100
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.0224825
evaluation/Rewards Std              0.0243099
evaluation/Rewards Max              0.212441
evaluation/Rewards Min              3.42175e-07
evaluation/Returns Mean            11.2413
evaluation/Returns Std              9.06252
evaluation/Returns Max             30.7586
evaluation/Returns Min              0.139152
evaluation/ExplReturns Mean        11.2413
evaluation/ExplReturns Std          9.06252
evaluation/ExplReturns Max         30.7586
evaluation/ExplReturns Min          0.139152
evaluation/Actions Mean            -0.0640368
evaluation/Actions Std              0.579971
evaluation/Actions Max              0.999881
evaluation/Actions Min             -0.998779
evaluation/Num Paths               10
evaluation/Average Returns         11.2413
time/data storing (s)               0.0313976
time/evaluation sampling (s)       70.5951
time/exploration sampling (s)      77.989
time/logging (s)                    0.0258893
time/saving (s)                     0.0853754
time/training (s)                  10.1497
time/epoch (s)                    158.876
time/total (s)                  17490.9
Epoch                             109
-----------------------------  ----------------
2023-08-31 16:44:32.275867 CST | [Stack_Panda_OSC_POSE_SEED1_2023_08_31_11_50_28_0000--s-0] Epoch 110 finished
-----------------------------  ----------------
replay_buffer/size             556000
trainer/QF1 Loss                    0.206704
trainer/QF2 Loss                    0.19475
trainer/Policy Loss                -4.97428
trainer/Q1 Predictions Mean        11.6387
trainer/Q1 Predictions Std          9.26913
trainer/Q1 Predictions Max         93.2065
trainer/Q1 Predictions Min         -1.37581
trainer/Q2 Predictions Mean        11.6296
trainer/Q2 Predictions Std          9.23312
trainer/Q2 Predictions Max         92.925
trainer/Q2 Predictions Min         -1.57199
trainer/Q Targets Mean             11.6777
trainer/Q Targets Std               9.36815
trainer/Q Targets Max              94.9338
trainer/Q Targets Min              -1.50601
trainer/Log Pis Mean                6.80383
trainer/Log Pis Std                 5.08294
trainer/Log Pis Max                27.0653
trainer/Log Pis Min                -4.37712
trainer/Policy mu Mean             -0.129991
trainer/Policy mu Std               1.59789
trainer/Policy mu Max               4.43705
trainer/Policy mu Min              -3.93602
trainer/Policy log std Mean        -0.639993
trainer/Policy log std Std          0.251977
trainer/Policy log std Max          0.359213
trainer/Policy log std Min         -1.91153
trainer/Alpha                       0.00375891
trainer/Alpha Loss                 -1.09534
exploration/num steps total    556000
exploration/num paths total      1112
exploration/path length Mean      500
exploration/path length Std         0
exploration/path length Max       500
exploration/path length Min       500
exploration/Rewards Mean            0.0137702
exploration/Rewards Std             0.0153723
exploration/Rewards Max             0.0858249
exploration/Rewards Min             2.86466e-07
exploration/Returns Mean            6.8851
exploration/Returns Std             6.1817
exploration/Returns Max            19.4404
exploration/Returns Min             0.0369663
exploration/Actions Mean           -0.143959
exploration/Actions Std             0.629372
exploration/Actions Max             0.999888
exploration/Actions Min            -0.999978
exploration/Num Paths              10
exploration/Average Returns         6.8851
evaluation/num steps total     555000
evaluation/num paths total       1110
evaluation/path length Mean       500
evaluation/path length Std          0
evaluation/path length Max        500
evaluation/path length Min        500
evaluation/Rewards Mean             0.030588
evaluation/Rewards Std              0.0632259
evaluation/Rewards Max              0.735134
evaluation/Rewards Min              7.96379e-08
evaluation/Returns Mean            15.294
evaluation/Returns Std             29.4928
evaluation/Returns Max            100.013
evaluation/Returns Min              0.138027
evaluation/ExplReturns Mean        15.294
evaluation/ExplReturns Std         29.4928
evaluation/ExplReturns Max        100.013
evaluation/ExplReturns Min          0.138027
evaluation/Actions Mean            -0.167716
evaluation/Actions Std              0.582418
evaluation/Actions Max              0.997174
evaluation/Actions Min             -0.999716
evaluation/Num Paths               10
evaluation/Average Returns         15.294
time/data storing (s)               0.0313736
time/evaluation sampling (s)       71.6768
time/exploration sampling (s)      76.0113
time/logging (s)                    0.0256064
time/saving (s)                     0.0709666
time/training (s)                  10.7278
time/epoch (s)                    158.544
time/total (s)                  17649.5
Epoch                             110
-----------------------------  ----------------
