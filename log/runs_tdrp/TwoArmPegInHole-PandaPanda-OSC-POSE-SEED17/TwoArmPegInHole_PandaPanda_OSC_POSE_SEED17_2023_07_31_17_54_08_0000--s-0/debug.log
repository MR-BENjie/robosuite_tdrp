2023-07-31 17:58:26.672208 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 0 finished
-----------------------------  --------------------
replay_buffer/size             6000
trainer/tdrp Loss              [4791.0684]
trainer/QF1 Loss               72.219376
trainer/QF2 Loss               72.28337
trainer/Policy Loss            -8.000929
trainer/Q1 Predictions Mean    -0.0013547997
trainer/Q1 Predictions Std     0.0016003018
trainer/Q1 Predictions Max     0.0037402823
trainer/Q1 Predictions Min     -0.0064011402
trainer/Q2 Predictions Mean    -0.005132518
trainer/Q2 Predictions Std     0.0021193286
trainer/Q2 Predictions Max     0.0013050989
trainer/Q2 Predictions Min     -0.011479562
trainer/Q Targets Mean         8.466261
trainer/Q Targets Std          0.7202864
trainer/Q Targets Max          10.413342
trainer/Q Targets Min          6.0932117
trainer/Log Pis Mean           -8.006192
trainer/Log Pis Std            0.73511356
trainer/Log Pis Max            -6.083276
trainer/Log Pis Min            -9.819128
trainer/Policy mu Mean         0.00041091166
trainer/Policy mu Std          0.0011987145
trainer/Policy mu Max          0.0037607835
trainer/Policy mu Min          -0.003149306
trainer/Policy log std Mean    -0.00021145698
trainer/Policy log std Std     0.00094351365
trainer/Policy log std Max     0.0026460225
trainer/Policy log std Min     -0.0029323886
trainer/Alpha                  0.9997000694274902
trainer/Alpha Loss             -0.0
exploration/num steps total    6000
exploration/num paths total    12
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.43135745173926615
exploration/Rewards Std        0.08796293373276924
exploration/Rewards Max        0.6705582651051656
exploration/Rewards Min        0.18701781528381597
exploration/Returns Mean       215.67872586963304
exploration/Returns Std        24.15985421873657
exploration/Returns Max        246.32019501362845
exploration/Returns Min        175.14528742787692
exploration/Actions Mean       -0.0018616616
exploration/Actions Std        0.6283505
exploration/Actions Max        0.99980986
exploration/Actions Min        -0.99971867
exploration/Num Paths          10
exploration/Average Returns    215.67872586963304
evaluation/num steps total     5000
evaluation/num paths total     10
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5082743749712627
evaluation/Rewards Std         0.010128786976371243
evaluation/Rewards Max         0.5234277457110493
evaluation/Rewards Min         0.48600323994580574
evaluation/Returns Mean        254.13718748563124
evaluation/Returns Std         5.017829641071736
evaluation/Returns Max         261.18657811497025
evaluation/Returns Min         244.47504017700675
evaluation/ExplReturns Mean    254.13718748563124
evaluation/ExplReturns Std     5.017829641071736
evaluation/ExplReturns Max     261.18657811497025
evaluation/ExplReturns Min     244.47504017700675
evaluation/Actions Mean        0.0002760067
evaluation/Actions Std         0.0012767304
evaluation/Actions Max         0.0026042091
evaluation/Actions Min         -0.0025641825
evaluation/Num Paths           10
evaluation/Average Returns     254.13718748563124
time/data storing (s)          0.03463098406791687
time/evaluation sampling (s)   107.93239214736968
time/exploration sampling (s)  110.69361831434071
time/logging (s)               0.0313413767144084
time/saving (s)                0.017901980318129063
time/training (s)              9.71631112974137
time/epoch (s)                 228.42619593255222
time/total (s)                 258.62162541411817
Epoch                          0
-----------------------------  --------------------
2023-07-31 18:02:19.312603 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 1 finished
-----------------------------  --------------------
replay_buffer/size             11000
trainer/tdrp Loss              [4789.483]
trainer/QF1 Loss               0.09905177
trainer/QF2 Loss               0.100026265
trainer/Policy Loss            -39.235573
trainer/Q1 Predictions Mean    31.041218
trainer/Q1 Predictions Std     0.8298982
trainer/Q1 Predictions Max     32.975613
trainer/Q1 Predictions Min     27.581984
trainer/Q2 Predictions Mean    31.040527
trainer/Q2 Predictions Std     0.82720846
trainer/Q2 Predictions Max     32.974056
trainer/Q2 Predictions Min     27.824396
trainer/Q Targets Mean         31.04816
trainer/Q Targets Std          0.7653662
trainer/Q Targets Max          32.79669
trainer/Q Targets Min          28.004322
trainer/Log Pis Mean           -8.220513
trainer/Log Pis Std            0.36505952
trainer/Log Pis Max            -7.386205
trainer/Log Pis Min            -10.022607
trainer/Policy mu Mean         0.0023566573
trainer/Policy mu Std          0.0101730805
trainer/Policy mu Max          0.030736808
trainer/Policy mu Min          -0.014392699
trainer/Policy log std Mean    -0.12927116
trainer/Policy log std Std     0.007792799
trainer/Policy log std Max     -0.106236175
trainer/Policy log std Min     -0.15945585
trainer/Alpha                  0.7405495643615723
trainer/Alpha Loss             -6.067422389984131
exploration/num steps total    11000
exploration/num paths total    22
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.44129563372711855
exploration/Rewards Std        0.08675101593585662
exploration/Rewards Max        0.6800115163470591
exploration/Rewards Min        0.19441933849941936
exploration/Returns Mean       220.64781686355929
exploration/Returns Std        22.628037734092533
exploration/Returns Max        247.36410000954456
exploration/Returns Min        173.08585814814498
exploration/Actions Mean       0.001204132
exploration/Actions Std        0.5901811
exploration/Actions Max        0.99881935
exploration/Actions Min        -0.99894196
exploration/Num Paths          10
exploration/Average Returns    220.64781686355929
evaluation/num steps total     10000
evaluation/num paths total     20
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5552856712891339
evaluation/Rewards Std         0.025669574114627294
evaluation/Rewards Max         0.6043920994490495
evaluation/Rewards Min         0.4968556755563621
evaluation/Returns Mean        277.6428356445669
evaluation/Returns Std         2.2745942310891745
evaluation/Returns Max         280.85408614857795
evaluation/Returns Min         274.68872012404665
evaluation/ExplReturns Mean    277.6428356445669
evaluation/ExplReturns Std     2.2745942310891745
evaluation/ExplReturns Max     280.85408614857795
evaluation/ExplReturns Min     274.68872012404665
evaluation/Actions Mean        0.002562021
evaluation/Actions Std         0.010811372
evaluation/Actions Max         0.027854992
evaluation/Actions Min         -0.00788619
evaluation/Num Paths           10
evaluation/Average Returns     277.6428356445669
time/data storing (s)          0.03350947890430689
time/evaluation sampling (s)   111.71701908484101
time/exploration sampling (s)  111.29017698485404
time/logging (s)               0.032031127251684666
time/saving (s)                0.011625884100794792
time/training (s)              9.553210048936307
time/epoch (s)                 232.63757260888815
time/total (s)                 491.261913347058
Epoch                          1
-----------------------------  --------------------
2023-07-31 18:06:11.133715 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 2 finished
-----------------------------  --------------------
replay_buffer/size             16000
trainer/tdrp Loss              [4780.1777]
trainer/QF1 Loss               0.09300113
trainer/QF2 Loss               0.088704616
trainer/Policy Loss            -62.37817
trainer/Q1 Predictions Mean    54.20865
trainer/Q1 Predictions Std     1.3375227
trainer/Q1 Predictions Max     57.84509
trainer/Q1 Predictions Min     50.200138
trainer/Q2 Predictions Mean    54.205734
trainer/Q2 Predictions Std     1.3215104
trainer/Q2 Predictions Max     57.608387
trainer/Q2 Predictions Min     50.106533
trainer/Q Targets Mean         54.14762
trainer/Q Targets Std          1.3073721
trainer/Q Targets Max          57.849674
trainer/Q Targets Min          50.246227
trainer/Log Pis Mean           -8.21722
trainer/Log Pis Std            0.3846833
trainer/Log Pis Max            -7.2434077
trainer/Log Pis Min            -10.035196
trainer/Policy mu Mean         0.007840636
trainer/Policy mu Std          0.019450622
trainer/Policy mu Max          0.061967075
trainer/Policy mu Min          -0.03711382
trainer/Policy log std Mean    -0.12698908
trainer/Policy log std Std     0.007412612
trainer/Policy log std Max     -0.104578845
trainer/Policy log std Min     -0.14902852
trainer/Alpha                  0.5486050844192505
trainer/Alpha Loss             -12.131875038146973
exploration/num steps total    16000
exploration/num paths total    32
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4601385861365142
exploration/Rewards Std        0.0743014747324379
exploration/Rewards Max        0.6882028459623689
exploration/Rewards Min        0.2665165904737287
exploration/Returns Mean       230.06929306825705
exploration/Returns Std        18.112499470107778
exploration/Returns Max        260.6536654345744
exploration/Returns Min        198.93774297021173
exploration/Actions Mean       0.0065473677
exploration/Actions Std        0.59183383
exploration/Actions Max        0.99920404
exploration/Actions Min        -0.99829286
exploration/Num Paths          10
exploration/Average Returns    230.06929306825705
evaluation/num steps total     15000
evaluation/num paths total     30
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5179865434823295
evaluation/Rewards Std         0.01382130594475632
evaluation/Rewards Max         0.5483077159736602
evaluation/Rewards Min         0.487912490357167
evaluation/Returns Mean        258.99327174116473
evaluation/Returns Std         2.1218294311877695
evaluation/Returns Max         262.3563022872667
evaluation/Returns Min         256.27598460906455
evaluation/ExplReturns Mean    258.99327174116473
evaluation/ExplReturns Std     2.1218294311877695
evaluation/ExplReturns Max     262.3563022872667
evaluation/ExplReturns Min     256.27598460906455
evaluation/Actions Mean        0.0066660554
evaluation/Actions Std         0.019888371
evaluation/Actions Max         0.04710123
evaluation/Actions Min         -0.030630682
evaluation/Num Paths           10
evaluation/Average Returns     258.99327174116473
time/data storing (s)          0.034235441125929356
time/evaluation sampling (s)   111.75830268487334
time/exploration sampling (s)  110.4299140535295
time/logging (s)               0.030375372618436813
time/saving (s)                0.012009401805698872
time/training (s)              9.550834448076785
time/epoch (s)                 231.8156714020297
time/total (s)                 723.0806695697829
Epoch                          2
-----------------------------  --------------------
2023-07-31 18:10:03.151182 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 3 finished
-----------------------------  --------------------
replay_buffer/size             21000
trainer/tdrp Loss              [4778.761]
trainer/QF1 Loss               0.08001613
trainer/QF2 Loss               0.07309218
trainer/Policy Loss            -79.08648
trainer/Q1 Predictions Mean    70.941826
trainer/Q1 Predictions Std     1.6043532
trainer/Q1 Predictions Max     75.91565
trainer/Q1 Predictions Min     66.79019
trainer/Q2 Predictions Mean    70.93421
trainer/Q2 Predictions Std     1.5809654
trainer/Q2 Predictions Max     75.55894
trainer/Q2 Predictions Min     66.85321
trainer/Q Targets Mean         70.893936
trainer/Q Targets Std          1.5958725
trainer/Q Targets Max          75.45295
trainer/Q Targets Min          66.8963
trainer/Log Pis Mean           -8.182057
trainer/Log Pis Std            0.49660355
trainer/Log Pis Max            -7.132777
trainer/Log Pis Min            -11.011673
trainer/Policy mu Mean         0.010342651
trainer/Policy mu Std          0.03628325
trainer/Policy mu Max          0.11217039
trainer/Policy mu Min          -0.07598011
trainer/Policy log std Mean    -0.13151515
trainer/Policy log std Std     0.0090189865
trainer/Policy log std Max     -0.100819185
trainer/Policy log std Min     -0.16140428
trainer/Alpha                  0.4064357876777649
trainer/Alpha Loss             -18.164447784423828
exploration/num steps total    21000
exploration/num paths total    42
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.462047894435641
exploration/Rewards Std        0.08618005517886053
exploration/Rewards Max        0.6798342196258302
exploration/Rewards Min        0.17943719310513312
exploration/Returns Mean       231.02394721782048
exploration/Returns Std        20.367825379075644
exploration/Returns Max        266.5431218037846
exploration/Returns Min        199.24424590008476
exploration/Actions Mean       0.0075396094
exploration/Actions Std        0.59131527
exploration/Actions Max        0.99815613
exploration/Actions Min        -0.99882644
exploration/Num Paths          10
exploration/Average Returns    231.02394721782048
evaluation/num steps total     20000
evaluation/num paths total     40
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6192586081535217
evaluation/Rewards Std         0.058265553759431814
evaluation/Rewards Max         0.7270149148923558
evaluation/Rewards Min         0.4487302438949421
evaluation/Returns Mean        309.62930407676083
evaluation/Returns Std         8.779099190345494
evaluation/Returns Max         319.76101344938627
evaluation/Returns Min         294.6544860354194
evaluation/ExplReturns Mean    309.62930407676083
evaluation/ExplReturns Std     8.779099190345494
evaluation/ExplReturns Max     319.76101344938627
evaluation/ExplReturns Min     294.6544860354194
evaluation/Actions Mean        -0.0010705382
evaluation/Actions Std         0.031289488
evaluation/Actions Max         0.061946843
evaluation/Actions Min         -0.070626885
evaluation/Num Paths           10
evaluation/Average Returns     309.62930407676083
time/data storing (s)          0.03348137065768242
time/evaluation sampling (s)   112.00411965418607
time/exploration sampling (s)  110.39311282802373
time/logging (s)               0.033459111116826534
time/saving (s)                0.011893857270479202
time/training (s)              9.541340439580381
time/epoch (s)                 232.01740726083517
time/total (s)                 955.1005570152774
Epoch                          3
-----------------------------  --------------------
2023-07-31 18:13:56.376530 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 4 finished
-----------------------------  --------------------
replay_buffer/size             26000
trainer/tdrp Loss              [4756.0547]
trainer/QF1 Loss               0.07568254
trainer/QF2 Loss               0.076838985
trainer/Policy Loss            -90.88971
trainer/Q1 Predictions Mean    82.70687
trainer/Q1 Predictions Std     1.7956966
trainer/Q1 Predictions Max     87.32535
trainer/Q1 Predictions Min     78.17769
trainer/Q2 Predictions Mean    82.72928
trainer/Q2 Predictions Std     1.7794597
trainer/Q2 Predictions Max     87.092896
trainer/Q2 Predictions Min     78.287094
trainer/Q Targets Mean         82.5815
trainer/Q Targets Std          1.7560416
trainer/Q Targets Max          86.7558
trainer/Q Targets Min          77.65465
trainer/Log Pis Mean           -8.206913
trainer/Log Pis Std            0.5333608
trainer/Log Pis Max            -6.601125
trainer/Log Pis Min            -11.00034
trainer/Policy mu Mean         0.010106938
trainer/Policy mu Std          0.07042166
trainer/Policy mu Max          0.28451297
trainer/Policy mu Min          -0.18954813
trainer/Policy log std Mean    -0.1324907
trainer/Policy log std Std     0.009136354
trainer/Policy log std Max     -0.10252996
trainer/Policy log std Min     -0.18305762
trainer/Alpha                  0.3011459410190582
trainer/Alpha Loss             -24.24547576904297
exploration/num steps total    26000
exploration/num paths total    52
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5013401692536816
exploration/Rewards Std        0.08548516094485689
exploration/Rewards Max        0.6917691873815016
exploration/Rewards Min        0.16420478762138824
exploration/Returns Mean       250.6700846268408
exploration/Returns Std        25.029989597882146
exploration/Returns Max        277.0481412453832
exploration/Returns Min        195.57477457196126
exploration/Actions Mean       0.0070535503
exploration/Actions Std        0.5915859
exploration/Actions Max        0.9991359
exploration/Actions Min        -0.9994149
exploration/Num Paths          10
exploration/Average Returns    250.6700846268408
evaluation/num steps total     25000
evaluation/num paths total     50
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5123853897128587
evaluation/Rewards Std         0.07110658844347995
evaluation/Rewards Max         0.6369358644168592
evaluation/Rewards Min         0.33654752523991843
evaluation/Returns Mean        256.1926948564294
evaluation/Returns Std         22.404466671064434
evaluation/Returns Max         289.4832377110181
evaluation/Returns Min         211.70197945981974
evaluation/ExplReturns Mean    256.1926948564294
evaluation/ExplReturns Std     22.404466671064434
evaluation/ExplReturns Max     289.4832377110181
evaluation/ExplReturns Min     211.70197945981974
evaluation/Actions Mean        0.0002420781
evaluation/Actions Std         0.05747009
evaluation/Actions Max         0.14349136
evaluation/Actions Min         -0.15179282
evaluation/Num Paths           10
evaluation/Average Returns     256.1926948564294
time/data storing (s)          0.034220634028315544
time/evaluation sampling (s)   113.76406692806631
time/exploration sampling (s)  110.44892424158752
time/logging (s)               0.030475884675979614
time/saving (s)                0.011158233508467674
time/training (s)              8.930289477109909
time/epoch (s)                 233.2191353989765
time/total (s)                 1188.3222565697506
Epoch                          4
-----------------------------  --------------------
2023-07-31 18:17:52.377460 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 5 finished
-----------------------------  --------------------
replay_buffer/size             31000
trainer/tdrp Loss              [4757.625]
trainer/QF1 Loss               0.11107738
trainer/QF2 Loss               0.08396745
trainer/Policy Loss            -98.277725
trainer/Q1 Predictions Mean    90.12019
trainer/Q1 Predictions Std     2.186057
trainer/Q1 Predictions Max     94.90305
trainer/Q1 Predictions Min     84.82646
trainer/Q2 Predictions Mean    90.17955
trainer/Q2 Predictions Std     2.1756978
trainer/Q2 Predictions Max     94.94653
trainer/Q2 Predictions Min     85.11306
trainer/Q Targets Mean         90.256546
trainer/Q Targets Std          2.1914706
trainer/Q Targets Max          95.044716
trainer/Q Targets Min          85.228775
trainer/Log Pis Mean           -8.160603
trainer/Log Pis Std            0.5996945
trainer/Log Pis Max            -6.502818
trainer/Log Pis Min            -11.042866
trainer/Policy mu Mean         -0.0042075478
trainer/Policy mu Std          0.10012931
trainer/Policy mu Max          0.31645882
trainer/Policy mu Min          -0.36290872
trainer/Policy log std Mean    -0.12769698
trainer/Policy log std Std     0.009883536
trainer/Policy log std Max     -0.095671065
trainer/Policy log std Min     -0.16267234
trainer/Alpha                  0.22319748997688293
trainer/Alpha Loss             -30.22878646850586
exploration/num steps total    31000
exploration/num paths total    62
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.47930532424724254
exploration/Rewards Std        0.10318373787674615
exploration/Rewards Max        0.7333385713362928
exploration/Rewards Min        0.17279453037469686
exploration/Returns Mean       239.6526621236213
exploration/Returns Std        31.308345652575433
exploration/Returns Max        285.7538458350766
exploration/Returns Min        165.804018679515
exploration/Actions Mean       -0.0014523725
exploration/Actions Std        0.5913783
exploration/Actions Max        0.9993835
exploration/Actions Min        -0.9998843
exploration/Num Paths          10
exploration/Average Returns    239.6526621236213
evaluation/num steps total     30000
evaluation/num paths total     60
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4444733816049062
evaluation/Rewards Std         0.07950702045915463
evaluation/Rewards Max         0.6189403334990051
evaluation/Rewards Min         0.24718109938209537
evaluation/Returns Mean        222.23669080245304
evaluation/Returns Std         20.991727120312785
evaluation/Returns Max         256.22774552952933
evaluation/Returns Min         198.62719865705347
evaluation/ExplReturns Mean    222.23669080245304
evaluation/ExplReturns Std     20.991727120312785
evaluation/ExplReturns Max     256.22774552952933
evaluation/ExplReturns Min     198.62719865705347
evaluation/Actions Mean        -0.0075232484
evaluation/Actions Std         0.07769944
evaluation/Actions Max         0.18349592
evaluation/Actions Min         -0.23635514
evaluation/Num Paths           10
evaluation/Average Returns     222.23669080245304
time/data storing (s)          0.03362858481705189
time/evaluation sampling (s)   115.85617959778756
time/exploration sampling (s)  110.5813229419291
time/logging (s)               0.0312228761613369
time/saving (s)                0.011741193011403084
time/training (s)              9.484524625353515
time/epoch (s)                 235.99861981905997
time/total (s)                 1424.323284478858
Epoch                          5
-----------------------------  --------------------
2023-07-31 18:21:44.174683 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 6 finished
-----------------------------  --------------------
replay_buffer/size             36000
trainer/tdrp Loss              [4763.5234]
trainer/QF1 Loss               0.09462373
trainer/QF2 Loss               0.081416965
trainer/Policy Loss            -103.72319
trainer/Q1 Predictions Mean    95.788055
trainer/Q1 Predictions Std     2.5302804
trainer/Q1 Predictions Max     103.6266
trainer/Q1 Predictions Min     89.75765
trainer/Q2 Predictions Mean    95.75456
trainer/Q2 Predictions Std     2.5147653
trainer/Q2 Predictions Max     103.77326
trainer/Q2 Predictions Min     89.88297
trainer/Q Targets Mean         95.67043
trainer/Q Targets Std          2.5129542
trainer/Q Targets Max          103.6118
trainer/Q Targets Min          89.88592
trainer/Log Pis Mean           -7.9716043
trainer/Log Pis Std            0.7329889
trainer/Log Pis Max            -5.4788303
trainer/Log Pis Min            -10.314665
trainer/Policy mu Mean         -0.0042139823
trainer/Policy mu Std          0.16346787
trainer/Policy mu Max          0.54739803
trainer/Policy mu Min          -0.5972183
trainer/Policy log std Mean    -0.13467185
trainer/Policy log std Std     0.015663194
trainer/Policy log std Max     -0.09501435
trainer/Policy log std Min     -0.21716696
trainer/Alpha                  0.16551107168197632
trainer/Alpha Loss             -35.91730880737305
exploration/num steps total    36000
exploration/num paths total    72
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.47991181380478226
exploration/Rewards Std        0.07480678037995116
exploration/Rewards Max        0.7110088781190105
exploration/Rewards Min        0.27868315517214487
exploration/Returns Mean       239.95590690239118
exploration/Returns Std        13.99568708437404
exploration/Returns Max        270.79333256949235
exploration/Returns Min        221.47900015708137
exploration/Actions Mean       0.007625193
exploration/Actions Std        0.59241515
exploration/Actions Max        0.9988142
exploration/Actions Min        -0.9987823
exploration/Num Paths          10
exploration/Average Returns    239.95590690239118
evaluation/num steps total     35000
evaluation/num paths total     70
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5221870353390453
evaluation/Rewards Std         0.11599778310261728
evaluation/Rewards Max         0.6934865229502645
evaluation/Rewards Min         0.19177311883603948
evaluation/Returns Mean        261.0935176695226
evaluation/Returns Std         27.881207970069276
evaluation/Returns Max         291.53157760403394
evaluation/Returns Min         203.68545724601253
evaluation/ExplReturns Mean    261.0935176695226
evaluation/ExplReturns Std     27.881207970069276
evaluation/ExplReturns Max     291.53157760403394
evaluation/ExplReturns Min     203.68545724601253
evaluation/Actions Mean        0.0007926379
evaluation/Actions Std         0.12027481
evaluation/Actions Max         0.5051248
evaluation/Actions Min         -0.4319407
evaluation/Num Paths           10
evaluation/Average Returns     261.0935176695226
time/data storing (s)          0.033374289982020855
time/evaluation sampling (s)   111.46362127736211
time/exploration sampling (s)  110.47327751480043
time/logging (s)               0.03157186508178711
time/saving (s)                0.01103272009640932
time/training (s)              9.780941815115511
time/epoch (s)                 231.79381948243827
time/total (s)                 1656.1201858911663
Epoch                          6
-----------------------------  --------------------
2023-07-31 18:25:37.239474 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 7 finished
-----------------------------  --------------------
replay_buffer/size             41000
trainer/tdrp Loss              [4716.4146]
trainer/QF1 Loss               0.119256504
trainer/QF2 Loss               0.11534754
trainer/Policy Loss            -106.03201
trainer/Q1 Predictions Mean    98.204926
trainer/Q1 Predictions Std     3.054734
trainer/Q1 Predictions Max     109.37198
trainer/Q1 Predictions Min     86.93141
trainer/Q2 Predictions Mean    98.21245
trainer/Q2 Predictions Std     3.060908
trainer/Q2 Predictions Max     109.52702
trainer/Q2 Predictions Min     87.04755
trainer/Q Targets Mean         98.30472
trainer/Q Targets Std          3.0856469
trainer/Q Targets Max          109.05461
trainer/Q Targets Min          87.520584
trainer/Log Pis Mean           -7.8278522
trainer/Log Pis Std            1.005947
trainer/Log Pis Max            -4.5638423
trainer/Log Pis Min            -10.622152
trainer/Policy mu Mean         0.00040775942
trainer/Policy mu Std          0.22500451
trainer/Policy mu Max          0.64843845
trainer/Policy mu Min          -0.9235057
trainer/Policy log std Mean    -0.1292879
trainer/Policy log std Std     0.020439392
trainer/Policy log std Max     -0.07619594
trainer/Policy log std Min     -0.25024986
trainer/Alpha                  0.1228465586900711
trainer/Alpha Loss             -41.569515228271484
exploration/num steps total    41000
exploration/num paths total    82
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.46579076147993626
exploration/Rewards Std        0.0883397932018661
exploration/Rewards Max        0.684932175811657
exploration/Rewards Min        0.2051345229420022
exploration/Returns Mean       232.89538073996815
exploration/Returns Std        24.62242447640191
exploration/Returns Max        280.3956954332745
exploration/Returns Min        201.40244406746265
exploration/Actions Mean       0.011557252
exploration/Actions Std        0.59777826
exploration/Actions Max        0.9989686
exploration/Actions Min        -0.99933344
exploration/Num Paths          10
exploration/Average Returns    232.89538073996815
evaluation/num steps total     40000
evaluation/num paths total     80
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.47347917345974894
evaluation/Rewards Std         0.14417443390106668
evaluation/Rewards Max         0.7113561042006781
evaluation/Rewards Min         0.0860372504188382
evaluation/Returns Mean        236.73958672987447
evaluation/Returns Std         47.12957862973976
evaluation/Returns Max         307.0162734335233
evaluation/Returns Min         166.5534351326144
evaluation/ExplReturns Mean    236.73958672987447
evaluation/ExplReturns Std     47.12957862973976
evaluation/ExplReturns Max     307.0162734335233
evaluation/ExplReturns Min     166.5534351326144
evaluation/Actions Mean        0.004931892
evaluation/Actions Std         0.15237886
evaluation/Actions Max         0.54710877
evaluation/Actions Min         -0.66287184
evaluation/Num Paths           10
evaluation/Average Returns     236.73958672987447
time/data storing (s)          0.0337942810729146
time/evaluation sampling (s)   112.07729691732675
time/exploration sampling (s)  111.54985754750669
time/logging (s)               0.030676472932100296
time/saving (s)                0.011631319299340248
time/training (s)              9.357445346191525
time/epoch (s)                 233.06070188432932
time/total (s)                 1889.1834071381018
Epoch                          7
-----------------------------  --------------------
2023-07-31 18:29:26.635076 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 8 finished
-----------------------------  --------------------
replay_buffer/size             46000
trainer/tdrp Loss              [4735.1694]
trainer/QF1 Loss               0.12878986
trainer/QF2 Loss               0.1196836
trainer/Policy Loss            -108.275276
trainer/Q1 Predictions Mean    100.749374
trainer/Q1 Predictions Std     3.598932
trainer/Q1 Predictions Max     113.624374
trainer/Q1 Predictions Min     90.825386
trainer/Q2 Predictions Mean    100.70749
trainer/Q2 Predictions Std     3.6039698
trainer/Q2 Predictions Max     113.59514
trainer/Q2 Predictions Min     90.852776
trainer/Q Targets Mean         100.70102
trainer/Q Targets Std          3.6289742
trainer/Q Targets Max          113.3763
trainer/Q Targets Min          90.30609
trainer/Log Pis Mean           -7.5300946
trainer/Log Pis Std            1.194567
trainer/Log Pis Max            -4.1804705
trainer/Log Pis Min            -10.678433
trainer/Policy mu Mean         0.011886195
trainer/Policy mu Std          0.28146428
trainer/Policy mu Max          1.0760609
trainer/Policy mu Min          -1.0019423
trainer/Policy log std Mean    -0.13349223
trainer/Policy log std Std     0.028644582
trainer/Policy log std Max     -0.06445338
trainer/Policy log std Min     -0.27759296
trainer/Alpha                  0.09128685295581818
trainer/Alpha Loss             -46.744354248046875
exploration/num steps total    46000
exploration/num paths total    92
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.43917338628749475
exploration/Rewards Std        0.0919845090659698
exploration/Rewards Max        0.690378204288295
exploration/Rewards Min        0.15765273891164866
exploration/Returns Mean       219.58669314374728
exploration/Returns Std        22.02807368877415
exploration/Returns Max        254.791647937538
exploration/Returns Min        190.20897887801524
exploration/Actions Mean       0.017694185
exploration/Actions Std        0.6000829
exploration/Actions Max        0.99927163
exploration/Actions Min        -0.99963194
exploration/Num Paths          10
exploration/Average Returns    219.58669314374728
evaluation/num steps total     45000
evaluation/num paths total     90
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4346706060583377
evaluation/Rewards Std         0.14526684064367576
evaluation/Rewards Max         0.9669159414284079
evaluation/Rewards Min         0.10190487916237437
evaluation/Returns Mean        217.33530302916878
evaluation/Returns Std         28.446974346413487
evaluation/Returns Max         259.33799788364786
evaluation/Returns Min         174.3090456242257
evaluation/ExplReturns Mean    217.33530302916878
evaluation/ExplReturns Std     28.446974346413487
evaluation/ExplReturns Max     259.33799788364786
evaluation/ExplReturns Min     174.3090456242257
evaluation/Actions Mean        0.007432644
evaluation/Actions Std         0.21635526
evaluation/Actions Max         0.8526441
evaluation/Actions Min         -0.83880544
evaluation/Num Paths           10
evaluation/Average Returns     217.33530302916878
time/data storing (s)          0.03421211615204811
time/evaluation sampling (s)   109.22925217170268
time/exploration sampling (s)  110.7988717444241
time/logging (s)               0.03125340677797794
time/saving (s)                0.010680756531655788
time/training (s)              9.28870802745223
time/epoch (s)                 229.3929782230407
time/total (s)                 2118.5789049426094
Epoch                          8
-----------------------------  --------------------
2023-07-31 18:33:17.698281 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 9 finished
-----------------------------  --------------------
replay_buffer/size             51000
trainer/tdrp Loss              [4724.264]
trainer/QF1 Loss               0.13013546
trainer/QF2 Loss               0.12914987
trainer/Policy Loss            -108.19847
trainer/Q1 Predictions Mean    101.29854
trainer/Q1 Predictions Std     3.3560977
trainer/Q1 Predictions Max     113.87377
trainer/Q1 Predictions Min     94.57807
trainer/Q2 Predictions Mean    101.25775
trainer/Q2 Predictions Std     3.3685622
trainer/Q2 Predictions Max     114.018166
trainer/Q2 Predictions Min     94.26736
trainer/Q Targets Mean         101.29094
trainer/Q Targets Std          3.3617737
trainer/Q Targets Max          114.60995
trainer/Q Targets Min          94.39387
trainer/Log Pis Mean           -6.840016
trainer/Log Pis Std            1.7560865
trainer/Log Pis Max            -0.72922754
trainer/Log Pis Min            -11.27317
trainer/Policy mu Mean         0.0064930134
trainer/Policy mu Std          0.39439994
trainer/Policy mu Max          1.1882896
trainer/Policy mu Min          -1.3506196
trainer/Policy log std Mean    -0.14400369
trainer/Policy log std Std     0.045241788
trainer/Policy log std Max     -0.057600163
trainer/Policy log std Min     -0.38225287
trainer/Alpha                  0.06796859949827194
trainer/Alpha Loss             -50.649818420410156
exploration/num steps total    51000
exploration/num paths total    102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.444024210869343
exploration/Rewards Std        0.07944963091939657
exploration/Rewards Max        0.6748049787208626
exploration/Rewards Min        0.20627342569884594
exploration/Returns Mean       222.0121054346715
exploration/Returns Std        12.421387043530501
exploration/Returns Max        242.07850069346907
exploration/Returns Min        205.33546045315907
exploration/Actions Mean       0.01344283
exploration/Actions Std        0.6090212
exploration/Actions Max        0.9990757
exploration/Actions Min        -0.99894446
exploration/Num Paths          10
exploration/Average Returns    222.0121054346715
evaluation/num steps total     50000
evaluation/num paths total     100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.37894197404990193
evaluation/Rewards Std         0.10707507126823121
evaluation/Rewards Max         0.6811207245399032
evaluation/Rewards Min         0.11469347946570874
evaluation/Returns Mean        189.47098702495097
evaluation/Returns Std         14.238890011583486
evaluation/Returns Max         209.8806648451879
evaluation/Returns Min         168.24670464551963
evaluation/ExplReturns Mean    189.47098702495097
evaluation/ExplReturns Std     14.238890011583486
evaluation/ExplReturns Max     209.8806648451879
evaluation/ExplReturns Min     168.24670464551963
evaluation/Actions Mean        0.015603302
evaluation/Actions Std         0.26910374
evaluation/Actions Max         0.8346216
evaluation/Actions Min         -0.84361446
evaluation/Num Paths           10
evaluation/Average Returns     189.47098702495097
time/data storing (s)          0.033884516917169094
time/evaluation sampling (s)   111.08265075646341
time/exploration sampling (s)  110.73232534062117
time/logging (s)               0.030430124141275883
time/saving (s)                0.011906834319233894
time/training (s)              9.168040471151471
time/epoch (s)                 231.05923804361373
time/total (s)                 2349.640618064441
Epoch                          9
-----------------------------  --------------------
2023-07-31 18:37:06.505595 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 10 finished
-----------------------------  --------------------
replay_buffer/size             56000
trainer/tdrp Loss              [4688.7183]
trainer/QF1 Loss               0.21814248
trainer/QF2 Loss               0.19653243
trainer/Policy Loss            -107.368935
trainer/Q1 Predictions Mean    100.88771
trainer/Q1 Predictions Std     3.6319857
trainer/Q1 Predictions Max     114.41734
trainer/Q1 Predictions Min     92.43184
trainer/Q2 Predictions Mean    100.80252
trainer/Q2 Predictions Std     3.647359
trainer/Q2 Predictions Max     114.95884
trainer/Q2 Predictions Min     92.321846
trainer/Q Targets Mean         100.78642
trainer/Q Targets Std          3.6449423
trainer/Q Targets Max          114.75971
trainer/Q Targets Min          91.95163
trainer/Log Pis Mean           -6.4644957
trainer/Log Pis Std            1.8789207
trainer/Log Pis Max            -1.65891
trainer/Log Pis Min            -11.704502
trainer/Policy mu Mean         0.034743354
trainer/Policy mu Std          0.46358177
trainer/Policy mu Max          1.5958072
trainer/Policy mu Min          -1.3891138
trainer/Policy log std Mean    -0.1511416
trainer/Policy log std Std     0.059253246
trainer/Policy log std Max     -0.036017522
trainer/Policy log std Min     -0.51270515
trainer/Alpha                  0.050727445632219315
trainer/Alpha Loss             -55.042633056640625
exploration/num steps total    56000
exploration/num paths total    112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.459475657689493
exploration/Rewards Std        0.0960959431981239
exploration/Rewards Max        0.6850176099670197
exploration/Rewards Min        0.1472694592197285
exploration/Returns Mean       229.73782884474653
exploration/Returns Std        16.876631403481973
exploration/Returns Max        249.41985549095747
exploration/Returns Min        198.280912477717
exploration/Actions Mean       0.031314746
exploration/Actions Std        0.61852
exploration/Actions Max        0.9990024
exploration/Actions Min        -0.99912536
exploration/Num Paths          10
exploration/Average Returns    229.73782884474653
evaluation/num steps total     55000
evaluation/num paths total     110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.3812662596289
evaluation/Rewards Std         0.1342486534180516
evaluation/Rewards Max         0.7121672923927997
evaluation/Rewards Min         0.0677689411792551
evaluation/Returns Mean        190.63312981445003
evaluation/Returns Std         24.17344416960752
evaluation/Returns Max         249.50738097863305
evaluation/Returns Min         160.268193816049
evaluation/ExplReturns Mean    190.63312981445003
evaluation/ExplReturns Std     24.17344416960752
evaluation/ExplReturns Max     249.50738097863305
evaluation/ExplReturns Min     160.268193816049
evaluation/Actions Mean        0.029370574
evaluation/Actions Std         0.3332364
evaluation/Actions Max         0.9379385
evaluation/Actions Min         -0.9234042
evaluation/Num Paths           10
evaluation/Average Returns     190.63312981445003
time/data storing (s)          0.03329928498715162
time/evaluation sampling (s)   108.98768002074212
time/exploration sampling (s)  110.37592360191047
time/logging (s)               0.030528447590768337
time/saving (s)                0.012878743931651115
time/training (s)              9.363871038891375
time/epoch (s)                 228.80418113805354
time/total (s)                 2578.447360545397
Epoch                          10
-----------------------------  --------------------
2023-07-31 18:40:54.945864 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 11 finished
-----------------------------  --------------------
replay_buffer/size             61000
trainer/tdrp Loss              [4652.732]
trainer/QF1 Loss               0.2269558
trainer/QF2 Loss               0.21210602
trainer/Policy Loss            -106.02643
trainer/Q1 Predictions Mean    100.50188
trainer/Q1 Predictions Std     4.1555457
trainer/Q1 Predictions Max     112.50786
trainer/Q1 Predictions Min     90.34709
trainer/Q2 Predictions Mean    100.50476
trainer/Q2 Predictions Std     4.1471195
trainer/Q2 Predictions Max     112.26427
trainer/Q2 Predictions Min     90.60746
trainer/Q Targets Mean         100.34854
trainer/Q Targets Std          4.1890993
trainer/Q Targets Max          111.86455
trainer/Q Targets Min          90.59993
trainer/Log Pis Mean           -5.420486
trainer/Log Pis Std            2.2816386
trainer/Log Pis Max            0.9729649
trainer/Log Pis Min            -10.856903
trainer/Policy mu Mean         0.032034073
trainer/Policy mu Std          0.5884991
trainer/Policy mu Max          1.6486242
trainer/Policy mu Min          -1.759677
trainer/Policy log std Mean    -0.17275642
trainer/Policy log std Std     0.07270123
trainer/Policy log std Max     -0.02118301
trainer/Policy log std Min     -0.4990218
trainer/Alpha                  0.038011059165000916
trainer/Alpha Loss             -56.957923889160156
exploration/num steps total    61000
exploration/num paths total    122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4032620874453449
exploration/Rewards Std        0.09691833815440425
exploration/Rewards Max        0.6854259063649811
exploration/Rewards Min        0.11516389608295008
exploration/Returns Mean       201.6310437226724
exploration/Returns Std        11.01882058829048
exploration/Returns Max        213.22030964784136
exploration/Returns Min        181.73927184862407
exploration/Actions Mean       0.023027124
exploration/Actions Std        0.634723
exploration/Actions Max        0.9987988
exploration/Actions Min        -0.99930024
exploration/Num Paths          10
exploration/Average Returns    201.6310437226724
evaluation/num steps total     60000
evaluation/num paths total     120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.43032979962308215
evaluation/Rewards Std         0.10042467909439741
evaluation/Rewards Max         0.7128712437245911
evaluation/Rewards Min         0.14613253426679093
evaluation/Returns Mean        215.1648998115411
evaluation/Returns Std         16.373775516563274
evaluation/Returns Max         238.3530741521231
evaluation/Returns Min         192.95022169416615
evaluation/ExplReturns Mean    215.1648998115411
evaluation/ExplReturns Std     16.373775516563274
evaluation/ExplReturns Max     238.3530741521231
evaluation/ExplReturns Min     192.95022169416615
evaluation/Actions Mean        0.022832286
evaluation/Actions Std         0.41922945
evaluation/Actions Max         0.9400259
evaluation/Actions Min         -0.9409517
evaluation/Num Paths           10
evaluation/Average Returns     215.1648998115411
time/data storing (s)          0.033771196380257607
time/evaluation sampling (s)   108.44602924771607
time/exploration sampling (s)  110.52633148431778
time/logging (s)               0.03033665008842945
time/saving (s)                0.012986648827791214
time/training (s)              9.387495539151132
time/epoch (s)                 228.43695076648146
time/total (s)                 2806.886753415689
Epoch                          11
-----------------------------  --------------------
2023-07-31 18:44:46.684755 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 12 finished
-----------------------------  --------------------
replay_buffer/size             66000
trainer/tdrp Loss              [4690.3228]
trainer/QF1 Loss               0.21479477
trainer/QF2 Loss               0.21785486
trainer/Policy Loss            -102.951965
trainer/Q1 Predictions Mean    98.67645
trainer/Q1 Predictions Std     4.0674896
trainer/Q1 Predictions Max     108.57507
trainer/Q1 Predictions Min     70.289856
trainer/Q2 Predictions Mean    98.63281
trainer/Q2 Predictions Std     4.0571847
trainer/Q2 Predictions Max     108.45717
trainer/Q2 Predictions Min     70.63075
trainer/Q Targets Mean         98.729744
trainer/Q Targets Std          4.1053276
trainer/Q Targets Max          109.23509
trainer/Q Targets Min          70.11018
trainer/Log Pis Mean           -4.1248255
trainer/Log Pis Std            3.0008974
trainer/Log Pis Max            7.2166653
trainer/Log Pis Min            -13.775471
trainer/Policy mu Mean         0.04532432
trainer/Policy mu Std          0.6923825
trainer/Policy mu Max          2.0991535
trainer/Policy mu Min          -2.3063293
trainer/Policy log std Mean    -0.19489197
trainer/Policy log std Std     0.09374661
trainer/Policy log std Max     0.031803574
trainer/Policy log std Min     -0.6545712
trainer/Alpha                  0.02861730009317398
trainer/Alpha Loss             -57.2989501953125
exploration/num steps total    66000
exploration/num paths total    132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4722010954427778
exploration/Rewards Std        0.09941829047577803
exploration/Rewards Max        0.9096769949149026
exploration/Rewards Min        0.1627867079529203
exploration/Returns Mean       236.10054772138884
exploration/Returns Std        26.710623619252388
exploration/Returns Max        260.2753333800849
exploration/Returns Min        175.56634786945386
exploration/Actions Mean       0.015041796
exploration/Actions Std        0.6457406
exploration/Actions Max        0.99936664
exploration/Actions Min        -0.9996504
exploration/Num Paths          10
exploration/Average Returns    236.10054772138884
evaluation/num steps total     65000
evaluation/num paths total     130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.47364798893690513
evaluation/Rewards Std         0.10281742136378248
evaluation/Rewards Max         0.7223122695845685
evaluation/Rewards Min         0.14052521299544893
evaluation/Returns Mean        236.82399446845247
evaluation/Returns Std         19.145564029788392
evaluation/Returns Max         267.0660634691051
evaluation/Returns Min         204.90690608388394
evaluation/ExplReturns Mean    236.82399446845247
evaluation/ExplReturns Std     19.145564029788392
evaluation/ExplReturns Max     267.0660634691051
evaluation/ExplReturns Min     204.90690608388394
evaluation/Actions Mean        0.037218213
evaluation/Actions Std         0.48697418
evaluation/Actions Max         0.96402705
evaluation/Actions Min         -0.9775708
evaluation/Num Paths           10
evaluation/Average Returns     236.82399446845247
time/data storing (s)          0.03334375098347664
time/evaluation sampling (s)   111.16150916647166
time/exploration sampling (s)  111.07904576323926
time/logging (s)               0.030796189792454243
time/saving (s)                0.012535293586552143
time/training (s)              9.418987962417305
time/epoch (s)                 231.7362181264907
time/total (s)                 3038.625471530482
Epoch                          12
-----------------------------  --------------------
2023-07-31 18:48:34.690686 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 13 finished
-----------------------------  --------------------
replay_buffer/size             71000
trainer/tdrp Loss              [4659.656]
trainer/QF1 Loss               0.27564895
trainer/QF2 Loss               0.30374804
trainer/Policy Loss            -100.6492
trainer/Q1 Predictions Mean    97.58245
trainer/Q1 Predictions Std     4.601015
trainer/Q1 Predictions Max     106.133415
trainer/Q1 Predictions Min     70.27462
trainer/Q2 Predictions Mean    97.71744
trainer/Q2 Predictions Std     4.585122
trainer/Q2 Predictions Max     106.63988
trainer/Q2 Predictions Min     70.62441
trainer/Q Targets Mean         97.50722
trainer/Q Targets Std          4.5738525
trainer/Q Targets Max          105.836975
trainer/Q Targets Min          69.851746
trainer/Log Pis Mean           -2.8400264
trainer/Log Pis Std            3.0821579
trainer/Log Pis Max            6.34369
trainer/Log Pis Min            -10.618853
trainer/Policy mu Mean         0.067819275
trainer/Policy mu Std          0.82801944
trainer/Policy mu Max          2.049541
trainer/Policy mu Min          -2.2325065
trainer/Policy log std Mean    -0.22668262
trainer/Policy log std Std     0.1143655
trainer/Policy log std Max     0.0382601
trainer/Policy log std Min     -0.65371466
trainer/Alpha                  0.0217120423913002
trainer/Alpha Loss             -56.83161163330078
exploration/num steps total    71000
exploration/num paths total    142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.44185031550684245
exploration/Rewards Std        0.10825196770527387
exploration/Rewards Max        0.7148211593275132
exploration/Rewards Min        0.14931123328842444
exploration/Returns Mean       220.92515775342116
exploration/Returns Std        19.656198342687627
exploration/Returns Max        266.9006364109947
exploration/Returns Min        191.4276729651843
exploration/Actions Mean       0.043180663
exploration/Actions Std        0.6634187
exploration/Actions Max        0.9992432
exploration/Actions Min        -0.99960977
exploration/Num Paths          10
exploration/Average Returns    220.92515775342116
evaluation/num steps total     70000
evaluation/num paths total     140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.38316770989548804
evaluation/Rewards Std         0.12828016874389883
evaluation/Rewards Max         0.6859800572845265
evaluation/Rewards Min         0.02775924542835125
evaluation/Returns Mean        191.58385494774404
evaluation/Returns Std         20.719960748057723
evaluation/Returns Max         232.1425857207882
evaluation/Returns Min         153.45945270215702
evaluation/ExplReturns Mean    191.58385494774404
evaluation/ExplReturns Std     20.719960748057723
evaluation/ExplReturns Max     232.1425857207882
evaluation/ExplReturns Min     153.45945270215702
evaluation/Actions Mean        0.061152533
evaluation/Actions Std         0.55072284
evaluation/Actions Max         0.9936902
evaluation/Actions Min         -0.986466
evaluation/Num Paths           10
evaluation/Average Returns     191.58385494774404
time/data storing (s)          0.03323030099272728
time/evaluation sampling (s)   108.66636081784964
time/exploration sampling (s)  109.8780697407201
time/logging (s)               0.030542386695742607
time/saving (s)                0.012890254147350788
time/training (s)              9.381092854775488
time/epoch (s)                 228.00218635518104
time/total (s)                 3266.63045219332
Epoch                          13
-----------------------------  --------------------
2023-07-31 18:52:23.961000 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 14 finished
-----------------------------  --------------------
replay_buffer/size             76000
trainer/tdrp Loss              [4661.4404]
trainer/QF1 Loss               0.25280306
trainer/QF2 Loss               0.25651926
trainer/Policy Loss            -97.46838
trainer/Q1 Predictions Mean    95.59187
trainer/Q1 Predictions Std     4.4684196
trainer/Q1 Predictions Max     103.60947
trainer/Q1 Predictions Min     70.316414
trainer/Q2 Predictions Mean    95.58077
trainer/Q2 Predictions Std     4.4865
trainer/Q2 Predictions Max     103.50055
trainer/Q2 Predictions Min     70.178116
trainer/Q Targets Mean         95.65136
trainer/Q Targets Std          4.498156
trainer/Q Targets Max          103.8716
trainer/Q Targets Min          69.11303
trainer/Log Pis Mean           -1.721184
trainer/Log Pis Std            3.4354177
trainer/Log Pis Max            7.571563
trainer/Log Pis Min            -10.959604
trainer/Policy mu Mean         0.07486529
trainer/Policy mu Std          0.9122526
trainer/Policy mu Max          2.4960053
trainer/Policy mu Min          -2.862769
trainer/Policy log std Mean    -0.23237634
trainer/Policy log std Std     0.12207625
trainer/Policy log std Max     0.16159242
trainer/Policy log std Min     -0.6909596
trainer/Alpha                  0.016508042812347412
trainer/Alpha Loss             -56.30681610107422
exploration/num steps total    76000
exploration/num paths total    152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.42271974695343567
exploration/Rewards Std        0.112105434801404
exploration/Rewards Max        0.9357431510054804
exploration/Rewards Min        0.12261852666381297
exploration/Returns Mean       211.35987347671784
exploration/Returns Std        19.944134971540386
exploration/Returns Max        245.27405344229138
exploration/Returns Min        183.78846498978857
exploration/Actions Mean       0.03572558
exploration/Actions Std        0.6729854
exploration/Actions Max        0.9997467
exploration/Actions Min        -0.9997667
exploration/Num Paths          10
exploration/Average Returns    211.35987347671784
evaluation/num steps total     75000
evaluation/num paths total     150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4041094683097492
evaluation/Rewards Std         0.1169713885279882
evaluation/Rewards Max         0.7409777005841264
evaluation/Rewards Min         0.029794472239809335
evaluation/Returns Mean        202.0547341548746
evaluation/Returns Std         19.407453125272156
evaluation/Returns Max         232.79973342458393
evaluation/Returns Min         162.26193571647394
evaluation/ExplReturns Mean    202.0547341548746
evaluation/ExplReturns Std     19.407453125272156
evaluation/ExplReturns Max     232.79973342458393
evaluation/ExplReturns Min     162.26193571647394
evaluation/Actions Mean        0.06554224
evaluation/Actions Std         0.5648651
evaluation/Actions Max         0.99280125
evaluation/Actions Min         -0.9953955
evaluation/Num Paths           10
evaluation/Average Returns     202.0547341548746
time/data storing (s)          0.034066724590957165
time/evaluation sampling (s)   109.434596138075
time/exploration sampling (s)  110.67242232523859
time/logging (s)               0.030264055356383324
time/saving (s)                0.012291391380131245
time/training (s)              9.083228045143187
time/epoch (s)                 229.26686867978424
time/total (s)                 3495.8998092897236
Epoch                          14
-----------------------------  --------------------
2023-07-31 18:56:13.203608 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 15 finished
-----------------------------  --------------------
replay_buffer/size             81000
trainer/tdrp Loss              [4571.5405]
trainer/QF1 Loss               0.28604224
trainer/QF2 Loss               0.2877644
trainer/Policy Loss            -92.03135
trainer/Q1 Predictions Mean    93.693115
trainer/Q1 Predictions Std     7.0276146
trainer/Q1 Predictions Max     103.10862
trainer/Q1 Predictions Min     54.289333
trainer/Q2 Predictions Mean    93.6958
trainer/Q2 Predictions Std     7.0689855
trainer/Q2 Predictions Max     103.26811
trainer/Q2 Predictions Min     53.93344
trainer/Q Targets Mean         93.750824
trainer/Q Targets Std          7.186738
trainer/Q Targets Max          103.20072
trainer/Q Targets Min          53.680695
trainer/Log Pis Mean           1.8219885
trainer/Log Pis Std            4.581318
trainer/Log Pis Max            19.183008
trainer/Log Pis Min            -9.177274
trainer/Policy mu Mean         0.116357185
trainer/Policy mu Std          1.1362131
trainer/Policy mu Max          3.829205
trainer/Policy mu Min          -3.383806
trainer/Policy log std Mean    -0.2724155
trainer/Policy log std Std     0.16138116
trainer/Policy log std Max     0.2924082
trainer/Policy log std Min     -0.792485
trainer/Alpha                  0.012632536701858044
trainer/Alpha Loss             -44.490379333496094
exploration/num steps total    81000
exploration/num paths total    162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.36442343308215275
exploration/Rewards Std        0.14604045428564608
exploration/Rewards Max        0.7264317623283889
exploration/Rewards Min        0.034878054834734544
exploration/Returns Mean       182.21171654107638
exploration/Returns Std        32.347236189230145
exploration/Returns Max        229.96601512972484
exploration/Returns Min        124.25452365024627
exploration/Actions Mean       0.08747883
exploration/Actions Std        0.7127199
exploration/Actions Max        0.9999743
exploration/Actions Min        -0.9999718
exploration/Num Paths          10
exploration/Average Returns    182.21171654107638
evaluation/num steps total     80000
evaluation/num paths total     160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.42882014826962583
evaluation/Rewards Std         0.11989529012078046
evaluation/Rewards Max         0.7278511587277612
evaluation/Rewards Min         0.10872406429127467
evaluation/Returns Mean        214.41007413481293
evaluation/Returns Std         16.4492521092331
evaluation/Returns Max         240.310587275564
evaluation/Returns Min         186.84007980654044
evaluation/ExplReturns Mean    214.41007413481293
evaluation/ExplReturns Std     16.4492521092331
evaluation/ExplReturns Max     240.310587275564
evaluation/ExplReturns Min     186.84007980654044
evaluation/Actions Mean        0.10106304
evaluation/Actions Std         0.617042
evaluation/Actions Max         0.9966035
evaluation/Actions Min         -0.9997267
evaluation/Num Paths           10
evaluation/Average Returns     214.41007413481293
time/data storing (s)          0.034215749241411686
time/evaluation sampling (s)   110.03266087919474
time/exploration sampling (s)  110.76250070426613
time/logging (s)               0.030445683747529984
time/saving (s)                0.01250991690903902
time/training (s)              8.367235866375268
time/epoch (s)                 229.23956879973412
time/total (s)                 3725.1419069934636
Epoch                          15
-----------------------------  --------------------
2023-07-31 19:00:05.930996 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 16 finished
-----------------------------  --------------------
replay_buffer/size             86000
trainer/tdrp Loss              [4624.5054]
trainer/QF1 Loss               0.2434864
trainer/QF2 Loss               0.20873033
trainer/Policy Loss            -90.21437
trainer/Q1 Predictions Mean    91.023636
trainer/Q1 Predictions Std     6.671269
trainer/Q1 Predictions Max     100.3509
trainer/Q1 Predictions Min     57.727375
trainer/Q2 Predictions Mean    91.07406
trainer/Q2 Predictions Std     6.6739264
trainer/Q2 Predictions Max     100.43914
trainer/Q2 Predictions Min     57.883133
trainer/Q Targets Mean         91.17638
trainer/Q Targets Std          6.689199
trainer/Q Targets Max          101.1569
trainer/Q Targets Min          58.868164
trainer/Log Pis Mean           1.0087473
trainer/Log Pis Std            4.67937
trainer/Log Pis Max            13.354474
trainer/Log Pis Min            -12.056719
trainer/Policy mu Mean         0.08546779
trainer/Policy mu Std          1.1069875
trainer/Policy mu Max          2.927124
trainer/Policy mu Min          -3.868398
trainer/Policy log std Mean    -0.2531781
trainer/Policy log std Std     0.14776316
trainer/Policy log std Max     0.2743665
trainer/Policy log std Min     -0.8384422
trainer/Alpha                  0.009764209389686584
trainer/Alpha Loss             -50.87592315673828
exploration/num steps total    86000
exploration/num paths total    172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4756589275962437
exploration/Rewards Std        0.10020438971438435
exploration/Rewards Max        0.7132965983875811
exploration/Rewards Min        0.1547074728788886
exploration/Returns Mean       237.82946379812182
exploration/Returns Std        18.916627152801105
exploration/Returns Max        263.1157119985851
exploration/Returns Min        199.10394441850983
exploration/Actions Mean       0.07838645
exploration/Actions Std        0.6747023
exploration/Actions Max        0.99972725
exploration/Actions Min        -0.99964637
exploration/Num Paths          10
exploration/Average Returns    237.82946379812182
evaluation/num steps total     85000
evaluation/num paths total     170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.45786201989403497
evaluation/Rewards Std         0.11078924508487495
evaluation/Rewards Max         0.7117061460499052
evaluation/Rewards Min         0.06998889394268432
evaluation/Returns Mean        228.93100994701746
evaluation/Returns Std         23.91229451181376
evaluation/Returns Max         254.25483667279136
evaluation/Returns Min         174.07433096140562
evaluation/ExplReturns Mean    228.93100994701746
evaluation/ExplReturns Std     23.91229451181376
evaluation/ExplReturns Max     254.25483667279136
evaluation/ExplReturns Min     174.07433096140562
evaluation/Actions Mean        0.09841766
evaluation/Actions Std         0.5684862
evaluation/Actions Max         0.9985514
evaluation/Actions Min         -0.9961397
evaluation/Num Paths           10
evaluation/Average Returns     228.93100994701746
time/data storing (s)          0.03363252151757479
time/evaluation sampling (s)   111.10830638371408
time/exploration sampling (s)  112.14224936254323
time/logging (s)               0.030530663207173347
time/saving (s)                0.012602226808667183
time/training (s)              9.397020331583917
time/epoch (s)                 232.72434148937464
time/total (s)                 3957.8686821581796
Epoch                          16
-----------------------------  --------------------
2023-07-31 19:03:56.537191 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 17 finished
-----------------------------  --------------------
replay_buffer/size             91000
trainer/tdrp Loss              [4572.5493]
trainer/QF1 Loss               0.31487936
trainer/QF2 Loss               0.27553067
trainer/Policy Loss            -86.60075
trainer/Q1 Predictions Mean    89.8873
trainer/Q1 Predictions Std     7.3824167
trainer/Q1 Predictions Max     98.62128
trainer/Q1 Predictions Min     44.894634
trainer/Q2 Predictions Mean    89.817184
trainer/Q2 Predictions Std     7.40626
trainer/Q2 Predictions Max     98.66344
trainer/Q2 Predictions Min     45.349644
trainer/Q Targets Mean         89.740555
trainer/Q Targets Std          7.4009023
trainer/Q Targets Max          98.463066
trainer/Q Targets Min          45.60429
trainer/Log Pis Mean           3.3744407
trainer/Log Pis Std            6.3639603
trainer/Log Pis Max            38.888535
trainer/Log Pis Min            -9.462637
trainer/Policy mu Mean         -0.007538074
trainer/Policy mu Std          1.2598025
trainer/Policy mu Max          3.594854
trainer/Policy mu Min          -3.821093
trainer/Policy log std Mean    -0.2766698
trainer/Policy log std Std     0.1407359
trainer/Policy log std Max     0.23026991
trainer/Policy log std Min     -0.78450775
trainer/Alpha                  0.007623677607625723
trainer/Alpha Loss             -42.06044387817383
exploration/num steps total    91000
exploration/num paths total    182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.3967795095891921
exploration/Rewards Std        0.12376581506392155
exploration/Rewards Max        0.713951882217907
exploration/Rewards Min        0.08208430642787579
exploration/Returns Mean       198.3897547945961
exploration/Returns Std        32.03974034257691
exploration/Returns Max        269.94338276099
exploration/Returns Min        151.39644331558958
exploration/Actions Mean       0.06812985
exploration/Actions Std        0.69162923
exploration/Actions Max        0.9999797
exploration/Actions Min        -0.9999601
exploration/Num Paths          10
exploration/Average Returns    198.3897547945961
evaluation/num steps total     90000
evaluation/num paths total     180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.39313550011593335
evaluation/Rewards Std         0.11741553204161156
evaluation/Rewards Max         0.6894422156161802
evaluation/Rewards Min         0.05538975174614905
evaluation/Returns Mean        196.56775005796663
evaluation/Returns Std         16.437910902120706
evaluation/Returns Max         217.96618103856144
evaluation/Returns Min         154.2734832413551
evaluation/ExplReturns Mean    196.56775005796663
evaluation/ExplReturns Std     16.437910902120706
evaluation/ExplReturns Max     217.96618103856144
evaluation/ExplReturns Min     154.2734832413551
evaluation/Actions Mean        0.08384654
evaluation/Actions Std         0.5992213
evaluation/Actions Max         0.9998568
evaluation/Actions Min         -0.9989625
evaluation/Num Paths           10
evaluation/Average Returns     196.56775005796663
time/data storing (s)          0.03374455589801073
time/evaluation sampling (s)   109.91832383349538
time/exploration sampling (s)  111.21915430761874
time/logging (s)               0.0334602314978838
time/saving (s)                0.01867152936756611
time/training (s)              9.382382845506072
time/epoch (s)                 230.60573730338365
time/total (s)                 4188.477018862963
Epoch                          17
-----------------------------  --------------------
2023-07-31 19:07:47.623648 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 18 finished
-----------------------------  ---------------------
replay_buffer/size             96000
trainer/tdrp Loss              [4558.109]
trainer/QF1 Loss               0.2265982
trainer/QF2 Loss               0.21719334
trainer/Policy Loss            -81.977356
trainer/Q1 Predictions Mean    87.97349
trainer/Q1 Predictions Std     7.9576488
trainer/Q1 Predictions Max     96.67735
trainer/Q1 Predictions Min     49.804157
trainer/Q2 Predictions Mean    87.90653
trainer/Q2 Predictions Std     7.965597
trainer/Q2 Predictions Max     96.55823
trainer/Q2 Predictions Min     49.142784
trainer/Q Targets Mean         87.94541
trainer/Q Targets Std          7.9295225
trainer/Q Targets Max          96.31297
trainer/Q Targets Min          49.6257
trainer/Log Pis Mean           6.1454067
trainer/Log Pis Std            7.806197
trainer/Log Pis Max            51.15416
trainer/Log Pis Min            -9.323523
trainer/Policy mu Mean         0.06743688
trainer/Policy mu Std          1.4308095
trainer/Policy mu Max          4.7787414
trainer/Policy mu Min          -4.9861474
trainer/Policy log std Mean    -0.32563972
trainer/Policy log std Std     0.14653501
trainer/Policy log std Max     0.23667696
trainer/Policy log std Min     -0.9911841
trainer/Alpha                  0.0060622296296060085
trainer/Alpha Loss             -29.890453338623047
exploration/num steps total    96000
exploration/num paths total    192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4556387277368287
exploration/Rewards Std        0.10924954985556547
exploration/Rewards Max        0.959960313335024
exploration/Rewards Min        0.1502414992833488
exploration/Returns Mean       227.8193638684143
exploration/Returns Std        15.578927237146873
exploration/Returns Max        258.1698213004427
exploration/Returns Min        210.76793368075428
exploration/Actions Mean       0.059539497
exploration/Actions Std        0.70320207
exploration/Actions Max        0.99984604
exploration/Actions Min        -0.9998141
exploration/Num Paths          10
exploration/Average Returns    227.8193638684143
evaluation/num steps total     95000
evaluation/num paths total     190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.46792271847424544
evaluation/Rewards Std         0.09837240335059595
evaluation/Rewards Max         0.7327844874590922
evaluation/Rewards Min         0.16164938891625838
evaluation/Returns Mean        233.96135923712268
evaluation/Returns Std         12.222335236396093
evaluation/Returns Max         251.8975555698759
evaluation/Returns Min         208.18046597901113
evaluation/ExplReturns Mean    233.96135923712268
evaluation/ExplReturns Std     12.222335236396093
evaluation/ExplReturns Max     251.8975555698759
evaluation/ExplReturns Min     208.18046597901113
evaluation/Actions Mean        0.0756808
evaluation/Actions Std         0.65098065
evaluation/Actions Max         0.9999031
evaluation/Actions Min         -0.9997782
evaluation/Num Paths           10
evaluation/Average Returns     233.96135923712268
time/data storing (s)          0.033430879935622215
time/evaluation sampling (s)   110.80446788296103
time/exploration sampling (s)  110.77067931275815
time/logging (s)               0.03036538977175951
time/saving (s)                0.010207160376012325
time/training (s)              9.4308709083125
time/epoch (s)                 231.08002153411508
time/total (s)                 4419.559719839133
Epoch                          18
-----------------------------  ---------------------
2023-07-31 19:11:46.346945 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 19 finished
-----------------------------  --------------------
replay_buffer/size             101000
trainer/tdrp Loss              [4570.571]
trainer/QF1 Loss               0.2384087
trainer/QF2 Loss               0.2172234
trainer/Policy Loss            -79.28777
trainer/Q1 Predictions Mean    87.35672
trainer/Q1 Predictions Std     5.9817047
trainer/Q1 Predictions Max     96.22285
trainer/Q1 Predictions Min     59.282516
trainer/Q2 Predictions Mean    87.353
trainer/Q2 Predictions Std     5.9686875
trainer/Q2 Predictions Max     96.01178
trainer/Q2 Predictions Min     59.25538
trainer/Q Targets Mean         87.33938
trainer/Q Targets Std          6.0008426
trainer/Q Targets Max          96.01532
trainer/Q Targets Min          60.26236
trainer/Log Pis Mean           8.246319
trainer/Log Pis Std            8.747683
trainer/Log Pis Max            50.516674
trainer/Log Pis Min            -9.627655
trainer/Policy mu Mean         0.13581637
trainer/Policy mu Std          1.5492432
trainer/Policy mu Max          5.240473
trainer/Policy mu Min          -4.0718355
trainer/Policy log std Mean    -0.32552257
trainer/Policy log std Std     0.14679825
trainer/Policy log std Max     0.17649037
trainer/Policy log std Min     -0.84620094
trainer/Alpha                  0.004975953605026007
trainer/Alpha Loss             -19.905685424804688
exploration/num steps total    101000
exploration/num paths total    202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.515106105156609
exploration/Rewards Std        0.07221265603071636
exploration/Rewards Max        0.6889471050905421
exploration/Rewards Min        0.2119869457812037
exploration/Returns Mean       257.5530525783044
exploration/Returns Std        10.062770496514425
exploration/Returns Max        274.75108606003755
exploration/Returns Min        239.14978260634695
exploration/Actions Mean       0.06596109
exploration/Actions Std        0.70664394
exploration/Actions Max        0.99997437
exploration/Actions Min        -0.99992466
exploration/Num Paths          10
exploration/Average Returns    257.5530525783044
evaluation/num steps total     100000
evaluation/num paths total     200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5173082448510374
evaluation/Rewards Std         0.06923838272200294
evaluation/Rewards Max         0.701124213676824
evaluation/Rewards Min         0.256430834796709
evaluation/Returns Mean        258.6541224255188
evaluation/Returns Std         8.580169239675454
evaluation/Returns Max         270.7383370790169
evaluation/Returns Min         243.75778615063038
evaluation/ExplReturns Mean    258.6541224255188
evaluation/ExplReturns Std     8.580169239675454
evaluation/ExplReturns Max     270.7383370790169
evaluation/ExplReturns Min     243.75778615063038
evaluation/Actions Mean        0.06761678
evaluation/Actions Std         0.66471326
evaluation/Actions Max         0.9998023
evaluation/Actions Min         -0.999909
evaluation/Num Paths           10
evaluation/Average Returns     258.6541224255188
time/data storing (s)          0.03412105981260538
time/evaluation sampling (s)   115.43147299066186
time/exploration sampling (s)  114.24487212952226
time/logging (s)               0.03023633547127247
time/saving (s)                0.01063657645136118
time/training (s)              8.968633346259594
time/epoch (s)                 238.71997243817896
time/total (s)                 4658.282173988409
Epoch                          19
-----------------------------  --------------------
2023-07-31 19:15:38.466343 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 20 finished
-----------------------------  --------------------
replay_buffer/size             106000
trainer/tdrp Loss              [4462.2026]
trainer/QF1 Loss               0.2984752
trainer/QF2 Loss               0.3082556
trainer/Policy Loss            -73.22961
trainer/Q1 Predictions Mean    83.99939
trainer/Q1 Predictions Std     9.122841
trainer/Q1 Predictions Max     94.343994
trainer/Q1 Predictions Min     30.43428
trainer/Q2 Predictions Mean    83.9458
trainer/Q2 Predictions Std     9.0939455
trainer/Q2 Predictions Max     93.95487
trainer/Q2 Predictions Min     31.057287
trainer/Q Targets Mean         83.854095
trainer/Q Targets Std          9.221172
trainer/Q Targets Max          94.140686
trainer/Q Targets Min          28.946405
trainer/Log Pis Mean           10.891165
trainer/Log Pis Std            8.696133
trainer/Log Pis Max            59.33541
trainer/Log Pis Min            -10.518811
trainer/Policy mu Mean         0.098171584
trainer/Policy mu Std          1.6835426
trainer/Policy mu Max          5.3526974
trainer/Policy mu Min          -4.75114
trainer/Policy log std Mean    -0.3588934
trainer/Policy log std Std     0.13860534
trainer/Policy log std Max     0.17865407
trainer/Policy log std Min     -0.92690325
trainer/Alpha                  0.004300777800381184
trainer/Alpha Loss             -6.04188346862793
exploration/num steps total    106000
exploration/num paths total    212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4228426068527664
exploration/Rewards Std        0.117017946626255
exploration/Rewards Max        0.7263353212985354
exploration/Rewards Min        0.057489796462304565
exploration/Returns Mean       211.4213034263831
exploration/Returns Std        27.304223476915613
exploration/Returns Max        259.5246166562235
exploration/Returns Min        159.64383540086607
exploration/Actions Mean       0.10154453
exploration/Actions Std        0.74941033
exploration/Actions Max        0.99999964
exploration/Actions Min        -0.9999934
exploration/Num Paths          10
exploration/Average Returns    211.4213034263831
evaluation/num steps total     105000
evaluation/num paths total     210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4355340125533481
evaluation/Rewards Std         0.10516761888501121
evaluation/Rewards Max         0.7239635344933743
evaluation/Rewards Min         0.13154346250036436
evaluation/Returns Mean        217.76700627667407
evaluation/Returns Std         13.637279667091073
evaluation/Returns Max         237.20027584744946
evaluation/Returns Min         195.53796764953123
evaluation/ExplReturns Mean    217.76700627667407
evaluation/ExplReturns Std     13.637279667091073
evaluation/ExplReturns Max     237.20027584744946
evaluation/ExplReturns Min     195.53796764953123
evaluation/Actions Mean        0.12258124
evaluation/Actions Std         0.72457194
evaluation/Actions Max         0.9999996
evaluation/Actions Min         -0.99998784
evaluation/Num Paths           10
evaluation/Average Returns     217.76700627667407
time/data storing (s)          0.033471872098743916
time/evaluation sampling (s)   111.06086573004723
time/exploration sampling (s)  111.77813876233995
time/logging (s)               0.030227831564843655
time/saving (s)                0.010241818614304066
time/training (s)              9.203077998943627
time/epoch (s)                 232.1160240136087
time/total (s)                 4890.4008434563875
Epoch                          20
-----------------------------  --------------------
2023-07-31 19:19:32.180165 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 21 finished
-----------------------------  ---------------------
replay_buffer/size             111000
trainer/tdrp Loss              [4582.5537]
trainer/QF1 Loss               0.23306674
trainer/QF2 Loss               0.23876429
trainer/Policy Loss            -71.832054
trainer/Q1 Predictions Mean    83.50273
trainer/Q1 Predictions Std     6.3429766
trainer/Q1 Predictions Max     92.86993
trainer/Q1 Predictions Min     52.787617
trainer/Q2 Predictions Mean    83.56207
trainer/Q2 Predictions Std     6.3686733
trainer/Q2 Predictions Max     93.077156
trainer/Q2 Predictions Min     52.57631
trainer/Q Targets Mean         83.4124
trainer/Q Targets Std          6.3791995
trainer/Q Targets Max          92.75822
trainer/Q Targets Min          52.882534
trainer/Log Pis Mean           11.888899
trainer/Log Pis Std            9.122492
trainer/Log Pis Max            47.403595
trainer/Log Pis Min            -5.014077
trainer/Policy mu Mean         -0.08409226
trainer/Policy mu Std          1.7607523
trainer/Policy mu Max          6.73158
trainer/Policy mu Min          -5.9333715
trainer/Policy log std Mean    -0.3682467
trainer/Policy log std Std     0.13930286
trainer/Policy log std Max     0.13654841
trainer/Policy log std Min     -0.8609054
trainer/Alpha                  0.0040282937698066235
trainer/Alpha Loss             -0.6126570105552673
exploration/num steps total    111000
exploration/num paths total    222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.48535871513981294
exploration/Rewards Std        0.09930744343249412
exploration/Rewards Max        0.7118436873199278
exploration/Rewards Min        0.20039305839937818
exploration/Returns Mean       242.67935756990647
exploration/Returns Std        22.854476680962645
exploration/Returns Max        269.7928401715764
exploration/Returns Min        209.2722321803458
exploration/Actions Mean       -0.13056076
exploration/Actions Std        0.7444579
exploration/Actions Max        0.99999267
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    242.67935756990647
evaluation/num steps total     110000
evaluation/num paths total     220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4981518057008936
evaluation/Rewards Std         0.09089901611721005
evaluation/Rewards Max         0.709378776168737
evaluation/Rewards Min         0.16546986390059631
evaluation/Returns Mean        249.0759028504468
evaluation/Returns Std         20.988461003504188
evaluation/Returns Max         287.10852837258847
evaluation/Returns Min         206.29341203914925
evaluation/ExplReturns Mean    249.0759028504468
evaluation/ExplReturns Std     20.988461003504188
evaluation/ExplReturns Max     287.10852837258847
evaluation/ExplReturns Min     206.29341203914925
evaluation/Actions Mean        -0.077749655
evaluation/Actions Std         0.729894
evaluation/Actions Max         0.9999907
evaluation/Actions Min         -0.9999995
evaluation/Num Paths           10
evaluation/Average Returns     249.0759028504468
time/data storing (s)          0.03469679318368435
time/evaluation sampling (s)   112.21587325632572
time/exploration sampling (s)  112.05136334057897
time/logging (s)               0.030891191214323044
time/saving (s)                0.012568090111017227
time/training (s)              9.365846261382103
time/epoch (s)                 233.71123893279582
time/total (s)                 5124.11455137562
Epoch                          21
-----------------------------  ---------------------
2023-07-31 19:23:21.381466 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 22 finished
-----------------------------  ---------------------
replay_buffer/size             116000
trainer/tdrp Loss              [4309.4727]
trainer/QF1 Loss               0.23345087
trainer/QF2 Loss               0.2164216
trainer/Policy Loss            -70.208374
trainer/Q1 Predictions Mean    82.74916
trainer/Q1 Predictions Std     5.7257648
trainer/Q1 Predictions Max     90.1228
trainer/Q1 Predictions Min     53.731472
trainer/Q2 Predictions Mean    82.61115
trainer/Q2 Predictions Std     5.731589
trainer/Q2 Predictions Max     90.06226
trainer/Q2 Predictions Min     53.588104
trainer/Q Targets Mean         82.64434
trainer/Q Targets Std          5.728106
trainer/Q Targets Max          90.34163
trainer/Q Targets Min          55.129864
trainer/Log Pis Mean           12.641109
trainer/Log Pis Std            8.51055
trainer/Log Pis Max            44.894363
trainer/Log Pis Min            -4.67016
trainer/Policy mu Mean         0.1991883
trainer/Policy mu Std          1.7290397
trainer/Policy mu Max          4.458319
trainer/Policy mu Min          -4.2163925
trainer/Policy log std Mean    -0.3936615
trainer/Policy log std Std     0.1328775
trainer/Policy log std Max     0.07425769
trainer/Policy log std Min     -0.91427654
trainer/Alpha                  0.0038606540765613317
trainer/Alpha Loss             3.56266450881958
exploration/num steps total    116000
exploration/num paths total    232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4626138772476674
exploration/Rewards Std        0.08079258871715463
exploration/Rewards Max        0.7131441262440734
exploration/Rewards Min        0.20132478708012883
exploration/Returns Mean       231.30693862383364
exploration/Returns Std        12.44760512045506
exploration/Returns Max        249.6204952871435
exploration/Returns Min        218.53151945167434
exploration/Actions Mean       0.0927698
exploration/Actions Std        0.75377905
exploration/Actions Max        0.99999195
exploration/Actions Min        -0.9999941
exploration/Num Paths          10
exploration/Average Returns    231.30693862383364
evaluation/num steps total     115000
evaluation/num paths total     230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4465044382100898
evaluation/Rewards Std         0.0781885545395675
evaluation/Rewards Max         0.7057835631867557
evaluation/Rewards Min         0.1765796247943856
evaluation/Returns Mean        223.25221910504496
evaluation/Returns Std         9.531745251320844
evaluation/Returns Max         237.33307108871566
evaluation/Returns Min         207.21818455360062
evaluation/ExplReturns Mean    223.25221910504496
evaluation/ExplReturns Std     9.531745251320844
evaluation/ExplReturns Max     237.33307108871566
evaluation/ExplReturns Min     207.21818455360062
evaluation/Actions Mean        0.10383166
evaluation/Actions Std         0.74961805
evaluation/Actions Max         0.99998
evaluation/Actions Min         -0.99993837
evaluation/Num Paths           10
evaluation/Average Returns     223.25221910504496
time/data storing (s)          0.03367471043020487
time/evaluation sampling (s)   109.16392887756228
time/exploration sampling (s)  110.62525022402406
time/logging (s)               0.03034755028784275
time/saving (s)                0.011904402635991573
time/training (s)              9.332300531677902
time/epoch (s)                 229.19740629661828
time/total (s)                 5353.314549176954
Epoch                          22
-----------------------------  ---------------------
2023-07-31 19:27:15.812965 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 23 finished
-----------------------------  ---------------------
replay_buffer/size             121000
trainer/tdrp Loss              [4270.789]
trainer/QF1 Loss               0.22777313
trainer/QF2 Loss               0.20475557
trainer/Policy Loss            -70.52284
trainer/Q1 Predictions Mean    81.05599
trainer/Q1 Predictions Std     6.637042
trainer/Q1 Predictions Max     90.21265
trainer/Q1 Predictions Min     52.073956
trainer/Q2 Predictions Mean    81.080414
trainer/Q2 Predictions Std     6.617841
trainer/Q2 Predictions Max     90.8946
trainer/Q2 Predictions Min     52.563206
trainer/Q Targets Mean         81.07118
trainer/Q Targets Std          6.632552
trainer/Q Targets Max          90.1791
trainer/Q Targets Min          52.42944
trainer/Log Pis Mean           10.659935
trainer/Log Pis Std            8.783269
trainer/Log Pis Max            45.220512
trainer/Log Pis Min            -7.316559
trainer/Policy mu Mean         -0.100536175
trainer/Policy mu Std          1.6942776
trainer/Policy mu Max          4.7285867
trainer/Policy mu Min          -6.156376
trainer/Policy log std Mean    -0.33863655
trainer/Policy log std Std     0.12491745
trainer/Policy log std Max     0.27946275
trainer/Policy log std Min     -0.77777994
trainer/Alpha                  0.0036482131108641624
trainer/Alpha Loss             -7.522554397583008
exploration/num steps total    121000
exploration/num paths total    242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.45426973373258134
exploration/Rewards Std        0.10518533260730596
exploration/Rewards Max        0.7086685139759961
exploration/Rewards Min        0.13051397819336588
exploration/Returns Mean       227.13486686629057
exploration/Returns Std        20.202693637119182
exploration/Returns Max        250.7218087392967
exploration/Returns Min        185.4315724129891
exploration/Actions Mean       -0.007904247
exploration/Actions Std        0.74577785
exploration/Actions Max        0.9999996
exploration/Actions Min        -0.9999993
exploration/Num Paths          10
exploration/Average Returns    227.13486686629057
evaluation/num steps total     120000
evaluation/num paths total     240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4465848359532408
evaluation/Rewards Std         0.10486371588456414
evaluation/Rewards Max         0.7193643104233254
evaluation/Rewards Min         0.1910956635753015
evaluation/Returns Mean        223.29241797662036
evaluation/Returns Std         27.124329550237444
evaluation/Returns Max         280.6316958882772
evaluation/Returns Min         190.1816105537477
evaluation/ExplReturns Mean    223.29241797662036
evaluation/ExplReturns Std     27.124329550237444
evaluation/ExplReturns Max     280.6316958882772
evaluation/ExplReturns Min     190.1816105537477
evaluation/Actions Mean        -0.0024591289
evaluation/Actions Std         0.7071648
evaluation/Actions Max         0.9999985
evaluation/Actions Min         -0.99999136
evaluation/Num Paths           10
evaluation/Average Returns     223.29241797662036
time/data storing (s)          0.03345397859811783
time/evaluation sampling (s)   112.62316100019962
time/exploration sampling (s)  112.34131570439786
time/logging (s)               0.030482321977615356
time/saving (s)                0.01125427521765232
time/training (s)              9.388713851571083
time/epoch (s)                 234.42838113196194
time/total (s)                 5587.745445229113
Epoch                          23
-----------------------------  ---------------------
2023-07-31 19:31:07.408355 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 24 finished
-----------------------------  --------------------
replay_buffer/size             126000
trainer/tdrp Loss              [4366.5625]
trainer/QF1 Loss               0.25821793
trainer/QF2 Loss               0.24377415
trainer/Policy Loss            -67.826164
trainer/Q1 Predictions Mean    79.45633
trainer/Q1 Predictions Std     6.155422
trainer/Q1 Predictions Max     87.92597
trainer/Q1 Predictions Min     51.671326
trainer/Q2 Predictions Mean    79.51688
trainer/Q2 Predictions Std     6.1278033
trainer/Q2 Predictions Max     87.68639
trainer/Q2 Predictions Min     51.77247
trainer/Q Targets Mean         79.62804
trainer/Q Targets Std          6.1418133
trainer/Q Targets Max          87.99923
trainer/Q Targets Min          53.024857
trainer/Log Pis Mean           11.808233
trainer/Log Pis Std            9.198502
trainer/Log Pis Max            43.610397
trainer/Log Pis Min            -7.3694115
trainer/Policy mu Mean         0.14549904
trainer/Policy mu Std          1.7554219
trainer/Policy mu Max          5.7170115
trainer/Policy mu Min          -4.432207
trainer/Policy log std Mean    -0.34880176
trainer/Policy log std Std     0.15077187
trainer/Policy log std Max     0.4880823
trainer/Policy log std Min     -0.86826706
trainer/Alpha                  0.003568934975191951
trainer/Alpha Loss             -1.0806914567947388
exploration/num steps total    126000
exploration/num paths total    252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.45182027632556776
exploration/Rewards Std        0.12856921680360214
exploration/Rewards Max        0.7349167206831654
exploration/Rewards Min        0.04432358062220771
exploration/Returns Mean       225.91013816278388
exploration/Returns Std        29.41650254231058
exploration/Returns Max        270.45873140980035
exploration/Returns Min        178.6616913202386
exploration/Actions Mean       0.058111317
exploration/Actions Std        0.7344803
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999076
exploration/Num Paths          10
exploration/Average Returns    225.91013816278388
evaluation/num steps total     125000
evaluation/num paths total     250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4403688632550307
evaluation/Rewards Std         0.11908864382508688
evaluation/Rewards Max         0.7197549557239068
evaluation/Rewards Min         0.10942031921433448
evaluation/Returns Mean        220.18443162751547
evaluation/Returns Std         24.12219050441802
evaluation/Returns Max         259.0639993003451
evaluation/Returns Min         189.3615122328521
evaluation/ExplReturns Mean    220.18443162751547
evaluation/ExplReturns Std     24.12219050441802
evaluation/ExplReturns Max     259.0639993003451
evaluation/ExplReturns Min     189.3615122328521
evaluation/Actions Mean        0.051644646
evaluation/Actions Std         0.69161606
evaluation/Actions Max         0.9999975
evaluation/Actions Min         -0.9999991
evaluation/Num Paths           10
evaluation/Average Returns     220.18443162751547
time/data storing (s)          0.03392358589917421
time/evaluation sampling (s)   110.97893490921706
time/exploration sampling (s)  111.4630708321929
time/logging (s)               0.03038865327835083
time/saving (s)                0.01238800585269928
time/training (s)              9.073304922319949
time/epoch (s)                 231.59201090876013
time/total (s)                 5819.339989581145
Epoch                          24
-----------------------------  --------------------
2023-07-31 19:35:04.062169 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 25 finished
-----------------------------  ---------------------
replay_buffer/size             131000
trainer/tdrp Loss              [4149.312]
trainer/QF1 Loss               0.29866326
trainer/QF2 Loss               0.30810332
trainer/Policy Loss            -67.0839
trainer/Q1 Predictions Mean    78.37216
trainer/Q1 Predictions Std     6.1049566
trainer/Q1 Predictions Max     85.930595
trainer/Q1 Predictions Min     35.784634
trainer/Q2 Predictions Mean    78.350395
trainer/Q2 Predictions Std     6.0971127
trainer/Q2 Predictions Max     85.89391
trainer/Q2 Predictions Min     36.106438
trainer/Q Targets Mean         78.53205
trainer/Q Targets Std          6.0615535
trainer/Q Targets Max          86.34547
trainer/Q Targets Min          36.8633
trainer/Log Pis Mean           11.4270525
trainer/Log Pis Std            8.99958
trainer/Log Pis Max            54.43816
trainer/Log Pis Min            -9.6859455
trainer/Policy mu Mean         -0.13149303
trainer/Policy mu Std          1.7432268
trainer/Policy mu Max          5.1825585
trainer/Policy mu Min          -6.2700176
trainer/Policy log std Mean    -0.30608323
trainer/Policy log std Std     0.13439415
trainer/Policy log std Max     0.2203858
trainer/Policy log std Min     -0.8169167
trainer/Alpha                  0.0036709492560476065
trainer/Alpha Loss             -3.21274995803833
exploration/num steps total    131000
exploration/num paths total    262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.510082355890334
exploration/Rewards Std        0.10082630398407508
exploration/Rewards Max        0.9649866029987048
exploration/Rewards Min        0.13179296430312892
exploration/Returns Mean       255.04117794516705
exploration/Returns Std        22.55491629093875
exploration/Returns Max        308.78926284891645
exploration/Returns Min        227.56714304612095
exploration/Actions Mean       -0.0650943
exploration/Actions Std        0.7474746
exploration/Actions Max        0.9999872
exploration/Actions Min        -0.99999124
exploration/Num Paths          10
exploration/Average Returns    255.04117794516705
evaluation/num steps total     130000
evaluation/num paths total     260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.517051779223429
evaluation/Rewards Std         0.08694565777773405
evaluation/Rewards Max         0.7063796398125473
evaluation/Rewards Min         0.20115613603463262
evaluation/Returns Mean        258.52588961171455
evaluation/Returns Std         10.704297741133514
evaluation/Returns Max         272.07298569556934
evaluation/Returns Min         239.11703981298336
evaluation/ExplReturns Mean    258.52588961171455
evaluation/ExplReturns Std     10.704297741133514
evaluation/ExplReturns Max     272.07298569556934
evaluation/ExplReturns Min     239.11703981298336
evaluation/Actions Mean        -0.045019325
evaluation/Actions Std         0.7079682
evaluation/Actions Max         0.9998413
evaluation/Actions Min         -0.9999455
evaluation/Num Paths           10
evaluation/Average Returns     258.52588961171455
time/data storing (s)          0.03448974434286356
time/evaluation sampling (s)   112.71464973781258
time/exploration sampling (s)  114.12591476924717
time/logging (s)               0.030405388213694096
time/saving (s)                0.011906962841749191
time/training (s)              9.73327443189919
time/epoch (s)                 236.65064103435725
time/total (s)                 6055.993064693175
Epoch                          25
-----------------------------  ---------------------
2023-07-31 19:38:59.161489 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 26 finished
-----------------------------  --------------------
replay_buffer/size             136000
trainer/tdrp Loss              [4047.3145]
trainer/QF1 Loss               0.20565091
trainer/QF2 Loss               0.2062541
trainer/Policy Loss            -65.68804
trainer/Q1 Predictions Mean    77.64126
trainer/Q1 Predictions Std     5.9205093
trainer/Q1 Predictions Max     87.09133
trainer/Q1 Predictions Min     49.673615
trainer/Q2 Predictions Mean    77.549934
trainer/Q2 Predictions Std     5.9084044
trainer/Q2 Predictions Max     87.5162
trainer/Q2 Predictions Min     49.574387
trainer/Q Targets Mean         77.56652
trainer/Q Targets Std          5.910152
trainer/Q Targets Max          87.04494
trainer/Q Targets Min          49.66561
trainer/Log Pis Mean           12.033691
trainer/Log Pis Std            9.711477
trainer/Log Pis Max            41.71666
trainer/Log Pis Min            -9.169011
trainer/Policy mu Mean         0.08264365
trainer/Policy mu Std          1.7651962
trainer/Policy mu Max          4.7854304
trainer/Policy mu Min          -5.6441097
trainer/Policy log std Mean    -0.32565656
trainer/Policy log std Std     0.14171818
trainer/Policy log std Max     0.32841116
trainer/Policy log std Min     -0.9494724
trainer/Alpha                  0.003479460021480918
trainer/Alpha Loss             0.1907205581665039
exploration/num steps total    136000
exploration/num paths total    272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5307806100786556
exploration/Rewards Std        0.07669659795265786
exploration/Rewards Max        0.7186991012040393
exploration/Rewards Min        0.24709122295875008
exploration/Returns Mean       265.3903050393278
exploration/Returns Std        9.960010624512222
exploration/Returns Max        284.98726041048565
exploration/Returns Min        250.7853422957563
exploration/Actions Mean       0.054550834
exploration/Actions Std        0.7302051
exploration/Actions Max        0.99998635
exploration/Actions Min        -0.99999857
exploration/Num Paths          10
exploration/Average Returns    265.3903050393278
evaluation/num steps total     135000
evaluation/num paths total     270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5313957097795524
evaluation/Rewards Std         0.07657857055252111
evaluation/Rewards Max         0.9652307838283534
evaluation/Rewards Min         0.272707326884139
evaluation/Returns Mean        265.69785488977607
evaluation/Returns Std         8.704405256280086
evaluation/Returns Max         284.62611394425664
evaluation/Returns Min         252.156601639739
evaluation/ExplReturns Mean    265.69785488977607
evaluation/ExplReturns Std     8.704405256280086
evaluation/ExplReturns Max     284.62611394425664
evaluation/ExplReturns Min     252.156601639739
evaluation/Actions Mean        0.045625832
evaluation/Actions Std         0.68344986
evaluation/Actions Max         0.99994826
evaluation/Actions Min         -0.9999736
evaluation/Num Paths           10
evaluation/Average Returns     265.69785488977607
time/data storing (s)          0.034233082085847855
time/evaluation sampling (s)   112.59717561956495
time/exploration sampling (s)  113.00063192844391
time/logging (s)               0.030740737915039062
time/saving (s)                0.012822984717786312
time/training (s)              9.420772387646139
time/epoch (s)                 235.09637674037367
time/total (s)                 6291.091942459345
Epoch                          26
-----------------------------  --------------------
2023-07-31 19:42:51.497723 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 27 finished
-----------------------------  --------------------
replay_buffer/size             141000
trainer/tdrp Loss              [4453.544]
trainer/QF1 Loss               0.20706981
trainer/QF2 Loss               0.21950933
trainer/Policy Loss            -65.246445
trainer/Q1 Predictions Mean    76.16167
trainer/Q1 Predictions Std     4.958589
trainer/Q1 Predictions Max     83.41967
trainer/Q1 Predictions Min     49.01039
trainer/Q2 Predictions Mean    76.133316
trainer/Q2 Predictions Std     4.949861
trainer/Q2 Predictions Max     83.29704
trainer/Q2 Predictions Min     48.965805
trainer/Q Targets Mean         76.15811
trainer/Q Targets Std          4.9675274
trainer/Q Targets Max          83.70336
trainer/Q Targets Min          49.30229
trainer/Log Pis Mean           10.990174
trainer/Log Pis Std            8.282746
trainer/Log Pis Max            49.73401
trainer/Log Pis Min            -8.977056
trainer/Policy mu Mean         0.1654616
trainer/Policy mu Std          1.6849684
trainer/Policy mu Max          4.886883
trainer/Policy mu Min          -4.8782573
trainer/Policy log std Mean    -0.3412782
trainer/Policy log std Std     0.13790834
trainer/Policy log std Max     0.21034457
trainer/Policy log std Min     -0.99532956
trainer/Alpha                  0.003389333840459585
trainer/Alpha Loss             -5.74304723739624
exploration/num steps total    141000
exploration/num paths total    282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5113370941357717
exploration/Rewards Std        0.0863346512299538
exploration/Rewards Max        0.7123704880430277
exploration/Rewards Min        0.21236933483363438
exploration/Returns Mean       255.66854706788595
exploration/Returns Std        8.094424724170809
exploration/Returns Max        270.2973957068496
exploration/Returns Min        244.18752602657958
exploration/Actions Mean       0.04253434
exploration/Actions Std        0.74318767
exploration/Actions Max        0.99999785
exploration/Actions Min        -0.999992
exploration/Num Paths          10
exploration/Average Returns    255.66854706788595
evaluation/num steps total     140000
evaluation/num paths total     280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4950978021519784
evaluation/Rewards Std         0.10730709614768626
evaluation/Rewards Max         0.7184200179874399
evaluation/Rewards Min         0.11094920346812938
evaluation/Returns Mean        247.54890107598916
evaluation/Returns Std         17.555757479608257
evaluation/Returns Max         268.3393448167168
evaluation/Returns Min         202.78860679416385
evaluation/ExplReturns Mean    247.54890107598916
evaluation/ExplReturns Std     17.555757479608257
evaluation/ExplReturns Max     268.3393448167168
evaluation/ExplReturns Min     202.78860679416385
evaluation/Actions Mean        0.019995643
evaluation/Actions Std         0.73697335
evaluation/Actions Max         0.9999908
evaluation/Actions Min         -0.9999696
evaluation/Num Paths           10
evaluation/Average Returns     247.54890107598916
time/data storing (s)          0.03382853604853153
time/evaluation sampling (s)   111.68697195127606
time/exploration sampling (s)  111.1487743454054
time/logging (s)               0.03162194322794676
time/saving (s)                0.012706122361123562
time/training (s)              9.419834066182375
time/epoch (s)                 232.33373696450144
time/total (s)                 6523.428199789487
Epoch                          27
-----------------------------  --------------------
2023-07-31 19:46:52.621405 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 28 finished
-----------------------------  ---------------------
replay_buffer/size             146000
trainer/tdrp Loss              [4434.606]
trainer/QF1 Loss               0.1948737
trainer/QF2 Loss               0.19758143
trainer/Policy Loss            -62.578617
trainer/Q1 Predictions Mean    74.94597
trainer/Q1 Predictions Std     5.857488
trainer/Q1 Predictions Max     85.55158
trainer/Q1 Predictions Min     31.71848
trainer/Q2 Predictions Mean    74.94768
trainer/Q2 Predictions Std     5.8736844
trainer/Q2 Predictions Max     85.483574
trainer/Q2 Predictions Min     31.381435
trainer/Q Targets Mean         74.92413
trainer/Q Targets Std          5.853707
trainer/Q Targets Max          85.9394
trainer/Q Targets Min          31.31426
trainer/Log Pis Mean           12.470101
trainer/Log Pis Std            9.021737
trainer/Log Pis Max            50.872124
trainer/Log Pis Min            -5.2878294
trainer/Policy mu Mean         -0.11301864
trainer/Policy mu Std          1.7937154
trainer/Policy mu Max          4.8198533
trainer/Policy mu Min          -5.9488406
trainer/Policy log std Mean    -0.3309078
trainer/Policy log std Std     0.14831683
trainer/Policy log std Max     0.20704252
trainer/Policy log std Min     -1.0292742
trainer/Alpha                  0.0032373543363064528
trainer/Alpha Loss             2.695096969604492
exploration/num steps total    146000
exploration/num paths total    292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4828775857072831
exploration/Rewards Std        0.09256219487058065
exploration/Rewards Max        0.7094578563358507
exploration/Rewards Min        0.2527163918878938
exploration/Returns Mean       241.43879285364156
exploration/Returns Std        26.900180759543176
exploration/Returns Max        271.13105567154656
exploration/Returns Min        190.1252248890125
exploration/Actions Mean       -0.041653037
exploration/Actions Std        0.7541563
exploration/Actions Max        0.9999975
exploration/Actions Min        -0.9999995
exploration/Num Paths          10
exploration/Average Returns    241.43879285364156
evaluation/num steps total     145000
evaluation/num paths total     290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4741562788075116
evaluation/Rewards Std         0.08946313240985827
evaluation/Rewards Max         0.7077962501109104
evaluation/Rewards Min         0.265391297340914
evaluation/Returns Mean        237.07813940375576
evaluation/Returns Std         18.52841178319607
evaluation/Returns Max         272.7960312046117
evaluation/Returns Min         202.68804916350084
evaluation/ExplReturns Mean    237.07813940375576
evaluation/ExplReturns Std     18.52841178319607
evaluation/ExplReturns Max     272.7960312046117
evaluation/ExplReturns Min     202.68804916350084
evaluation/Actions Mean        -0.1110171
evaluation/Actions Std         0.71436024
evaluation/Actions Max         0.9999995
evaluation/Actions Min         -0.99999654
evaluation/Num Paths           10
evaluation/Average Returns     237.07813940375576
time/data storing (s)          0.033659751527011395
time/evaluation sampling (s)   116.39386985637248
time/exploration sampling (s)  116.0752415806055
time/logging (s)               0.030531100928783417
time/saving (s)                0.01223387848585844
time/training (s)              8.573430823162198
time/epoch (s)                 241.11896699108183
time/total (s)                 6764.549993775785
Epoch                          28
-----------------------------  ---------------------
2023-07-31 19:50:46.591316 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 29 finished
-----------------------------  --------------------
replay_buffer/size             151000
trainer/tdrp Loss              [4309.6787]
trainer/QF1 Loss               0.1888594
trainer/QF2 Loss               0.1804104
trainer/Policy Loss            -61.906227
trainer/Q1 Predictions Mean    73.310745
trainer/Q1 Predictions Std     5.5799093
trainer/Q1 Predictions Max     82.10806
trainer/Q1 Predictions Min     46.820023
trainer/Q2 Predictions Mean    73.30678
trainer/Q2 Predictions Std     5.6557603
trainer/Q2 Predictions Max     82.194016
trainer/Q2 Predictions Min     46.7939
trainer/Q Targets Mean         73.24161
trainer/Q Targets Std          5.6556005
trainer/Q Targets Max          82.14679
trainer/Q Targets Min          46.484295
trainer/Log Pis Mean           11.510599
trainer/Log Pis Std            10.17819
trainer/Log Pis Max            44.15351
trainer/Log Pis Min            -8.081003
trainer/Policy mu Mean         -0.23365916
trainer/Policy mu Std          1.7284058
trainer/Policy mu Max          5.392359
trainer/Policy mu Min          -5.201362
trainer/Policy log std Mean    -0.29849932
trainer/Policy log std Std     0.14691801
trainer/Policy log std Max     0.22408292
trainer/Policy log std Min     -0.8869987
trainer/Alpha                  0.003374940250068903
trainer/Alpha Loss             -2.7852988243103027
exploration/num steps total    151000
exploration/num paths total    302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.501726803701919
exploration/Rewards Std        0.10925135207010991
exploration/Rewards Max        0.9699870068563226
exploration/Rewards Min        0.19951134765774003
exploration/Returns Mean       250.8634018509594
exploration/Returns Std        29.25430000255334
exploration/Returns Max        319.8474195403185
exploration/Returns Min        210.57467314750818
exploration/Actions Mean       -0.12002209
exploration/Actions Std        0.73531765
exploration/Actions Max        0.99999833
exploration/Actions Min        -0.9999966
exploration/Num Paths          10
exploration/Average Returns    250.8634018509594
evaluation/num steps total     150000
evaluation/num paths total     300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.49403150273475377
evaluation/Rewards Std         0.09792377626571071
evaluation/Rewards Max         0.7037776466968558
evaluation/Rewards Min         0.16134294454451484
evaluation/Returns Mean        247.01575136737688
evaluation/Returns Std         13.991443334179703
evaluation/Returns Max         271.86638234305616
evaluation/Returns Min         227.05172387922727
evaluation/ExplReturns Mean    247.01575136737688
evaluation/ExplReturns Std     13.991443334179703
evaluation/ExplReturns Max     271.86638234305616
evaluation/ExplReturns Min     227.05172387922727
evaluation/Actions Mean        -0.018308826
evaluation/Actions Std         0.70814997
evaluation/Actions Max         0.99998915
evaluation/Actions Min         -0.99999946
evaluation/Num Paths           10
evaluation/Average Returns     247.01575136737688
time/data storing (s)          0.0342148607596755
time/evaluation sampling (s)   111.09252477157861
time/exploration sampling (s)  113.53399165254086
time/logging (s)               0.030414587818086147
time/saving (s)                0.012617318890988827
time/training (s)              9.262733535841107
time/epoch (s)                 233.96649672742933
time/total (s)                 6998.518998637795
Epoch                          29
-----------------------------  --------------------
2023-07-31 19:54:41.623929 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 30 finished
-----------------------------  ---------------------
replay_buffer/size             156000
trainer/tdrp Loss              [4333.2197]
trainer/QF1 Loss               0.20606843
trainer/QF2 Loss               0.21078175
trainer/Policy Loss            -60.585876
trainer/Q1 Predictions Mean    72.31707
trainer/Q1 Predictions Std     5.22094
trainer/Q1 Predictions Max     80.77691
trainer/Q1 Predictions Min     47.390224
trainer/Q2 Predictions Mean    72.34418
trainer/Q2 Predictions Std     5.2066774
trainer/Q2 Predictions Max     80.714165
trainer/Q2 Predictions Min     47.302444
trainer/Q Targets Mean         72.294174
trainer/Q Targets Std          5.17638
trainer/Q Targets Max          80.80136
trainer/Q Targets Min          47.455208
trainer/Log Pis Mean           11.867651
trainer/Log Pis Std            9.104382
trainer/Log Pis Max            38.422485
trainer/Log Pis Min            -7.72533
trainer/Policy mu Mean         -0.014834653
trainer/Policy mu Std          1.7808391
trainer/Policy mu Max          6.0281663
trainer/Policy mu Min          -5.479287
trainer/Policy log std Mean    -0.32186612
trainer/Policy log std Std     0.15097137
trainer/Policy log std Max     0.17958815
trainer/Policy log std Min     -0.9050511
trainer/Alpha                  0.0033312211744487286
trainer/Alpha Loss             -0.7549809217453003
exploration/num steps total    156000
exploration/num paths total    312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5141634524563551
exploration/Rewards Std        0.10442075455236605
exploration/Rewards Max        0.7433810662753725
exploration/Rewards Min        0.18384990100788684
exploration/Returns Mean       257.08172622817744
exploration/Returns Std        27.310507479712115
exploration/Returns Max        287.11984029311105
exploration/Returns Min        208.0663834122729
exploration/Actions Mean       0.00024928336
exploration/Actions Std        0.75227696
exploration/Actions Max        0.9999792
exploration/Actions Min        -0.99999577
exploration/Num Paths          10
exploration/Average Returns    257.08172622817744
evaluation/num steps total     155000
evaluation/num paths total     310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5041327552694269
evaluation/Rewards Std         0.09456884403034746
evaluation/Rewards Max         0.724742479463488
evaluation/Rewards Min         0.15404261979778505
evaluation/Returns Mean        252.06637763471355
evaluation/Returns Std         17.6601740540451
evaluation/Returns Max         277.3118437107176
evaluation/Returns Min         221.94093212168227
evaluation/ExplReturns Mean    252.06637763471355
evaluation/ExplReturns Std     17.6601740540451
evaluation/ExplReturns Max     277.3118437107176
evaluation/ExplReturns Min     221.94093212168227
evaluation/Actions Mean        0.05289998
evaluation/Actions Std         0.70353156
evaluation/Actions Max         0.99996394
evaluation/Actions Min         -0.99997973
evaluation/Num Paths           10
evaluation/Average Returns     252.06637763471355
time/data storing (s)          0.03365615755319595
time/evaluation sampling (s)   111.53317657671869
time/exploration sampling (s)  113.49182177055627
time/logging (s)               0.03057354222983122
time/saving (s)                0.011314750649034977
time/training (s)              9.92893398180604
time/epoch (s)                 235.02947677951306
time/total (s)                 7233.550979743712
Epoch                          30
-----------------------------  ---------------------
2023-07-31 19:58:36.503259 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 31 finished
-----------------------------  ---------------------
replay_buffer/size             161000
trainer/tdrp Loss              [4555.7583]
trainer/QF1 Loss               0.18733194
trainer/QF2 Loss               0.18793052
trainer/Policy Loss            -60.115437
trainer/Q1 Predictions Mean    71.65636
trainer/Q1 Predictions Std     5.3533463
trainer/Q1 Predictions Max     80.13297
trainer/Q1 Predictions Min     46.380463
trainer/Q2 Predictions Mean    71.6552
trainer/Q2 Predictions Std     5.3791876
trainer/Q2 Predictions Max     79.980644
trainer/Q2 Predictions Min     46.26121
trainer/Q Targets Mean         71.706024
trainer/Q Targets Std          5.338419
trainer/Q Targets Max          80.308525
trainer/Q Targets Min          46.45454
trainer/Log Pis Mean           11.62924
trainer/Log Pis Std            9.920305
trainer/Log Pis Max            52.237305
trainer/Log Pis Min            -6.6025295
trainer/Policy mu Mean         0.01410021
trainer/Policy mu Std          1.7582961
trainer/Policy mu Max          6.343318
trainer/Policy mu Min          -7.0815854
trainer/Policy log std Mean    -0.32201728
trainer/Policy log std Std     0.14661443
trainer/Policy log std Max     0.2616412
trainer/Policy log std Min     -1.070433
trainer/Alpha                  0.0034154639579355717
trainer/Alpha Loss             -2.105764150619507
exploration/num steps total    161000
exploration/num paths total    322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5313830736398624
exploration/Rewards Std        0.08976181120840485
exploration/Rewards Max        0.7165694607343946
exploration/Rewards Min        0.18584372783765624
exploration/Returns Mean       265.6915368199312
exploration/Returns Std        16.710496692276163
exploration/Returns Max        292.2074294087894
exploration/Returns Min        239.47457942760988
exploration/Actions Mean       0.047639642
exploration/Actions Std        0.73729306
exploration/Actions Max        0.9999985
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    265.6915368199312
evaluation/num steps total     160000
evaluation/num paths total     320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5064757866123206
evaluation/Rewards Std         0.09812990967110533
evaluation/Rewards Max         0.9206116299374539
evaluation/Rewards Min         0.15661900701981366
evaluation/Returns Mean        253.23789330616037
evaluation/Returns Std         12.651934412168025
evaluation/Returns Max         269.17590952047016
evaluation/Returns Min         227.42523162803732
evaluation/ExplReturns Mean    253.23789330616037
evaluation/ExplReturns Std     12.651934412168025
evaluation/ExplReturns Max     269.17590952047016
evaluation/ExplReturns Min     227.42523162803732
evaluation/Actions Mean        0.054167368
evaluation/Actions Std         0.7194609
evaluation/Actions Max         0.9999998
evaluation/Actions Min         -0.9999998
evaluation/Num Paths           10
evaluation/Average Returns     253.23789330616037
time/data storing (s)          0.034290509298443794
time/evaluation sampling (s)   112.26377915684134
time/exploration sampling (s)  113.20322860684246
time/logging (s)               0.030582381412386894
time/saving (s)                0.010595269501209259
time/training (s)              9.333571564406157
time/epoch (s)                 234.876047488302
time/total (s)                 7468.429509120993
Epoch                          31
-----------------------------  ---------------------
2023-07-31 20:02:31.130691 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 32 finished
-----------------------------  --------------------
replay_buffer/size             166000
trainer/tdrp Loss              [4223.491]
trainer/QF1 Loss               0.20384899
trainer/QF2 Loss               0.19660076
trainer/Policy Loss            -60.79265
trainer/Q1 Predictions Mean    70.88495
trainer/Q1 Predictions Std     4.686007
trainer/Q1 Predictions Max     77.702446
trainer/Q1 Predictions Min     48.79209
trainer/Q2 Predictions Mean    70.88822
trainer/Q2 Predictions Std     4.6760607
trainer/Q2 Predictions Max     77.85699
trainer/Q2 Predictions Min     48.99974
trainer/Q Targets Mean         71.047005
trainer/Q Targets Std          4.671518
trainer/Q Targets Max          78.06292
trainer/Q Targets Min          49.506718
trainer/Log Pis Mean           10.187629
trainer/Log Pis Std            9.421165
trainer/Log Pis Max            60.777405
trainer/Log Pis Min            -5.9386463
trainer/Policy mu Mean         -0.031169355
trainer/Policy mu Std          1.7016481
trainer/Policy mu Max          5.5009065
trainer/Policy mu Min          -5.6340404
trainer/Policy log std Mean    -0.29315946
trainer/Policy log std Std     0.13608924
trainer/Policy log std Max     0.24361132
trainer/Policy log std Min     -0.86634624
trainer/Alpha                  0.003409313503652811
trainer/Alpha Loss             -10.29617977142334
exploration/num steps total    166000
exploration/num paths total    332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5040384378339137
exploration/Rewards Std        0.11578156588956963
exploration/Rewards Max        0.9581978304398927
exploration/Rewards Min        0.1372810184977535
exploration/Returns Mean       252.0192189169568
exploration/Returns Std        34.99781040182125
exploration/Returns Max        323.7907052718839
exploration/Returns Min        173.96424006241537
exploration/Actions Mean       -0.037963957
exploration/Actions Std        0.74403554
exploration/Actions Max        0.9999992
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    252.0192189169568
evaluation/num steps total     165000
evaluation/num paths total     330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5044105672100957
evaluation/Rewards Std         0.10157375851173898
evaluation/Rewards Max         0.9632921382865014
evaluation/Rewards Min         0.24216381228118006
evaluation/Returns Mean        252.20528360504787
evaluation/Returns Std         25.761123634711662
evaluation/Returns Max         311.4333427984623
evaluation/Returns Min         227.13193845040806
evaluation/ExplReturns Mean    252.20528360504787
evaluation/ExplReturns Std     25.761123634711662
evaluation/ExplReturns Max     311.4333427984623
evaluation/ExplReturns Min     227.13193845040806
evaluation/Actions Mean        -0.016030554
evaluation/Actions Std         0.71092105
evaluation/Actions Max         0.9999947
evaluation/Actions Min         -0.9999976
evaluation/Num Paths           10
evaluation/Average Returns     252.20528360504787
time/data storing (s)          0.03392776846885681
time/evaluation sampling (s)   112.20725780446082
time/exploration sampling (s)  113.23094572965056
time/logging (s)               0.030371788889169693
time/saving (s)                0.010473886504769325
time/training (s)              9.110920462757349
time/epoch (s)                 234.62389744073153
time/total (s)                 7703.055900844745
Epoch                          32
-----------------------------  --------------------
2023-07-31 20:06:27.906928 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 33 finished
-----------------------------  ---------------------
replay_buffer/size             171000
trainer/tdrp Loss              [4362.1777]
trainer/QF1 Loss               0.15381305
trainer/QF2 Loss               0.13286343
trainer/Policy Loss            -57.917763
trainer/Q1 Predictions Mean    70.566284
trainer/Q1 Predictions Std     4.160739
trainer/Q1 Predictions Max     78.234695
trainer/Q1 Predictions Min     50.103706
trainer/Q2 Predictions Mean    70.52344
trainer/Q2 Predictions Std     4.1611776
trainer/Q2 Predictions Max     77.98048
trainer/Q2 Predictions Min     50.085545
trainer/Q Targets Mean         70.49917
trainer/Q Targets Std          4.1722593
trainer/Q Targets Max          77.96283
trainer/Q Targets Min          49.188007
trainer/Log Pis Mean           12.736464
trainer/Log Pis Std            11.234587
trainer/Log Pis Max            70.63138
trainer/Log Pis Min            -8.706845
trainer/Policy mu Mean         0.14014561
trainer/Policy mu Std          1.8283801
trainer/Policy mu Max          6.2212524
trainer/Policy mu Min          -6.648777
trainer/Policy log std Mean    -0.31679627
trainer/Policy log std Std     0.13447878
trainer/Policy log std Max     0.26967996
trainer/Policy log std Min     -0.84717596
trainer/Alpha                  0.0033365164417773485
trainer/Alpha Loss             4.199984550476074
exploration/num steps total    171000
exploration/num paths total    342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5435390255676551
exploration/Rewards Std        0.09145810782482848
exploration/Rewards Max        0.9700898748299601
exploration/Rewards Min        0.2104261276155037
exploration/Returns Mean       271.7695127838277
exploration/Returns Std        11.738979637459499
exploration/Returns Max        287.99203330647737
exploration/Returns Min        247.1168062823354
exploration/Actions Mean       0.06818349
exploration/Actions Std        0.7511871
exploration/Actions Max        0.9999999
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    271.7695127838277
evaluation/num steps total     170000
evaluation/num paths total     340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5249207805251308
evaluation/Rewards Std         0.09305255048875215
evaluation/Rewards Max         0.7137424342198537
evaluation/Rewards Min         0.26054695772293507
evaluation/Returns Mean        262.4603902625654
evaluation/Returns Std         17.05962668935837
evaluation/Returns Max         300.07713613825575
evaluation/Returns Min         227.15947948053088
evaluation/ExplReturns Mean    262.4603902625654
evaluation/ExplReturns Std     17.05962668935837
evaluation/ExplReturns Max     300.07713613825575
evaluation/ExplReturns Min     227.15947948053088
evaluation/Actions Mean        0.051640376
evaluation/Actions Std         0.73017704
evaluation/Actions Max         0.99999315
evaluation/Actions Min         -0.9999972
evaluation/Num Paths           10
evaluation/Average Returns     262.4603902625654
time/data storing (s)          0.03332459460943937
time/evaluation sampling (s)   113.23982091713697
time/exploration sampling (s)  113.29991668183357
time/logging (s)               0.030406964011490345
time/saving (s)                0.011805999092757702
time/training (s)              10.157713662832975
time/epoch (s)                 236.7729888195172
time/total (s)                 7939.831337108277
Epoch                          33
-----------------------------  ---------------------
2023-07-31 20:10:21.805626 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 34 finished
-----------------------------  ---------------------
replay_buffer/size             176000
trainer/tdrp Loss              [4286.231]
trainer/QF1 Loss               0.19719465
trainer/QF2 Loss               0.20563097
trainer/Policy Loss            -59.135597
trainer/Q1 Predictions Mean    69.98091
trainer/Q1 Predictions Std     3.6711998
trainer/Q1 Predictions Max     77.95899
trainer/Q1 Predictions Min     56.357517
trainer/Q2 Predictions Mean    69.98072
trainer/Q2 Predictions Std     3.6582475
trainer/Q2 Predictions Max     77.83806
trainer/Q2 Predictions Min     56.67668
trainer/Q Targets Mean         69.811005
trainer/Q Targets Std          3.6891217
trainer/Q Targets Max          77.6659
trainer/Q Targets Min          56.280624
trainer/Log Pis Mean           10.910946
trainer/Log Pis Std            9.407326
trainer/Log Pis Max            50.09371
trainer/Log Pis Min            -8.273566
trainer/Policy mu Mean         0.111578465
trainer/Policy mu Std          1.7444825
trainer/Policy mu Max          5.396878
trainer/Policy mu Min          -5.499671
trainer/Policy log std Mean    -0.28705847
trainer/Policy log std Std     0.16129373
trainer/Policy log std Max     0.3277626
trainer/Policy log std Min     -0.7537941
trainer/Alpha                  0.0032521316315978765
trainer/Alpha Loss             -6.238565444946289
exploration/num steps total    176000
exploration/num paths total    352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5036093367204119
exploration/Rewards Std        0.08762136259810802
exploration/Rewards Max        0.704678651777843
exploration/Rewards Min        0.22001367771080893
exploration/Returns Mean       251.8046683602059
exploration/Returns Std        15.501211618579976
exploration/Returns Max        272.0217050773364
exploration/Returns Min        225.90039682393197
exploration/Actions Mean       0.06738092
exploration/Actions Std        0.7304032
exploration/Actions Max        0.9999996
exploration/Actions Min        -0.9999744
exploration/Num Paths          10
exploration/Average Returns    251.8046683602059
evaluation/num steps total     175000
evaluation/num paths total     350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4877170264054745
evaluation/Rewards Std         0.0809194412826964
evaluation/Rewards Max         0.7307423912808908
evaluation/Rewards Min         0.1745859116753745
evaluation/Returns Mean        243.85851320273719
evaluation/Returns Std         13.204633502420801
evaluation/Returns Max         276.4928332343743
evaluation/Returns Min         225.79851402849357
evaluation/ExplReturns Mean    243.85851320273719
evaluation/ExplReturns Std     13.204633502420801
evaluation/ExplReturns Max     276.4928332343743
evaluation/ExplReturns Min     225.79851402849357
evaluation/Actions Mean        0.10981873
evaluation/Actions Std         0.67073095
evaluation/Actions Max         0.99999976
evaluation/Actions Min         -0.99999774
evaluation/Num Paths           10
evaluation/Average Returns     243.85851320273719
time/data storing (s)          0.0344585170969367
time/evaluation sampling (s)   111.53206243366003
time/exploration sampling (s)  112.84766242466867
time/logging (s)               0.03184452932327986
time/saving (s)                0.01171422004699707
time/training (s)              9.439053865149617
time/epoch (s)                 233.89679598994553
time/total (s)                 8173.730614271946
Epoch                          34
-----------------------------  ---------------------
2023-07-31 20:14:17.554592 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 35 finished
-----------------------------  --------------------
replay_buffer/size             181000
trainer/tdrp Loss              [3974.9885]
trainer/QF1 Loss               0.19091554
trainer/QF2 Loss               0.18140492
trainer/Policy Loss            -55.707542
trainer/Q1 Predictions Mean    67.86157
trainer/Q1 Predictions Std     4.50799
trainer/Q1 Predictions Max     77.72667
trainer/Q1 Predictions Min     49.68769
trainer/Q2 Predictions Mean    67.90711
trainer/Q2 Predictions Std     4.5334573
trainer/Q2 Predictions Max     77.76013
trainer/Q2 Predictions Min     49.392628
trainer/Q Targets Mean         67.87905
trainer/Q Targets Std          4.473222
trainer/Q Targets Max          78.40266
trainer/Q Targets Min          49.02426
trainer/Log Pis Mean           12.28056
trainer/Log Pis Std            8.993902
trainer/Log Pis Max            47.305428
trainer/Log Pis Min            -5.913113
trainer/Policy mu Mean         -0.049040258
trainer/Policy mu Std          1.8141073
trainer/Policy mu Max          7.7924085
trainer/Policy mu Min          -6.605841
trainer/Policy log std Mean    -0.30451643
trainer/Policy log std Std     0.13173299
trainer/Policy log std Max     0.32091165
trainer/Policy log std Min     -0.8163607
trainer/Alpha                  0.003306320635601878
trainer/Alpha Loss             1.6025609970092773
exploration/num steps total    181000
exploration/num paths total    362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.49115623297583605
exploration/Rewards Std        0.09843697331603657
exploration/Rewards Max        0.7018592368522514
exploration/Rewards Min        0.21479847788385178
exploration/Returns Mean       245.57811648791804
exploration/Returns Std        25.31670962067093
exploration/Returns Max        290.13212455398457
exploration/Returns Min        219.7172083679818
exploration/Actions Mean       -0.0091733895
exploration/Actions Std        0.7246642
exploration/Actions Max        0.9999994
exploration/Actions Min        -0.9999966
exploration/Num Paths          10
exploration/Average Returns    245.57811648791804
evaluation/num steps total     180000
evaluation/num paths total     360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5058121468874466
evaluation/Rewards Std         0.09098930023296674
evaluation/Rewards Max         0.9724144823072151
evaluation/Rewards Min         0.25583040544455976
evaluation/Returns Mean        252.9060734437233
evaluation/Returns Std         12.237221899975344
evaluation/Returns Max         272.634565418732
evaluation/Returns Min         231.15753897616455
evaluation/ExplReturns Mean    252.9060734437233
evaluation/ExplReturns Std     12.237221899975344
evaluation/ExplReturns Max     272.634565418732
evaluation/ExplReturns Min     231.15753897616455
evaluation/Actions Mean        -0.009059871
evaluation/Actions Std         0.6827797
evaluation/Actions Max         0.9999976
evaluation/Actions Min         -0.9999671
evaluation/Num Paths           10
evaluation/Average Returns     252.9060734437233
time/data storing (s)          0.03412545844912529
time/evaluation sampling (s)   113.22530980966985
time/exploration sampling (s)  112.41643182747066
time/logging (s)               0.03037084173411131
time/saving (s)                0.015727325342595577
time/training (s)              10.022192860022187
time/epoch (s)                 235.74415812268853
time/total (s)                 8409.477256783284
Epoch                          35
-----------------------------  --------------------
2023-07-31 20:18:10.690172 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 36 finished
-----------------------------  --------------------
replay_buffer/size             186000
trainer/tdrp Loss              [4253.464]
trainer/QF1 Loss               0.1905354
trainer/QF2 Loss               0.19226712
trainer/Policy Loss            -55.887146
trainer/Q1 Predictions Mean    68.133514
trainer/Q1 Predictions Std     4.434756
trainer/Q1 Predictions Max     75.165115
trainer/Q1 Predictions Min     36.7374
trainer/Q2 Predictions Mean    68.08389
trainer/Q2 Predictions Std     4.4178286
trainer/Q2 Predictions Max     75.07186
trainer/Q2 Predictions Min     36.871395
trainer/Q Targets Mean         67.936516
trainer/Q Targets Std          4.4288974
trainer/Q Targets Max          74.908195
trainer/Q Targets Min          36.435284
trainer/Log Pis Mean           12.325724
trainer/Log Pis Std            9.690688
trainer/Log Pis Max            56.074486
trainer/Log Pis Min            -8.930642
trainer/Policy mu Mean         0.14338838
trainer/Policy mu Std          1.800328
trainer/Policy mu Max          7.121219
trainer/Policy mu Min          -5.9931965
trainer/Policy log std Mean    -0.29639623
trainer/Policy log std Std     0.1422954
trainer/Policy log std Max     0.2630486
trainer/Policy log std Min     -0.9657062
trainer/Alpha                  0.003202216001227498
trainer/Alpha Loss             1.8709001541137695
exploration/num steps total    186000
exploration/num paths total    372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5408779611906473
exploration/Rewards Std        0.08851562453913558
exploration/Rewards Max        0.9550256260937003
exploration/Rewards Min        0.2895814654075764
exploration/Returns Mean       270.4389805953236
exploration/Returns Std        18.835190436679632
exploration/Returns Max        298.4399864966882
exploration/Returns Min        238.1363935829622
exploration/Actions Mean       -0.017068563
exploration/Actions Std        0.71665084
exploration/Actions Max        0.9999976
exploration/Actions Min        -0.99999404
exploration/Num Paths          10
exploration/Average Returns    270.4389805953236
evaluation/num steps total     185000
evaluation/num paths total     370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5254032668274848
evaluation/Rewards Std         0.08415685696480604
evaluation/Rewards Max         0.7389371971131058
evaluation/Rewards Min         0.1822016713453246
evaluation/Returns Mean        262.70163341374234
evaluation/Returns Std         18.93830780205867
evaluation/Returns Max         297.20046356420164
evaluation/Returns Min         237.40259035484445
evaluation/ExplReturns Mean    262.70163341374234
evaluation/ExplReturns Std     18.93830780205867
evaluation/ExplReturns Max     297.20046356420164
evaluation/ExplReturns Min     237.40259035484445
evaluation/Actions Mean        0.016722038
evaluation/Actions Std         0.6604186
evaluation/Actions Max         0.99999166
evaluation/Actions Min         -0.99999225
evaluation/Num Paths           10
evaluation/Average Returns     262.70163341374234
time/data storing (s)          0.03395998664200306
time/evaluation sampling (s)   111.00062595680356
time/exploration sampling (s)  112.64989959169179
time/logging (s)               0.03047681413590908
time/saving (s)                0.012006565928459167
time/training (s)              9.405392732471228
time/epoch (s)                 233.13236164767295
time/total (s)                 8642.612084366381
Epoch                          36
-----------------------------  --------------------
2023-07-31 20:22:10.064165 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 37 finished
-----------------------------  --------------------
replay_buffer/size             191000
trainer/tdrp Loss              [4321.817]
trainer/QF1 Loss               0.16417384
trainer/QF2 Loss               0.17413053
trainer/Policy Loss            -56.066887
trainer/Q1 Predictions Mean    67.61311
trainer/Q1 Predictions Std     3.5793078
trainer/Q1 Predictions Max     74.04547
trainer/Q1 Predictions Min     50.086823
trainer/Q2 Predictions Mean    67.61888
trainer/Q2 Predictions Std     3.5816634
trainer/Q2 Predictions Max     74.20413
trainer/Q2 Predictions Min     50.050488
trainer/Q Targets Mean         67.55989
trainer/Q Targets Std          3.603353
trainer/Q Targets Max          74.519104
trainer/Q Targets Min          49.683403
trainer/Log Pis Mean           11.654364
trainer/Log Pis Std            8.956006
trainer/Log Pis Max            41.050842
trainer/Log Pis Min            -6.908407
trainer/Policy mu Mean         -0.022919947
trainer/Policy mu Std          1.7718666
trainer/Policy mu Max          5.1730537
trainer/Policy mu Min          -7.052877
trainer/Policy log std Mean    -0.31215337
trainer/Policy log std Std     0.13845697
trainer/Policy log std Max     0.25538808
trainer/Policy log std Min     -0.91849744
trainer/Alpha                  0.003378999652341008
trainer/Alpha Loss             -1.9666862487792969
exploration/num steps total    191000
exploration/num paths total    382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5471133023507873
exploration/Rewards Std        0.08323088464289025
exploration/Rewards Max        0.7292020516675178
exploration/Rewards Min        0.2963392988155114
exploration/Returns Mean       273.55665117539377
exploration/Returns Std        17.414274779587345
exploration/Returns Max        307.9131837468288
exploration/Returns Min        240.97134650146998
exploration/Actions Mean       -0.08998825
exploration/Actions Std        0.7419144
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    273.55665117539377
evaluation/num steps total     190000
evaluation/num paths total     380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5424628491329837
evaluation/Rewards Std         0.09659311141961581
evaluation/Rewards Max         0.7366602981213903
evaluation/Rewards Min         0.2074984193110721
evaluation/Returns Mean        271.23142456649185
evaluation/Returns Std         28.611133809629457
evaluation/Returns Max         301.64369555547336
evaluation/Returns Min         191.19586899387645
evaluation/ExplReturns Mean    271.23142456649185
evaluation/ExplReturns Std     28.611133809629457
evaluation/ExplReturns Max     301.64369555547336
evaluation/ExplReturns Min     191.19586899387645
evaluation/Actions Mean        -0.08377674
evaluation/Actions Std         0.69679964
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -0.9999998
evaluation/Num Paths           10
evaluation/Average Returns     271.23142456649185
time/data storing (s)          0.03414990473538637
time/evaluation sampling (s)   114.47212233766913
time/exploration sampling (s)  115.36629663500935
time/logging (s)               0.030461179092526436
time/saving (s)                0.011548450216650963
time/training (s)              9.455867271870375
time/epoch (s)                 239.37044577859342
time/total (s)                 8881.9852121789
Epoch                          37
-----------------------------  --------------------
2023-07-31 20:26:06.330780 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 38 finished
-----------------------------  --------------------
replay_buffer/size             196000
trainer/tdrp Loss              [4049.9822]
trainer/QF1 Loss               0.1738445
trainer/QF2 Loss               0.19831498
trainer/Policy Loss            -54.56428
trainer/Q1 Predictions Mean    66.733284
trainer/Q1 Predictions Std     4.165223
trainer/Q1 Predictions Max     72.623604
trainer/Q1 Predictions Min     37.391464
trainer/Q2 Predictions Mean    66.71044
trainer/Q2 Predictions Std     4.167039
trainer/Q2 Predictions Max     72.77047
trainer/Q2 Predictions Min     37.426785
trainer/Q Targets Mean         66.83278
trainer/Q Targets Std          4.199757
trainer/Q Targets Max          72.87331
trainer/Q Targets Min          37.49684
trainer/Log Pis Mean           12.261296
trainer/Log Pis Std            9.701265
trainer/Log Pis Max            52.615093
trainer/Log Pis Min            -9.638253
trainer/Policy mu Mean         0.018477662
trainer/Policy mu Std          1.7672037
trainer/Policy mu Max          4.7944183
trainer/Policy mu Min          -5.2813606
trainer/Policy log std Mean    -0.32426986
trainer/Policy log std Std     0.1388311
trainer/Policy log std Max     0.2530256
trainer/Policy log std Min     -0.89769566
trainer/Alpha                  0.003292095847427845
trainer/Alpha Loss             1.4936168193817139
exploration/num steps total    196000
exploration/num paths total    392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5509570215099631
exploration/Rewards Std        0.06898771451604474
exploration/Rewards Max        0.7187713691140174
exploration/Rewards Min        0.27958387364678816
exploration/Returns Mean       275.4785107549816
exploration/Returns Std        9.524826518529052
exploration/Returns Max        290.1149236071205
exploration/Returns Min        257.7091628535517
exploration/Actions Mean       -0.04081271
exploration/Actions Std        0.7294087
exploration/Actions Max        0.9999886
exploration/Actions Min        -0.9999981
exploration/Num Paths          10
exploration/Average Returns    275.4785107549816
evaluation/num steps total     195000
evaluation/num paths total     390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5442689775197468
evaluation/Rewards Std         0.07130133320933468
evaluation/Rewards Max         0.7354892693189748
evaluation/Rewards Min         0.3365502911784135
evaluation/Returns Mean        272.1344887598733
evaluation/Returns Std         6.0709608649918545
evaluation/Returns Max         283.5759717503154
evaluation/Returns Min         263.9670747608153
evaluation/ExplReturns Mean    272.1344887598733
evaluation/ExplReturns Std     6.0709608649918545
evaluation/ExplReturns Max     283.5759717503154
evaluation/ExplReturns Min     263.9670747608153
evaluation/Actions Mean        -0.018567754
evaluation/Actions Std         0.69255245
evaluation/Actions Max         0.99996877
evaluation/Actions Min         -0.99999136
evaluation/Num Paths           10
evaluation/Average Returns     272.1344887598733
time/data storing (s)          0.03432210814207792
time/evaluation sampling (s)   113.22507429867983
time/exploration sampling (s)  113.46708320081234
time/logging (s)               0.031110706739127636
time/saving (s)                0.011002677492797375
time/training (s)              9.49523958005011
time/epoch (s)                 236.26383257191628
time/total (s)                 9118.251568921842
Epoch                          38
-----------------------------  --------------------
2023-07-31 20:30:02.386821 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 39 finished
-----------------------------  --------------------
replay_buffer/size             201000
trainer/tdrp Loss              [4127.1597]
trainer/QF1 Loss               0.17010811
trainer/QF2 Loss               0.17945501
trainer/Policy Loss            -54.92975
trainer/Q1 Predictions Mean    66.05388
trainer/Q1 Predictions Std     3.6768427
trainer/Q1 Predictions Max     72.336235
trainer/Q1 Predictions Min     48.252304
trainer/Q2 Predictions Mean    66.07159
trainer/Q2 Predictions Std     3.705903
trainer/Q2 Predictions Max     72.30631
trainer/Q2 Predictions Min     48.291393
trainer/Q Targets Mean         66.02394
trainer/Q Targets Std          3.7187576
trainer/Q Targets Max          72.39923
trainer/Q Targets Min          48.210064
trainer/Log Pis Mean           11.23112
trainer/Log Pis Std            9.351699
trainer/Log Pis Max            46.577522
trainer/Log Pis Min            -8.754902
trainer/Policy mu Mean         -0.08762536
trainer/Policy mu Std          1.7563777
trainer/Policy mu Max          4.9963045
trainer/Policy mu Min          -7.177937
trainer/Policy log std Mean    -0.30789876
trainer/Policy log std Std     0.14075482
trainer/Policy log std Max     0.2910224
trainer/Policy log std Min     -0.926332
trainer/Alpha                  0.003207690082490444
trainer/Alpha Loss             -4.414741039276123
exploration/num steps total    201000
exploration/num paths total    402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5364299828899408
exploration/Rewards Std        0.09505595669326264
exploration/Rewards Max        0.7357512505072116
exploration/Rewards Min        0.25931154309142385
exploration/Returns Mean       268.2149914449703
exploration/Returns Std        22.440327939883364
exploration/Returns Max        320.3626262634667
exploration/Returns Min        237.4124449991905
exploration/Actions Mean       0.010221001
exploration/Actions Std        0.7394923
exploration/Actions Max        0.99999785
exploration/Actions Min        -0.9999977
exploration/Num Paths          10
exploration/Average Returns    268.2149914449703
evaluation/num steps total     200000
evaluation/num paths total     400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5256613977795344
evaluation/Rewards Std         0.09707600736128588
evaluation/Rewards Max         0.7494037368049045
evaluation/Rewards Min         0.226632049529885
evaluation/Returns Mean        262.8306988897672
evaluation/Returns Std         17.43457144563686
evaluation/Returns Max         292.20424548165494
evaluation/Returns Min         230.55465831481712
evaluation/ExplReturns Mean    262.8306988897672
evaluation/ExplReturns Std     17.43457144563686
evaluation/ExplReturns Max     292.20424548165494
evaluation/ExplReturns Min     230.55465831481712
evaluation/Actions Mean        -0.02069974
evaluation/Actions Std         0.69640267
evaluation/Actions Max         0.9999897
evaluation/Actions Min         -0.99999994
evaluation/Num Paths           10
evaluation/Average Returns     262.8306988897672
time/data storing (s)          0.034189216792583466
time/evaluation sampling (s)   112.42284497246146
time/exploration sampling (s)  114.29317422676831
time/logging (s)               0.030479193665087223
time/saving (s)                0.01029262412339449
time/training (s)              9.260986190289259
time/epoch (s)                 236.0519664241001
time/total (s)                 9354.306113316678
Epoch                          39
-----------------------------  --------------------
2023-07-31 20:33:57.858232 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 40 finished
-----------------------------  ---------------------
replay_buffer/size             206000
trainer/tdrp Loss              [4163.605]
trainer/QF1 Loss               0.2068864
trainer/QF2 Loss               0.20661178
trainer/Policy Loss            -51.665176
trainer/Q1 Predictions Mean    65.32039
trainer/Q1 Predictions Std     3.9202752
trainer/Q1 Predictions Max     71.54015
trainer/Q1 Predictions Min     48.61986
trainer/Q2 Predictions Mean    65.293274
trainer/Q2 Predictions Std     3.9078076
trainer/Q2 Predictions Max     71.57952
trainer/Q2 Predictions Min     48.170918
trainer/Q Targets Mean         65.477905
trainer/Q Targets Std          3.9758725
trainer/Q Targets Max          71.92361
trainer/Q Targets Min          48.42586
trainer/Log Pis Mean           13.73095
trainer/Log Pis Std            10.334446
trainer/Log Pis Max            57.209827
trainer/Log Pis Min            -8.847696
trainer/Policy mu Mean         -0.20448434
trainer/Policy mu Std          1.8687878
trainer/Policy mu Max          5.9987907
trainer/Policy mu Min          -10.798553
trainer/Policy log std Mean    -0.3099466
trainer/Policy log std Std     0.14662342
trainer/Policy log std Max     0.6736678
trainer/Policy log std Min     -0.89822304
trainer/Alpha                  0.0032481160014867783
trainer/Alpha Loss             9.918027877807617
exploration/num steps total    206000
exploration/num paths total    412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5094138087293192
exploration/Rewards Std        0.07898232503400385
exploration/Rewards Max        0.6959069379530918
exploration/Rewards Min        0.08888593844188103
exploration/Returns Mean       254.7069043646596
exploration/Returns Std        10.197606479101616
exploration/Returns Max        268.9272613589448
exploration/Returns Min        235.51138238144253
exploration/Actions Mean       -0.042582154
exploration/Actions Std        0.74209154
exploration/Actions Max        0.9999987
exploration/Actions Min        -0.9999997
exploration/Num Paths          10
exploration/Average Returns    254.7069043646596
evaluation/num steps total     205000
evaluation/num paths total     410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5128226430431325
evaluation/Rewards Std         0.08089131055649225
evaluation/Rewards Max         0.9259067742047972
evaluation/Rewards Min         0.19610727697443373
evaluation/Returns Mean        256.41132152156626
evaluation/Returns Std         17.36197315067205
evaluation/Returns Max         284.49664439542846
evaluation/Returns Min         218.90560402694564
evaluation/ExplReturns Mean    256.41132152156626
evaluation/ExplReturns Std     17.36197315067205
evaluation/ExplReturns Max     284.49664439542846
evaluation/ExplReturns Min     218.90560402694564
evaluation/Actions Mean        -0.05428517
evaluation/Actions Std         0.72405785
evaluation/Actions Max         0.9999913
evaluation/Actions Min         -0.99999964
evaluation/Num Paths           10
evaluation/Average Returns     256.41132152156626
time/data storing (s)          0.03373598400503397
time/evaluation sampling (s)   112.13613101933151
time/exploration sampling (s)  113.21395322680473
time/logging (s)               0.030590297654271126
time/saving (s)                0.012090645730495453
time/training (s)              10.041629910469055
time/epoch (s)                 235.4681310839951
time/total (s)                 9589.776748091914
Epoch                          40
-----------------------------  ---------------------
2023-07-31 20:37:48.739299 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 41 finished
-----------------------------  --------------------
replay_buffer/size             211000
trainer/tdrp Loss              [4304.8335]
trainer/QF1 Loss               0.18887943
trainer/QF2 Loss               0.20190391
trainer/Policy Loss            -52.76394
trainer/Q1 Predictions Mean    65.249054
trainer/Q1 Predictions Std     3.8259137
trainer/Q1 Predictions Max     71.94793
trainer/Q1 Predictions Min     45.638348
trainer/Q2 Predictions Mean    65.24385
trainer/Q2 Predictions Std     3.8131573
trainer/Q2 Predictions Max     71.84042
trainer/Q2 Predictions Min     45.741455
trainer/Q Targets Mean         65.12716
trainer/Q Targets Std          3.8400514
trainer/Q Targets Max          71.446785
trainer/Q Targets Min          45.601562
trainer/Log Pis Mean           12.586862
trainer/Log Pis Std            8.860415
trainer/Log Pis Max            43.595573
trainer/Log Pis Min            -7.0263586
trainer/Policy mu Mean         0.09647146
trainer/Policy mu Std          1.8169161
trainer/Policy mu Max          6.147489
trainer/Policy mu Min          -5.782808
trainer/Policy log std Mean    -0.30810782
trainer/Policy log std Std     0.13743708
trainer/Policy log std Max     0.38850856
trainer/Policy log std Min     -0.87459433
trainer/Alpha                  0.003124183276668191
trainer/Alpha Loss             3.385469913482666
exploration/num steps total    211000
exploration/num paths total    422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.502338767749028
exploration/Rewards Std        0.10020918739128826
exploration/Rewards Max        0.9581202754663812
exploration/Rewards Min        0.21991150108778995
exploration/Returns Mean       251.16938387451393
exploration/Returns Std        13.035833374708549
exploration/Returns Max        267.2175728829026
exploration/Returns Min        227.1091423321816
exploration/Actions Mean       0.07384008
exploration/Actions Std        0.74388
exploration/Actions Max        0.99999976
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    251.16938387451393
evaluation/num steps total     210000
evaluation/num paths total     420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.4988394688055387
evaluation/Rewards Std         0.08803601547854416
evaluation/Rewards Max         0.7148926303416673
evaluation/Rewards Min         0.24453086518742784
evaluation/Returns Mean        249.41973440276928
evaluation/Returns Std         13.471957679259043
evaluation/Returns Max         262.31499151257356
evaluation/Returns Min         212.49718663012624
evaluation/ExplReturns Mean    249.41973440276928
evaluation/ExplReturns Std     13.471957679259043
evaluation/ExplReturns Max     262.31499151257356
evaluation/ExplReturns Min     212.49718663012624
evaluation/Actions Mean        0.062959366
evaluation/Actions Std         0.71451217
evaluation/Actions Max         0.99999875
evaluation/Actions Min         -0.9999993
evaluation/Num Paths           10
evaluation/Average Returns     249.41973440276928
time/data storing (s)          0.03394803311675787
time/evaluation sampling (s)   110.64583625178784
time/exploration sampling (s)  110.7391018634662
time/logging (s)               0.030666889622807503
time/saving (s)                0.012746269814670086
time/training (s)              9.415513305924833
time/epoch (s)                 230.8778126137331
time/total (s)                 9820.657011842355
Epoch                          41
-----------------------------  --------------------
2023-07-31 20:41:43.025422 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 42 finished
-----------------------------  ---------------------
replay_buffer/size             216000
trainer/tdrp Loss              [4101.2964]
trainer/QF1 Loss               0.14662525
trainer/QF2 Loss               0.15368015
trainer/Policy Loss            -53.5166
trainer/Q1 Predictions Mean    64.771286
trainer/Q1 Predictions Std     3.3446383
trainer/Q1 Predictions Max     71.652115
trainer/Q1 Predictions Min     47.898247
trainer/Q2 Predictions Mean    64.74777
trainer/Q2 Predictions Std     3.3331106
trainer/Q2 Predictions Max     71.61413
trainer/Q2 Predictions Min     48.0283
trainer/Q Targets Mean         64.66086
trainer/Q Targets Std          3.3542652
trainer/Q Targets Max          71.66765
trainer/Q Targets Min          47.731106
trainer/Log Pis Mean           11.287691
trainer/Log Pis Std            8.638962
trainer/Log Pis Max            46.29942
trainer/Log Pis Min            -7.7552466
trainer/Policy mu Mean         -0.1674397
trainer/Policy mu Std          1.757053
trainer/Policy mu Max          5.526204
trainer/Policy mu Min          -6.497425
trainer/Policy log std Mean    -0.30096996
trainer/Policy log std Std     0.13330415
trainer/Policy log std Max     0.20999014
trainer/Policy log std Min     -0.79845667
trainer/Alpha                  0.0030751419253647327
trainer/Alpha Loss             -4.120264530181885
exploration/num steps total    216000
exploration/num paths total    432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4821510838867327
exploration/Rewards Std        0.09261077556838147
exploration/Rewards Max        0.7244435287309128
exploration/Rewards Min        0.2526553475549749
exploration/Returns Mean       241.07554194336635
exploration/Returns Std        17.32414496134467
exploration/Returns Max        272.7375592289928
exploration/Returns Min        224.36086038550195
exploration/Actions Mean       -0.019890824
exploration/Actions Std        0.72785246
exploration/Actions Max        0.999996
exploration/Actions Min        -0.9999986
exploration/Num Paths          10
exploration/Average Returns    241.07554194336635
evaluation/num steps total     215000
evaluation/num paths total     430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.546232413239821
evaluation/Rewards Std         0.11513997716942743
evaluation/Rewards Max         0.7356693058995001
evaluation/Rewards Min         0.22730148116805454
evaluation/Returns Mean        273.11620661991054
evaluation/Returns Std         37.59126277063027
evaluation/Returns Max         345.95612380012534
evaluation/Returns Min         221.32530099455158
evaluation/ExplReturns Mean    273.11620661991054
evaluation/ExplReturns Std     37.59126277063027
evaluation/ExplReturns Max     345.95612380012534
evaluation/ExplReturns Min     221.32530099455158
evaluation/Actions Mean        -0.0822086
evaluation/Actions Std         0.7010508
evaluation/Actions Max         0.9999489
evaluation/Actions Min         -0.99997425
evaluation/Num Paths           10
evaluation/Average Returns     273.11620661991054
time/data storing (s)          0.03370861802250147
time/evaluation sampling (s)   113.98647182062268
time/exploration sampling (s)  110.8488588584587
time/logging (s)               0.030469860881567
time/saving (s)                0.012142928317189217
time/training (s)              9.370827535167336
time/epoch (s)                 234.28247962146997
time/total (s)                 10054.942042804323
Epoch                          42
-----------------------------  ---------------------
2023-07-31 20:45:33.658605 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 43 finished
-----------------------------  ---------------------
replay_buffer/size             221000
trainer/tdrp Loss              [4141.8257]
trainer/QF1 Loss               0.16739218
trainer/QF2 Loss               0.17556347
trainer/Policy Loss            -51.99138
trainer/Q1 Predictions Mean    63.70424
trainer/Q1 Predictions Std     3.4981003
trainer/Q1 Predictions Max     70.6204
trainer/Q1 Predictions Min     43.66026
trainer/Q2 Predictions Mean    63.7242
trainer/Q2 Predictions Std     3.4822521
trainer/Q2 Predictions Max     70.806305
trainer/Q2 Predictions Min     44.00598
trainer/Q Targets Mean         63.68866
trainer/Q Targets Std          3.4500856
trainer/Q Targets Max          70.94468
trainer/Q Targets Min          44.151184
trainer/Log Pis Mean           11.830505
trainer/Log Pis Std            8.561348
trainer/Log Pis Max            46.37178
trainer/Log Pis Min            -5.456156
trainer/Policy mu Mean         -0.16685076
trainer/Policy mu Std          1.7748419
trainer/Policy mu Max          5.621902
trainer/Policy mu Min          -6.72767
trainer/Policy log std Mean    -0.3163283
trainer/Policy log std Std     0.13701649
trainer/Policy log std Max     0.20405094
trainer/Policy log std Min     -0.83174
trainer/Alpha                  0.0031397435814142227
trainer/Alpha Loss             -0.9769034385681152
exploration/num steps total    221000
exploration/num paths total    442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5006294088366052
exploration/Rewards Std        0.090041501457846
exploration/Rewards Max        0.7256186369964136
exploration/Rewards Min        0.24950679189408495
exploration/Returns Mean       250.31470441830257
exploration/Returns Std        11.707075855272368
exploration/Returns Max        272.68024867286243
exploration/Returns Min        229.19209950273367
exploration/Actions Mean       0.0023446605
exploration/Actions Std        0.741127
exploration/Actions Max        0.99999815
exploration/Actions Min        -0.9999999
exploration/Num Paths          10
exploration/Average Returns    250.31470441830257
evaluation/num steps total     220000
evaluation/num paths total     440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5083474010363032
evaluation/Rewards Std         0.08154911390788007
evaluation/Rewards Max         0.7110335961209048
evaluation/Rewards Min         0.20095490501927246
evaluation/Returns Mean        254.17370051815163
evaluation/Returns Std         13.470108376476263
evaluation/Returns Max         268.50022076735746
evaluation/Returns Min         230.6941992516201
evaluation/ExplReturns Mean    254.17370051815163
evaluation/ExplReturns Std     13.470108376476263
evaluation/ExplReturns Max     268.50022076735746
evaluation/ExplReturns Min     230.6941992516201
evaluation/Actions Mean        0.0017380937
evaluation/Actions Std         0.70997334
evaluation/Actions Max         0.9999897
evaluation/Actions Min         -0.99985373
evaluation/Num Paths           10
evaluation/Average Returns     254.17370051815163
time/data storing (s)          0.034356617368757725
time/evaluation sampling (s)   110.48810428474098
time/exploration sampling (s)  110.83752559684217
time/logging (s)               0.0303209675475955
time/saving (s)                0.010286662727594376
time/training (s)              9.229092461057007
time/epoch (s)                 230.6296865902841
time/total (s)                 10285.574190261774
Epoch                          43
-----------------------------  ---------------------
2023-07-31 20:49:29.020692 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 44 finished
-----------------------------  --------------------
replay_buffer/size             226000
trainer/tdrp Loss              [4003.816]
trainer/QF1 Loss               0.15126204
trainer/QF2 Loss               0.13589707
trainer/Policy Loss            -51.495056
trainer/Q1 Predictions Mean    63.430267
trainer/Q1 Predictions Std     3.5003967
trainer/Q1 Predictions Max     69.50113
trainer/Q1 Predictions Min     47.373913
trainer/Q2 Predictions Mean    63.37017
trainer/Q2 Predictions Std     3.5253472
trainer/Q2 Predictions Max     69.2725
trainer/Q2 Predictions Min     46.978584
trainer/Q Targets Mean         63.44157
trainer/Q Targets Std          3.5768132
trainer/Q Targets Max          69.544914
trainer/Q Targets Min          47.439934
trainer/Log Pis Mean           12.023759
trainer/Log Pis Std            9.39802
trainer/Log Pis Max            49.542152
trainer/Log Pis Min            -10.274218
trainer/Policy mu Mean         -0.088237725
trainer/Policy mu Std          1.8138292
trainer/Policy mu Max          6.2832317
trainer/Policy mu Min          -6.217834
trainer/Policy log std Mean    -0.29366204
trainer/Policy log std Std     0.14777964
trainer/Policy log std Max     0.35731658
trainer/Policy log std Min     -0.83815694
trainer/Alpha                  0.003080855356529355
trainer/Alpha Loss             0.13738417625427246
exploration/num steps total    226000
exploration/num paths total    452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5384386443031577
exploration/Rewards Std        0.07502465717526807
exploration/Rewards Max        0.7195353884381535
exploration/Rewards Min        0.25403879734069484
exploration/Returns Mean       269.21932215157887
exploration/Returns Std        11.400256745787969
exploration/Returns Max        291.69720799662286
exploration/Returns Min        255.86721500734353
exploration/Actions Mean       -0.041033264
exploration/Actions Std        0.70450526
exploration/Actions Max        0.9999995
exploration/Actions Min        -0.9999962
exploration/Num Paths          10
exploration/Average Returns    269.21932215157887
evaluation/num steps total     225000
evaluation/num paths total     450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5295282285427069
evaluation/Rewards Std         0.07856648982090454
evaluation/Rewards Max         0.9517335997244585
evaluation/Rewards Min         0.20308093258176704
evaluation/Returns Mean        264.7641142713534
evaluation/Returns Std         18.338718893488842
evaluation/Returns Max         293.16817703458634
evaluation/Returns Min         228.5900438813413
evaluation/ExplReturns Mean    264.7641142713534
evaluation/ExplReturns Std     18.338718893488842
evaluation/ExplReturns Max     293.16817703458634
evaluation/ExplReturns Min     228.5900438813413
evaluation/Actions Mean        -0.041551873
evaluation/Actions Std         0.6393501
evaluation/Actions Max         0.9999851
evaluation/Actions Min         -0.99998224
evaluation/Num Paths           10
evaluation/Average Returns     264.7641142713534
time/data storing (s)          0.03400444891303778
time/evaluation sampling (s)   112.3134943805635
time/exploration sampling (s)  113.6237702537328
time/logging (s)               0.030393488705158234
time/saving (s)                0.012310284189879894
time/training (s)              9.344872426241636
time/epoch (s)                 235.358845282346
time/total (s)                 10520.935461354442
Epoch                          44
-----------------------------  --------------------
2023-07-31 20:53:26.002112 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 45 finished
-----------------------------  --------------------
replay_buffer/size             231000
trainer/tdrp Loss              [4419.184]
trainer/QF1 Loss               0.19939603
trainer/QF2 Loss               0.17736383
trainer/Policy Loss            -49.57645
trainer/Q1 Predictions Mean    62.1848
trainer/Q1 Predictions Std     4.3115396
trainer/Q1 Predictions Max     70.050606
trainer/Q1 Predictions Min     39.95415
trainer/Q2 Predictions Mean    62.1895
trainer/Q2 Predictions Std     4.3125987
trainer/Q2 Predictions Max     70.31068
trainer/Q2 Predictions Min     40.02121
trainer/Q Targets Mean         62.292274
trainer/Q Targets Std          4.3385344
trainer/Q Targets Max          70.18623
trainer/Q Targets Min          40.001812
trainer/Log Pis Mean           12.710354
trainer/Log Pis Std            8.812747
trainer/Log Pis Max            39.901924
trainer/Log Pis Min            -6.097293
trainer/Policy mu Mean         -0.08860954
trainer/Policy mu Std          1.7912321
trainer/Policy mu Max          5.6517587
trainer/Policy mu Min          -5.6552353
trainer/Policy log std Mean    -0.3254892
trainer/Policy log std Std     0.14531225
trainer/Policy log std Max     0.19191024
trainer/Policy log std Min     -0.9471318
trainer/Alpha                  0.003137951949611306
trainer/Alpha Loss             4.094559669494629
exploration/num steps total    231000
exploration/num paths total    462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5802696560191012
exploration/Rewards Std        0.08932335893481058
exploration/Rewards Max        0.9531339286909346
exploration/Rewards Min        0.3009639898770491
exploration/Returns Mean       290.1348280095505
exploration/Returns Std        22.623555535615793
exploration/Returns Max        327.7978803417172
exploration/Returns Min        259.0332245479531
exploration/Actions Mean       -0.02121344
exploration/Actions Std        0.72135425
exploration/Actions Max        0.9999961
exploration/Actions Min        -0.9999979
exploration/Num Paths          10
exploration/Average Returns    290.1348280095505
evaluation/num steps total     230000
evaluation/num paths total     460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5667437476231202
evaluation/Rewards Std         0.07521621362230055
evaluation/Rewards Max         0.7319662262333505
evaluation/Rewards Min         0.3414038022538452
evaluation/Returns Mean        283.3718738115602
evaluation/Returns Std         19.27411459173124
evaluation/Returns Max         303.76261117883706
evaluation/Returns Min         235.32754351731435
evaluation/ExplReturns Mean    283.3718738115602
evaluation/ExplReturns Std     19.27411459173124
evaluation/ExplReturns Max     303.76261117883706
evaluation/ExplReturns Min     235.32754351731435
evaluation/Actions Mean        -0.046823725
evaluation/Actions Std         0.68088454
evaluation/Actions Max         0.9999699
evaluation/Actions Min         -0.9999935
evaluation/Num Paths           10
evaluation/Average Returns     283.3718738115602
time/data storing (s)          0.03422683570533991
time/evaluation sampling (s)   113.57034273538738
time/exploration sampling (s)  113.81725027877837
time/logging (s)               0.030657649971544743
time/saving (s)                0.011929121799767017
time/training (s)              9.513931127265096
time/epoch (s)                 236.9783377489075
time/total (s)                 10757.91625407897
Epoch                          45
-----------------------------  --------------------
2023-07-31 20:57:17.517627 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 46 finished
-----------------------------  --------------------
replay_buffer/size             236000
trainer/tdrp Loss              [4329.658]
trainer/QF1 Loss               0.16164823
trainer/QF2 Loss               0.17117397
trainer/Policy Loss            -50.48726
trainer/Q1 Predictions Mean    62.53366
trainer/Q1 Predictions Std     3.5463328
trainer/Q1 Predictions Max     68.11249
trainer/Q1 Predictions Min     45.05443
trainer/Q2 Predictions Mean    62.396584
trainer/Q2 Predictions Std     3.554102
trainer/Q2 Predictions Max     67.877335
trainer/Q2 Predictions Min     44.614296
trainer/Q Targets Mean         62.522423
trainer/Q Targets Std          3.5853884
trainer/Q Targets Max          68.02112
trainer/Q Targets Min          44.377926
trainer/Log Pis Mean           12.055787
trainer/Log Pis Std            8.863509
trainer/Log Pis Max            46.489994
trainer/Log Pis Min            -4.9669905
trainer/Policy mu Mean         -0.047845587
trainer/Policy mu Std          1.8045152
trainer/Policy mu Max          5.8889885
trainer/Policy mu Min          -5.0649443
trainer/Policy log std Mean    -0.3322316
trainer/Policy log std Std     0.13378672
trainer/Policy log std Max     0.1707281
trainer/Policy log std Min     -0.7701264
trainer/Alpha                  0.00314449449069798
trainer/Alpha Loss             0.3214638829231262
exploration/num steps total    236000
exploration/num paths total    472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.611972769369239
exploration/Rewards Std        0.059732643323164594
exploration/Rewards Max        0.9347717579023688
exploration/Rewards Min        0.39088942653212894
exploration/Returns Mean       305.98638468461957
exploration/Returns Std        4.58128506054835
exploration/Returns Max        312.2281069723496
exploration/Returns Min        297.9190849802476
exploration/Actions Mean       0.09418916
exploration/Actions Std        0.7350265
exploration/Actions Max        0.99997616
exploration/Actions Min        -0.99998355
exploration/Num Paths          10
exploration/Average Returns    305.98638468461957
evaluation/num steps total     235000
evaluation/num paths total     470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6105330220295978
evaluation/Rewards Std         0.06142992279056922
evaluation/Rewards Max         0.7576142207230641
evaluation/Rewards Min         0.39473466907325316
evaluation/Returns Mean        305.2665110147988
evaluation/Returns Std         11.516484518024528
evaluation/Returns Max         335.17729396562726
evaluation/Returns Min         292.954056405594
evaluation/ExplReturns Mean    305.2665110147988
evaluation/ExplReturns Std     11.516484518024528
evaluation/ExplReturns Max     335.17729396562726
evaluation/ExplReturns Min     292.954056405594
evaluation/Actions Mean        0.09051929
evaluation/Actions Std         0.7107803
evaluation/Actions Max         0.99972326
evaluation/Actions Min         -0.99965024
evaluation/Num Paths           10
evaluation/Average Returns     305.2665110147988
time/data storing (s)          0.03437564987689257
time/evaluation sampling (s)   111.02005261182785
time/exploration sampling (s)  111.03350524231791
time/logging (s)               0.030562504194676876
time/saving (s)                0.012188541702926159
time/training (s)              9.3810343015939
time/epoch (s)                 231.51171885151416
time/total (s)                 10989.430770011619
Epoch                          46
-----------------------------  --------------------
2023-07-31 21:01:16.207944 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 47 finished
-----------------------------  ---------------------
replay_buffer/size             241000
trainer/tdrp Loss              [4304.442]
trainer/QF1 Loss               0.15432516
trainer/QF2 Loss               0.13440333
trainer/Policy Loss            -49.972214
trainer/Q1 Predictions Mean    62.34855
trainer/Q1 Predictions Std     4.071146
trainer/Q1 Predictions Max     69.06153
trainer/Q1 Predictions Min     39.59168
trainer/Q2 Predictions Mean    62.415916
trainer/Q2 Predictions Std     4.0752025
trainer/Q2 Predictions Max     69.00513
trainer/Q2 Predictions Min     39.79366
trainer/Q Targets Mean         62.42308
trainer/Q Targets Std          4.086843
trainer/Q Targets Max          68.5869
trainer/Q Targets Min          39.779716
trainer/Log Pis Mean           12.495508
trainer/Log Pis Std            9.334617
trainer/Log Pis Max            51.068214
trainer/Log Pis Min            -6.9862733
trainer/Policy mu Mean         0.042689066
trainer/Policy mu Std          1.8169385
trainer/Policy mu Max          5.9518824
trainer/Policy mu Min          -7.1813135
trainer/Policy log std Mean    -0.31996936
trainer/Policy log std Std     0.13989745
trainer/Policy log std Max     0.4568174
trainer/Policy log std Min     -0.8924638
trainer/Alpha                  0.0031166737899184227
trainer/Alpha Loss             2.859600067138672
exploration/num steps total    241000
exploration/num paths total    482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5453271326020059
exploration/Rewards Std        0.08249620203361037
exploration/Rewards Max        0.9196752742821085
exploration/Rewards Min        0.2815285968556903
exploration/Returns Mean       272.66356630100296
exploration/Returns Std        9.218505349131016
exploration/Returns Max        286.34444861308725
exploration/Returns Min        255.42766229961933
exploration/Actions Mean       0.100074545
exploration/Actions Std        0.7254498
exploration/Actions Max        0.9999948
exploration/Actions Min        -0.9999824
exploration/Num Paths          10
exploration/Average Returns    272.66356630100296
evaluation/num steps total     240000
evaluation/num paths total     480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5599590802212296
evaluation/Rewards Std         0.09265318577901292
evaluation/Rewards Max         0.9673293733597529
evaluation/Rewards Min         0.27928275086722876
evaluation/Returns Mean        279.9795401106148
evaluation/Returns Std         22.42052335502285
evaluation/Returns Max         321.0022573513729
evaluation/Returns Min         251.82855506200684
evaluation/ExplReturns Mean    279.9795401106148
evaluation/ExplReturns Std     22.42052335502285
evaluation/ExplReturns Max     321.0022573513729
evaluation/ExplReturns Min     251.82855506200684
evaluation/Actions Mean        0.068118304
evaluation/Actions Std         0.6628433
evaluation/Actions Max         0.9998267
evaluation/Actions Min         -0.9999488
evaluation/Num Paths           10
evaluation/Average Returns     279.9795401106148
time/data storing (s)          0.03410330042243004
time/evaluation sampling (s)   115.11269758455455
time/exploration sampling (s)  113.30913037154824
time/logging (s)               0.030393505468964577
time/saving (s)                0.011583607643842697
time/training (s)              10.188711850903928
time/epoch (s)                 238.68662022054195
time/total (s)                 11228.120011830702
Epoch                          47
-----------------------------  ---------------------
2023-07-31 21:05:08.125748 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 48 finished
-----------------------------  --------------------
replay_buffer/size             246000
trainer/tdrp Loss              [4014.9458]
trainer/QF1 Loss               0.17965144
trainer/QF2 Loss               0.15324447
trainer/Policy Loss            -49.352272
trainer/Q1 Predictions Mean    61.949413
trainer/Q1 Predictions Std     3.964312
trainer/Q1 Predictions Max     69.549706
trainer/Q1 Predictions Min     41.383793
trainer/Q2 Predictions Mean    61.931633
trainer/Q2 Predictions Std     3.958429
trainer/Q2 Predictions Max     69.478676
trainer/Q2 Predictions Min     41.129406
trainer/Q Targets Mean         61.828545
trainer/Q Targets Std          3.930921
trainer/Q Targets Max          69.31409
trainer/Q Targets Min          41.70065
trainer/Log Pis Mean           12.68688
trainer/Log Pis Std            9.032992
trainer/Log Pis Max            43.42599
trainer/Log Pis Min            -7.1279736
trainer/Policy mu Mean         -0.029782929
trainer/Policy mu Std          1.8310302
trainer/Policy mu Max          5.821596
trainer/Policy mu Min          -6.733976
trainer/Policy log std Mean    -0.31880274
trainer/Policy log std Std     0.13742211
trainer/Policy log std Max     0.43604174
trainer/Policy log std Min     -0.84987473
trainer/Alpha                  0.00316530279815197
trainer/Alpha Loss             3.9534881114959717
exploration/num steps total    246000
exploration/num paths total    492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5657067726737809
exploration/Rewards Std        0.09922175537808622
exploration/Rewards Max        0.9744041227661221
exploration/Rewards Min        0.17769849685077654
exploration/Returns Mean       282.8533863368904
exploration/Returns Std        26.013292407924638
exploration/Returns Max        316.31661958942357
exploration/Returns Min        222.07394681787298
exploration/Actions Mean       0.014314122
exploration/Actions Std        0.71515596
exploration/Actions Max        0.9999983
exploration/Actions Min        -0.9999906
exploration/Num Paths          10
exploration/Average Returns    282.8533863368904
evaluation/num steps total     245000
evaluation/num paths total     490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5837504399092968
evaluation/Rewards Std         0.08206956724153773
evaluation/Rewards Max         0.7410771103495105
evaluation/Rewards Min         0.2699211053895934
evaluation/Returns Mean        291.8752199546483
evaluation/Returns Std         15.064301956059676
evaluation/Returns Max         323.38775340819655
evaluation/Returns Min         265.75266864274096
evaluation/ExplReturns Mean    291.8752199546483
evaluation/ExplReturns Std     15.064301956059676
evaluation/ExplReturns Max     323.38775340819655
evaluation/ExplReturns Min     265.75266864274096
evaluation/Actions Mean        0.05006979
evaluation/Actions Std         0.6869772
evaluation/Actions Max         0.9999791
evaluation/Actions Min         -0.9999944
evaluation/Num Paths           10
evaluation/Average Returns     291.8752199546483
time/data storing (s)          0.03422984387725592
time/evaluation sampling (s)   110.84448659326881
time/exploration sampling (s)  111.628487277776
time/logging (s)               0.030300266109406948
time/saving (s)                0.010236079804599285
time/training (s)              9.366552448831499
time/epoch (s)                 231.91429250966758
time/total (s)                 11460.036793570966
Epoch                          48
-----------------------------  --------------------
2023-07-31 21:09:04.331650 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 49 finished
-----------------------------  --------------------
replay_buffer/size             251000
trainer/tdrp Loss              [4045.6846]
trainer/QF1 Loss               0.18182746
trainer/QF2 Loss               0.15104087
trainer/Policy Loss            -51.044655
trainer/Q1 Predictions Mean    61.720634
trainer/Q1 Predictions Std     3.5646725
trainer/Q1 Predictions Max     67.252426
trainer/Q1 Predictions Min     39.33107
trainer/Q2 Predictions Mean    61.79529
trainer/Q2 Predictions Std     3.5805194
trainer/Q2 Predictions Max     67.30713
trainer/Q2 Predictions Min     39.658455
trainer/Q Targets Mean         61.68749
trainer/Q Targets Std          3.607989
trainer/Q Targets Max          67.65458
trainer/Q Targets Min          39.293438
trainer/Log Pis Mean           10.787769
trainer/Log Pis Std            8.58803
trainer/Log Pis Max            37.75547
trainer/Log Pis Min            -8.472655
trainer/Policy mu Mean         -0.14758931
trainer/Policy mu Std          1.7493421
trainer/Policy mu Max          6.4411683
trainer/Policy mu Min          -5.944317
trainer/Policy log std Mean    -0.3270493
trainer/Policy log std Std     0.13746099
trainer/Policy log std Max     0.25597018
trainer/Policy log std Min     -0.9037156
trainer/Alpha                  0.003054222324863076
trainer/Alpha Loss             -7.020256042480469
exploration/num steps total    251000
exploration/num paths total    502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.571153468575767
exploration/Rewards Std        0.0856608110683053
exploration/Rewards Max        0.9431833927347202
exploration/Rewards Min        0.3036157495167491
exploration/Returns Mean       285.5767342878836
exploration/Returns Std        26.542112467151295
exploration/Returns Max        318.9819754500415
exploration/Returns Min        236.07772785034823
exploration/Actions Mean       -0.08620535
exploration/Actions Std        0.7432451
exploration/Actions Max        0.99999964
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    285.5767342878836
evaluation/num steps total     250000
evaluation/num paths total     500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5995485652749163
evaluation/Rewards Std         0.0847290170287853
evaluation/Rewards Max         0.9620549893406509
evaluation/Rewards Min         0.23810045088792192
evaluation/Returns Mean        299.77428263745816
evaluation/Returns Std         21.247285880124394
evaluation/Returns Max         338.22609179464615
evaluation/Returns Min         259.66243455105837
evaluation/ExplReturns Mean    299.77428263745816
evaluation/ExplReturns Std     21.247285880124394
evaluation/ExplReturns Max     338.22609179464615
evaluation/ExplReturns Min     259.66243455105837
evaluation/Actions Mean        -0.06537748
evaluation/Actions Std         0.68893766
evaluation/Actions Max         0.99999475
evaluation/Actions Min         -0.9999921
evaluation/Num Paths           10
evaluation/Average Returns     299.77428263745816
time/data storing (s)          0.034277744591236115
time/evaluation sampling (s)   112.10633269324899
time/exploration sampling (s)  114.64641581755131
time/logging (s)               0.030338749289512634
time/saving (s)                0.010459588840603828
time/training (s)              9.374706273898482
time/epoch (s)                 236.20253086742014
time/total (s)                 11696.241808847524
Epoch                          49
-----------------------------  --------------------
2023-07-31 21:12:56.777772 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 50 finished
-----------------------------  --------------------
replay_buffer/size             256000
trainer/tdrp Loss              [4103.5063]
trainer/QF1 Loss               0.1394744
trainer/QF2 Loss               0.13642235
trainer/Policy Loss            -49.314705
trainer/Q1 Predictions Mean    61.546516
trainer/Q1 Predictions Std     3.066398
trainer/Q1 Predictions Max     67.11366
trainer/Q1 Predictions Min     46.940563
trainer/Q2 Predictions Mean    61.556087
trainer/Q2 Predictions Std     3.0770516
trainer/Q2 Predictions Max     67.15282
trainer/Q2 Predictions Min     46.93423
trainer/Q Targets Mean         61.60032
trainer/Q Targets Std          3.0651712
trainer/Q Targets Max          66.85505
trainer/Q Targets Min          47.63562
trainer/Log Pis Mean           12.344248
trainer/Log Pis Std            8.8238125
trainer/Log Pis Max            43.212524
trainer/Log Pis Min            -10.014166
trainer/Policy mu Mean         -0.067034744
trainer/Policy mu Std          1.7688481
trainer/Policy mu Max          6.22723
trainer/Policy mu Min          -5.0881643
trainer/Policy log std Mean    -0.314034
trainer/Policy log std Std     0.1404008
trainer/Policy log std Max     0.36856213
trainer/Policy log std Min     -0.989413
trainer/Alpha                  0.003045568009838462
trainer/Alpha Loss             1.9946208000183105
exploration/num steps total    256000
exploration/num paths total    512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5789427284703808
exploration/Rewards Std        0.08235995464349471
exploration/Rewards Max        0.9643817587886017
exploration/Rewards Min        0.26569860951351154
exploration/Returns Mean       289.4713642351904
exploration/Returns Std        10.996455771179972
exploration/Returns Max        302.22001321181125
exploration/Returns Min        272.8734193985679
exploration/Actions Mean       0.04368358
exploration/Actions Std        0.71552026
exploration/Actions Max        0.9999894
exploration/Actions Min        -0.99999887
exploration/Num Paths          10
exploration/Average Returns    289.4713642351904
evaluation/num steps total     255000
evaluation/num paths total     510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.582061219100756
evaluation/Rewards Std         0.08737939754770421
evaluation/Rewards Max         0.9648890283899334
evaluation/Rewards Min         0.3134233464605818
evaluation/Returns Mean        291.03060955037796
evaluation/Returns Std         14.817932440187672
evaluation/Returns Max         324.5121179899287
evaluation/Returns Min         268.37680454579834
evaluation/ExplReturns Mean    291.03060955037796
evaluation/ExplReturns Std     14.817932440187672
evaluation/ExplReturns Max     324.5121179899287
evaluation/ExplReturns Min     268.37680454579834
evaluation/Actions Mean        0.0429228
evaluation/Actions Std         0.66629976
evaluation/Actions Max         0.9998646
evaluation/Actions Min         -0.9999278
evaluation/Num Paths           10
evaluation/Average Returns     291.03060955037796
time/data storing (s)          0.034004717133939266
time/evaluation sampling (s)   110.78444285318255
time/exploration sampling (s)  112.09023536276072
time/logging (s)               0.030397835187613964
time/saving (s)                0.011890986002981663
time/training (s)              9.491802072152495
time/epoch (s)                 232.4427738264203
time/total (s)                 11928.687029629014
Epoch                          50
-----------------------------  --------------------
2023-07-31 21:16:52.150740 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 51 finished
-----------------------------  --------------------
replay_buffer/size             261000
trainer/tdrp Loss              [4050.0457]
trainer/QF1 Loss               0.15192258
trainer/QF2 Loss               0.16496594
trainer/Policy Loss            -48.29018
trainer/Q1 Predictions Mean    60.708984
trainer/Q1 Predictions Std     3.80084
trainer/Q1 Predictions Max     67.36683
trainer/Q1 Predictions Min     48.51095
trainer/Q2 Predictions Mean    60.668762
trainer/Q2 Predictions Std     3.8019474
trainer/Q2 Predictions Max     67.166885
trainer/Q2 Predictions Min     48.34638
trainer/Q Targets Mean         60.733315
trainer/Q Targets Std          3.828754
trainer/Q Targets Max          67.166725
trainer/Q Targets Min          47.99032
trainer/Log Pis Mean           12.48228
trainer/Log Pis Std            8.84705
trainer/Log Pis Max            36.664726
trainer/Log Pis Min            -8.232527
trainer/Policy mu Mean         -0.16309474
trainer/Policy mu Std          1.773729
trainer/Policy mu Max          5.839517
trainer/Policy mu Min          -6.513833
trainer/Policy log std Mean    -0.30762708
trainer/Policy log std Std     0.14193667
trainer/Policy log std Max     0.26579887
trainer/Policy log std Min     -0.80483353
trainer/Alpha                  0.002983909798786044
trainer/Alpha Loss             2.8041839599609375
exploration/num steps total    261000
exploration/num paths total    522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5913990011641869
exploration/Rewards Std        0.07857794923247724
exploration/Rewards Max        0.9719105134596435
exploration/Rewards Min        0.3637050652612668
exploration/Returns Mean       295.69950058209344
exploration/Returns Std        9.713000220142042
exploration/Returns Max        309.94369127070775
exploration/Returns Min        276.2406988699047
exploration/Actions Mean       -0.02046906
exploration/Actions Std        0.73034936
exploration/Actions Max        0.9999974
exploration/Actions Min        -0.9999979
exploration/Num Paths          10
exploration/Average Returns    295.69950058209344
evaluation/num steps total     260000
evaluation/num paths total     520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5842728626095598
evaluation/Rewards Std         0.07444654368320486
evaluation/Rewards Max         0.7288420254226677
evaluation/Rewards Min         0.27792391072865724
evaluation/Returns Mean        292.13643130477976
evaluation/Returns Std         14.94661930763599
evaluation/Returns Max         325.7454797827516
evaluation/Returns Min         273.5026674067404
evaluation/ExplReturns Mean    292.13643130477976
evaluation/ExplReturns Std     14.94661930763599
evaluation/ExplReturns Max     325.7454797827516
evaluation/ExplReturns Min     273.5026674067404
evaluation/Actions Mean        -0.010236092
evaluation/Actions Std         0.6776049
evaluation/Actions Max         0.9999922
evaluation/Actions Min         -0.9999474
evaluation/Num Paths           10
evaluation/Average Returns     292.13643130477976
time/data storing (s)          0.034088882617652416
time/evaluation sampling (s)   113.24155749194324
time/exploration sampling (s)  112.63143597729504
time/logging (s)               0.03050414565950632
time/saving (s)                0.0106072798371315
time/training (s)              9.421027419157326
time/epoch (s)                 235.3692211965099
time/total (s)                 12164.059151316062
Epoch                          51
-----------------------------  --------------------
2023-07-31 21:20:49.143893 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 52 finished
-----------------------------  --------------------
replay_buffer/size             266000
trainer/tdrp Loss              [4158.987]
trainer/QF1 Loss               0.13949904
trainer/QF2 Loss               0.1403313
trainer/Policy Loss            -48.84532
trainer/Q1 Predictions Mean    60.84103
trainer/Q1 Predictions Std     3.5274844
trainer/Q1 Predictions Max     67.24305
trainer/Q1 Predictions Min     39.58075
trainer/Q2 Predictions Mean    60.826492
trainer/Q2 Predictions Std     3.4904563
trainer/Q2 Predictions Max     67.34024
trainer/Q2 Predictions Min     39.681725
trainer/Q Targets Mean         60.83438
trainer/Q Targets Std          3.5179548
trainer/Q Targets Max          67.49483
trainer/Q Targets Min          39.64992
trainer/Log Pis Mean           12.101374
trainer/Log Pis Std            7.9164324
trainer/Log Pis Max            32.623234
trainer/Log Pis Min            -8.910307
trainer/Policy mu Mean         -0.06930322
trainer/Policy mu Std          1.751079
trainer/Policy mu Max          4.4586463
trainer/Policy mu Min          -5.63001
trainer/Policy log std Mean    -0.33656478
trainer/Policy log std Std     0.12893239
trainer/Policy log std Max     0.20200267
trainer/Policy log std Min     -0.82374245
trainer/Alpha                  0.003058450296521187
trainer/Alpha Loss             0.5869458913803101
exploration/num steps total    266000
exploration/num paths total    532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6117478294358021
exploration/Rewards Std        0.10413297226133887
exploration/Rewards Max        0.9750150330382606
exploration/Rewards Min        0.29431393096690733
exploration/Returns Mean       305.87391471790096
exploration/Returns Std        25.68834964359159
exploration/Returns Max        351.4792358354217
exploration/Returns Min        269.06358898277716
exploration/Actions Mean       0.09860443
exploration/Actions Std        0.73637635
exploration/Actions Max        0.9999499
exploration/Actions Min        -0.9999449
exploration/Num Paths          10
exploration/Average Returns    305.87391471790096
evaluation/num steps total     265000
evaluation/num paths total     530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6139465887622225
evaluation/Rewards Std         0.07590165127780157
evaluation/Rewards Max         0.9344805020164172
evaluation/Rewards Min         0.29303202814421847
evaluation/Returns Mean        306.97329438111126
evaluation/Returns Std         19.558586492980194
evaluation/Returns Max         326.6626322126143
evaluation/Returns Min         257.36304544307694
evaluation/ExplReturns Mean    306.97329438111126
evaluation/ExplReturns Std     19.558586492980194
evaluation/ExplReturns Max     326.6626322126143
evaluation/ExplReturns Min     257.36304544307694
evaluation/Actions Mean        0.12959604
evaluation/Actions Std         0.6952826
evaluation/Actions Max         0.99958813
evaluation/Actions Min         -0.9994418
evaluation/Num Paths           10
evaluation/Average Returns     306.97329438111126
time/data storing (s)          0.034116046503186226
time/evaluation sampling (s)   113.25234659668058
time/exploration sampling (s)  114.2413162542507
time/logging (s)               0.030378000810742378
time/saving (s)                0.011459949426352978
time/training (s)              9.419870156794786
time/epoch (s)                 236.98948700446635
time/total (s)                 12401.051203053445
Epoch                          52
-----------------------------  --------------------
2023-07-31 21:24:47.793115 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 53 finished
-----------------------------  ---------------------
replay_buffer/size             271000
trainer/tdrp Loss              [3983.3196]
trainer/QF1 Loss               0.13165414
trainer/QF2 Loss               0.11540349
trainer/Policy Loss            -49.33104
trainer/Q1 Predictions Mean    60.721565
trainer/Q1 Predictions Std     2.9695554
trainer/Q1 Predictions Max     67.89375
trainer/Q1 Predictions Min     49.56794
trainer/Q2 Predictions Mean    60.828743
trainer/Q2 Predictions Std     2.9635987
trainer/Q2 Predictions Max     67.69478
trainer/Q2 Predictions Min     49.888245
trainer/Q Targets Mean         60.819954
trainer/Q Targets Std          2.9879375
trainer/Q Targets Max          67.88791
trainer/Q Targets Min          49.968155
trainer/Log Pis Mean           11.522418
trainer/Log Pis Std            8.092286
trainer/Log Pis Max            41.331154
trainer/Log Pis Min            -5.749814
trainer/Policy mu Mean         -0.17734142
trainer/Policy mu Std          1.7267838
trainer/Policy mu Max          4.608143
trainer/Policy mu Min          -5.66494
trainer/Policy log std Mean    -0.33326787
trainer/Policy log std Std     0.13980825
trainer/Policy log std Max     0.32333553
trainer/Policy log std Min     -0.8589351
trainer/Alpha                  0.0030207994859665632
trainer/Alpha Loss             -2.7711222171783447
exploration/num steps total    271000
exploration/num paths total    542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5835005164010197
exploration/Rewards Std        0.07713484549298305
exploration/Rewards Max        0.9532621158058152
exploration/Rewards Min        0.3521266082347718
exploration/Returns Mean       291.7502582005099
exploration/Returns Std        17.70342508306784
exploration/Returns Max        318.498603519916
exploration/Returns Min        269.3062265762936
exploration/Actions Mean       0.0034257867
exploration/Actions Std        0.7326551
exploration/Actions Max        0.9999995
exploration/Actions Min        -0.999998
exploration/Num Paths          10
exploration/Average Returns    291.7502582005099
evaluation/num steps total     270000
evaluation/num paths total     540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6080436510232619
evaluation/Rewards Std         0.08762681663895659
evaluation/Rewards Max         0.9697270951593476
evaluation/Rewards Min         0.2677842250823976
evaluation/Returns Mean        304.0218255116308
evaluation/Returns Std         18.86538779353537
evaluation/Returns Max         329.0098507374543
evaluation/Returns Min         262.11468254600834
evaluation/ExplReturns Mean    304.0218255116308
evaluation/ExplReturns Std     18.86538779353537
evaluation/ExplReturns Max     329.0098507374543
evaluation/ExplReturns Min     262.11468254600834
evaluation/Actions Mean        -0.018232718
evaluation/Actions Std         0.6942588
evaluation/Actions Max         0.99969846
evaluation/Actions Min         -0.99984396
evaluation/Num Paths           10
evaluation/Average Returns     304.0218255116308
time/data storing (s)          0.03430661465972662
time/evaluation sampling (s)   114.31469258107245
time/exploration sampling (s)  114.78261526394635
time/logging (s)               0.030446063727140427
time/saving (s)                0.010194476693868637
time/training (s)              9.47358707524836
time/epoch (s)                 238.6458420753479
time/total (s)                 12639.699538272806
Epoch                          53
-----------------------------  ---------------------
2023-07-31 21:28:44.485900 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 54 finished
-----------------------------  ---------------------
replay_buffer/size             276000
trainer/tdrp Loss              [4171.5596]
trainer/QF1 Loss               0.16459364
trainer/QF2 Loss               0.13440013
trainer/Policy Loss            -48.22846
trainer/Q1 Predictions Mean    60.225834
trainer/Q1 Predictions Std     3.391952
trainer/Q1 Predictions Max     67.55748
trainer/Q1 Predictions Min     46.29597
trainer/Q2 Predictions Mean    60.179302
trainer/Q2 Predictions Std     3.3891425
trainer/Q2 Predictions Max     67.068565
trainer/Q2 Predictions Min     45.98007
trainer/Q Targets Mean         60.11062
trainer/Q Targets Std          3.3896995
trainer/Q Targets Max          66.83419
trainer/Q Targets Min          46.09728
trainer/Log Pis Mean           12.0789
trainer/Log Pis Std            8.880399
trainer/Log Pis Max            40.200195
trainer/Log Pis Min            -7.6157064
trainer/Policy mu Mean         0.048865717
trainer/Policy mu Std          1.7750548
trainer/Policy mu Max          5.463664
trainer/Policy mu Min          -4.7745643
trainer/Policy log std Mean    -0.33352506
trainer/Policy log std Std     0.13520585
trainer/Policy log std Max     0.27128968
trainer/Policy log std Min     -0.8345098
trainer/Alpha                  0.0030352193862199783
trainer/Alpha Loss             0.4574270248413086
exploration/num steps total    276000
exploration/num paths total    552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.520441395913301
exploration/Rewards Std        0.08639180448751141
exploration/Rewards Max        0.7338256366697811
exploration/Rewards Min        0.19071278215799153
exploration/Returns Mean       260.2206979566505
exploration/Returns Std        12.62820766516673
exploration/Returns Max        282.92936896234517
exploration/Returns Min        242.25705925139766
exploration/Actions Mean       0.022838311
exploration/Actions Std        0.6984273
exploration/Actions Max        0.9999865
exploration/Actions Min        -0.99999964
exploration/Num Paths          10
exploration/Average Returns    260.2206979566505
evaluation/num steps total     275000
evaluation/num paths total     550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5264147482551277
evaluation/Rewards Std         0.0846243844304289
evaluation/Rewards Max         0.9285104978570552
evaluation/Rewards Min         0.2643811670583231
evaluation/Returns Mean        263.2073741275638
evaluation/Returns Std         15.439925848821503
evaluation/Returns Max         291.79627506024906
evaluation/Returns Min         240.13906771017577
evaluation/ExplReturns Mean    263.2073741275638
evaluation/ExplReturns Std     15.439925848821503
evaluation/ExplReturns Max     291.79627506024906
evaluation/ExplReturns Min     240.13906771017577
evaluation/Actions Mean        0.043214206
evaluation/Actions Std         0.67832905
evaluation/Actions Max         0.9998402
evaluation/Actions Min         -0.99987465
evaluation/Num Paths           10
evaluation/Average Returns     263.2073741275638
time/data storing (s)          0.03375849314033985
time/evaluation sampling (s)   113.76513316296041
time/exploration sampling (s)  112.8848999561742
time/logging (s)               0.030329573899507523
time/saving (s)                0.012028016149997711
time/training (s)              9.96294043213129
time/epoch (s)                 236.68908963445574
time/total (s)                 12876.391237753443
Epoch                          54
-----------------------------  ---------------------
2023-07-31 21:32:39.368991 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 55 finished
-----------------------------  --------------------
replay_buffer/size             281000
trainer/tdrp Loss              [4111.9565]
trainer/QF1 Loss               0.13315517
trainer/QF2 Loss               0.115410686
trainer/Policy Loss            -47.435936
trainer/Q1 Predictions Mean    60.175285
trainer/Q1 Predictions Std     3.2679996
trainer/Q1 Predictions Max     66.542625
trainer/Q1 Predictions Min     39.638416
trainer/Q2 Predictions Mean    60.223022
trainer/Q2 Predictions Std     3.2980788
trainer/Q2 Predictions Max     66.70898
trainer/Q2 Predictions Min     39.87959
trainer/Q Targets Mean         60.170868
trainer/Q Targets Std          3.3234656
trainer/Q Targets Max          66.97299
trainer/Q Targets Min          39.38783
trainer/Log Pis Mean           12.829115
trainer/Log Pis Std            9.358351
trainer/Log Pis Max            45.007027
trainer/Log Pis Min            -3.790193
trainer/Policy mu Mean         -0.11796615
trainer/Policy mu Std          1.806377
trainer/Policy mu Max          5.529656
trainer/Policy mu Min          -5.904974
trainer/Policy log std Mean    -0.32809168
trainer/Policy log std Std     0.14251405
trainer/Policy log std Max     0.20499068
trainer/Policy log std Min     -0.96878105
trainer/Alpha                  0.002993476577103138
trainer/Alpha Loss             4.818427085876465
exploration/num steps total    281000
exploration/num paths total    562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6065735747036906
exploration/Rewards Std        0.07493470740505145
exploration/Rewards Max        0.9638577376418669
exploration/Rewards Min        0.3117922336280901
exploration/Returns Mean       303.2867873518452
exploration/Returns Std        17.904515942938936
exploration/Returns Max        336.2244183026177
exploration/Returns Min        278.499048585575
exploration/Actions Mean       0.02279851
exploration/Actions Std        0.7330054
exploration/Actions Max        0.9999972
exploration/Actions Min        -0.99997324
exploration/Num Paths          10
exploration/Average Returns    303.2867873518452
evaluation/num steps total     280000
evaluation/num paths total     560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5856546800103948
evaluation/Rewards Std         0.07802733511334552
evaluation/Rewards Max         0.7263918188455707
evaluation/Rewards Min         0.32236680888942665
evaluation/Returns Mean        292.82734000519736
evaluation/Returns Std         18.986965355775446
evaluation/Returns Max         320.6026052840845
evaluation/Returns Min         266.2390082141006
evaluation/ExplReturns Mean    292.82734000519736
evaluation/ExplReturns Std     18.986965355775446
evaluation/ExplReturns Max     320.6026052840845
evaluation/ExplReturns Min     266.2390082141006
evaluation/Actions Mean        0.05336125
evaluation/Actions Std         0.6867674
evaluation/Actions Max         0.99997294
evaluation/Actions Min         -0.9998055
evaluation/Num Paths           10
evaluation/Average Returns     292.82734000519736
time/data storing (s)          0.03424351383000612
time/evaluation sampling (s)   111.57580649852753
time/exploration sampling (s)  113.84578602481633
time/logging (s)               0.030422317795455456
time/saving (s)                0.012276500463485718
time/training (s)              9.38119235355407
time/epoch (s)                 234.87972720898688
time/total (s)                 13111.273458566517
Epoch                          55
-----------------------------  --------------------
2023-07-31 21:36:35.276379 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 56 finished
-----------------------------  --------------------
replay_buffer/size             286000
trainer/tdrp Loss              [4219.811]
trainer/QF1 Loss               0.1149942
trainer/QF2 Loss               0.11500038
trainer/Policy Loss            -48.473316
trainer/Q1 Predictions Mean    59.782726
trainer/Q1 Predictions Std     3.5812669
trainer/Q1 Predictions Max     66.1909
trainer/Q1 Predictions Min     46.89863
trainer/Q2 Predictions Mean    59.75651
trainer/Q2 Predictions Std     3.5810823
trainer/Q2 Predictions Max     66.11737
trainer/Q2 Predictions Min     47.243134
trainer/Q Targets Mean         59.830627
trainer/Q Targets Std          3.57956
trainer/Q Targets Max          66.00906
trainer/Q Targets Min          47.51934
trainer/Log Pis Mean           11.410414
trainer/Log Pis Std            8.388986
trainer/Log Pis Max            42.47953
trainer/Log Pis Min            -7.7403946
trainer/Policy mu Mean         -0.04711041
trainer/Policy mu Std          1.7363899
trainer/Policy mu Max          5.307439
trainer/Policy mu Min          -6.108383
trainer/Policy log std Mean    -0.32880625
trainer/Policy log std Std     0.13913815
trainer/Policy log std Max     0.33826768
trainer/Policy log std Min     -0.80535996
trainer/Alpha                  0.003080457216128707
trainer/Alpha Loss             -3.4092867374420166
exploration/num steps total    286000
exploration/num paths total    572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6175592814791584
exploration/Rewards Std        0.07705362499772882
exploration/Rewards Max        0.9659903144947354
exploration/Rewards Min        0.28171382196701644
exploration/Returns Mean       308.7796407395791
exploration/Returns Std        11.939780761488029
exploration/Returns Max        325.4173281441942
exploration/Returns Min        288.73599230711784
exploration/Actions Mean       -0.04908188
exploration/Actions Std        0.73870826
exploration/Actions Max        0.999993
exploration/Actions Min        -0.999999
exploration/Num Paths          10
exploration/Average Returns    308.7796407395791
evaluation/num steps total     285000
evaluation/num paths total     570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6147975188017641
evaluation/Rewards Std         0.07458095425846101
evaluation/Rewards Max         0.9728669287820498
evaluation/Rewards Min         0.3907023033391564
evaluation/Returns Mean        307.3987594008821
evaluation/Returns Std         11.874932025929121
evaluation/Returns Max         330.4928718117808
evaluation/Returns Min         291.4405922404691
evaluation/ExplReturns Mean    307.3987594008821
evaluation/ExplReturns Std     11.874932025929121
evaluation/ExplReturns Max     330.4928718117808
evaluation/ExplReturns Min     291.4405922404691
evaluation/Actions Mean        0.025301164
evaluation/Actions Std         0.69729275
evaluation/Actions Max         0.9999339
evaluation/Actions Min         -0.99972254
evaluation/Num Paths           10
evaluation/Average Returns     307.3987594008821
time/data storing (s)          0.03448723256587982
time/evaluation sampling (s)   112.60221968498081
time/exploration sampling (s)  113.72281303908676
time/logging (s)               0.03068335633724928
time/saving (s)                0.01027415320277214
time/training (s)              9.50352289993316
time/epoch (s)                 235.90400036610663
time/total (s)                 13347.180120166391
Epoch                          56
-----------------------------  --------------------
2023-07-31 21:40:32.250784 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 57 finished
-----------------------------  ---------------------
replay_buffer/size             291000
trainer/tdrp Loss              [4089.4048]
trainer/QF1 Loss               0.19037883
trainer/QF2 Loss               0.13841191
trainer/Policy Loss            -47.332607
trainer/Q1 Predictions Mean    59.96594
trainer/Q1 Predictions Std     3.0871987
trainer/Q1 Predictions Max     66.31691
trainer/Q1 Predictions Min     47.74988
trainer/Q2 Predictions Mean    59.862877
trainer/Q2 Predictions Std     3.102756
trainer/Q2 Predictions Max     66.353294
trainer/Q2 Predictions Min     47.337376
trainer/Q Targets Mean         59.749664
trainer/Q Targets Std          3.1346452
trainer/Q Targets Max          66.608376
trainer/Q Targets Min          47.72716
trainer/Log Pis Mean           12.655096
trainer/Log Pis Std            8.116626
trainer/Log Pis Max            43.130947
trainer/Log Pis Min            -6.053172
trainer/Policy mu Mean         -0.08712245
trainer/Policy mu Std          1.7895784
trainer/Policy mu Max          7.2453527
trainer/Policy mu Min          -5.339151
trainer/Policy log std Mean    -0.3311557
trainer/Policy log std Std     0.13592201
trainer/Policy log std Max     0.2935453
trainer/Policy log std Min     -0.8110111
trainer/Alpha                  0.0030363239347934723
trainer/Alpha Loss             3.797666072845459
exploration/num steps total    291000
exploration/num paths total    582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.5897313016424208
exploration/Rewards Std        0.07544624941128447
exploration/Rewards Max        0.742447481952056
exploration/Rewards Min        0.32964085439064517
exploration/Returns Mean       294.8656508212104
exploration/Returns Std        13.36493725618826
exploration/Returns Max        321.66551796907567
exploration/Returns Min        271.945286249388
exploration/Actions Mean       -0.077878535
exploration/Actions Std        0.73414385
exploration/Actions Max        0.99999803
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    294.8656508212104
evaluation/num steps total     290000
evaluation/num paths total     580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6038006465587774
evaluation/Rewards Std         0.0795730262967441
evaluation/Rewards Max         0.9425009420526854
evaluation/Rewards Min         0.3453017733158492
evaluation/Returns Mean        301.90032327938866
evaluation/Returns Std         23.982294220743157
evaluation/Returns Max         345.9379133800997
evaluation/Returns Min         250.41619526658224
evaluation/ExplReturns Mean    301.90032327938866
evaluation/ExplReturns Std     23.982294220743157
evaluation/ExplReturns Max     345.9379133800997
evaluation/ExplReturns Min     250.41619526658224
evaluation/Actions Mean        -0.112637706
evaluation/Actions Std         0.6951585
evaluation/Actions Max         0.9998967
evaluation/Actions Min         -0.999997
evaluation/Num Paths           10
evaluation/Average Returns     301.90032327938866
time/data storing (s)          0.033951287157833576
time/evaluation sampling (s)   114.6788476947695
time/exploration sampling (s)  113.56867032591254
time/logging (s)               0.03043950814753771
time/saving (s)                0.01033011730760336
time/training (s)              8.64846311043948
time/epoch (s)                 236.9707020437345
time/total (s)                 13584.153319158591
Epoch                          57
-----------------------------  ---------------------
2023-07-31 21:44:28.416031 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 58 finished
-----------------------------  ---------------------
replay_buffer/size             296000
trainer/tdrp Loss              [3985.6536]
trainer/QF1 Loss               0.13640353
trainer/QF2 Loss               0.15449682
trainer/Policy Loss            -48.91915
trainer/Q1 Predictions Mean    59.650475
trainer/Q1 Predictions Std     3.2202716
trainer/Q1 Predictions Max     67.376656
trainer/Q1 Predictions Min     47.235104
trainer/Q2 Predictions Mean    59.701584
trainer/Q2 Predictions Std     3.2290428
trainer/Q2 Predictions Max     66.91408
trainer/Q2 Predictions Min     46.882637
trainer/Q Targets Mean         59.575073
trainer/Q Targets Std          3.1909482
trainer/Q Targets Max          66.474785
trainer/Q Targets Min          47.04156
trainer/Log Pis Mean           10.850592
trainer/Log Pis Std            7.726192
trainer/Log Pis Max            39.033966
trainer/Log Pis Min            -5.444094
trainer/Policy mu Mean         -0.008339961
trainer/Policy mu Std          1.7041265
trainer/Policy mu Max          6.809351
trainer/Policy mu Min          -5.738921
trainer/Policy log std Mean    -0.33709857
trainer/Policy log std Std     0.12899335
trainer/Policy log std Max     0.31929973
trainer/Policy log std Min     -0.7798388
trainer/Alpha                  0.0031335754320025444
trainer/Alpha Loss             -6.626773357391357
exploration/num steps total    296000
exploration/num paths total    592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6092631407941158
exploration/Rewards Std        0.07912981702472682
exploration/Rewards Max        0.7360280158568826
exploration/Rewards Min        0.2592783335859542
exploration/Returns Mean       304.63157039705794
exploration/Returns Std        18.292326683603086
exploration/Returns Max        329.2507082175291
exploration/Returns Min        255.1927425892623
exploration/Actions Mean       -0.003380293
exploration/Actions Std        0.7472278
exploration/Actions Max        0.9999995
exploration/Actions Min        -0.9999927
exploration/Num Paths          10
exploration/Average Returns    304.63157039705794
evaluation/num steps total     295000
evaluation/num paths total     590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6022430746855696
evaluation/Rewards Std         0.096638886247284
evaluation/Rewards Max         0.9694327782291463
evaluation/Rewards Min         0.28406570084979493
evaluation/Returns Mean        301.1215373427848
evaluation/Returns Std         30.365406462545746
evaluation/Returns Max         344.58281817806477
evaluation/Returns Min         224.28040317613502
evaluation/ExplReturns Mean    301.1215373427848
evaluation/ExplReturns Std     30.365406462545746
evaluation/ExplReturns Max     344.58281817806477
evaluation/ExplReturns Min     224.28040317613502
evaluation/Actions Mean        -0.007862113
evaluation/Actions Std         0.717148
evaluation/Actions Max         0.999943
evaluation/Actions Min         -0.99994177
evaluation/Num Paths           10
evaluation/Average Returns     301.1215373427848
time/data storing (s)          0.03411250561475754
time/evaluation sampling (s)   112.5050220778212
time/exploration sampling (s)  114.15869757253677
time/logging (s)               0.030719292350113392
time/saving (s)                0.01159234344959259
time/training (s)              9.421852574683726
time/epoch (s)                 236.16199636645615
time/total (s)                 13820.317787764594
Epoch                          58
-----------------------------  ---------------------
2023-07-31 21:48:22.793884 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 59 finished
-----------------------------  ---------------------
replay_buffer/size             301000
trainer/tdrp Loss              [3901.4988]
trainer/QF1 Loss               0.14431153
trainer/QF2 Loss               0.13518393
trainer/Policy Loss            -47.905773
trainer/Q1 Predictions Mean    59.393692
trainer/Q1 Predictions Std     3.3688524
trainer/Q1 Predictions Max     67.04105
trainer/Q1 Predictions Min     46.852036
trainer/Q2 Predictions Mean    59.459923
trainer/Q2 Predictions Std     3.364071
trainer/Q2 Predictions Max     66.93072
trainer/Q2 Predictions Min     46.396255
trainer/Q Targets Mean         59.37952
trainer/Q Targets Std          3.3754337
trainer/Q Targets Max          67.169266
trainer/Q Targets Min          46.636967
trainer/Log Pis Mean           11.607785
trainer/Log Pis Std            7.833486
trainer/Log Pis Max            38.70597
trainer/Log Pis Min            -5.2161975
trainer/Policy mu Mean         -0.048032906
trainer/Policy mu Std          1.7309569
trainer/Policy mu Max          5.0406046
trainer/Policy mu Min          -5.1709104
trainer/Policy log std Mean    -0.32432893
trainer/Policy log std Std     0.13283697
trainer/Policy log std Max     0.26938292
trainer/Policy log std Min     -0.826604
trainer/Alpha                  0.0031150050926953554
trainer/Alpha Loss             -2.263638496398926
exploration/num steps total    301000
exploration/num paths total    602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6445952189158878
exploration/Rewards Std        0.06880451767798323
exploration/Rewards Max        0.9670749442078865
exploration/Rewards Min        0.39828943804158906
exploration/Returns Mean       322.29760945794385
exploration/Returns Std        13.805591131201233
exploration/Returns Max        346.7768442860335
exploration/Returns Min        304.41035029144695
exploration/Actions Mean       0.020026281
exploration/Actions Std        0.7326913
exploration/Actions Max        0.9999955
exploration/Actions Min        -0.99998736
exploration/Num Paths          10
exploration/Average Returns    322.29760945794385
evaluation/num steps total     300000
evaluation/num paths total     600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6417814722130227
evaluation/Rewards Std         0.08188910175852941
evaluation/Rewards Max         0.9656294704732433
evaluation/Rewards Min         0.27114336884945567
evaluation/Returns Mean        320.8907361065113
evaluation/Returns Std         20.980519746462182
evaluation/Returns Max         366.66182066986335
evaluation/Returns Min         276.9376565837216
evaluation/ExplReturns Mean    320.8907361065113
evaluation/ExplReturns Std     20.980519746462182
evaluation/ExplReturns Max     366.66182066986335
evaluation/ExplReturns Min     276.9376565837216
evaluation/Actions Mean        0.044996664
evaluation/Actions Std         0.6990819
evaluation/Actions Max         0.99993056
evaluation/Actions Min         -0.9996873
evaluation/Num Paths           10
evaluation/Average Returns     320.8907361065113
time/data storing (s)          0.03418502677232027
time/evaluation sampling (s)   112.55661305226386
time/exploration sampling (s)  112.33465383667499
time/logging (s)               0.030998801812529564
time/saving (s)                0.011163570918142796
time/training (s)              9.406937113963068
time/epoch (s)                 234.3745514024049
time/total (s)                 14054.694856324233
Epoch                          59
-----------------------------  ---------------------
2023-07-31 21:52:18.040414 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 60 finished
-----------------------------  --------------------
replay_buffer/size             306000
trainer/tdrp Loss              [3876.711]
trainer/QF1 Loss               0.15749608
trainer/QF2 Loss               0.18289143
trainer/Policy Loss            -48.530827
trainer/Q1 Predictions Mean    59.44287
trainer/Q1 Predictions Std     3.247987
trainer/Q1 Predictions Max     66.89865
trainer/Q1 Predictions Min     45.175217
trainer/Q2 Predictions Mean    59.361774
trainer/Q2 Predictions Std     3.276102
trainer/Q2 Predictions Max     66.64399
trainer/Q2 Predictions Min     45.147892
trainer/Q Targets Mean         59.618156
trainer/Q Targets Std          3.281799
trainer/Q Targets Max          67.12383
trainer/Q Targets Min          45.35907
trainer/Log Pis Mean           10.947058
trainer/Log Pis Std            8.159933
trainer/Log Pis Max            34.08847
trainer/Log Pis Min            -11.925578
trainer/Policy mu Mean         -0.18390544
trainer/Policy mu Std          1.718695
trainer/Policy mu Max          5.417668
trainer/Policy mu Min          -6.2862687
trainer/Policy log std Mean    -0.31625187
trainer/Policy log std Std     0.13384347
trainer/Policy log std Max     0.21053788
trainer/Policy log std Min     -0.7980873
trainer/Alpha                  0.003179634688422084
trainer/Alpha Loss             -6.055197238922119
exploration/num steps total    306000
exploration/num paths total    612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6240598352298874
exploration/Rewards Std        0.09272624437021969
exploration/Rewards Max        0.9723107898838675
exploration/Rewards Min        0.2968281948849899
exploration/Returns Mean       312.02991761494366
exploration/Returns Std        16.488676562207836
exploration/Returns Max        347.3667544075558
exploration/Returns Min        290.9320838593135
exploration/Actions Mean       -0.057847727
exploration/Actions Std        0.7119905
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.99998313
exploration/Num Paths          10
exploration/Average Returns    312.02991761494366
evaluation/num steps total     305000
evaluation/num paths total     610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6253772213212276
evaluation/Rewards Std         0.0700843487545034
evaluation/Rewards Max         0.9727035776808632
evaluation/Rewards Min         0.36217346413208384
evaluation/Returns Mean        312.68861066061396
evaluation/Returns Std         16.313411088157565
evaluation/Returns Max         341.20146301764265
evaluation/Returns Min         284.8233170510428
evaluation/ExplReturns Mean    312.68861066061396
evaluation/ExplReturns Std     16.313411088157565
evaluation/ExplReturns Max     341.20146301764265
evaluation/ExplReturns Min     284.8233170510428
evaluation/Actions Mean        -0.05075465
evaluation/Actions Std         0.6319119
evaluation/Actions Max         0.9999033
evaluation/Actions Min         -0.9999254
evaluation/Num Paths           10
evaluation/Average Returns     312.68861066061396
time/data storing (s)          0.03436048701405525
time/evaluation sampling (s)   113.36541816219687
time/exploration sampling (s)  112.67803643085063
time/logging (s)               0.030396138317883015
time/saving (s)                0.012554398737847805
time/training (s)              9.1215676413849
time/epoch (s)                 235.24233325850219
time/total (s)                 14289.93975699693
Epoch                          60
-----------------------------  --------------------
2023-07-31 21:56:12.637694 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 61 finished
-----------------------------  --------------------
replay_buffer/size             311000
trainer/tdrp Loss              [4263.163]
trainer/QF1 Loss               0.1373439
trainer/QF2 Loss               0.12537555
trainer/Policy Loss            -48.166084
trainer/Q1 Predictions Mean    59.50476
trainer/Q1 Predictions Std     3.356293
trainer/Q1 Predictions Max     65.73145
trainer/Q1 Predictions Min     47.17883
trainer/Q2 Predictions Mean    59.412216
trainer/Q2 Predictions Std     3.3406448
trainer/Q2 Predictions Max     65.88985
trainer/Q2 Predictions Min     47.240494
trainer/Q Targets Mean         59.437614
trainer/Q Targets Std          3.3907335
trainer/Q Targets Max          65.7992
trainer/Q Targets Min          47.377655
trainer/Log Pis Mean           11.408598
trainer/Log Pis Std            7.3920617
trainer/Log Pis Max            32.14
trainer/Log Pis Min            -7.307798
trainer/Policy mu Mean         -0.12400081
trainer/Policy mu Std          1.7012482
trainer/Policy mu Max          4.549865
trainer/Policy mu Min          -4.567165
trainer/Policy log std Mean    -0.33273533
trainer/Policy log std Std     0.13572527
trainer/Policy log std Max     0.20144731
trainer/Policy log std Min     -0.7586198
trainer/Alpha                  0.003108623204752803
trainer/Alpha Loss             -3.414264440536499
exploration/num steps total    311000
exploration/num paths total    622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.649633102662591
exploration/Rewards Std        0.06900419911222962
exploration/Rewards Max        0.9758826751014837
exploration/Rewards Min        0.34766431308919404
exploration/Returns Mean       324.81655133129544
exploration/Returns Std        9.057000930006472
exploration/Returns Max        338.1356909343854
exploration/Returns Min        315.4085073891544
exploration/Actions Mean       -0.0055265157
exploration/Actions Std        0.71887857
exploration/Actions Max        0.99997514
exploration/Actions Min        -0.99998856
exploration/Num Paths          10
exploration/Average Returns    324.81655133129544
evaluation/num steps total     310000
evaluation/num paths total     620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6258873436914658
evaluation/Rewards Std         0.061333810782056464
evaluation/Rewards Max         0.9743002439204163
evaluation/Rewards Min         0.3871555638763436
evaluation/Returns Mean        312.943671845733
evaluation/Returns Std         12.524985366814745
evaluation/Returns Max         334.31290302024655
evaluation/Returns Min         289.54248584319924
evaluation/ExplReturns Mean    312.943671845733
evaluation/ExplReturns Std     12.524985366814745
evaluation/ExplReturns Max     334.31290302024655
evaluation/ExplReturns Min     289.54248584319924
evaluation/Actions Mean        -0.063708395
evaluation/Actions Std         0.6238491
evaluation/Actions Max         0.99982154
evaluation/Actions Min         -0.9997393
evaluation/Num Paths           10
evaluation/Average Returns     312.943671845733
time/data storing (s)          0.03469355124980211
time/evaluation sampling (s)   111.32408293243498
time/exploration sampling (s)  112.86046054400504
time/logging (s)               0.03420818876475096
time/saving (s)                0.01313391700387001
time/training (s)              10.330977880395949
time/epoch (s)                 234.59755701385438
time/total (s)                 14524.539764591493
Epoch                          61
-----------------------------  --------------------
2023-07-31 22:00:07.516868 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 62 finished
-----------------------------  --------------------
replay_buffer/size             316000
trainer/tdrp Loss              [3921.0103]
trainer/QF1 Loss               0.1308616
trainer/QF2 Loss               0.12339913
trainer/Policy Loss            -47.22895
trainer/Q1 Predictions Mean    59.465866
trainer/Q1 Predictions Std     3.6839876
trainer/Q1 Predictions Max     67.0604
trainer/Q1 Predictions Min     45.411797
trainer/Q2 Predictions Mean    59.44494
trainer/Q2 Predictions Std     3.6802452
trainer/Q2 Predictions Max     66.67786
trainer/Q2 Predictions Min     45.373264
trainer/Q Targets Mean         59.454117
trainer/Q Targets Std          3.6950064
trainer/Q Targets Max          66.58633
trainer/Q Targets Min          45.640285
trainer/Log Pis Mean           12.334354
trainer/Log Pis Std            8.354739
trainer/Log Pis Max            37.372948
trainer/Log Pis Min            -7.408039
trainer/Policy mu Mean         -0.060685735
trainer/Policy mu Std          1.7572416
trainer/Policy mu Max          4.9638824
trainer/Policy mu Min          -5.8354936
trainer/Policy log std Mean    -0.34075034
trainer/Policy log std Std     0.13731448
trainer/Policy log std Max     0.13043475
trainer/Policy log std Min     -0.86533725
trainer/Alpha                  0.003120919456705451
trainer/Alpha Loss             1.9290415048599243
exploration/num steps total    316000
exploration/num paths total    632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6784366992907624
exploration/Rewards Std        0.09123650437544834
exploration/Rewards Max        0.973821614600407
exploration/Rewards Min        0.3919549475258319
exploration/Returns Mean       339.2183496453812
exploration/Returns Std        23.719110320818352
exploration/Returns Max        396.95749353974804
exploration/Returns Min        317.51635139616656
exploration/Actions Mean       0.024618004
exploration/Actions Std        0.730308
exploration/Actions Max        0.9999963
exploration/Actions Min        -0.99998564
exploration/Num Paths          10
exploration/Average Returns    339.2183496453812
evaluation/num steps total     315000
evaluation/num paths total     630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6524341798729254
evaluation/Rewards Std         0.06349853155909181
evaluation/Rewards Max         0.961535251943388
evaluation/Rewards Min         0.32885383914592276
evaluation/Returns Mean        326.2170899364627
evaluation/Returns Std         10.896229658223266
evaluation/Returns Max         347.1089225486268
evaluation/Returns Min         312.12902471862304
evaluation/ExplReturns Mean    326.2170899364627
evaluation/ExplReturns Std     10.896229658223266
evaluation/ExplReturns Max     347.1089225486268
evaluation/ExplReturns Min     312.12902471862304
evaluation/Actions Mean        0.022802336
evaluation/Actions Std         0.69015414
evaluation/Actions Max         0.9999703
evaluation/Actions Min         -0.9996686
evaluation/Num Paths           10
evaluation/Average Returns     326.2170899364627
time/data storing (s)          0.033414239063858986
time/evaluation sampling (s)   112.19362905528396
time/exploration sampling (s)  113.22807496692985
time/logging (s)               0.030244745314121246
time/saving (s)                0.012320728041231632
time/training (s)              9.373870742507279
time/epoch (s)                 234.8715544771403
time/total (s)                 14759.413910096511
Epoch                          62
-----------------------------  --------------------
2023-07-31 22:04:00.244554 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 63 finished
-----------------------------  --------------------
replay_buffer/size             321000
trainer/tdrp Loss              [4067.168]
trainer/QF1 Loss               0.120416254
trainer/QF2 Loss               0.11391181
trainer/Policy Loss            -47.05088
trainer/Q1 Predictions Mean    59.76575
trainer/Q1 Predictions Std     2.9961848
trainer/Q1 Predictions Max     66.33959
trainer/Q1 Predictions Min     50.552383
trainer/Q2 Predictions Mean    59.83979
trainer/Q2 Predictions Std     3.0084276
trainer/Q2 Predictions Max     66.46095
trainer/Q2 Predictions Min     50.441593
trainer/Q Targets Mean         59.8448
trainer/Q Targets Std          2.9886663
trainer/Q Targets Max          66.47634
trainer/Q Targets Min          50.746044
trainer/Log Pis Mean           12.850587
trainer/Log Pis Std            7.7541347
trainer/Log Pis Max            36.029606
trainer/Log Pis Min            -8.367193
trainer/Policy mu Mean         -0.065200575
trainer/Policy mu Std          1.7992388
trainer/Policy mu Max          5.2482815
trainer/Policy mu Min          -5.1614623
trainer/Policy log std Mean    -0.3483489
trainer/Policy log std Std     0.13563177
trainer/Policy log std Max     0.2193149
trainer/Policy log std Min     -0.8046814
trainer/Alpha                  0.003183384658768773
trainer/Alpha Loss             4.890778541564941
exploration/num steps total    321000
exploration/num paths total    642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6437914799083548
exploration/Rewards Std        0.06444892754881415
exploration/Rewards Max        0.9640018637330435
exploration/Rewards Min        0.4285450014664763
exploration/Returns Mean       321.8957399541775
exploration/Returns Std        18.70266329295723
exploration/Returns Max        335.7493221097511
exploration/Returns Min        282.6666872317056
exploration/Actions Mean       0.0072881035
exploration/Actions Std        0.71727186
exploration/Actions Max        0.9999832
exploration/Actions Min        -0.99994636
exploration/Num Paths          10
exploration/Average Returns    321.8957399541775
evaluation/num steps total     320000
evaluation/num paths total     640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6482490045902725
evaluation/Rewards Std         0.08564818177112891
evaluation/Rewards Max         0.9716752195936311
evaluation/Rewards Min         0.2973266709872944
evaluation/Returns Mean        324.12450229513615
evaluation/Returns Std         20.08889467463898
evaluation/Returns Max         346.817213393919
evaluation/Returns Min         275.4228622184614
evaluation/ExplReturns Mean    324.12450229513615
evaluation/ExplReturns Std     20.08889467463898
evaluation/ExplReturns Max     346.817213393919
evaluation/ExplReturns Min     275.4228622184614
evaluation/Actions Mean        0.003051755
evaluation/Actions Std         0.685353
evaluation/Actions Max         0.99996114
evaluation/Actions Min         -0.99995685
evaluation/Num Paths           10
evaluation/Average Returns     324.12450229513615
time/data storing (s)          0.03363914228975773
time/evaluation sampling (s)   111.05227700714022
time/exploration sampling (s)  112.25944915600121
time/logging (s)               0.030589381232857704
time/saving (s)                0.012406256049871445
time/training (s)              9.336054204963148
time/epoch (s)                 232.72441514767706
time/total (s)                 14992.140886363573
Epoch                          63
-----------------------------  --------------------
2023-07-31 22:07:53.964348 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 64 finished
-----------------------------  ---------------------
replay_buffer/size             326000
trainer/tdrp Loss              [4141.095]
trainer/QF1 Loss               0.09623122
trainer/QF2 Loss               0.107727475
trainer/Policy Loss            -48.589523
trainer/Q1 Predictions Mean    59.733635
trainer/Q1 Predictions Std     3.860011
trainer/Q1 Predictions Max     66.63028
trainer/Q1 Predictions Min     43.128117
trainer/Q2 Predictions Mean    59.75073
trainer/Q2 Predictions Std     3.8664565
trainer/Q2 Predictions Max     66.5744
trainer/Q2 Predictions Min     43.173904
trainer/Q Targets Mean         59.71668
trainer/Q Targets Std          3.852019
trainer/Q Targets Max          66.274704
trainer/Q Targets Min          43.562622
trainer/Log Pis Mean           11.262365
trainer/Log Pis Std            8.260462
trainer/Log Pis Max            36.73582
trainer/Log Pis Min            -10.640374
trainer/Policy mu Mean         -0.032966428
trainer/Policy mu Std          1.7233281
trainer/Policy mu Max          5.5287232
trainer/Policy mu Min          -5.4417143
trainer/Policy log std Mean    -0.33728743
trainer/Policy log std Std     0.12705019
trainer/Policy log std Max     0.09377833
trainer/Policy log std Min     -0.7924014
trainer/Alpha                  0.0031230738386511803
trainer/Alpha Loss             -4.255224704742432
exploration/num steps total    326000
exploration/num paths total    652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6590801211191567
exploration/Rewards Std        0.06002006003965375
exploration/Rewards Max        0.9631480067607598
exploration/Rewards Min        0.4641004019979873
exploration/Returns Mean       329.5400605595784
exploration/Returns Std        6.926739125581835
exploration/Returns Max        341.1592739757536
exploration/Returns Min        318.19675829701987
exploration/Actions Mean       0.04831009
exploration/Actions Std        0.7234046
exploration/Actions Max        0.99999404
exploration/Actions Min        -0.99997187
exploration/Num Paths          10
exploration/Average Returns    329.5400605595784
evaluation/num steps total     325000
evaluation/num paths total     650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6544518657957248
evaluation/Rewards Std         0.055963966122366114
evaluation/Rewards Max         0.9561550415820895
evaluation/Rewards Min         0.46058224192951036
evaluation/Returns Mean        327.2259328978624
evaluation/Returns Std         12.983478232967862
evaluation/Returns Max         339.90337042914217
evaluation/Returns Min         292.68318002050825
evaluation/ExplReturns Mean    327.2259328978624
evaluation/ExplReturns Std     12.983478232967862
evaluation/ExplReturns Max     339.90337042914217
evaluation/ExplReturns Min     292.68318002050825
evaluation/Actions Mean        0.03182983
evaluation/Actions Std         0.6319755
evaluation/Actions Max         0.999961
evaluation/Actions Min         -0.9996259
evaluation/Num Paths           10
evaluation/Average Returns     327.2259328978624
time/data storing (s)          0.034356328658759594
time/evaluation sampling (s)   111.93757790792733
time/exploration sampling (s)  112.24309495277703
time/logging (s)               0.030329124070703983
time/saving (s)                0.011360020376741886
time/training (s)              9.45922573003918
time/epoch (s)                 233.71594406384975
time/total (s)                 15225.859393492341
Epoch                          64
-----------------------------  ---------------------
2023-07-31 22:11:48.658470 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 65 finished
-----------------------------  --------------------
replay_buffer/size             331000
trainer/tdrp Loss              [4175.1895]
trainer/QF1 Loss               0.12934189
trainer/QF2 Loss               0.116129205
trainer/Policy Loss            -47.85971
trainer/Q1 Predictions Mean    59.601448
trainer/Q1 Predictions Std     3.329178
trainer/Q1 Predictions Max     66.03132
trainer/Q1 Predictions Min     46.15349
trainer/Q2 Predictions Mean    59.581085
trainer/Q2 Predictions Std     3.3099468
trainer/Q2 Predictions Max     65.72412
trainer/Q2 Predictions Min     46.05527
trainer/Q Targets Mean         59.567432
trainer/Q Targets Std          3.314859
trainer/Q Targets Max          65.80727
trainer/Q Targets Min          45.8557
trainer/Log Pis Mean           11.842135
trainer/Log Pis Std            7.4832573
trainer/Log Pis Max            46.50338
trainer/Log Pis Min            -3.3078406
trainer/Policy mu Mean         -0.16003801
trainer/Policy mu Std          1.7389883
trainer/Policy mu Max          6.296617
trainer/Policy mu Min          -5.2387576
trainer/Policy log std Mean    -0.33840027
trainer/Policy log std Std     0.12877266
trainer/Policy log std Max     0.25806326
trainer/Policy log std Min     -0.74482477
trainer/Alpha                  0.003119592322036624
trainer/Alpha Loss             -0.9108511805534363
exploration/num steps total    331000
exploration/num paths total    662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6751509941937377
exploration/Rewards Std        0.08638251368479379
exploration/Rewards Max        0.9785520055453398
exploration/Rewards Min        0.42775209698069994
exploration/Returns Mean       337.57549709686873
exploration/Returns Std        13.031221552676966
exploration/Returns Max        362.99601761162853
exploration/Returns Min        318.60946691344446
exploration/Actions Mean       0.022520086
exploration/Actions Std        0.7418649
exploration/Actions Max        0.9999956
exploration/Actions Min        -0.9999811
exploration/Num Paths          10
exploration/Average Returns    337.57549709686873
evaluation/num steps total     330000
evaluation/num paths total     660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7045885521541421
evaluation/Rewards Std         0.11041466207587895
evaluation/Rewards Max         0.9781893514936005
evaluation/Rewards Min         0.36200977480390634
evaluation/Returns Mean        352.29427607707106
evaluation/Returns Std         22.314915487563464
evaluation/Returns Max         383.93451442789325
evaluation/Returns Min         311.8263937785495
evaluation/ExplReturns Mean    352.29427607707106
evaluation/ExplReturns Std     22.314915487563464
evaluation/ExplReturns Max     383.93451442789325
evaluation/ExplReturns Min     311.8263937785495
evaluation/Actions Mean        0.05461516
evaluation/Actions Std         0.67169434
evaluation/Actions Max         0.99980116
evaluation/Actions Min         -0.999964
evaluation/Num Paths           10
evaluation/Average Returns     352.29427607707106
time/data storing (s)          0.0337105393409729
time/evaluation sampling (s)   111.95287219528109
time/exploration sampling (s)  113.17108294554055
time/logging (s)               0.030316459946334362
time/saving (s)                0.010220304131507874
time/training (s)              9.492470002733171
time/epoch (s)                 234.69067244697362
time/total (s)                 15460.552476956509
Epoch                          65
-----------------------------  --------------------
2023-07-31 22:15:47.741215 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 66 finished
-----------------------------  ---------------------
replay_buffer/size             336000
trainer/tdrp Loss              [3886.291]
trainer/QF1 Loss               0.15315321
trainer/QF2 Loss               0.14156088
trainer/Policy Loss            -48.197693
trainer/Q1 Predictions Mean    59.842457
trainer/Q1 Predictions Std     3.8018925
trainer/Q1 Predictions Max     66.287544
trainer/Q1 Predictions Min     43.8091
trainer/Q2 Predictions Mean    59.85824
trainer/Q2 Predictions Std     3.814514
trainer/Q2 Predictions Max     66.24395
trainer/Q2 Predictions Min     43.564518
trainer/Q Targets Mean         59.69447
trainer/Q Targets Std          3.7734637
trainer/Q Targets Max          66.057304
trainer/Q Targets Min          42.823986
trainer/Log Pis Mean           11.787935
trainer/Log Pis Std            7.47061
trainer/Log Pis Max            34.852005
trainer/Log Pis Min            -6.5272493
trainer/Policy mu Mean         -0.1810181
trainer/Policy mu Std          1.7399833
trainer/Policy mu Max          4.8486915
trainer/Policy mu Min          -5.1820126
trainer/Policy log std Mean    -0.35499159
trainer/Policy log std Std     0.12686335
trainer/Policy log std Max     0.21182233
trainer/Policy log std Min     -0.9021623
trainer/Alpha                  0.0032100204844027758
trainer/Alpha Loss             -1.217566728591919
exploration/num steps total    336000
exploration/num paths total    672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6764592687348
exploration/Rewards Std        0.07870933961620116
exploration/Rewards Max        0.9757788004643064
exploration/Rewards Min        0.435706395012401
exploration/Returns Mean       338.2296343674
exploration/Returns Std        16.04557400271985
exploration/Returns Max        371.3933679705181
exploration/Returns Min        314.68098134636045
exploration/Actions Mean       -0.024308726
exploration/Actions Std        0.7438016
exploration/Actions Max        0.9999902
exploration/Actions Min        -0.9999957
exploration/Num Paths          10
exploration/Average Returns    338.2296343674
evaluation/num steps total     335000
evaluation/num paths total     670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6798376499270565
evaluation/Rewards Std         0.0839686986688197
evaluation/Rewards Max         0.9729435387654846
evaluation/Rewards Min         0.38847451092242363
evaluation/Returns Mean        339.9188249635283
evaluation/Returns Std         16.564613275588854
evaluation/Returns Max         365.86532966584264
evaluation/Returns Min         303.1283144437515
evaluation/ExplReturns Mean    339.9188249635283
evaluation/ExplReturns Std     16.564613275588854
evaluation/ExplReturns Max     365.86532966584264
evaluation/ExplReturns Min     303.1283144437515
evaluation/Actions Mean        -0.0044496814
evaluation/Actions Std         0.7034139
evaluation/Actions Max         0.9998424
evaluation/Actions Min         -0.99964803
evaluation/Num Paths           10
evaluation/Average Returns     339.9188249635283
time/data storing (s)          0.034063794650137424
time/evaluation sampling (s)   114.56274492107332
time/exploration sampling (s)  114.96764635108411
time/logging (s)               0.030633049085736275
time/saving (s)                0.012127640657126904
time/training (s)              9.47232427727431
time/epoch (s)                 239.07954003382474
time/total (s)                 15699.634487537667
Epoch                          66
-----------------------------  ---------------------
2023-07-31 22:19:40.840384 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 67 finished
-----------------------------  ---------------------
replay_buffer/size             341000
trainer/tdrp Loss              [4254.318]
trainer/QF1 Loss               0.12230712
trainer/QF2 Loss               0.14378785
trainer/Policy Loss            -47.720894
trainer/Q1 Predictions Mean    59.934406
trainer/Q1 Predictions Std     3.7110527
trainer/Q1 Predictions Max     66.19995
trainer/Q1 Predictions Min     40.32974
trainer/Q2 Predictions Mean    59.999058
trainer/Q2 Predictions Std     3.7249804
trainer/Q2 Predictions Max     66.31346
trainer/Q2 Predictions Min     40.362926
trainer/Q Targets Mean         59.835526
trainer/Q Targets Std          3.6928344
trainer/Q Targets Max          66.18622
trainer/Q Targets Min          39.902924
trainer/Log Pis Mean           12.380594
trainer/Log Pis Std            7.4349494
trainer/Log Pis Max            39.782368
trainer/Log Pis Min            -3.6916413
trainer/Policy mu Mean         -0.13375588
trainer/Policy mu Std          1.7586852
trainer/Policy mu Max          5.676092
trainer/Policy mu Min          -5.0896025
trainer/Policy log std Mean    -0.3627213
trainer/Policy log std Std     0.12920637
trainer/Policy log std Max     0.10471478
trainer/Policy log std Min     -0.81616867
trainer/Alpha                  0.0032146035227924585
trainer/Alpha Loss             2.184720039367676
exploration/num steps total    341000
exploration/num paths total    682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6713560644738236
exploration/Rewards Std        0.07261143531973589
exploration/Rewards Max        0.9754225809739023
exploration/Rewards Min        0.3747748422569652
exploration/Returns Mean       335.67803223691163
exploration/Returns Std        17.035051908626304
exploration/Returns Max        384.21230381726144
exploration/Returns Min        320.1985802020247
exploration/Actions Mean       -0.00080020726
exploration/Actions Std        0.7320776
exploration/Actions Max        0.9999908
exploration/Actions Min        -0.9999877
exploration/Num Paths          10
exploration/Average Returns    335.67803223691163
evaluation/num steps total     340000
evaluation/num paths total     680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6966148689453047
evaluation/Rewards Std         0.0927621204269423
evaluation/Rewards Max         0.9778336611555457
evaluation/Rewards Min         0.47395864206694976
evaluation/Returns Mean        348.3074344726524
evaluation/Returns Std         23.348686889793044
evaluation/Returns Max         394.3208980381143
evaluation/Returns Min         326.46508746861446
evaluation/ExplReturns Mean    348.3074344726524
evaluation/ExplReturns Std     23.348686889793044
evaluation/ExplReturns Max     394.3208980381143
evaluation/ExplReturns Min     326.46508746861446
evaluation/Actions Mean        0.039142486
evaluation/Actions Std         0.6916559
evaluation/Actions Max         0.99954087
evaluation/Actions Min         -0.9996909
evaluation/Num Paths           10
evaluation/Average Returns     348.3074344726524
time/data storing (s)          0.03398802783340216
time/evaluation sampling (s)   111.42874394636601
time/exploration sampling (s)  112.06832025386393
time/logging (s)               0.030368847772479057
time/saving (s)                0.011212929151952267
time/training (s)              9.522575952112675
time/epoch (s)                 233.09520995710045
time/total (s)                 15932.732311090454
Epoch                          67
-----------------------------  ---------------------
2023-07-31 22:23:39.056555 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 68 finished
-----------------------------  ---------------------
replay_buffer/size             346000
trainer/tdrp Loss              [4161.156]
trainer/QF1 Loss               0.108226724
trainer/QF2 Loss               0.100220084
trainer/Policy Loss            -49.49285
trainer/Q1 Predictions Mean    60.216484
trainer/Q1 Predictions Std     3.5438242
trainer/Q1 Predictions Max     66.17415
trainer/Q1 Predictions Min     45.72646
trainer/Q2 Predictions Mean    60.17147
trainer/Q2 Predictions Std     3.5697305
trainer/Q2 Predictions Max     66.19953
trainer/Q2 Predictions Min     45.819443
trainer/Q Targets Mean         60.17198
trainer/Q Targets Std          3.6097238
trainer/Q Targets Max          66.40997
trainer/Q Targets Min          46.609318
trainer/Log Pis Mean           10.821586
trainer/Log Pis Std            7.0146465
trainer/Log Pis Max            34.62394
trainer/Log Pis Min            -9.024328
trainer/Policy mu Mean         -0.12637119
trainer/Policy mu Std          1.7270231
trainer/Policy mu Max          4.4876485
trainer/Policy mu Min          -5.5912733
trainer/Policy log std Mean    -0.33748612
trainer/Policy log std Std     0.13076423
trainer/Policy log std Max     0.11289933
trainer/Policy log std Min     -0.73908865
trainer/Alpha                  0.0031839448492974043
trainer/Alpha Loss             -6.77505350112915
exploration/num steps total    346000
exploration/num paths total    692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6774544825800903
exploration/Rewards Std        0.0744894061711179
exploration/Rewards Max        0.976267203521274
exploration/Rewards Min        0.36840466547348405
exploration/Returns Mean       338.7272412900453
exploration/Returns Std        8.558565009914535
exploration/Returns Max        353.37683939788906
exploration/Returns Min        323.5716788186431
exploration/Actions Mean       -0.04826514
exploration/Actions Std        0.7212892
exploration/Actions Max        0.9999839
exploration/Actions Min        -0.9999928
exploration/Num Paths          10
exploration/Average Returns    338.7272412900453
evaluation/num steps total     345000
evaluation/num paths total     690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6768614710383523
evaluation/Rewards Std         0.07432046538114216
evaluation/Rewards Max         0.9686995122890659
evaluation/Rewards Min         0.4035885804106479
evaluation/Returns Mean        338.4307355191763
evaluation/Returns Std         15.070110791498504
evaluation/Returns Max         365.62587110647587
evaluation/Returns Min         323.61782220686473
evaluation/ExplReturns Mean    338.4307355191763
evaluation/ExplReturns Std     15.070110791498504
evaluation/ExplReturns Max     365.62587110647587
evaluation/ExplReturns Min     323.61782220686473
evaluation/Actions Mean        -0.07727824
evaluation/Actions Std         0.62807286
evaluation/Actions Max         0.9996788
evaluation/Actions Min         -0.9999741
evaluation/Num Paths           10
evaluation/Average Returns     338.4307355191763
time/data storing (s)          0.033933437429368496
time/evaluation sampling (s)   114.16196976788342
time/exploration sampling (s)  114.4487716993317
time/logging (s)               0.030339470133185387
time/saving (s)                0.011335516348481178
time/training (s)              9.526302109472454
time/epoch (s)                 238.2126520005986
time/total (s)                 16170.947390183806
Epoch                          68
-----------------------------  ---------------------
2023-07-31 22:27:33.103105 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 69 finished
-----------------------------  --------------------
replay_buffer/size             351000
trainer/tdrp Loss              [3977.2517]
trainer/QF1 Loss               0.14208518
trainer/QF2 Loss               0.13030857
trainer/Policy Loss            -48.163475
trainer/Q1 Predictions Mean    59.90251
trainer/Q1 Predictions Std     3.4338667
trainer/Q1 Predictions Max     67.309105
trainer/Q1 Predictions Min     44.69104
trainer/Q2 Predictions Mean    59.837357
trainer/Q2 Predictions Std     3.4054067
trainer/Q2 Predictions Max     67.08907
trainer/Q2 Predictions Min     45.282494
trainer/Q Targets Mean         59.95036
trainer/Q Targets Std          3.4359202
trainer/Q Targets Max          66.811874
trainer/Q Targets Min          44.850746
trainer/Log Pis Mean           11.831475
trainer/Log Pis Std            7.443893
trainer/Log Pis Max            34.736885
trainer/Log Pis Min            -8.060843
trainer/Policy mu Mean         -0.009787087
trainer/Policy mu Std          1.734359
trainer/Policy mu Max          5.50069
trainer/Policy mu Min          -4.643447
trainer/Policy log std Mean    -0.36169982
trainer/Policy log std Std     0.12701507
trainer/Policy log std Max     0.064475805
trainer/Policy log std Min     -0.83714736
trainer/Alpha                  0.003175752703100443
trainer/Alpha Loss             -0.9693979024887085
exploration/num steps total    351000
exploration/num paths total    702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6734287705610085
exploration/Rewards Std        0.05090263474938784
exploration/Rewards Max        0.9483425196597435
exploration/Rewards Min        0.3831504998058286
exploration/Returns Mean       336.7143852805043
exploration/Returns Std        5.744419562810078
exploration/Returns Max        343.72300213559834
exploration/Returns Min        327.90738274770007
exploration/Actions Mean       0.0872428
exploration/Actions Std        0.7275262
exploration/Actions Max        0.9999964
exploration/Actions Min        -0.9999471
exploration/Num Paths          10
exploration/Average Returns    336.7143852805043
evaluation/num steps total     350000
evaluation/num paths total     700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6656859027007955
evaluation/Rewards Std         0.04548029484218325
evaluation/Rewards Max         0.7449728758804355
evaluation/Rewards Min         0.49174561285523355
evaluation/Returns Mean        332.84295135039764
evaluation/Returns Std         8.871270610676357
evaluation/Returns Max         345.57203957654764
evaluation/Returns Min         319.4744665391575
evaluation/ExplReturns Mean    332.84295135039764
evaluation/ExplReturns Std     8.871270610676357
evaluation/ExplReturns Max     345.57203957654764
evaluation/ExplReturns Min     319.4744665391575
evaluation/Actions Mean        0.120482855
evaluation/Actions Std         0.6635804
evaluation/Actions Max         0.99967366
evaluation/Actions Min         -0.99812156
evaluation/Num Paths           10
evaluation/Average Returns     332.84295135039764
time/data storing (s)          0.034645684994757175
time/evaluation sampling (s)   112.04418387450278
time/exploration sampling (s)  112.62521072663367
time/logging (s)               0.030225160531699657
time/saving (s)                0.012703894637525082
time/training (s)              9.29597788117826
time/epoch (s)                 234.0429472224787
time/total (s)                 16404.99275537394
Epoch                          69
-----------------------------  --------------------
2023-07-31 22:31:31.047243 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 70 finished
-----------------------------  ---------------------
replay_buffer/size             356000
trainer/tdrp Loss              [4205.1816]
trainer/QF1 Loss               0.13228078
trainer/QF2 Loss               0.10406579
trainer/Policy Loss            -49.75627
trainer/Q1 Predictions Mean    60.698124
trainer/Q1 Predictions Std     3.4828665
trainer/Q1 Predictions Max     66.80886
trainer/Q1 Predictions Min     50.339195
trainer/Q2 Predictions Mean    60.61052
trainer/Q2 Predictions Std     3.4734855
trainer/Q2 Predictions Max     66.64645
trainer/Q2 Predictions Min     49.989147
trainer/Q Targets Mean         60.612576
trainer/Q Targets Std          3.496598
trainer/Q Targets Max          66.95248
trainer/Q Targets Min          49.62785
trainer/Log Pis Mean           11.018316
trainer/Log Pis Std            7.706224
trainer/Log Pis Max            48.413475
trainer/Log Pis Min            -7.888962
trainer/Policy mu Mean         -0.06943614
trainer/Policy mu Std          1.706909
trainer/Policy mu Max          4.7757616
trainer/Policy mu Min          -5.9291716
trainer/Policy log std Mean    -0.34319732
trainer/Policy log std Std     0.12930022
trainer/Policy log std Max     0.20551059
trainer/Policy log std Min     -0.80159956
trainer/Alpha                  0.0032155646476894617
trainer/Alpha Loss             -5.634377956390381
exploration/num steps total    356000
exploration/num paths total    712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6891653264321409
exploration/Rewards Std        0.06651314873436108
exploration/Rewards Max        0.9749979451974493
exploration/Rewards Min        0.45575902686314934
exploration/Returns Mean       344.5826632160705
exploration/Returns Std        8.873991052035947
exploration/Returns Max        365.86412050779234
exploration/Returns Min        338.16877710596435
exploration/Actions Mean       0.014539502
exploration/Actions Std        0.72828203
exploration/Actions Max        0.99996114
exploration/Actions Min        -0.99997747
exploration/Num Paths          10
exploration/Average Returns    344.5826632160705
evaluation/num steps total     355000
evaluation/num paths total     710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6691083796543121
evaluation/Rewards Std         0.05992974029551919
evaluation/Rewards Max         0.974444431542032
evaluation/Rewards Min         0.4202132583224482
evaluation/Returns Mean        334.55418982715616
evaluation/Returns Std         11.850749292610663
evaluation/Returns Max         357.1229633812584
evaluation/Returns Min         317.29099248611874
evaluation/ExplReturns Mean    334.55418982715616
evaluation/ExplReturns Std     11.850749292610663
evaluation/ExplReturns Max     357.1229633812584
evaluation/ExplReturns Min     317.29099248611874
evaluation/Actions Mean        -0.07916257
evaluation/Actions Std         0.6677728
evaluation/Actions Max         0.9995521
evaluation/Actions Min         -0.9988511
evaluation/Num Paths           10
evaluation/Average Returns     334.55418982715616
time/data storing (s)          0.03420157078653574
time/evaluation sampling (s)   113.94891251437366
time/exploration sampling (s)  114.27009032387286
time/logging (s)               0.030485901050269604
time/saving (s)                0.012629599310457706
time/training (s)              9.644493576139212
time/epoch (s)                 237.940813485533
time/total (s)                 16642.936084290035
Epoch                          70
-----------------------------  ---------------------
2023-07-31 22:35:27.683806 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 71 finished
-----------------------------  --------------------
replay_buffer/size             361000
trainer/tdrp Loss              [4098.1978]
trainer/QF1 Loss               0.12948105
trainer/QF2 Loss               0.1288734
trainer/Policy Loss            -48.494186
trainer/Q1 Predictions Mean    60.82171
trainer/Q1 Predictions Std     3.2425873
trainer/Q1 Predictions Max     67.21268
trainer/Q1 Predictions Min     45.00678
trainer/Q2 Predictions Mean    60.821644
trainer/Q2 Predictions Std     3.206556
trainer/Q2 Predictions Max     67.304985
trainer/Q2 Predictions Min     44.918766
trainer/Q Targets Mean         60.75518
trainer/Q Targets Std          3.2364378
trainer/Q Targets Max          66.98136
trainer/Q Targets Min          45.031113
trainer/Log Pis Mean           12.459797
trainer/Log Pis Std            7.5547595
trainer/Log Pis Max            44.687958
trainer/Log Pis Min            -5.178094
trainer/Policy mu Mean         -0.24578802
trainer/Policy mu Std          1.7379873
trainer/Policy mu Max          5.0145435
trainer/Policy mu Min          -5.0009985
trainer/Policy log std Mean    -0.36775303
trainer/Policy log std Std     0.12886128
trainer/Policy log std Max     0.16107246
trainer/Policy log std Min     -0.8466302
trainer/Alpha                  0.003142563859000802
trainer/Alpha Loss             2.6497554779052734
exploration/num steps total    361000
exploration/num paths total    722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7042629220044115
exploration/Rewards Std        0.08733443639681418
exploration/Rewards Max        0.9783819474725881
exploration/Rewards Min        0.4387690293900143
exploration/Returns Mean       352.1314610022057
exploration/Returns Std        26.8849417422243
exploration/Returns Max        407.93358214100675
exploration/Returns Min        323.88685585040054
exploration/Actions Mean       -0.08245479
exploration/Actions Std        0.7203816
exploration/Actions Max        0.9999915
exploration/Actions Min        -0.9999949
exploration/Num Paths          10
exploration/Average Returns    352.1314610022057
evaluation/num steps total     360000
evaluation/num paths total     720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7068134680661151
evaluation/Rewards Std         0.09257601905644501
evaluation/Rewards Max         0.9766746695416247
evaluation/Rewards Min         0.4560131547987661
evaluation/Returns Mean        353.40673403305743
evaluation/Returns Std         24.20592993102826
evaluation/Returns Max         408.9251797533544
evaluation/Returns Min         331.70534169087273
evaluation/ExplReturns Mean    353.40673403305743
evaluation/ExplReturns Std     24.20592993102826
evaluation/ExplReturns Max     408.9251797533544
evaluation/ExplReturns Min     331.70534169087273
evaluation/Actions Mean        -0.084594965
evaluation/Actions Std         0.6532843
evaluation/Actions Max         0.99968123
evaluation/Actions Min         -0.99982923
evaluation/Num Paths           10
evaluation/Average Returns     353.40673403305743
time/data storing (s)          0.03423444461077452
time/evaluation sampling (s)   112.43580473400652
time/exploration sampling (s)  114.56315223965794
time/logging (s)               0.03047906793653965
time/saving (s)                0.012572204694151878
time/training (s)              9.55639523640275
time/epoch (s)                 236.63263792730868
time/total (s)                 16879.571548322216
Epoch                          71
-----------------------------  --------------------
2023-07-31 22:39:24.848944 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 72 finished
-----------------------------  ---------------------
replay_buffer/size             366000
trainer/tdrp Loss              [4250.445]
trainer/QF1 Loss               0.14762416
trainer/QF2 Loss               0.11503787
trainer/Policy Loss            -49.078716
trainer/Q1 Predictions Mean    60.740986
trainer/Q1 Predictions Std     3.4405377
trainer/Q1 Predictions Max     67.67057
trainer/Q1 Predictions Min     48.51849
trainer/Q2 Predictions Mean    60.80719
trainer/Q2 Predictions Std     3.4609916
trainer/Q2 Predictions Max     67.4468
trainer/Q2 Predictions Min     47.462044
trainer/Q Targets Mean         60.885452
trainer/Q Targets Std          3.475867
trainer/Q Targets Max          67.62521
trainer/Q Targets Min          47.42001
trainer/Log Pis Mean           11.831694
trainer/Log Pis Std            7.2061896
trainer/Log Pis Max            28.110338
trainer/Log Pis Min            -7.2244306
trainer/Policy mu Mean         -0.09192988
trainer/Policy mu Std          1.7111067
trainer/Policy mu Max          4.608701
trainer/Policy mu Min          -4.7499666
trainer/Policy log std Mean    -0.36409727
trainer/Policy log std Std     0.124496676
trainer/Policy log std Max     0.15325797
trainer/Policy log std Min     -0.8544085
trainer/Alpha                  0.0032086370047181845
trainer/Alpha Loss             -0.9663758277893066
exploration/num steps total    366000
exploration/num paths total    732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6667735547512279
exploration/Rewards Std        0.09936225845758426
exploration/Rewards Max        0.9793213522968758
exploration/Rewards Min        0.36548437012027296
exploration/Returns Mean       333.38677737561386
exploration/Returns Std        18.48314789313832
exploration/Returns Max        372.0261054425413
exploration/Returns Min        304.9509078760017
exploration/Actions Mean       -0.04338266
exploration/Actions Std        0.71166575
exploration/Actions Max        0.9999566
exploration/Actions Min        -0.9999779
exploration/Num Paths          10
exploration/Average Returns    333.38677737561386
evaluation/num steps total     365000
evaluation/num paths total     730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.683237246244139
evaluation/Rewards Std         0.08132457104379315
evaluation/Rewards Max         0.9770043379072103
evaluation/Rewards Min         0.36458649757046313
evaluation/Returns Mean        341.61862312206944
evaluation/Returns Std         13.434217181390077
evaluation/Returns Max         370.3794192966734
evaluation/Returns Min         321.36006259177236
evaluation/ExplReturns Mean    341.61862312206944
evaluation/ExplReturns Std     13.434217181390077
evaluation/ExplReturns Max     370.3794192966734
evaluation/ExplReturns Min     321.36006259177236
evaluation/Actions Mean        -0.069952846
evaluation/Actions Std         0.64219314
evaluation/Actions Max         0.99931103
evaluation/Actions Min         -0.9998046
evaluation/Num Paths           10
evaluation/Average Returns     341.61862312206944
time/data storing (s)          0.034237091429531574
time/evaluation sampling (s)   112.99867769517004
time/exploration sampling (s)  114.69633169751614
time/logging (s)               0.030465727671980858
time/saving (s)                0.01035735011100769
time/training (s)              9.391065048985183
time/epoch (s)                 237.1611346108839
time/total (s)                 17116.73558259569
Epoch                          72
-----------------------------  ---------------------
2023-07-31 22:43:23.773697 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 73 finished
-----------------------------  --------------------
replay_buffer/size             371000
trainer/tdrp Loss              [3957.263]
trainer/QF1 Loss               0.1516599
trainer/QF2 Loss               0.1431346
trainer/Policy Loss            -49.898384
trainer/Q1 Predictions Mean    61.202667
trainer/Q1 Predictions Std     3.6224864
trainer/Q1 Predictions Max     67.653885
trainer/Q1 Predictions Min     48.441612
trainer/Q2 Predictions Mean    61.141
trainer/Q2 Predictions Std     3.6179204
trainer/Q2 Predictions Max     67.8395
trainer/Q2 Predictions Min     47.85077
trainer/Q Targets Mean         61.047394
trainer/Q Targets Std          3.6518753
trainer/Q Targets Max          67.54732
trainer/Q Targets Min          47.730335
trainer/Log Pis Mean           11.40497
trainer/Log Pis Std            7.891658
trainer/Log Pis Max            34.02594
trainer/Log Pis Min            -7.0489197
trainer/Policy mu Mean         -0.18717985
trainer/Policy mu Std          1.7054908
trainer/Policy mu Max          4.9365287
trainer/Policy mu Min          -6.103403
trainer/Policy log std Mean    -0.36605242
trainer/Policy log std Std     0.12432257
trainer/Policy log std Max     0.29223847
trainer/Policy log std Min     -0.8422283
trainer/Alpha                  0.003286888124421239
trainer/Alpha Loss             -3.4022417068481445
exploration/num steps total    371000
exploration/num paths total    742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.641255786761388
exploration/Rewards Std        0.12434803474042051
exploration/Rewards Max        0.9757896395102101
exploration/Rewards Min        0.2565441582488898
exploration/Returns Mean       320.62789338069393
exploration/Returns Std        35.527799698609435
exploration/Returns Max        389.2119562360379
exploration/Returns Min        284.4714916172776
exploration/Actions Mean       -0.10526927
exploration/Actions Std        0.7311298
exploration/Actions Max        0.9999985
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    320.62789338069393
evaluation/num steps total     370000
evaluation/num paths total     740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6581588623639293
evaluation/Rewards Std         0.14846053083802777
evaluation/Rewards Max         0.9736528136394084
evaluation/Rewards Min         0.2634796296496325
evaluation/Returns Mean        329.07943118196454
evaluation/Returns Std         51.53349901373661
evaluation/Returns Max         402.6841262890667
evaluation/Returns Min         264.9782208255325
evaluation/ExplReturns Mean    329.07943118196454
evaluation/ExplReturns Std     51.53349901373661
evaluation/ExplReturns Max     402.6841262890667
evaluation/ExplReturns Min     264.9782208255325
evaluation/Actions Mean        -0.04930083
evaluation/Actions Std         0.68047893
evaluation/Actions Max         0.99999297
evaluation/Actions Min         -0.9999804
evaluation/Num Paths           10
evaluation/Average Returns     329.07943118196454
time/data storing (s)          0.03415412735193968
time/evaluation sampling (s)   114.79628018196672
time/exploration sampling (s)  114.48197339940816
time/logging (s)               0.030484543181955814
time/saving (s)                0.01094405073672533
time/training (s)              9.567313176579773
time/epoch (s)                 238.92114947922528
time/total (s)                 17355.659243560396
Epoch                          73
-----------------------------  --------------------
2023-07-31 22:47:19.279421 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 74 finished
-----------------------------  ---------------------
replay_buffer/size             376000
trainer/tdrp Loss              [3872.8857]
trainer/QF1 Loss               0.14272669
trainer/QF2 Loss               0.14580864
trainer/Policy Loss            -50.573277
trainer/Q1 Predictions Mean    61.25611
trainer/Q1 Predictions Std     3.579234
trainer/Q1 Predictions Max     67.258354
trainer/Q1 Predictions Min     47.76469
trainer/Q2 Predictions Mean    61.171078
trainer/Q2 Predictions Std     3.5646064
trainer/Q2 Predictions Max     67.03323
trainer/Q2 Predictions Min     47.578274
trainer/Q Targets Mean         61.17994
trainer/Q Targets Std          3.5877013
trainer/Q Targets Max          67.316696
trainer/Q Targets Min          47.604183
trainer/Log Pis Mean           10.75119
trainer/Log Pis Std            7.0052915
trainer/Log Pis Max            31.382961
trainer/Log Pis Min            -8.11532
trainer/Policy mu Mean         -0.11708838
trainer/Policy mu Std          1.6945509
trainer/Policy mu Max          4.6494546
trainer/Policy mu Min          -5.0852623
trainer/Policy log std Mean    -0.36930194
trainer/Policy log std Std     0.12962843
trainer/Policy log std Max     0.19486254
trainer/Policy log std Min     -0.760099
trainer/Alpha                  0.0032497101929038763
trainer/Alpha Loss             -7.154592037200928
exploration/num steps total    376000
exploration/num paths total    752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7079852096690288
exploration/Rewards Std        0.08759957802722948
exploration/Rewards Max        0.9788540085813289
exploration/Rewards Min        0.41253475910825826
exploration/Returns Mean       353.9926048345143
exploration/Returns Std        18.33049393242963
exploration/Returns Max        390.87972111015836
exploration/Returns Min        330.88885376204087
exploration/Actions Mean       -0.013198823
exploration/Actions Std        0.71688837
exploration/Actions Max        0.9999839
exploration/Actions Min        -0.99990267
exploration/Num Paths          10
exploration/Average Returns    353.9926048345143
evaluation/num steps total     375000
evaluation/num paths total     750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7153911587233833
evaluation/Rewards Std         0.08772273528969599
evaluation/Rewards Max         0.9744677928164661
evaluation/Rewards Min         0.5046973478499479
evaluation/Returns Mean        357.6955793616917
evaluation/Returns Std         24.950704405172228
evaluation/Returns Max         405.58440788645487
evaluation/Returns Min         325.2647091346289
evaluation/ExplReturns Mean    357.6955793616917
evaluation/ExplReturns Std     24.950704405172228
evaluation/ExplReturns Max     405.58440788645487
evaluation/ExplReturns Min     325.2647091346289
evaluation/Actions Mean        0.008885006
evaluation/Actions Std         0.6133671
evaluation/Actions Max         0.9996659
evaluation/Actions Min         -0.9997389
evaluation/Num Paths           10
evaluation/Average Returns     357.6955793616917
time/data storing (s)          0.034154425375163555
time/evaluation sampling (s)   112.8188487617299
time/exploration sampling (s)  113.35265049804002
time/logging (s)               0.0305476076900959
time/saving (s)                0.010315182618796825
time/training (s)              9.255677565000951
time/epoch (s)                 235.50219404045492
time/total (s)                 17591.16392549593
Epoch                          74
-----------------------------  ---------------------
2023-07-31 22:51:14.766310 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 75 finished
-----------------------------  --------------------
replay_buffer/size             381000
trainer/tdrp Loss              [4255.593]
trainer/QF1 Loss               0.1183149
trainer/QF2 Loss               0.106690064
trainer/Policy Loss            -48.037834
trainer/Q1 Predictions Mean    60.81957
trainer/Q1 Predictions Std     4.285987
trainer/Q1 Predictions Max     67.96808
trainer/Q1 Predictions Min     41.310253
trainer/Q2 Predictions Mean    60.87734
trainer/Q2 Predictions Std     4.2628574
trainer/Q2 Predictions Max     67.99685
trainer/Q2 Predictions Min     41.50896
trainer/Q Targets Mean         60.873516
trainer/Q Targets Std          4.29394
trainer/Q Targets Max          68.27319
trainer/Q Targets Min          41.403904
trainer/Log Pis Mean           12.960554
trainer/Log Pis Std            7.6124434
trainer/Log Pis Max            38.055603
trainer/Log Pis Min            -7.1745934
trainer/Policy mu Mean         -0.23509598
trainer/Policy mu Std          1.7519025
trainer/Policy mu Max          5.733232
trainer/Policy mu Min          -4.6831207
trainer/Policy log std Mean    -0.38898048
trainer/Policy log std Std     0.120232105
trainer/Policy log std Max     0.053152084
trainer/Policy log std Min     -0.8039056
trainer/Alpha                  0.003220821963623166
trainer/Alpha Loss             5.511697292327881
exploration/num steps total    381000
exploration/num paths total    762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7622764575641641
exploration/Rewards Std        0.1181082268785069
exploration/Rewards Max        0.9797726399792075
exploration/Rewards Min        0.4703609191138699
exploration/Returns Mean       381.13822878208185
exploration/Returns Std        22.819200042310577
exploration/Returns Max        405.25437341651116
exploration/Returns Min        347.24407824148426
exploration/Actions Mean       -0.016520502
exploration/Actions Std        0.7008266
exploration/Actions Max        0.9999594
exploration/Actions Min        -0.9999569
exploration/Num Paths          10
exploration/Average Returns    381.13822878208185
evaluation/num steps total     380000
evaluation/num paths total     760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7498003042276066
evaluation/Rewards Std         0.12309399138224757
evaluation/Rewards Max         0.9783816897910376
evaluation/Rewards Min         0.44713951852264544
evaluation/Returns Mean        374.9001521138033
evaluation/Returns Std         17.250094436189098
evaluation/Returns Max         404.73531302997
evaluation/Returns Min         343.8918839924035
evaluation/ExplReturns Mean    374.9001521138033
evaluation/ExplReturns Std     17.250094436189098
evaluation/ExplReturns Max     404.73531302997
evaluation/ExplReturns Min     343.8918839924035
evaluation/Actions Mean        -0.0048168222
evaluation/Actions Std         0.6308671
evaluation/Actions Max         0.99976224
evaluation/Actions Min         -0.99970126
evaluation/Num Paths           10
evaluation/Average Returns     374.9001521138033
time/data storing (s)          0.033612980507314205
time/evaluation sampling (s)   112.85891400836408
time/exploration sampling (s)  113.13753760047257
time/logging (s)               0.03035846631973982
time/saving (s)                0.010259455069899559
time/training (s)              9.412364966236055
time/epoch (s)                 235.48304747696966
time/total (s)                 17826.649495462887
Epoch                          75
-----------------------------  --------------------
2023-07-31 22:55:08.144329 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 76 finished
-----------------------------  ---------------------
replay_buffer/size             386000
trainer/tdrp Loss              [3976.9944]
trainer/QF1 Loss               0.10181111
trainer/QF2 Loss               0.10520233
trainer/Policy Loss            -49.084576
trainer/Q1 Predictions Mean    61.60914
trainer/Q1 Predictions Std     3.627852
trainer/Q1 Predictions Max     67.874825
trainer/Q1 Predictions Min     46.77224
trainer/Q2 Predictions Mean    61.558937
trainer/Q2 Predictions Std     3.6308122
trainer/Q2 Predictions Max     67.58423
trainer/Q2 Predictions Min     46.780853
trainer/Q Targets Mean         61.570515
trainer/Q Targets Std          3.665469
trainer/Q Targets Max          68.47848
trainer/Q Targets Min          46.600075
trainer/Log Pis Mean           12.6205015
trainer/Log Pis Std            7.8318415
trainer/Log Pis Max            32.84813
trainer/Log Pis Min            -11.58477
trainer/Policy mu Mean         -0.043649822
trainer/Policy mu Std          1.7783508
trainer/Policy mu Max          5.8308697
trainer/Policy mu Min          -4.272374
trainer/Policy log std Mean    -0.3711418
trainer/Policy log std Std     0.1281649
trainer/Policy log std Max     0.13517931
trainer/Policy log std Min     -0.8296758
trainer/Alpha                  0.0033171724062412977
trainer/Alpha Loss             3.5423734188079834
exploration/num steps total    386000
exploration/num paths total    772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6950521229569937
exploration/Rewards Std        0.05836927083552841
exploration/Rewards Max        0.9589347198963035
exploration/Rewards Min        0.5027205244306205
exploration/Returns Mean       347.52606147849684
exploration/Returns Std        4.617774005764989
exploration/Returns Max        354.2287564040513
exploration/Returns Min        340.437193796
exploration/Actions Mean       0.10310556
exploration/Actions Std        0.68447876
exploration/Actions Max        0.9999474
exploration/Actions Min        -0.9999822
exploration/Num Paths          10
exploration/Average Returns    347.52606147849684
evaluation/num steps total     385000
evaluation/num paths total     770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6971848492950077
evaluation/Rewards Std         0.05096446555987178
evaluation/Rewards Max         0.9573211452815175
evaluation/Rewards Min         0.4962972227292471
evaluation/Returns Mean        348.5924246475039
evaluation/Returns Std         6.076409145628016
evaluation/Returns Max         361.4148959124176
evaluation/Returns Min         339.8265638991308
evaluation/ExplReturns Mean    348.5924246475039
evaluation/ExplReturns Std     6.076409145628016
evaluation/ExplReturns Max     361.4148959124176
evaluation/ExplReturns Min     339.8265638991308
evaluation/Actions Mean        0.08189677
evaluation/Actions Std         0.55332345
evaluation/Actions Max         0.9989489
evaluation/Actions Min         -0.99816644
evaluation/Num Paths           10
evaluation/Average Returns     348.5924246475039
time/data storing (s)          0.033783222548663616
time/evaluation sampling (s)   112.48841706756502
time/exploration sampling (s)  111.33416768815368
time/logging (s)               0.030531945638358593
time/saving (s)                0.012552180327475071
time/training (s)              9.475133501924574
time/epoch (s)                 233.37458560615778
time/total (s)                 18060.026578127407
Epoch                          76
-----------------------------  ---------------------
2023-07-31 22:59:03.668376 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 77 finished
-----------------------------  --------------------
replay_buffer/size             391000
trainer/tdrp Loss              [4147.631]
trainer/QF1 Loss               0.12073301
trainer/QF2 Loss               0.1217278
trainer/Policy Loss            -50.263557
trainer/Q1 Predictions Mean    61.821457
trainer/Q1 Predictions Std     3.6253307
trainer/Q1 Predictions Max     68.13883
trainer/Q1 Predictions Min     42.324253
trainer/Q2 Predictions Mean    61.81763
trainer/Q2 Predictions Std     3.6203272
trainer/Q2 Predictions Max     68.07842
trainer/Q2 Predictions Min     42.37605
trainer/Q Targets Mean         61.822792
trainer/Q Targets Std          3.6329858
trainer/Q Targets Max          68.43786
trainer/Q Targets Min          42.499367
trainer/Log Pis Mean           11.714476
trainer/Log Pis Std            7.210771
trainer/Log Pis Max            41.006615
trainer/Log Pis Min            -6.4632225
trainer/Policy mu Mean         -0.10323792
trainer/Policy mu Std          1.7085453
trainer/Policy mu Max          3.9598708
trainer/Policy mu Min          -4.3709693
trainer/Policy log std Mean    -0.40151635
trainer/Policy log std Std     0.12048991
trainer/Policy log std Max     0.19729963
trainer/Policy log std Min     -0.8224137
trainer/Alpha                  0.003361466806381941
trainer/Alpha Loss             -1.626129388809204
exploration/num steps total    391000
exploration/num paths total    782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7369302303909258
exploration/Rewards Std        0.08670301730909291
exploration/Rewards Max        0.9764482782291936
exploration/Rewards Min        0.49555234504271495
exploration/Returns Mean       368.46511519546306
exploration/Returns Std        20.98885063038835
exploration/Returns Max        414.69599932366197
exploration/Returns Min        346.85499661385205
exploration/Actions Mean       0.00456444
exploration/Actions Std        0.6713346
exploration/Actions Max        0.99991095
exploration/Actions Min        -0.9999632
exploration/Num Paths          10
exploration/Average Returns    368.46511519546306
evaluation/num steps total     390000
evaluation/num paths total     780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7322063627718851
evaluation/Rewards Std         0.07718501565402645
evaluation/Rewards Max         0.9774781315822832
evaluation/Rewards Min         0.48746651768941657
evaluation/Returns Mean        366.1031813859426
evaluation/Returns Std         16.682348546751086
evaluation/Returns Max         392.3992093268898
evaluation/Returns Min         340.2616918245206
evaluation/ExplReturns Mean    366.1031813859426
evaluation/ExplReturns Std     16.682348546751086
evaluation/ExplReturns Max     392.3992093268898
evaluation/ExplReturns Min     340.2616918245206
evaluation/Actions Mean        0.018076997
evaluation/Actions Std         0.5618669
evaluation/Actions Max         0.9992403
evaluation/Actions Min         -0.99961597
evaluation/Num Paths           10
evaluation/Average Returns     366.1031813859426
time/data storing (s)          0.03405371680855751
time/evaluation sampling (s)   113.68411990720779
time/exploration sampling (s)  112.26882757619023
time/logging (s)               0.030908341519534588
time/saving (s)                0.012676950544118881
time/training (s)              9.490173120982945
time/epoch (s)                 235.52075961325318
time/total (s)                 18295.54984847363
Epoch                          77
-----------------------------  --------------------
2023-07-31 23:02:58.042293 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 78 finished
-----------------------------  --------------------
replay_buffer/size             396000
trainer/tdrp Loss              [4105.086]
trainer/QF1 Loss               0.10530114
trainer/QF2 Loss               0.11310228
trainer/Policy Loss            -49.85495
trainer/Q1 Predictions Mean    62.04775
trainer/Q1 Predictions Std     3.655031
trainer/Q1 Predictions Max     68.48545
trainer/Q1 Predictions Min     49.91907
trainer/Q2 Predictions Mean    62.041714
trainer/Q2 Predictions Std     3.6776645
trainer/Q2 Predictions Max     68.54411
trainer/Q2 Predictions Min     49.827896
trainer/Q Targets Mean         62.081047
trainer/Q Targets Std          3.6844642
trainer/Q Targets Max          68.546364
trainer/Q Targets Min          49.915703
trainer/Log Pis Mean           12.35685
trainer/Log Pis Std            7.515808
trainer/Log Pis Max            33.421043
trainer/Log Pis Min            -6.518673
trainer/Policy mu Mean         -0.13854925
trainer/Policy mu Std          1.7306993
trainer/Policy mu Max          4.8232355
trainer/Policy mu Min          -4.4502006
trainer/Policy log std Mean    -0.401824
trainer/Policy log std Std     0.11448562
trainer/Policy log std Max     0.14213425
trainer/Policy log std Min     -0.8012206
trainer/Alpha                  0.003208145732060075
trainer/Alpha Loss             2.0490596294403076
exploration/num steps total    396000
exploration/num paths total    792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7126224637715393
exploration/Rewards Std        0.08356805399827318
exploration/Rewards Max        0.9777049502462751
exploration/Rewards Min        0.48472420631128826
exploration/Returns Mean       356.31123188576964
exploration/Returns Std        18.639850177808206
exploration/Returns Max        403.86797991243515
exploration/Returns Min        337.8997276302524
exploration/Actions Mean       -0.0121826185
exploration/Actions Std        0.6888498
exploration/Actions Max        0.9999802
exploration/Actions Min        -0.9999228
exploration/Num Paths          10
exploration/Average Returns    356.31123188576964
evaluation/num steps total     395000
evaluation/num paths total     790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7258591595777961
evaluation/Rewards Std         0.08097778825007952
evaluation/Rewards Max         0.9721521899051022
evaluation/Rewards Min         0.4868686152350885
evaluation/Returns Mean        362.92957978889797
evaluation/Returns Std         22.683229244875864
evaluation/Returns Max         403.39819780419094
evaluation/Returns Min         335.40685778888394
evaluation/ExplReturns Mean    362.92957978889797
evaluation/ExplReturns Std     22.683229244875864
evaluation/ExplReturns Max     403.39819780419094
evaluation/ExplReturns Min     335.40685778888394
evaluation/Actions Mean        -0.02157626
evaluation/Actions Std         0.6619295
evaluation/Actions Max         0.99928457
evaluation/Actions Min         -0.99905753
evaluation/Num Paths           10
evaluation/Average Returns     362.92957978889797
time/data storing (s)          0.03395621385425329
time/evaluation sampling (s)   112.22848705668002
time/exploration sampling (s)  112.55707039218396
time/logging (s)               0.030557836405932903
time/saving (s)                0.011918825097382069
time/training (s)              9.507924750447273
time/epoch (s)                 234.36991507466882
time/total (s)                 18529.922254664823
Epoch                          78
-----------------------------  --------------------
2023-07-31 23:06:52.841388 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 79 finished
-----------------------------  ---------------------
replay_buffer/size             401000
trainer/tdrp Loss              [4175.673]
trainer/QF1 Loss               0.13051024
trainer/QF2 Loss               0.113799214
trainer/Policy Loss            -51.18656
trainer/Q1 Predictions Mean    61.902954
trainer/Q1 Predictions Std     4.378399
trainer/Q1 Predictions Max     68.728874
trainer/Q1 Predictions Min     39.684708
trainer/Q2 Predictions Mean    61.951588
trainer/Q2 Predictions Std     4.39346
trainer/Q2 Predictions Max     68.91051
trainer/Q2 Predictions Min     39.80671
trainer/Q Targets Mean         62.08761
trainer/Q Targets Std          4.3671627
trainer/Q Targets Max          69.10904
trainer/Q Targets Min          39.377037
trainer/Log Pis Mean           10.884979
trainer/Log Pis Std            6.8694696
trainer/Log Pis Max            36.713913
trainer/Log Pis Min            -9.58502
trainer/Policy mu Mean         -0.23413873
trainer/Policy mu Std          1.6554371
trainer/Policy mu Max          4.630054
trainer/Policy mu Min          -4.7265697
trainer/Policy log std Mean    -0.40777445
trainer/Policy log std Std     0.116270356
trainer/Policy log std Max     0.030325025
trainer/Policy log std Min     -0.7983875
trainer/Alpha                  0.0032159248366951942
trainer/Alpha Loss             -6.399630069732666
exploration/num steps total    401000
exploration/num paths total    802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8191524374847357
exploration/Rewards Std        0.13885353290465752
exploration/Rewards Max        0.9793214325660371
exploration/Rewards Min        0.497362982314957
exploration/Returns Mean       409.57621874236787
exploration/Returns Std        44.217433141043564
exploration/Returns Max        447.3176170433344
exploration/Returns Min        337.21935749650186
exploration/Actions Mean       -0.01628585
exploration/Actions Std        0.69860846
exploration/Actions Max        0.9998866
exploration/Actions Min        -0.999953
exploration/Num Paths          10
exploration/Average Returns    409.57621874236787
evaluation/num steps total     400000
evaluation/num paths total     800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7174151657336317
evaluation/Rewards Std         0.10159242571130613
evaluation/Rewards Max         0.9754256524751824
evaluation/Rewards Min         0.4015014065031163
evaluation/Returns Mean        358.7075828668161
evaluation/Returns Std         27.41190147005282
evaluation/Returns Max         399.2552679293108
evaluation/Returns Min         329.5963448538572
evaluation/ExplReturns Mean    358.7075828668161
evaluation/ExplReturns Std     27.41190147005282
evaluation/ExplReturns Max     399.2552679293108
evaluation/ExplReturns Min     329.5963448538572
evaluation/Actions Mean        -0.022117116
evaluation/Actions Std         0.6517733
evaluation/Actions Max         0.9998916
evaluation/Actions Min         -0.99976754
evaluation/Num Paths           10
evaluation/Average Returns     358.7075828668161
time/data storing (s)          0.03414168581366539
time/evaluation sampling (s)   112.4404619820416
time/exploration sampling (s)  112.79109152685851
time/logging (s)               0.03027976118028164
time/saving (s)                0.012230336666107178
time/training (s)              9.486756772734225
time/epoch (s)                 234.79496206529438
time/total (s)                 18764.71991097182
Epoch                          79
-----------------------------  ---------------------
2023-07-31 23:10:48.822053 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 80 finished
-----------------------------  ---------------------
replay_buffer/size             406000
trainer/tdrp Loss              [3993.9214]
trainer/QF1 Loss               0.15723732
trainer/QF2 Loss               0.12600961
trainer/Policy Loss            -51.59458
trainer/Q1 Predictions Mean    62.751537
trainer/Q1 Predictions Std     4.1163445
trainer/Q1 Predictions Max     69.85263
trainer/Q1 Predictions Min     43.84868
trainer/Q2 Predictions Mean    62.75125
trainer/Q2 Predictions Std     4.096199
trainer/Q2 Predictions Max     70.09344
trainer/Q2 Predictions Min     44.16253
trainer/Q Targets Mean         62.691788
trainer/Q Targets Std          4.12331
trainer/Q Targets Max          69.8709
trainer/Q Targets Min          44.29969
trainer/Log Pis Mean           11.32904
trainer/Log Pis Std            7.294122
trainer/Log Pis Max            35.35466
trainer/Log Pis Min            -6.7814918
trainer/Policy mu Mean         -0.11529652
trainer/Policy mu Std          1.6831138
trainer/Policy mu Max          4.9211035
trainer/Policy mu Min          -4.1008024
trainer/Policy log std Mean    -0.39698827
trainer/Policy log std Std     0.114589915
trainer/Policy log std Max     0.11437163
trainer/Policy log std Min     -0.7428982
trainer/Alpha                  0.0031968913972377777
trainer/Alpha Loss             -3.854984998703003
exploration/num steps total    406000
exploration/num paths total    812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6968364209213105
exploration/Rewards Std        0.05558706281127113
exploration/Rewards Max        0.9736973376068399
exploration/Rewards Min        0.44893812763675306
exploration/Returns Mean       348.41821046065513
exploration/Returns Std        11.682796027476803
exploration/Returns Max        368.65754620905716
exploration/Returns Min        325.8600364570159
exploration/Actions Mean       -0.013597101
exploration/Actions Std        0.68494594
exploration/Actions Max        0.9999279
exploration/Actions Min        -0.99988997
exploration/Num Paths          10
exploration/Average Returns    348.41821046065513
evaluation/num steps total     405000
evaluation/num paths total     810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6987647073066974
evaluation/Rewards Std         0.06491638366605859
evaluation/Rewards Max         0.9737029283014631
evaluation/Rewards Min         0.4172168590781496
evaluation/Returns Mean        349.3823536533486
evaluation/Returns Std         14.402966745871744
evaluation/Returns Max         376.3918315171281
evaluation/Returns Min         320.65488451035384
evaluation/ExplReturns Mean    349.3823536533486
evaluation/ExplReturns Std     14.402966745871744
evaluation/ExplReturns Max     376.3918315171281
evaluation/ExplReturns Min     320.65488451035384
evaluation/Actions Mean        0.013333837
evaluation/Actions Std         0.6162859
evaluation/Actions Max         0.9982778
evaluation/Actions Min         -0.99882656
evaluation/Num Paths           10
evaluation/Average Returns     349.3823536533486
time/data storing (s)          0.034326652996242046
time/evaluation sampling (s)   112.99366436898708
time/exploration sampling (s)  113.43898759689182
time/logging (s)               0.03054596297442913
time/saving (s)                0.011978337541222572
time/training (s)              9.467786858789623
time/epoch (s)                 235.97728977818042
time/total (s)                 19000.699677283876
Epoch                          80
-----------------------------  ---------------------
2023-07-31 23:14:43.009400 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 81 finished
-----------------------------  --------------------
replay_buffer/size             411000
trainer/tdrp Loss              [3971.594]
trainer/QF1 Loss               0.12827289
trainer/QF2 Loss               0.13809064
trainer/Policy Loss            -51.09509
trainer/Q1 Predictions Mean    62.686455
trainer/Q1 Predictions Std     3.9962862
trainer/Q1 Predictions Max     69.57014
trainer/Q1 Predictions Min     47.130936
trainer/Q2 Predictions Mean    62.758724
trainer/Q2 Predictions Std     3.9717073
trainer/Q2 Predictions Max     69.866104
trainer/Q2 Predictions Min     47.172077
trainer/Q Targets Mean         62.61831
trainer/Q Targets Std          4.020561
trainer/Q Targets Max          69.95296
trainer/Q Targets Min          47.307518
trainer/Log Pis Mean           11.769454
trainer/Log Pis Std            7.8924665
trainer/Log Pis Max            35.58244
trainer/Log Pis Min            -12.993303
trainer/Policy mu Mean         -0.14253327
trainer/Policy mu Std          1.6943115
trainer/Policy mu Max          4.603806
trainer/Policy mu Min          -4.787099
trainer/Policy log std Mean    -0.41124383
trainer/Policy log std Std     0.11527119
trainer/Policy log std Max     0.13932335
trainer/Policy log std Min     -0.80869114
trainer/Alpha                  0.003261531936004758
trainer/Alpha Loss             -1.3199869394302368
exploration/num steps total    411000
exploration/num paths total    822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6870378589883792
exploration/Rewards Std        0.04921336296625621
exploration/Rewards Max        0.9602784273524109
exploration/Rewards Min        0.3210074740073064
exploration/Returns Mean       343.51892949418954
exploration/Returns Std        5.691787850789001
exploration/Returns Max        353.27027170267206
exploration/Returns Min        335.75573753543785
exploration/Actions Mean       -0.005407169
exploration/Actions Std        0.6652687
exploration/Actions Max        0.999938
exploration/Actions Min        -0.99995464
exploration/Num Paths          10
exploration/Average Returns    343.51892949418954
evaluation/num steps total     410000
evaluation/num paths total     820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7007626382924698
evaluation/Rewards Std         0.04572957126973761
evaluation/Rewards Max         0.9725017468195178
evaluation/Rewards Min         0.49785963254703874
evaluation/Returns Mean        350.3813191462349
evaluation/Returns Std         4.777073307193767
evaluation/Returns Max         356.81559427730343
evaluation/Returns Min         340.09174824214455
evaluation/ExplReturns Mean    350.3813191462349
evaluation/ExplReturns Std     4.777073307193767
evaluation/ExplReturns Max     356.81559427730343
evaluation/ExplReturns Min     340.09174824214455
evaluation/Actions Mean        0.023037208
evaluation/Actions Std         0.45713064
evaluation/Actions Max         0.99813265
evaluation/Actions Min         -0.9990984
evaluation/Num Paths           10
evaluation/Average Returns     350.3813191462349
time/data storing (s)          0.03419629670679569
time/evaluation sampling (s)   112.19716622401029
time/exploration sampling (s)  112.7944680582732
time/logging (s)               0.03070787899196148
time/saving (s)                0.011065573431551456
time/training (s)              9.116297158412635
time/epoch (s)                 234.18390118982643
time/total (s)                 19234.886014794
Epoch                          81
-----------------------------  --------------------
2023-07-31 23:18:37.846429 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 82 finished
-----------------------------  --------------------
replay_buffer/size             416000
trainer/tdrp Loss              [3897.4443]
trainer/QF1 Loss               0.1324761
trainer/QF2 Loss               0.12743531
trainer/Policy Loss            -50.740135
trainer/Q1 Predictions Mean    62.898617
trainer/Q1 Predictions Std     3.7707849
trainer/Q1 Predictions Max     70.73058
trainer/Q1 Predictions Min     47.20218
trainer/Q2 Predictions Mean    62.943985
trainer/Q2 Predictions Std     3.784292
trainer/Q2 Predictions Max     70.756226
trainer/Q2 Predictions Min     47.08904
trainer/Q Targets Mean         62.788857
trainer/Q Targets Std          3.7835991
trainer/Q Targets Max          70.72073
trainer/Q Targets Min          47.307987
trainer/Log Pis Mean           12.361847
trainer/Log Pis Std            7.577345
trainer/Log Pis Max            36.951527
trainer/Log Pis Min            -5.6173825
trainer/Policy mu Mean         -0.16525249
trainer/Policy mu Std          1.7217518
trainer/Policy mu Max          4.4294844
trainer/Policy mu Min          -4.602134
trainer/Policy log std Mean    -0.42342603
trainer/Policy log std Std     0.112230204
trainer/Policy log std Max     -0.013791099
trainer/Policy log std Min     -0.8344162
trainer/Alpha                  0.003217461984604597
trainer/Alpha Loss             2.0767593383789062
exploration/num steps total    416000
exploration/num paths total    832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6976021001540846
exploration/Rewards Std        0.0895663990199173
exploration/Rewards Max        0.9776820504294325
exploration/Rewards Min        0.5038074984640574
exploration/Returns Mean       348.80105007704253
exploration/Returns Std        24.4728875435916
exploration/Returns Max        406.17455966222286
exploration/Returns Min        329.6106724059138
exploration/Actions Mean       -0.06806922
exploration/Actions Std        0.6819399
exploration/Actions Max        0.9997699
exploration/Actions Min        -0.99996704
exploration/Num Paths          10
exploration/Average Returns    348.80105007704253
evaluation/num steps total     415000
evaluation/num paths total     830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7314141443974544
evaluation/Rewards Std         0.12032301327020392
evaluation/Rewards Max         0.9754513168389747
evaluation/Rewards Min         0.4825002019721054
evaluation/Returns Mean        365.7070721987272
evaluation/Returns Std         43.05933432640779
evaluation/Returns Max         436.604356974191
evaluation/Returns Min         331.9815025638794
evaluation/ExplReturns Mean    365.7070721987272
evaluation/ExplReturns Std     43.05933432640779
evaluation/ExplReturns Max     436.604356974191
evaluation/ExplReturns Min     331.9815025638794
evaluation/Actions Mean        -0.04900641
evaluation/Actions Std         0.60294056
evaluation/Actions Max         0.99989206
evaluation/Actions Min         -0.99976254
evaluation/Num Paths           10
evaluation/Average Returns     365.7070721987272
time/data storing (s)          0.034272393211722374
time/evaluation sampling (s)   112.55685175396502
time/exploration sampling (s)  112.7131920196116
time/logging (s)               0.030584514141082764
time/saving (s)                0.012764723040163517
time/training (s)              9.485604358837008
time/epoch (s)                 234.8332697628066
time/total (s)                 19469.721744241193
Epoch                          82
-----------------------------  --------------------
2023-07-31 23:22:32.157953 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 83 finished
-----------------------------  --------------------
replay_buffer/size             421000
trainer/tdrp Loss              [3992.5806]
trainer/QF1 Loss               0.1312331
trainer/QF2 Loss               0.12834
trainer/Policy Loss            -52.22853
trainer/Q1 Predictions Mean    63.566353
trainer/Q1 Predictions Std     4.245317
trainer/Q1 Predictions Max     71.642204
trainer/Q1 Predictions Min     44.177307
trainer/Q2 Predictions Mean    63.544228
trainer/Q2 Predictions Std     4.229849
trainer/Q2 Predictions Max     71.51055
trainer/Q2 Predictions Min     44.351982
trainer/Q Targets Mean         63.430447
trainer/Q Targets Std          4.2456603
trainer/Q Targets Max          71.71851
trainer/Q Targets Min          44.31115
trainer/Log Pis Mean           11.482294
trainer/Log Pis Std            7.537772
trainer/Log Pis Max            34.76061
trainer/Log Pis Min            -6.6084065
trainer/Policy mu Mean         -0.12518209
trainer/Policy mu Std          1.6880459
trainer/Policy mu Max          4.5735188
trainer/Policy mu Min          -5.369773
trainer/Policy log std Mean    -0.41158167
trainer/Policy log std Std     0.11851306
trainer/Policy log std Max     -0.0018073134
trainer/Policy log std Min     -0.8043953
trainer/Alpha                  0.003209013259038329
trainer/Alpha Loss             -2.9724488258361816
exploration/num steps total    421000
exploration/num paths total    842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6927332907856065
exploration/Rewards Std        0.06277745226240074
exploration/Rewards Max        0.9710190547718227
exploration/Rewards Min        0.46645457707181487
exploration/Returns Mean       346.3666453928032
exploration/Returns Std        11.83681556253937
exploration/Returns Max        376.96580879033377
exploration/Returns Min        334.024662949048
exploration/Actions Mean       -0.013285311
exploration/Actions Std        0.7085959
exploration/Actions Max        0.999855
exploration/Actions Min        -0.99995553
exploration/Num Paths          10
exploration/Average Returns    346.3666453928032
evaluation/num steps total     420000
evaluation/num paths total     840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7043679610794059
evaluation/Rewards Std         0.06262943391355888
evaluation/Rewards Max         0.9698435068437775
evaluation/Rewards Min         0.4957568839370985
evaluation/Returns Mean        352.1839805397031
evaluation/Returns Std         14.688158144620763
evaluation/Returns Max         375.931909958161
evaluation/Returns Min         333.1789099183683
evaluation/ExplReturns Mean    352.1839805397031
evaluation/ExplReturns Std     14.688158144620763
evaluation/ExplReturns Max     375.931909958161
evaluation/ExplReturns Min     333.1789099183683
evaluation/Actions Mean        -0.043896876
evaluation/Actions Std         0.65780604
evaluation/Actions Max         0.9990917
evaluation/Actions Min         -0.9999209
evaluation/Num Paths           10
evaluation/Average Returns     352.1839805397031
time/data storing (s)          0.03432757779955864
time/evaluation sampling (s)   112.33889913093299
time/exploration sampling (s)  112.36668914742768
time/logging (s)               0.03051850851625204
time/saving (s)                0.011971980333328247
time/training (s)              9.525301423855126
time/epoch (s)                 234.30770776886493
time/total (s)                 19704.031988146715
Epoch                          83
-----------------------------  --------------------
2023-07-31 23:26:22.617549 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 84 finished
-----------------------------  ---------------------
replay_buffer/size             426000
trainer/tdrp Loss              [3824.101]
trainer/QF1 Loss               0.113514856
trainer/QF2 Loss               0.10214968
trainer/Policy Loss            -50.87386
trainer/Q1 Predictions Mean    63.20755
trainer/Q1 Predictions Std     4.3711553
trainer/Q1 Predictions Max     71.43802
trainer/Q1 Predictions Min     44.324314
trainer/Q2 Predictions Mean    63.273357
trainer/Q2 Predictions Std     4.391822
trainer/Q2 Predictions Max     71.65592
trainer/Q2 Predictions Min     44.133373
trainer/Q Targets Mean         63.33224
trainer/Q Targets Std          4.379234
trainer/Q Targets Max          71.79137
trainer/Q Targets Min          44.518528
trainer/Log Pis Mean           12.544534
trainer/Log Pis Std            7.294576
trainer/Log Pis Max            43.95415
trainer/Log Pis Min            -5.5045977
trainer/Policy mu Mean         -0.014570765
trainer/Policy mu Std          1.7622559
trainer/Policy mu Max          5.600425
trainer/Policy mu Min          -4.8304777
trainer/Policy log std Mean    -0.4233967
trainer/Policy log std Std     0.116151504
trainer/Policy log std Max     0.17169791
trainer/Policy log std Min     -0.7758372
trainer/Alpha                  0.0031854528933763504
trainer/Alpha Loss             3.1308603286743164
exploration/num steps total    426000
exploration/num paths total    852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6941435615764993
exploration/Rewards Std        0.03695596377881045
exploration/Rewards Max        0.9637688149015324
exploration/Rewards Min        0.4843500529013393
exploration/Returns Mean       347.0717807882496
exploration/Returns Std        5.661886217663263
exploration/Returns Max        357.68945096623764
exploration/Returns Min        341.7929621741728
exploration/Actions Mean       0.032471463
exploration/Actions Std        0.66076523
exploration/Actions Max        0.99974567
exploration/Actions Min        -0.9996963
exploration/Num Paths          10
exploration/Average Returns    347.0717807882496
evaluation/num steps total     425000
evaluation/num paths total     850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7033474010162389
evaluation/Rewards Std         0.08968236176747858
evaluation/Rewards Max         0.9724534284895419
evaluation/Rewards Min         0.4320081882867022
evaluation/Returns Mean        351.67370050811945
evaluation/Returns Std         32.35226289970667
evaluation/Returns Max         444.5881938004117
evaluation/Returns Min         323.7199781003496
evaluation/ExplReturns Mean    351.67370050811945
evaluation/ExplReturns Std     32.35226289970667
evaluation/ExplReturns Max     444.5881938004117
evaluation/ExplReturns Min     323.7199781003496
evaluation/Actions Mean        0.030322596
evaluation/Actions Std         0.558251
evaluation/Actions Max         0.99966
evaluation/Actions Min         -0.9994637
evaluation/Num Paths           10
evaluation/Average Returns     351.67370050811945
time/data storing (s)          0.033994720317423344
time/evaluation sampling (s)   110.46669598668814
time/exploration sampling (s)  110.66477348655462
time/logging (s)               0.030549238435924053
time/saving (s)                0.010306883603334427
time/training (s)              9.249529976397753
time/epoch (s)                 230.4558502919972
time/total (s)                 19934.490410859697
Epoch                          84
-----------------------------  ---------------------
2023-07-31 23:30:12.763325 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 85 finished
-----------------------------  --------------------
replay_buffer/size             431000
trainer/tdrp Loss              [4085.3667]
trainer/QF1 Loss               0.13273929
trainer/QF2 Loss               0.10385552
trainer/Policy Loss            -51.804947
trainer/Q1 Predictions Mean    64.28643
trainer/Q1 Predictions Std     4.3725924
trainer/Q1 Predictions Max     72.0277
trainer/Q1 Predictions Min     47.590717
trainer/Q2 Predictions Mean    64.26384
trainer/Q2 Predictions Std     4.3976774
trainer/Q2 Predictions Max     72.069374
trainer/Q2 Predictions Min     47.001324
trainer/Q Targets Mean         64.23679
trainer/Q Targets Std          4.4122415
trainer/Q Targets Max          72.29713
trainer/Q Targets Min          46.84184
trainer/Log Pis Mean           12.604657
trainer/Log Pis Std            7.0517945
trainer/Log Pis Max            37.103733
trainer/Log Pis Min            -7.5139246
trainer/Policy mu Mean         -0.09096557
trainer/Policy mu Std          1.7198148
trainer/Policy mu Max          4.57248
trainer/Policy mu Min          -4.7210674
trainer/Policy log std Mean    -0.4389535
trainer/Policy log std Std     0.11124075
trainer/Policy log std Max     0.14204776
trainer/Policy log std Min     -0.8335736
trainer/Alpha                  0.003176721977069974
trainer/Alpha Loss             3.4780445098876953
exploration/num steps total    431000
exploration/num paths total    862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6831785928015637
exploration/Rewards Std        0.044439444147177876
exploration/Rewards Max        0.9622658747294764
exploration/Rewards Min        0.48799872134661204
exploration/Returns Mean       341.58929640078185
exploration/Returns Std        11.259043139863254
exploration/Returns Max        367.49548769229597
exploration/Returns Min        327.46803739845336
exploration/Actions Mean       -0.018493075
exploration/Actions Std        0.659204
exploration/Actions Max        0.9998741
exploration/Actions Min        -0.9998451
exploration/Num Paths          10
exploration/Average Returns    341.58929640078185
evaluation/num steps total     430000
evaluation/num paths total     860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7567694118827594
evaluation/Rewards Std         0.12594349897800663
evaluation/Rewards Max         0.9667424035541308
evaluation/Rewards Min         0.4990485180529751
evaluation/Returns Mean        378.3847059413797
evaluation/Returns Std         52.62578182536025
evaluation/Returns Max         453.82769093362043
evaluation/Returns Min         332.61951838116
evaluation/ExplReturns Mean    378.3847059413797
evaluation/ExplReturns Std     52.62578182536025
evaluation/ExplReturns Max     453.82769093362043
evaluation/ExplReturns Min     332.61951838116
evaluation/Actions Mean        -0.031469144
evaluation/Actions Std         0.5294046
evaluation/Actions Max         0.99729943
evaluation/Actions Min         -0.9967058
evaluation/Num Paths           10
evaluation/Average Returns     378.3847059413797
time/data storing (s)          0.03428172692656517
time/evaluation sampling (s)   110.45614053867757
time/exploration sampling (s)  110.12481545750052
time/logging (s)               0.03044978342950344
time/saving (s)                0.012545828707516193
time/training (s)              9.483779254369438
time/epoch (s)                 230.1420125896111
time/total (s)                 20164.634894688614
Epoch                          85
-----------------------------  --------------------
2023-07-31 23:34:03.286971 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 86 finished
-----------------------------  ---------------------
replay_buffer/size             436000
trainer/tdrp Loss              [4041.9895]
trainer/QF1 Loss               0.15060233
trainer/QF2 Loss               0.13810688
trainer/Policy Loss            -52.19146
trainer/Q1 Predictions Mean    63.950813
trainer/Q1 Predictions Std     4.3815885
trainer/Q1 Predictions Max     72.34035
trainer/Q1 Predictions Min     45.922653
trainer/Q2 Predictions Mean    63.81327
trainer/Q2 Predictions Std     4.3655295
trainer/Q2 Predictions Max     72.085785
trainer/Q2 Predictions Min     45.583107
trainer/Q Targets Mean         63.91029
trainer/Q Targets Std          4.3895755
trainer/Q Targets Max          72.6714
trainer/Q Targets Min          45.76637
trainer/Log Pis Mean           11.857883
trainer/Log Pis Std            7.7715454
trainer/Log Pis Max            43.185646
trainer/Log Pis Min            -6.3788023
trainer/Policy mu Mean         -0.0496723
trainer/Policy mu Std          1.7179861
trainer/Policy mu Max          4.7517443
trainer/Policy mu Min          -4.04576
trainer/Policy log std Mean    -0.44105282
trainer/Policy log std Std     0.11145923
trainer/Policy log std Max     0.05848673
trainer/Policy log std Min     -0.85484254
trainer/Alpha                  0.0032094402704387903
trainer/Alpha Loss             -0.8159881830215454
exploration/num steps total    436000
exploration/num paths total    872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6906819734363067
exploration/Rewards Std        0.043429346808109164
exploration/Rewards Max        0.9531489897025699
exploration/Rewards Min        0.45445501346510286
exploration/Returns Mean       345.3409867181534
exploration/Returns Std        8.707031372690407
exploration/Returns Max        370.61874831645275
exploration/Returns Min        339.31035484468504
exploration/Actions Mean       0.030638255
exploration/Actions Std        0.6645306
exploration/Actions Max        0.99986404
exploration/Actions Min        -0.99990773
exploration/Num Paths          10
exploration/Average Returns    345.3409867181534
evaluation/num steps total     435000
evaluation/num paths total     870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7122011254928878
evaluation/Rewards Std         0.07269066304667317
evaluation/Rewards Max         0.9547528631181598
evaluation/Rewards Min         0.4085601785815405
evaluation/Returns Mean        356.100562746444
evaluation/Returns Std         29.28472319566251
evaluation/Returns Max         443.90649344092105
evaluation/Returns Min         344.6142929500185
evaluation/ExplReturns Mean    356.100562746444
evaluation/ExplReturns Std     29.28472319566251
evaluation/ExplReturns Max     443.90649344092105
evaluation/ExplReturns Min     344.6142929500185
evaluation/Actions Mean        0.04590489
evaluation/Actions Std         0.53922546
evaluation/Actions Max         0.9989109
evaluation/Actions Min         -0.9960295
evaluation/Num Paths           10
evaluation/Average Returns     356.100562746444
time/data storing (s)          0.03388361446559429
time/evaluation sampling (s)   110.32487366069108
time/exploration sampling (s)  110.93293890357018
time/logging (s)               0.030621511861681938
time/saving (s)                0.012728249654173851
time/training (s)              9.184978999197483
time/epoch (s)                 230.5200249394402
time/total (s)                 20395.157516303472
Epoch                          86
-----------------------------  ---------------------
2023-07-31 23:37:54.426870 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 87 finished
-----------------------------  --------------------
replay_buffer/size             441000
trainer/tdrp Loss              [4027.4683]
trainer/QF1 Loss               0.11064793
trainer/QF2 Loss               0.1277762
trainer/Policy Loss            -51.67904
trainer/Q1 Predictions Mean    64.73362
trainer/Q1 Predictions Std     4.4226923
trainer/Q1 Predictions Max     72.93737
trainer/Q1 Predictions Min     45.171513
trainer/Q2 Predictions Mean    64.78789
trainer/Q2 Predictions Std     4.4169927
trainer/Q2 Predictions Max     72.788345
trainer/Q2 Predictions Min     45.132656
trainer/Q Targets Mean         64.66203
trainer/Q Targets Std          4.4472213
trainer/Q Targets Max          73.13427
trainer/Q Targets Min          44.718296
trainer/Log Pis Mean           13.236729
trainer/Log Pis Std            7.8075476
trainer/Log Pis Max            42.786514
trainer/Log Pis Min            -5.5600786
trainer/Policy mu Mean         -0.14532477
trainer/Policy mu Std          1.7604123
trainer/Policy mu Max          5.2905903
trainer/Policy mu Min          -6.041724
trainer/Policy log std Mean    -0.4446683
trainer/Policy log std Std     0.12084697
trainer/Policy log std Max     0.16668934
trainer/Policy log std Min     -1.1043355
trainer/Alpha                  0.003077076282352209
trainer/Alpha Loss             7.1531476974487305
exploration/num steps total    441000
exploration/num paths total    882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7079493711804247
exploration/Rewards Std        0.04275979100107123
exploration/Rewards Max        0.9675331327243684
exploration/Rewards Min        0.5070354183205453
exploration/Returns Mean       353.97468559021246
exploration/Returns Std        3.1119102436401405
exploration/Returns Max        358.1024457785202
exploration/Returns Min        347.72590916504635
exploration/Actions Mean       -0.010228674
exploration/Actions Std        0.6579295
exploration/Actions Max        0.9999675
exploration/Actions Min        -0.9998739
exploration/Num Paths          10
exploration/Average Returns    353.97468559021246
evaluation/num steps total     440000
evaluation/num paths total     880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6994542587643892
evaluation/Rewards Std         0.02795453518973744
evaluation/Rewards Max         0.9301094937473467
evaluation/Rewards Min         0.49306602262301547
evaluation/Returns Mean        349.7271293821946
evaluation/Returns Std         6.214161167310133
evaluation/Returns Max         358.16936037513017
evaluation/Returns Min         333.6328817107117
evaluation/ExplReturns Mean    349.7271293821946
evaluation/ExplReturns Std     6.214161167310133
evaluation/ExplReturns Max     358.16936037513017
evaluation/ExplReturns Min     333.6328817107117
evaluation/Actions Mean        0.0057067545
evaluation/Actions Std         0.528019
evaluation/Actions Max         0.99728566
evaluation/Actions Min         -0.9962653
evaluation/Num Paths           10
evaluation/Average Returns     349.7271293821946
time/data storing (s)          0.03447110019624233
time/evaluation sampling (s)   110.17650330159813
time/exploration sampling (s)  111.31039872672409
time/logging (s)               0.031175043433904648
time/saving (s)                0.0107627147808671
time/training (s)              9.573418752290308
time/epoch (s)                 231.13672963902354
time/total (s)                 20626.296719837002
Epoch                          87
-----------------------------  --------------------
2023-07-31 23:41:45.882329 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 88 finished
-----------------------------  ---------------------
replay_buffer/size             446000
trainer/tdrp Loss              [3931.1577]
trainer/QF1 Loss               0.119281456
trainer/QF2 Loss               0.122281685
trainer/Policy Loss            -54.98954
trainer/Q1 Predictions Mean    65.50207
trainer/Q1 Predictions Std     3.8300467
trainer/Q1 Predictions Max     73.119484
trainer/Q1 Predictions Min     50.171078
trainer/Q2 Predictions Mean    65.48779
trainer/Q2 Predictions Std     3.8617811
trainer/Q2 Predictions Max     73.23791
trainer/Q2 Predictions Min     50.099884
trainer/Q Targets Mean         65.60144
trainer/Q Targets Std          3.8765836
trainer/Q Targets Max          73.55879
trainer/Q Targets Min          50.066284
trainer/Log Pis Mean           10.666093
trainer/Log Pis Std            7.0885315
trainer/Log Pis Max            34.751076
trainer/Log Pis Min            -18.303383
trainer/Policy mu Mean         -0.06547337
trainer/Policy mu Std          1.6487117
trainer/Policy mu Max          4.907456
trainer/Policy mu Min          -4.4883895
trainer/Policy log std Mean    -0.43957344
trainer/Policy log std Std     0.10633944
trainer/Policy log std Max     0.13986707
trainer/Policy log std Min     -0.8057559
trainer/Alpha                  0.0031338531989604235
trainer/Alpha Loss             -7.690304756164551
exploration/num steps total    446000
exploration/num paths total    892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.702335120233482
exploration/Rewards Std        0.05618377098752505
exploration/Rewards Max        0.9758472444390999
exploration/Rewards Min        0.4578682001943355
exploration/Returns Mean       351.16756011674096
exploration/Returns Std        8.652870548762364
exploration/Returns Max        368.6882069116879
exploration/Returns Min        335.3828086813914
exploration/Actions Mean       0.040304456
exploration/Actions Std        0.6588616
exploration/Actions Max        0.99986047
exploration/Actions Min        -0.99970895
exploration/Num Paths          10
exploration/Average Returns    351.16756011674096
evaluation/num steps total     445000
evaluation/num paths total     890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7135603954895893
evaluation/Rewards Std         0.04979053447511901
evaluation/Rewards Max         0.976138866003831
evaluation/Rewards Min         0.5048140658099539
evaluation/Returns Mean        356.7801977447945
evaluation/Returns Std         8.531431716631342
evaluation/Returns Max         369.95113474821017
evaluation/Returns Min         342.29529487334213
evaluation/ExplReturns Mean    356.7801977447945
evaluation/ExplReturns Std     8.531431716631342
evaluation/ExplReturns Max     369.95113474821017
evaluation/ExplReturns Min     342.29529487334213
evaluation/Actions Mean        0.013827036
evaluation/Actions Std         0.500417
evaluation/Actions Max         0.9994183
evaluation/Actions Min         -0.9985593
evaluation/Num Paths           10
evaluation/Average Returns     356.7801977447945
time/data storing (s)          0.03416998405009508
time/evaluation sampling (s)   110.38955900166184
time/exploration sampling (s)  111.8108940795064
time/logging (s)               0.030463257804512978
time/saving (s)                0.011857843957841396
time/training (s)              9.174088737927377
time/epoch (s)                 231.45103290490806
time/total (s)                 20857.750241706148
Epoch                          88
-----------------------------  ---------------------
2023-07-31 23:45:39.572554 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 89 finished
-----------------------------  ---------------------
replay_buffer/size             451000
trainer/tdrp Loss              [3892.2856]
trainer/QF1 Loss               0.1367568
trainer/QF2 Loss               0.14635423
trainer/Policy Loss            -53.339634
trainer/Q1 Predictions Mean    65.247604
trainer/Q1 Predictions Std     4.73729
trainer/Q1 Predictions Max     74.0785
trainer/Q1 Predictions Min     48.750076
trainer/Q2 Predictions Mean    65.304886
trainer/Q2 Predictions Std     4.7206054
trainer/Q2 Predictions Max     74.16377
trainer/Q2 Predictions Min     49.26488
trainer/Q Targets Mean         65.14923
trainer/Q Targets Std          4.7048197
trainer/Q Targets Max          73.73443
trainer/Q Targets Min          48.70083
trainer/Log Pis Mean           12.072573
trainer/Log Pis Std            7.3170724
trainer/Log Pis Max            38.098038
trainer/Log Pis Min            -7.4350643
trainer/Policy mu Mean         -0.031910866
trainer/Policy mu Std          1.6928279
trainer/Policy mu Max          4.655735
trainer/Policy mu Min          -4.695455
trainer/Policy log std Mean    -0.45173457
trainer/Policy log std Std     0.11075005
trainer/Policy log std Max     0.02964443
trainer/Policy log std Min     -0.82179135
trainer/Alpha                  0.0030242756474763155
trainer/Alpha Loss             0.4210021495819092
exploration/num steps total    451000
exploration/num paths total    902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7081716323577115
exploration/Rewards Std        0.06174811645680599
exploration/Rewards Max        0.9779006912671204
exploration/Rewards Min        0.46517993321171236
exploration/Returns Mean       354.08581617885585
exploration/Returns Std        12.438173761256639
exploration/Returns Max        387.52626678925577
exploration/Returns Min        339.79710327302286
exploration/Actions Mean       -0.013226469
exploration/Actions Std        0.6641549
exploration/Actions Max        0.999981
exploration/Actions Min        -0.9998257
exploration/Num Paths          10
exploration/Average Returns    354.08581617885585
evaluation/num steps total     450000
evaluation/num paths total     900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6673852262010345
evaluation/Rewards Std         0.03329404470485427
evaluation/Rewards Max         0.7472539431210219
evaluation/Rewards Min         0.4645176699467179
evaluation/Returns Mean        333.6926131005172
evaluation/Returns Std         9.859619335520017
evaluation/Returns Max         349.58412284457995
evaluation/Returns Min         325.2154283601138
evaluation/ExplReturns Mean    333.6926131005172
evaluation/ExplReturns Std     9.859619335520017
evaluation/ExplReturns Max     349.58412284457995
evaluation/ExplReturns Min     325.2154283601138
evaluation/Actions Mean        -0.05547724
evaluation/Actions Std         0.51997316
evaluation/Actions Max         0.99918497
evaluation/Actions Min         -0.9972918
evaluation/Num Paths           10
evaluation/Average Returns     333.6926131005172
time/data storing (s)          0.034471480175852776
time/evaluation sampling (s)   111.91939563769847
time/exploration sampling (s)  111.12225175090134
time/logging (s)               0.03118826262652874
time/saving (s)                0.011484998278319836
time/training (s)              10.568415138870478
time/epoch (s)                 233.687207268551
time/total (s)                 21091.439911916852
Epoch                          89
-----------------------------  ---------------------
2023-07-31 23:49:33.831014 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 90 finished
-----------------------------  --------------------
replay_buffer/size             456000
trainer/tdrp Loss              [3976.176]
trainer/QF1 Loss               0.0936196
trainer/QF2 Loss               0.11694494
trainer/Policy Loss            -52.297684
trainer/Q1 Predictions Mean    65.131256
trainer/Q1 Predictions Std     4.5317917
trainer/Q1 Predictions Max     72.97186
trainer/Q1 Predictions Min     43.92042
trainer/Q2 Predictions Mean    65.053955
trainer/Q2 Predictions Std     4.543757
trainer/Q2 Predictions Max     72.907616
trainer/Q2 Predictions Min     43.5951
trainer/Q Targets Mean         65.14219
trainer/Q Targets Std          4.5546856
trainer/Q Targets Max          72.95833
trainer/Q Targets Min          44.030396
trainer/Log Pis Mean           12.995766
trainer/Log Pis Std            7.8767085
trainer/Log Pis Max            38.99026
trainer/Log Pis Min            -6.0215645
trainer/Policy mu Mean         -0.09582799
trainer/Policy mu Std          1.7211442
trainer/Policy mu Max          4.3392587
trainer/Policy mu Min          -4.5310955
trainer/Policy log std Mean    -0.47951245
trainer/Policy log std Std     0.11284372
trainer/Policy log std Max     0.008228213
trainer/Policy log std Min     -0.83776194
trainer/Alpha                  0.002989359898492694
trainer/Alpha Loss             5.788143157958984
exploration/num steps total    456000
exploration/num paths total    912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.734143562354799
exploration/Rewards Std        0.0894950715314564
exploration/Rewards Max        0.9767837117914436
exploration/Rewards Min        0.5035845717271629
exploration/Returns Mean       367.07178117739954
exploration/Returns Std        33.9977141759884
exploration/Returns Max        446.7307692414589
exploration/Returns Min        344.32559821377583
exploration/Actions Mean       0.04655405
exploration/Actions Std        0.6667917
exploration/Actions Max        0.9999053
exploration/Actions Min        -0.9998867
exploration/Num Paths          10
exploration/Average Returns    367.07178117739954
evaluation/num steps total     455000
evaluation/num paths total     910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7223174459256567
evaluation/Rewards Std         0.07569933595661442
evaluation/Rewards Max         0.9750921772661334
evaluation/Rewards Min         0.5030994581786743
evaluation/Returns Mean        361.15872296282834
evaluation/Returns Std         27.250418133113453
evaluation/Returns Max         427.67104685340985
evaluation/Returns Min         322.8395858698707
evaluation/ExplReturns Mean    361.15872296282834
evaluation/ExplReturns Std     27.250418133113453
evaluation/ExplReturns Max     427.67104685340985
evaluation/ExplReturns Min     322.8395858698707
evaluation/Actions Mean        0.0583831
evaluation/Actions Std         0.60303855
evaluation/Actions Max         0.9979392
evaluation/Actions Min         -0.9994314
evaluation/Num Paths           10
evaluation/Average Returns     361.15872296282834
time/data storing (s)          0.03414668142795563
time/evaluation sampling (s)   113.25244080740958
time/exploration sampling (s)  111.961963490583
time/logging (s)               0.030482535250484943
time/saving (s)                0.011752516962587833
time/training (s)              8.963205333799124
time/epoch (s)                 234.25399136543274
time/total (s)                 21325.69641183596
Epoch                          90
-----------------------------  --------------------
2023-07-31 23:53:25.145756 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 91 finished
-----------------------------  --------------------
replay_buffer/size             461000
trainer/tdrp Loss              [3859.4702]
trainer/QF1 Loss               0.12712617
trainer/QF2 Loss               0.11758896
trainer/Policy Loss            -54.241783
trainer/Q1 Predictions Mean    66.10913
trainer/Q1 Predictions Std     4.7668347
trainer/Q1 Predictions Max     74.23012
trainer/Q1 Predictions Min     48.136806
trainer/Q2 Predictions Mean    66.111115
trainer/Q2 Predictions Std     4.748046
trainer/Q2 Predictions Max     74.24154
trainer/Q2 Predictions Min     47.487488
trainer/Q Targets Mean         66.07439
trainer/Q Targets Std          4.720436
trainer/Q Targets Max          74.47942
trainer/Q Targets Min          48.406292
trainer/Log Pis Mean           12.044949
trainer/Log Pis Std            7.9927335
trainer/Log Pis Max            45.658077
trainer/Log Pis Min            -7.815446
trainer/Policy mu Mean         -0.04767609
trainer/Policy mu Std          1.6905366
trainer/Policy mu Max          4.552389
trainer/Policy mu Min          -4.215811
trainer/Policy log std Mean    -0.46347567
trainer/Policy log std Std     0.11437314
trainer/Policy log std Max     0.031161308
trainer/Policy log std Min     -0.84272337
trainer/Alpha                  0.002970212372019887
trainer/Alpha Loss             0.2615615129470825
exploration/num steps total    461000
exploration/num paths total    922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6745718233640061
exploration/Rewards Std        0.05850708483226755
exploration/Rewards Max        0.9640541322287133
exploration/Rewards Min        0.5073235697283233
exploration/Returns Mean       337.2859116820031
exploration/Returns Std        15.405794711004935
exploration/Returns Max        375.6630637051673
exploration/Returns Min        318.68958682203225
exploration/Actions Mean       -0.04833309
exploration/Actions Std        0.64259434
exploration/Actions Max        0.9996434
exploration/Actions Min        -0.99983454
exploration/Num Paths          10
exploration/Average Returns    337.2859116820031
evaluation/num steps total     460000
evaluation/num paths total     920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6962309442275753
evaluation/Rewards Std         0.0261025394588279
evaluation/Rewards Max         0.7460034371329578
evaluation/Rewards Min         0.4965077330966363
evaluation/Returns Mean        348.11547211378763
evaluation/Returns Std         4.228202979345839
evaluation/Returns Max         353.7998326080387
evaluation/Returns Min         340.68035144417235
evaluation/ExplReturns Mean    348.11547211378763
evaluation/ExplReturns Std     4.228202979345839
evaluation/ExplReturns Max     353.7998326080387
evaluation/ExplReturns Min     340.68035144417235
evaluation/Actions Mean        0.018040888
evaluation/Actions Std         0.5656304
evaluation/Actions Max         0.99662685
evaluation/Actions Min         -0.9960032
evaluation/Num Paths           10
evaluation/Average Returns     348.11547211378763
time/data storing (s)          0.03443501144647598
time/evaluation sampling (s)   110.75587421376258
time/exploration sampling (s)  110.94946720451117
time/logging (s)               0.030888906680047512
time/saving (s)                0.010370597243309021
time/training (s)              9.530358642339706
time/epoch (s)                 231.3113945759833
time/total (s)                 21557.01027248893
Epoch                          91
-----------------------------  --------------------
2023-07-31 23:57:20.473923 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 92 finished
-----------------------------  --------------------
replay_buffer/size             466000
trainer/tdrp Loss              [3831.626]
trainer/QF1 Loss               0.13881104
trainer/QF2 Loss               0.1370589
trainer/Policy Loss            -54.055008
trainer/Q1 Predictions Mean    65.92974
trainer/Q1 Predictions Std     4.57456
trainer/Q1 Predictions Max     73.446236
trainer/Q1 Predictions Min     46.364788
trainer/Q2 Predictions Mean    65.84625
trainer/Q2 Predictions Std     4.5531864
trainer/Q2 Predictions Max     73.31425
trainer/Q2 Predictions Min     46.303318
trainer/Q Targets Mean         65.970024
trainer/Q Targets Std          4.6076665
trainer/Q Targets Max          73.557144
trainer/Q Targets Min          46.645676
trainer/Log Pis Mean           12.011529
trainer/Log Pis Std            6.986621
trainer/Log Pis Max            34.62128
trainer/Log Pis Min            -5.909221
trainer/Policy mu Mean         -0.16911662
trainer/Policy mu Std          1.700122
trainer/Policy mu Max          4.8366957
trainer/Policy mu Min          -5.6551924
trainer/Policy log std Mean    -0.46972236
trainer/Policy log std Std     0.10548529
trainer/Policy log std Max     -0.03471294
trainer/Policy log std Min     -0.7988309
trainer/Alpha                  0.002956484444439411
trainer/Alpha Loss             0.06714534759521484
exploration/num steps total    466000
exploration/num paths total    932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7365751398837654
exploration/Rewards Std        0.08408261671687668
exploration/Rewards Max        0.9750098075199788
exploration/Rewards Min        0.5051014902589291
exploration/Returns Mean       368.2875699418827
exploration/Returns Std        24.01763774259772
exploration/Returns Max        419.0670744919095
exploration/Returns Min        343.2208187770538
exploration/Actions Mean       -0.07591372
exploration/Actions Std        0.67984277
exploration/Actions Max        0.99993694
exploration/Actions Min        -0.99997115
exploration/Num Paths          10
exploration/Average Returns    368.2875699418827
evaluation/num steps total     465000
evaluation/num paths total     930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7067618525711783
evaluation/Rewards Std         0.03192000824231278
evaluation/Rewards Max         0.7455886911689351
evaluation/Rewards Min         0.48266759121391545
evaluation/Returns Mean        353.3809262855892
evaluation/Returns Std         7.624677832112752
evaluation/Returns Max         365.7779593619154
evaluation/Returns Min         338.28788120270303
evaluation/ExplReturns Mean    353.3809262855892
evaluation/ExplReturns Std     7.624677832112752
evaluation/ExplReturns Max     365.7779593619154
evaluation/ExplReturns Min     338.28788120270303
evaluation/Actions Mean        -0.09921659
evaluation/Actions Std         0.5596828
evaluation/Actions Max         0.99960613
evaluation/Actions Min         -0.99940014
evaluation/Num Paths           10
evaluation/Average Returns     353.3809262855892
time/data storing (s)          0.0337093835696578
time/evaluation sampling (s)   111.97598399966955
time/exploration sampling (s)  113.69921671506017
time/logging (s)               0.030351919122040272
time/saving (s)                0.012012519873678684
time/training (s)              9.572593881748617
time/epoch (s)                 235.32386841904372
time/total (s)                 21792.3366490053
Epoch                          92
-----------------------------  --------------------
2023-08-01 00:01:15.055983 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 93 finished
-----------------------------  --------------------
replay_buffer/size             471000
trainer/tdrp Loss              [3859.1013]
trainer/QF1 Loss               0.11385213
trainer/QF2 Loss               0.12857875
trainer/Policy Loss            -54.442745
trainer/Q1 Predictions Mean    66.69605
trainer/Q1 Predictions Std     4.5030107
trainer/Q1 Predictions Max     75.107544
trainer/Q1 Predictions Min     47.791065
trainer/Q2 Predictions Mean    66.68254
trainer/Q2 Predictions Std     4.4940343
trainer/Q2 Predictions Max     75.23246
trainer/Q2 Predictions Min     47.607117
trainer/Q Targets Mean         66.73718
trainer/Q Targets Std          4.5379257
trainer/Q Targets Max          75.32168
trainer/Q Targets Min          47.26397
trainer/Log Pis Mean           12.405895
trainer/Log Pis Std            7.594441
trainer/Log Pis Max            38.568104
trainer/Log Pis Min            -8.694099
trainer/Policy mu Mean         -0.08980211
trainer/Policy mu Std          1.6961123
trainer/Policy mu Max          4.680686
trainer/Policy mu Min          -4.205928
trainer/Policy log std Mean    -0.48795927
trainer/Policy log std Std     0.11928497
trainer/Policy log std Max     0.058481038
trainer/Policy log std Min     -0.8281185
trainer/Alpha                  0.002951814793050289
trainer/Alpha Loss             2.364649772644043
exploration/num steps total    471000
exploration/num paths total    942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7217317922624406
exploration/Rewards Std        0.07382739569068776
exploration/Rewards Max        0.9761610095825465
exploration/Rewards Min        0.503124679236556
exploration/Returns Mean       360.8658961312203
exploration/Returns Std        21.29816502529155
exploration/Returns Max        409.94081723788725
exploration/Returns Min        336.12906318569816
exploration/Actions Mean       0.08023143
exploration/Actions Std        0.6852554
exploration/Actions Max        0.99997944
exploration/Actions Min        -0.99987864
exploration/Num Paths          10
exploration/Average Returns    360.8658961312203
evaluation/num steps total     470000
evaluation/num paths total     940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7055701601624985
evaluation/Rewards Std         0.02291189312678827
evaluation/Rewards Max         0.745829793668862
evaluation/Rewards Min         0.5118164756372576
evaluation/Returns Mean        352.78508008124953
evaluation/Returns Std         5.071193777673843
evaluation/Returns Max         362.4914401891715
evaluation/Returns Min         346.4701356464383
evaluation/ExplReturns Mean    352.78508008124953
evaluation/ExplReturns Std     5.071193777673843
evaluation/ExplReturns Max     362.4914401891715
evaluation/ExplReturns Min     346.4701356464383
evaluation/Actions Mean        0.047310505
evaluation/Actions Std         0.6010259
evaluation/Actions Max         0.99950045
evaluation/Actions Min         -0.99966204
evaluation/Num Paths           10
evaluation/Average Returns     352.78508008124953
time/data storing (s)          0.03445897251367569
time/evaluation sampling (s)   112.7940883282572
time/exploration sampling (s)  112.22451106831431
time/logging (s)               0.030290679074823856
time/saving (s)                0.012511608190834522
time/training (s)              9.482378855347633
time/epoch (s)                 234.57823951169848
time/total (s)                 22026.917412089184
Epoch                          93
-----------------------------  --------------------
2023-08-01 00:05:08.591348 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 94 finished
-----------------------------  ---------------------
replay_buffer/size             476000
trainer/tdrp Loss              [3914.6199]
trainer/QF1 Loss               0.09592456
trainer/QF2 Loss               0.10631059
trainer/Policy Loss            -54.50367
trainer/Q1 Predictions Mean    66.60145
trainer/Q1 Predictions Std     5.0042605
trainer/Q1 Predictions Max     75.49736
trainer/Q1 Predictions Min     39.222164
trainer/Q2 Predictions Mean    66.645065
trainer/Q2 Predictions Std     4.9773893
trainer/Q2 Predictions Max     75.50497
trainer/Q2 Predictions Min     39.855442
trainer/Q Targets Mean         66.66674
trainer/Q Targets Std          4.9672265
trainer/Q Targets Max          75.47401
trainer/Q Targets Min          39.768696
trainer/Log Pis Mean           12.271242
trainer/Log Pis Std            7.357572
trainer/Log Pis Max            32.609516
trainer/Log Pis Min            -5.258539
trainer/Policy mu Mean         -0.00277064
trainer/Policy mu Std          1.6872306
trainer/Policy mu Max          4.20274
trainer/Policy mu Min          -4.4737277
trainer/Policy log std Mean    -0.4810613
trainer/Policy log std Std     0.11289533
trainer/Policy log std Max     0.021004573
trainer/Policy log std Min     -0.83787864
trainer/Alpha                  0.0029414694290608168
trainer/Alpha Loss             1.5810198783874512
exploration/num steps total    476000
exploration/num paths total    952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7330908254082665
exploration/Rewards Std        0.10085608690061557
exploration/Rewards Max        0.9763873271260328
exploration/Rewards Min        0.49277019017692525
exploration/Returns Mean       366.5454127041333
exploration/Returns Std        25.646096893404398
exploration/Returns Max        421.23078402452455
exploration/Returns Min        333.0550017311037
exploration/Actions Mean       0.0043707266
exploration/Actions Std        0.66288984
exploration/Actions Max        0.9997974
exploration/Actions Min        -0.9999262
exploration/Num Paths          10
exploration/Average Returns    366.5454127041333
evaluation/num steps total     475000
evaluation/num paths total     950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7224140228936247
evaluation/Rewards Std         0.0726838403900246
evaluation/Rewards Max         0.973722523416191
evaluation/Rewards Min         0.4993598333556376
evaluation/Returns Mean        361.2070114468123
evaluation/Returns Std         30.68100601652692
evaluation/Returns Max         451.21628783877907
evaluation/Returns Min         341.89745783284326
evaluation/ExplReturns Mean    361.2070114468123
evaluation/ExplReturns Std     30.68100601652692
evaluation/ExplReturns Max     451.21628783877907
evaluation/ExplReturns Min     341.89745783284326
evaluation/Actions Mean        0.04823873
evaluation/Actions Std         0.56952775
evaluation/Actions Max         0.9991713
evaluation/Actions Min         -0.9983246
evaluation/Num Paths           10
evaluation/Average Returns     361.2070114468123
time/data storing (s)          0.034548256546258926
time/evaluation sampling (s)   111.61360477283597
time/exploration sampling (s)  112.3584456415847
time/logging (s)               0.030620703473687172
time/saving (s)                0.012585664168000221
time/training (s)              9.482058976776898
time/epoch (s)                 233.5318640153855
time/total (s)                 22260.451834782027
Epoch                          94
-----------------------------  ---------------------
2023-08-01 00:09:06.296421 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 95 finished
-----------------------------  ---------------------
replay_buffer/size             481000
trainer/tdrp Loss              [3874.64]
trainer/QF1 Loss               0.13036665
trainer/QF2 Loss               0.14013281
trainer/Policy Loss            -54.42729
trainer/Q1 Predictions Mean    66.80861
trainer/Q1 Predictions Std     4.380762
trainer/Q1 Predictions Max     75.73461
trainer/Q1 Predictions Min     44.592087
trainer/Q2 Predictions Mean    66.74657
trainer/Q2 Predictions Std     4.378692
trainer/Q2 Predictions Max     75.68609
trainer/Q2 Predictions Min     44.36275
trainer/Q Targets Mean         66.893326
trainer/Q Targets Std          4.427913
trainer/Q Targets Max          76.181465
trainer/Q Targets Min          44.01228
trainer/Log Pis Mean           12.529709
trainer/Log Pis Std            7.8398066
trainer/Log Pis Max            37.82718
trainer/Log Pis Min            -5.1387467
trainer/Policy mu Mean         -0.04228435
trainer/Policy mu Std          1.7004097
trainer/Policy mu Max          5.371594
trainer/Policy mu Min          -5.4340587
trainer/Policy log std Mean    -0.48175177
trainer/Policy log std Std     0.12150076
trainer/Policy log std Max     -0.040775746
trainer/Policy log std Min     -0.84570134
trainer/Alpha                  0.0028764628805220127
trainer/Alpha Loss             3.099379539489746
exploration/num steps total    481000
exploration/num paths total    962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7070309167966726
exploration/Rewards Std        0.02655554913019365
exploration/Rewards Max        0.7480348260247482
exploration/Rewards Min        0.4952410245123683
exploration/Returns Mean       353.5154583983363
exploration/Returns Std        6.062256633880059
exploration/Returns Max        362.18631661938787
exploration/Returns Min        339.9232688432528
exploration/Actions Mean       -0.043341886
exploration/Actions Std        0.65744764
exploration/Actions Max        0.9995097
exploration/Actions Min        -0.9998619
exploration/Num Paths          10
exploration/Average Returns    353.5154583983363
evaluation/num steps total     480000
evaluation/num paths total     960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6829936139394863
evaluation/Rewards Std         0.023783077252880095
evaluation/Rewards Max         0.7452530090205525
evaluation/Rewards Min         0.49111589695000557
evaluation/Returns Mean        341.49680696974315
evaluation/Returns Std         7.921865627904186
evaluation/Returns Max         363.5905681679519
evaluation/Returns Min         330.55086839728256
evaluation/ExplReturns Mean    341.49680696974315
evaluation/ExplReturns Std     7.921865627904186
evaluation/ExplReturns Max     363.5905681679519
evaluation/ExplReturns Min     330.55086839728256
evaluation/Actions Mean        -0.1640862
evaluation/Actions Std         0.46463358
evaluation/Actions Max         0.9935445
evaluation/Actions Min         -0.9993433
evaluation/Num Paths           10
evaluation/Average Returns     341.49680696974315
time/data storing (s)          0.034279015846550465
time/evaluation sampling (s)   114.52472223993391
time/exploration sampling (s)  112.8439498282969
time/logging (s)               0.03105669654905796
time/saving (s)                0.012897872366011143
time/training (s)              10.254855738952756
time/epoch (s)                 237.70176139194518
time/total (s)                 22498.156072121114
Epoch                          95
-----------------------------  ---------------------
2023-08-01 00:13:00.280541 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 96 finished
-----------------------------  ---------------------
replay_buffer/size             486000
trainer/tdrp Loss              [4052.2751]
trainer/QF1 Loss               0.12322264
trainer/QF2 Loss               0.09788163
trainer/Policy Loss            -56.115925
trainer/Q1 Predictions Mean    67.287445
trainer/Q1 Predictions Std     4.703795
trainer/Q1 Predictions Max     75.01503
trainer/Q1 Predictions Min     47.710796
trainer/Q2 Predictions Mean    67.21922
trainer/Q2 Predictions Std     4.682003
trainer/Q2 Predictions Max     74.869576
trainer/Q2 Predictions Min     48.23497
trainer/Q Targets Mean         67.168564
trainer/Q Targets Std          4.7044773
trainer/Q Targets Max          74.832985
trainer/Q Targets Min          46.729378
trainer/Log Pis Mean           11.304958
trainer/Log Pis Std            7.710758
trainer/Log Pis Max            52.731255
trainer/Log Pis Min            -9.465451
trainer/Policy mu Mean         0.03878185
trainer/Policy mu Std          1.6676714
trainer/Policy mu Max          5.2702203
trainer/Policy mu Min          -4.7104225
trainer/Policy log std Mean    -0.48533234
trainer/Policy log std Std     0.12003065
trainer/Policy log std Max     0.09118472
trainer/Policy log std Min     -0.8799743
trainer/Alpha                  0.0029640747234225273
trainer/Alpha Loss             -4.04597282409668
exploration/num steps total    486000
exploration/num paths total    972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7250948736467716
exploration/Rewards Std        0.044944210661924625
exploration/Rewards Max        0.9721445750632681
exploration/Rewards Min        0.49341418211010935
exploration/Returns Mean       362.54743682338596
exploration/Returns Std        9.569288847155743
exploration/Returns Max        380.67584386957634
exploration/Returns Min        347.5702435211384
exploration/Actions Mean       -0.011024843
exploration/Actions Std        0.6584836
exploration/Actions Max        0.99982643
exploration/Actions Min        -0.999688
exploration/Num Paths          10
exploration/Average Returns    362.54743682338596
evaluation/num steps total     485000
evaluation/num paths total     970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6989595451057243
evaluation/Rewards Std         0.030032335283164513
evaluation/Rewards Max         0.7472511178375852
evaluation/Rewards Min         0.5057493636325304
evaluation/Returns Mean        349.47977255286224
evaluation/Returns Std         6.6091248565077665
evaluation/Returns Max         361.38668634783676
evaluation/Returns Min         343.31693139668306
evaluation/ExplReturns Mean    349.47977255286224
evaluation/ExplReturns Std     6.6091248565077665
evaluation/ExplReturns Max     361.38668634783676
evaluation/ExplReturns Min     343.31693139668306
evaluation/Actions Mean        0.035640668
evaluation/Actions Std         0.59758586
evaluation/Actions Max         0.9991151
evaluation/Actions Min         -0.9967321
evaluation/Num Paths           10
evaluation/Average Returns     349.47977255286224
time/data storing (s)          0.03412173129618168
time/evaluation sampling (s)   112.2230418547988
time/exploration sampling (s)  112.20706790219992
time/logging (s)               0.03045905940234661
time/saving (s)                0.011187122203409672
time/training (s)              9.473887427709997
time/epoch (s)                 233.97976509761065
time/total (s)                 22732.1383186467
Epoch                          96
-----------------------------  ---------------------
2023-08-01 00:16:54.952775 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 97 finished
-----------------------------  ---------------------
replay_buffer/size             491000
trainer/tdrp Loss              [3726.4502]
trainer/QF1 Loss               0.1031488
trainer/QF2 Loss               0.08658241
trainer/Policy Loss            -55.54278
trainer/Q1 Predictions Mean    67.44005
trainer/Q1 Predictions Std     4.5138144
trainer/Q1 Predictions Max     76.414665
trainer/Q1 Predictions Min     46.599495
trainer/Q2 Predictions Mean    67.408615
trainer/Q2 Predictions Std     4.5348396
trainer/Q2 Predictions Max     76.498184
trainer/Q2 Predictions Min     46.747787
trainer/Q Targets Mean         67.39692
trainer/Q Targets Std          4.520116
trainer/Q Targets Max          76.42718
trainer/Q Targets Min          47.11899
trainer/Log Pis Mean           12.022483
trainer/Log Pis Std            7.5961294
trainer/Log Pis Max            36.236862
trainer/Log Pis Min            -10.1184025
trainer/Policy mu Mean         -0.037357617
trainer/Policy mu Std          1.6871377
trainer/Policy mu Max          5.2358866
trainer/Policy mu Min          -5.077073
trainer/Policy log std Mean    -0.48161247
trainer/Policy log std Std     0.1256194
trainer/Policy log std Max     -0.0355004
trainer/Policy log std Min     -0.91933525
trainer/Alpha                  0.0029875815380364656
trainer/Alpha Loss             0.13070392608642578
exploration/num steps total    491000
exploration/num paths total    982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7086110888167223
exploration/Rewards Std        0.05795114550227685
exploration/Rewards Max        0.9776182683441574
exploration/Rewards Min        0.5089954536023481
exploration/Returns Mean       354.3055444083612
exploration/Returns Std        16.876543388558066
exploration/Returns Max        402.20612353972507
exploration/Returns Min        341.9333895511729
exploration/Actions Mean       0.048288167
exploration/Actions Std        0.6473574
exploration/Actions Max        0.9999205
exploration/Actions Min        -0.9998171
exploration/Num Paths          10
exploration/Average Returns    354.3055444083612
evaluation/num steps total     490000
evaluation/num paths total     980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6931645159518137
evaluation/Rewards Std         0.017442618129507096
evaluation/Rewards Max         0.7462102315091488
evaluation/Rewards Min         0.502480757044777
evaluation/Returns Mean        346.5822579759068
evaluation/Returns Std         3.3716414243610897
evaluation/Returns Max         352.94164553400594
evaluation/Returns Min         339.8389683402845
evaluation/ExplReturns Mean    346.5822579759068
evaluation/ExplReturns Std     3.3716414243610897
evaluation/ExplReturns Max     352.94164553400594
evaluation/ExplReturns Min     339.8389683402845
evaluation/Actions Mean        0.05712069
evaluation/Actions Std         0.50816715
evaluation/Actions Max         0.9983021
evaluation/Actions Min         -0.9942624
evaluation/Num Paths           10
evaluation/Average Returns     346.5822579759068
time/data storing (s)          0.03435476217418909
time/evaluation sampling (s)   112.85295853763819
time/exploration sampling (s)  112.25105400197208
time/logging (s)               0.0303815845400095
time/saving (s)                0.011296888813376427
time/training (s)              9.488373369909823
time/epoch (s)                 234.66841914504766
time/total (s)                 22966.80920292344
Epoch                          97
-----------------------------  ---------------------
2023-08-01 00:20:48.968995 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 98 finished
-----------------------------  ---------------------
replay_buffer/size             496000
trainer/tdrp Loss              [4056.6384]
trainer/QF1 Loss               0.10861247
trainer/QF2 Loss               0.113548
trainer/Policy Loss            -56.168064
trainer/Q1 Predictions Mean    67.924995
trainer/Q1 Predictions Std     4.195753
trainer/Q1 Predictions Max     76.53535
trainer/Q1 Predictions Min     48.454308
trainer/Q2 Predictions Mean    67.94993
trainer/Q2 Predictions Std     4.211455
trainer/Q2 Predictions Max     76.548454
trainer/Q2 Predictions Min     48.518543
trainer/Q Targets Mean         67.9675
trainer/Q Targets Std          4.232541
trainer/Q Targets Max          76.53322
trainer/Q Targets Min          48.587578
trainer/Log Pis Mean           11.931346
trainer/Log Pis Std            6.7426753
trainer/Log Pis Max            34.054413
trainer/Log Pis Min            -6.73937
trainer/Policy mu Mean         -0.15269627
trainer/Policy mu Std          1.6471951
trainer/Policy mu Max          4.365558
trainer/Policy mu Min          -6.5493584
trainer/Policy log std Mean    -0.502358
trainer/Policy log std Std     0.1280436
trainer/Policy log std Max     0.09410575
trainer/Policy log std Min     -0.8968569
trainer/Alpha                  0.0028832287061959505
trainer/Alpha Loss             -0.40154731273651123
exploration/num steps total    496000
exploration/num paths total    992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7619713983743681
exploration/Rewards Std        0.12032281202094142
exploration/Rewards Max        0.977921612612489
exploration/Rewards Min        0.5035907738865807
exploration/Returns Mean       380.985699187184
exploration/Returns Std        41.213659476629765
exploration/Returns Max        445.4265928346877
exploration/Returns Min        339.94069913434765
exploration/Actions Mean       0.026307605
exploration/Actions Std        0.65824646
exploration/Actions Max        0.99994695
exploration/Actions Min        -0.999896
exploration/Num Paths          10
exploration/Average Returns    380.985699187184
evaluation/num steps total     495000
evaluation/num paths total     990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.680279495321347
evaluation/Rewards Std         0.07486356208453547
evaluation/Rewards Max         0.9739623547729241
evaluation/Rewards Min         0.5131601346641506
evaluation/Returns Mean        340.1397476606735
evaluation/Returns Std         29.483967651742404
evaluation/Returns Max         420.16857348740433
evaluation/Returns Min         319.61720871307335
evaluation/ExplReturns Mean    340.1397476606735
evaluation/ExplReturns Std     29.483967651742404
evaluation/ExplReturns Max     420.16857348740433
evaluation/ExplReturns Min     319.61720871307335
evaluation/Actions Mean        0.025876582
evaluation/Actions Std         0.5025872
evaluation/Actions Max         0.9996757
evaluation/Actions Min         -0.9976075
evaluation/Num Paths           10
evaluation/Average Returns     340.1397476606735
time/data storing (s)          0.03453280031681061
time/evaluation sampling (s)   111.0609100740403
time/exploration sampling (s)  113.34447094425559
time/logging (s)               0.030525445006787777
time/saving (s)                0.012190496549010277
time/training (s)              9.529941297136247
time/epoch (s)                 234.01257105730474
time/total (s)                 23200.824272559956
Epoch                          98
-----------------------------  ---------------------
2023-08-01 00:24:42.939367 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 99 finished
-----------------------------  --------------------
replay_buffer/size             501000
trainer/tdrp Loss              [3751.1943]
trainer/QF1 Loss               0.14155796
trainer/QF2 Loss               0.114080116
trainer/Policy Loss            -56.69155
trainer/Q1 Predictions Mean    68.0954
trainer/Q1 Predictions Std     4.4825754
trainer/Q1 Predictions Max     74.83042
trainer/Q1 Predictions Min     46.3598
trainer/Q2 Predictions Mean    68.076775
trainer/Q2 Predictions Std     4.483403
trainer/Q2 Predictions Max     74.778206
trainer/Q2 Predictions Min     46.448914
trainer/Q Targets Mean         68.05745
trainer/Q Targets Std          4.5269203
trainer/Q Targets Max          75.092926
trainer/Q Targets Min          46.227875
trainer/Log Pis Mean           11.5190325
trainer/Log Pis Std            7.7772098
trainer/Log Pis Max            35.184822
trainer/Log Pis Min            -7.5972104
trainer/Policy mu Mean         -0.15835555
trainer/Policy mu Std          1.6475122
trainer/Policy mu Max          4.3606505
trainer/Policy mu Min          -4.1772385
trainer/Policy log std Mean    -0.48908147
trainer/Policy log std Std     0.12834693
trainer/Policy log std Max     -0.020300806
trainer/Policy log std Min     -0.96896553
trainer/Alpha                  0.002905996050685644
trainer/Alpha Loss             -2.8092923164367676
exploration/num steps total    501000
exploration/num paths total    1002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.68761564944579
exploration/Rewards Std        0.04188198181498048
exploration/Rewards Max        0.9550281878853952
exploration/Rewards Min        0.4874212333720526
exploration/Returns Mean       343.8078247228951
exploration/Returns Std        11.278895783333896
exploration/Returns Max        372.9641423322032
exploration/Returns Min        332.4939573679006
exploration/Actions Mean       -0.016822983
exploration/Actions Std        0.64511144
exploration/Actions Max        0.99996513
exploration/Actions Min        -0.99982226
exploration/Num Paths          10
exploration/Average Returns    343.8078247228951
evaluation/num steps total     500000
evaluation/num paths total     1000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7035086875793504
evaluation/Rewards Std         0.040582130267232105
evaluation/Rewards Max         0.9619273615803835
evaluation/Rewards Min         0.5028144829631159
evaluation/Returns Mean        351.75434378967526
evaluation/Returns Std         12.096368603825502
evaluation/Returns Max         374.5678356463037
evaluation/Returns Min         337.12003578347924
evaluation/ExplReturns Mean    351.75434378967526
evaluation/ExplReturns Std     12.096368603825502
evaluation/ExplReturns Max     374.5678356463037
evaluation/ExplReturns Min     337.12003578347924
evaluation/Actions Mean        -0.05030984
evaluation/Actions Std         0.5260132
evaluation/Actions Max         0.9970675
evaluation/Actions Min         -0.99818707
evaluation/Num Paths           10
evaluation/Average Returns     351.75434378967526
time/data storing (s)          0.033793690614402294
time/evaluation sampling (s)   111.98859242908657
time/exploration sampling (s)  112.38074672594666
time/logging (s)               0.030676004476845264
time/saving (s)                0.0126171400770545
time/training (s)              9.520232303068042
time/epoch (s)                 233.96665829326957
time/total (s)                 23434.793500286527
Epoch                          99
-----------------------------  --------------------
2023-08-01 00:28:38.334026 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 100 finished
-----------------------------  ---------------------
replay_buffer/size             506000
trainer/tdrp Loss              [3647.9285]
trainer/QF1 Loss               0.12172511
trainer/QF2 Loss               0.1259721
trainer/Policy Loss            -56.944546
trainer/Q1 Predictions Mean    68.24155
trainer/Q1 Predictions Std     4.412275
trainer/Q1 Predictions Max     77.18044
trainer/Q1 Predictions Min     52.513496
trainer/Q2 Predictions Mean    68.23694
trainer/Q2 Predictions Std     4.417965
trainer/Q2 Predictions Max     77.30155
trainer/Q2 Predictions Min     52.13096
trainer/Q Targets Mean         68.31275
trainer/Q Targets Std          4.3820252
trainer/Q Targets Max          77.13982
trainer/Q Targets Min          52.4336
trainer/Log Pis Mean           11.452553
trainer/Log Pis Std            7.615603
trainer/Log Pis Max            35.528973
trainer/Log Pis Min            -7.000863
trainer/Policy mu Mean         -0.0070311627
trainer/Policy mu Std          1.6337047
trainer/Policy mu Max          5.1860595
trainer/Policy mu Min          -5.2380886
trainer/Policy log std Mean    -0.51487154
trainer/Policy log std Std     0.12659524
trainer/Policy log std Max     0.19640398
trainer/Policy log std Min     -0.95858914
trainer/Alpha                  0.0027576421853154898
trainer/Alpha Loss             -3.2261853218078613
exploration/num steps total    506000
exploration/num paths total    1012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7582550865487168
exploration/Rewards Std        0.10160329944886616
exploration/Rewards Max        0.9766219116512254
exploration/Rewards Min        0.499835535156447
exploration/Returns Mean       379.12754327435835
exploration/Returns Std        38.270699748242755
exploration/Returns Max        443.0803063404312
exploration/Returns Min        344.72398882656364
exploration/Actions Mean       0.0014886545
exploration/Actions Std        0.6508307
exploration/Actions Max        0.99957
exploration/Actions Min        -0.99920386
exploration/Num Paths          10
exploration/Average Returns    379.12754327435835
evaluation/num steps total     505000
evaluation/num paths total     1010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8010660917288209
evaluation/Rewards Std         0.13208874788209946
evaluation/Rewards Max         0.976610442879926
evaluation/Rewards Min         0.41009402715111165
evaluation/Returns Mean        400.5330458644104
evaluation/Returns Std         47.488019086057555
evaluation/Returns Max         456.41892890945866
evaluation/Returns Min         342.2600529353073
evaluation/ExplReturns Mean    400.5330458644104
evaluation/ExplReturns Std     47.488019086057555
evaluation/ExplReturns Max     456.41892890945866
evaluation/ExplReturns Min     342.2600529353073
evaluation/Actions Mean        0.00080263213
evaluation/Actions Std         0.5789509
evaluation/Actions Max         0.9999857
evaluation/Actions Min         -0.9999127
evaluation/Num Paths           10
evaluation/Average Returns     400.5330458644104
time/data storing (s)          0.03441370278596878
time/evaluation sampling (s)   113.04375076573342
time/exploration sampling (s)  112.71155605372041
time/logging (s)               0.030860701575875282
time/saving (s)                0.010919633321464062
time/training (s)              9.559504336677492
time/epoch (s)                 235.39100519381464
time/total (s)                 23670.18705913145
Epoch                          100
-----------------------------  ---------------------
2023-08-01 00:32:34.404395 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 101 finished
-----------------------------  --------------------
replay_buffer/size             511000
trainer/tdrp Loss              [3389.3884]
trainer/QF1 Loss               0.12043662
trainer/QF2 Loss               0.13350913
trainer/Policy Loss            -56.358337
trainer/Q1 Predictions Mean    68.6145
trainer/Q1 Predictions Std     4.4628916
trainer/Q1 Predictions Max     77.19544
trainer/Q1 Predictions Min     44.741512
trainer/Q2 Predictions Mean    68.66862
trainer/Q2 Predictions Std     4.468699
trainer/Q2 Predictions Max     77.184166
trainer/Q2 Predictions Min     45.326267
trainer/Q Targets Mean         68.52319
trainer/Q Targets Std          4.466053
trainer/Q Targets Max          77.11829
trainer/Q Targets Min          44.55604
trainer/Log Pis Mean           12.4299755
trainer/Log Pis Std            8.227598
trainer/Log Pis Max            33.93558
trainer/Log Pis Min            -7.224262
trainer/Policy mu Mean         -0.0752196
trainer/Policy mu Std          1.6884192
trainer/Policy mu Max          6.0039153
trainer/Policy mu Min          -4.8262053
trainer/Policy log std Mean    -0.5135104
trainer/Policy log std Std     0.1272458
trainer/Policy log std Max     -0.031513214
trainer/Policy log std Min     -0.95651686
trainer/Alpha                  0.002876909915357828
trainer/Alpha Loss             2.515791416168213
exploration/num steps total    511000
exploration/num paths total    1022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7934476043429021
exploration/Rewards Std        0.11840384163103257
exploration/Rewards Max        0.9794899006567106
exploration/Rewards Min        0.5034049672587799
exploration/Returns Mean       396.723802171451
exploration/Returns Std        45.1713783147168
exploration/Returns Max        459.1217053978449
exploration/Returns Min        349.9517884710622
exploration/Actions Mean       0.043912135
exploration/Actions Std        0.6543834
exploration/Actions Max        0.9998568
exploration/Actions Min        -0.9997093
exploration/Num Paths          10
exploration/Average Returns    396.723802171451
evaluation/num steps total     510000
evaluation/num paths total     1020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7381988660827756
evaluation/Rewards Std         0.07240794426409577
evaluation/Rewards Max         0.9768119974968402
evaluation/Rewards Min         0.5045400688331102
evaluation/Returns Mean        369.0994330413878
evaluation/Returns Std         31.922704065164663
evaluation/Returns Max         463.43376735355383
evaluation/Returns Min         342.2552255241619
evaluation/ExplReturns Mean    369.0994330413878
evaluation/ExplReturns Std     31.922704065164663
evaluation/ExplReturns Max     463.43376735355383
evaluation/ExplReturns Min     342.2552255241619
evaluation/Actions Mean        0.117093764
evaluation/Actions Std         0.51190674
evaluation/Actions Max         0.99993765
evaluation/Actions Min         -0.99512815
evaluation/Num Paths           10
evaluation/Average Returns     369.0994330413878
time/data storing (s)          0.03442166838794947
time/evaluation sampling (s)   112.38422960136086
time/exploration sampling (s)  113.33000842574984
time/logging (s)               0.03125938959419727
time/saving (s)                0.013020123355090618
time/training (s)              10.273802069947124
time/epoch (s)                 236.06674127839506
time/total (s)                 23906.256441997364
Epoch                          101
-----------------------------  --------------------
2023-08-01 00:36:32.352769 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 102 finished
-----------------------------  ---------------------
replay_buffer/size             516000
trainer/tdrp Loss              [3856.785]
trainer/QF1 Loss               0.15542024
trainer/QF2 Loss               0.12864614
trainer/Policy Loss            -56.792904
trainer/Q1 Predictions Mean    68.25485
trainer/Q1 Predictions Std     5.178955
trainer/Q1 Predictions Max     77.01528
trainer/Q1 Predictions Min     46.250298
trainer/Q2 Predictions Mean    68.25553
trainer/Q2 Predictions Std     5.16554
trainer/Q2 Predictions Max     77.16946
trainer/Q2 Predictions Min     46.39326
trainer/Q Targets Mean         68.25688
trainer/Q Targets Std          5.2079034
trainer/Q Targets Max          77.15501
trainer/Q Targets Min          46.201706
trainer/Log Pis Mean           11.617237
trainer/Log Pis Std            7.4106374
trainer/Log Pis Max            34.915985
trainer/Log Pis Min            -6.487619
trainer/Policy mu Mean         0.13449831
trainer/Policy mu Std          1.6533815
trainer/Policy mu Max          5.1273685
trainer/Policy mu Min          -3.8634574
trainer/Policy log std Mean    -0.52888566
trainer/Policy log std Std     0.13302921
trainer/Policy log std Max     0.033108324
trainer/Policy log std Min     -1.0104935
trainer/Alpha                  0.0028153860475867987
trainer/Alpha Loss             -2.24774169921875
exploration/num steps total    516000
exploration/num paths total    1032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7193223453152068
exploration/Rewards Std        0.07367893075153259
exploration/Rewards Max        0.9755455426127171
exploration/Rewards Min        0.504339156781848
exploration/Returns Mean       359.6611726576035
exploration/Returns Std        25.441696217729216
exploration/Returns Max        434.5076816999413
exploration/Returns Min        344.98909501470285
exploration/Actions Mean       0.05529355
exploration/Actions Std        0.6610554
exploration/Actions Max        0.9998896
exploration/Actions Min        -0.9999041
exploration/Num Paths          10
exploration/Average Returns    359.6611726576035
evaluation/num steps total     515000
evaluation/num paths total     1030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.739073028441542
evaluation/Rewards Std         0.09570818466663272
evaluation/Rewards Max         0.9759951257147738
evaluation/Rewards Min         0.4780104628246208
evaluation/Returns Mean        369.5365142207709
evaluation/Returns Std         22.25790102087245
evaluation/Returns Max         415.1578325495599
evaluation/Returns Min         346.4227537704293
evaluation/ExplReturns Mean    369.5365142207709
evaluation/ExplReturns Std     22.25790102087245
evaluation/ExplReturns Max     415.1578325495599
evaluation/ExplReturns Min     346.4227537704293
evaluation/Actions Mean        0.019878516
evaluation/Actions Std         0.55364585
evaluation/Actions Max         0.9979575
evaluation/Actions Min         -0.998977
evaluation/Num Paths           10
evaluation/Average Returns     369.5365142207709
time/data storing (s)          0.03417708911001682
time/evaluation sampling (s)   113.40430479124188
time/exploration sampling (s)  114.32552070450038
time/logging (s)               0.031069171614944935
time/saving (s)                0.012510484084486961
time/training (s)              10.136752744205296
time/epoch (s)                 237.944334984757
time/total (s)                 24144.20326820668
Epoch                          102
-----------------------------  ---------------------
2023-08-01 00:40:26.894612 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 103 finished
-----------------------------  --------------------
replay_buffer/size             521000
trainer/tdrp Loss              [3674.2542]
trainer/QF1 Loss               0.09373313
trainer/QF2 Loss               0.09881206
trainer/Policy Loss            -57.8991
trainer/Q1 Predictions Mean    68.96257
trainer/Q1 Predictions Std     4.800389
trainer/Q1 Predictions Max     77.79254
trainer/Q1 Predictions Min     50.834892
trainer/Q2 Predictions Mean    68.97577
trainer/Q2 Predictions Std     4.769346
trainer/Q2 Predictions Max     77.61274
trainer/Q2 Predictions Min     50.632843
trainer/Q Targets Mean         69.03209
trainer/Q Targets Std          4.7865543
trainer/Q Targets Max          77.713936
trainer/Q Targets Min          50.685135
trainer/Log Pis Mean           11.23717
trainer/Log Pis Std            7.3889627
trainer/Log Pis Max            32.98244
trainer/Log Pis Min            -5.0229635
trainer/Policy mu Mean         -0.024022438
trainer/Policy mu Std          1.6391487
trainer/Policy mu Max          4.244574
trainer/Policy mu Min          -4.8805137
trainer/Policy log std Mean    -0.5066554
trainer/Policy log std Std     0.1438379
trainer/Policy log std Max     0.028454542
trainer/Policy log std Min     -1.0289518
trainer/Alpha                  0.002859532367438078
trainer/Alpha Loss             -4.467930793762207
exploration/num steps total    521000
exploration/num paths total    1042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7087057943675724
exploration/Rewards Std        0.06721860460531515
exploration/Rewards Max        0.9669444112445476
exploration/Rewards Min        0.4907209455658807
exploration/Returns Mean       354.3528971837861
exploration/Returns Std        12.223944088584085
exploration/Returns Max        377.36990049847225
exploration/Returns Min        340.6591114839391
exploration/Actions Mean       0.044037033
exploration/Actions Std        0.6555556
exploration/Actions Max        0.99992895
exploration/Actions Min        -0.99985254
exploration/Num Paths          10
exploration/Average Returns    354.3528971837861
evaluation/num steps total     520000
evaluation/num paths total     1040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.709263390431317
evaluation/Rewards Std         0.05663496745631799
evaluation/Rewards Max         0.9497311882063668
evaluation/Rewards Min         0.4038687883083818
evaluation/Returns Mean        354.6316952156585
evaluation/Returns Std         14.030906006624258
evaluation/Returns Max         383.30295818507506
evaluation/Returns Min         333.0409362337378
evaluation/ExplReturns Mean    354.6316952156585
evaluation/ExplReturns Std     14.030906006624258
evaluation/ExplReturns Max     383.30295818507506
evaluation/ExplReturns Min     333.0409362337378
evaluation/Actions Mean        0.0078463685
evaluation/Actions Std         0.56467503
evaluation/Actions Max         0.9998441
evaluation/Actions Min         -0.9972449
evaluation/Num Paths           10
evaluation/Average Returns     354.6316952156585
time/data storing (s)          0.03425994887948036
time/evaluation sampling (s)   113.57440977077931
time/exploration sampling (s)  111.39000707212836
time/logging (s)               0.03115054313093424
time/saving (s)                0.012828615494072437
time/training (s)              9.495362043380737
time/epoch (s)                 234.5380179937929
time/total (s)                 24378.743819414638
Epoch                          103
-----------------------------  --------------------
2023-08-01 00:44:20.937252 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 104 finished
-----------------------------  ---------------------
replay_buffer/size             526000
trainer/tdrp Loss              [3717.9539]
trainer/QF1 Loss               0.12868941
trainer/QF2 Loss               0.10768375
trainer/Policy Loss            -56.612015
trainer/Q1 Predictions Mean    68.85545
trainer/Q1 Predictions Std     4.426704
trainer/Q1 Predictions Max     78.34574
trainer/Q1 Predictions Min     54.95272
trainer/Q2 Predictions Mean    68.802704
trainer/Q2 Predictions Std     4.4245963
trainer/Q2 Predictions Max     78.182884
trainer/Q2 Predictions Min     54.983437
trainer/Q Targets Mean         68.718216
trainer/Q Targets Std          4.4442244
trainer/Q Targets Max          78.25736
trainer/Q Targets Min          54.992306
trainer/Log Pis Mean           12.391759
trainer/Log Pis Std            7.964286
trainer/Log Pis Max            38.054886
trainer/Log Pis Min            -4.082097
trainer/Policy mu Mean         -0.086875044
trainer/Policy mu Std          1.6988031
trainer/Policy mu Max          4.245782
trainer/Policy mu Min          -4.3605194
trainer/Policy log std Mean    -0.5150252
trainer/Policy log std Std     0.12678443
trainer/Policy log std Max     -0.0040317774
trainer/Policy log std Min     -1.0344677
trainer/Alpha                  0.0028738784603774548
trainer/Alpha Loss             2.2926836013793945
exploration/num steps total    526000
exploration/num paths total    1052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7789888806861025
exploration/Rewards Std        0.1154625609542578
exploration/Rewards Max        0.976531109401546
exploration/Rewards Min        0.4785990342624475
exploration/Returns Mean       389.4944403430512
exploration/Returns Std        30.037164991733995
exploration/Returns Max        444.388350897179
exploration/Returns Min        345.81330485361036
exploration/Actions Mean       -0.0032291098
exploration/Actions Std        0.66236305
exploration/Actions Max        0.999873
exploration/Actions Min        -0.9997769
exploration/Num Paths          10
exploration/Average Returns    389.4944403430512
evaluation/num steps total     525000
evaluation/num paths total     1050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.760405207272858
evaluation/Rewards Std         0.1097897566667422
evaluation/Rewards Max         0.975834407880295
evaluation/Rewards Min         0.508764485561421
evaluation/Returns Mean        380.202603636429
evaluation/Returns Std         45.227005274143224
evaluation/Returns Max         457.0619059633297
evaluation/Returns Min         340.07912167970443
evaluation/ExplReturns Mean    380.202603636429
evaluation/ExplReturns Std     45.227005274143224
evaluation/ExplReturns Max     457.0619059633297
evaluation/ExplReturns Min     340.07912167970443
evaluation/Actions Mean        -0.06159366
evaluation/Actions Std         0.60519886
evaluation/Actions Max         0.99946856
evaluation/Actions Min         -0.9963456
evaluation/Num Paths           10
evaluation/Average Returns     380.202603636429
time/data storing (s)          0.034246508963406086
time/evaluation sampling (s)   112.16710005700588
time/exploration sampling (s)  112.52649976685643
time/logging (s)               0.0305605074390769
time/saving (s)                0.012232932262122631
time/training (s)              9.267550712451339
time/epoch (s)                 234.03819048497826
time/total (s)                 24612.784505076706
Epoch                          104
-----------------------------  ---------------------
2023-08-01 00:48:14.912469 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 105 finished
-----------------------------  --------------------
replay_buffer/size             531000
trainer/tdrp Loss              [3581.1362]
trainer/QF1 Loss               0.14536038
trainer/QF2 Loss               0.12278512
trainer/Policy Loss            -56.346848
trainer/Q1 Predictions Mean    69.12616
trainer/Q1 Predictions Std     4.523514
trainer/Q1 Predictions Max     78.60204
trainer/Q1 Predictions Min     52.08589
trainer/Q2 Predictions Mean    68.977295
trainer/Q2 Predictions Std     4.543532
trainer/Q2 Predictions Max     78.604256
trainer/Q2 Predictions Min     52.333733
trainer/Q Targets Mean         68.93901
trainer/Q Targets Std          4.5107083
trainer/Q Targets Max          78.53381
trainer/Q Targets Min          52.310955
trainer/Log Pis Mean           12.860235
trainer/Log Pis Std            7.698945
trainer/Log Pis Max            33.396103
trainer/Log Pis Min            -6.8863363
trainer/Policy mu Mean         -0.06105115
trainer/Policy mu Std          1.6902934
trainer/Policy mu Max          5.6883755
trainer/Policy mu Min          -4.428257
trainer/Policy log std Mean    -0.5233293
trainer/Policy log std Std     0.1392366
trainer/Policy log std Max     0.05094397
trainer/Policy log std Min     -1.1258699
trainer/Alpha                  0.002848888048902154
trainer/Alpha Loss             5.0416789054870605
exploration/num steps total    531000
exploration/num paths total    1062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7231330259085944
exploration/Rewards Std        0.07365528521591785
exploration/Rewards Max        0.9710954526003601
exploration/Rewards Min        0.5059704264219754
exploration/Returns Mean       361.56651295429725
exploration/Returns Std        20.889734276081814
exploration/Returns Max        417.4629529566277
exploration/Returns Min        343.54066923779106
exploration/Actions Mean       0.011369399
exploration/Actions Std        0.6344398
exploration/Actions Max        0.9998134
exploration/Actions Min        -0.9994891
exploration/Num Paths          10
exploration/Average Returns    361.56651295429725
evaluation/num steps total     530000
evaluation/num paths total     1060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8133366435164979
evaluation/Rewards Std         0.11733213855947702
evaluation/Rewards Max         0.9524370551381764
evaluation/Rewards Min         0.5070373401768902
evaluation/Returns Mean        406.66832175824896
evaluation/Returns Std         49.75319532270802
evaluation/Returns Max         462.0947400611945
evaluation/Returns Min         355.253513483549
evaluation/ExplReturns Mean    406.66832175824896
evaluation/ExplReturns Std     49.75319532270802
evaluation/ExplReturns Max     462.0947400611945
evaluation/ExplReturns Min     355.253513483549
evaluation/Actions Mean        0.059300512
evaluation/Actions Std         0.5472949
evaluation/Actions Max         0.9965322
evaluation/Actions Min         -0.99696094
evaluation/Num Paths           10
evaluation/Average Returns     406.66832175824896
time/data storing (s)          0.03421376831829548
time/evaluation sampling (s)   112.4807489560917
time/exploration sampling (s)  112.03757127001882
time/logging (s)               0.030565583147108555
time/saving (s)                0.01121072843670845
time/training (s)              9.376909346319735
time/epoch (s)                 233.97121965233237
time/total (s)                 24846.75840437319
Epoch                          105
-----------------------------  --------------------
2023-08-01 00:52:11.197544 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 106 finished
-----------------------------  ---------------------
replay_buffer/size             536000
trainer/tdrp Loss              [3796.0066]
trainer/QF1 Loss               0.13524339
trainer/QF2 Loss               0.14277408
trainer/Policy Loss            -57.384117
trainer/Q1 Predictions Mean    69.20978
trainer/Q1 Predictions Std     5.158898
trainer/Q1 Predictions Max     78.76211
trainer/Q1 Predictions Min     49.24001
trainer/Q2 Predictions Mean    69.16977
trainer/Q2 Predictions Std     5.1734014
trainer/Q2 Predictions Max     78.79459
trainer/Q2 Predictions Min     48.775402
trainer/Q Targets Mean         69.25063
trainer/Q Targets Std          5.1608543
trainer/Q Targets Max          78.96592
trainer/Q Targets Min          49.01728
trainer/Log Pis Mean           11.961656
trainer/Log Pis Std            8.010351
trainer/Log Pis Max            46.877228
trainer/Log Pis Min            -3.6677983
trainer/Policy mu Mean         -0.17038178
trainer/Policy mu Std          1.6693429
trainer/Policy mu Max          5.143261
trainer/Policy mu Min          -4.8875556
trainer/Policy log std Mean    -0.5141001
trainer/Policy log std Std     0.13451311
trainer/Policy log std Max     0.021834493
trainer/Policy log std Min     -1.0466431
trainer/Alpha                  0.0027952075470238924
trainer/Alpha Loss             -0.22545671463012695
exploration/num steps total    536000
exploration/num paths total    1072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7992514187013244
exploration/Rewards Std        0.1270197800379387
exploration/Rewards Max        0.9729750875685945
exploration/Rewards Min        0.5041633513845764
exploration/Returns Mean       399.6257093506621
exploration/Returns Std        35.7726709910773
exploration/Returns Max        443.3268691002318
exploration/Returns Min        345.6485525703012
exploration/Actions Mean       0.0901847
exploration/Actions Std        0.63758534
exploration/Actions Max        0.99973553
exploration/Actions Min        -0.99991226
exploration/Num Paths          10
exploration/Average Returns    399.6257093506621
evaluation/num steps total     535000
evaluation/num paths total     1070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.805146404711147
evaluation/Rewards Std         0.1285973009036051
evaluation/Rewards Max         0.9690685545634751
evaluation/Rewards Min         0.4724917269437569
evaluation/Returns Mean        402.5732023555735
evaluation/Returns Std         41.02701190785769
evaluation/Returns Max         459.00838356714996
evaluation/Returns Min         348.3472232467611
evaluation/ExplReturns Mean    402.5732023555735
evaluation/ExplReturns Std     41.02701190785769
evaluation/ExplReturns Max     459.00838356714996
evaluation/ExplReturns Min     348.3472232467611
evaluation/Actions Mean        0.08157328
evaluation/Actions Std         0.581421
evaluation/Actions Max         0.9984553
evaluation/Actions Min         -0.9988901
evaluation/Num Paths           10
evaluation/Average Returns     402.5732023555735
time/data storing (s)          0.034285761415958405
time/evaluation sampling (s)   113.21372386347502
time/exploration sampling (s)  113.44910693820566
time/logging (s)               0.0302937850356102
time/saving (s)                0.011035698466002941
time/training (s)              9.542517603375018
time/epoch (s)                 236.28096364997327
time/total (s)                 25083.041847378016
Epoch                          106
-----------------------------  ---------------------
2023-08-01 00:56:07.841427 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 107 finished
-----------------------------  --------------------
replay_buffer/size             541000
trainer/tdrp Loss              [3792.8179]
trainer/QF1 Loss               0.09359002
trainer/QF2 Loss               0.12001047
trainer/Policy Loss            -57.764595
trainer/Q1 Predictions Mean    69.23916
trainer/Q1 Predictions Std     4.6442056
trainer/Q1 Predictions Max     78.291084
trainer/Q1 Predictions Min     55.350967
trainer/Q2 Predictions Mean    69.24364
trainer/Q2 Predictions Std     4.6258497
trainer/Q2 Predictions Max     78.15142
trainer/Q2 Predictions Min     55.678158
trainer/Q Targets Mean         69.24854
trainer/Q Targets Std          4.590929
trainer/Q Targets Max          78.87847
trainer/Q Targets Min          55.83516
trainer/Log Pis Mean           11.655783
trainer/Log Pis Std            7.590709
trainer/Log Pis Max            37.10274
trainer/Log Pis Min            -3.2084758
trainer/Policy mu Mean         -0.106785156
trainer/Policy mu Std          1.6601961
trainer/Policy mu Max          4.3026934
trainer/Policy mu Min          -4.961789
trainer/Policy log std Mean    -0.52452785
trainer/Policy log std Std     0.14209078
trainer/Policy log std Max     0.021041185
trainer/Policy log std Min     -1.1012365
trainer/Alpha                  0.002860912587493658
trainer/Alpha Loss             -2.015929698944092
exploration/num steps total    541000
exploration/num paths total    1082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7577005633522469
exploration/Rewards Std        0.1056609165545028
exploration/Rewards Max        0.9752994817088707
exploration/Rewards Min        0.4704271416911695
exploration/Returns Mean       378.85028167612353
exploration/Returns Std        30.61440604830193
exploration/Returns Max        441.5100911089265
exploration/Returns Min        348.5568724925575
exploration/Actions Mean       0.048821334
exploration/Actions Std        0.67015123
exploration/Actions Max        0.9998425
exploration/Actions Min        -0.9996282
exploration/Num Paths          10
exploration/Average Returns    378.85028167612353
evaluation/num steps total     540000
evaluation/num paths total     1080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7060265673756876
evaluation/Rewards Std         0.027234249546095345
evaluation/Rewards Max         0.9323915695924921
evaluation/Rewards Min         0.5118001549842169
evaluation/Returns Mean        353.0132836878439
evaluation/Returns Std         2.742589185914534
evaluation/Returns Max         359.80893924674143
evaluation/Returns Min         349.89118270206643
evaluation/ExplReturns Mean    353.0132836878439
evaluation/ExplReturns Std     2.742589185914534
evaluation/ExplReturns Max     359.80893924674143
evaluation/ExplReturns Min     349.89118270206643
evaluation/Actions Mean        0.057525
evaluation/Actions Std         0.5728058
evaluation/Actions Max         0.99967104
evaluation/Actions Min         -0.9959594
evaluation/Num Paths           10
evaluation/Average Returns     353.0132836878439
time/data storing (s)          0.03408328630030155
time/evaluation sampling (s)   113.13380301650614
time/exploration sampling (s)  113.90857570245862
time/logging (s)               0.030656082555651665
time/saving (s)                0.01277184672653675
time/training (s)              9.520420458167791
time/epoch (s)                 236.64031039271504
time/total (s)                 25319.684724704362
Epoch                          107
-----------------------------  --------------------
2023-08-01 01:00:02.792397 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 108 finished
-----------------------------  ---------------------
replay_buffer/size             546000
trainer/tdrp Loss              [3774.3894]
trainer/QF1 Loss               0.15581578
trainer/QF2 Loss               0.121606655
trainer/Policy Loss            -56.4675
trainer/Q1 Predictions Mean    68.63237
trainer/Q1 Predictions Std     5.566471
trainer/Q1 Predictions Max     78.85609
trainer/Q1 Predictions Min     44.444817
trainer/Q2 Predictions Mean    68.68266
trainer/Q2 Predictions Std     5.6225977
trainer/Q2 Predictions Max     78.993904
trainer/Q2 Predictions Min     43.949646
trainer/Q Targets Mean         68.83904
trainer/Q Targets Std          5.638236
trainer/Q Targets Max          79.300285
trainer/Q Targets Min          44.42957
trainer/Log Pis Mean           12.354582
trainer/Log Pis Std            7.6752806
trainer/Log Pis Max            42.86404
trainer/Log Pis Min            -6.5968494
trainer/Policy mu Mean         -0.05220622
trainer/Policy mu Std          1.7044042
trainer/Policy mu Max          4.6407814
trainer/Policy mu Min          -5.5982695
trainer/Policy log std Mean    -0.51707405
trainer/Policy log std Std     0.14066362
trainer/Policy log std Max     0.07864115
trainer/Policy log std Min     -1.1126544
trainer/Alpha                  0.0028923016507178545
trainer/Alpha Loss             2.0727169513702393
exploration/num steps total    546000
exploration/num paths total    1092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7606929614859163
exploration/Rewards Std        0.09289593159679553
exploration/Rewards Max        0.9738195480384862
exploration/Rewards Min        0.5016333696348184
exploration/Returns Mean       380.346480742958
exploration/Returns Std        21.801512238199113
exploration/Returns Max        403.1027748078843
exploration/Returns Min        346.3382739595961
exploration/Actions Mean       -0.028147416
exploration/Actions Std        0.63499475
exploration/Actions Max        0.99981767
exploration/Actions Min        -0.9995868
exploration/Num Paths          10
exploration/Average Returns    380.346480742958
evaluation/num steps total     545000
evaluation/num paths total     1090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7023175016777925
evaluation/Rewards Std         0.03770745396991029
evaluation/Rewards Max         0.945395242036701
evaluation/Rewards Min         0.5059127242023415
evaluation/Returns Mean        351.15875083889614
evaluation/Returns Std         9.476398660905357
evaluation/Returns Max         366.7927303827729
evaluation/Returns Min         342.0486817831368
evaluation/ExplReturns Mean    351.15875083889614
evaluation/ExplReturns Std     9.476398660905357
evaluation/ExplReturns Max     366.7927303827729
evaluation/ExplReturns Min     342.0486817831368
evaluation/Actions Mean        -0.010339976
evaluation/Actions Std         0.55081457
evaluation/Actions Max         0.99525154
evaluation/Actions Min         -0.9958752
evaluation/Num Paths           10
evaluation/Average Returns     351.15875083889614
time/data storing (s)          0.034248411655426025
time/evaluation sampling (s)   112.65560863167048
time/exploration sampling (s)  112.60937066469342
time/logging (s)               0.030459132976830006
time/saving (s)                0.0112982876598835
time/training (s)              9.605933094397187
time/epoch (s)                 234.94691822305322
time/total (s)                 25554.634147504345
Epoch                          108
-----------------------------  ---------------------
2023-08-01 01:03:58.426756 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 109 finished
-----------------------------  ---------------------
replay_buffer/size             551000
trainer/tdrp Loss              [3815.4702]
trainer/QF1 Loss               0.1829653
trainer/QF2 Loss               0.1292303
trainer/Policy Loss            -58.837044
trainer/Q1 Predictions Mean    70.578384
trainer/Q1 Predictions Std     4.4357243
trainer/Q1 Predictions Max     79.93419
trainer/Q1 Predictions Min     56.76956
trainer/Q2 Predictions Mean    70.44886
trainer/Q2 Predictions Std     4.4163365
trainer/Q2 Predictions Max     79.7966
trainer/Q2 Predictions Min     56.26118
trainer/Q Targets Mean         70.34569
trainer/Q Targets Std          4.4578843
trainer/Q Targets Max          79.92611
trainer/Q Targets Min          55.61377
trainer/Log Pis Mean           11.834302
trainer/Log Pis Std            7.4824886
trainer/Log Pis Max            33.42535
trainer/Log Pis Min            -8.898061
trainer/Policy mu Mean         -0.093498506
trainer/Policy mu Std          1.6669319
trainer/Policy mu Max          4.516414
trainer/Policy mu Min          -4.546136
trainer/Policy log std Mean    -0.5340206
trainer/Policy log std Std     0.13283539
trainer/Policy log std Max     0.022374362
trainer/Policy log std Min     -1.0504159
trainer/Alpha                  0.0028407720383256674
trainer/Alpha Loss             -0.9715747833251953
exploration/num steps total    551000
exploration/num paths total    1102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7818782168036489
exploration/Rewards Std        0.11371418588916356
exploration/Rewards Max        0.9746138842381038
exploration/Rewards Min        0.5082977831108607
exploration/Returns Mean       390.9391084018244
exploration/Returns Std        39.274516306964436
exploration/Returns Max        448.66906740296355
exploration/Returns Min        350.4432566006078
exploration/Actions Mean       -0.04579731
exploration/Actions Std        0.651431
exploration/Actions Max        0.9999192
exploration/Actions Min        -0.99990857
exploration/Num Paths          10
exploration/Average Returns    390.9391084018244
evaluation/num steps total     550000
evaluation/num paths total     1100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8479645212528052
evaluation/Rewards Std         0.12520700536911275
evaluation/Rewards Max         0.9752834350187108
evaluation/Rewards Min         0.49462492407189756
evaluation/Returns Mean        423.9822606264026
evaluation/Returns Std         13.444354536761235
evaluation/Returns Max         447.3983030627284
evaluation/Returns Min         400.92949638289684
evaluation/ExplReturns Mean    423.9822606264026
evaluation/ExplReturns Std     13.444354536761235
evaluation/ExplReturns Max     447.3983030627284
evaluation/ExplReturns Min     400.92949638289684
evaluation/Actions Mean        -0.04740676
evaluation/Actions Std         0.59321666
evaluation/Actions Max         0.99963963
evaluation/Actions Min         -0.9985512
evaluation/Num Paths           10
evaluation/Average Returns     423.9822606264026
time/data storing (s)          0.034266198985278606
time/evaluation sampling (s)   113.09584956429899
time/exploration sampling (s)  112.52682091668248
time/logging (s)               0.030785766430199146
time/saving (s)                0.010401667095720768
time/training (s)              9.932674437761307
time/epoch (s)                 235.63079855125397
time/total (s)                 25790.26743164379
Epoch                          109
-----------------------------  ---------------------
2023-08-01 01:07:51.459741 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 110 finished
-----------------------------  ---------------------
replay_buffer/size             556000
trainer/tdrp Loss              [3682.3599]
trainer/QF1 Loss               0.1425465
trainer/QF2 Loss               0.1419146
trainer/Policy Loss            -58.047615
trainer/Q1 Predictions Mean    70.20537
trainer/Q1 Predictions Std     4.667873
trainer/Q1 Predictions Max     79.66393
trainer/Q1 Predictions Min     56.793056
trainer/Q2 Predictions Mean    70.19893
trainer/Q2 Predictions Std     4.6900535
trainer/Q2 Predictions Max     79.61468
trainer/Q2 Predictions Min     56.894543
trainer/Q Targets Mean         70.11932
trainer/Q Targets Std          4.7071238
trainer/Q Targets Max          79.62378
trainer/Q Targets Min          56.73674
trainer/Log Pis Mean           12.322521
trainer/Log Pis Std            7.586027
trainer/Log Pis Max            49.637215
trainer/Log Pis Min            -4.882268
trainer/Policy mu Mean         0.07240782
trainer/Policy mu Std          1.7011981
trainer/Policy mu Max          4.525672
trainer/Policy mu Min          -7.7819138
trainer/Policy log std Mean    -0.52972037
trainer/Policy log std Std     0.14510328
trainer/Policy log std Max     0.15361518
trainer/Policy log std Min     -1.1434505
trainer/Alpha                  0.0028277896344661713
trainer/Alpha Loss             1.8926551342010498
exploration/num steps total    556000
exploration/num paths total    1112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7335988003094089
exploration/Rewards Std        0.05411419747021218
exploration/Rewards Max        0.9721838668970927
exploration/Rewards Min        0.5104997137917531
exploration/Returns Mean       366.7994001547044
exploration/Returns Std        18.066977591125156
exploration/Returns Max        420.7896886794531
exploration/Returns Min        356.23215510355703
exploration/Actions Mean       0.10757335
exploration/Actions Std        0.62362444
exploration/Actions Max        0.9997794
exploration/Actions Min        -0.999464
exploration/Num Paths          10
exploration/Average Returns    366.7994001547044
evaluation/num steps total     555000
evaluation/num paths total     1110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7480785716223927
evaluation/Rewards Std         0.07785702875367463
evaluation/Rewards Max         0.9699762784608391
evaluation/Rewards Min         0.5123183412324892
evaluation/Returns Mean        374.0392858111963
evaluation/Returns Std         29.299467871441973
evaluation/Returns Max         454.00744189841737
evaluation/Returns Min         357.84127815886524
evaluation/ExplReturns Mean    374.0392858111963
evaluation/ExplReturns Std     29.299467871441973
evaluation/ExplReturns Max     454.00744189841737
evaluation/ExplReturns Min     357.84127815886524
evaluation/Actions Mean        0.07918977
evaluation/Actions Std         0.5134213
evaluation/Actions Max         0.99897027
evaluation/Actions Min         -0.99667126
evaluation/Num Paths           10
evaluation/Average Returns     374.0392858111963
time/data storing (s)          0.034646378830075264
time/evaluation sampling (s)   112.45439950469881
time/exploration sampling (s)  111.5657211272046
time/logging (s)               0.030908871442079544
time/saving (s)                0.012755364179611206
time/training (s)              8.93054467625916
time/epoch (s)                 233.02897592261434
time/total (s)                 26023.299109389074
Epoch                          110
-----------------------------  ---------------------
2023-08-01 01:11:48.140513 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 111 finished
-----------------------------  ---------------------
replay_buffer/size             561000
trainer/tdrp Loss              [3717.328]
trainer/QF1 Loss               0.14513119
trainer/QF2 Loss               0.13014553
trainer/Policy Loss            -57.31285
trainer/Q1 Predictions Mean    69.85221
trainer/Q1 Predictions Std     4.9036617
trainer/Q1 Predictions Max     79.85453
trainer/Q1 Predictions Min     53.9258
trainer/Q2 Predictions Mean    69.8743
trainer/Q2 Predictions Std     4.877752
trainer/Q2 Predictions Max     79.82394
trainer/Q2 Predictions Min     53.640255
trainer/Q Targets Mean         69.88315
trainer/Q Targets Std          4.885641
trainer/Q Targets Max          80.00096
trainer/Q Targets Min          53.9459
trainer/Log Pis Mean           12.749554
trainer/Log Pis Std            7.801879
trainer/Log Pis Max            43.210632
trainer/Log Pis Min            -1.9592035
trainer/Policy mu Mean         0.023807565
trainer/Policy mu Std          1.7315784
trainer/Policy mu Max          5.545514
trainer/Policy mu Min          -4.1237288
trainer/Policy log std Mean    -0.53037477
trainer/Policy log std Std     0.14039344
trainer/Policy log std Max     0.005252242
trainer/Policy log std Min     -1.0888561
trainer/Alpha                  0.0028846741188317537
trainer/Alpha Loss             4.383790969848633
exploration/num steps total    561000
exploration/num paths total    1122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7100631668866427
exploration/Rewards Std        0.03954891791378761
exploration/Rewards Max        0.9552885453494414
exploration/Rewards Min        0.5062593769657311
exploration/Returns Mean       355.03158344332144
exploration/Returns Std        7.1440030118862206
exploration/Returns Max        372.1840295603458
exploration/Returns Min        347.40539270790237
exploration/Actions Mean       -0.054823894
exploration/Actions Std        0.6240079
exploration/Actions Max        0.99981666
exploration/Actions Min        -0.99942774
exploration/Num Paths          10
exploration/Average Returns    355.03158344332144
evaluation/num steps total     560000
evaluation/num paths total     1120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7176917268330815
evaluation/Rewards Std         0.06143993382916691
evaluation/Rewards Max         0.9473498998458043
evaluation/Rewards Min         0.5004317374679087
evaluation/Returns Mean        358.84586341654074
evaluation/Returns Std         16.74231428157421
evaluation/Returns Max         372.7951433372453
evaluation/Returns Min         317.76205251328963
evaluation/ExplReturns Mean    358.84586341654074
evaluation/ExplReturns Std     16.74231428157421
evaluation/ExplReturns Max     372.7951433372453
evaluation/ExplReturns Min     317.76205251328963
evaluation/Actions Mean        0.026926361
evaluation/Actions Std         0.6178695
evaluation/Actions Max         0.9993818
evaluation/Actions Min         -0.9992481
evaluation/Num Paths           10
evaluation/Average Returns     358.84586341654074
time/data storing (s)          0.034144673496484756
time/evaluation sampling (s)   114.45184777956456
time/exploration sampling (s)  112.12109907157719
time/logging (s)               0.0306005934253335
time/saving (s)                0.012449948117136955
time/training (s)              10.026288310065866
time/epoch (s)                 236.67643037624657
time/total (s)                 26259.978184059262
Epoch                          111
-----------------------------  ---------------------
2023-08-01 01:15:42.818587 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 112 finished
-----------------------------  --------------------
replay_buffer/size             566000
trainer/tdrp Loss              [3509.5198]
trainer/QF1 Loss               0.112473935
trainer/QF2 Loss               0.11839025
trainer/Policy Loss            -59.305656
trainer/Q1 Predictions Mean    70.70706
trainer/Q1 Predictions Std     5.1382346
trainer/Q1 Predictions Max     80.11802
trainer/Q1 Predictions Min     50.6072
trainer/Q2 Predictions Mean    70.67958
trainer/Q2 Predictions Std     5.147567
trainer/Q2 Predictions Max     80.059685
trainer/Q2 Predictions Min     50.693874
trainer/Q Targets Mean         70.763565
trainer/Q Targets Std          5.2061567
trainer/Q Targets Max          80.4435
trainer/Q Targets Min          50.723705
trainer/Log Pis Mean           11.521963
trainer/Log Pis Std            7.8322535
trainer/Log Pis Max            34.58931
trainer/Log Pis Min            -9.09728
trainer/Policy mu Mean         0.01678788
trainer/Policy mu Std          1.6405759
trainer/Policy mu Max          5.999934
trainer/Policy mu Min          -4.3819814
trainer/Policy log std Mean    -0.5321801
trainer/Policy log std Std     0.14169918
trainer/Policy log std Max     0.28371
trainer/Policy log std Min     -1.1031928
trainer/Alpha                  0.002910877577960491
trainer/Alpha Loss             -2.7913737297058105
exploration/num steps total    566000
exploration/num paths total    1132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7948506587017243
exploration/Rewards Std        0.11561709838120447
exploration/Rewards Max        0.9705221816834627
exploration/Rewards Min        0.5028678556856899
exploration/Returns Mean       397.42532935086217
exploration/Returns Std        21.09362722801626
exploration/Returns Max        427.6253774689041
exploration/Returns Min        357.9208194383585
exploration/Actions Mean       0.027524376
exploration/Actions Std        0.62360364
exploration/Actions Max        0.9997754
exploration/Actions Min        -0.99990517
exploration/Num Paths          10
exploration/Average Returns    397.42532935086217
evaluation/num steps total     565000
evaluation/num paths total     1130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7729155501144364
evaluation/Rewards Std         0.11684320675366479
evaluation/Rewards Max         0.9509166581525641
evaluation/Rewards Min         0.4993094876019446
evaluation/Returns Mean        386.4577750572183
evaluation/Returns Std         36.32492666745749
evaluation/Returns Max         431.5133524793703
evaluation/Returns Min         343.56539365650036
evaluation/ExplReturns Mean    386.4577750572183
evaluation/ExplReturns Std     36.32492666745749
evaluation/ExplReturns Max     431.5133524793703
evaluation/ExplReturns Min     343.56539365650036
evaluation/Actions Mean        0.02438993
evaluation/Actions Std         0.4690829
evaluation/Actions Max         0.9974735
evaluation/Actions Min         -0.99793714
evaluation/Num Paths           10
evaluation/Average Returns     386.4577750572183
time/data storing (s)          0.03409159369766712
time/evaluation sampling (s)   112.792997864075
time/exploration sampling (s)  112.27969227451831
time/logging (s)               0.030918225646018982
time/saving (s)                0.010895670391619205
time/training (s)              9.525820801965892
time/epoch (s)                 234.6744164302945
time/total (s)                 26494.65515587479
Epoch                          112
-----------------------------  --------------------
2023-08-01 01:19:38.759968 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 113 finished
-----------------------------  ---------------------
replay_buffer/size             571000
trainer/tdrp Loss              [3403.3333]
trainer/QF1 Loss               0.15020904
trainer/QF2 Loss               0.12719053
trainer/Policy Loss            -59.593674
trainer/Q1 Predictions Mean    70.84181
trainer/Q1 Predictions Std     4.667333
trainer/Q1 Predictions Max     80.80544
trainer/Q1 Predictions Min     50.834286
trainer/Q2 Predictions Mean    70.77309
trainer/Q2 Predictions Std     4.642402
trainer/Q2 Predictions Max     80.56905
trainer/Q2 Predictions Min     51.015026
trainer/Q Targets Mean         70.78879
trainer/Q Targets Std          4.674047
trainer/Q Targets Max          80.68694
trainer/Q Targets Min          51.048447
trainer/Log Pis Mean           11.344425
trainer/Log Pis Std            7.22746
trainer/Log Pis Max            33.05547
trainer/Log Pis Min            -7.6375656
trainer/Policy mu Mean         -0.09337313
trainer/Policy mu Std          1.6501409
trainer/Policy mu Max          4.580565
trainer/Policy mu Min          -4.1826143
trainer/Policy log std Mean    -0.52012235
trainer/Policy log std Std     0.1405922
trainer/Policy log std Max     0.13278806
trainer/Policy log std Min     -1.1353843
trainer/Alpha                  0.0029502699617296457
trainer/Alpha Loss             -3.8192789554595947
exploration/num steps total    571000
exploration/num paths total    1142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7232995604555555
exploration/Rewards Std        0.061225795304867
exploration/Rewards Max        0.9746731324647211
exploration/Rewards Min        0.5113518156356384
exploration/Returns Mean       361.6497802277779
exploration/Returns Std        21.841165386220307
exploration/Returns Max        427.05127664373094
exploration/Returns Min        351.6294012798413
exploration/Actions Mean       -0.014556729
exploration/Actions Std        0.6425512
exploration/Actions Max        0.9994764
exploration/Actions Min        -0.99998814
exploration/Num Paths          10
exploration/Average Returns    361.6497802277779
evaluation/num steps total     570000
evaluation/num paths total     1140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7089674970881861
evaluation/Rewards Std         0.013724121064580999
evaluation/Rewards Max         0.7400217290998721
evaluation/Rewards Min         0.512553402472349
evaluation/Returns Mean        354.48374854409315
evaluation/Returns Std         1.8567573235741135
evaluation/Returns Max         357.30311273912287
evaluation/Returns Min         351.57111234903334
evaluation/ExplReturns Mean    354.48374854409315
evaluation/ExplReturns Std     1.8567573235741135
evaluation/ExplReturns Max     357.30311273912287
evaluation/ExplReturns Min     351.57111234903334
evaluation/Actions Mean        -0.035535526
evaluation/Actions Std         0.44713932
evaluation/Actions Max         0.990159
evaluation/Actions Min         -0.9992837
evaluation/Num Paths           10
evaluation/Average Returns     354.48374854409315
time/data storing (s)          0.03431203402578831
time/evaluation sampling (s)   113.84363794140518
time/exploration sampling (s)  112.52818733919412
time/logging (s)               0.030456004664301872
time/saving (s)                0.012519472278654575
time/training (s)              9.487934627570212
time/epoch (s)                 235.93704741913825
time/total (s)                 26730.594662453048
Epoch                          113
-----------------------------  ---------------------
2023-08-01 01:23:34.504160 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 114 finished
-----------------------------  ---------------------
replay_buffer/size             576000
trainer/tdrp Loss              [3677.1614]
trainer/QF1 Loss               0.12844709
trainer/QF2 Loss               0.10698728
trainer/Policy Loss            -59.99648
trainer/Q1 Predictions Mean    71.225235
trainer/Q1 Predictions Std     4.885866
trainer/Q1 Predictions Max     81.04383
trainer/Q1 Predictions Min     47.25236
trainer/Q2 Predictions Mean    71.21817
trainer/Q2 Predictions Std     4.86787
trainer/Q2 Predictions Max     81.04965
trainer/Q2 Predictions Min     47.481106
trainer/Q Targets Mean         71.071655
trainer/Q Targets Std          4.8733044
trainer/Q Targets Max          81.09441
trainer/Q Targets Min          47.894825
trainer/Log Pis Mean           11.376638
trainer/Log Pis Std            6.9486995
trainer/Log Pis Max            35.169613
trainer/Log Pis Min            -3.9232092
trainer/Policy mu Mean         0.12552166
trainer/Policy mu Std          1.6240333
trainer/Policy mu Max          4.765228
trainer/Policy mu Min          -4.2305536
trainer/Policy log std Mean    -0.54447585
trainer/Policy log std Std     0.13368706
trainer/Policy log std Max     -0.044024274
trainer/Policy log std Min     -1.1426911
trainer/Alpha                  0.0029049429576843977
trainer/Alpha Loss             -3.641284704208374
exploration/num steps total    576000
exploration/num paths total    1152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9003109993447084
exploration/Rewards Std        0.10814964898953713
exploration/Rewards Max        0.9790124883900735
exploration/Rewards Min        0.5156334852398538
exploration/Returns Mean       450.1554996723541
exploration/Returns Std        6.274766338352184
exploration/Returns Max        457.2038238370608
exploration/Returns Min        434.7268374521159
exploration/Actions Mean       0.07723616
exploration/Actions Std        0.6421481
exploration/Actions Max        0.9998516
exploration/Actions Min        -0.99947727
exploration/Num Paths          10
exploration/Average Returns    450.1554996723541
evaluation/num steps total     575000
evaluation/num paths total     1150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7593907577246287
evaluation/Rewards Std         0.11051412070008852
evaluation/Rewards Max         0.9732589367399413
evaluation/Rewards Min         0.4782003392556969
evaluation/Returns Mean        379.69537886231427
evaluation/Returns Std         46.102033394519275
evaluation/Returns Max         452.6502146201142
evaluation/Returns Min         338.1503510047565
evaluation/ExplReturns Mean    379.69537886231427
evaluation/ExplReturns Std     46.102033394519275
evaluation/ExplReturns Max     452.6502146201142
evaluation/ExplReturns Min     338.1503510047565
evaluation/Actions Mean        0.04461792
evaluation/Actions Std         0.5380727
evaluation/Actions Max         0.9997419
evaluation/Actions Min         -0.99900764
evaluation/Num Paths           10
evaluation/Average Returns     379.69537886231427
time/data storing (s)          0.034655697643756866
time/evaluation sampling (s)   112.67466421239078
time/exploration sampling (s)  113.46470310539007
time/logging (s)               0.030518190935254097
time/saving (s)                0.01141724456101656
time/training (s)              9.524381914176047
time/epoch (s)                 235.74034036509693
time/total (s)                 26966.33751710225
Epoch                          114
-----------------------------  ---------------------
2023-08-01 01:27:28.676373 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 115 finished
-----------------------------  ---------------------
replay_buffer/size             581000
trainer/tdrp Loss              [3341.3105]
trainer/QF1 Loss               0.12270791
trainer/QF2 Loss               0.12586267
trainer/Policy Loss            -58.658707
trainer/Q1 Predictions Mean    70.813095
trainer/Q1 Predictions Std     4.8361125
trainer/Q1 Predictions Max     81.03229
trainer/Q1 Predictions Min     50.164543
trainer/Q2 Predictions Mean    70.77245
trainer/Q2 Predictions Std     4.82436
trainer/Q2 Predictions Max     80.94139
trainer/Q2 Predictions Min     50.42308
trainer/Q Targets Mean         70.89762
trainer/Q Targets Std          4.831658
trainer/Q Targets Max          81.23451
trainer/Q Targets Min          50.355637
trainer/Log Pis Mean           12.321002
trainer/Log Pis Std            6.802434
trainer/Log Pis Max            36.35393
trainer/Log Pis Min            -4.788618
trainer/Policy mu Mean         -0.075091146
trainer/Policy mu Std          1.6954073
trainer/Policy mu Max          5.4490256
trainer/Policy mu Min          -5.567668
trainer/Policy log std Mean    -0.52652097
trainer/Policy log std Std     0.13254164
trainer/Policy log std Max     -0.01200968
trainer/Policy log std Min     -1.1433039
trainer/Alpha                  0.0029347194358706474
trainer/Alpha Loss             1.8718411922454834
exploration/num steps total    581000
exploration/num paths total    1162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8968923706909916
exploration/Rewards Std        0.10394945706033488
exploration/Rewards Max        0.9770668418234465
exploration/Rewards Min        0.5069088226185865
exploration/Returns Mean       448.4461853454958
exploration/Returns Std        11.09512525067962
exploration/Returns Max        462.9556011744937
exploration/Returns Min        422.87615540859673
exploration/Actions Mean       0.0633744
exploration/Actions Std        0.64787847
exploration/Actions Max        0.9998791
exploration/Actions Min        -0.9999769
exploration/Num Paths          10
exploration/Average Returns    448.4461853454958
evaluation/num steps total     580000
evaluation/num paths total     1160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.851574782803378
evaluation/Rewards Std         0.125266971482845
evaluation/Rewards Max         0.9730668490606773
evaluation/Rewards Min         0.5058949003242091
evaluation/Returns Mean        425.7873914016888
evaluation/Returns Std         49.032241771997846
evaluation/Returns Max         466.0785642344734
evaluation/Returns Min         346.8336016780788
evaluation/ExplReturns Mean    425.7873914016888
evaluation/ExplReturns Std     49.032241771997846
evaluation/ExplReturns Max     466.0785642344734
evaluation/ExplReturns Min     346.8336016780788
evaluation/Actions Mean        0.07345604
evaluation/Actions Std         0.59052944
evaluation/Actions Max         0.99792236
evaluation/Actions Min         -0.9997222
evaluation/Num Paths           10
evaluation/Average Returns     425.7873914016888
time/data storing (s)          0.034208258613944054
time/evaluation sampling (s)   112.19234495889395
time/exploration sampling (s)  112.35820993036032
time/logging (s)               0.0306568406522274
time/saving (s)                0.012521404772996902
time/training (s)              9.540486061014235
time/epoch (s)                 234.16842745430768
time/total (s)                 27200.508445120417
Epoch                          115
-----------------------------  ---------------------
2023-08-01 01:31:21.580343 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 116 finished
-----------------------------  --------------------
replay_buffer/size             586000
trainer/tdrp Loss              [3706.6858]
trainer/QF1 Loss               0.1425596
trainer/QF2 Loss               0.12031536
trainer/Policy Loss            -58.995506
trainer/Q1 Predictions Mean    71.23209
trainer/Q1 Predictions Std     5.5257325
trainer/Q1 Predictions Max     81.430954
trainer/Q1 Predictions Min     47.37253
trainer/Q2 Predictions Mean    71.23369
trainer/Q2 Predictions Std     5.4997573
trainer/Q2 Predictions Max     81.420616
trainer/Q2 Predictions Min     47.874195
trainer/Q Targets Mean         71.108894
trainer/Q Targets Std          5.522374
trainer/Q Targets Max          81.44878
trainer/Q Targets Min          47.25951
trainer/Log Pis Mean           12.4051
trainer/Log Pis Std            7.659423
trainer/Log Pis Max            32.87478
trainer/Log Pis Min            -7.566016
trainer/Policy mu Mean         -0.055813048
trainer/Policy mu Std          1.6865005
trainer/Policy mu Max          4.9877067
trainer/Policy mu Min          -4.3535643
trainer/Policy log std Mean    -0.5271282
trainer/Policy log std Std     0.13829042
trainer/Policy log std Max     -0.016910613
trainer/Policy log std Min     -1.1062161
trainer/Alpha                  0.002923995954915881
trainer/Alpha Loss             2.363687515258789
exploration/num steps total    586000
exploration/num paths total    1172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9194454608872491
exploration/Rewards Std        0.09958127801856119
exploration/Rewards Max        0.9782729119208716
exploration/Rewards Min        0.5088845433919282
exploration/Returns Mean       459.7227304436243
exploration/Returns Std        6.733464719243264
exploration/Returns Max        467.6462667539439
exploration/Returns Min        443.7806919893283
exploration/Actions Mean       0.039591674
exploration/Actions Std        0.6331859
exploration/Actions Max        0.999859
exploration/Actions Min        -0.9998283
exploration/Num Paths          10
exploration/Average Returns    459.7227304436243
evaluation/num steps total     585000
evaluation/num paths total     1170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9134295601849877
evaluation/Rewards Std         0.10621330902263529
evaluation/Rewards Max         0.9769259837517069
evaluation/Rewards Min         0.4998449384657603
evaluation/Returns Mean        456.71478009249387
evaluation/Returns Std         10.003933067719787
evaluation/Returns Max         464.6174570802385
evaluation/Returns Min         428.64404814361336
evaluation/ExplReturns Mean    456.71478009249387
evaluation/ExplReturns Std     10.003933067719787
evaluation/ExplReturns Max     464.6174570802385
evaluation/ExplReturns Min     428.64404814361336
evaluation/Actions Mean        0.00709645
evaluation/Actions Std         0.5514935
evaluation/Actions Max         0.99962425
evaluation/Actions Min         -0.9987443
evaluation/Num Paths           10
evaluation/Average Returns     456.71478009249387
time/data storing (s)          0.03423831705003977
time/evaluation sampling (s)   110.70499889738858
time/exploration sampling (s)  112.55848512984812
time/logging (s)               0.03060675784945488
time/saving (s)                0.01137176901102066
time/training (s)              9.560192424803972
time/epoch (s)                 232.8998932959512
time/total (s)                 27433.41094020754
Epoch                          116
-----------------------------  --------------------
2023-08-01 01:35:11.993988 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 117 finished
-----------------------------  --------------------
replay_buffer/size             591000
trainer/tdrp Loss              [3506.5684]
trainer/QF1 Loss               0.119450524
trainer/QF2 Loss               0.11503287
trainer/Policy Loss            -59.412666
trainer/Q1 Predictions Mean    71.333046
trainer/Q1 Predictions Std     5.7984304
trainer/Q1 Predictions Max     81.62912
trainer/Q1 Predictions Min     47.39388
trainer/Q2 Predictions Mean    71.418884
trainer/Q2 Predictions Std     5.7843733
trainer/Q2 Predictions Max     81.7375
trainer/Q2 Predictions Min     47.111496
trainer/Q Targets Mean         71.429665
trainer/Q Targets Std          5.801637
trainer/Q Targets Max          81.37343
trainer/Q Targets Min          46.88945
trainer/Log Pis Mean           12.136585
trainer/Log Pis Std            6.8493886
trainer/Log Pis Max            31.295475
trainer/Log Pis Min            -6.8885307
trainer/Policy mu Mean         0.09734858
trainer/Policy mu Std          1.7137934
trainer/Policy mu Max          4.695074
trainer/Policy mu Min          -5.4748282
trainer/Policy log std Mean    -0.53623295
trainer/Policy log std Std     0.14817697
trainer/Policy log std Max     0.16977645
trainer/Policy log std Min     -1.0912069
trainer/Alpha                  0.002983544021844864
trainer/Alpha Loss             0.794187068939209
exploration/num steps total    591000
exploration/num paths total    1182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7622379806078147
exploration/Rewards Std        0.10268795478058157
exploration/Rewards Max        0.9610953423192076
exploration/Rewards Min        0.5022715397843703
exploration/Returns Mean       381.11899030390737
exploration/Returns Std        31.303690467402646
exploration/Returns Max        448.35997760182744
exploration/Returns Min        341.51007778244065
exploration/Actions Mean       0.054882243
exploration/Actions Std        0.6472931
exploration/Actions Max        0.9995731
exploration/Actions Min        -0.9997593
exploration/Num Paths          10
exploration/Average Returns    381.11899030390737
evaluation/num steps total     590000
evaluation/num paths total     1180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7525896567989605
evaluation/Rewards Std         0.08167882683459457
evaluation/Rewards Max         0.9536766015043776
evaluation/Rewards Min         0.5064897739650153
evaluation/Returns Mean        376.29482839948037
evaluation/Returns Std         25.46588423996094
evaluation/Returns Max         449.87168101954705
evaluation/Returns Min         358.3782292465693
evaluation/ExplReturns Mean    376.29482839948037
evaluation/ExplReturns Std     25.46588423996094
evaluation/ExplReturns Max     449.87168101954705
evaluation/ExplReturns Min     358.3782292465693
evaluation/Actions Mean        0.0024628332
evaluation/Actions Std         0.58349806
evaluation/Actions Max         0.9977825
evaluation/Actions Min         -0.997387
evaluation/Num Paths           10
evaluation/Average Returns     376.29482839948037
time/data storing (s)          0.03384839650243521
time/evaluation sampling (s)   110.12098065763712
time/exploration sampling (s)  111.4270212771371
time/logging (s)               0.030227732844650745
time/saving (s)                0.010267376899719238
time/training (s)              8.786984876729548
time/epoch (s)                 230.40933031775057
time/total (s)                 27663.82277592458
Epoch                          117
-----------------------------  --------------------
2023-08-01 01:39:05.732620 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 118 finished
-----------------------------  --------------------
replay_buffer/size             596000
trainer/tdrp Loss              [3525.8542]
trainer/QF1 Loss               0.1270132
trainer/QF2 Loss               0.12933427
trainer/Policy Loss            -59.65908
trainer/Q1 Predictions Mean    71.9294
trainer/Q1 Predictions Std     5.4484344
trainer/Q1 Predictions Max     81.735664
trainer/Q1 Predictions Min     48.719135
trainer/Q2 Predictions Mean    71.84178
trainer/Q2 Predictions Std     5.4391656
trainer/Q2 Predictions Max     81.673965
trainer/Q2 Predictions Min     48.70988
trainer/Q Targets Mean         71.87992
trainer/Q Targets Std          5.423327
trainer/Q Targets Max          81.64852
trainer/Q Targets Min          48.37924
trainer/Log Pis Mean           12.379034
trainer/Log Pis Std            6.995413
trainer/Log Pis Max            31.240103
trainer/Log Pis Min            -4.0518284
trainer/Policy mu Mean         0.07007787
trainer/Policy mu Std          1.6787472
trainer/Policy mu Max          5.7042155
trainer/Policy mu Min          -4.5629697
trainer/Policy log std Mean    -0.5412385
trainer/Policy log std Std     0.14377128
trainer/Policy log std Max     0.29310685
trainer/Policy log std Min     -1.1213238
trainer/Alpha                  0.003007147926837206
trainer/Alpha Loss             2.200972080230713
exploration/num steps total    596000
exploration/num paths total    1192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8424845930847943
exploration/Rewards Std        0.12769337339521386
exploration/Rewards Max        0.9750450007605516
exploration/Rewards Min        0.5031331158406425
exploration/Returns Mean       421.24229654239724
exploration/Returns Std        36.51925598819833
exploration/Returns Max        452.12096397744017
exploration/Returns Min        348.9490268993641
exploration/Actions Mean       0.043830168
exploration/Actions Std        0.6470658
exploration/Actions Max        0.9996095
exploration/Actions Min        -0.9996641
exploration/Num Paths          10
exploration/Average Returns    421.24229654239724
evaluation/num steps total     595000
evaluation/num paths total     1190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7752222444666077
evaluation/Rewards Std         0.13066283729058906
evaluation/Rewards Max         0.9701244863913949
evaluation/Rewards Min         0.5020101599346181
evaluation/Returns Mean        387.61112223330383
evaluation/Returns Std         52.521816581197044
evaluation/Returns Max         464.25874753410324
evaluation/Returns Min         321.00163335606965
evaluation/ExplReturns Mean    387.61112223330383
evaluation/ExplReturns Std     52.521816581197044
evaluation/ExplReturns Max     464.25874753410324
evaluation/ExplReturns Min     321.00163335606965
evaluation/Actions Mean        -0.0031287258
evaluation/Actions Std         0.59441656
evaluation/Actions Max         0.9975546
evaluation/Actions Min         -0.9991299
evaluation/Num Paths           10
evaluation/Average Returns     387.61112223330383
time/data storing (s)          0.03413398750126362
time/evaluation sampling (s)   111.97763095982373
time/exploration sampling (s)  112.05672901496291
time/logging (s)               0.03053244110196829
time/saving (s)                0.012379390187561512
time/training (s)              9.623609131202102
time/epoch (s)                 233.73501492477953
time/total (s)                 27897.56026989408
Epoch                          118
-----------------------------  --------------------
2023-08-01 01:43:02.434042 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 119 finished
-----------------------------  ---------------------
replay_buffer/size             601000
trainer/tdrp Loss              [3360.6943]
trainer/QF1 Loss               0.1396229
trainer/QF2 Loss               0.14583574
trainer/Policy Loss            -61.2015
trainer/Q1 Predictions Mean    72.669556
trainer/Q1 Predictions Std     5.280815
trainer/Q1 Predictions Max     82.08538
trainer/Q1 Predictions Min     53.42831
trainer/Q2 Predictions Mean    72.65059
trainer/Q2 Predictions Std     5.292431
trainer/Q2 Predictions Max     82.06033
trainer/Q2 Predictions Min     54.02244
trainer/Q Targets Mean         72.56906
trainer/Q Targets Std          5.222175
trainer/Q Targets Max          81.95477
trainer/Q Targets Min          54.336483
trainer/Log Pis Mean           11.634372
trainer/Log Pis Std            7.3972282
trainer/Log Pis Max            38.663765
trainer/Log Pis Min            -4.0536933
trainer/Policy mu Mean         0.1305081
trainer/Policy mu Std          1.6524798
trainer/Policy mu Max          5.687871
trainer/Policy mu Min          -4.327324
trainer/Policy log std Mean    -0.54308486
trainer/Policy log std Std     0.14907375
trainer/Policy log std Max     0.03210962
trainer/Policy log std Min     -1.1788802
trainer/Alpha                  0.0030669118277728558
trainer/Alpha Loss             -2.115953207015991
exploration/num steps total    601000
exploration/num paths total    1202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7948636549071915
exploration/Rewards Std        0.11454850344572631
exploration/Rewards Max        0.9764306107474546
exploration/Rewards Min        0.4927845913548519
exploration/Returns Mean       397.4318274535957
exploration/Returns Std        34.11176470254891
exploration/Returns Max        440.11623249457296
exploration/Returns Min        357.5870841279563
exploration/Actions Mean       0.048239827
exploration/Actions Std        0.64467824
exploration/Actions Max        0.99960464
exploration/Actions Min        -0.99997115
exploration/Num Paths          10
exploration/Average Returns    397.4318274535957
evaluation/num steps total     600000
evaluation/num paths total     1200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7095380646882375
evaluation/Rewards Std         0.021454498448706717
evaluation/Rewards Max         0.9284666088025862
evaluation/Rewards Min         0.5053341990620777
evaluation/Returns Mean        354.7690323441188
evaluation/Returns Std         3.4035206543543057
evaluation/Returns Max         363.27994231695095
evaluation/Returns Min         350.07178414765855
evaluation/ExplReturns Mean    354.7690323441188
evaluation/ExplReturns Std     3.4035206543543057
evaluation/ExplReturns Max     363.27994231695095
evaluation/ExplReturns Min     350.07178414765855
evaluation/Actions Mean        -0.035249926
evaluation/Actions Std         0.5666521
evaluation/Actions Max         0.99750865
evaluation/Actions Min         -0.998439
evaluation/Num Paths           10
evaluation/Average Returns     354.7690323441188
time/data storing (s)          0.034331003203988075
time/evaluation sampling (s)   113.34946167562157
time/exploration sampling (s)  113.66716290451586
time/logging (s)               0.030999462120234966
time/saving (s)                0.012954192236065865
time/training (s)              9.603054309263825
time/epoch (s)                 236.69796354696155
time/total (s)                 28134.26067461539
Epoch                          119
-----------------------------  ---------------------
2023-08-01 01:46:58.543112 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 120 finished
-----------------------------  ---------------------
replay_buffer/size             606000
trainer/tdrp Loss              [3669.3413]
trainer/QF1 Loss               0.14911431
trainer/QF2 Loss               0.14710552
trainer/Policy Loss            -60.41513
trainer/Q1 Predictions Mean    72.02559
trainer/Q1 Predictions Std     5.239569
trainer/Q1 Predictions Max     82.10628
trainer/Q1 Predictions Min     48.95808
trainer/Q2 Predictions Mean    71.97421
trainer/Q2 Predictions Std     5.2376633
trainer/Q2 Predictions Max     82.2746
trainer/Q2 Predictions Min     48.56374
trainer/Q Targets Mean         72.07933
trainer/Q Targets Std          5.246633
trainer/Q Targets Max          82.31599
trainer/Q Targets Min          48.48413
trainer/Log Pis Mean           11.771887
trainer/Log Pis Std            7.520842
trainer/Log Pis Max            42.78948
trainer/Log Pis Min            -4.4574327
trainer/Policy mu Mean         0.06592805
trainer/Policy mu Std          1.6742227
trainer/Policy mu Max          4.834816
trainer/Policy mu Min          -5.0259824
trainer/Policy log std Mean    -0.5332787
trainer/Policy log std Std     0.15598454
trainer/Policy log std Max     0.058335125
trainer/Policy log std Min     -1.2284408
trainer/Alpha                  0.0030922514852136374
trainer/Alpha Loss             -1.3182066679000854
exploration/num steps total    606000
exploration/num paths total    1212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7672183694288502
exploration/Rewards Std        0.10475926684031366
exploration/Rewards Max        0.9797374787510766
exploration/Rewards Min        0.49810834888031474
exploration/Returns Mean       383.609184714425
exploration/Returns Std        40.37680482515653
exploration/Returns Max        453.1213295022307
exploration/Returns Min        352.65868867405516
exploration/Actions Mean       0.035456568
exploration/Actions Std        0.64137554
exploration/Actions Max        0.9998115
exploration/Actions Min        -0.99970984
exploration/Num Paths          10
exploration/Average Returns    383.609184714425
evaluation/num steps total     605000
evaluation/num paths total     1210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7408738052204907
evaluation/Rewards Std         0.08571645999050326
evaluation/Rewards Max         0.9749019790092893
evaluation/Rewards Min         0.5097436468385331
evaluation/Returns Mean        370.4369026102453
evaluation/Returns Std         31.73745842438268
evaluation/Returns Max         435.9224061751138
evaluation/Returns Min         350.712897673995
evaluation/ExplReturns Mean    370.4369026102453
evaluation/ExplReturns Std     31.73745842438268
evaluation/ExplReturns Max     435.9224061751138
evaluation/ExplReturns Min     350.712897673995
evaluation/Actions Mean        0.009446947
evaluation/Actions Std         0.5623083
evaluation/Actions Max         0.99525297
evaluation/Actions Min         -0.9974619
evaluation/Num Paths           10
evaluation/Average Returns     370.4369026102453
time/data storing (s)          0.034324388951063156
time/evaluation sampling (s)   112.87959819473326
time/exploration sampling (s)  113.62329545430839
time/logging (s)               0.031019738875329494
time/saving (s)                0.012035854160785675
time/training (s)              9.524651627987623
time/epoch (s)                 236.10492525901645
time/total (s)                 28370.368260890245
Epoch                          120
-----------------------------  ---------------------
2023-08-01 01:50:53.795768 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 121 finished
-----------------------------  --------------------
replay_buffer/size             611000
trainer/tdrp Loss              [3487.461]
trainer/QF1 Loss               0.11587998
trainer/QF2 Loss               0.128071
trainer/Policy Loss            -60.868355
trainer/Q1 Predictions Mean    72.3638
trainer/Q1 Predictions Std     5.1317706
trainer/Q1 Predictions Max     82.31107
trainer/Q1 Predictions Min     56.65957
trainer/Q2 Predictions Mean    72.28342
trainer/Q2 Predictions Std     5.1084266
trainer/Q2 Predictions Max     82.190216
trainer/Q2 Predictions Min     56.856434
trainer/Q Targets Mean         72.4032
trainer/Q Targets Std          5.163954
trainer/Q Targets Max          82.51169
trainer/Q Targets Min          56.860336
trainer/Log Pis Mean           11.605089
trainer/Log Pis Std            7.110124
trainer/Log Pis Max            34.507893
trainer/Log Pis Min            -3.4560165
trainer/Policy mu Mean         0.10136243
trainer/Policy mu Std          1.6517398
trainer/Policy mu Max          5.4745235
trainer/Policy mu Min          -4.155785
trainer/Policy log std Mean    -0.5446946
trainer/Policy log std Std     0.15874214
trainer/Policy log std Max     -0.03846973
trainer/Policy log std Min     -1.196971
trainer/Alpha                  0.003047100268304348
trainer/Alpha Loss             -2.2878990173339844
exploration/num steps total    611000
exploration/num paths total    1222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.798214195443682
exploration/Rewards Std        0.11476250693749504
exploration/Rewards Max        0.9784315047228458
exploration/Rewards Min        0.5038391960885291
exploration/Returns Mean       399.107097721841
exploration/Returns Std        41.71109796934674
exploration/Returns Max        467.12415434954187
exploration/Returns Min        354.38052648517623
exploration/Actions Mean       0.031684067
exploration/Actions Std        0.6397225
exploration/Actions Max        0.9999472
exploration/Actions Min        -0.9998895
exploration/Num Paths          10
exploration/Average Returns    399.107097721841
evaluation/num steps total     610000
evaluation/num paths total     1220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7191100154696041
evaluation/Rewards Std         0.015418260081206727
evaluation/Rewards Max         0.7417217882918926
evaluation/Rewards Min         0.513250862273235
evaluation/Returns Mean        359.55500773480196
evaluation/Returns Std         2.309235167354433
evaluation/Returns Max         362.6820035772409
evaluation/Returns Min         354.84821645501796
evaluation/ExplReturns Mean    359.55500773480196
evaluation/ExplReturns Std     2.309235167354433
evaluation/ExplReturns Max     362.6820035772409
evaluation/ExplReturns Min     354.84821645501796
evaluation/Actions Mean        0.046906233
evaluation/Actions Std         0.5476458
evaluation/Actions Max         0.99773103
evaluation/Actions Min         -0.99822706
evaluation/Num Paths           10
evaluation/Average Returns     359.55500773480196
time/data storing (s)          0.0339696416631341
time/evaluation sampling (s)   112.78401045873761
time/exploration sampling (s)  112.95324977207929
time/logging (s)               0.03062513004988432
time/saving (s)                0.012623937800526619
time/training (s)              9.433911193162203
time/epoch (s)                 235.24839013349265
time/total (s)                 28605.61905758083
Epoch                          121
-----------------------------  --------------------
2023-08-01 01:54:52.438249 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 122 finished
-----------------------------  ---------------------
replay_buffer/size             616000
trainer/tdrp Loss              [3632.035]
trainer/QF1 Loss               0.14050126
trainer/QF2 Loss               0.11900479
trainer/Policy Loss            -60.62454
trainer/Q1 Predictions Mean    72.51173
trainer/Q1 Predictions Std     5.3768597
trainer/Q1 Predictions Max     83.11627
trainer/Q1 Predictions Min     50.389503
trainer/Q2 Predictions Mean    72.59042
trainer/Q2 Predictions Std     5.392973
trainer/Q2 Predictions Max     83.23446
trainer/Q2 Predictions Min     49.966465
trainer/Q Targets Mean         72.59521
trainer/Q Targets Std          5.3833833
trainer/Q Targets Max          83.52173
trainer/Q Targets Min          50.654064
trainer/Log Pis Mean           12.110295
trainer/Log Pis Std            7.173247
trainer/Log Pis Max            33.9899
trainer/Log Pis Min            -6.4969597
trainer/Policy mu Mean         0.04118855
trainer/Policy mu Std          1.6568649
trainer/Policy mu Max          3.9848223
trainer/Policy mu Min          -4.527895
trainer/Policy log std Mean    -0.53734475
trainer/Policy log std Std     0.15326704
trainer/Policy log std Max     0.0039553344
trainer/Policy log std Min     -1.247719
trainer/Alpha                  0.0030830686446279287
trainer/Alpha Loss             0.6376972198486328
exploration/num steps total    616000
exploration/num paths total    1232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8198549621693645
exploration/Rewards Std        0.12342097008036752
exploration/Rewards Max        0.9780857310132349
exploration/Rewards Min        0.4981817220364733
exploration/Returns Mean       409.9274810846822
exploration/Returns Std        36.02022213725508
exploration/Returns Max        454.4578973776509
exploration/Returns Min        348.55670300088303
exploration/Actions Mean       0.06748242
exploration/Actions Std        0.64235854
exploration/Actions Max        0.99997234
exploration/Actions Min        -0.99998784
exploration/Num Paths          10
exploration/Average Returns    409.9274810846822
evaluation/num steps total     615000
evaluation/num paths total     1230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7507074140535143
evaluation/Rewards Std         0.09306711118884406
evaluation/Rewards Max         0.974806657692168
evaluation/Rewards Min         0.5020067133777985
evaluation/Returns Mean        375.35370702675704
evaluation/Returns Std         24.581111592971837
evaluation/Returns Max         426.3209650287081
evaluation/Returns Min         351.3926153982085
evaluation/ExplReturns Mean    375.35370702675704
evaluation/ExplReturns Std     24.581111592971837
evaluation/ExplReturns Max     426.3209650287081
evaluation/ExplReturns Min     351.3926153982085
evaluation/Actions Mean        0.04433876
evaluation/Actions Std         0.5582345
evaluation/Actions Max         0.998288
evaluation/Actions Min         -0.99914116
evaluation/Num Paths           10
evaluation/Average Returns     375.35370702675704
time/data storing (s)          0.034422735683619976
time/evaluation sampling (s)   114.88988010771573
time/exploration sampling (s)  114.32689057476819
time/logging (s)               0.0326233534142375
time/saving (s)                0.010257836431264877
time/training (s)              9.346306085586548
time/epoch (s)                 238.64038069359958
time/total (s)                 28844.26208679285
Epoch                          122
-----------------------------  ---------------------
2023-08-01 01:58:47.092343 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 123 finished
-----------------------------  ---------------------
replay_buffer/size             621000
trainer/tdrp Loss              [3326.654]
trainer/QF1 Loss               0.16694191
trainer/QF2 Loss               0.15451497
trainer/Policy Loss            -61.291153
trainer/Q1 Predictions Mean    72.38919
trainer/Q1 Predictions Std     6.288693
trainer/Q1 Predictions Max     83.59366
trainer/Q1 Predictions Min     46.850685
trainer/Q2 Predictions Mean    72.42836
trainer/Q2 Predictions Std     6.2932386
trainer/Q2 Predictions Max     83.482185
trainer/Q2 Predictions Min     46.559196
trainer/Q Targets Mean         72.48307
trainer/Q Targets Std          6.2425485
trainer/Q Targets Max          83.19929
trainer/Q Targets Min          47.253326
trainer/Log Pis Mean           11.284383
trainer/Log Pis Std            7.4290104
trainer/Log Pis Max            35.40247
trainer/Log Pis Min            -3.8523743
trainer/Policy mu Mean         -0.07217836
trainer/Policy mu Std          1.6288656
trainer/Policy mu Max          4.288981
trainer/Policy mu Min          -4.6614885
trainer/Policy log std Mean    -0.5655909
trainer/Policy log std Std     0.16403686
trainer/Policy log std Max     -0.05743748
trainer/Policy log std Min     -1.3927422
trainer/Alpha                  0.0030602109618484974
trainer/Alpha Loss             -4.142924785614014
exploration/num steps total    621000
exploration/num paths total    1242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7556550051097047
exploration/Rewards Std        0.10931482885938662
exploration/Rewards Max        0.9792795701522801
exploration/Rewards Min        0.4950930372286004
exploration/Returns Mean       377.82750255485223
exploration/Returns Std        43.24901709879375
exploration/Returns Max        461.1502853305692
exploration/Returns Min        334.6521700126002
exploration/Actions Mean       0.021570195
exploration/Actions Std        0.6382649
exploration/Actions Max        0.99956506
exploration/Actions Min        -0.99990946
exploration/Num Paths          10
exploration/Average Returns    377.82750255485223
evaluation/num steps total     620000
evaluation/num paths total     1240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7348104069773522
evaluation/Rewards Std         0.07817841268919888
evaluation/Rewards Max         0.9775294363202601
evaluation/Rewards Min         0.5029362553397763
evaluation/Returns Mean        367.4052034886761
evaluation/Returns Std         29.05446546198023
evaluation/Returns Max         448.06833494844284
evaluation/Returns Min         336.63978233601085
evaluation/ExplReturns Mean    367.4052034886761
evaluation/ExplReturns Std     29.05446546198023
evaluation/ExplReturns Max     448.06833494844284
evaluation/ExplReturns Min     336.63978233601085
evaluation/Actions Mean        0.010962727
evaluation/Actions Std         0.5457778
evaluation/Actions Max         0.99719006
evaluation/Actions Min         -0.9982836
evaluation/Num Paths           10
evaluation/Average Returns     367.4052034886761
time/data storing (s)          0.034116572700440884
time/evaluation sampling (s)   112.23331950418651
time/exploration sampling (s)  113.30906554311514
time/logging (s)               0.030678965151309967
time/saving (s)                0.012457082979381084
time/training (s)              9.028413206338882
time/epoch (s)                 234.64805087447166
time/total (s)                 29078.9127789801
Epoch                          123
-----------------------------  ---------------------
2023-08-01 02:02:41.857642 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 124 finished
-----------------------------  ---------------------
replay_buffer/size             626000
trainer/tdrp Loss              [3523.9583]
trainer/QF1 Loss               0.12817976
trainer/QF2 Loss               0.107729286
trainer/Policy Loss            -61.865314
trainer/Q1 Predictions Mean    73.5113
trainer/Q1 Predictions Std     6.1413383
trainer/Q1 Predictions Max     83.028015
trainer/Q1 Predictions Min     48.23352
trainer/Q2 Predictions Mean    73.450516
trainer/Q2 Predictions Std     6.1744866
trainer/Q2 Predictions Max     83.06433
trainer/Q2 Predictions Min     48.084152
trainer/Q Targets Mean         73.38081
trainer/Q Targets Std          6.194855
trainer/Q Targets Max          83.44445
trainer/Q Targets Min          48.124264
trainer/Log Pis Mean           11.795744
trainer/Log Pis Std            7.08006
trainer/Log Pis Max            31.890007
trainer/Log Pis Min            -5.136659
trainer/Policy mu Mean         0.16366549
trainer/Policy mu Std          1.6547716
trainer/Policy mu Max          4.8159876
trainer/Policy mu Min          -4.859948
trainer/Policy log std Mean    -0.56334704
trainer/Policy log std Std     0.1610814
trainer/Policy log std Max     0.15466723
trainer/Policy log std Min     -1.2650807
trainer/Alpha                  0.0031579413916915655
trainer/Alpha Loss             -1.1761327981948853
exploration/num steps total    626000
exploration/num paths total    1252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8450382754744361
exploration/Rewards Std        0.1175479686361825
exploration/Rewards Max        0.9750291408143579
exploration/Rewards Min        0.49974901201847444
exploration/Returns Mean       422.519137737218
exploration/Returns Std        24.221944113028677
exploration/Returns Max        454.1832911337693
exploration/Returns Min        359.6837128476986
exploration/Actions Mean       0.06783187
exploration/Actions Std        0.6357671
exploration/Actions Max        0.9996812
exploration/Actions Min        -0.9995166
exploration/Num Paths          10
exploration/Average Returns    422.519137737218
evaluation/num steps total     625000
evaluation/num paths total     1250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7218138114707952
evaluation/Rewards Std         0.04586895105204218
evaluation/Rewards Max         0.9664610479600214
evaluation/Rewards Min         0.503028305772455
evaluation/Returns Mean        360.9069057353976
evaluation/Returns Std         12.734408132304305
evaluation/Returns Max         397.51700821621444
evaluation/Returns Min         350.10581681792354
evaluation/ExplReturns Mean    360.9069057353976
evaluation/ExplReturns Std     12.734408132304305
evaluation/ExplReturns Max     397.51700821621444
evaluation/ExplReturns Min     350.10581681792354
evaluation/Actions Mean        0.046390112
evaluation/Actions Std         0.48953268
evaluation/Actions Max         0.9969127
evaluation/Actions Min         -0.99517816
evaluation/Num Paths           10
evaluation/Average Returns     360.9069057353976
time/data storing (s)          0.03428467828780413
time/evaluation sampling (s)   112.8390574613586
time/exploration sampling (s)  112.78256582003087
time/logging (s)               0.03060276433825493
time/saving (s)                0.012177681550383568
time/training (s)              9.062569219619036
time/epoch (s)                 234.76125762518495
time/total (s)                 29313.67653398961
Epoch                          124
-----------------------------  ---------------------
2023-08-01 02:06:37.431172 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 125 finished
-----------------------------  ---------------------
replay_buffer/size             631000
trainer/tdrp Loss              [3583.308]
trainer/QF1 Loss               0.16236821
trainer/QF2 Loss               0.15015899
trainer/Policy Loss            -62.458908
trainer/Q1 Predictions Mean    73.90402
trainer/Q1 Predictions Std     5.5803885
trainer/Q1 Predictions Max     83.730034
trainer/Q1 Predictions Min     50.80893
trainer/Q2 Predictions Mean    73.86023
trainer/Q2 Predictions Std     5.5675235
trainer/Q2 Predictions Max     83.59595
trainer/Q2 Predictions Min     50.55068
trainer/Q Targets Mean         73.79962
trainer/Q Targets Std          5.568575
trainer/Q Targets Max          83.74839
trainer/Q Targets Min          49.949623
trainer/Log Pis Mean           11.599956
trainer/Log Pis Std            8.044311
trainer/Log Pis Max            46.447517
trainer/Log Pis Min            -6.6504264
trainer/Policy mu Mean         0.069425546
trainer/Policy mu Std          1.6294733
trainer/Policy mu Max          6.964427
trainer/Policy mu Min          -4.545779
trainer/Policy log std Mean    -0.5629987
trainer/Policy log std Std     0.16067126
trainer/Policy log std Max     0.061270297
trainer/Policy log std Min     -1.2510715
trainer/Alpha                  0.0031298792455345392
trainer/Alpha Loss             -2.3068907260894775
exploration/num steps total    631000
exploration/num paths total    1262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8281916130758289
exploration/Rewards Std        0.12566264222196066
exploration/Rewards Max        0.9773386028915185
exploration/Rewards Min        0.5009621177884042
exploration/Returns Mean       414.09580653791437
exploration/Returns Std        42.78649088820685
exploration/Returns Max        465.9315057658935
exploration/Returns Min        359.03263196420346
exploration/Actions Mean       0.051053666
exploration/Actions Std        0.6318713
exploration/Actions Max        0.99979675
exploration/Actions Min        -0.99992794
exploration/Num Paths          10
exploration/Average Returns    414.09580653791437
evaluation/num steps total     630000
evaluation/num paths total     1260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7170624273954415
evaluation/Rewards Std         0.019321692636205697
evaluation/Rewards Max         0.9285265574383197
evaluation/Rewards Min         0.5018742369812536
evaluation/Returns Mean        358.5312136977208
evaluation/Returns Std         1.986121065104956
evaluation/Returns Max         364.1193877493885
evaluation/Returns Min         357.15017321044525
evaluation/ExplReturns Mean    358.5312136977208
evaluation/ExplReturns Std     1.986121065104956
evaluation/ExplReturns Max     364.1193877493885
evaluation/ExplReturns Min     357.15017321044525
evaluation/Actions Mean        -0.05686726
evaluation/Actions Std         0.53678805
evaluation/Actions Max         0.9957563
evaluation/Actions Min         -0.9955601
evaluation/Num Paths           10
evaluation/Average Returns     358.5312136977208
time/data storing (s)          0.03417828865349293
time/evaluation sampling (s)   112.97315900959074
time/exploration sampling (s)  113.1264375904575
time/logging (s)               0.03093578852713108
time/saving (s)                0.011764490976929665
time/training (s)              9.393333805724978
time/epoch (s)                 235.56980897393078
time/total (s)                 29549.248881847598
Epoch                          125
-----------------------------  ---------------------
2023-08-01 02:10:34.748461 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 126 finished
-----------------------------  ---------------------
replay_buffer/size             636000
trainer/tdrp Loss              [3641.0889]
trainer/QF1 Loss               0.13515815
trainer/QF2 Loss               0.1378341
trainer/Policy Loss            -61.428364
trainer/Q1 Predictions Mean    73.32245
trainer/Q1 Predictions Std     6.025902
trainer/Q1 Predictions Max     83.77299
trainer/Q1 Predictions Min     52.050144
trainer/Q2 Predictions Mean    73.3279
trainer/Q2 Predictions Std     6.013231
trainer/Q2 Predictions Max     83.86709
trainer/Q2 Predictions Min     51.834885
trainer/Q Targets Mean         73.35616
trainer/Q Targets Std          6.025796
trainer/Q Targets Max          83.93347
trainer/Q Targets Min          52.211575
trainer/Log Pis Mean           12.082154
trainer/Log Pis Std            6.8044486
trainer/Log Pis Max            31.919842
trainer/Log Pis Min            -9.314305
trainer/Policy mu Mean         0.007060776
trainer/Policy mu Std          1.6885121
trainer/Policy mu Max          8.528325
trainer/Policy mu Min          -4.001621
trainer/Policy log std Mean    -0.55426234
trainer/Policy log std Std     0.1601954
trainer/Policy log std Max     0.33878043
trainer/Policy log std Min     -1.3019359
trainer/Alpha                  0.0031959221232682467
trainer/Alpha Loss             0.4720521569252014
exploration/num steps total    636000
exploration/num paths total    1272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8573783928442059
exploration/Rewards Std        0.11967678449100459
exploration/Rewards Max        0.9790974464669348
exploration/Rewards Min        0.5003971290967829
exploration/Returns Mean       428.68919642210284
exploration/Returns Std        21.84091771620429
exploration/Returns Max        461.0992360801503
exploration/Returns Min        389.30785517469155
exploration/Actions Mean       0.0658704
exploration/Actions Std        0.6507893
exploration/Actions Max        0.99992377
exploration/Actions Min        -0.9998459
exploration/Num Paths          10
exploration/Average Returns    428.68919642210284
evaluation/num steps total     635000
evaluation/num paths total     1270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8386217750322219
evaluation/Rewards Std         0.12746173964316143
evaluation/Rewards Max         0.9758678382442023
evaluation/Rewards Min         0.5051705974735758
evaluation/Returns Mean        419.31088751611077
evaluation/Returns Std         42.82515364412196
evaluation/Returns Max         459.25035353045547
evaluation/Returns Min         339.05036714679295
evaluation/ExplReturns Mean    419.31088751611077
evaluation/ExplReturns Std     42.82515364412196
evaluation/ExplReturns Max     459.25035353045547
evaluation/ExplReturns Min     339.05036714679295
evaluation/Actions Mean        0.07652515
evaluation/Actions Std         0.5917866
evaluation/Actions Max         0.999265
evaluation/Actions Min         -0.9990408
evaluation/Num Paths           10
evaluation/Average Returns     419.31088751611077
time/data storing (s)          0.03381517715752125
time/evaluation sampling (s)   113.66404456458986
time/exploration sampling (s)  113.15277894027531
time/logging (s)               0.030612178146839142
time/saving (s)                0.012424562126398087
time/training (s)              10.419206330552697
time/epoch (s)                 237.31288175284863
time/total (s)                 29786.56435183715
Epoch                          126
-----------------------------  ---------------------
2023-08-01 02:14:28.406330 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 127 finished
-----------------------------  --------------------
replay_buffer/size             641000
trainer/tdrp Loss              [3557.9692]
trainer/QF1 Loss               0.15650567
trainer/QF2 Loss               0.16082034
trainer/Policy Loss            -62.404884
trainer/Q1 Predictions Mean    73.52234
trainer/Q1 Predictions Std     6.21777
trainer/Q1 Predictions Max     84.18471
trainer/Q1 Predictions Min     52.68475
trainer/Q2 Predictions Mean    73.58718
trainer/Q2 Predictions Std     6.1736727
trainer/Q2 Predictions Max     84.254425
trainer/Q2 Predictions Min     52.560627
trainer/Q Targets Mean         73.57022
trainer/Q Targets Std          6.2406144
trainer/Q Targets Max          84.35327
trainer/Q Targets Min          52.89696
trainer/Log Pis Mean           11.296082
trainer/Log Pis Std            7.3616757
trainer/Log Pis Max            34.63025
trainer/Log Pis Min            -4.5143514
trainer/Policy mu Mean         -0.117602654
trainer/Policy mu Std          1.6207895
trainer/Policy mu Max          4.4128466
trainer/Policy mu Min          -5.3699503
trainer/Policy log std Mean    -0.55676603
trainer/Policy log std Std     0.1727432
trainer/Policy log std Max     0.05104068
trainer/Policy log std Min     -1.2515125
trainer/Alpha                  0.003116003470495343
trainer/Alpha Loss             -4.062294960021973
exploration/num steps total    641000
exploration/num paths total    1282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7290723990946989
exploration/Rewards Std        0.08496762327363243
exploration/Rewards Max        0.9753814107111227
exploration/Rewards Min        0.5058470045990233
exploration/Returns Mean       364.53619954734944
exploration/Returns Std        34.02631983146517
exploration/Returns Max        458.8841087995679
exploration/Returns Min        344.5653179855784
exploration/Actions Mean       -0.007759201
exploration/Actions Std        0.62687916
exploration/Actions Max        0.9997709
exploration/Actions Min        -0.9995754
exploration/Num Paths          10
exploration/Average Returns    364.53619954734944
evaluation/num steps total     640000
evaluation/num paths total     1280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8109857280178996
evaluation/Rewards Std         0.13096149001886345
evaluation/Rewards Max         0.9757314432600929
evaluation/Rewards Min         0.5133740340676586
evaluation/Returns Mean        405.49286400894977
evaluation/Returns Std         56.73571372252859
evaluation/Returns Max         468.257135447408
evaluation/Returns Min         348.79076153970374
evaluation/ExplReturns Mean    405.49286400894977
evaluation/ExplReturns Std     56.73571372252859
evaluation/ExplReturns Max     468.257135447408
evaluation/ExplReturns Min     348.79076153970374
evaluation/Actions Mean        0.028302
evaluation/Actions Std         0.5246225
evaluation/Actions Max         0.995877
evaluation/Actions Min         -0.9958333
evaluation/Num Paths           10
evaluation/Average Returns     405.49286400894977
time/data storing (s)          0.03432267252355814
time/evaluation sampling (s)   111.51776596345007
time/exploration sampling (s)  112.37399805150926
time/logging (s)               0.03186248429119587
time/saving (s)                0.013052660040557384
time/training (s)              9.684025737456977
time/epoch (s)                 233.65502756927162
time/total (s)                 30020.2219187608
Epoch                          127
-----------------------------  --------------------
2023-08-01 02:18:23.993334 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 128 finished
-----------------------------  --------------------
replay_buffer/size             646000
trainer/tdrp Loss              [3498.8743]
trainer/QF1 Loss               0.15755862
trainer/QF2 Loss               0.14356492
trainer/Policy Loss            -62.03941
trainer/Q1 Predictions Mean    73.65474
trainer/Q1 Predictions Std     6.074989
trainer/Q1 Predictions Max     84.55948
trainer/Q1 Predictions Min     49.406197
trainer/Q2 Predictions Mean    73.69848
trainer/Q2 Predictions Std     6.0622497
trainer/Q2 Predictions Max     84.51212
trainer/Q2 Predictions Min     49.83542
trainer/Q Targets Mean         73.72836
trainer/Q Targets Std          6.0578036
trainer/Q Targets Max          84.719604
trainer/Q Targets Min          49.98811
trainer/Log Pis Mean           11.818221
trainer/Log Pis Std            7.0035305
trainer/Log Pis Max            44.310658
trainer/Log Pis Min            -5.3009973
trainer/Policy mu Mean         0.059388038
trainer/Policy mu Std          1.6467642
trainer/Policy mu Max          4.306109
trainer/Policy mu Min          -5.3599052
trainer/Policy log std Mean    -0.572795
trainer/Policy log std Std     0.1595126
trainer/Policy log std Max     0.16453815
trainer/Policy log std Min     -1.3251741
trainer/Alpha                  0.003161849919706583
trainer/Alpha Loss             -1.0464470386505127
exploration/num steps total    646000
exploration/num paths total    1292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8690074946511046
exploration/Rewards Std        0.11626500697469394
exploration/Rewards Max        0.9739991438368426
exploration/Rewards Min        0.5102432735729874
exploration/Returns Mean       434.50374732555235
exploration/Returns Std        32.51990292251154
exploration/Returns Max        455.9872361036477
exploration/Returns Min        366.24795413700326
exploration/Actions Mean       0.00568886
exploration/Actions Std        0.6244438
exploration/Actions Max        0.9993386
exploration/Actions Min        -0.99951565
exploration/Num Paths          10
exploration/Average Returns    434.50374732555235
evaluation/num steps total     645000
evaluation/num paths total     1290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7208477382943125
evaluation/Rewards Std         0.01646678641194624
evaluation/Rewards Max         0.7426176527782758
evaluation/Rewards Min         0.5051520313878554
evaluation/Returns Mean        360.42386914715615
evaluation/Returns Std         1.9137909355758798
evaluation/Returns Max         363.8706244075366
evaluation/Returns Min         357.58372655188356
evaluation/ExplReturns Mean    360.42386914715615
evaluation/ExplReturns Std     1.9137909355758798
evaluation/ExplReturns Max     363.8706244075366
evaluation/ExplReturns Min     357.58372655188356
evaluation/Actions Mean        -0.07836865
evaluation/Actions Std         0.5212623
evaluation/Actions Max         0.9910282
evaluation/Actions Min         -0.9946784
evaluation/Num Paths           10
evaluation/Average Returns     360.42386914715615
time/data storing (s)          0.03376800660043955
time/evaluation sampling (s)   113.15109540056437
time/exploration sampling (s)  112.82012888975441
time/logging (s)               0.03067911323159933
time/saving (s)                0.01224407646805048
time/training (s)              9.533948314376175
time/epoch (s)                 235.58186380099505
time/total (s)                 30255.806249108166
Epoch                          128
-----------------------------  --------------------
2023-08-01 02:22:19.955195 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 129 finished
-----------------------------  --------------------
replay_buffer/size             651000
trainer/tdrp Loss              [3430.8699]
trainer/QF1 Loss               0.1350567
trainer/QF2 Loss               0.124522336
trainer/Policy Loss            -62.570488
trainer/Q1 Predictions Mean    74.3487
trainer/Q1 Predictions Std     6.0439568
trainer/Q1 Predictions Max     85.03692
trainer/Q1 Predictions Min     55.884907
trainer/Q2 Predictions Mean    74.26973
trainer/Q2 Predictions Std     6.047914
trainer/Q2 Predictions Max     85.051254
trainer/Q2 Predictions Min     55.530094
trainer/Q Targets Mean         74.25801
trainer/Q Targets Std          6.046646
trainer/Q Targets Max          84.91984
trainer/Q Targets Min          55.709698
trainer/Log Pis Mean           11.903186
trainer/Log Pis Std            7.3084946
trainer/Log Pis Max            38.880318
trainer/Log Pis Min            -3.9973269
trainer/Policy mu Mean         -0.00440169
trainer/Policy mu Std          1.6573997
trainer/Policy mu Max          5.520947
trainer/Policy mu Min          -4.2654305
trainer/Policy log std Mean    -0.5653698
trainer/Policy log std Std     0.16193765
trainer/Policy log std Max     0.017923236
trainer/Policy log std Min     -1.1784033
trainer/Alpha                  0.003168684197589755
trainer/Alpha Loss             -0.557121753692627
exploration/num steps total    651000
exploration/num paths total    1302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7672316415919835
exploration/Rewards Std        0.10038400346522879
exploration/Rewards Max        0.9579333705916087
exploration/Rewards Min        0.5087346121102464
exploration/Returns Mean       383.6158207959917
exploration/Returns Std        16.490606867478412
exploration/Returns Max        413.01820783074527
exploration/Returns Min        348.792472547438
exploration/Actions Mean       -0.012704486
exploration/Actions Std        0.6248218
exploration/Actions Max        0.9997985
exploration/Actions Min        -0.99974847
exploration/Num Paths          10
exploration/Average Returns    383.6158207959917
evaluation/num steps total     650000
evaluation/num paths total     1300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7149091651208194
evaluation/Rewards Std         0.06067221368495225
evaluation/Rewards Max         0.9445134804971738
evaluation/Rewards Min         0.507882956646685
evaluation/Returns Mean        357.4545825604097
evaluation/Returns Std         24.174245985607538
evaluation/Returns Max         429.6400789770024
evaluation/Returns Min         345.9121635929489
evaluation/ExplReturns Mean    357.4545825604097
evaluation/ExplReturns Std     24.174245985607538
evaluation/ExplReturns Max     429.6400789770024
evaluation/ExplReturns Min     345.9121635929489
evaluation/Actions Mean        0.051487625
evaluation/Actions Std         0.5805073
evaluation/Actions Max         0.9944272
evaluation/Actions Min         -0.99855113
evaluation/Num Paths           10
evaluation/Average Returns     357.4545825604097
time/data storing (s)          0.033999125473201275
time/evaluation sampling (s)   114.27682526409626
time/exploration sampling (s)  112.02594866137952
time/logging (s)               0.030397839844226837
time/saving (s)                0.012645473703742027
time/training (s)              9.577781310305
time/epoch (s)                 235.95759767480195
time/total (s)                 30491.766331213526
Epoch                          129
-----------------------------  --------------------
2023-08-01 02:26:12.217486 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 130 finished
-----------------------------  --------------------
replay_buffer/size             656000
trainer/tdrp Loss              [3396.5596]
trainer/QF1 Loss               0.19046769
trainer/QF2 Loss               0.16905364
trainer/Policy Loss            -63.026432
trainer/Q1 Predictions Mean    74.531784
trainer/Q1 Predictions Std     5.8615646
trainer/Q1 Predictions Max     85.151115
trainer/Q1 Predictions Min     56.5977
trainer/Q2 Predictions Mean    74.56409
trainer/Q2 Predictions Std     5.8261786
trainer/Q2 Predictions Max     85.17902
trainer/Q2 Predictions Min     56.758156
trainer/Q Targets Mean         74.69185
trainer/Q Targets Std          5.869596
trainer/Q Targets Max          85.05495
trainer/Q Targets Min          57.204277
trainer/Log Pis Mean           11.6850195
trainer/Log Pis Std            7.144603
trainer/Log Pis Max            36.34097
trainer/Log Pis Min            -3.5250945
trainer/Policy mu Mean         -0.03189418
trainer/Policy mu Std          1.5983618
trainer/Policy mu Max          4.7620454
trainer/Policy mu Min          -4.708235
trainer/Policy log std Mean    -0.5806678
trainer/Policy log std Std     0.16128343
trainer/Policy log std Max     -0.050538555
trainer/Policy log std Min     -1.3369393
trainer/Alpha                  0.003079686313867569
trainer/Alpha Loss             -1.8214706182479858
exploration/num steps total    656000
exploration/num paths total    1312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9211888374753282
exploration/Rewards Std        0.09382836135587773
exploration/Rewards Max        0.9785901805651289
exploration/Rewards Min        0.49233981970158053
exploration/Returns Mean       460.5944187376641
exploration/Returns Std        8.183678495395558
exploration/Returns Max        475.70729970213495
exploration/Returns Min        449.74853730282945
exploration/Actions Mean       0.029225666
exploration/Actions Std        0.6297735
exploration/Actions Max        0.9992661
exploration/Actions Min        -0.9999702
exploration/Num Paths          10
exploration/Average Returns    460.5944187376641
evaluation/num steps total     655000
evaluation/num paths total     1310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9254608090061082
evaluation/Rewards Std         0.09271955448883668
evaluation/Rewards Max         0.9763692329137517
evaluation/Rewards Min         0.5044761542720284
evaluation/Returns Mean        462.73040450305416
evaluation/Returns Std         3.90955700699354
evaluation/Returns Max         467.72242409391583
evaluation/Returns Min         454.3890404955176
evaluation/ExplReturns Mean    462.73040450305416
evaluation/ExplReturns Std     3.90955700699354
evaluation/ExplReturns Max     467.72242409391583
evaluation/ExplReturns Min     454.3890404955176
evaluation/Actions Mean        0.036997672
evaluation/Actions Std         0.5761449
evaluation/Actions Max         0.9975676
evaluation/Actions Min         -0.9997508
evaluation/Num Paths           10
evaluation/Average Returns     462.73040450305416
time/data storing (s)          0.03382558934390545
time/evaluation sampling (s)   110.6504963086918
time/exploration sampling (s)  111.96592968143523
time/logging (s)               0.030437239445745945
time/saving (s)                0.012159529142081738
time/training (s)              9.565435175783932
time/epoch (s)                 232.2582835238427
time/total (s)                 30724.02714987565
Epoch                          130
-----------------------------  --------------------
2023-08-01 02:30:07.761037 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 131 finished
-----------------------------  --------------------
replay_buffer/size             661000
trainer/tdrp Loss              [3513.38]
trainer/QF1 Loss               0.14789906
trainer/QF2 Loss               0.13768658
trainer/Policy Loss            -63.633373
trainer/Q1 Predictions Mean    75.095505
trainer/Q1 Predictions Std     6.5570283
trainer/Q1 Predictions Max     85.62165
trainer/Q1 Predictions Min     50.028336
trainer/Q2 Predictions Mean    75.13782
trainer/Q2 Predictions Std     6.572406
trainer/Q2 Predictions Max     85.69435
trainer/Q2 Predictions Min     49.372
trainer/Q Targets Mean         75.06173
trainer/Q Targets Std          6.6037364
trainer/Q Targets Max          85.65042
trainer/Q Targets Min          49.889446
trainer/Log Pis Mean           11.649279
trainer/Log Pis Std            7.581766
trainer/Log Pis Max            52.950783
trainer/Log Pis Min            -4.5762835
trainer/Policy mu Mean         0.09790313
trainer/Policy mu Std          1.6327996
trainer/Policy mu Max          6.750385
trainer/Policy mu Min          -4.088608
trainer/Policy log std Mean    -0.5771095
trainer/Policy log std Std     0.17332697
trainer/Policy log std Max     0.083226144
trainer/Policy log std Min     -1.3037478
trainer/Alpha                  0.003242896171286702
trainer/Alpha Loss             -2.010133743286133
exploration/num steps total    661000
exploration/num paths total    1322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8904253322668206
exploration/Rewards Std        0.12707384945491002
exploration/Rewards Max        0.9797198501638227
exploration/Rewards Min        0.506653999977322
exploration/Returns Mean       445.2126661334102
exploration/Returns Std        51.34490222288127
exploration/Returns Max        479.2133002194946
exploration/Returns Min        335.9350011679278
exploration/Actions Mean       0.042083062
exploration/Actions Std        0.6244499
exploration/Actions Max        0.9997476
exploration/Actions Min        -0.9996388
exploration/Num Paths          10
exploration/Average Returns    445.2126661334102
evaluation/num steps total     660000
evaluation/num paths total     1320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8615270607308354
evaluation/Rewards Std         0.12943900682541418
evaluation/Rewards Max         0.9785052298768213
evaluation/Rewards Min         0.5053169026641087
evaluation/Returns Mean        430.7635303654175
evaluation/Returns Std         55.06986510818122
evaluation/Returns Max         472.5730494091487
evaluation/Returns Min         337.0681845763995
evaluation/ExplReturns Mean    430.7635303654175
evaluation/ExplReturns Std     55.06986510818122
evaluation/ExplReturns Max     472.5730494091487
evaluation/ExplReturns Min     337.0681845763995
evaluation/Actions Mean        0.015190006
evaluation/Actions Std         0.59307206
evaluation/Actions Max         0.98762494
evaluation/Actions Min         -0.9928177
evaluation/Num Paths           10
evaluation/Average Returns     430.7635303654175
time/data storing (s)          0.03432330954819918
time/evaluation sampling (s)   113.39207061287016
time/exploration sampling (s)  112.56953325215727
time/logging (s)               0.030150556936860085
time/saving (s)                0.011103516444563866
time/training (s)              9.502084387466311
time/epoch (s)                 235.53926563542336
time/total (s)                 30959.56891065277
Epoch                          131
-----------------------------  --------------------
2023-08-01 02:34:07.132495 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 132 finished
-----------------------------  ---------------------
replay_buffer/size             666000
trainer/tdrp Loss              [4034.1165]
trainer/QF1 Loss               0.16149077
trainer/QF2 Loss               0.14230306
trainer/Policy Loss            -61.33756
trainer/Q1 Predictions Mean    74.336136
trainer/Q1 Predictions Std     6.206979
trainer/Q1 Predictions Max     86.050224
trainer/Q1 Predictions Min     46.811966
trainer/Q2 Predictions Mean    74.21276
trainer/Q2 Predictions Std     6.2151585
trainer/Q2 Predictions Max     85.82402
trainer/Q2 Predictions Min     46.444763
trainer/Q Targets Mean         74.29768
trainer/Q Targets Std          6.192925
trainer/Q Targets Max          86.183304
trainer/Q Targets Min          47.74212
trainer/Log Pis Mean           13.122025
trainer/Log Pis Std            6.9534883
trainer/Log Pis Max            33.76014
trainer/Log Pis Min            -2.4370794
trainer/Policy mu Mean         0.0691753
trainer/Policy mu Std          1.6938895
trainer/Policy mu Max          5.652148
trainer/Policy mu Min          -4.1670227
trainer/Policy log std Mean    -0.5843157
trainer/Policy log std Std     0.16004582
trainer/Policy log std Max     0.22771466
trainer/Policy log std Min     -1.357603
trainer/Alpha                  0.0032117979135364294
trainer/Alpha Loss             6.441719055175781
exploration/num steps total    666000
exploration/num paths total    1332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8158835577301332
exploration/Rewards Std        0.12260751903778017
exploration/Rewards Max        0.9778935329644091
exploration/Rewards Min        0.4963049183310939
exploration/Returns Mean       407.94177886506657
exploration/Returns Std        41.01857446545606
exploration/Returns Max        465.5815336965353
exploration/Returns Min        359.0360362692887
exploration/Actions Mean       0.113532454
exploration/Actions Std        0.650107
exploration/Actions Max        0.9996038
exploration/Actions Min        -0.9995334
exploration/Num Paths          10
exploration/Average Returns    407.94177886506657
evaluation/num steps total     665000
evaluation/num paths total     1330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8090971145626229
evaluation/Rewards Std         0.12191824054613482
evaluation/Rewards Max         0.9749210811992732
evaluation/Rewards Min         0.501891792614628
evaluation/Returns Mean        404.5485572813115
evaluation/Returns Std         53.63564861706886
evaluation/Returns Max         470.4698444994071
evaluation/Returns Min         358.0887544776062
evaluation/ExplReturns Mean    404.5485572813115
evaluation/ExplReturns Std     53.63564861706886
evaluation/ExplReturns Max     470.4698444994071
evaluation/ExplReturns Min     358.0887544776062
evaluation/Actions Mean        0.14259031
evaluation/Actions Std         0.5919858
evaluation/Actions Max         0.9996799
evaluation/Actions Min         -0.9978071
evaluation/Num Paths           10
evaluation/Average Returns     404.5485572813115
time/data storing (s)          0.03418425377458334
time/evaluation sampling (s)   115.15006196592003
time/exploration sampling (s)  114.58449276629835
time/logging (s)               0.03054871130734682
time/saving (s)                0.012562408111989498
time/training (s)              9.555780973285437
time/epoch (s)                 239.36763107869774
time/total (s)                 31198.939250712283
Epoch                          132
-----------------------------  ---------------------
2023-08-01 02:38:01.869711 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 133 finished
-----------------------------  --------------------
replay_buffer/size             671000
trainer/tdrp Loss              [3424.638]
trainer/QF1 Loss               0.16003186
trainer/QF2 Loss               0.15468231
trainer/Policy Loss            -63.673492
trainer/Q1 Predictions Mean    75.623856
trainer/Q1 Predictions Std     6.7198267
trainer/Q1 Predictions Max     86.55764
trainer/Q1 Predictions Min     44.73902
trainer/Q2 Predictions Mean    75.62883
trainer/Q2 Predictions Std     6.743475
trainer/Q2 Predictions Max     86.58384
trainer/Q2 Predictions Min     43.646057
trainer/Q Targets Mean         75.48221
trainer/Q Targets Std          6.7650943
trainer/Q Targets Max          86.552864
trainer/Q Targets Min          43.577957
trainer/Log Pis Mean           12.109282
trainer/Log Pis Std            6.582348
trainer/Log Pis Max            29.993586
trainer/Log Pis Min            -4.0617437
trainer/Policy mu Mean         0.10456733
trainer/Policy mu Std          1.6313955
trainer/Policy mu Max          5.047507
trainer/Policy mu Min          -4.1747227
trainer/Policy log std Mean    -0.5903452
trainer/Policy log std Std     0.18327034
trainer/Policy log std Max     -0.028230548
trainer/Policy log std Min     -1.4397655
trainer/Alpha                  0.003170502372086048
trainer/Alpha Loss             0.6288065910339355
exploration/num steps total    671000
exploration/num paths total    1342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9087630778413278
exploration/Rewards Std        0.1087373072050605
exploration/Rewards Max        0.9750712331948712
exploration/Rewards Min        0.4403401780432765
exploration/Returns Mean       454.38153892066396
exploration/Returns Std        5.86002469519182
exploration/Returns Max        463.5367242702679
exploration/Returns Min        444.0498163405683
exploration/Actions Mean       0.04253387
exploration/Actions Std        0.6522198
exploration/Actions Max        0.9999385
exploration/Actions Min        -0.9999082
exploration/Num Paths          10
exploration/Average Returns    454.38153892066396
evaluation/num steps total     670000
evaluation/num paths total     1340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8130832002895653
evaluation/Rewards Std         0.13617629976774323
evaluation/Rewards Max         0.9725314105227065
evaluation/Rewards Min         0.5003642173400492
evaluation/Returns Mean        406.54160014478265
evaluation/Returns Std         20.570554990256507
evaluation/Returns Max         440.7145006536979
evaluation/Returns Min         367.8133112037412
evaluation/ExplReturns Mean    406.54160014478265
evaluation/ExplReturns Std     20.570554990256507
evaluation/ExplReturns Max     440.7145006536979
evaluation/ExplReturns Min     367.8133112037412
evaluation/Actions Mean        0.016616732
evaluation/Actions Std         0.60784847
evaluation/Actions Max         0.9973301
evaluation/Actions Min         -0.9978239
evaluation/Num Paths           10
evaluation/Average Returns     406.54160014478265
time/data storing (s)          0.033538869582116604
time/evaluation sampling (s)   113.06732289493084
time/exploration sampling (s)  112.02965933922678
time/logging (s)               0.030501938425004482
time/saving (s)                0.012820630334317684
time/training (s)              9.5592195186764
time/epoch (s)                 234.73306319117546
time/total (s)                 31433.674866251647
Epoch                          133
-----------------------------  --------------------
2023-08-01 02:41:58.444718 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 134 finished
-----------------------------  --------------------
replay_buffer/size             676000
trainer/tdrp Loss              [3524.618]
trainer/QF1 Loss               0.124657825
trainer/QF2 Loss               0.12554288
trainer/Policy Loss            -64.015526
trainer/Q1 Predictions Mean    75.385376
trainer/Q1 Predictions Std     6.2298393
trainer/Q1 Predictions Max     86.71876
trainer/Q1 Predictions Min     53.27736
trainer/Q2 Predictions Mean    75.41995
trainer/Q2 Predictions Std     6.2189713
trainer/Q2 Predictions Max     86.718346
trainer/Q2 Predictions Min     53.3211
trainer/Q Targets Mean         75.40304
trainer/Q Targets Std          6.243276
trainer/Q Targets Max          86.828636
trainer/Q Targets Min          53.52303
trainer/Log Pis Mean           11.550484
trainer/Log Pis Std            6.619325
trainer/Log Pis Max            31.88226
trainer/Log Pis Min            -4.570587
trainer/Policy mu Mean         0.034981593
trainer/Policy mu Std          1.5934765
trainer/Policy mu Max          5.7521634
trainer/Policy mu Min          -4.4884353
trainer/Policy log std Mean    -0.60478234
trainer/Policy log std Std     0.17678954
trainer/Policy log std Max     -0.022914648
trainer/Policy log std Min     -1.4828796
trainer/Alpha                  0.003125326242297888
trainer/Alpha Loss             -2.5928444862365723
exploration/num steps total    676000
exploration/num paths total    1352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7971867279944278
exploration/Rewards Std        0.12450388027884096
exploration/Rewards Max        0.9797958798586874
exploration/Rewards Min        0.49546573743933514
exploration/Returns Mean       398.59336399721394
exploration/Returns Std        32.671008895661124
exploration/Returns Max        451.4351864282271
exploration/Returns Min        355.8019934592603
exploration/Actions Mean       0.012993411
exploration/Actions Std        0.62497413
exploration/Actions Max        0.9998207
exploration/Actions Min        -0.99964494
exploration/Num Paths          10
exploration/Average Returns    398.59336399721394
evaluation/num steps total     675000
evaluation/num paths total     1350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7012359054592046
evaluation/Rewards Std         0.016830863815093286
evaluation/Rewards Max         0.7386057098457856
evaluation/Rewards Min         0.4791286565223639
evaluation/Returns Mean        350.61795272960217
evaluation/Returns Std         0.35700443934871007
evaluation/Returns Max         351.13404888002253
evaluation/Returns Min         349.88300332567184
evaluation/ExplReturns Mean    350.61795272960217
evaluation/ExplReturns Std     0.35700443934871007
evaluation/ExplReturns Max     351.13404888002253
evaluation/ExplReturns Min     349.88300332567184
evaluation/Actions Mean        0.033995
evaluation/Actions Std         0.5294635
evaluation/Actions Max         0.994089
evaluation/Actions Min         -0.9974724
evaluation/Num Paths           10
evaluation/Average Returns     350.61795272960217
time/data storing (s)          0.034220462664961815
time/evaluation sampling (s)   113.64189972449094
time/exploration sampling (s)  113.41501579340547
time/logging (s)               0.030998733825981617
time/saving (s)                0.011488460935652256
time/training (s)              9.437821106985211
time/epoch (s)                 236.57144428230822
time/total (s)                 31670.248818836175
Epoch                          134
-----------------------------  --------------------
2023-08-01 02:45:52.244648 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 135 finished
-----------------------------  --------------------
replay_buffer/size             681000
trainer/tdrp Loss              [3804.6406]
trainer/QF1 Loss               0.13201094
trainer/QF2 Loss               0.15742107
trainer/Policy Loss            -64.70741
trainer/Q1 Predictions Mean    76.267334
trainer/Q1 Predictions Std     5.9761543
trainer/Q1 Predictions Max     87.03268
trainer/Q1 Predictions Min     52.227566
trainer/Q2 Predictions Mean    76.32152
trainer/Q2 Predictions Std     5.9312215
trainer/Q2 Predictions Max     86.904274
trainer/Q2 Predictions Min     52.21377
trainer/Q Targets Mean         76.20291
trainer/Q Targets Std          5.985806
trainer/Q Targets Max          87.026985
trainer/Q Targets Min          52.067726
trainer/Log Pis Mean           11.764859
trainer/Log Pis Std            7.4410667
trainer/Log Pis Max            37.778244
trainer/Log Pis Min            -3.6601844
trainer/Policy mu Mean         -0.110098034
trainer/Policy mu Std          1.6237016
trainer/Policy mu Max          4.8262396
trainer/Policy mu Min          -4.445012
trainer/Policy log std Mean    -0.5933948
trainer/Policy log std Std     0.18843892
trainer/Policy log std Max     0.13840985
trainer/Policy log std Min     -1.4419234
trainer/Alpha                  0.003182317828759551
trainer/Alpha Loss             -1.3521064519882202
exploration/num steps total    681000
exploration/num paths total    1362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9340126058417786
exploration/Rewards Std        0.09731020648529154
exploration/Rewards Max        0.9796551175243486
exploration/Rewards Min        0.5027801068166208
exploration/Returns Mean       467.00630292088925
exploration/Returns Std        5.491258523690741
exploration/Returns Max        477.4167229942824
exploration/Returns Min        461.4101036158073
exploration/Actions Mean       0.024579665
exploration/Actions Std        0.6309123
exploration/Actions Max        0.99992037
exploration/Actions Min        -0.99972737
exploration/Num Paths          10
exploration/Average Returns    467.00630292088925
evaluation/num steps total     680000
evaluation/num paths total     1360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8263701189284725
evaluation/Rewards Std         0.13442504971442337
evaluation/Rewards Max         0.9782453365670094
evaluation/Rewards Min         0.5051488006184466
evaluation/Returns Mean        413.1850594642363
evaluation/Returns Std         60.16491755060374
evaluation/Returns Max         479.078009930533
evaluation/Returns Min         351.43518279949626
evaluation/ExplReturns Mean    413.1850594642363
evaluation/ExplReturns Std     60.16491755060374
evaluation/ExplReturns Max     479.078009930533
evaluation/ExplReturns Min     351.43518279949626
evaluation/Actions Mean        0.010428157
evaluation/Actions Std         0.5673009
evaluation/Actions Max         0.9976289
evaluation/Actions Min         -0.9970544
evaluation/Num Paths           10
evaluation/Average Returns     413.1850594642363
time/data storing (s)          0.033925775438547134
time/evaluation sampling (s)   112.03599099814892
time/exploration sampling (s)  112.22170882951468
time/logging (s)               0.03035162016749382
time/saving (s)                0.011237949132919312
time/training (s)              9.462064076215029
time/epoch (s)                 233.7952792486176
time/total (s)                 31904.0465504108
Epoch                          135
-----------------------------  --------------------
2023-08-01 02:49:48.233346 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 136 finished
-----------------------------  ---------------------
replay_buffer/size             686000
trainer/tdrp Loss              [3489.4116]
trainer/QF1 Loss               0.16771623
trainer/QF2 Loss               0.1461512
trainer/Policy Loss            -63.860947
trainer/Q1 Predictions Mean    75.84115
trainer/Q1 Predictions Std     6.8823137
trainer/Q1 Predictions Max     87.45408
trainer/Q1 Predictions Min     51.474083
trainer/Q2 Predictions Mean    75.88521
trainer/Q2 Predictions Std     6.8434534
trainer/Q2 Predictions Max     87.51787
trainer/Q2 Predictions Min     51.426216
trainer/Q Targets Mean         75.935616
trainer/Q Targets Std          6.811939
trainer/Q Targets Max          87.21378
trainer/Q Targets Min          51.629303
trainer/Log Pis Mean           12.230189
trainer/Log Pis Std            6.8892493
trainer/Log Pis Max            39.95279
trainer/Log Pis Min            -2.066804
trainer/Policy mu Mean         0.05868058
trainer/Policy mu Std          1.6461526
trainer/Policy mu Max          4.943698
trainer/Policy mu Min          -4.140788
trainer/Policy log std Mean    -0.6039059
trainer/Policy log std Std     0.18902697
trainer/Policy log std Max     -0.016494036
trainer/Policy log std Min     -1.4489379
trainer/Alpha                  0.0031884009949862957
trainer/Alpha Loss             1.3232187032699585
exploration/num steps total    686000
exploration/num paths total    1372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9254478925985113
exploration/Rewards Std        0.10310328866035477
exploration/Rewards Max        0.9796472020900251
exploration/Rewards Min        0.5001577474926536
exploration/Returns Mean       462.72394629925566
exploration/Returns Std        10.240842392339326
exploration/Returns Max        477.7704154400136
exploration/Returns Min        448.7497763009993
exploration/Actions Mean       0.10283953
exploration/Actions Std        0.65392566
exploration/Actions Max        0.9998164
exploration/Actions Min        -0.9997018
exploration/Num Paths          10
exploration/Average Returns    462.72394629925566
evaluation/num steps total     685000
evaluation/num paths total     1370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9052362132046085
evaluation/Rewards Std         0.11556934727889916
evaluation/Rewards Max         0.9795173239263747
evaluation/Rewards Min         0.4937998555805958
evaluation/Returns Mean        452.6181066023044
evaluation/Returns Std         48.19221543902377
evaluation/Returns Max         479.4893902184249
evaluation/Returns Min         356.07252332290557
evaluation/ExplReturns Mean    452.6181066023044
evaluation/ExplReturns Std     48.19221543902377
evaluation/ExplReturns Max     479.4893902184249
evaluation/ExplReturns Min     356.07252332290557
evaluation/Actions Mean        0.09536217
evaluation/Actions Std         0.61634594
evaluation/Actions Max         0.9973423
evaluation/Actions Min         -0.9956563
evaluation/Num Paths           10
evaluation/Average Returns     452.6181066023044
time/data storing (s)          0.03426132071763277
time/evaluation sampling (s)   113.11767225060612
time/exploration sampling (s)  113.27554218750447
time/logging (s)               0.030551917850971222
time/saving (s)                0.012303146533668041
time/training (s)              9.51446274574846
time/epoch (s)                 235.98479356896132
time/total (s)                 32140.033920577727
Epoch                          136
-----------------------------  ---------------------
2023-08-01 02:53:45.215068 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 137 finished
-----------------------------  ---------------------
replay_buffer/size             691000
trainer/tdrp Loss              [3475.6445]
trainer/QF1 Loss               0.147614
trainer/QF2 Loss               0.17873624
trainer/Policy Loss            -64.023315
trainer/Q1 Predictions Mean    76.307236
trainer/Q1 Predictions Std     6.3257833
trainer/Q1 Predictions Max     87.30062
trainer/Q1 Predictions Min     53.275887
trainer/Q2 Predictions Mean    76.1892
trainer/Q2 Predictions Std     6.2891846
trainer/Q2 Predictions Max     87.2197
trainer/Q2 Predictions Min     52.9447
trainer/Q Targets Mean         76.30815
trainer/Q Targets Std          6.3965616
trainer/Q Targets Max          87.63336
trainer/Q Targets Min          53.297504
trainer/Log Pis Mean           12.424654
trainer/Log Pis Std            7.3353734
trainer/Log Pis Max            40.16582
trainer/Log Pis Min            -3.7591767
trainer/Policy mu Mean         -0.019066967
trainer/Policy mu Std          1.6740941
trainer/Policy mu Max          5.001604
trainer/Policy mu Min          -4.6029477
trainer/Policy log std Mean    -0.6023797
trainer/Policy log std Std     0.17710952
trainer/Policy log std Max     -0.045565203
trainer/Policy log std Min     -1.5267655
trainer/Alpha                  0.0031782672740519047
trainer/Alpha Loss             2.4424667358398438
exploration/num steps total    691000
exploration/num paths total    1382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8895246262785579
exploration/Rewards Std        0.12457459072718968
exploration/Rewards Max        0.9783559636785228
exploration/Rewards Min        0.5082648912572477
exploration/Returns Mean       444.76231313927894
exploration/Returns Std        35.79246571870789
exploration/Returns Max        467.44660235230646
exploration/Returns Min        340.251218765164
exploration/Actions Mean       0.05032507
exploration/Actions Std        0.6453103
exploration/Actions Max        0.9999272
exploration/Actions Min        -0.9998614
exploration/Num Paths          10
exploration/Average Returns    444.76231313927894
evaluation/num steps total     690000
evaluation/num paths total     1380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7176583430808469
evaluation/Rewards Std         0.06595492738821343
evaluation/Rewards Max         0.9673184958196208
evaluation/Rewards Min         0.5094693153679902
evaluation/Returns Mean        358.8291715404233
evaluation/Returns Std         25.187840796976666
evaluation/Returns Max         434.13566447451615
evaluation/Returns Min         347.06943095756435
evaluation/ExplReturns Mean    358.8291715404233
evaluation/ExplReturns Std     25.187840796976666
evaluation/ExplReturns Max     434.13566447451615
evaluation/ExplReturns Min     347.06943095756435
evaluation/Actions Mean        -0.04312607
evaluation/Actions Std         0.56897277
evaluation/Actions Max         0.99936974
evaluation/Actions Min         -0.9997306
evaluation/Num Paths           10
evaluation/Average Returns     358.8291715404233
time/data storing (s)          0.03436210099607706
time/evaluation sampling (s)   114.72609520051628
time/exploration sampling (s)  112.50519052520394
time/logging (s)               0.030533858574926853
time/saving (s)                0.010657072998583317
time/training (s)              9.6707473564893
time/epoch (s)                 236.97758611477911
time/total (s)                 32377.01407380402
Epoch                          137
-----------------------------  ---------------------
2023-08-01 02:57:39.676327 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 138 finished
-----------------------------  ---------------------
replay_buffer/size             696000
trainer/tdrp Loss              [3201.0642]
trainer/QF1 Loss               0.16486496
trainer/QF2 Loss               0.16408555
trainer/Policy Loss            -64.752426
trainer/Q1 Predictions Mean    76.79899
trainer/Q1 Predictions Std     6.4284177
trainer/Q1 Predictions Max     88.03591
trainer/Q1 Predictions Min     50.919186
trainer/Q2 Predictions Mean    76.834274
trainer/Q2 Predictions Std     6.408372
trainer/Q2 Predictions Max     88.047874
trainer/Q2 Predictions Min     50.869396
trainer/Q Targets Mean         76.94444
trainer/Q Targets Std          6.4577208
trainer/Q Targets Max          87.99434
trainer/Q Targets Min          51.095707
trainer/Log Pis Mean           12.256187
trainer/Log Pis Std            6.9635267
trainer/Log Pis Max            30.491596
trainer/Log Pis Min            -7.290042
trainer/Policy mu Mean         -0.0018529476
trainer/Policy mu Std          1.6542534
trainer/Policy mu Max          4.4517174
trainer/Policy mu Min          -4.77129
trainer/Policy log std Mean    -0.5922584
trainer/Policy log std Std     0.1750631
trainer/Policy log std Max     0.051291764
trainer/Policy log std Min     -1.3589118
trainer/Alpha                  0.0032285486813634634
trainer/Alpha Loss             1.469443440437317
exploration/num steps total    696000
exploration/num paths total    1392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.774766914663012
exploration/Rewards Std        0.06862918714179107
exploration/Rewards Max        0.9785141376819587
exploration/Rewards Min        0.5145485160530002
exploration/Returns Mean       387.38345733150607
exploration/Returns Std        7.2960793515459
exploration/Returns Max        404.1084829139201
exploration/Returns Min        379.50732259074516
exploration/Actions Mean       0.09347333
exploration/Actions Std        0.64819044
exploration/Actions Max        0.99970144
exploration/Actions Min        -0.9998565
exploration/Num Paths          10
exploration/Average Returns    387.38345733150607
evaluation/num steps total     695000
evaluation/num paths total     1390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7396839432021698
evaluation/Rewards Std         0.04485775902311794
evaluation/Rewards Max         0.9693850066134418
evaluation/Rewards Min         0.5111185418948415
evaluation/Returns Mean        369.8419716010848
evaluation/Returns Std         12.276087136151023
evaluation/Returns Max         380.5825355563713
evaluation/Returns Min         345.10120418369314
evaluation/ExplReturns Mean    369.8419716010848
evaluation/ExplReturns Std     12.276087136151023
evaluation/ExplReturns Max     380.5825355563713
evaluation/ExplReturns Min     345.10120418369314
evaluation/Actions Mean        0.06832218
evaluation/Actions Std         0.5818432
evaluation/Actions Max         0.99902695
evaluation/Actions Min         -0.99836516
evaluation/Num Paths           10
evaluation/Average Returns     369.8419716010848
time/data storing (s)          0.034205482341349125
time/evaluation sampling (s)   112.3115577576682
time/exploration sampling (s)  112.5098056672141
time/logging (s)               0.030760987661778927
time/saving (s)                0.010269129648804665
time/training (s)              9.560774262994528
time/epoch (s)                 234.45737328752875
time/total (s)                 32611.473978551105
Epoch                          138
-----------------------------  ---------------------
2023-08-01 03:01:36.022469 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 139 finished
-----------------------------  --------------------
replay_buffer/size             701000
trainer/tdrp Loss              [3436.1868]
trainer/QF1 Loss               0.13982357
trainer/QF2 Loss               0.11703912
trainer/Policy Loss            -66.24707
trainer/Q1 Predictions Mean    77.32071
trainer/Q1 Predictions Std     6.467667
trainer/Q1 Predictions Max     88.428154
trainer/Q1 Predictions Min     57.253693
trainer/Q2 Predictions Mean    77.20082
trainer/Q2 Predictions Std     6.492121
trainer/Q2 Predictions Max     88.31
trainer/Q2 Predictions Min     56.902092
trainer/Q Targets Mean         77.25183
trainer/Q Targets Std          6.4828205
trainer/Q Targets Max          88.31594
trainer/Q Targets Min          57.700493
trainer/Log Pis Mean           11.165542
trainer/Log Pis Std            6.3549113
trainer/Log Pis Max            41.970894
trainer/Log Pis Min            -0.71674824
trainer/Policy mu Mean         -0.0007797703
trainer/Policy mu Std          1.5800403
trainer/Policy mu Max          5.098416
trainer/Policy mu Min          -5.883216
trainer/Policy log std Mean    -0.6136414
trainer/Policy log std Std     0.19096172
trainer/Policy log std Max     0.18561095
trainer/Policy log std Min     -1.449208
trainer/Alpha                  0.003218936501070857
trainer/Alpha Loss             -4.788545608520508
exploration/num steps total    701000
exploration/num paths total    1402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8990098501348959
exploration/Rewards Std        0.11844987273737292
exploration/Rewards Max        0.9797135477150981
exploration/Rewards Min        0.5063664772467064
exploration/Returns Mean       449.504925067448
exploration/Returns Std        32.58072673180499
exploration/Returns Max        470.0469646123948
exploration/Returns Min        355.20434569808975
exploration/Actions Mean       0.040872924
exploration/Actions Std        0.6312677
exploration/Actions Max        0.9996956
exploration/Actions Min        -0.9999529
exploration/Num Paths          10
exploration/Average Returns    449.504925067448
evaluation/num steps total     700000
evaluation/num paths total     1400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7754587373256587
evaluation/Rewards Std         0.11760630798734012
evaluation/Rewards Max         0.9796408438445342
evaluation/Rewards Min         0.5082345818561133
evaluation/Returns Mean        387.7293686628293
evaluation/Returns Std         52.29848741997378
evaluation/Returns Max         470.61210259719024
evaluation/Returns Min         352.6089948611794
evaluation/ExplReturns Mean    387.7293686628293
evaluation/ExplReturns Std     52.29848741997378
evaluation/ExplReturns Max     470.61210259719024
evaluation/ExplReturns Min     352.6089948611794
evaluation/Actions Mean        0.011583043
evaluation/Actions Std         0.55024946
evaluation/Actions Max         0.9976686
evaluation/Actions Min         -0.999977
evaluation/Num Paths           10
evaluation/Average Returns     387.7293686628293
time/data storing (s)          0.034447490237653255
time/evaluation sampling (s)   113.31391913909465
time/exploration sampling (s)  113.38925624080002
time/logging (s)               0.030458600260317326
time/saving (s)                0.010278292931616306
time/training (s)              9.563142570666969
time/epoch (s)                 236.34150233399123
time/total (s)                 32847.81824294757
Epoch                          139
-----------------------------  --------------------
2023-08-01 03:05:29.897267 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 140 finished
-----------------------------  --------------------
replay_buffer/size             706000
trainer/tdrp Loss              [3500.8406]
trainer/QF1 Loss               0.15181834
trainer/QF2 Loss               0.18513517
trainer/Policy Loss            -65.27739
trainer/Q1 Predictions Mean    77.07578
trainer/Q1 Predictions Std     6.836719
trainer/Q1 Predictions Max     88.764725
trainer/Q1 Predictions Min     56.739826
trainer/Q2 Predictions Mean    77.107834
trainer/Q2 Predictions Std     6.8269696
trainer/Q2 Predictions Max     88.82875
trainer/Q2 Predictions Min     56.780216
trainer/Q Targets Mean         76.98599
trainer/Q Targets Std          6.8482533
trainer/Q Targets Max          88.765305
trainer/Q Targets Min          55.583412
trainer/Log Pis Mean           11.981031
trainer/Log Pis Std            7.0783787
trainer/Log Pis Max            36.371643
trainer/Log Pis Min            -7.9547396
trainer/Policy mu Mean         0.07131278
trainer/Policy mu Std          1.6319926
trainer/Policy mu Max          4.7602377
trainer/Policy mu Min          -4.915402
trainer/Policy log std Mean    -0.5938847
trainer/Policy log std Std     0.18544917
trainer/Policy log std Max     -0.015644133
trainer/Policy log std Min     -1.4603806
trainer/Alpha                  0.003191616851836443
trainer/Alpha Loss             -0.10901892185211182
exploration/num steps total    706000
exploration/num paths total    1412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9457049260865968
exploration/Rewards Std        0.06850902357958671
exploration/Rewards Max        0.9786285232073104
exploration/Rewards Min        0.5049777383896348
exploration/Returns Mean       472.8524630432983
exploration/Returns Std        2.894219055559347
exploration/Returns Max        476.9822913265984
exploration/Returns Min        467.4635535850628
exploration/Actions Mean       0.08115171
exploration/Actions Std        0.6296708
exploration/Actions Max        0.99950755
exploration/Actions Min        -0.9999944
exploration/Num Paths          10
exploration/Average Returns    472.8524630432983
evaluation/num steps total     705000
evaluation/num paths total     1410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8755740399669124
evaluation/Rewards Std         0.12631371339362138
evaluation/Rewards Max         0.9787104892756965
evaluation/Rewards Min         0.511687571553365
evaluation/Returns Mean        437.78701998345616
evaluation/Returns Std         48.01348223710826
evaluation/Returns Max         475.1596398773197
evaluation/Returns Min         343.49839966716314
evaluation/ExplReturns Mean    437.78701998345616
evaluation/ExplReturns Std     48.01348223710826
evaluation/ExplReturns Max     475.1596398773197
evaluation/ExplReturns Min     343.49839966716314
evaluation/Actions Mean        0.052947026
evaluation/Actions Std         0.588707
evaluation/Actions Max         0.9958158
evaluation/Actions Min         -0.99949634
evaluation/Num Paths           10
evaluation/Average Returns     437.78701998345616
time/data storing (s)          0.03376960847526789
time/evaluation sampling (s)   111.82705019507557
time/exploration sampling (s)  112.35727496258914
time/logging (s)               0.030856831930577755
time/saving (s)                0.011141536757349968
time/training (s)              9.611068475991488
time/epoch (s)                 233.8711616108194
time/total (s)                 33081.691812526435
Epoch                          140
-----------------------------  --------------------
2023-08-01 03:09:22.970157 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 141 finished
-----------------------------  ---------------------
replay_buffer/size             711000
trainer/tdrp Loss              [3693.1147]
trainer/QF1 Loss               0.19269562
trainer/QF2 Loss               0.19828576
trainer/Policy Loss            -64.827675
trainer/Q1 Predictions Mean    76.68564
trainer/Q1 Predictions Std     7.244577
trainer/Q1 Predictions Max     89.483826
trainer/Q1 Predictions Min     51.716583
trainer/Q2 Predictions Mean    76.7129
trainer/Q2 Predictions Std     7.2684374
trainer/Q2 Predictions Max     89.589134
trainer/Q2 Predictions Min     51.628914
trainer/Q Targets Mean         76.85387
trainer/Q Targets Std          7.282044
trainer/Q Targets Max          89.69943
trainer/Q Targets Min          52.727192
trainer/Log Pis Mean           12.076027
trainer/Log Pis Std            7.073326
trainer/Log Pis Max            35.35212
trainer/Log Pis Min            -6.8398376
trainer/Policy mu Mean         0.04561868
trainer/Policy mu Std          1.6344413
trainer/Policy mu Max          4.607583
trainer/Policy mu Min          -4.5903535
trainer/Policy log std Mean    -0.60839677
trainer/Policy log std Std     0.17834616
trainer/Policy log std Max     0.07659823
trainer/Policy log std Min     -1.4079242
trainer/Alpha                  0.0032286904752254486
trainer/Alpha Loss             0.43605726957321167
exploration/num steps total    711000
exploration/num paths total    1422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9284488003581207
exploration/Rewards Std        0.10068384562214819
exploration/Rewards Max        0.979789181350191
exploration/Rewards Min        0.5084590418464316
exploration/Returns Mean       464.22440017906047
exploration/Returns Std        7.217047708742348
exploration/Returns Max        473.9554122663912
exploration/Returns Min        447.62889246769464
exploration/Actions Mean       -0.025068229
exploration/Actions Std        0.5974816
exploration/Actions Max        0.9993475
exploration/Actions Min        -0.9997127
exploration/Num Paths          10
exploration/Average Returns    464.22440017906047
evaluation/num steps total     710000
evaluation/num paths total     1420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8358467646978923
evaluation/Rewards Std         0.1416963998369682
evaluation/Rewards Max         0.9795314785661946
evaluation/Rewards Min         0.5092187721393379
evaluation/Returns Mean        417.92338234894635
evaluation/Returns Std         59.36555418197545
evaluation/Returns Max         475.095000232934
evaluation/Returns Min         344.75697338269356
evaluation/ExplReturns Mean    417.92338234894635
evaluation/ExplReturns Std     59.36555418197545
evaluation/ExplReturns Max     475.095000232934
evaluation/ExplReturns Min     344.75697338269356
evaluation/Actions Mean        -0.011742452
evaluation/Actions Std         0.55844015
evaluation/Actions Max         0.99745333
evaluation/Actions Min         -0.99837774
evaluation/Num Paths           10
evaluation/Average Returns     417.92338234894635
time/data storing (s)          0.034344048239290714
time/evaluation sampling (s)   111.75007737800479
time/exploration sampling (s)  111.6773757217452
time/logging (s)               0.030750324949622154
time/saving (s)                0.011915909126400948
time/training (s)              9.564263794571161
time/epoch (s)                 233.06872717663646
time/total (s)                 33314.76301397011
Epoch                          141
-----------------------------  ---------------------
2023-08-01 03:13:16.602265 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 142 finished
-----------------------------  ---------------------
replay_buffer/size             716000
trainer/tdrp Loss              [3318.2913]
trainer/QF1 Loss               0.15459809
trainer/QF2 Loss               0.18522678
trainer/Policy Loss            -65.70162
trainer/Q1 Predictions Mean    77.2692
trainer/Q1 Predictions Std     7.3420496
trainer/Q1 Predictions Max     90.31043
trainer/Q1 Predictions Min     54.116123
trainer/Q2 Predictions Mean    77.298996
trainer/Q2 Predictions Std     7.298766
trainer/Q2 Predictions Max     89.98767
trainer/Q2 Predictions Min     54.381847
trainer/Q Targets Mean         77.14981
trainer/Q Targets Std          7.3268228
trainer/Q Targets Max          89.66652
trainer/Q Targets Min          53.891876
trainer/Log Pis Mean           11.752655
trainer/Log Pis Std            6.9699802
trainer/Log Pis Max            36.345222
trainer/Log Pis Min            -5.2420464
trainer/Policy mu Mean         0.022445885
trainer/Policy mu Std          1.6267577
trainer/Policy mu Max          4.818365
trainer/Policy mu Min          -4.956108
trainer/Policy log std Mean    -0.6109881
trainer/Policy log std Std     0.17864673
trainer/Policy log std Max     0.030341744
trainer/Policy log std Min     -1.3843932
trainer/Alpha                  0.0033005583100020885
trainer/Alpha Loss             -1.413271188735962
exploration/num steps total    716000
exploration/num paths total    1432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7538405951762001
exploration/Rewards Std        0.1086446481986941
exploration/Rewards Max        0.9707617296647526
exploration/Rewards Min        0.5032663433606753
exploration/Returns Mean       376.9202975881001
exploration/Returns Std        38.80445728063816
exploration/Returns Max        447.3604955605002
exploration/Returns Min        348.7351575643407
exploration/Actions Mean       -0.08463452
exploration/Actions Std        0.641963
exploration/Actions Max        0.9996909
exploration/Actions Min        -0.99974227
exploration/Num Paths          10
exploration/Average Returns    376.9202975881001
evaluation/num steps total     715000
evaluation/num paths total     1430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.85756072782372
evaluation/Rewards Std         0.1271588747679946
evaluation/Rewards Max         0.9679054953049623
evaluation/Rewards Min         0.49631886454651286
evaluation/Returns Mean        428.78036391185987
evaluation/Returns Std         51.94988082730862
evaluation/Returns Max         466.3348161234025
evaluation/Returns Min         348.84214513713647
evaluation/ExplReturns Mean    428.78036391185987
evaluation/ExplReturns Std     51.94988082730862
evaluation/ExplReturns Max     466.3348161234025
evaluation/ExplReturns Min     348.84214513713647
evaluation/Actions Mean        -0.02763515
evaluation/Actions Std         0.54149854
evaluation/Actions Max         0.9982277
evaluation/Actions Min         -0.9988349
evaluation/Num Paths           10
evaluation/Average Returns     428.78036391185987
time/data storing (s)          0.03390746284276247
time/evaluation sampling (s)   111.98901700600982
time/exploration sampling (s)  112.00127552170306
time/logging (s)               0.03033164981752634
time/saving (s)                0.010329913347959518
time/training (s)              9.562703979201615
time/epoch (s)                 233.62756553292274
time/total (s)                 33548.39309399668
Epoch                          142
-----------------------------  ---------------------
2023-08-01 03:17:09.862558 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 143 finished
-----------------------------  --------------------
replay_buffer/size             721000
trainer/tdrp Loss              [3590.832]
trainer/QF1 Loss               0.14538714
trainer/QF2 Loss               0.16403896
trainer/Policy Loss            -65.30698
trainer/Q1 Predictions Mean    77.59735
trainer/Q1 Predictions Std     7.6716905
trainer/Q1 Predictions Max     90.026535
trainer/Q1 Predictions Min     58.005913
trainer/Q2 Predictions Mean    77.673676
trainer/Q2 Predictions Std     7.685219
trainer/Q2 Predictions Max     90.1062
trainer/Q2 Predictions Min     57.67044
trainer/Q Targets Mean         77.606
trainer/Q Targets Std          7.7718983
trainer/Q Targets Max          90.06219
trainer/Q Targets Min          57.348953
trainer/Log Pis Mean           12.522905
trainer/Log Pis Std            7.7813144
trainer/Log Pis Max            34.138824
trainer/Log Pis Min            -3.0635576
trainer/Policy mu Mean         0.018256158
trainer/Policy mu Std          1.643861
trainer/Policy mu Max          4.6684027
trainer/Policy mu Min          -4.357191
trainer/Policy log std Mean    -0.6193585
trainer/Policy log std Std     0.19732675
trainer/Policy log std Max     0.0206905
trainer/Policy log std Min     -1.5407974
trainer/Alpha                  0.003306953003630042
trainer/Alpha Loss             2.98675799369812
exploration/num steps total    721000
exploration/num paths total    1442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8934177759118666
exploration/Rewards Std        0.12010184410630938
exploration/Rewards Max        0.9798641171438933
exploration/Rewards Min        0.5033874702373854
exploration/Returns Mean       446.7088879559334
exploration/Returns Std        43.39737160348103
exploration/Returns Max        479.7616465313171
exploration/Returns Min        358.81206407792286
exploration/Actions Mean       0.028538523
exploration/Actions Std        0.5988983
exploration/Actions Max        0.9990875
exploration/Actions Min        -0.9999138
exploration/Num Paths          10
exploration/Average Returns    446.7088879559334
evaluation/num steps total     720000
evaluation/num paths total     1440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8863891103586189
evaluation/Rewards Std         0.12457039735458694
evaluation/Rewards Max         0.9786710483128334
evaluation/Rewards Min         0.5021050233463634
evaluation/Returns Mean        443.19455517930953
evaluation/Returns Std         45.44044205424124
evaluation/Returns Max         476.5587657681739
evaluation/Returns Min         348.23887956913023
evaluation/ExplReturns Mean    443.19455517930953
evaluation/ExplReturns Std     45.44044205424124
evaluation/ExplReturns Max     476.5587657681739
evaluation/ExplReturns Min     348.23887956913023
evaluation/Actions Mean        0.03016031
evaluation/Actions Std         0.55924976
evaluation/Actions Max         0.99787444
evaluation/Actions Min         -0.9976643
evaluation/Num Paths           10
evaluation/Average Returns     443.19455517930953
time/data storing (s)          0.033717275597155094
time/evaluation sampling (s)   111.7569922702387
time/exploration sampling (s)  111.83593116421252
time/logging (s)               0.030520664528012276
time/saving (s)                0.012792923487722874
time/training (s)              9.586435304954648
time/epoch (s)                 233.25638960301876
time/total (s)                 33781.65193497203
Epoch                          143
-----------------------------  --------------------
2023-08-01 03:21:08.341590 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 144 finished
-----------------------------  ---------------------
replay_buffer/size             726000
trainer/tdrp Loss              [3504.8599]
trainer/QF1 Loss               0.14614081
trainer/QF2 Loss               0.16361503
trainer/Policy Loss            -65.16881
trainer/Q1 Predictions Mean    77.875496
trainer/Q1 Predictions Std     7.6043277
trainer/Q1 Predictions Max     90.54694
trainer/Q1 Predictions Min     52.144386
trainer/Q2 Predictions Mean    77.87128
trainer/Q2 Predictions Std     7.6102934
trainer/Q2 Predictions Max     90.605034
trainer/Q2 Predictions Min     52.31502
trainer/Q Targets Mean         77.84102
trainer/Q Targets Std          7.58246
trainer/Q Targets Max          90.48927
trainer/Q Targets Min          52.31818
trainer/Log Pis Mean           12.917845
trainer/Log Pis Std            7.416949
trainer/Log Pis Max            38.60146
trainer/Log Pis Min            -8.346279
trainer/Policy mu Mean         0.21186805
trainer/Policy mu Std          1.6793737
trainer/Policy mu Max          5.1904273
trainer/Policy mu Min          -4.3641596
trainer/Policy log std Mean    -0.6122062
trainer/Policy log std Std     0.20661348
trainer/Policy log std Max     0.26188856
trainer/Policy log std Min     -1.6116943
trainer/Alpha                  0.0033523556776344776
trainer/Alpha Loss             5.230348587036133
exploration/num steps total    726000
exploration/num paths total    1452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8310383479121894
exploration/Rewards Std        0.12901745547034973
exploration/Rewards Max        0.9794123606183288
exploration/Rewards Min        0.4982582171277583
exploration/Returns Mean       415.51917395609473
exploration/Returns Std        35.805731719794345
exploration/Returns Max        468.0487131044983
exploration/Returns Min        353.3373212224023
exploration/Actions Mean       0.060271263
exploration/Actions Std        0.63282335
exploration/Actions Max        0.99984366
exploration/Actions Min        -0.9998578
exploration/Num Paths          10
exploration/Average Returns    415.51917395609473
evaluation/num steps total     725000
evaluation/num paths total     1450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7200982790188375
evaluation/Rewards Std         0.07297366408344735
evaluation/Rewards Max         0.9782888647786143
evaluation/Rewards Min         0.5041178689125013
evaluation/Returns Mean        360.04913950941875
evaluation/Returns Std         31.43571480011389
evaluation/Returns Max         454.2426149489399
evaluation/Returns Min         345.17024698319614
evaluation/ExplReturns Mean    360.04913950941875
evaluation/ExplReturns Std     31.43571480011389
evaluation/ExplReturns Max     454.2426149489399
evaluation/ExplReturns Min     345.17024698319614
evaluation/Actions Mean        0.057883944
evaluation/Actions Std         0.5357939
evaluation/Actions Max         0.99951726
evaluation/Actions Min         -0.9984919
evaluation/Num Paths           10
evaluation/Average Returns     360.04913950941875
time/data storing (s)          0.03426625858992338
time/evaluation sampling (s)   114.38628375064582
time/exploration sampling (s)  114.37377568800002
time/logging (s)               0.03072851523756981
time/saving (s)                0.012094535864889622
time/training (s)              9.637788485735655
time/epoch (s)                 238.47493723407388
time/total (s)                 34020.12956072949
Epoch                          144
-----------------------------  ---------------------
2023-08-01 03:25:00.822340 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 145 finished
-----------------------------  --------------------
replay_buffer/size             731000
trainer/tdrp Loss              [3395.5571]
trainer/QF1 Loss               0.13917384
trainer/QF2 Loss               0.16188487
trainer/Policy Loss            -66.88967
trainer/Q1 Predictions Mean    78.39985
trainer/Q1 Predictions Std     7.431358
trainer/Q1 Predictions Max     90.859955
trainer/Q1 Predictions Min     57.703587
trainer/Q2 Predictions Mean    78.49183
trainer/Q2 Predictions Std     7.455849
trainer/Q2 Predictions Max     91.081566
trainer/Q2 Predictions Min     58.25257
trainer/Q Targets Mean         78.32735
trainer/Q Targets Std          7.4300833
trainer/Q Targets Max          90.98563
trainer/Q Targets Min          58.012268
trainer/Log Pis Mean           11.729044
trainer/Log Pis Std            7.6121564
trainer/Log Pis Max            32.64994
trainer/Log Pis Min            -6.651647
trainer/Policy mu Mean         0.18171203
trainer/Policy mu Std          1.6138487
trainer/Policy mu Max          4.3685365
trainer/Policy mu Min          -4.7173014
trainer/Policy log std Mean    -0.6211155
trainer/Policy log std Std     0.19941753
trainer/Policy log std Max     -0.019729733
trainer/Policy log std Min     -1.4733793
trainer/Alpha                  0.003277125768363476
trainer/Alpha Loss             -1.5500942468643188
exploration/num steps total    731000
exploration/num paths total    1462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8198401804607675
exploration/Rewards Std        0.12272561530894611
exploration/Rewards Max        0.9781251686113125
exploration/Rewards Min        0.4959454439095161
exploration/Returns Mean       409.92009023038355
exploration/Returns Std        35.06192493764921
exploration/Returns Max        458.7543467649408
exploration/Returns Min        368.4824497444081
exploration/Actions Mean       -0.02094111
exploration/Actions Std        0.6193775
exploration/Actions Max        0.9997664
exploration/Actions Min        -0.99966305
exploration/Num Paths          10
exploration/Average Returns    409.92009023038355
evaluation/num steps total     730000
evaluation/num paths total     1460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7530174546099723
evaluation/Rewards Std         0.0857520489859576
evaluation/Rewards Max         0.9307164629040265
evaluation/Rewards Min         0.4963165652768113
evaluation/Returns Mean        376.508727304986
evaluation/Returns Std         5.225314713283548
evaluation/Returns Max         385.08036878077905
evaluation/Returns Min         369.79465923642056
evaluation/ExplReturns Mean    376.508727304986
evaluation/ExplReturns Std     5.225314713283548
evaluation/ExplReturns Max     385.08036878077905
evaluation/ExplReturns Min     369.79465923642056
evaluation/Actions Mean        -0.07046843
evaluation/Actions Std         0.5722769
evaluation/Actions Max         0.99857265
evaluation/Actions Min         -0.9974648
evaluation/Num Paths           10
evaluation/Average Returns     376.508727304986
time/data storing (s)          0.034378050826489925
time/evaluation sampling (s)   111.46730616874993
time/exploration sampling (s)  111.90545508917421
time/logging (s)               0.030388811603188515
time/saving (s)                0.01030094362795353
time/training (s)              9.028522683307528
time/epoch (s)                 232.4763517472893
time/total (s)                 34252.60836706869
Epoch                          145
-----------------------------  --------------------
2023-08-01 03:28:55.749080 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 146 finished
-----------------------------  ---------------------
replay_buffer/size             736000
trainer/tdrp Loss              [3801.5754]
trainer/QF1 Loss               0.19398168
trainer/QF2 Loss               0.19501008
trainer/Policy Loss            -66.55269
trainer/Q1 Predictions Mean    78.39809
trainer/Q1 Predictions Std     6.8389163
trainer/Q1 Predictions Max     91.12741
trainer/Q1 Predictions Min     55.626175
trainer/Q2 Predictions Mean    78.37367
trainer/Q2 Predictions Std     6.8475833
trainer/Q2 Predictions Max     90.879295
trainer/Q2 Predictions Min     56.156364
trainer/Q Targets Mean         78.47493
trainer/Q Targets Std          6.8542466
trainer/Q Targets Max          91.00235
trainer/Q Targets Min          55.215813
trainer/Log Pis Mean           12.062897
trainer/Log Pis Std            6.9096303
trainer/Log Pis Max            33.347282
trainer/Log Pis Min            -4.394494
trainer/Policy mu Mean         0.2103287
trainer/Policy mu Std          1.6199702
trainer/Policy mu Max          4.424621
trainer/Policy mu Min          -4.4994035
trainer/Policy log std Mean    -0.6338047
trainer/Policy log std Std     0.18815118
trainer/Policy log std Max     -0.06831747
trainer/Policy log std Min     -1.4984143
trainer/Alpha                  0.0031948157120496035
trainer/Alpha Loss             0.36142146587371826
exploration/num steps total    736000
exploration/num paths total    1472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9110101226488623
exploration/Rewards Std        0.09845728365201606
exploration/Rewards Max        0.9758098312829905
exploration/Rewards Min        0.4920648832303498
exploration/Returns Mean       455.50506132443115
exploration/Returns Std        7.827512103711226
exploration/Returns Max        466.1830922503966
exploration/Returns Min        435.1984395852194
exploration/Actions Mean       0.026250048
exploration/Actions Std        0.5989787
exploration/Actions Max        0.9997825
exploration/Actions Min        -0.99981964
exploration/Num Paths          10
exploration/Average Returns    455.50506132443115
evaluation/num steps total     735000
evaluation/num paths total     1470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8222869756442335
evaluation/Rewards Std         0.12776439619782826
evaluation/Rewards Max         0.9665833431253387
evaluation/Rewards Min         0.5013211598934201
evaluation/Returns Mean        411.14348782211664
evaluation/Returns Std         46.994664671334945
evaluation/Returns Max         467.85687595195384
evaluation/Returns Min         352.7522422089859
evaluation/ExplReturns Mean    411.14348782211664
evaluation/ExplReturns Std     46.994664671334945
evaluation/ExplReturns Max     467.85687595195384
evaluation/ExplReturns Min     352.7522422089859
evaluation/Actions Mean        0.044071194
evaluation/Actions Std         0.5343203
evaluation/Actions Max         0.99994147
evaluation/Actions Min         -0.9996657
evaluation/Num Paths           10
evaluation/Average Returns     411.14348782211664
time/data storing (s)          0.034361706115305424
time/evaluation sampling (s)   112.83867798745632
time/exploration sampling (s)  112.37223078496754
time/logging (s)               0.030515930615365505
time/saving (s)                0.012231165543198586
time/training (s)              9.634742120280862
time/epoch (s)                 234.9227596949786
time/total (s)                 34487.53360419627
Epoch                          146
-----------------------------  ---------------------
2023-08-01 03:32:47.548292 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 147 finished
-----------------------------  ---------------------
replay_buffer/size             741000
trainer/tdrp Loss              [3444.0918]
trainer/QF1 Loss               0.17248271
trainer/QF2 Loss               0.13891844
trainer/Policy Loss            -66.878204
trainer/Q1 Predictions Mean    78.92868
trainer/Q1 Predictions Std     7.218984
trainer/Q1 Predictions Max     91.80039
trainer/Q1 Predictions Min     55.95268
trainer/Q2 Predictions Mean    78.92679
trainer/Q2 Predictions Std     7.197315
trainer/Q2 Predictions Max     91.75952
trainer/Q2 Predictions Min     55.908855
trainer/Q Targets Mean         78.84738
trainer/Q Targets Std          7.2259226
trainer/Q Targets Max          91.6997
trainer/Q Targets Min          56.91313
trainer/Log Pis Mean           12.240074
trainer/Log Pis Std            7.3744583
trainer/Log Pis Max            40.86252
trainer/Log Pis Min            -6.6715117
trainer/Policy mu Mean         -0.05058227
trainer/Policy mu Std          1.6262128
trainer/Policy mu Max          4.4620886
trainer/Policy mu Min          -4.0307336
trainer/Policy log std Mean    -0.62544554
trainer/Policy log std Std     0.19784321
trainer/Policy log std Max     0.0018613636
trainer/Policy log std Min     -1.5584081
trainer/Alpha                  0.0032341310288757086
trainer/Alpha Loss             1.3766173124313354
exploration/num steps total    741000
exploration/num paths total    1482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9147243314795587
exploration/Rewards Std        0.10895571479654455
exploration/Rewards Max        0.9797646945091268
exploration/Rewards Min        0.4984347477102068
exploration/Returns Mean       457.3621657397792
exploration/Returns Std        8.486426422235905
exploration/Returns Max        468.52502289781154
exploration/Returns Min        442.28803365190777
exploration/Actions Mean       0.04102155
exploration/Actions Std        0.6342903
exploration/Actions Max        0.9998471
exploration/Actions Min        -0.9998278
exploration/Num Paths          10
exploration/Average Returns    457.3621657397792
evaluation/num steps total     740000
evaluation/num paths total     1480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8038694863359276
evaluation/Rewards Std         0.13661381263571287
evaluation/Rewards Max         0.9788521610476568
evaluation/Rewards Min         0.5035028758506437
evaluation/Returns Mean        401.9347431679639
evaluation/Returns Std         46.055706201206675
evaluation/Returns Max         456.329199317081
evaluation/Returns Min         344.08490710878544
evaluation/ExplReturns Mean    401.9347431679639
evaluation/ExplReturns Std     46.055706201206675
evaluation/ExplReturns Max     456.329199317081
evaluation/ExplReturns Min     344.08490710878544
evaluation/Actions Mean        0.04623135
evaluation/Actions Std         0.5795574
evaluation/Actions Max         0.999807
evaluation/Actions Min         -0.9990659
evaluation/Num Paths           10
evaluation/Average Returns     401.9347431679639
time/data storing (s)          0.034320706501603127
time/evaluation sampling (s)   110.76587174274027
time/exploration sampling (s)  111.51462353020906
time/logging (s)               0.030323988758027554
time/saving (s)                0.01242843084037304
time/training (s)              9.437163099646568
time/epoch (s)                 231.7947314986959
time/total (s)                 34719.331002039835
Epoch                          147
-----------------------------  ---------------------
2023-08-01 03:36:43.523539 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 148 finished
-----------------------------  --------------------
replay_buffer/size             746000
trainer/tdrp Loss              [3358.4097]
trainer/QF1 Loss               0.16301522
trainer/QF2 Loss               0.13991798
trainer/Policy Loss            -66.76575
trainer/Q1 Predictions Mean    79.18506
trainer/Q1 Predictions Std     7.9859924
trainer/Q1 Predictions Max     91.948524
trainer/Q1 Predictions Min     51.22211
trainer/Q2 Predictions Mean    79.192154
trainer/Q2 Predictions Std     8.012517
trainer/Q2 Predictions Max     92.05959
trainer/Q2 Predictions Min     52.236492
trainer/Q Targets Mean         79.20733
trainer/Q Targets Std          8.036242
trainer/Q Targets Max          91.86885
trainer/Q Targets Min          50.966343
trainer/Log Pis Mean           12.623961
trainer/Log Pis Std            7.002982
trainer/Log Pis Max            38.476654
trainer/Log Pis Min            -3.1924777
trainer/Policy mu Mean         0.097238936
trainer/Policy mu Std          1.6398963
trainer/Policy mu Max          4.9152126
trainer/Policy mu Min          -4.5512333
trainer/Policy log std Mean    -0.6250134
trainer/Policy log std Std     0.20968741
trainer/Policy log std Max     0.074677944
trainer/Policy log std Min     -1.4755784
trainer/Alpha                  0.003400353016331792
trainer/Alpha Loss             3.5466086864471436
exploration/num steps total    746000
exploration/num paths total    1492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8383584732435018
exploration/Rewards Std        0.12807318414359545
exploration/Rewards Max        0.9794899776144237
exploration/Rewards Min        0.5124379144470419
exploration/Returns Mean       419.1792366217509
exploration/Returns Std        40.283517768063774
exploration/Returns Max        459.1656339775065
exploration/Returns Min        348.3296844894769
exploration/Actions Mean       0.0020320513
exploration/Actions Std        0.6387987
exploration/Actions Max        0.9997163
exploration/Actions Min        -0.99989724
exploration/Num Paths          10
exploration/Average Returns    419.1792366217509
evaluation/num steps total     745000
evaluation/num paths total     1490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7100974414458636
evaluation/Rewards Std         0.0170235055802251
evaluation/Rewards Max         0.7413888193954684
evaluation/Rewards Min         0.5053078958310138
evaluation/Returns Mean        355.04872072293176
evaluation/Returns Std         3.9411978933633502
evaluation/Returns Max         359.9935990472251
evaluation/Returns Min         346.70469946777837
evaluation/ExplReturns Mean    355.04872072293176
evaluation/ExplReturns Std     3.9411978933633502
evaluation/ExplReturns Max     359.9935990472251
evaluation/ExplReturns Min     346.70469946777837
evaluation/Actions Mean        -0.067068174
evaluation/Actions Std         0.6016656
evaluation/Actions Max         0.9988601
evaluation/Actions Min         -0.9994174
evaluation/Num Paths           10
evaluation/Average Returns     355.04872072293176
time/data storing (s)          0.034078205935657024
time/evaluation sampling (s)   114.48633477743715
time/exploration sampling (s)  111.76332231797278
time/logging (s)               0.03043289575725794
time/saving (s)                0.012506122700870037
time/training (s)              9.644569806754589
time/epoch (s)                 235.9712441265583
time/total (s)                 34955.304746273905
Epoch                          148
-----------------------------  --------------------
2023-08-01 03:40:37.039960 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 149 finished
-----------------------------  --------------------
replay_buffer/size             751000
trainer/tdrp Loss              [3798.9949]
trainer/QF1 Loss               0.16478302
trainer/QF2 Loss               0.17447251
trainer/Policy Loss            -69.62198
trainer/Q1 Predictions Mean    80.59956
trainer/Q1 Predictions Std     7.7196913
trainer/Q1 Predictions Max     91.860275
trainer/Q1 Predictions Min     60.331158
trainer/Q2 Predictions Mean    80.57814
trainer/Q2 Predictions Std     7.6748147
trainer/Q2 Predictions Max     91.84605
trainer/Q2 Predictions Min     60.629368
trainer/Q Targets Mean         80.66681
trainer/Q Targets Std          7.775585
trainer/Q Targets Max          92.03955
trainer/Q Targets Min          60.061802
trainer/Log Pis Mean           11.145151
trainer/Log Pis Std            6.8550286
trainer/Log Pis Max            33.45705
trainer/Log Pis Min            -4.4035597
trainer/Policy mu Mean         0.007187055
trainer/Policy mu Std          1.577005
trainer/Policy mu Max          4.4101343
trainer/Policy mu Min          -4.458862
trainer/Policy log std Mean    -0.6501164
trainer/Policy log std Std     0.22297661
trainer/Policy log std Max     -0.009947151
trainer/Policy log std Min     -1.6437861
trainer/Alpha                  0.003235442331060767
trainer/Alpha Loss             -4.901175022125244
exploration/num steps total    751000
exploration/num paths total    1502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8730552757536225
exploration/Rewards Std        0.12645713261212352
exploration/Rewards Max        0.979188042652935
exploration/Rewards Min        0.5118438930899141
exploration/Returns Mean       436.52763787681107
exploration/Returns Std        31.399451479267693
exploration/Returns Max        472.56370753243414
exploration/Returns Min        370.6667975016136
exploration/Actions Mean       0.04983838
exploration/Actions Std        0.6376169
exploration/Actions Max        0.9999558
exploration/Actions Min        -0.99991405
exploration/Num Paths          10
exploration/Average Returns    436.52763787681107
evaluation/num steps total     750000
evaluation/num paths total     1500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7647750675209951
evaluation/Rewards Std         0.11230422992627476
evaluation/Rewards Max         0.9780785108699395
evaluation/Rewards Min         0.5124280491330725
evaluation/Returns Mean        382.3875337604976
evaluation/Returns Std         46.443244880622345
evaluation/Returns Max         469.7428517728177
evaluation/Returns Min         347.3781512035427
evaluation/ExplReturns Mean    382.3875337604976
evaluation/ExplReturns Std     46.443244880622345
evaluation/ExplReturns Max     469.7428517728177
evaluation/ExplReturns Min     347.3781512035427
evaluation/Actions Mean        -0.01679067
evaluation/Actions Std         0.5678474
evaluation/Actions Max         0.9990462
evaluation/Actions Min         -0.9996041
evaluation/Num Paths           10
evaluation/Average Returns     382.3875337604976
time/data storing (s)          0.034269251860678196
time/evaluation sampling (s)   112.17179805599153
time/exploration sampling (s)  111.65144044999033
time/logging (s)               0.030444197356700897
time/saving (s)                0.011309043504297733
time/training (s)              9.61300279200077
time/epoch (s)                 233.5122637907043
time/total (s)                 35188.81952045672
Epoch                          149
-----------------------------  --------------------
2023-08-01 03:44:35.463318 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 150 finished
-----------------------------  ---------------------
replay_buffer/size             756000
trainer/tdrp Loss              [3496.2317]
trainer/QF1 Loss               0.17615569
trainer/QF2 Loss               0.15375538
trainer/Policy Loss            -68.50061
trainer/Q1 Predictions Mean    80.17288
trainer/Q1 Predictions Std     7.8765287
trainer/Q1 Predictions Max     92.37324
trainer/Q1 Predictions Min     54.043114
trainer/Q2 Predictions Mean    80.19731
trainer/Q2 Predictions Std     7.886057
trainer/Q2 Predictions Max     92.302826
trainer/Q2 Predictions Min     54.058994
trainer/Q Targets Mean         80.327866
trainer/Q Targets Std          7.887909
trainer/Q Targets Max          92.23601
trainer/Q Targets Min          53.909428
trainer/Log Pis Mean           11.884368
trainer/Log Pis Std            7.0686035
trainer/Log Pis Max            36.911865
trainer/Log Pis Min            -3.2167997
trainer/Policy mu Mean         0.03604571
trainer/Policy mu Std          1.6076244
trainer/Policy mu Max          5.0174994
trainer/Policy mu Min          -4.2044334
trainer/Policy log std Mean    -0.65548426
trainer/Policy log std Std     0.23103212
trainer/Policy log std Max     0.14218742
trainer/Policy log std Min     -1.6841623
trainer/Alpha                  0.0033706172835081816
trainer/Alpha Loss             -0.6582579016685486
exploration/num steps total    756000
exploration/num paths total    1512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9163119802342586
exploration/Rewards Std        0.10554899004639944
exploration/Rewards Max        0.9799087055622622
exploration/Rewards Min        0.5116636384455867
exploration/Returns Mean       458.1559901171292
exploration/Returns Std        14.107381197357823
exploration/Returns Max        467.67455569123416
exploration/Returns Min        427.0494015643083
exploration/Actions Mean       0.01435635
exploration/Actions Std        0.5932673
exploration/Actions Max        0.9999875
exploration/Actions Min        -0.99978423
exploration/Num Paths          10
exploration/Average Returns    458.1559901171292
evaluation/num steps total     755000
evaluation/num paths total     1510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7645683272990841
evaluation/Rewards Std         0.09759772103081922
evaluation/Rewards Max         0.9717243830627095
evaluation/Rewards Min         0.5023853659688485
evaluation/Returns Mean        382.28416364954205
evaluation/Returns Std         39.87517893245747
evaluation/Returns Max         462.6418234287586
evaluation/Returns Min         359.54942592514567
evaluation/ExplReturns Mean    382.28416364954205
evaluation/ExplReturns Std     39.87517893245747
evaluation/ExplReturns Max     462.6418234287586
evaluation/ExplReturns Min     359.54942592514567
evaluation/Actions Mean        0.023531845
evaluation/Actions Std         0.5749878
evaluation/Actions Max         0.9998839
evaluation/Actions Min         -0.9989136
evaluation/Num Paths           10
evaluation/Average Returns     382.28416364954205
time/data storing (s)          0.03413737379014492
time/evaluation sampling (s)   115.48439840693027
time/exploration sampling (s)  112.96701159048826
time/logging (s)               0.03083300031721592
time/saving (s)                0.010715203359723091
time/training (s)              9.892450761981308
time/epoch (s)                 238.41954633686692
time/total (s)                 35427.24159035366
Epoch                          150
-----------------------------  ---------------------
2023-08-01 03:48:28.275336 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 151 finished
-----------------------------  --------------------
replay_buffer/size             761000
trainer/tdrp Loss              [3209.6592]
trainer/QF1 Loss               0.15323201
trainer/QF2 Loss               0.1592463
trainer/Policy Loss            -68.470146
trainer/Q1 Predictions Mean    79.988266
trainer/Q1 Predictions Std     7.4328766
trainer/Q1 Predictions Max     92.72966
trainer/Q1 Predictions Min     54.871437
trainer/Q2 Predictions Mean    80.08065
trainer/Q2 Predictions Std     7.4528537
trainer/Q2 Predictions Max     92.77497
trainer/Q2 Predictions Min     54.71273
trainer/Q Targets Mean         79.966934
trainer/Q Targets Std          7.4498053
trainer/Q Targets Max          92.753975
trainer/Q Targets Min          54.668896
trainer/Log Pis Mean           11.771449
trainer/Log Pis Std            6.7764053
trainer/Log Pis Max            34.54158
trainer/Log Pis Min            -6.7795973
trainer/Policy mu Mean         -0.06083219
trainer/Policy mu Std          1.6109704
trainer/Policy mu Max          4.2228
trainer/Policy mu Min          -4.421899
trainer/Policy log std Mean    -0.6183691
trainer/Policy log std Std     0.20933169
trainer/Policy log std Max     0.060613215
trainer/Policy log std Min     -1.6074805
trainer/Alpha                  0.003418250009417534
trainer/Alpha Loss             -1.2978641986846924
exploration/num steps total    761000
exploration/num paths total    1522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9211965184855522
exploration/Rewards Std        0.09579646751235567
exploration/Rewards Max        0.9785229430280489
exploration/Rewards Min        0.5001938250472054
exploration/Returns Mean       460.5982592427763
exploration/Returns Std        4.406185310462833
exploration/Returns Max        467.4514034444513
exploration/Returns Min        451.5620333542968
exploration/Actions Mean       0.04163297
exploration/Actions Std        0.61800516
exploration/Actions Max        0.9998471
exploration/Actions Min        -0.99993676
exploration/Num Paths          10
exploration/Average Returns    460.5982592427763
evaluation/num steps total     760000
evaluation/num paths total     1520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9075078476939616
evaluation/Rewards Std         0.10782115167071239
evaluation/Rewards Max         0.9702906948453269
evaluation/Rewards Min         0.4998245197071904
evaluation/Returns Mean        453.7539238469808
evaluation/Returns Std         9.584957065108298
evaluation/Returns Max         468.34459787092703
evaluation/Returns Min         444.22550374006255
evaluation/ExplReturns Mean    453.7539238469808
evaluation/ExplReturns Std     9.584957065108298
evaluation/ExplReturns Max     468.34459787092703
evaluation/ExplReturns Min     444.22550374006255
evaluation/Actions Mean        0.05466569
evaluation/Actions Std         0.53384733
evaluation/Actions Max         0.9995724
evaluation/Actions Min         -0.99918073
evaluation/Num Paths           10
evaluation/Average Returns     453.7539238469808
time/data storing (s)          0.03407188318669796
time/evaluation sampling (s)   111.47808098047972
time/exploration sampling (s)  111.66501338128
time/logging (s)               0.031041601672768593
time/saving (s)                0.012084181420505047
time/training (s)              9.587800439447165
time/epoch (s)                 232.80809246748686
time/total (s)                 35660.052134006284
Epoch                          151
-----------------------------  --------------------
2023-08-01 03:52:17.797146 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 152 finished
-----------------------------  --------------------
replay_buffer/size             766000
trainer/tdrp Loss              [3551.191]
trainer/QF1 Loss               0.18776387
trainer/QF2 Loss               0.1687458
trainer/Policy Loss            -68.14606
trainer/Q1 Predictions Mean    79.92151
trainer/Q1 Predictions Std     7.6271377
trainer/Q1 Predictions Max     93.09569
trainer/Q1 Predictions Min     55.57816
trainer/Q2 Predictions Mean    79.86183
trainer/Q2 Predictions Std     7.6233387
trainer/Q2 Predictions Max     92.87456
trainer/Q2 Predictions Min     55.375393
trainer/Q Targets Mean         79.92441
trainer/Q Targets Std          7.6308765
trainer/Q Targets Max          92.85374
trainer/Q Targets Min          55.766777
trainer/Log Pis Mean           11.971383
trainer/Log Pis Std            7.121043
trainer/Log Pis Max            33.795494
trainer/Log Pis Min            -3.9115455
trainer/Policy mu Mean         0.13350557
trainer/Policy mu Std          1.6197248
trainer/Policy mu Max          5.0572987
trainer/Policy mu Min          -4.977553
trainer/Policy log std Mean    -0.61921006
trainer/Policy log std Std     0.22238463
trainer/Policy log std Max     -0.07321356
trainer/Policy log std Min     -1.7386506
trainer/Alpha                  0.003322622971609235
trainer/Alpha Loss             -0.16331881284713745
exploration/num steps total    766000
exploration/num paths total    1532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9304984148147288
exploration/Rewards Std        0.07973623963321502
exploration/Rewards Max        0.9789220512514989
exploration/Rewards Min        0.5030375618323915
exploration/Returns Mean       465.24920740736445
exploration/Returns Std        6.094174187430839
exploration/Returns Max        473.92675670852555
exploration/Returns Min        455.51083570242787
exploration/Actions Mean       0.085195586
exploration/Actions Std        0.6299781
exploration/Actions Max        0.9993327
exploration/Actions Min        -0.99934644
exploration/Num Paths          10
exploration/Average Returns    465.24920740736445
evaluation/num steps total     765000
evaluation/num paths total     1530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9483911421866349
evaluation/Rewards Std         0.06330299833767354
evaluation/Rewards Max         0.978869392604588
evaluation/Rewards Min         0.5033100637305208
evaluation/Returns Mean        474.19557109331754
evaluation/Returns Std         3.810240652401135
evaluation/Returns Max         476.2433062211574
evaluation/Returns Min         463.2302344283997
evaluation/ExplReturns Mean    474.19557109331754
evaluation/ExplReturns Std     3.810240652401135
evaluation/ExplReturns Max     476.2433062211574
evaluation/ExplReturns Min     463.2302344283997
evaluation/Actions Mean        0.095405266
evaluation/Actions Std         0.56240237
evaluation/Actions Max         0.9977293
evaluation/Actions Min         -0.99752545
evaluation/Num Paths           10
evaluation/Average Returns     474.19557109331754
time/data storing (s)          0.03387828078120947
time/evaluation sampling (s)   108.88628691527992
time/exploration sampling (s)  110.95075776893646
time/logging (s)               0.030643275007605553
time/saving (s)                0.01275966502726078
time/training (s)              9.60286250244826
time/epoch (s)                 229.51718840748072
time/total (s)                 35889.57187894732
Epoch                          152
-----------------------------  --------------------
2023-08-01 03:56:07.889127 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 153 finished
-----------------------------  ---------------------
replay_buffer/size             771000
trainer/tdrp Loss              [3542.0989]
trainer/QF1 Loss               0.17009227
trainer/QF2 Loss               0.17767599
trainer/Policy Loss            -68.55464
trainer/Q1 Predictions Mean    80.93216
trainer/Q1 Predictions Std     7.4132853
trainer/Q1 Predictions Max     93.48935
trainer/Q1 Predictions Min     61.826122
trainer/Q2 Predictions Mean    80.910805
trainer/Q2 Predictions Std     7.3802032
trainer/Q2 Predictions Max     93.41947
trainer/Q2 Predictions Min     62.093735
trainer/Q Targets Mean         80.85019
trainer/Q Targets Std          7.3217483
trainer/Q Targets Max          93.19135
trainer/Q Targets Min          62.13162
trainer/Log Pis Mean           12.580727
trainer/Log Pis Std            7.479227
trainer/Log Pis Max            35.737293
trainer/Log Pis Min            -3.8286698
trainer/Policy mu Mean         -0.07041967
trainer/Policy mu Std          1.6542346
trainer/Policy mu Max          5.41126
trainer/Policy mu Min          -4.963763
trainer/Policy log std Mean    -0.61194104
trainer/Policy log std Std     0.20890354
trainer/Policy log std Max     0.043934315
trainer/Policy log std Min     -1.6359998
trainer/Alpha                  0.0034423714969307184
trainer/Alpha Loss             3.2936763763427734
exploration/num steps total    771000
exploration/num paths total    1542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9321602197236946
exploration/Rewards Std        0.08912065085266575
exploration/Rewards Max        0.9788833544997445
exploration/Rewards Min        0.5028140950265073
exploration/Returns Mean       466.0801098618473
exploration/Returns Std        6.749815242294439
exploration/Returns Max        476.575556700623
exploration/Returns Min        457.08339787863423
exploration/Actions Mean       0.022810541
exploration/Actions Std        0.6184834
exploration/Actions Max        0.999413
exploration/Actions Min        -0.9998589
exploration/Num Paths          10
exploration/Average Returns    466.0801098618473
evaluation/num steps total     770000
evaluation/num paths total     1540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9266043507345028
evaluation/Rewards Std         0.09691932831020811
evaluation/Rewards Max         0.9770749637579563
evaluation/Rewards Min         0.5085123506567335
evaluation/Returns Mean        463.3021753672514
evaluation/Returns Std         10.15321406477173
evaluation/Returns Max         476.5148335109135
evaluation/Returns Min         444.6116177148806
evaluation/ExplReturns Mean    463.3021753672514
evaluation/ExplReturns Std     10.15321406477173
evaluation/ExplReturns Max     476.5148335109135
evaluation/ExplReturns Min     444.6116177148806
evaluation/Actions Mean        0.04181002
evaluation/Actions Std         0.53695494
evaluation/Actions Max         0.9986143
evaluation/Actions Min         -0.998788
evaluation/Num Paths           10
evaluation/Average Returns     463.3021753672514
time/data storing (s)          0.03381663095206022
time/evaluation sampling (s)   109.71029512118548
time/exploration sampling (s)  111.57144948653877
time/logging (s)               0.030193991027772427
time/saving (s)                0.011076437309384346
time/training (s)              8.730571014806628
time/epoch (s)                 230.0874026818201
time/total (s)                 36119.66175899375
Epoch                          153
-----------------------------  ---------------------
2023-08-01 04:00:01.139518 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 154 finished
-----------------------------  --------------------
replay_buffer/size             776000
trainer/tdrp Loss              [3432.5398]
trainer/QF1 Loss               0.1511148
trainer/QF2 Loss               0.14492175
trainer/Policy Loss            -68.669876
trainer/Q1 Predictions Mean    80.62394
trainer/Q1 Predictions Std     7.9285665
trainer/Q1 Predictions Max     93.981895
trainer/Q1 Predictions Min     58.075703
trainer/Q2 Predictions Mean    80.5361
trainer/Q2 Predictions Std     7.92239
trainer/Q2 Predictions Max     93.83324
trainer/Q2 Predictions Min     58.252346
trainer/Q Targets Mean         80.59457
trainer/Q Targets Std          7.9293385
trainer/Q Targets Max          93.47295
trainer/Q Targets Min          58.644535
trainer/Log Pis Mean           12.151457
trainer/Log Pis Std            7.407699
trainer/Log Pis Max            33.079296
trainer/Log Pis Min            -4.168463
trainer/Policy mu Mean         -0.0049822065
trainer/Policy mu Std          1.6272382
trainer/Policy mu Max          4.573111
trainer/Policy mu Min          -5.5372443
trainer/Policy log std Mean    -0.64353514
trainer/Policy log std Std     0.22296944
trainer/Policy log std Max     0.15883088
trainer/Policy log std Min     -1.7127752
trainer/Alpha                  0.003381762420758605
trainer/Alpha Loss             0.8617007732391357
exploration/num steps total    776000
exploration/num paths total    1552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9300048996929873
exploration/Rewards Std        0.0901609037391728
exploration/Rewards Max        0.9792635731026241
exploration/Rewards Min        0.503109820400432
exploration/Returns Mean       465.0024498464935
exploration/Returns Std        8.322022282266518
exploration/Returns Max        473.58823843583434
exploration/Returns Min        445.7632549771209
exploration/Actions Mean       0.03923443
exploration/Actions Std        0.6387518
exploration/Actions Max        0.99936426
exploration/Actions Min        -0.99934775
exploration/Num Paths          10
exploration/Average Returns    465.0024498464935
evaluation/num steps total     775000
evaluation/num paths total     1550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8208877484513352
evaluation/Rewards Std         0.13120410177393885
evaluation/Rewards Max         0.978789046873062
evaluation/Rewards Min         0.5044842440576685
evaluation/Returns Mean        410.4438742256674
evaluation/Returns Std         59.929178961839455
evaluation/Returns Max         471.8676283116467
evaluation/Returns Min         349.70493244035197
evaluation/ExplReturns Mean    410.4438742256674
evaluation/ExplReturns Std     59.929178961839455
evaluation/ExplReturns Max     471.8676283116467
evaluation/ExplReturns Min     349.70493244035197
evaluation/Actions Mean        0.02395052
evaluation/Actions Std         0.5435238
evaluation/Actions Max         0.9962714
evaluation/Actions Min         -0.9979289
evaluation/Num Paths           10
evaluation/Average Returns     410.4438742256674
time/data storing (s)          0.03398480173200369
time/evaluation sampling (s)   111.98636125586927
time/exploration sampling (s)  112.29084367211908
time/logging (s)               0.030305948108434677
time/saving (s)                0.010239757597446442
time/training (s)              8.894618920981884
time/epoch (s)                 233.24635435640812
time/total (s)                 36352.91060230322
Epoch                          154
-----------------------------  --------------------
2023-08-01 04:03:52.806116 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 155 finished
-----------------------------  ---------------------
replay_buffer/size             781000
trainer/tdrp Loss              [3749.9526]
trainer/QF1 Loss               0.15051849
trainer/QF2 Loss               0.16674273
trainer/Policy Loss            -70.481255
trainer/Q1 Predictions Mean    82.11571
trainer/Q1 Predictions Std     7.7418666
trainer/Q1 Predictions Max     93.961296
trainer/Q1 Predictions Min     61.531395
trainer/Q2 Predictions Mean    82.078766
trainer/Q2 Predictions Std     7.7356763
trainer/Q2 Predictions Max     93.95243
trainer/Q2 Predictions Min     61.75258
trainer/Q Targets Mean         82.08538
trainer/Q Targets Std          7.729599
trainer/Q Targets Max          93.876076
trainer/Q Targets Min          61.953403
trainer/Log Pis Mean           11.829785
trainer/Log Pis Std            7.0461216
trainer/Log Pis Max            32.48281
trainer/Log Pis Min            -7.556015
trainer/Policy mu Mean         0.10557415
trainer/Policy mu Std          1.5946007
trainer/Policy mu Max          3.9819527
trainer/Policy mu Min          -4.0055413
trainer/Policy log std Mean    -0.65715015
trainer/Policy log std Std     0.21914369
trainer/Policy log std Max     -0.06024331
trainer/Policy log std Min     -1.6957148
trainer/Alpha                  0.0033668552059680223
trainer/Alpha Loss             -0.9691592454910278
exploration/num steps total    781000
exploration/num paths total    1562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9347228809977179
exploration/Rewards Std        0.0853854022391953
exploration/Rewards Max        0.9794409729899796
exploration/Rewards Min        0.5076132874721091
exploration/Returns Mean       467.36144049885905
exploration/Returns Std        4.021468852132734
exploration/Returns Max        472.5102787750622
exploration/Returns Min        460.2142036353108
exploration/Actions Mean       0.058222383
exploration/Actions Std        0.62398857
exploration/Actions Max        0.9997939
exploration/Actions Min        -0.99972504
exploration/Num Paths          10
exploration/Average Returns    467.36144049885905
evaluation/num steps total     780000
evaluation/num paths total     1560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9268167404230253
evaluation/Rewards Std         0.0886031090875664
evaluation/Rewards Max         0.9755349679138224
evaluation/Rewards Min         0.506753097520276
evaluation/Returns Mean        463.40837021151265
evaluation/Returns Std         4.028970071573997
evaluation/Returns Max         470.85872257374996
evaluation/Returns Min         457.1542042051597
evaluation/ExplReturns Mean    463.40837021151265
evaluation/ExplReturns Std     4.028970071573997
evaluation/ExplReturns Max     470.85872257374996
evaluation/ExplReturns Min     457.1542042051597
evaluation/Actions Mean        0.08147147
evaluation/Actions Std         0.57761914
evaluation/Actions Max         0.99881804
evaluation/Actions Min         -0.9997031
evaluation/Num Paths           10
evaluation/Average Returns     463.40837021151265
time/data storing (s)          0.03417317010462284
time/evaluation sampling (s)   110.03847949113697
time/exploration sampling (s)  111.93547127675265
time/logging (s)               0.030374704860150814
time/saving (s)                0.010834702290594578
time/training (s)              9.613078653812408
time/epoch (s)                 231.6624119989574
time/total (s)                 36584.57559522707
Epoch                          155
-----------------------------  ---------------------
2023-08-01 04:07:46.585957 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 156 finished
-----------------------------  --------------------
replay_buffer/size             786000
trainer/tdrp Loss              [3733.8694]
trainer/QF1 Loss               0.17135772
trainer/QF2 Loss               0.14417969
trainer/Policy Loss            -70.44274
trainer/Q1 Predictions Mean    81.87657
trainer/Q1 Predictions Std     7.2830243
trainer/Q1 Predictions Max     94.00809
trainer/Q1 Predictions Min     59.404106
trainer/Q2 Predictions Mean    81.9184
trainer/Q2 Predictions Std     7.252236
trainer/Q2 Predictions Max     94.02628
trainer/Q2 Predictions Min     59.666164
trainer/Q Targets Mean         81.82584
trainer/Q Targets Std          7.232418
trainer/Q Targets Max          93.76195
trainer/Q Targets Min          59.744644
trainer/Log Pis Mean           11.673964
trainer/Log Pis Std            6.645978
trainer/Log Pis Max            29.104113
trainer/Log Pis Min            -2.893433
trainer/Policy mu Mean         0.011242621
trainer/Policy mu Std          1.5941652
trainer/Policy mu Max          4.64306
trainer/Policy mu Min          -4.1247196
trainer/Policy log std Mean    -0.63062066
trainer/Policy log std Std     0.2191482
trainer/Policy log std Max     0.086850524
trainer/Policy log std Min     -1.7132155
trainer/Alpha                  0.00342141673900187
trainer/Alpha Loss             -1.8510689735412598
exploration/num steps total    786000
exploration/num paths total    1572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9376398065003515
exploration/Rewards Std        0.08928751380358475
exploration/Rewards Max        0.9797695841072603
exploration/Rewards Min        0.49848442079688504
exploration/Returns Mean       468.81990325017586
exploration/Returns Std        8.029837412623081
exploration/Returns Max        479.3516330392404
exploration/Returns Min        452.22570041040024
exploration/Actions Mean       0.060593296
exploration/Actions Std        0.6410528
exploration/Actions Max        0.99995047
exploration/Actions Min        -0.9999381
exploration/Num Paths          10
exploration/Average Returns    468.81990325017586
evaluation/num steps total     785000
evaluation/num paths total     1570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8733082032359715
evaluation/Rewards Std         0.12663579348813894
evaluation/Rewards Max         0.97733119829993
evaluation/Rewards Min         0.506494329795051
evaluation/Returns Mean        436.6541016179858
evaluation/Returns Std         53.6242952216271
evaluation/Returns Max         476.27570368925
evaluation/Returns Min         353.14218727726177
evaluation/ExplReturns Mean    436.6541016179858
evaluation/ExplReturns Std     53.6242952216271
evaluation/ExplReturns Max     476.27570368925
evaluation/ExplReturns Min     353.14218727726177
evaluation/Actions Mean        0.04679036
evaluation/Actions Std         0.6030687
evaluation/Actions Max         0.9993241
evaluation/Actions Min         -0.9996559
evaluation/Num Paths           10
evaluation/Average Returns     436.6541016179858
time/data storing (s)          0.03395617660135031
time/evaluation sampling (s)   111.57933559454978
time/exploration sampling (s)  112.50748312100768
time/logging (s)               0.030460127629339695
time/saving (s)                0.010993550531566143
time/training (s)              9.613529226742685
time/epoch (s)                 233.7757577970624
time/total (s)                 36818.35382611025
Epoch                          156
-----------------------------  --------------------
2023-08-01 04:11:41.318361 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 157 finished
-----------------------------  --------------------
replay_buffer/size             791000
trainer/tdrp Loss              [3385.481]
trainer/QF1 Loss               0.2017749
trainer/QF2 Loss               0.21155779
trainer/Policy Loss            -69.86835
trainer/Q1 Predictions Mean    81.78916
trainer/Q1 Predictions Std     7.853572
trainer/Q1 Predictions Max     94.2793
trainer/Q1 Predictions Min     50.658394
trainer/Q2 Predictions Mean    81.82055
trainer/Q2 Predictions Std     7.8453054
trainer/Q2 Predictions Max     94.15396
trainer/Q2 Predictions Min     49.73048
trainer/Q Targets Mean         81.74702
trainer/Q Targets Std          7.932108
trainer/Q Targets Max          94.09211
trainer/Q Targets Min          49.624615
trainer/Log Pis Mean           12.176848
trainer/Log Pis Std            6.6058497
trainer/Log Pis Max            33.370564
trainer/Log Pis Min            -4.5358305
trainer/Policy mu Mean         0.043792408
trainer/Policy mu Std          1.6417476
trainer/Policy mu Max          4.668365
trainer/Policy mu Min          -4.6771383
trainer/Policy log std Mean    -0.6199692
trainer/Policy log std Std     0.21504454
trainer/Policy log std Max     0.0026771128
trainer/Policy log std Min     -1.6646737
trainer/Alpha                  0.003449446754530072
trainer/Alpha Loss             1.0026779174804688
exploration/num steps total    791000
exploration/num paths total    1582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9353271572350177
exploration/Rewards Std        0.09078252331187252
exploration/Rewards Max        0.978860336598538
exploration/Rewards Min        0.4885648073362009
exploration/Returns Mean       467.66357861750896
exploration/Returns Std        3.415891347347875
exploration/Returns Max        476.3354432067021
exploration/Returns Min        463.5003062731915
exploration/Actions Mean       0.07961175
exploration/Actions Std        0.65070283
exploration/Actions Max        0.9998568
exploration/Actions Min        -0.9999458
exploration/Num Paths          10
exploration/Average Returns    467.66357861750896
evaluation/num steps total     790000
evaluation/num paths total     1580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8972547728702852
evaluation/Rewards Std         0.1368660128631882
evaluation/Rewards Max         0.9775138548269136
evaluation/Rewards Min         0.4977028313106582
evaluation/Returns Mean        448.6273864351427
evaluation/Returns Std         51.5536699697354
evaluation/Returns Max         473.8895394484893
evaluation/Returns Min         294.76666060838977
evaluation/ExplReturns Mean    448.6273864351427
evaluation/ExplReturns Std     51.5536699697354
evaluation/ExplReturns Max     473.8895394484893
evaluation/ExplReturns Min     294.76666060838977
evaluation/Actions Mean        0.0763188
evaluation/Actions Std         0.6327394
evaluation/Actions Max         0.99981165
evaluation/Actions Min         -0.99914336
evaluation/Num Paths           10
evaluation/Average Returns     448.6273864351427
time/data storing (s)          0.03435070253908634
time/evaluation sampling (s)   112.93731213640422
time/exploration sampling (s)  112.13484210707247
time/logging (s)               0.03088284283876419
time/saving (s)                0.010408476926386356
time/training (s)              9.580793649889529
time/epoch (s)                 234.72858991567045
time/total (s)                 37053.084909211844
Epoch                          157
-----------------------------  --------------------
2023-08-01 04:15:38.919879 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 158 finished
-----------------------------  --------------------
replay_buffer/size             796000
trainer/tdrp Loss              [3375.919]
trainer/QF1 Loss               0.22373316
trainer/QF2 Loss               0.18148911
trainer/Policy Loss            -70.910706
trainer/Q1 Predictions Mean    82.24631
trainer/Q1 Predictions Std     7.9099116
trainer/Q1 Predictions Max     94.33168
trainer/Q1 Predictions Min     53.744453
trainer/Q2 Predictions Mean    82.25782
trainer/Q2 Predictions Std     7.918038
trainer/Q2 Predictions Max     94.21238
trainer/Q2 Predictions Min     53.209007
trainer/Q Targets Mean         82.50482
trainer/Q Targets Std          7.9501348
trainer/Q Targets Max          94.493355
trainer/Q Targets Min          52.539253
trainer/Log Pis Mean           11.578441
trainer/Log Pis Std            7.0350704
trainer/Log Pis Max            36.12745
trainer/Log Pis Min            -1.8784862
trainer/Policy mu Mean         -0.042540167
trainer/Policy mu Std          1.6051661
trainer/Policy mu Max          5.9509993
trainer/Policy mu Min          -4.8710203
trainer/Policy log std Mean    -0.6452221
trainer/Policy log std Std     0.21692248
trainer/Policy log std Max     0.22035754
trainer/Policy log std Min     -1.5913445
trainer/Alpha                  0.003496972844004631
trainer/Alpha Loss             -2.3842039108276367
exploration/num steps total    796000
exploration/num paths total    1592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9254907008953068
exploration/Rewards Std        0.10060322610372717
exploration/Rewards Max        0.9796794984729549
exploration/Rewards Min        0.49795391769122177
exploration/Returns Mean       462.74535044765355
exploration/Returns Std        12.669518593676392
exploration/Returns Max        476.1365588532399
exploration/Returns Min        435.7009060485137
exploration/Actions Mean       0.04673989
exploration/Actions Std        0.64239836
exploration/Actions Max        0.9993662
exploration/Actions Min        -0.9998184
exploration/Num Paths          10
exploration/Average Returns    462.74535044765355
evaluation/num steps total     795000
evaluation/num paths total     1590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7376027021283158
evaluation/Rewards Std         0.08603338554602329
evaluation/Rewards Max         0.9778089129811571
evaluation/Rewards Min         0.4992471127037253
evaluation/Returns Mean        368.80135106415776
evaluation/Returns Std         36.20579768036505
evaluation/Returns Max         475.1709184064479
evaluation/Returns Min         352.8048970876867
evaluation/ExplReturns Mean    368.80135106415776
evaluation/ExplReturns Std     36.20579768036505
evaluation/ExplReturns Max     475.1709184064479
evaluation/ExplReturns Min     352.8048970876867
evaluation/Actions Mean        0.014796857
evaluation/Actions Std         0.5367535
evaluation/Actions Max         0.99974585
evaluation/Actions Min         -0.99656206
evaluation/Num Paths           10
evaluation/Average Returns     368.80135106415776
time/data storing (s)          0.03387568611651659
time/evaluation sampling (s)   115.52705613803118
time/exploration sampling (s)  112.39625520538539
time/logging (s)               0.030232074670493603
time/saving (s)                0.010416451841592789
time/training (s)              9.598809408955276
time/epoch (s)                 237.59664496500045
time/total (s)                 37290.684035100974
Epoch                          158
-----------------------------  --------------------
2023-08-01 04:19:33.941477 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 159 finished
-----------------------------  --------------------
replay_buffer/size             801000
trainer/tdrp Loss              [3613.7207]
trainer/QF1 Loss               0.16063066
trainer/QF2 Loss               0.15438008
trainer/Policy Loss            -70.32413
trainer/Q1 Predictions Mean    81.79202
trainer/Q1 Predictions Std     8.222536
trainer/Q1 Predictions Max     94.45861
trainer/Q1 Predictions Min     57.97574
trainer/Q2 Predictions Mean    81.8499
trainer/Q2 Predictions Std     8.219276
trainer/Q2 Predictions Max     94.70025
trainer/Q2 Predictions Min     58.128006
trainer/Q Targets Mean         81.81448
trainer/Q Targets Std          8.225107
trainer/Q Targets Max          94.68263
trainer/Q Targets Min          58.643337
trainer/Log Pis Mean           11.735185
trainer/Log Pis Std            6.9923034
trainer/Log Pis Max            31.951729
trainer/Log Pis Min            -4.058256
trainer/Policy mu Mean         0.089989595
trainer/Policy mu Std          1.6149766
trainer/Policy mu Max          4.3302584
trainer/Policy mu Min          -5.3776975
trainer/Policy log std Mean    -0.6428571
trainer/Policy log std Std     0.22197485
trainer/Policy log std Max     0.030924797
trainer/Policy log std Min     -1.632572
trainer/Alpha                  0.003427551593631506
trainer/Alpha Loss             -1.503044843673706
exploration/num steps total    801000
exploration/num paths total    1602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9270246333954212
exploration/Rewards Std        0.08963155391085742
exploration/Rewards Max        0.9781936542039988
exploration/Rewards Min        0.4963047186659685
exploration/Returns Mean       463.5123166977108
exploration/Returns Std        4.825840031439001
exploration/Returns Max        469.88892846249627
exploration/Returns Min        454.4482282652641
exploration/Actions Mean       0.067459986
exploration/Actions Std        0.63041204
exploration/Actions Max        0.99968356
exploration/Actions Min        -0.99988675
exploration/Num Paths          10
exploration/Average Returns    463.5123166977108
evaluation/num steps total     800000
evaluation/num paths total     1600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7760979700933697
evaluation/Rewards Std         0.1157707687223924
evaluation/Rewards Max         0.9703166858901769
evaluation/Rewards Min         0.5047608989284491
evaluation/Returns Mean        388.0489850466846
evaluation/Returns Std         54.310278717095265
evaluation/Returns Max         472.2141075366402
evaluation/Returns Min         351.0676254468161
evaluation/ExplReturns Mean    388.0489850466846
evaluation/ExplReturns Std     54.310278717095265
evaluation/ExplReturns Max     472.2141075366402
evaluation/ExplReturns Min     351.0676254468161
evaluation/Actions Mean        0.030352756
evaluation/Actions Std         0.569174
evaluation/Actions Max         0.99617064
evaluation/Actions Min         -0.9987353
evaluation/Num Paths           10
evaluation/Average Returns     388.0489850466846
time/data storing (s)          0.03425770439207554
time/evaluation sampling (s)   114.5410035494715
time/exploration sampling (s)  110.8295026505366
time/logging (s)               0.030763745307922363
time/saving (s)                0.01226252131164074
time/training (s)              9.569934130646288
time/epoch (s)                 235.01772430166602
time/total (s)                 37525.70442144014
Epoch                          159
-----------------------------  --------------------
2023-08-01 04:23:28.064924 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 160 finished
-----------------------------  --------------------
replay_buffer/size             806000
trainer/tdrp Loss              [3430.598]
trainer/QF1 Loss               0.20788303
trainer/QF2 Loss               0.19545077
trainer/Policy Loss            -68.532104
trainer/Q1 Predictions Mean    81.54345
trainer/Q1 Predictions Std     8.504239
trainer/Q1 Predictions Max     94.76586
trainer/Q1 Predictions Min     51.614414
trainer/Q2 Predictions Mean    81.54515
trainer/Q2 Predictions Std     8.518345
trainer/Q2 Predictions Max     94.70483
trainer/Q2 Predictions Min     51.82887
trainer/Q Targets Mean         81.62095
trainer/Q Targets Std          8.556847
trainer/Q Targets Max          94.72543
trainer/Q Targets Min          51.214912
trainer/Log Pis Mean           13.248943
trainer/Log Pis Std            7.323357
trainer/Log Pis Max            33.01587
trainer/Log Pis Min            -5.250307
trainer/Policy mu Mean         -0.013988224
trainer/Policy mu Std          1.6865048
trainer/Policy mu Max          5.008908
trainer/Policy mu Min          -4.967035
trainer/Policy log std Mean    -0.63768595
trainer/Policy log std Std     0.22957668
trainer/Policy log std Max     0.23257786
trainer/Policy log std Min     -1.7517416
trainer/Alpha                  0.003310740925371647
trainer/Alpha Loss             7.1323394775390625
exploration/num steps total    806000
exploration/num paths total    1612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9335924928501638
exploration/Rewards Std        0.0914414508633477
exploration/Rewards Max        0.9798532570119923
exploration/Rewards Min        0.48593870325320493
exploration/Returns Mean       466.7962464250819
exploration/Returns Std        5.441508362782118
exploration/Returns Max        473.8057620247765
exploration/Returns Min        456.409498253305
exploration/Actions Mean       0.037570752
exploration/Actions Std        0.62295043
exploration/Actions Max        0.9996701
exploration/Actions Min        -0.9999624
exploration/Num Paths          10
exploration/Average Returns    466.7962464250819
evaluation/num steps total     805000
evaluation/num paths total     1610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7882837344115385
evaluation/Rewards Std         0.11252127469815629
evaluation/Rewards Max         0.9797326152263252
evaluation/Rewards Min         0.4978835997915634
evaluation/Returns Mean        394.1418672057692
evaluation/Returns Std         52.09767466127841
evaluation/Returns Max         473.8053132156758
evaluation/Returns Min         356.33438808785377
evaluation/ExplReturns Mean    394.1418672057692
evaluation/ExplReturns Std     52.09767466127841
evaluation/ExplReturns Max     473.8053132156758
evaluation/ExplReturns Min     356.33438808785377
evaluation/Actions Mean        -0.0076204245
evaluation/Actions Std         0.56315356
evaluation/Actions Max         0.9970375
evaluation/Actions Min         -0.9992352
evaluation/Num Paths           10
evaluation/Average Returns     394.1418672057692
time/data storing (s)          0.03402028698474169
time/evaluation sampling (s)   112.6322747124359
time/exploration sampling (s)  111.87757243588567
time/logging (s)               0.0304607218131423
time/saving (s)                0.012187158688902855
time/training (s)              9.532290793955326
time/epoch (s)                 234.11880610976368
time/total (s)                 37759.825823361985
Epoch                          160
-----------------------------  --------------------
2023-08-01 04:27:20.021175 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 161 finished
-----------------------------  ---------------------
replay_buffer/size             811000
trainer/tdrp Loss              [3529.6758]
trainer/QF1 Loss               0.15322895
trainer/QF2 Loss               0.12664938
trainer/Policy Loss            -71.64143
trainer/Q1 Predictions Mean    83.399
trainer/Q1 Predictions Std     8.242301
trainer/Q1 Predictions Max     95.476006
trainer/Q1 Predictions Min     47.54423
trainer/Q2 Predictions Mean    83.2972
trainer/Q2 Predictions Std     8.205488
trainer/Q2 Predictions Max     95.14747
trainer/Q2 Predictions Min     47.587475
trainer/Q Targets Mean         83.325485
trainer/Q Targets Std          8.20695
trainer/Q Targets Max          95.09977
trainer/Q Targets Min          47.47607
trainer/Log Pis Mean           11.8980465
trainer/Log Pis Std            6.937449
trainer/Log Pis Max            32.513744
trainer/Log Pis Min            -3.0564544
trainer/Policy mu Mean         0.007614855
trainer/Policy mu Std          1.6056587
trainer/Policy mu Max          5.394957
trainer/Policy mu Min          -4.9023256
trainer/Policy log std Mean    -0.6597902
trainer/Policy log std Std     0.2292173
trainer/Policy log std Max     0.13776459
trainer/Policy log std Min     -1.6563756
trainer/Alpha                  0.0033968864008784294
trainer/Alpha Loss             -0.5795993804931641
exploration/num steps total    811000
exploration/num paths total    1622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9351100440181978
exploration/Rewards Std        0.09199979691558925
exploration/Rewards Max        0.9788499588726197
exploration/Rewards Min        0.4960034633495998
exploration/Returns Mean       467.55502200909876
exploration/Returns Std        5.480639587774603
exploration/Returns Max        477.28987404851506
exploration/Returns Min        458.93736514683815
exploration/Actions Mean       0.04946454
exploration/Actions Std        0.6365599
exploration/Actions Max        0.99992126
exploration/Actions Min        -0.99991006
exploration/Num Paths          10
exploration/Average Returns    467.55502200909876
evaluation/num steps total     810000
evaluation/num paths total     1620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9141171055465973
evaluation/Rewards Std         0.11092344133558946
evaluation/Rewards Max         0.9781666560872199
evaluation/Rewards Min         0.49183751395719355
evaluation/Returns Mean        457.05855277329874
evaluation/Returns Std         17.591444052777035
evaluation/Returns Max         471.4903037166328
evaluation/Returns Min         424.4403812164498
evaluation/ExplReturns Mean    457.05855277329874
evaluation/ExplReturns Std     17.591444052777035
evaluation/ExplReturns Max     471.4903037166328
evaluation/ExplReturns Min     424.4403812164498
evaluation/Actions Mean        0.055767685
evaluation/Actions Std         0.57939327
evaluation/Actions Max         0.9990201
evaluation/Actions Min         -0.99955
evaluation/Num Paths           10
evaluation/Average Returns     457.05855277329874
time/data storing (s)          0.03417217452079058
time/evaluation sampling (s)   110.97936873231083
time/exploration sampling (s)  111.6211491022259
time/logging (s)               0.030558637343347073
time/saving (s)                0.011065691709518433
time/training (s)              9.275867100805044
time/epoch (s)                 231.95218143891543
time/total (s)                 37991.78044928331
Epoch                          161
-----------------------------  ---------------------
2023-08-01 04:31:12.215170 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 162 finished
-----------------------------  --------------------
replay_buffer/size             816000
trainer/tdrp Loss              [3411.5266]
trainer/QF1 Loss               0.2342352
trainer/QF2 Loss               0.1687272
trainer/Policy Loss            -70.72934
trainer/Q1 Predictions Mean    82.88155
trainer/Q1 Predictions Std     7.7368627
trainer/Q1 Predictions Max     94.99871
trainer/Q1 Predictions Min     57.16177
trainer/Q2 Predictions Mean    82.99639
trainer/Q2 Predictions Std     7.7724457
trainer/Q2 Predictions Max     95.090126
trainer/Q2 Predictions Min     57.16233
trainer/Q Targets Mean         83.12424
trainer/Q Targets Std          7.780844
trainer/Q Targets Max          95.23663
trainer/Q Targets Min          57.67784
trainer/Log Pis Mean           12.401822
trainer/Log Pis Std            7.1353726
trainer/Log Pis Max            36.989697
trainer/Log Pis Min            -4.9315734
trainer/Policy mu Mean         -0.10487571
trainer/Policy mu Std          1.637456
trainer/Policy mu Max          5.0380516
trainer/Policy mu Min          -6.2115264
trainer/Policy log std Mean    -0.6445885
trainer/Policy log std Std     0.21316968
trainer/Policy log std Max     0.10079813
trainer/Policy log std Min     -1.6493349
trainer/Alpha                  0.003510467242449522
trainer/Alpha Loss             2.2710418701171875
exploration/num steps total    816000
exploration/num paths total    1632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9281939524899644
exploration/Rewards Std        0.09629778200335021
exploration/Rewards Max        0.9793479341262192
exploration/Rewards Min        0.4860847111404725
exploration/Returns Mean       464.09697624498205
exploration/Returns Std        12.80483090308122
exploration/Returns Max        471.62592435534583
exploration/Returns Min        427.4698081549931
exploration/Actions Mean       0.042644396
exploration/Actions Std        0.6289945
exploration/Actions Max        0.9998613
exploration/Actions Min        -0.99994624
exploration/Num Paths          10
exploration/Average Returns    464.09697624498205
evaluation/num steps total     815000
evaluation/num paths total     1630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8784835832544792
evaluation/Rewards Std         0.12410242018587353
evaluation/Rewards Max         0.9782480633524442
evaluation/Rewards Min         0.4886236417931703
evaluation/Returns Mean        439.2417916272396
evaluation/Returns Std         46.52193713097951
evaluation/Returns Max         469.2403573220204
evaluation/Returns Min         347.1275469728649
evaluation/ExplReturns Mean    439.2417916272396
evaluation/ExplReturns Std     46.52193713097951
evaluation/ExplReturns Max     469.2403573220204
evaluation/ExplReturns Min     347.1275469728649
evaluation/Actions Mean        0.050102647
evaluation/Actions Std         0.57369095
evaluation/Actions Max         0.9989034
evaluation/Actions Min         -0.99869984
evaluation/Num Paths           10
evaluation/Average Returns     439.2417916272396
time/data storing (s)          0.03387789335101843
time/evaluation sampling (s)   111.25530941411853
time/exploration sampling (s)  111.27918403036892
time/logging (s)               0.030351243913173676
time/saving (s)                0.012636936269700527
time/training (s)              9.578192232176661
time/epoch (s)                 232.189551750198
time/total (s)                 38223.97250443697
Epoch                          162
-----------------------------  --------------------
2023-08-01 04:35:05.405655 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 163 finished
-----------------------------  --------------------
replay_buffer/size             821000
trainer/tdrp Loss              [3663.272]
trainer/QF1 Loss               0.14218335
trainer/QF2 Loss               0.16466106
trainer/Policy Loss            -72.620224
trainer/Q1 Predictions Mean    83.60364
trainer/Q1 Predictions Std     8.024298
trainer/Q1 Predictions Max     95.88232
trainer/Q1 Predictions Min     48.645325
trainer/Q2 Predictions Mean    83.61589
trainer/Q2 Predictions Std     8.029278
trainer/Q2 Predictions Max     95.77373
trainer/Q2 Predictions Min     49.58178
trainer/Q Targets Mean         83.50832
trainer/Q Targets Std          8.0355425
trainer/Q Targets Max          95.65074
trainer/Q Targets Min          47.734806
trainer/Log Pis Mean           11.204691
trainer/Log Pis Std            6.381297
trainer/Log Pis Max            34.01586
trainer/Log Pis Min            -5.9717145
trainer/Policy mu Mean         0.07435334
trainer/Policy mu Std          1.5457685
trainer/Policy mu Max          4.234312
trainer/Policy mu Min          -3.7766738
trainer/Policy log std Mean    -0.65305763
trainer/Policy log std Std     0.22141239
trainer/Policy log std Max     -0.061950803
trainer/Policy log std Min     -1.6807269
trainer/Alpha                  0.003457488026469946
trainer/Alpha Loss             -4.5068440437316895
exploration/num steps total    821000
exploration/num paths total    1642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9450429892556887
exploration/Rewards Std        0.07798318655082567
exploration/Rewards Max        0.9799583775784619
exploration/Rewards Min        0.4887601927162372
exploration/Returns Mean       472.52149462784445
exploration/Returns Std        1.6728119550385243
exploration/Returns Max        475.12007075097256
exploration/Returns Min        468.93819982678934
exploration/Actions Mean       0.033627998
exploration/Actions Std        0.6211448
exploration/Actions Max        0.999185
exploration/Actions Min        -0.9998293
exploration/Num Paths          10
exploration/Average Returns    472.52149462784445
evaluation/num steps total     820000
evaluation/num paths total     1640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8659685384003402
evaluation/Rewards Std         0.1310977779082841
evaluation/Rewards Max         0.9786469060756109
evaluation/Rewards Min         0.49644535243477006
evaluation/Returns Mean        432.9842692001703
evaluation/Returns Std         52.44986965903855
evaluation/Returns Max         471.46709994097046
evaluation/Returns Min         352.77974534720073
evaluation/ExplReturns Mean    432.9842692001703
evaluation/ExplReturns Std     52.44986965903855
evaluation/ExplReturns Max     471.46709994097046
evaluation/ExplReturns Min     352.77974534720073
evaluation/Actions Mean        0.03283419
evaluation/Actions Std         0.5613961
evaluation/Actions Max         0.9934539
evaluation/Actions Min         -0.9994689
evaluation/Num Paths           10
evaluation/Average Returns     432.9842692001703
time/data storing (s)          0.034242646768689156
time/evaluation sampling (s)   112.06324521731585
time/exploration sampling (s)  111.43636862840503
time/logging (s)               0.03037470392882824
time/saving (s)                0.010268989950418472
time/training (s)              9.611790935508907
time/epoch (s)                 233.18629112187773
time/total (s)                 38457.1612754073
Epoch                          163
-----------------------------  --------------------
2023-08-01 04:39:00.456207 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 164 finished
-----------------------------  ---------------------
replay_buffer/size             826000
trainer/tdrp Loss              [3596.5564]
trainer/QF1 Loss               0.16499642
trainer/QF2 Loss               0.14840358
trainer/Policy Loss            -73.04486
trainer/Q1 Predictions Mean    84.15669
trainer/Q1 Predictions Std     9.128029
trainer/Q1 Predictions Max     95.69017
trainer/Q1 Predictions Min     51.078354
trainer/Q2 Predictions Mean    84.23058
trainer/Q2 Predictions Std     9.181912
trainer/Q2 Predictions Max     95.66671
trainer/Q2 Predictions Min     50.875694
trainer/Q Targets Mean         84.2769
trainer/Q Targets Std          9.156545
trainer/Q Targets Max          95.84807
trainer/Q Targets Min          50.81921
trainer/Log Pis Mean           11.311988
trainer/Log Pis Std            7.4088745
trainer/Log Pis Max            34.164093
trainer/Log Pis Min            -6.831125
trainer/Policy mu Mean         -0.035767935
trainer/Policy mu Std          1.569146
trainer/Policy mu Max          4.8391037
trainer/Policy mu Min          -4.6510863
trainer/Policy log std Mean    -0.6538669
trainer/Policy log std Std     0.23530321
trainer/Policy log std Max     0.21245718
trainer/Policy log std Min     -1.7433964
trainer/Alpha                  0.0035296690184623003
trainer/Alpha Loss             -3.884899616241455
exploration/num steps total    826000
exploration/num paths total    1652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9379008387429855
exploration/Rewards Std        0.09094534215593397
exploration/Rewards Max        0.9797716940902333
exploration/Rewards Min        0.5005129488151651
exploration/Returns Mean       468.95041937149256
exploration/Returns Std        5.568844277593841
exploration/Returns Max        474.03689961460987
exploration/Returns Min        457.188418095429
exploration/Actions Mean       0.04129756
exploration/Actions Std        0.63867855
exploration/Actions Max        0.9997904
exploration/Actions Min        -0.9998911
exploration/Num Paths          10
exploration/Average Returns    468.95041937149256
evaluation/num steps total     825000
evaluation/num paths total     1650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7120532446134843
evaluation/Rewards Std         0.016807339369832357
evaluation/Rewards Max         0.7456989298318759
evaluation/Rewards Min         0.49910015149424514
evaluation/Returns Mean        356.02662230674224
evaluation/Returns Std         1.9573154126386811
evaluation/Returns Max         359.7556428987108
evaluation/Returns Min         353.0803987959711
evaluation/ExplReturns Mean    356.02662230674224
evaluation/ExplReturns Std     1.9573154126386811
evaluation/ExplReturns Max     359.7556428987108
evaluation/ExplReturns Min     353.0803987959711
evaluation/Actions Mean        -0.026888285
evaluation/Actions Std         0.5465731
evaluation/Actions Max         0.9977837
evaluation/Actions Min         -0.9989911
evaluation/Num Paths           10
evaluation/Average Returns     356.02662230674224
time/data storing (s)          0.034223753958940506
time/evaluation sampling (s)   113.32544096559286
time/exploration sampling (s)  112.31565213855356
time/logging (s)               0.03044711332768202
time/saving (s)                0.012533945962786674
time/training (s)              9.32804804109037
time/epoch (s)                 235.0463459584862
time/total (s)                 38692.210157778114
Epoch                          164
-----------------------------  ---------------------
2023-08-01 04:42:52.841106 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 165 finished
-----------------------------  ---------------------
replay_buffer/size             831000
trainer/tdrp Loss              [3603.992]
trainer/QF1 Loss               0.18537727
trainer/QF2 Loss               0.17531803
trainer/Policy Loss            -72.77996
trainer/Q1 Predictions Mean    84.17725
trainer/Q1 Predictions Std     7.584071
trainer/Q1 Predictions Max     96.14533
trainer/Q1 Predictions Min     65.694534
trainer/Q2 Predictions Mean    84.219795
trainer/Q2 Predictions Std     7.601321
trainer/Q2 Predictions Max     96.02202
trainer/Q2 Predictions Min     65.12616
trainer/Q Targets Mean         84.13922
trainer/Q Targets Std          7.5913944
trainer/Q Targets Max          95.93512
trainer/Q Targets Min          64.99453
trainer/Log Pis Mean           11.651945
trainer/Log Pis Std            6.7273407
trainer/Log Pis Max            29.974562
trainer/Log Pis Min            -8.653576
trainer/Policy mu Mean         0.05459714
trainer/Policy mu Std          1.5939682
trainer/Policy mu Max          4.1052146
trainer/Policy mu Min          -4.3917866
trainer/Policy log std Mean    -0.64368147
trainer/Policy log std Std     0.21372877
trainer/Policy log std Max     0.053043306
trainer/Policy log std Min     -1.6752915
trainer/Alpha                  0.0034945225343108177
trainer/Alpha Loss             -1.9687838554382324
exploration/num steps total    831000
exploration/num paths total    1662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9426730687598797
exploration/Rewards Std        0.08465858111853697
exploration/Rewards Max        0.9782841044120274
exploration/Rewards Min        0.49754768451166154
exploration/Returns Mean       471.33653437993974
exploration/Returns Std        1.7746668695152137
exploration/Returns Max        473.1015672240848
exploration/Returns Min        466.9824762162007
exploration/Actions Mean       0.029500067
exploration/Actions Std        0.62898606
exploration/Actions Max        0.99992305
exploration/Actions Min        -0.9998848
exploration/Num Paths          10
exploration/Average Returns    471.33653437993974
evaluation/num steps total     830000
evaluation/num paths total     1660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8968478087242873
evaluation/Rewards Std         0.1190183372767808
evaluation/Rewards Max         0.9785146501543723
evaluation/Rewards Min         0.49550325946524815
evaluation/Returns Mean        448.42390436214345
evaluation/Returns Std         45.8756440588759
evaluation/Returns Max         476.9459099331459
evaluation/Returns Min         356.174341379666
evaluation/ExplReturns Mean    448.42390436214345
evaluation/ExplReturns Std     45.8756440588759
evaluation/ExplReturns Max     476.9459099331459
evaluation/ExplReturns Min     356.174341379666
evaluation/Actions Mean        0.03608329
evaluation/Actions Std         0.57061267
evaluation/Actions Max         0.99808025
evaluation/Actions Min         -0.99924135
evaluation/Num Paths           10
evaluation/Average Returns     448.42390436214345
time/data storing (s)          0.03438394330441952
time/evaluation sampling (s)   111.05744405742735
time/exploration sampling (s)  111.70675939787179
time/logging (s)               0.030577938072383404
time/saving (s)                0.011396938934922218
time/training (s)              9.540236247703433
time/epoch (s)                 232.3807985233143
time/total (s)                 38924.593398706056
Epoch                          165
-----------------------------  ---------------------
2023-08-01 04:46:49.382364 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 166 finished
-----------------------------  ---------------------
replay_buffer/size             836000
trainer/tdrp Loss              [3768.5745]
trainer/QF1 Loss               0.17867483
trainer/QF2 Loss               0.16920784
trainer/Policy Loss            -71.30427
trainer/Q1 Predictions Mean    83.83717
trainer/Q1 Predictions Std     8.70114
trainer/Q1 Predictions Max     95.80361
trainer/Q1 Predictions Min     52.744728
trainer/Q2 Predictions Mean    83.82384
trainer/Q2 Predictions Std     8.72599
trainer/Q2 Predictions Max     95.81144
trainer/Q2 Predictions Min     52.300507
trainer/Q Targets Mean         83.854004
trainer/Q Targets Std          8.747137
trainer/Q Targets Max          95.87383
trainer/Q Targets Min          52.21565
trainer/Log Pis Mean           12.743823
trainer/Log Pis Std            7.882109
trainer/Log Pis Max            33.9172
trainer/Log Pis Min            -5.810383
trainer/Policy mu Mean         0.00788545
trainer/Policy mu Std          1.6507462
trainer/Policy mu Max          4.535289
trainer/Policy mu Min          -4.4843116
trainer/Policy log std Mean    -0.64154506
trainer/Policy log std Std     0.220873
trainer/Policy log std Max     0.012500703
trainer/Policy log std Min     -1.5829902
trainer/Alpha                  0.0033645215444266796
trainer/Alpha Loss             4.23565673828125
exploration/num steps total    836000
exploration/num paths total    1672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8726753986470159
exploration/Rewards Std        0.12868272274870476
exploration/Rewards Max        0.9784447641542308
exploration/Rewards Min        0.5081070667223492
exploration/Returns Mean       436.337699323508
exploration/Returns Std        45.6957014537862
exploration/Returns Max        470.38772949270077
exploration/Returns Min        347.40327115432774
exploration/Actions Mean       0.049954906
exploration/Actions Std        0.65006995
exploration/Actions Max        0.9997752
exploration/Actions Min        -0.9996804
exploration/Num Paths          10
exploration/Average Returns    436.337699323508
evaluation/num steps total     835000
evaluation/num paths total     1670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8402595300974434
evaluation/Rewards Std         0.13216167417334082
evaluation/Rewards Max         0.9755919718051711
evaluation/Rewards Min         0.5052083145362127
evaluation/Returns Mean        420.12976504872165
evaluation/Returns Std         25.338929693545026
evaluation/Returns Max         448.27349207252024
evaluation/Returns Min         359.67262424219064
evaluation/ExplReturns Mean    420.12976504872165
evaluation/ExplReturns Std     25.338929693545026
evaluation/ExplReturns Max     448.27349207252024
evaluation/ExplReturns Min     359.67262424219064
evaluation/Actions Mean        0.03247931
evaluation/Actions Std         0.5977153
evaluation/Actions Max         0.99789494
evaluation/Actions Min         -0.99917907
evaluation/Num Paths           10
evaluation/Average Returns     420.12976504872165
time/data storing (s)          0.033642107620835304
time/evaluation sampling (s)   113.98906437214464
time/exploration sampling (s)  112.79627419263124
time/logging (s)               0.030517559498548508
time/saving (s)                0.01186359953135252
time/training (s)              9.675560396164656
time/epoch (s)                 236.53692222759128
time/total (s)                 39161.13282846846
Epoch                          166
-----------------------------  ---------------------
2023-08-01 04:50:42.879487 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 167 finished
-----------------------------  --------------------
replay_buffer/size             841000
trainer/tdrp Loss              [3842.4875]
trainer/QF1 Loss               0.15663545
trainer/QF2 Loss               0.1516847
trainer/Policy Loss            -73.527374
trainer/Q1 Predictions Mean    84.82201
trainer/Q1 Predictions Std     7.869439
trainer/Q1 Predictions Max     96.359055
trainer/Q1 Predictions Min     61.336536
trainer/Q2 Predictions Mean    84.82622
trainer/Q2 Predictions Std     7.8702064
trainer/Q2 Predictions Max     96.21767
trainer/Q2 Predictions Min     61.155556
trainer/Q Targets Mean         84.80574
trainer/Q Targets Std          7.9310675
trainer/Q Targets Max          96.31255
trainer/Q Targets Min          61.909912
trainer/Log Pis Mean           11.501305
trainer/Log Pis Std            6.6097283
trainer/Log Pis Max            35.472866
trainer/Log Pis Min            -1.4377377
trainer/Policy mu Mean         -0.09098963
trainer/Policy mu Std          1.5817406
trainer/Policy mu Max          4.947821
trainer/Policy mu Min          -4.3531904
trainer/Policy log std Mean    -0.6574692
trainer/Policy log std Std     0.20998292
trainer/Policy log std Max     0.08984882
trainer/Policy log std Min     -1.6025715
trainer/Alpha                  0.003440719097852707
trainer/Alpha Loss             -2.828437328338623
exploration/num steps total    841000
exploration/num paths total    1682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9241617031011988
exploration/Rewards Std        0.09934888491544364
exploration/Rewards Max        0.9787101320095343
exploration/Rewards Min        0.5099074364001902
exploration/Returns Mean       462.0808515505996
exploration/Returns Std        4.563828655073453
exploration/Returns Max        468.6234030458322
exploration/Returns Min        451.27326916154453
exploration/Actions Mean       0.031137675
exploration/Actions Std        0.62517095
exploration/Actions Max        0.9999078
exploration/Actions Min        -0.9999791
exploration/Num Paths          10
exploration/Average Returns    462.0808515505996
evaluation/num steps total     840000
evaluation/num paths total     1680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9309067997369086
evaluation/Rewards Std         0.09296400454457521
evaluation/Rewards Max         0.9749564882953197
evaluation/Rewards Min         0.5102012598292063
evaluation/Returns Mean        465.4533998684543
evaluation/Returns Std         0.8059649958393006
evaluation/Returns Max         467.02331111162005
evaluation/Returns Min         464.4586621761293
evaluation/ExplReturns Mean    465.4533998684543
evaluation/ExplReturns Std     0.8059649958393006
evaluation/ExplReturns Max     467.02331111162005
evaluation/ExplReturns Min     464.4586621761293
evaluation/Actions Mean        0.04695478
evaluation/Actions Std         0.56825054
evaluation/Actions Max         0.9983123
evaluation/Actions Min         -0.99963665
evaluation/Num Paths           10
evaluation/Average Returns     465.4533998684543
time/data storing (s)          0.03417281340807676
time/evaluation sampling (s)   111.96014023479074
time/exploration sampling (s)  112.07169549260288
time/logging (s)               0.030404673889279366
time/saving (s)                0.011554011143743992
time/training (s)              9.384341555647552
time/epoch (s)                 233.49230878148228
time/total (s)                 39394.628042970784
Epoch                          167
-----------------------------  --------------------
2023-08-01 04:54:37.109398 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 168 finished
-----------------------------  ---------------------
replay_buffer/size             846000
trainer/tdrp Loss              [3861.7466]
trainer/QF1 Loss               0.19662195
trainer/QF2 Loss               0.18392804
trainer/Policy Loss            -72.61575
trainer/Q1 Predictions Mean    84.59803
trainer/Q1 Predictions Std     8.305955
trainer/Q1 Predictions Max     96.616425
trainer/Q1 Predictions Min     62.849293
trainer/Q2 Predictions Mean    84.50297
trainer/Q2 Predictions Std     8.280487
trainer/Q2 Predictions Max     96.36405
trainer/Q2 Predictions Min     62.855495
trainer/Q Targets Mean         84.460754
trainer/Q Targets Std          8.266606
trainer/Q Targets Max          96.36545
trainer/Q Targets Min          62.778034
trainer/Log Pis Mean           12.157064
trainer/Log Pis Std            7.024993
trainer/Log Pis Max            31.278555
trainer/Log Pis Min            -5.9322925
trainer/Policy mu Mean         -0.08788395
trainer/Policy mu Std          1.600623
trainer/Policy mu Max          4.1690245
trainer/Policy mu Min          -4.4480934
trainer/Policy log std Mean    -0.6464762
trainer/Policy log std Std     0.21320966
trainer/Policy log std Max     0.018111438
trainer/Policy log std Min     -1.583197
trainer/Alpha                  0.0035003444645553827
trainer/Alpha Loss             0.8881862163543701
exploration/num steps total    846000
exploration/num paths total    1692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9259377346209927
exploration/Rewards Std        0.10050486851221486
exploration/Rewards Max        0.9799273966210023
exploration/Rewards Min        0.5048770803755536
exploration/Returns Mean       462.96886731049636
exploration/Returns Std        7.865231592548058
exploration/Returns Max        474.88287942751793
exploration/Returns Min        449.1540487728224
exploration/Actions Mean       0.055953927
exploration/Actions Std        0.6349465
exploration/Actions Max        0.99982315
exploration/Actions Min        -0.99966663
exploration/Num Paths          10
exploration/Average Returns    462.96886731049636
evaluation/num steps total     845000
evaluation/num paths total     1690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8849601653036032
evaluation/Rewards Std         0.1277726678503413
evaluation/Rewards Max         0.97998814268648
evaluation/Rewards Min         0.5106903328970284
evaluation/Returns Mean        442.4800826518016
evaluation/Returns Std         48.2270623711104
evaluation/Returns Max         474.5483801908228
evaluation/Returns Min         343.20246238411977
evaluation/ExplReturns Mean    442.4800826518016
evaluation/ExplReturns Std     48.2270623711104
evaluation/ExplReturns Max     474.5483801908228
evaluation/ExplReturns Min     343.20246238411977
evaluation/Actions Mean        0.054376435
evaluation/Actions Std         0.5876146
evaluation/Actions Max         0.9991545
evaluation/Actions Min         -0.99789625
evaluation/Num Paths           10
evaluation/Average Returns     442.4800826518016
time/data storing (s)          0.03417942952364683
time/evaluation sampling (s)   111.82515646517277
time/exploration sampling (s)  112.65751380752772
time/logging (s)               0.03101102076470852
time/saving (s)                0.010397914797067642
time/training (s)              9.667980957776308
time/epoch (s)                 234.22623959556222
time/total (s)                 39628.85680854041
Epoch                          168
-----------------------------  ---------------------
2023-08-01 04:58:32.716917 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 169 finished
-----------------------------  ---------------------
replay_buffer/size             851000
trainer/tdrp Loss              [3744.1104]
trainer/QF1 Loss               0.17563817
trainer/QF2 Loss               0.14378946
trainer/Policy Loss            -73.51328
trainer/Q1 Predictions Mean    85.27301
trainer/Q1 Predictions Std     8.964201
trainer/Q1 Predictions Max     96.90594
trainer/Q1 Predictions Min     61.322807
trainer/Q2 Predictions Mean    85.201355
trainer/Q2 Predictions Std     8.957373
trainer/Q2 Predictions Max     96.8469
trainer/Q2 Predictions Min     60.70536
trainer/Q Targets Mean         85.174576
trainer/Q Targets Std          8.959011
trainer/Q Targets Max          96.57838
trainer/Q Targets Min          60.97783
trainer/Log Pis Mean           11.891571
trainer/Log Pis Std            7.008858
trainer/Log Pis Max            32.804146
trainer/Log Pis Min            -5.2378488
trainer/Policy mu Mean         -0.056754958
trainer/Policy mu Std          1.5743909
trainer/Policy mu Max          4.6328673
trainer/Policy mu Min          -4.153841
trainer/Policy log std Mean    -0.6673334
trainer/Policy log std Std     0.21831796
trainer/Policy log std Max     -0.059263647
trainer/Policy log std Min     -1.6064605
trainer/Alpha                  0.0035395235754549503
trainer/Alpha Loss             -0.6119223833084106
exploration/num steps total    851000
exploration/num paths total    1702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8453062058549689
exploration/Rewards Std        0.12916267795111777
exploration/Rewards Max        0.9798502310030699
exploration/Rewards Min        0.5043101769338674
exploration/Returns Mean       422.65310292748455
exploration/Returns Std        38.714953879937475
exploration/Returns Max        472.75054688272303
exploration/Returns Min        350.2365076296066
exploration/Actions Mean       -0.0023453247
exploration/Actions Std        0.63680613
exploration/Actions Max        0.9993896
exploration/Actions Min        -0.99962115
exploration/Num Paths          10
exploration/Average Returns    422.65310292748455
evaluation/num steps total     850000
evaluation/num paths total     1700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6984038221396848
evaluation/Rewards Std         0.019964164035365828
evaluation/Rewards Max         0.7385270899580838
evaluation/Rewards Min         0.4985642812319829
evaluation/Returns Mean        349.20191106984237
evaluation/Returns Std         3.9390029026291553
evaluation/Returns Max         354.9914740656973
evaluation/Returns Min         340.28832872884453
evaluation/ExplReturns Mean    349.20191106984237
evaluation/ExplReturns Std     3.9390029026291553
evaluation/ExplReturns Max     354.9914740656973
evaluation/ExplReturns Min     340.28832872884453
evaluation/Actions Mean        -0.012743675
evaluation/Actions Std         0.5676906
evaluation/Actions Max         0.9992068
evaluation/Actions Min         -0.9982073
evaluation/Num Paths           10
evaluation/Average Returns     349.20191106984237
time/data storing (s)          0.03423226531594992
time/evaluation sampling (s)   113.32685404922813
time/exploration sampling (s)  112.58576925937086
time/logging (s)               0.03062776941806078
time/saving (s)                0.012498698197305202
time/training (s)              9.61281622108072
time/epoch (s)                 235.60279826261103
time/total (s)                 39864.4620507136
Epoch                          169
-----------------------------  ---------------------
2023-08-01 05:02:28.130021 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 170 finished
-----------------------------  ---------------------
replay_buffer/size             856000
trainer/tdrp Loss              [3905.406]
trainer/QF1 Loss               0.15054126
trainer/QF2 Loss               0.1470314
trainer/Policy Loss            -73.58778
trainer/Q1 Predictions Mean    84.97868
trainer/Q1 Predictions Std     7.8979726
trainer/Q1 Predictions Max     96.78189
trainer/Q1 Predictions Min     61.60328
trainer/Q2 Predictions Mean    84.95766
trainer/Q2 Predictions Std     7.8745475
trainer/Q2 Predictions Max     96.62642
trainer/Q2 Predictions Min     62.786903
trainer/Q Targets Mean         85.02106
trainer/Q Targets Std          7.892832
trainer/Q Targets Max          96.93388
trainer/Q Targets Min          62.296116
trainer/Log Pis Mean           11.594367
trainer/Log Pis Std            6.720176
trainer/Log Pis Max            35.050606
trainer/Log Pis Min            -2.3496742
trainer/Policy mu Mean         -0.044783056
trainer/Policy mu Std          1.5873277
trainer/Policy mu Max          4.4449153
trainer/Policy mu Min          -3.9717414
trainer/Policy log std Mean    -0.6548693
trainer/Policy log std Std     0.21529698
trainer/Policy log std Max     0.058680773
trainer/Policy log std Min     -1.6083001
trainer/Alpha                  0.0034748937468975782
trainer/Alpha Loss             -2.2967183589935303
exploration/num steps total    856000
exploration/num paths total    1712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8000009606273706
exploration/Rewards Std        0.1289462490807671
exploration/Rewards Max        0.9769732342267585
exploration/Rewards Min        0.5079336325969865
exploration/Returns Mean       400.00048031368533
exploration/Returns Std        42.74608351203049
exploration/Returns Max        475.69830346743396
exploration/Returns Min        348.814258411666
exploration/Actions Mean       -0.0022857452
exploration/Actions Std        0.65642196
exploration/Actions Max        0.9991488
exploration/Actions Min        -0.9998277
exploration/Num Paths          10
exploration/Average Returns    400.00048031368533
evaluation/num steps total     855000
evaluation/num paths total     1710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7229824728216332
evaluation/Rewards Std         0.07975166918955319
evaluation/Rewards Max         0.9736879317438034
evaluation/Rewards Min         0.506325154667853
evaluation/Returns Mean        361.4912364108166
evaluation/Returns Std         37.420782940204745
evaluation/Returns Max         473.7408414924284
evaluation/Returns Min         348.2606529435286
evaluation/ExplReturns Mean    361.4912364108166
evaluation/ExplReturns Std     37.420782940204745
evaluation/ExplReturns Max     473.7408414924284
evaluation/ExplReturns Min     348.2606529435286
evaluation/Actions Mean        0.008165512
evaluation/Actions Std         0.6239714
evaluation/Actions Max         0.9960861
evaluation/Actions Min         -0.99523616
evaluation/Num Paths           10
evaluation/Average Returns     361.4912364108166
time/data storing (s)          0.03410366177558899
time/evaluation sampling (s)   113.73360862303525
time/exploration sampling (s)  113.26286671683192
time/logging (s)               0.030441601760685444
time/saving (s)                0.01188423577696085
time/training (s)              8.335283175110817
time/epoch (s)                 235.40818801429123
time/total (s)                 40099.87318905722
Epoch                          170
-----------------------------  ---------------------
2023-08-01 05:06:26.919622 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 171 finished
-----------------------------  --------------------
replay_buffer/size             861000
trainer/tdrp Loss              [3778.887]
trainer/QF1 Loss               0.16383629
trainer/QF2 Loss               0.17999715
trainer/Policy Loss            -75.73963
trainer/Q1 Predictions Mean    86.58397
trainer/Q1 Predictions Std     7.95247
trainer/Q1 Predictions Max     96.98875
trainer/Q1 Predictions Min     56.767174
trainer/Q2 Predictions Mean    86.56651
trainer/Q2 Predictions Std     7.9089656
trainer/Q2 Predictions Max     96.955765
trainer/Q2 Predictions Min     57.833492
trainer/Q Targets Mean         86.52163
trainer/Q Targets Std          7.9447865
trainer/Q Targets Max          96.927185
trainer/Q Targets Min          56.373344
trainer/Log Pis Mean           11.044009
trainer/Log Pis Std            7.17501
trainer/Log Pis Max            32.463207
trainer/Log Pis Min            -5.440487
trainer/Policy mu Mean         0.021767477
trainer/Policy mu Std          1.5675865
trainer/Policy mu Max          5.110886
trainer/Policy mu Min          -4.568471
trainer/Policy log std Mean    -0.66506493
trainer/Policy log std Std     0.20498045
trainer/Policy log std Max     0.12788805
trainer/Policy log std Min     -1.4572859
trainer/Alpha                  0.003602395299822092
trainer/Alpha Loss             -5.37856388092041
exploration/num steps total    861000
exploration/num paths total    1722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9141395747450146
exploration/Rewards Std        0.10495397742019014
exploration/Rewards Max        0.9782433034775254
exploration/Rewards Min        0.5054803153755468
exploration/Returns Mean       457.0697873725072
exploration/Returns Std        23.385076472318808
exploration/Returns Max        469.2717908082939
exploration/Returns Min        388.11085000234846
exploration/Actions Mean       0.038221356
exploration/Actions Std        0.62445
exploration/Actions Max        0.99989104
exploration/Actions Min        -0.99962646
exploration/Num Paths          10
exploration/Average Returns    457.0697873725072
evaluation/num steps total     860000
evaluation/num paths total     1720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7059992900119267
evaluation/Rewards Std         0.019703171187362513
evaluation/Rewards Max         0.7350563990416482
evaluation/Rewards Min         0.4973368020701764
evaluation/Returns Mean        352.9996450059634
evaluation/Returns Std         6.0895055480007185
evaluation/Returns Max         363.7677805787402
evaluation/Returns Min         347.4015562460431
evaluation/ExplReturns Mean    352.9996450059634
evaluation/ExplReturns Std     6.0895055480007185
evaluation/ExplReturns Max     363.7677805787402
evaluation/ExplReturns Min     347.4015562460431
evaluation/Actions Mean        0.049760018
evaluation/Actions Std         0.57633317
evaluation/Actions Max         0.9966127
evaluation/Actions Min         -0.99813336
evaluation/Num Paths           10
evaluation/Average Returns     352.9996450059634
time/data storing (s)          0.03451080992817879
time/evaluation sampling (s)   116.42462815903127
time/exploration sampling (s)  112.97076679114252
time/logging (s)               0.03060156386345625
time/saving (s)                0.012685900554060936
time/training (s)              9.312248419970274
time/epoch (s)                 238.78544164448977
time/total (s)                 40338.66112886928
Epoch                          171
-----------------------------  --------------------
2023-08-01 05:10:18.912978 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 172 finished
-----------------------------  ---------------------
replay_buffer/size             866000
trainer/tdrp Loss              [3674.0508]
trainer/QF1 Loss               0.22368398
trainer/QF2 Loss               0.18471587
trainer/Policy Loss            -73.134155
trainer/Q1 Predictions Mean    85.36421
trainer/Q1 Predictions Std     8.737957
trainer/Q1 Predictions Max     97.53356
trainer/Q1 Predictions Min     56.53961
trainer/Q2 Predictions Mean    85.3303
trainer/Q2 Predictions Std     8.725831
trainer/Q2 Predictions Max     97.325
trainer/Q2 Predictions Min     56.80143
trainer/Q Targets Mean         85.13696
trainer/Q Targets Std          8.69195
trainer/Q Targets Max          97.18629
trainer/Q Targets Min          57.28597
trainer/Log Pis Mean           12.407675
trainer/Log Pis Std            7.5569263
trainer/Log Pis Max            32.92492
trainer/Log Pis Min            -3.0586505
trainer/Policy mu Mean         0.09482315
trainer/Policy mu Std          1.6319808
trainer/Policy mu Max          6.8715496
trainer/Policy mu Min          -4.5381045
trainer/Policy log std Mean    -0.64726245
trainer/Policy log std Std     0.21117976
trainer/Policy log std Max     0.17783177
trainer/Policy log std Min     -1.5166376
trainer/Alpha                  0.0035353642888367176
trainer/Alpha Loss             2.3013505935668945
exploration/num steps total    866000
exploration/num paths total    1732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9229716171257515
exploration/Rewards Std        0.10117871241927534
exploration/Rewards Max        0.9779302475272152
exploration/Rewards Min        0.5150065826987905
exploration/Returns Mean       461.48580856287555
exploration/Returns Std        3.9478260985169853
exploration/Returns Max        468.48745228448655
exploration/Returns Min        451.6395113835437
exploration/Actions Mean       0.03189691
exploration/Actions Std        0.6380266
exploration/Actions Max        0.9998681
exploration/Actions Min        -0.9999041
exploration/Num Paths          10
exploration/Average Returns    461.48580856287555
evaluation/num steps total     865000
evaluation/num paths total     1730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9298934928771306
evaluation/Rewards Std         0.09652519123654812
evaluation/Rewards Max         0.9750113099143967
evaluation/Rewards Min         0.49434630930083556
evaluation/Returns Mean        464.94674643856536
evaluation/Returns Std         5.732884287950464
evaluation/Returns Max         476.7604471376417
evaluation/Returns Min         459.9097971408575
evaluation/ExplReturns Mean    464.94674643856536
evaluation/ExplReturns Std     5.732884287950464
evaluation/ExplReturns Max     476.7604471376417
evaluation/ExplReturns Min     459.9097971408575
evaluation/Actions Mean        0.048152182
evaluation/Actions Std         0.61655164
evaluation/Actions Max         0.9980867
evaluation/Actions Min         -0.9978712
evaluation/Num Paths           10
evaluation/Average Returns     464.94674643856536
time/data storing (s)          0.033957826904952526
time/evaluation sampling (s)   111.3281800346449
time/exploration sampling (s)  111.60495042521507
time/logging (s)               0.03054660651832819
time/saving (s)                0.012072280049324036
time/training (s)              8.979247691109776
time/epoch (s)                 231.98895486444235
time/total (s)                 40570.65261428524
Epoch                          172
-----------------------------  ---------------------
2023-08-01 05:14:11.616759 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 173 finished
-----------------------------  ---------------------
replay_buffer/size             871000
trainer/tdrp Loss              [3614.8533]
trainer/QF1 Loss               0.16280651
trainer/QF2 Loss               0.18471433
trainer/Policy Loss            -72.15699
trainer/Q1 Predictions Mean    84.935425
trainer/Q1 Predictions Std     8.943398
trainer/Q1 Predictions Max     97.49228
trainer/Q1 Predictions Min     58.66909
trainer/Q2 Predictions Mean    84.98663
trainer/Q2 Predictions Std     8.96537
trainer/Q2 Predictions Max     97.40581
trainer/Q2 Predictions Min     58.222874
trainer/Q Targets Mean         84.9483
trainer/Q Targets Std          8.973312
trainer/Q Targets Max          97.2226
trainer/Q Targets Min          57.75159
trainer/Log Pis Mean           13.017899
trainer/Log Pis Std            7.3569
trainer/Log Pis Max            35.415913
trainer/Log Pis Min            -3.7181125
trainer/Policy mu Mean         0.049338832
trainer/Policy mu Std          1.6373669
trainer/Policy mu Max          4.5006223
trainer/Policy mu Min          -4.603693
trainer/Policy log std Mean    -0.67119646
trainer/Policy log std Std     0.22377416
trainer/Policy log std Max     -0.05943352
trainer/Policy log std Min     -1.6744562
trainer/Alpha                  0.0034434024710208178
trainer/Alpha Loss             5.772975921630859
exploration/num steps total    871000
exploration/num paths total    1742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9394706251692336
exploration/Rewards Std        0.08936574292456621
exploration/Rewards Max        0.9795713984282804
exploration/Rewards Min        0.5041052490104038
exploration/Returns Mean       469.7353125846166
exploration/Returns Std        2.385045445969578
exploration/Returns Max        474.49613190811476
exploration/Returns Min        465.4713127932619
exploration/Actions Mean       0.0025454254
exploration/Actions Std        0.6161418
exploration/Actions Max        0.9995877
exploration/Actions Min        -0.9997632
exploration/Num Paths          10
exploration/Average Returns    469.7353125846166
evaluation/num steps total     870000
evaluation/num paths total     1740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8314653520952974
evaluation/Rewards Std         0.1402373124541418
evaluation/Rewards Max         0.9784690089404866
evaluation/Rewards Min         0.5092940113009802
evaluation/Returns Mean        415.7326760476488
evaluation/Returns Std         59.02225202835233
evaluation/Returns Max         474.04417488504225
evaluation/Returns Min         345.1603036064433
evaluation/ExplReturns Mean    415.7326760476488
evaluation/ExplReturns Std     59.02225202835233
evaluation/ExplReturns Max     474.04417488504225
evaluation/ExplReturns Min     345.1603036064433
evaluation/Actions Mean        0.025050828
evaluation/Actions Std         0.61021477
evaluation/Actions Max         0.99921566
evaluation/Actions Min         -0.99906284
evaluation/Num Paths           10
evaluation/Average Returns     415.7326760476488
time/data storing (s)          0.03382153436541557
time/evaluation sampling (s)   111.71776104997844
time/exploration sampling (s)  111.7677864804864
time/logging (s)               0.03045864775776863
time/saving (s)                0.011336556635797024
time/training (s)              9.138224909082055
time/epoch (s)                 232.69938917830586
time/total (s)                 40803.35449977871
Epoch                          173
-----------------------------  ---------------------
2023-08-01 05:18:05.986844 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 174 finished
-----------------------------  --------------------
replay_buffer/size             876000
trainer/tdrp Loss              [3474.9033]
trainer/QF1 Loss               0.16472512
trainer/QF2 Loss               0.14360122
trainer/Policy Loss            -74.99389
trainer/Q1 Predictions Mean    86.368835
trainer/Q1 Predictions Std     9.18442
trainer/Q1 Predictions Max     97.904175
trainer/Q1 Predictions Min     54.925415
trainer/Q2 Predictions Mean    86.25035
trainer/Q2 Predictions Std     9.1670685
trainer/Q2 Predictions Max     97.76894
trainer/Q2 Predictions Min     54.35764
trainer/Q Targets Mean         86.31689
trainer/Q Targets Std          9.194938
trainer/Q Targets Max          97.50995
trainer/Q Targets Min          53.95273
trainer/Log Pis Mean           11.532145
trainer/Log Pis Std            7.0047283
trainer/Log Pis Max            32.53241
trainer/Log Pis Min            -6.542204
trainer/Policy mu Mean         0.037093338
trainer/Policy mu Std          1.5935736
trainer/Policy mu Max          4.846543
trainer/Policy mu Min          -5.6851974
trainer/Policy log std Mean    -0.6661317
trainer/Policy log std Std     0.23958847
trainer/Policy log std Max     0.04640889
trainer/Policy log std Min     -1.6302402
trainer/Alpha                  0.003517026547342539
trainer/Alpha Loss             -2.6433348655700684
exploration/num steps total    876000
exploration/num paths total    1752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8801699956694596
exploration/Rewards Std        0.12317885710010384
exploration/Rewards Max        0.9793276619915311
exploration/Rewards Min        0.5032421484354542
exploration/Returns Mean       440.0849978347299
exploration/Returns Std        24.602622996070785
exploration/Returns Max        475.910860459431
exploration/Returns Min        412.27430936016805
exploration/Actions Mean       0.007133042
exploration/Actions Std        0.63947827
exploration/Actions Max        0.9990797
exploration/Actions Min        -0.99995726
exploration/Num Paths          10
exploration/Average Returns    440.0849978347299
evaluation/num steps total     875000
evaluation/num paths total     1750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7228054784933106
evaluation/Rewards Std         0.017997134216528578
evaluation/Rewards Max         0.7367950397515215
evaluation/Rewards Min         0.5151224648350533
evaluation/Returns Mean        361.40273924665524
evaluation/Returns Std         1.4943157537908398
evaluation/Returns Max         362.72990646000846
evaluation/Returns Min         358.568003817135
evaluation/ExplReturns Mean    361.40273924665524
evaluation/ExplReturns Std     1.4943157537908398
evaluation/ExplReturns Max     362.72990646000846
evaluation/ExplReturns Min     358.568003817135
evaluation/Actions Mean        0.044508923
evaluation/Actions Std         0.6019709
evaluation/Actions Max         0.99023676
evaluation/Actions Min         -0.9954753
evaluation/Num Paths           10
evaluation/Average Returns     361.40273924665524
time/data storing (s)          0.03458432201296091
time/evaluation sampling (s)   112.11095488350838
time/exploration sampling (s)  112.50930670648813
time/logging (s)               0.03052606899291277
time/saving (s)                0.01027010753750801
time/training (s)              9.670074726454914
time/epoch (s)                 234.3657168149948
time/total (s)                 41037.722830747254
Epoch                          174
-----------------------------  --------------------
2023-08-01 05:21:58.870948 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 175 finished
-----------------------------  ---------------------
replay_buffer/size             881000
trainer/tdrp Loss              [3703.3254]
trainer/QF1 Loss               0.15157828
trainer/QF2 Loss               0.1303962
trainer/Policy Loss            -74.683395
trainer/Q1 Predictions Mean    86.150055
trainer/Q1 Predictions Std     8.582514
trainer/Q1 Predictions Max     97.486946
trainer/Q1 Predictions Min     60.531643
trainer/Q2 Predictions Mean    86.16455
trainer/Q2 Predictions Std     8.594715
trainer/Q2 Predictions Max     97.481026
trainer/Q2 Predictions Min     60.1939
trainer/Q Targets Mean         86.223724
trainer/Q Targets Std          8.615456
trainer/Q Targets Max          97.526726
trainer/Q Targets Min          60.48639
trainer/Log Pis Mean           11.691558
trainer/Log Pis Std            7.1920094
trainer/Log Pis Max            34.11582
trainer/Log Pis Min            -4.735405
trainer/Policy mu Mean         0.07892334
trainer/Policy mu Std          1.578121
trainer/Policy mu Max          4.1688704
trainer/Policy mu Min          -3.8553543
trainer/Policy log std Mean    -0.6776473
trainer/Policy log std Std     0.22282615
trainer/Policy log std Max     0.13481617
trainer/Policy log std Min     -1.6084663
trainer/Alpha                  0.0035570745822042227
trainer/Alpha Loss             -1.7392328977584839
exploration/num steps total    881000
exploration/num paths total    1762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9327313516717984
exploration/Rewards Std        0.0928585661898194
exploration/Rewards Max        0.9798156646289519
exploration/Rewards Min        0.513506025173932
exploration/Returns Mean       466.3656758358992
exploration/Returns Std        2.7921798086106926
exploration/Returns Max        471.16637382152317
exploration/Returns Min        462.35436583777675
exploration/Actions Mean       0.014868622
exploration/Actions Std        0.6382083
exploration/Actions Max        0.9997792
exploration/Actions Min        -0.99982274
exploration/Num Paths          10
exploration/Average Returns    466.3656758358992
evaluation/num steps total     880000
evaluation/num paths total     1760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8250398464032738
evaluation/Rewards Std         0.13693815900799997
evaluation/Rewards Max         0.9785012887326534
evaluation/Rewards Min         0.5140012162382174
evaluation/Returns Mean        412.5199232016371
evaluation/Returns Std         50.00915664835415
evaluation/Returns Max         466.75722977744675
evaluation/Returns Min         346.40105163668403
evaluation/ExplReturns Mean    412.5199232016371
evaluation/ExplReturns Std     50.00915664835415
evaluation/ExplReturns Max     466.75722977744675
evaluation/ExplReturns Min     346.40105163668403
evaluation/Actions Mean        0.022803089
evaluation/Actions Std         0.6295058
evaluation/Actions Max         0.9975702
evaluation/Actions Min         -0.99853843
evaluation/Num Paths           10
evaluation/Average Returns     412.5199232016371
time/data storing (s)          0.033786495216190815
time/evaluation sampling (s)   111.48243889119476
time/exploration sampling (s)  111.67832826636732
time/logging (s)               0.030420337803661823
time/saving (s)                0.012672949582338333
time/training (s)              9.642048932611942
time/epoch (s)                 232.8796958727762
time/total (s)                 41270.605001900345
Epoch                          175
-----------------------------  ---------------------
2023-08-01 05:25:49.739623 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 176 finished
-----------------------------  ---------------------
replay_buffer/size             886000
trainer/tdrp Loss              [3401.4348]
trainer/QF1 Loss               0.1710244
trainer/QF2 Loss               0.14700946
trainer/Policy Loss            -74.50819
trainer/Q1 Predictions Mean    86.06798
trainer/Q1 Predictions Std     8.341143
trainer/Q1 Predictions Max     97.60402
trainer/Q1 Predictions Min     52.106632
trainer/Q2 Predictions Mean    86.12131
trainer/Q2 Predictions Std     8.399992
trainer/Q2 Predictions Max     97.63889
trainer/Q2 Predictions Min     52.30985
trainer/Q Targets Mean         86.17599
trainer/Q Targets Std          8.474622
trainer/Q Targets Max          97.528625
trainer/Q Targets Min          52.120213
trainer/Log Pis Mean           11.761749
trainer/Log Pis Std            6.893142
trainer/Log Pis Max            35.918877
trainer/Log Pis Min            -2.88866
trainer/Policy mu Mean         0.10658596
trainer/Policy mu Std          1.587601
trainer/Policy mu Max          4.1261435
trainer/Policy mu Min          -4.3888984
trainer/Policy log std Mean    -0.6732494
trainer/Policy log std Std     0.21511067
trainer/Policy log std Max     0.01719983
trainer/Policy log std Min     -1.614058
trainer/Alpha                  0.0034955409355461597
trainer/Alpha Loss             -1.3476688861846924
exploration/num steps total    886000
exploration/num paths total    1772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9384144785458358
exploration/Rewards Std        0.08957953993917224
exploration/Rewards Max        0.9789286977315484
exploration/Rewards Min        0.5048630620985933
exploration/Returns Mean       469.2072392729177
exploration/Returns Std        1.4623356313958598
exploration/Returns Max        472.14754994482985
exploration/Returns Min        467.3756973621084
exploration/Actions Mean       -0.009640849
exploration/Actions Std        0.592952
exploration/Actions Max        0.9998498
exploration/Actions Min        -0.99984664
exploration/Num Paths          10
exploration/Average Returns    469.2072392729177
evaluation/num steps total     885000
evaluation/num paths total     1770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9080006216712758
evaluation/Rewards Std         0.1184109700484052
evaluation/Rewards Max         0.978905060058944
evaluation/Rewards Min         0.5109130158094516
evaluation/Returns Mean        454.000310835638
evaluation/Returns Std         36.16371237556325
evaluation/Returns Max         467.09107072827345
evaluation/Returns Min         345.52691157919054
evaluation/ExplReturns Mean    454.000310835638
evaluation/ExplReturns Std     36.16371237556325
evaluation/ExplReturns Max     467.09107072827345
evaluation/ExplReturns Min     345.52691157919054
evaluation/Actions Mean        -0.0059692105
evaluation/Actions Std         0.5314421
evaluation/Actions Max         0.99679196
evaluation/Actions Min         -0.99956024
evaluation/Num Paths           10
evaluation/Average Returns     454.000310835638
time/data storing (s)          0.03439744655042887
time/evaluation sampling (s)   110.46847368963063
time/exploration sampling (s)  110.72082483489066
time/logging (s)               0.030429323203861713
time/saving (s)                0.010282440111041069
time/training (s)              9.59995554201305
time/epoch (s)                 230.86436327639967
time/total (s)                 41501.47184239142
Epoch                          176
-----------------------------  ---------------------
2023-08-01 05:29:40.522785 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 177 finished
-----------------------------  --------------------
replay_buffer/size             891000
trainer/tdrp Loss              [3542.7678]
trainer/QF1 Loss               0.16795826
trainer/QF2 Loss               0.14544412
trainer/Policy Loss            -74.39053
trainer/Q1 Predictions Mean    86.404526
trainer/Q1 Predictions Std     9.057896
trainer/Q1 Predictions Max     97.891174
trainer/Q1 Predictions Min     55.305874
trainer/Q2 Predictions Mean    86.52088
trainer/Q2 Predictions Std     9.088554
trainer/Q2 Predictions Max     97.94866
trainer/Q2 Predictions Min     55.371223
trainer/Q Targets Mean         86.50644
trainer/Q Targets Std          9.1275015
trainer/Q Targets Max          97.73959
trainer/Q Targets Min          54.40905
trainer/Log Pis Mean           12.292356
trainer/Log Pis Std            6.8046546
trainer/Log Pis Max            31.264381
trainer/Log Pis Min            -4.21809
trainer/Policy mu Mean         0.028189853
trainer/Policy mu Std          1.6313708
trainer/Policy mu Max          4.8908772
trainer/Policy mu Min          -4.296797
trainer/Policy log std Mean    -0.669559
trainer/Policy log std Std     0.2202633
trainer/Policy log std Max     0.17192727
trainer/Policy log std Min     -1.5287249
trainer/Alpha                  0.003528878092765808
trainer/Alpha Loss             1.6509020328521729
exploration/num steps total    891000
exploration/num paths total    1782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9417539012948105
exploration/Rewards Std        0.08281111728842859
exploration/Rewards Max        0.9797190458988325
exploration/Rewards Min        0.5040720146429528
exploration/Returns Mean       470.8769506474053
exploration/Returns Std        2.0056745158602345
exploration/Returns Max        473.696189932693
exploration/Returns Min        468.4225975039377
exploration/Actions Mean       -0.0057614353
exploration/Actions Std        0.61191934
exploration/Actions Max        0.9997995
exploration/Actions Min        -0.99963915
exploration/Num Paths          10
exploration/Average Returns    470.8769506474053
evaluation/num steps total     890000
evaluation/num paths total     1780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9429203494068661
evaluation/Rewards Std         0.07893321469363596
evaluation/Rewards Max         0.9760763999511042
evaluation/Rewards Min         0.5048076021111283
evaluation/Returns Mean        471.46017470343304
evaluation/Returns Std         2.2737965294289215
evaluation/Returns Max         473.4567801487961
evaluation/Returns Min         465.55071769252174
evaluation/ExplReturns Mean    471.46017470343304
evaluation/ExplReturns Std     2.2737965294289215
evaluation/ExplReturns Max     473.4567801487961
evaluation/ExplReturns Min     465.55071769252174
evaluation/Actions Mean        -0.008171358
evaluation/Actions Std         0.5587046
evaluation/Actions Max         0.9980155
evaluation/Actions Min         -0.9983451
evaluation/Num Paths           10
evaluation/Average Returns     471.46017470343304
time/data storing (s)          0.03454852104187012
time/evaluation sampling (s)   110.30651331599802
time/exploration sampling (s)  110.84541019704193
time/logging (s)               0.030440391041338444
time/saving (s)                0.012612257152795792
time/training (s)              9.549284149892628
time/epoch (s)                 230.77880883216858
time/total (s)                 41732.2531729117
Epoch                          177
-----------------------------  --------------------
2023-08-01 05:33:30.402687 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 178 finished
-----------------------------  ---------------------
replay_buffer/size             896000
trainer/tdrp Loss              [3572.654]
trainer/QF1 Loss               0.11969891
trainer/QF2 Loss               0.121921465
trainer/Policy Loss            -74.92772
trainer/Q1 Predictions Mean    86.8667
trainer/Q1 Predictions Std     8.496669
trainer/Q1 Predictions Max     98.121254
trainer/Q1 Predictions Min     54.92477
trainer/Q2 Predictions Mean    86.845695
trainer/Q2 Predictions Std     8.506186
trainer/Q2 Predictions Max     97.90507
trainer/Q2 Predictions Min     54.64469
trainer/Q Targets Mean         86.89247
trainer/Q Targets Std          8.530463
trainer/Q Targets Max          98.12756
trainer/Q Targets Min          55.318523
trainer/Log Pis Mean           12.153852
trainer/Log Pis Std            6.7582474
trainer/Log Pis Max            36.60856
trainer/Log Pis Min            -4.4758315
trainer/Policy mu Mean         -0.0326957
trainer/Policy mu Std          1.597918
trainer/Policy mu Max          4.4592443
trainer/Policy mu Min          -4.5579906
trainer/Policy log std Mean    -0.6857686
trainer/Policy log std Std     0.23221761
trainer/Policy log std Max     0.036483884
trainer/Policy log std Min     -1.6922646
trainer/Alpha                  0.0035348213277757168
trainer/Alpha Loss             0.8685637712478638
exploration/num steps total    896000
exploration/num paths total    1792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9403558656612498
exploration/Rewards Std        0.08383036537227632
exploration/Rewards Max        0.9799012771673585
exploration/Rewards Min        0.5010387717974251
exploration/Returns Mean       470.177932830625
exploration/Returns Std        1.7783146976583595
exploration/Returns Max        474.25026150615014
exploration/Returns Min        468.3742674942778
exploration/Actions Mean       0.002547835
exploration/Actions Std        0.62640405
exploration/Actions Max        0.99953467
exploration/Actions Min        -0.9995955
exploration/Num Paths          10
exploration/Average Returns    470.177932830625
evaluation/num steps total     895000
evaluation/num paths total     1790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.939441940488848
evaluation/Rewards Std         0.08051030901625657
evaluation/Rewards Max         0.9796541471509541
evaluation/Rewards Min         0.5085325556001342
evaluation/Returns Mean        469.7209702444241
evaluation/Returns Std         1.4480858706937423
evaluation/Returns Max         473.28295369020896
evaluation/Returns Min         468.222859908388
evaluation/ExplReturns Mean    469.7209702444241
evaluation/ExplReturns Std     1.4480858706937423
evaluation/ExplReturns Max     473.28295369020896
evaluation/ExplReturns Min     468.222859908388
evaluation/Actions Mean        0.005007259
evaluation/Actions Std         0.57609504
evaluation/Actions Max         0.9972255
evaluation/Actions Min         -0.9974505
evaluation/Num Paths           10
evaluation/Average Returns     469.7209702444241
time/data storing (s)          0.03403144422918558
time/evaluation sampling (s)   109.27452644798905
time/exploration sampling (s)  110.96628455072641
time/logging (s)               0.030330220237374306
time/saving (s)                0.012675863690674305
time/training (s)              9.557556003332138
time/epoch (s)                 229.87540453020483
time/total (s)                 41962.13112876937
Epoch                          178
-----------------------------  ---------------------
2023-08-01 05:37:21.950717 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 179 finished
-----------------------------  --------------------
replay_buffer/size             901000
trainer/tdrp Loss              [3306.7976]
trainer/QF1 Loss               0.14191933
trainer/QF2 Loss               0.16893098
trainer/Policy Loss            -76.11233
trainer/Q1 Predictions Mean    87.77489
trainer/Q1 Predictions Std     8.702508
trainer/Q1 Predictions Max     98.28039
trainer/Q1 Predictions Min     53.44923
trainer/Q2 Predictions Mean    87.8147
trainer/Q2 Predictions Std     8.689296
trainer/Q2 Predictions Max     98.19207
trainer/Q2 Predictions Min     53.848213
trainer/Q Targets Mean         87.81186
trainer/Q Targets Std          8.750645
trainer/Q Targets Max          98.27732
trainer/Q Targets Min          53.493187
trainer/Log Pis Mean           11.874769
trainer/Log Pis Std            6.617855
trainer/Log Pis Max            35.001595
trainer/Log Pis Min            -6.115302
trainer/Policy mu Mean         0.08862237
trainer/Policy mu Std          1.591056
trainer/Policy mu Max          4.404004
trainer/Policy mu Min          -4.436732
trainer/Policy log std Mean    -0.68332386
trainer/Policy log std Std     0.21870838
trainer/Policy log std Max     0.1365369
trainer/Policy log std Min     -1.5268865
trainer/Alpha                  0.003529941663146019
trainer/Alpha Loss             -0.707135796546936
exploration/num steps total    901000
exploration/num paths total    1802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.926477865123819
exploration/Rewards Std        0.09084372187542306
exploration/Rewards Max        0.9787915016155018
exploration/Rewards Min        0.4961214102542479
exploration/Returns Mean       463.2389325619094
exploration/Returns Std        4.519183973204801
exploration/Returns Max        473.75315269593784
exploration/Returns Min        457.1428063861255
exploration/Actions Mean       0.033810537
exploration/Actions Std        0.6295269
exploration/Actions Max        0.9999248
exploration/Actions Min        -0.9998947
exploration/Num Paths          10
exploration/Average Returns    463.2389325619094
evaluation/num steps total     900000
evaluation/num paths total     1800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9228593567270875
evaluation/Rewards Std         0.09296685980413014
evaluation/Rewards Max         0.9755964179229064
evaluation/Rewards Min         0.49192384875947276
evaluation/Returns Mean        461.4296783635435
evaluation/Returns Std         2.5791104572347043
evaluation/Returns Max         464.18595817211616
evaluation/Returns Min         457.80024236761835
evaluation/ExplReturns Mean    461.4296783635435
evaluation/ExplReturns Std     2.5791104572347043
evaluation/ExplReturns Max     464.18595817211616
evaluation/ExplReturns Min     457.80024236761835
evaluation/Actions Mean        0.036544126
evaluation/Actions Std         0.5673073
evaluation/Actions Max         0.99982786
evaluation/Actions Min         -0.99981534
evaluation/Num Paths           10
evaluation/Average Returns     461.4296783635435
time/data storing (s)          0.034260932356119156
time/evaluation sampling (s)   110.20327741187066
time/exploration sampling (s)  111.69082157406956
time/logging (s)               0.030135496519505978
time/saving (s)                0.012655777856707573
time/training (s)              9.572273841127753
time/epoch (s)                 231.5434250338003
time/total (s)                 42193.67711620219
Epoch                          179
-----------------------------  --------------------
2023-08-01 05:41:12.195315 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 180 finished
-----------------------------  ---------------------
replay_buffer/size             906000
trainer/tdrp Loss              [3981.7288]
trainer/QF1 Loss               0.16855119
trainer/QF2 Loss               0.17122303
trainer/Policy Loss            -75.54408
trainer/Q1 Predictions Mean    87.15329
trainer/Q1 Predictions Std     8.42885
trainer/Q1 Predictions Max     98.44833
trainer/Q1 Predictions Min     67.69576
trainer/Q2 Predictions Mean    87.11998
trainer/Q2 Predictions Std     8.419073
trainer/Q2 Predictions Max     98.36347
trainer/Q2 Predictions Min     67.28349
trainer/Q Targets Mean         87.232285
trainer/Q Targets Std          8.385128
trainer/Q Targets Max          98.29888
trainer/Q Targets Min          66.9481
trainer/Log Pis Mean           11.827673
trainer/Log Pis Std            6.964088
trainer/Log Pis Max            34.382008
trainer/Log Pis Min            -3.4821746
trainer/Policy mu Mean         0.14151292
trainer/Policy mu Std          1.5911722
trainer/Policy mu Max          4.585508
trainer/Policy mu Min          -4.1147003
trainer/Policy log std Mean    -0.67778903
trainer/Policy log std Std     0.228247
trainer/Policy log std Max     -0.025966823
trainer/Policy log std Min     -1.5686685
trainer/Alpha                  0.0034317104145884514
trainer/Alpha Loss             -0.9779372215270996
exploration/num steps total    906000
exploration/num paths total    1812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9375334847208245
exploration/Rewards Std        0.09385904709544156
exploration/Rewards Max        0.9797208611990054
exploration/Rewards Min        0.5016466637393163
exploration/Returns Mean       468.7667423604122
exploration/Returns Std        3.820692565717284
exploration/Returns Max        474.10263706647436
exploration/Returns Min        462.25400554470616
exploration/Actions Mean       0.05698845
exploration/Actions Std        0.64809704
exploration/Actions Max        0.9999581
exploration/Actions Min        -0.9997446
exploration/Num Paths          10
exploration/Average Returns    468.7667423604122
evaluation/num steps total     905000
evaluation/num paths total     1810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9465124086727519
evaluation/Rewards Std         0.0861953345962745
evaluation/Rewards Max         0.9795679482139596
evaluation/Rewards Min         0.5003014701770997
evaluation/Returns Mean        473.25620433637596
evaluation/Returns Std         1.5529859668353763
evaluation/Returns Max         475.9794174372674
evaluation/Returns Min         471.26515221205375
evaluation/ExplReturns Mean    473.25620433637596
evaluation/ExplReturns Std     1.5529859668353763
evaluation/ExplReturns Max     475.9794174372674
evaluation/ExplReturns Min     471.26515221205375
evaluation/Actions Mean        0.07425947
evaluation/Actions Std         0.6071542
evaluation/Actions Max         0.9964508
evaluation/Actions Min         -0.99746114
evaluation/Num Paths           10
evaluation/Average Returns     473.25620433637596
time/data storing (s)          0.0343337832018733
time/evaluation sampling (s)   110.05098530836403
time/exploration sampling (s)  110.62953762896359
time/logging (s)               0.030426306650042534
time/saving (s)                0.010228541679680347
time/training (s)              9.485007262788713
time/epoch (s)                 230.24051883164793
time/total (s)                 42423.920144122094
Epoch                          180
-----------------------------  ---------------------
2023-08-01 05:45:02.511309 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 181 finished
-----------------------------  ---------------------
replay_buffer/size             911000
trainer/tdrp Loss              [3358.8953]
trainer/QF1 Loss               0.16275887
trainer/QF2 Loss               0.143542
trainer/Policy Loss            -76.096695
trainer/Q1 Predictions Mean    87.399734
trainer/Q1 Predictions Std     8.529079
trainer/Q1 Predictions Max     98.37531
trainer/Q1 Predictions Min     54.727154
trainer/Q2 Predictions Mean    87.43905
trainer/Q2 Predictions Std     8.518585
trainer/Q2 Predictions Max     98.312065
trainer/Q2 Predictions Min     54.66642
trainer/Q Targets Mean         87.47476
trainer/Q Targets Std          8.56556
trainer/Q Targets Max          98.36943
trainer/Q Targets Min          54.972675
trainer/Log Pis Mean           11.544346
trainer/Log Pis Std            6.8635316
trainer/Log Pis Max            31.940588
trainer/Log Pis Min            -4.928607
trainer/Policy mu Mean         -0.018531464
trainer/Policy mu Std          1.570498
trainer/Policy mu Max          5.0217867
trainer/Policy mu Min          -5.8268785
trainer/Policy log std Mean    -0.67430097
trainer/Policy log std Std     0.21981682
trainer/Policy log std Max     0.05612707
trainer/Policy log std Min     -1.5885311
trainer/Alpha                  0.0034506923984736204
trainer/Alpha Loss             -2.5831034183502197
exploration/num steps total    911000
exploration/num paths total    1822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.936686868261169
exploration/Rewards Std        0.08689888309806304
exploration/Rewards Max        0.9791914154068202
exploration/Rewards Min        0.4856965432850071
exploration/Returns Mean       468.3434341305844
exploration/Returns Std        2.611525462760395
exploration/Returns Max        471.6990027861767
exploration/Returns Min        463.780788768864
exploration/Actions Mean       0.012712075
exploration/Actions Std        0.6181568
exploration/Actions Max        0.99981016
exploration/Actions Min        -0.9994909
exploration/Num Paths          10
exploration/Average Returns    468.3434341305844
evaluation/num steps total     910000
evaluation/num paths total     1820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.936126513966741
evaluation/Rewards Std         0.0878471967032064
evaluation/Rewards Max         0.9778542845707122
evaluation/Rewards Min         0.4986233881285078
evaluation/Returns Mean        468.0632569833706
evaluation/Returns Std         3.4476543271875686
evaluation/Returns Max         470.9268479825976
evaluation/Returns Min         458.3862447627358
evaluation/ExplReturns Mean    468.0632569833706
evaluation/ExplReturns Std     3.4476543271875686
evaluation/ExplReturns Max     470.9268479825976
evaluation/ExplReturns Min     458.3862447627358
evaluation/Actions Mean        0.022015575
evaluation/Actions Std         0.5498735
evaluation/Actions Max         0.9989082
evaluation/Actions Min         -0.9965846
evaluation/Num Paths           10
evaluation/Average Returns     468.0632569833706
time/data storing (s)          0.03399750031530857
time/evaluation sampling (s)   109.71129730995744
time/exploration sampling (s)  110.93648231588304
time/logging (s)               0.031411685049533844
time/saving (s)                0.012852625921368599
time/training (s)              9.58656296506524
time/epoch (s)                 230.31260440219194
time/total (s)                 42654.23520585243
Epoch                          181
-----------------------------  ---------------------
2023-08-01 05:48:53.296376 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 182 finished
-----------------------------  ---------------------
replay_buffer/size             916000
trainer/tdrp Loss              [3459.877]
trainer/QF1 Loss               0.15737054
trainer/QF2 Loss               0.14768648
trainer/Policy Loss            -77.17625
trainer/Q1 Predictions Mean    87.88483
trainer/Q1 Predictions Std     9.003952
trainer/Q1 Predictions Max     98.504364
trainer/Q1 Predictions Min     58.071533
trainer/Q2 Predictions Mean    87.92346
trainer/Q2 Predictions Std     9.008786
trainer/Q2 Predictions Max     98.57337
trainer/Q2 Predictions Min     58.30718
trainer/Q Targets Mean         87.860855
trainer/Q Targets Std          9.06402
trainer/Q Targets Max          98.566055
trainer/Q Targets Min          57.420666
trainer/Log Pis Mean           10.943426
trainer/Log Pis Std            6.546562
trainer/Log Pis Max            31.193668
trainer/Log Pis Min            -1.1043863
trainer/Policy mu Mean         0.10520038
trainer/Policy mu Std          1.553098
trainer/Policy mu Max          4.6113095
trainer/Policy mu Min          -4.069524
trainer/Policy log std Mean    -0.70867634
trainer/Policy log std Std     0.23651755
trainer/Policy log std Max     -0.021095604
trainer/Policy log std Min     -1.6849538
trainer/Alpha                  0.0033578062430024147
trainer/Alpha Loss             -6.018750190734863
exploration/num steps total    916000
exploration/num paths total    1832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9439632116119862
exploration/Rewards Std        0.08440113427780448
exploration/Rewards Max        0.9799506327204046
exploration/Rewards Min        0.5036295497501979
exploration/Returns Mean       471.98160580599307
exploration/Returns Std        2.230767065978189
exploration/Returns Max        478.0248146744233
exploration/Returns Min        469.74241674847485
exploration/Actions Mean       0.0464512
exploration/Actions Std        0.6417617
exploration/Actions Max        0.99974966
exploration/Actions Min        -0.99991494
exploration/Num Paths          10
exploration/Average Returns    471.98160580599307
evaluation/num steps total     915000
evaluation/num paths total     1830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9419781877583908
evaluation/Rewards Std         0.08611127456579594
evaluation/Rewards Max         0.9799021870279552
evaluation/Rewards Min         0.4976254053845617
evaluation/Returns Mean        470.9890938791952
evaluation/Returns Std         4.5467259816203205
evaluation/Returns Max         476.6299731022499
evaluation/Returns Min         459.1573548657374
evaluation/ExplReturns Mean    470.9890938791952
evaluation/ExplReturns Std     4.5467259816203205
evaluation/ExplReturns Max     476.6299731022499
evaluation/ExplReturns Min     459.1573548657374
evaluation/Actions Mean        0.06674884
evaluation/Actions Std         0.5896626
evaluation/Actions Max         0.9997303
evaluation/Actions Min         -0.99931395
evaluation/Num Paths           10
evaluation/Average Returns     470.9890938791952
time/data storing (s)          0.034134723246097565
time/evaluation sampling (s)   109.41198971681297
time/exploration sampling (s)  110.7625452876091
time/logging (s)               0.030267629772424698
time/saving (s)                0.01247993391007185
time/training (s)              10.52811028715223
time/epoch (s)                 230.7795275785029
time/total (s)                 42885.01725307014
Epoch                          182
-----------------------------  ---------------------
2023-08-01 05:52:45.395388 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 183 finished
-----------------------------  ---------------------
replay_buffer/size             921000
trainer/tdrp Loss              [3635.8992]
trainer/QF1 Loss               0.20048729
trainer/QF2 Loss               0.23120579
trainer/Policy Loss            -76.931755
trainer/Q1 Predictions Mean    87.673996
trainer/Q1 Predictions Std     8.768469
trainer/Q1 Predictions Max     98.81151
trainer/Q1 Predictions Min     65.630424
trainer/Q2 Predictions Mean    87.76044
trainer/Q2 Predictions Std     8.770048
trainer/Q2 Predictions Max     98.809364
trainer/Q2 Predictions Min     65.149704
trainer/Q Targets Mean         87.538445
trainer/Q Targets Std          8.756962
trainer/Q Targets Max          98.615944
trainer/Q Targets Min          65.374756
trainer/Log Pis Mean           10.971599
trainer/Log Pis Std            7.5727525
trainer/Log Pis Max            41.542915
trainer/Log Pis Min            -2.5406365
trainer/Policy mu Mean         0.0032611564
trainer/Policy mu Std          1.5591089
trainer/Policy mu Max          4.1750965
trainer/Policy mu Min          -5.3494005
trainer/Policy log std Mean    -0.670393
trainer/Policy log std Std     0.23326582
trainer/Policy log std Max     0.2570432
trainer/Policy log std Min     -1.6280402
trainer/Alpha                  0.0035110563039779663
trainer/Alpha Loss             -5.812116622924805
exploration/num steps total    921000
exploration/num paths total    1842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9026875398725398
exploration/Rewards Std        0.122181703698708
exploration/Rewards Max        0.979654487911385
exploration/Rewards Min        0.4987796191609527
exploration/Returns Mean       451.34376993626995
exploration/Returns Std        31.240950424893732
exploration/Returns Max        475.3027479273853
exploration/Returns Min        395.32990109872685
exploration/Actions Mean       0.019421842
exploration/Actions Std        0.653067
exploration/Actions Max        0.9999389
exploration/Actions Min        -0.99972844
exploration/Num Paths          10
exploration/Average Returns    451.34376993626995
evaluation/num steps total     920000
evaluation/num paths total     1840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9231609778110593
evaluation/Rewards Std         0.11047592175826791
evaluation/Rewards Max         0.9793029827508776
evaluation/Rewards Min         0.5049123000657304
evaluation/Returns Mean        461.58048890552953
evaluation/Returns Std         27.86714807065786
evaluation/Returns Max         472.73125379301393
evaluation/Returns Min         378.0572216906084
evaluation/ExplReturns Mean    461.58048890552953
evaluation/ExplReturns Std     27.86714807065786
evaluation/ExplReturns Max     472.73125379301393
evaluation/ExplReturns Min     378.0572216906084
evaluation/Actions Mean        0.008577362
evaluation/Actions Std         0.6294049
evaluation/Actions Max         0.9988774
evaluation/Actions Min         -0.99918234
evaluation/Num Paths           10
evaluation/Average Returns     461.58048890552953
time/data storing (s)          0.03378646448254585
time/evaluation sampling (s)   110.89832319319248
time/exploration sampling (s)  112.31528091989458
time/logging (s)               0.03021791484206915
time/saving (s)                0.01023074984550476
time/training (s)              8.80675370246172
time/epoch (s)                 232.0945929447189
time/total (s)                 43117.114321515895
Epoch                          183
-----------------------------  ---------------------
2023-08-01 05:56:37.175349 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 184 finished
-----------------------------  ---------------------
replay_buffer/size             926000
trainer/tdrp Loss              [3694.257]
trainer/QF1 Loss               0.1812819
trainer/QF2 Loss               0.1898198
trainer/Policy Loss            -75.401535
trainer/Q1 Predictions Mean    86.78196
trainer/Q1 Predictions Std     8.8949
trainer/Q1 Predictions Max     98.699974
trainer/Q1 Predictions Min     57.11279
trainer/Q2 Predictions Mean    86.77792
trainer/Q2 Predictions Std     8.915873
trainer/Q2 Predictions Max     98.54647
trainer/Q2 Predictions Min     56.611195
trainer/Q Targets Mean         86.78962
trainer/Q Targets Std          8.978401
trainer/Q Targets Max          98.53029
trainer/Q Targets Min          56.890213
trainer/Log Pis Mean           11.596202
trainer/Log Pis Std            6.896408
trainer/Log Pis Max            35.65983
trainer/Log Pis Min            -4.6018486
trainer/Policy mu Mean         0.05568363
trainer/Policy mu Std          1.5948396
trainer/Policy mu Max          4.678405
trainer/Policy mu Min          -4.6821604
trainer/Policy log std Mean    -0.67876166
trainer/Policy log std Std     0.23698592
trainer/Policy log std Max     0.07879659
trainer/Policy log std Min     -1.7222637
trainer/Alpha                  0.0033062337897717953
trainer/Alpha Loss             -2.3065402507781982
exploration/num steps total    926000
exploration/num paths total    1852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9450137649937372
exploration/Rewards Std        0.07380480712120814
exploration/Rewards Max        0.976952106896402
exploration/Rewards Min        0.4947303703057747
exploration/Returns Mean       472.50688249686857
exploration/Returns Std        3.1200022241874956
exploration/Returns Max        475.48808501887856
exploration/Returns Min        465.67032015682724
exploration/Actions Mean       -0.008957937
exploration/Actions Std        0.6217657
exploration/Actions Max        0.9998146
exploration/Actions Min        -0.9997114
exploration/Num Paths          10
exploration/Average Returns    472.50688249686857
evaluation/num steps total     925000
evaluation/num paths total     1850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.947022065539888
evaluation/Rewards Std         0.07379023349651444
evaluation/Rewards Max         0.97671242096061
evaluation/Rewards Min         0.5109369889561047
evaluation/Returns Mean        473.5110327699438
evaluation/Returns Std         2.002989065807395
evaluation/Returns Max         476.70849252917316
evaluation/Returns Min         471.51155407870203
evaluation/ExplReturns Mean    473.5110327699438
evaluation/ExplReturns Std     2.002989065807395
evaluation/ExplReturns Max     476.70849252917316
evaluation/ExplReturns Min     471.51155407870203
evaluation/Actions Mean        -0.00885188
evaluation/Actions Std         0.5668031
evaluation/Actions Max         0.99796367
evaluation/Actions Min         -0.99392873
evaluation/Num Paths           10
evaluation/Average Returns     473.5110327699438
time/data storing (s)          0.034198179841041565
time/evaluation sampling (s)   110.51604972034693
time/exploration sampling (s)  111.2582591008395
time/logging (s)               0.03110675234347582
time/saving (s)                0.012818405404686928
time/training (s)              9.924017588607967
time/epoch (s)                 231.7764497473836
time/total (s)                 43348.893220759
Epoch                          184
-----------------------------  ---------------------
2023-08-01 06:00:31.279469 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 185 finished
-----------------------------  --------------------
replay_buffer/size             931000
trainer/tdrp Loss              [3428.4072]
trainer/QF1 Loss               0.17064403
trainer/QF2 Loss               0.17049494
trainer/Policy Loss            -75.870224
trainer/Q1 Predictions Mean    87.64221
trainer/Q1 Predictions Std     8.633367
trainer/Q1 Predictions Max     99.001884
trainer/Q1 Predictions Min     63.305817
trainer/Q2 Predictions Mean    87.52879
trainer/Q2 Predictions Std     8.6350975
trainer/Q2 Predictions Max     98.751854
trainer/Q2 Predictions Min     64.400276
trainer/Q Targets Mean         87.59638
trainer/Q Targets Std          8.683482
trainer/Q Targets Max          98.80652
trainer/Q Targets Min          64.25247
trainer/Log Pis Mean           11.938268
trainer/Log Pis Std            6.2209682
trainer/Log Pis Max            31.569489
trainer/Log Pis Min            -3.5880632
trainer/Policy mu Mean         0.031695697
trainer/Policy mu Std          1.605185
trainer/Policy mu Max          4.1652427
trainer/Policy mu Min          -4.1863403
trainer/Policy log std Mean    -0.67182547
trainer/Policy log std Std     0.24138904
trainer/Policy log std Max     0.02205664
trainer/Policy log std Min     -1.608568
trainer/Alpha                  0.00345870153978467
trainer/Alpha Loss             -0.3498344421386719
exploration/num steps total    931000
exploration/num paths total    1862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9425869158484548
exploration/Rewards Std        0.0845600398056727
exploration/Rewards Max        0.9797368416223299
exploration/Rewards Min        0.4994526348818372
exploration/Returns Mean       471.29345792422737
exploration/Returns Std        5.798121408386432
exploration/Returns Max        477.3933958516374
exploration/Returns Min        455.2240505528786
exploration/Actions Mean       -0.014771002
exploration/Actions Std        0.5902245
exploration/Actions Max        0.99991953
exploration/Actions Min        -0.99977905
exploration/Num Paths          10
exploration/Average Returns    471.29345792422737
evaluation/num steps total     930000
evaluation/num paths total     1860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9206243555753215
evaluation/Rewards Std         0.10753540685567217
evaluation/Rewards Max         0.977409319535762
evaluation/Rewards Min         0.5057076395027379
evaluation/Returns Mean        460.31217778766074
evaluation/Returns Std         37.86349207256124
evaluation/Returns Max         477.88472561012577
evaluation/Returns Min         346.96952873182795
evaluation/ExplReturns Mean    460.31217778766074
evaluation/ExplReturns Std     37.86349207256124
evaluation/ExplReturns Max     477.88472561012577
evaluation/ExplReturns Min     346.96952873182795
evaluation/Actions Mean        -0.00073478086
evaluation/Actions Std         0.5191803
evaluation/Actions Max         0.99893206
evaluation/Actions Min         -0.9983085
evaluation/Num Paths           10
evaluation/Average Returns     460.31217778766074
time/data storing (s)          0.034459950402379036
time/evaluation sampling (s)   112.44289812352508
time/exploration sampling (s)  111.8892754195258
time/logging (s)               0.041168360970914364
time/saving (s)                0.016048752702772617
time/training (s)              9.68554906733334
time/epoch (s)                 234.1093996744603
time/total (s)                 43583.00531519763
Epoch                          185
-----------------------------  --------------------
2023-08-01 06:04:27.251083 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 186 finished
-----------------------------  --------------------
replay_buffer/size             936000
trainer/tdrp Loss              [3475.555]
trainer/QF1 Loss               0.15430012
trainer/QF2 Loss               0.13661815
trainer/Policy Loss            -77.760956
trainer/Q1 Predictions Mean    89.10519
trainer/Q1 Predictions Std     8.182495
trainer/Q1 Predictions Max     99.04815
trainer/Q1 Predictions Min     68.197975
trainer/Q2 Predictions Mean    88.95601
trainer/Q2 Predictions Std     8.178009
trainer/Q2 Predictions Max     98.90617
trainer/Q2 Predictions Min     68.34033
trainer/Q Targets Mean         89.00304
trainer/Q Targets Std          8.240455
trainer/Q Targets Max          98.89816
trainer/Q Targets Min          67.92603
trainer/Log Pis Mean           11.42071
trainer/Log Pis Std            7.1621714
trainer/Log Pis Max            30.22526
trainer/Log Pis Min            -5.094435
trainer/Policy mu Mean         0.033450224
trainer/Policy mu Std          1.5584506
trainer/Policy mu Max          4.1361
trainer/Policy mu Min          -4.2150955
trainer/Policy log std Mean    -0.6830377
trainer/Policy log std Std     0.23607284
trainer/Policy log std Max     0.04259187
trainer/Policy log std Min     -1.6298654
trainer/Alpha                  0.003329852130264044
trainer/Alpha Loss             -3.30472469329834
exploration/num steps total    936000
exploration/num paths total    1872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9305488139106921
exploration/Rewards Std        0.09239040932158717
exploration/Rewards Max        0.9767727594632216
exploration/Rewards Min        0.5016440343838474
exploration/Returns Mean       465.27440695534585
exploration/Returns Std        19.62519462630553
exploration/Returns Max        473.9774146480217
exploration/Returns Min        406.5377673389216
exploration/Actions Mean       -0.011643776
exploration/Actions Std        0.6267474
exploration/Actions Max        0.999873
exploration/Actions Min        -0.99961644
exploration/Num Paths          10
exploration/Average Returns    465.27440695534585
evaluation/num steps total     935000
evaluation/num paths total     1870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9463269281591845
evaluation/Rewards Std         0.07315779217880787
evaluation/Rewards Max         0.9751625352072804
evaluation/Rewards Min         0.5040455942809868
evaluation/Returns Mean        473.16346407959236
evaluation/Returns Std         0.8342173385093172
evaluation/Returns Max         474.34737851333216
evaluation/Returns Min         471.6403095587841
evaluation/ExplReturns Mean    473.16346407959236
evaluation/ExplReturns Std     0.8342173385093172
evaluation/ExplReturns Max     474.34737851333216
evaluation/ExplReturns Min     471.6403095587841
evaluation/Actions Mean        -0.034244522
evaluation/Actions Std         0.60702163
evaluation/Actions Max         0.9977828
evaluation/Actions Min         -0.99654377
evaluation/Num Paths           10
evaluation/Average Returns     473.16346407959236
time/data storing (s)          0.03445326816290617
time/evaluation sampling (s)   113.41813290119171
time/exploration sampling (s)  112.22509873099625
time/logging (s)               0.03093741089105606
time/saving (s)                0.012758191674947739
time/training (s)              10.235633349046111
time/epoch (s)                 235.95701385196298
time/total (s)                 43818.96481193043
Epoch                          186
-----------------------------  --------------------
2023-08-01 06:08:18.128626 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 187 finished
-----------------------------  ---------------------
replay_buffer/size             941000
trainer/tdrp Loss              [3403.0151]
trainer/QF1 Loss               0.16124591
trainer/QF2 Loss               0.14120875
trainer/Policy Loss            -76.35559
trainer/Q1 Predictions Mean    88.13784
trainer/Q1 Predictions Std     8.319126
trainer/Q1 Predictions Max     100.34988
trainer/Q1 Predictions Min     61.320587
trainer/Q2 Predictions Mean    88.00006
trainer/Q2 Predictions Std     8.275189
trainer/Q2 Predictions Max     100.27163
trainer/Q2 Predictions Min     60.719944
trainer/Q Targets Mean         88.00912
trainer/Q Targets Std          8.296124
trainer/Q Targets Max          99.65974
trainer/Q Targets Min          61.952145
trainer/Log Pis Mean           11.913048
trainer/Log Pis Std            7.0209203
trainer/Log Pis Max            33.510033
trainer/Log Pis Min            -10.216318
trainer/Policy mu Mean         -0.06202447
trainer/Policy mu Std          1.5946187
trainer/Policy mu Max          4.603409
trainer/Policy mu Min          -4.8752975
trainer/Policy log std Mean    -0.6620956
trainer/Policy log std Std     0.22575553
trainer/Policy log std Max     0.10933602
trainer/Policy log std Min     -1.6383284
trainer/Alpha                  0.0034302922431379557
trainer/Alpha Loss             -0.49345827102661133
exploration/num steps total    941000
exploration/num paths total    1882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.924868821918256
exploration/Rewards Std        0.09505019734068797
exploration/Rewards Max        0.9786704733964737
exploration/Rewards Min        0.4948572515529116
exploration/Returns Mean       462.43441095912806
exploration/Returns Std        25.174339519285844
exploration/Returns Max        474.0880170235741
exploration/Returns Min        387.02886097474646
exploration/Actions Mean       0.025040917
exploration/Actions Std        0.6423326
exploration/Actions Max        0.9999407
exploration/Actions Min        -0.99935716
exploration/Num Paths          10
exploration/Average Returns    462.43441095912806
evaluation/num steps total     940000
evaluation/num paths total     1880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9444249418257529
evaluation/Rewards Std         0.0693076129667367
evaluation/Rewards Max         0.9752404217584486
evaluation/Rewards Min         0.5075250560921326
evaluation/Returns Mean        472.2124709128764
evaluation/Returns Std         0.6146517147388832
evaluation/Returns Max         473.1553973888986
evaluation/Returns Min         470.94126652814845
evaluation/ExplReturns Mean    472.2124709128764
evaluation/ExplReturns Std     0.6146517147388832
evaluation/ExplReturns Max     473.1553973888986
evaluation/ExplReturns Min     470.94126652814845
evaluation/Actions Mean        0.03007185
evaluation/Actions Std         0.61285436
evaluation/Actions Max         0.9969639
evaluation/Actions Min         -0.9963958
evaluation/Num Paths           10
evaluation/Average Returns     472.2124709128764
time/data storing (s)          0.0341973714530468
time/evaluation sampling (s)   109.33934131637216
time/exploration sampling (s)  110.9344627968967
time/logging (s)               0.031093711033463478
time/saving (s)                0.01148732379078865
time/training (s)              10.522503176704049
time/epoch (s)                 230.8730856962502
time/total (s)                 44049.840545872226
Epoch                          187
-----------------------------  ---------------------
2023-08-01 06:12:07.659599 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 188 finished
-----------------------------  --------------------
replay_buffer/size             946000
trainer/tdrp Loss              [3435.5764]
trainer/QF1 Loss               0.16636154
trainer/QF2 Loss               0.17513078
trainer/Policy Loss            -75.67558
trainer/Q1 Predictions Mean    87.48593
trainer/Q1 Predictions Std     8.834172
trainer/Q1 Predictions Max     98.99301
trainer/Q1 Predictions Min     57.261066
trainer/Q2 Predictions Mean    87.53935
trainer/Q2 Predictions Std     8.84988
trainer/Q2 Predictions Max     98.89203
trainer/Q2 Predictions Min     56.866936
trainer/Q Targets Mean         87.556885
trainer/Q Targets Std          8.821744
trainer/Q Targets Max          98.82821
trainer/Q Targets Min          56.73715
trainer/Log Pis Mean           12.040731
trainer/Log Pis Std            7.140514
trainer/Log Pis Max            31.476767
trainer/Log Pis Min            -4.7358885
trainer/Policy mu Mean         0.019131005
trainer/Policy mu Std          1.6153755
trainer/Policy mu Max          4.624822
trainer/Policy mu Min          -4.6961594
trainer/Policy log std Mean    -0.66196364
trainer/Policy log std Std     0.20883626
trainer/Policy log std Max     0.08632499
trainer/Policy log std Min     -1.5379682
trainer/Alpha                  0.003360686358064413
trainer/Alpha Loss             0.2319856882095337
exploration/num steps total    946000
exploration/num paths total    1892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9393488670966189
exploration/Rewards Std        0.08787100669075625
exploration/Rewards Max        0.9797077508020199
exploration/Rewards Min        0.4990572965667262
exploration/Returns Mean       469.6744335483096
exploration/Returns Std        10.658574565079217
exploration/Returns Max        477.7148615877182
exploration/Returns Min        438.82846556088776
exploration/Actions Mean       0.013831433
exploration/Actions Std        0.61255014
exploration/Actions Max        0.9996861
exploration/Actions Min        -0.99965835
exploration/Num Paths          10
exploration/Average Returns    469.6744335483096
evaluation/num steps total     945000
evaluation/num paths total     1890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9552247054282142
evaluation/Rewards Std         0.07360419510067084
evaluation/Rewards Max         0.9797555223197811
evaluation/Rewards Min         0.49669379656505025
evaluation/Returns Mean        477.61235271410715
evaluation/Returns Std         0.8540649891353346
evaluation/Returns Max         478.84288078553817
evaluation/Returns Min         475.94404745832423
evaluation/ExplReturns Mean    477.61235271410715
evaluation/ExplReturns Std     0.8540649891353346
evaluation/ExplReturns Max     478.84288078553817
evaluation/ExplReturns Min     475.94404745832423
evaluation/Actions Mean        0.008335816
evaluation/Actions Std         0.556911
evaluation/Actions Max         0.9945263
evaluation/Actions Min         -0.9975801
evaluation/Num Paths           10
evaluation/Average Returns     477.61235271410715
time/data storing (s)          0.03440408781170845
time/evaluation sampling (s)   109.21505431458354
time/exploration sampling (s)  110.42552124708891
time/logging (s)               0.030382568016648293
time/saving (s)                0.010367357172071934
time/training (s)              9.809933547861874
time/epoch (s)                 229.52566312253475
time/total (s)                 44279.368843650445
Epoch                          188
-----------------------------  --------------------
2023-08-01 06:15:59.043307 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 189 finished
-----------------------------  ---------------------
replay_buffer/size             951000
trainer/tdrp Loss              [3246.144]
trainer/QF1 Loss               0.14351827
trainer/QF2 Loss               0.15776896
trainer/Policy Loss            -77.778305
trainer/Q1 Predictions Mean    88.76016
trainer/Q1 Predictions Std     8.596746
trainer/Q1 Predictions Max     98.91905
trainer/Q1 Predictions Min     64.09722
trainer/Q2 Predictions Mean    88.77917
trainer/Q2 Predictions Std     8.607791
trainer/Q2 Predictions Max     98.8483
trainer/Q2 Predictions Min     63.93431
trainer/Q Targets Mean         88.757034
trainer/Q Targets Std          8.698865
trainer/Q Targets Max          99.648865
trainer/Q Targets Min          63.658657
trainer/Log Pis Mean           11.168179
trainer/Log Pis Std            7.7456703
trainer/Log Pis Max            33.34782
trainer/Log Pis Min            -3.932056
trainer/Policy mu Mean         0.06517537
trainer/Policy mu Std          1.5751598
trainer/Policy mu Max          4.319234
trainer/Policy mu Min          -4.9050927
trainer/Policy log std Mean    -0.6826462
trainer/Policy log std Std     0.21799697
trainer/Policy log std Max     0.03413385
trainer/Policy log std Min     -1.5735002
trainer/Alpha                  0.0033014321234077215
trainer/Alpha Loss             -4.752440452575684
exploration/num steps total    951000
exploration/num paths total    1902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9385493876369283
exploration/Rewards Std        0.07912242438226957
exploration/Rewards Max        0.9792532900757407
exploration/Rewards Min        0.49652881730312404
exploration/Returns Mean       469.27469381846413
exploration/Returns Std        2.594305793605168
exploration/Returns Max        471.86057186107695
exploration/Returns Min        463.08460151253996
exploration/Actions Mean       0.048369754
exploration/Actions Std        0.6364864
exploration/Actions Max        0.9997755
exploration/Actions Min        -0.9997067
exploration/Num Paths          10
exploration/Average Returns    469.27469381846413
evaluation/num steps total     950000
evaluation/num paths total     1900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9366922381889461
evaluation/Rewards Std         0.08299427120689733
evaluation/Rewards Max         0.9786796325763485
evaluation/Rewards Min         0.4991643106817861
evaluation/Returns Mean        468.346119094473
evaluation/Returns Std         7.941210254793862
evaluation/Returns Max         473.37039761274633
evaluation/Returns Min         447.81873462521185
evaluation/ExplReturns Mean    468.346119094473
evaluation/ExplReturns Std     7.941210254793862
evaluation/ExplReturns Max     473.37039761274633
evaluation/ExplReturns Min     447.81873462521185
evaluation/Actions Mean        0.058144283
evaluation/Actions Std         0.6017847
evaluation/Actions Max         0.9993175
evaluation/Actions Min         -0.9990661
evaluation/Num Paths           10
evaluation/Average Returns     468.346119094473
time/data storing (s)          0.03405702859163284
time/evaluation sampling (s)   110.47034587524831
time/exploration sampling (s)  111.31042271573097
time/logging (s)               0.03034491464495659
time/saving (s)                0.012595410458743572
time/training (s)              9.521504857577384
time/epoch (s)                 231.379270802252
time/total (s)                 44510.75062720943
Epoch                          189
-----------------------------  ---------------------
2023-08-01 06:19:50.794549 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 190 finished
-----------------------------  --------------------
replay_buffer/size             956000
trainer/tdrp Loss              [3446.2317]
trainer/QF1 Loss               0.17204076
trainer/QF2 Loss               0.19064584
trainer/Policy Loss            -76.73653
trainer/Q1 Predictions Mean    88.36476
trainer/Q1 Predictions Std     8.646835
trainer/Q1 Predictions Max     99.205765
trainer/Q1 Predictions Min     65.84866
trainer/Q2 Predictions Mean    88.51432
trainer/Q2 Predictions Std     8.61678
trainer/Q2 Predictions Max     99.17363
trainer/Q2 Predictions Min     65.75201
trainer/Q Targets Mean         88.37193
trainer/Q Targets Std          8.646228
trainer/Q Targets Max          99.00763
trainer/Q Targets Min          65.90111
trainer/Log Pis Mean           11.84806
trainer/Log Pis Std            7.3724775
trainer/Log Pis Max            34.47065
trainer/Log Pis Min            -3.8412468
trainer/Policy mu Mean         0.10810447
trainer/Policy mu Std          1.5997037
trainer/Policy mu Max          5.035197
trainer/Policy mu Min          -5.6240425
trainer/Policy log std Mean    -0.67125434
trainer/Policy log std Std     0.2170852
trainer/Policy log std Max     0.24932092
trainer/Policy log std Min     -1.4699403
trainer/Alpha                  0.003307206789031625
trainer/Alpha Loss             -0.8678278923034668
exploration/num steps total    956000
exploration/num paths total    1912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9387911066553912
exploration/Rewards Std        0.0832624580827385
exploration/Rewards Max        0.9780715395655961
exploration/Rewards Min        0.500815058602926
exploration/Returns Mean       469.39555332769567
exploration/Returns Std        1.1937175834341733
exploration/Returns Max        470.78187842119877
exploration/Returns Min        467.07606638426057
exploration/Actions Mean       0.06646987
exploration/Actions Std        0.63996756
exploration/Actions Max        0.9998674
exploration/Actions Min        -0.99982804
exploration/Num Paths          10
exploration/Average Returns    469.39555332769567
evaluation/num steps total     955000
evaluation/num paths total     1910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.943386924207972
evaluation/Rewards Std         0.08131887687164008
evaluation/Rewards Max         0.9770794396860011
evaluation/Rewards Min         0.49863300291712237
evaluation/Returns Mean        471.693462103986
evaluation/Returns Std         0.9093134995665355
evaluation/Returns Max         472.60424075962425
evaluation/Returns Min         469.58439111297
evaluation/ExplReturns Mean    471.693462103986
evaluation/ExplReturns Std     0.9093134995665355
evaluation/ExplReturns Max     472.60424075962425
evaluation/ExplReturns Min     469.58439111297
evaluation/Actions Mean        0.084203646
evaluation/Actions Std         0.6067905
evaluation/Actions Max         0.9992628
evaluation/Actions Min         -0.9951738
evaluation/Num Paths           10
evaluation/Average Returns     471.693462103986
time/data storing (s)          0.03382082749158144
time/evaluation sampling (s)   110.4274025335908
time/exploration sampling (s)  112.23476540017873
time/logging (s)               0.030519580468535423
time/saving (s)                0.010711275041103363
time/training (s)              9.009751985780895
time/epoch (s)                 231.74697160255164
time/total (s)                 44742.500047091395
Epoch                          190
-----------------------------  --------------------
2023-08-01 06:23:43.697676 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 191 finished
-----------------------------  ---------------------
replay_buffer/size             961000
trainer/tdrp Loss              [3530.5786]
trainer/QF1 Loss               0.12616485
trainer/QF2 Loss               0.12205714
trainer/Policy Loss            -78.92674
trainer/Q1 Predictions Mean    89.40896
trainer/Q1 Predictions Std     8.865465
trainer/Q1 Predictions Max     99.42823
trainer/Q1 Predictions Min     59.19311
trainer/Q2 Predictions Mean    89.41841
trainer/Q2 Predictions Std     8.9024105
trainer/Q2 Predictions Max     99.44635
trainer/Q2 Predictions Min     59.08034
trainer/Q Targets Mean         89.53274
trainer/Q Targets Std          8.915373
trainer/Q Targets Max          99.4205
trainer/Q Targets Min          59.11589
trainer/Log Pis Mean           10.68438
trainer/Log Pis Std            7.8313537
trainer/Log Pis Max            38.367027
trainer/Log Pis Min            -4.086646
trainer/Policy mu Mean         0.073741026
trainer/Policy mu Std          1.5325025
trainer/Policy mu Max          4.0562277
trainer/Policy mu Min          -4.6055083
trainer/Policy log std Mean    -0.6903822
trainer/Policy log std Std     0.22484027
trainer/Policy log std Max     0.3641305
trainer/Policy log std Min     -1.4740658
trainer/Alpha                  0.0033120959997177124
trainer/Alpha Loss             -7.512287616729736
exploration/num steps total    961000
exploration/num paths total    1922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9230093473482568
exploration/Rewards Std        0.10465226157186704
exploration/Rewards Max        0.9799902877140214
exploration/Rewards Min        0.49953107398541186
exploration/Returns Mean       461.5046736741283
exploration/Returns Std        37.02349463025171
exploration/Returns Max        476.41156757361614
exploration/Returns Min        350.61290578581816
exploration/Actions Mean       0.060092766
exploration/Actions Std        0.63281685
exploration/Actions Max        0.99985504
exploration/Actions Min        -0.9998019
exploration/Num Paths          10
exploration/Average Returns    461.5046736741283
evaluation/num steps total     960000
evaluation/num paths total     1920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9278426229193949
evaluation/Rewards Std         0.10717081019329028
evaluation/Rewards Max         0.9799612979598309
evaluation/Rewards Min         0.4950950680103057
evaluation/Returns Mean        463.9213114596972
evaluation/Returns Std         39.82438244997072
evaluation/Returns Max         479.32067038292763
evaluation/Returns Min         344.62195679277977
evaluation/ExplReturns Mean    463.9213114596972
evaluation/ExplReturns Std     39.82438244997072
evaluation/ExplReturns Max     479.32067038292763
evaluation/ExplReturns Min     344.62195679277977
evaluation/Actions Mean        0.0650553
evaluation/Actions Std         0.61019814
evaluation/Actions Max         0.99929816
evaluation/Actions Min         -0.99651855
evaluation/Num Paths           10
evaluation/Average Returns     463.9213114596972
time/data storing (s)          0.03421839140355587
time/evaluation sampling (s)   110.15601924061775
time/exploration sampling (s)  113.00679414439946
time/logging (s)               0.030536673963069916
time/saving (s)                0.011084009893238544
time/training (s)              9.66002822201699
time/epoch (s)                 232.89868068229407
time/total (s)                 44975.401224792935
Epoch                          191
-----------------------------  ---------------------
2023-08-01 06:27:35.287722 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 192 finished
-----------------------------  --------------------
replay_buffer/size             966000
trainer/tdrp Loss              [3525.1604]
trainer/QF1 Loss               0.17832623
trainer/QF2 Loss               0.1589644
trainer/Policy Loss            -75.44192
trainer/Q1 Predictions Mean    87.81991
trainer/Q1 Predictions Std     8.28834
trainer/Q1 Predictions Max     99.17567
trainer/Q1 Predictions Min     64.620155
trainer/Q2 Predictions Mean    87.86956
trainer/Q2 Predictions Std     8.302458
trainer/Q2 Predictions Max     99.15849
trainer/Q2 Predictions Min     64.871994
trainer/Q Targets Mean         87.93005
trainer/Q Targets Std          8.267254
trainer/Q Targets Max          99.54458
trainer/Q Targets Min          64.73325
trainer/Log Pis Mean           12.626944
trainer/Log Pis Std            7.6413426
trainer/Log Pis Max            35.84777
trainer/Log Pis Min            -2.5613136
trainer/Policy mu Mean         0.083776094
trainer/Policy mu Std          1.6255295
trainer/Policy mu Max          4.845846
trainer/Policy mu Min          -5.2646217
trainer/Policy log std Mean    -0.655072
trainer/Policy log std Std     0.21174929
trainer/Policy log std Max     -0.008306026
trainer/Policy log std Min     -1.5592364
trainer/Alpha                  0.003463083179667592
trainer/Alpha Loss             3.5520002841949463
exploration/num steps total    966000
exploration/num paths total    1932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9410304931144056
exploration/Rewards Std        0.08558908135401169
exploration/Rewards Max        0.9798668026097741
exploration/Rewards Min        0.49132155477862827
exploration/Returns Mean       470.5152465572028
exploration/Returns Std        1.5604739669988383
exploration/Returns Max        472.810640817291
exploration/Returns Min        468.2130698048799
exploration/Actions Mean       0.05317637
exploration/Actions Std        0.6612378
exploration/Actions Max        0.9998814
exploration/Actions Min        -0.9995777
exploration/Num Paths          10
exploration/Average Returns    470.5152465572028
evaluation/num steps total     965000
evaluation/num paths total     1930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8385017195351393
evaluation/Rewards Std         0.1442107545263974
evaluation/Rewards Max         0.9798191609437957
evaluation/Rewards Min         0.49588227531097817
evaluation/Returns Mean        419.25085976756964
evaluation/Returns Std         63.83816235293628
evaluation/Returns Max         473.0622218942649
evaluation/Returns Min         335.49169989572243
evaluation/ExplReturns Mean    419.25085976756964
evaluation/ExplReturns Std     63.83816235293628
evaluation/ExplReturns Max     473.0622218942649
evaluation/ExplReturns Min     335.49169989572243
evaluation/Actions Mean        0.051627945
evaluation/Actions Std         0.63843995
evaluation/Actions Max         0.997389
evaluation/Actions Min         -0.9991121
evaluation/Num Paths           10
evaluation/Average Returns     419.25085976756964
time/data storing (s)          0.03404644690454006
time/evaluation sampling (s)   111.03888612799346
time/exploration sampling (s)  110.73919746745378
time/logging (s)               0.030487002804875374
time/saving (s)                0.010314319282770157
time/training (s)              9.73266758210957
time/epoch (s)                 231.585598946549
time/total (s)                 45206.989288052544
Epoch                          192
-----------------------------  --------------------
2023-08-01 06:31:34.150346 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 193 finished
-----------------------------  ---------------------
replay_buffer/size             971000
trainer/tdrp Loss              [3256.8503]
trainer/QF1 Loss               0.20527579
trainer/QF2 Loss               0.17247948
trainer/Policy Loss            -77.10932
trainer/Q1 Predictions Mean    89.26808
trainer/Q1 Predictions Std     8.827298
trainer/Q1 Predictions Max     99.805756
trainer/Q1 Predictions Min     59.594368
trainer/Q2 Predictions Mean    89.10884
trainer/Q2 Predictions Std     8.810487
trainer/Q2 Predictions Max     99.515755
trainer/Q2 Predictions Min     59.299507
trainer/Q Targets Mean         89.03934
trainer/Q Targets Std          8.798955
trainer/Q Targets Max          99.08061
trainer/Q Targets Min          59.22812
trainer/Log Pis Mean           12.232601
trainer/Log Pis Std            7.673645
trainer/Log Pis Max            33.95686
trainer/Log Pis Min            -8.452554
trainer/Policy mu Mean         0.06494438
trainer/Policy mu Std          1.609848
trainer/Policy mu Max          5.676955
trainer/Policy mu Min          -6.3110113
trainer/Policy log std Mean    -0.67272264
trainer/Policy log std Std     0.21408883
trainer/Policy log std Max     0.34819096
trainer/Policy log std Min     -1.5101793
trainer/Alpha                  0.0033057371620088816
trainer/Alpha Loss             1.3286335468292236
exploration/num steps total    971000
exploration/num paths total    1942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8663860052767948
exploration/Rewards Std        0.13135160803627113
exploration/Rewards Max        0.9792105449120069
exploration/Rewards Min        0.49597670859029813
exploration/Returns Mean       433.1930026383975
exploration/Returns Std        55.989057294889236
exploration/Returns Max        474.3852555100133
exploration/Returns Min        347.31834717467603
exploration/Actions Mean       0.02765277
exploration/Actions Std        0.6414996
exploration/Actions Max        0.9999916
exploration/Actions Min        -0.9996948
exploration/Num Paths          10
exploration/Average Returns    433.1930026383975
evaluation/num steps total     970000
evaluation/num paths total     1940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7484937462519685
evaluation/Rewards Std         0.10479058982847024
evaluation/Rewards Max         0.9791010468470378
evaluation/Rewards Min         0.4995767033733322
evaluation/Returns Mean        374.2468731259843
evaluation/Returns Std         48.72429016114503
evaluation/Returns Max         472.22504495632177
evaluation/Returns Min         342.8897611269903
evaluation/ExplReturns Mean    374.2468731259843
evaluation/ExplReturns Std     48.72429016114503
evaluation/ExplReturns Max     472.22504495632177
evaluation/ExplReturns Min     342.8897611269903
evaluation/Actions Mean        0.033859503
evaluation/Actions Std         0.5963487
evaluation/Actions Max         0.9998735
evaluation/Actions Min         -0.99852437
evaluation/Num Paths           10
evaluation/Average Returns     374.2468731259843
time/data storing (s)          0.034098717384040356
time/evaluation sampling (s)   116.15198448114097
time/exploration sampling (s)  113.03088832646608
time/logging (s)               0.030466238968074322
time/saving (s)                0.010716422460973263
time/training (s)              9.59999062679708
time/epoch (s)                 238.85814481321722
time/total (s)                 45445.84996056184
Epoch                          193
-----------------------------  ---------------------
2023-08-01 06:35:28.195842 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 194 finished
-----------------------------  --------------------
replay_buffer/size             976000
trainer/tdrp Loss              [3581.6184]
trainer/QF1 Loss               0.16000675
trainer/QF2 Loss               0.1803224
trainer/Policy Loss            -76.091125
trainer/Q1 Predictions Mean    88.697495
trainer/Q1 Predictions Std     8.508201
trainer/Q1 Predictions Max     99.33281
trainer/Q1 Predictions Min     62.34199
trainer/Q2 Predictions Mean    88.7058
trainer/Q2 Predictions Std     8.500908
trainer/Q2 Predictions Max     99.40864
trainer/Q2 Predictions Min     62.75387
trainer/Q Targets Mean         88.56561
trainer/Q Targets Std          8.513015
trainer/Q Targets Max          100.19108
trainer/Q Targets Min          62.25573
trainer/Log Pis Mean           12.836073
trainer/Log Pis Std            7.3703303
trainer/Log Pis Max            31.810444
trainer/Log Pis Min            -4.40114
trainer/Policy mu Mean         0.056864817
trainer/Policy mu Std          1.6293782
trainer/Policy mu Max          4.4320607
trainer/Policy mu Min          -4.6834197
trainer/Policy log std Mean    -0.66344565
trainer/Policy log std Std     0.21008362
trainer/Policy log std Max     0.12348479
trainer/Policy log std Min     -1.4754857
trainer/Alpha                  0.003372273175045848
trainer/Alpha Loss             4.759323596954346
exploration/num steps total    976000
exploration/num paths total    1952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.870856012125798
exploration/Rewards Std        0.1256572104017028
exploration/Rewards Max        0.9795594415386427
exploration/Rewards Min        0.5012221831694106
exploration/Returns Mean       435.42800606289904
exploration/Returns Std        39.65829370961248
exploration/Returns Max        474.32116887086033
exploration/Returns Min        353.2257019324472
exploration/Actions Mean       -0.0021985464
exploration/Actions Std        0.64889205
exploration/Actions Max        0.99965787
exploration/Actions Min        -0.9999377
exploration/Num Paths          10
exploration/Average Returns    435.42800606289904
evaluation/num steps total     975000
evaluation/num paths total     1950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.807360260464251
evaluation/Rewards Std         0.11523981042717031
evaluation/Rewards Max         0.9794268938138437
evaluation/Rewards Min         0.49799389875555333
evaluation/Returns Mean        403.6801302321254
evaluation/Returns Std         40.829674611791106
evaluation/Returns Max         468.94799377031563
evaluation/Returns Min         364.36991296504794
evaluation/ExplReturns Mean    403.6801302321254
evaluation/ExplReturns Std     40.829674611791106
evaluation/ExplReturns Max     468.94799377031563
evaluation/ExplReturns Min     364.36991296504794
evaluation/Actions Mean        -0.049474537
evaluation/Actions Std         0.5818251
evaluation/Actions Max         0.9954182
evaluation/Actions Min         -0.9979004
evaluation/Num Paths           10
evaluation/Average Returns     403.6801302321254
time/data storing (s)          0.03435514681041241
time/evaluation sampling (s)   112.05186368338764
time/exploration sampling (s)  112.25676119793206
time/logging (s)               0.03050509002059698
time/saving (s)                0.011562246829271317
time/training (s)              9.656053845770657
time/epoch (s)                 234.04110121075064
time/total (s)                 45679.89351876918
Epoch                          194
-----------------------------  --------------------
2023-08-01 06:39:21.322549 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 195 finished
-----------------------------  ---------------------
replay_buffer/size             981000
trainer/tdrp Loss              [3391.1746]
trainer/QF1 Loss               0.2000185
trainer/QF2 Loss               0.19492842
trainer/Policy Loss            -75.723816
trainer/Q1 Predictions Mean    88.60924
trainer/Q1 Predictions Std     8.964945
trainer/Q1 Predictions Max     99.684654
trainer/Q1 Predictions Min     48.47721
trainer/Q2 Predictions Mean    88.7462
trainer/Q2 Predictions Std     8.9799795
trainer/Q2 Predictions Max     99.743576
trainer/Q2 Predictions Min     48.92295
trainer/Q Targets Mean         88.69629
trainer/Q Targets Std          8.9626465
trainer/Q Targets Max          99.738686
trainer/Q Targets Min          47.946457
trainer/Log Pis Mean           13.122066
trainer/Log Pis Std            7.741105
trainer/Log Pis Max            35.912586
trainer/Log Pis Min            -2.097925
trainer/Policy mu Mean         -0.12381295
trainer/Policy mu Std          1.6530136
trainer/Policy mu Max          4.5854588
trainer/Policy mu Min          -5.552725
trainer/Policy log std Mean    -0.6478019
trainer/Policy log std Std     0.21298274
trainer/Policy log std Max     0.2364136
trainer/Policy log std Min     -1.4358323
trainer/Alpha                  0.0033280823845416307
trainer/Alpha Loss             6.401934623718262
exploration/num steps total    981000
exploration/num paths total    1962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9151711964458944
exploration/Rewards Std        0.10890740997190246
exploration/Rewards Max        0.9795292814054144
exploration/Rewards Min        0.4917073374066201
exploration/Returns Mean       457.58559822294717
exploration/Returns Std        36.98534062619833
exploration/Returns Max        472.93674340905477
exploration/Returns Min        346.71868109969
exploration/Actions Mean       0.041886024
exploration/Actions Std        0.66281486
exploration/Actions Max        0.9991927
exploration/Actions Min        -0.99995136
exploration/Num Paths          10
exploration/Average Returns    457.58559822294717
evaluation/num steps total     980000
evaluation/num paths total     1960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7957228779165627
evaluation/Rewards Std         0.13141529824532905
evaluation/Rewards Max         0.9791852044078239
evaluation/Rewards Min         0.49146222505228576
evaluation/Returns Mean        397.86143895828144
evaluation/Returns Std         60.661169613150484
evaluation/Returns Max         472.86062173937734
evaluation/Returns Min         344.25559798445846
evaluation/ExplReturns Mean    397.86143895828144
evaluation/ExplReturns Std     60.661169613150484
evaluation/ExplReturns Max     472.86062173937734
evaluation/ExplReturns Min     344.25559798445846
evaluation/Actions Mean        0.043802388
evaluation/Actions Std         0.6271743
evaluation/Actions Max         0.9962747
evaluation/Actions Min         -0.99924487
evaluation/Num Paths           10
evaluation/Average Returns     397.86143895828144
time/data storing (s)          0.03434065543115139
time/evaluation sampling (s)   111.59205149114132
time/exploration sampling (s)  111.7028325414285
time/logging (s)               0.030396067537367344
time/saving (s)                0.012773248367011547
time/training (s)              9.749613520689309
time/epoch (s)                 233.12200752459466
time/total (s)                 45913.01816686429
Epoch                          195
-----------------------------  ---------------------
2023-08-01 06:43:14.144360 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 196 finished
-----------------------------  --------------------
replay_buffer/size             986000
trainer/tdrp Loss              [3945.9197]
trainer/QF1 Loss               0.16231637
trainer/QF2 Loss               0.14374807
trainer/Policy Loss            -78.29521
trainer/Q1 Predictions Mean    89.5818
trainer/Q1 Predictions Std     8.662158
trainer/Q1 Predictions Max     99.71802
trainer/Q1 Predictions Min     56.679768
trainer/Q2 Predictions Mean    89.592514
trainer/Q2 Predictions Std     8.677946
trainer/Q2 Predictions Max     99.86622
trainer/Q2 Predictions Min     56.42229
trainer/Q Targets Mean         89.64708
trainer/Q Targets Std          8.705811
trainer/Q Targets Max          100.01693
trainer/Q Targets Min          56.003742
trainer/Log Pis Mean           11.506742
trainer/Log Pis Std            7.8599772
trainer/Log Pis Max            34.769947
trainer/Log Pis Min            -7.2247376
trainer/Policy mu Mean         -0.10519379
trainer/Policy mu Std          1.5817349
trainer/Policy mu Max          4.5066376
trainer/Policy mu Min          -4.1384397
trainer/Policy log std Mean    -0.68756485
trainer/Policy log std Std     0.22592124
trainer/Policy log std Max     0.0201708
trainer/Policy log std Min     -1.5825198
trainer/Alpha                  0.003206436289474368
trainer/Alpha Loss             -2.8325624465942383
exploration/num steps total    986000
exploration/num paths total    1972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9223164348324486
exploration/Rewards Std        0.10650247085558989
exploration/Rewards Max        0.9796084040167155
exploration/Rewards Min        0.499581694625811
exploration/Returns Mean       461.1582174162242
exploration/Returns Std        37.21428301972109
exploration/Returns Max        475.7219965978583
exploration/Returns Min        349.7110548759909
exploration/Actions Mean       0.030866338
exploration/Actions Std        0.64708465
exploration/Actions Max        0.9998782
exploration/Actions Min        -0.99998736
exploration/Num Paths          10
exploration/Average Returns    461.1582174162242
evaluation/num steps total     985000
evaluation/num paths total     1970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9472823155393553
evaluation/Rewards Std         0.07907743458536477
evaluation/Rewards Max         0.9788017002216916
evaluation/Rewards Min         0.5024997129761589
evaluation/Returns Mean        473.64115776967765
evaluation/Returns Std         0.3979218037170315
evaluation/Returns Max         474.28284645003794
evaluation/Returns Min         472.8583331452216
evaluation/ExplReturns Mean    473.64115776967765
evaluation/ExplReturns Std     0.3979218037170315
evaluation/ExplReturns Max     474.28284645003794
evaluation/ExplReturns Min     472.8583331452216
evaluation/Actions Mean        0.042484015
evaluation/Actions Std         0.6132846
evaluation/Actions Max         0.9963796
evaluation/Actions Min         -0.9980856
evaluation/Num Paths           10
evaluation/Average Returns     473.64115776967765
time/data storing (s)          0.03395984787493944
time/evaluation sampling (s)   110.84758765809238
time/exploration sampling (s)  112.39512616675347
time/logging (s)               0.03101416304707527
time/saving (s)                0.010462013073265553
time/training (s)              9.499778991565108
time/epoch (s)                 232.81792884040624
time/total (s)                 46145.838561939076
Epoch                          196
-----------------------------  --------------------
2023-08-01 06:47:09.795271 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 197 finished
-----------------------------  ---------------------
replay_buffer/size             991000
trainer/tdrp Loss              [3473.5042]
trainer/QF1 Loss               0.15064026
trainer/QF2 Loss               0.14371467
trainer/Policy Loss            -77.99735
trainer/Q1 Predictions Mean    89.3434
trainer/Q1 Predictions Std     8.639393
trainer/Q1 Predictions Max     99.940155
trainer/Q1 Predictions Min     55.47447
trainer/Q2 Predictions Mean    89.32124
trainer/Q2 Predictions Std     8.648524
trainer/Q2 Predictions Max     99.84277
trainer/Q2 Predictions Min     55.146866
trainer/Q Targets Mean         89.24223
trainer/Q Targets Std          8.635705
trainer/Q Targets Max          100.15641
trainer/Q Targets Min          55.25527
trainer/Log Pis Mean           11.494115
trainer/Log Pis Std            7.1357017
trainer/Log Pis Max            35.6815
trainer/Log Pis Min            -2.1973138
trainer/Policy mu Mean         -0.038985122
trainer/Policy mu Std          1.5872803
trainer/Policy mu Max          4.692071
trainer/Policy mu Min          -4.8142185
trainer/Policy log std Mean    -0.67126226
trainer/Policy log std Std     0.21978146
trainer/Policy log std Max     0.025918573
trainer/Policy log std Min     -1.480592
trainer/Alpha                  0.0032472009770572186
trainer/Alpha Loss             -2.898603677749634
exploration/num steps total    991000
exploration/num paths total    1982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9259780075431476
exploration/Rewards Std        0.0979157971523214
exploration/Rewards Max        0.9790282282243439
exploration/Rewards Min        0.4962876291895496
exploration/Returns Mean       462.9890037715737
exploration/Returns Std        9.826818970482547
exploration/Returns Max        473.32264474437693
exploration/Returns Min        446.4676204491026
exploration/Actions Mean       0.0050900304
exploration/Actions Std        0.63149947
exploration/Actions Max        0.99889565
exploration/Actions Min        -0.9993321
exploration/Num Paths          10
exploration/Average Returns    462.9890037715737
evaluation/num steps total     990000
evaluation/num paths total     1980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.893567952442067
evaluation/Rewards Std         0.08833731028165502
evaluation/Rewards Max         0.9781914847764034
evaluation/Rewards Min         0.49631466050255385
evaluation/Returns Mean        446.7839762210336
evaluation/Returns Std         10.63256319554184
evaluation/Returns Max         474.8203453581984
evaluation/Returns Min         432.85348091887033
evaluation/ExplReturns Mean    446.7839762210336
evaluation/ExplReturns Std     10.63256319554184
evaluation/ExplReturns Max     474.8203453581984
evaluation/ExplReturns Min     432.85348091887033
evaluation/Actions Mean        -0.102359585
evaluation/Actions Std         0.5287956
evaluation/Actions Max         0.98960626
evaluation/Actions Min         -0.9960957
evaluation/Num Paths           10
evaluation/Average Returns     446.7839762210336
time/data storing (s)          0.03412050008773804
time/evaluation sampling (s)   113.75178933609277
time/exploration sampling (s)  112.43976972158998
time/logging (s)               0.030841397121548653
time/saving (s)                0.01030243281275034
time/training (s)              9.379427487030625
time/epoch (s)                 235.64625087473541
time/total (s)                 46381.48729539476
Epoch                          197
-----------------------------  ---------------------
2023-08-01 06:51:01.660751 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 198 finished
-----------------------------  ---------------------
replay_buffer/size             996000
trainer/tdrp Loss              [3742.3003]
trainer/QF1 Loss               0.15407437
trainer/QF2 Loss               0.14510442
trainer/Policy Loss            -78.94745
trainer/Q1 Predictions Mean    89.99824
trainer/Q1 Predictions Std     8.660445
trainer/Q1 Predictions Max     99.55446
trainer/Q1 Predictions Min     64.5533
trainer/Q2 Predictions Mean    89.96655
trainer/Q2 Predictions Std     8.67891
trainer/Q2 Predictions Max     99.48172
trainer/Q2 Predictions Min     64.03354
trainer/Q Targets Mean         89.85331
trainer/Q Targets Std          8.664016
trainer/Q Targets Max          99.48753
trainer/Q Targets Min          63.740147
trainer/Log Pis Mean           11.241454
trainer/Log Pis Std            7.6933775
trainer/Log Pis Max            31.137352
trainer/Log Pis Min            -9.17118
trainer/Policy mu Mean         0.015613805
trainer/Policy mu Std          1.5784082
trainer/Policy mu Max          5.4571185
trainer/Policy mu Min          -4.1611238
trainer/Policy log std Mean    -0.67382234
trainer/Policy log std Std     0.21732967
trainer/Policy log std Max     0.11195545
trainer/Policy log std Min     -1.4964356
trainer/Alpha                  0.0032243903260678053
trainer/Alpha Loss             -4.351644039154053
exploration/num steps total    996000
exploration/num paths total    1992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9377857455631758
exploration/Rewards Std        0.08337817769618874
exploration/Rewards Max        0.9797075313861362
exploration/Rewards Min        0.4897992220726187
exploration/Returns Mean       468.8928727815877
exploration/Returns Std        6.474825214494934
exploration/Returns Max        475.8001449959016
exploration/Returns Min        454.1969657881227
exploration/Actions Mean       0.0081434855
exploration/Actions Std        0.6319208
exploration/Actions Max        0.9994137
exploration/Actions Min        -0.9997786
exploration/Num Paths          10
exploration/Average Returns    468.8928727815877
evaluation/num steps total     995000
evaluation/num paths total     1990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9533678251238898
evaluation/Rewards Std         0.06512132514909952
evaluation/Rewards Max         0.9775990496046707
evaluation/Rewards Min         0.49217920545725696
evaluation/Returns Mean        476.6839125619449
evaluation/Returns Std         2.8835091302911384
evaluation/Returns Max         479.0775782544532
evaluation/Returns Min         470.46834939834275
evaluation/ExplReturns Mean    476.6839125619449
evaluation/ExplReturns Std     2.8835091302911384
evaluation/ExplReturns Max     479.0775782544532
evaluation/ExplReturns Min     470.46834939834275
evaluation/Actions Mean        0.027128248
evaluation/Actions Std         0.5701537
evaluation/Actions Max         0.99353194
evaluation/Actions Min         -0.99654657
evaluation/Num Paths           10
evaluation/Average Returns     476.6839125619449
time/data storing (s)          0.03431284986436367
time/evaluation sampling (s)   110.35916936397552
time/exploration sampling (s)  112.07149491552263
time/logging (s)               0.030930688604712486
time/saving (s)                0.011338966898620129
time/training (s)              9.35376169718802
time/epoch (s)                 231.86100848205388
time/total (s)                 46613.35080227535
Epoch                          198
-----------------------------  ---------------------
2023-08-01 06:54:51.952831 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 199 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3421.3706]
trainer/QF1 Loss               0.1330299
trainer/QF2 Loss               0.15585181
trainer/Policy Loss            -77.712814
trainer/Q1 Predictions Mean    89.19988
trainer/Q1 Predictions Std     8.7784
trainer/Q1 Predictions Max     99.88968
trainer/Q1 Predictions Min     57.724564
trainer/Q2 Predictions Mean    89.145
trainer/Q2 Predictions Std     8.779421
trainer/Q2 Predictions Max     99.90597
trainer/Q2 Predictions Min     57.573357
trainer/Q Targets Mean         89.21448
trainer/Q Targets Std          8.739031
trainer/Q Targets Max          99.9777
trainer/Q Targets Min          57.49485
trainer/Log Pis Mean           11.644743
trainer/Log Pis Std            7.211328
trainer/Log Pis Max            34.35108
trainer/Log Pis Min            -4.1786976
trainer/Policy mu Mean         -0.06446172
trainer/Policy mu Std          1.5683529
trainer/Policy mu Max          4.2045317
trainer/Policy mu Min          -5.004389
trainer/Policy log std Mean    -0.6832265
trainer/Policy log std Std     0.21890844
trainer/Policy log std Max     0.04524499
trainer/Policy log std Min     -1.5091181
trainer/Alpha                  0.003268600208684802
trainer/Alpha Loss             -2.033275604248047
exploration/num steps total    1001000
exploration/num paths total    2002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9507498371441818
exploration/Rewards Std        0.07175347497279319
exploration/Rewards Max        0.9797340356201467
exploration/Rewards Min        0.47586377838902294
exploration/Returns Mean       475.37491857209096
exploration/Returns Std        1.6999310954947702
exploration/Returns Max        477.922983856265
exploration/Returns Min        472.9834352703867
exploration/Actions Mean       -0.0240129
exploration/Actions Std        0.58747995
exploration/Actions Max        0.9997986
exploration/Actions Min        -0.9998979
exploration/Num Paths          10
exploration/Average Returns    475.37491857209096
evaluation/num steps total     1000000
evaluation/num paths total     2000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9509942245915026
evaluation/Rewards Std         0.07065487841667231
evaluation/Rewards Max         0.9794856103403515
evaluation/Rewards Min         0.486776902756211
evaluation/Returns Mean        475.49711229575144
evaluation/Returns Std         0.9868333829715644
evaluation/Returns Max         477.30815253249636
evaluation/Returns Min         473.9860859681738
evaluation/ExplReturns Mean    475.49711229575144
evaluation/ExplReturns Std     0.9868333829715644
evaluation/ExplReturns Max     477.30815253249636
evaluation/ExplReturns Min     473.9860859681738
evaluation/Actions Mean        -0.021809448
evaluation/Actions Std         0.4951023
evaluation/Actions Max         0.9987734
evaluation/Actions Min         -0.99939454
evaluation/Num Paths           10
evaluation/Average Returns     475.49711229575144
time/data storing (s)          0.034047553315758705
time/evaluation sampling (s)   109.42684306483716
time/exploration sampling (s)  111.42998141981661
time/logging (s)               0.034150321036577225
time/saving (s)                0.011087460443377495
time/training (s)              9.354598549194634
time/epoch (s)                 230.29070836864412
time/total (s)                 46843.64406503178
Epoch                          199
-----------------------------  --------------------
2023-08-01 06:58:45.736456 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 200 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3883.3972]
trainer/QF1 Loss               0.13156235
trainer/QF2 Loss               0.13508198
trainer/Policy Loss            -77.77673
trainer/Q1 Predictions Mean    89.6945
trainer/Q1 Predictions Std     8.095546
trainer/Q1 Predictions Max     100.62075
trainer/Q1 Predictions Min     67.59484
trainer/Q2 Predictions Mean    89.66912
trainer/Q2 Predictions Std     8.101127
trainer/Q2 Predictions Max     100.59642
trainer/Q2 Predictions Min     68.27479
trainer/Q Targets Mean         89.68501
trainer/Q Targets Std          8.091724
trainer/Q Targets Max          100.41923
trainer/Q Targets Min          67.39337
trainer/Log Pis Mean           12.088554
trainer/Log Pis Std            7.963469
trainer/Log Pis Max            31.960201
trainer/Log Pis Min            -5.9376493
trainer/Policy mu Mean         -0.11544528
trainer/Policy mu Std          1.618807
trainer/Policy mu Max          4.547691
trainer/Policy mu Min          -4.410204
trainer/Policy log std Mean    -0.6693781
trainer/Policy log std Std     0.22908178
trainer/Policy log std Max     0.014542818
trainer/Policy log std Min     -1.4377
trainer/Alpha                  0.0032799476757645607
trainer/Alpha Loss             0.5065171718597412
exploration/num steps total    1006000
exploration/num paths total    2012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8789010582214789
exploration/Rewards Std        0.12408610628693247
exploration/Rewards Max        0.9796628151908755
exploration/Rewards Min        0.49356091865660673
exploration/Returns Mean       439.4505291107395
exploration/Returns Std        37.0156915277548
exploration/Returns Max        477.1206931386489
exploration/Returns Min        358.30513372514287
exploration/Actions Mean       -0.06771461
exploration/Actions Std        0.62667143
exploration/Actions Max        0.9997697
exploration/Actions Min        -0.9997156
exploration/Num Paths          10
exploration/Average Returns    439.4505291107395
evaluation/num steps total     1005000
evaluation/num paths total     2010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.853384197465377
evaluation/Rewards Std         0.13540439497915144
evaluation/Rewards Max         0.979355600915175
evaluation/Rewards Min         0.4973403543786168
evaluation/Returns Mean        426.69209873268846
evaluation/Returns Std         61.09164851524963
evaluation/Returns Max         479.30994372968945
evaluation/Returns Min         351.8284103835154
evaluation/ExplReturns Mean    426.69209873268846
evaluation/ExplReturns Std     61.09164851524963
evaluation/ExplReturns Max     479.30994372968945
evaluation/ExplReturns Min     351.8284103835154
evaluation/Actions Mean        -0.0786283
evaluation/Actions Std         0.53387916
evaluation/Actions Max         0.99802405
evaluation/Actions Min         -0.9974179
evaluation/Num Paths           10
evaluation/Average Returns     426.69209873268846
time/data storing (s)          0.0323713468387723
time/evaluation sampling (s)   112.55948246456683
time/exploration sampling (s)  111.41125743184239
time/logging (s)               0.03147258423268795
time/saving (s)                0.013029968366026878
time/training (s)              9.728773396462202
time/epoch (s)                 233.7763871923089
time/total (s)                 47077.42293526698
Epoch                          200
-----------------------------  ---------------------
2023-08-01 07:02:38.159214 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 201 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3466.3003]
trainer/QF1 Loss               0.17416935
trainer/QF2 Loss               0.15646352
trainer/Policy Loss            -76.537056
trainer/Q1 Predictions Mean    89.058365
trainer/Q1 Predictions Std     8.496539
trainer/Q1 Predictions Max     99.6576
trainer/Q1 Predictions Min     57.864002
trainer/Q2 Predictions Mean    89.02005
trainer/Q2 Predictions Std     8.459018
trainer/Q2 Predictions Max     99.41192
trainer/Q2 Predictions Min     57.405735
trainer/Q Targets Mean         88.99381
trainer/Q Targets Std          8.472132
trainer/Q Targets Max          99.409775
trainer/Q Targets Min          57.800385
trainer/Log Pis Mean           12.694574
trainer/Log Pis Std            7.0342345
trainer/Log Pis Max            36.746605
trainer/Log Pis Min            -2.8148472
trainer/Policy mu Mean         -0.16177417
trainer/Policy mu Std          1.6201184
trainer/Policy mu Max          5.643429
trainer/Policy mu Min          -6.3700147
trainer/Policy log std Mean    -0.6899166
trainer/Policy log std Std     0.2280384
trainer/Policy log std Max     0.1606629
trainer/Policy log std Min     -1.568876
trainer/Alpha                  0.003169888397678733
trainer/Alpha Loss             3.9967477321624756
exploration/num steps total    1011000
exploration/num paths total    2022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9510382252249299
exploration/Rewards Std        0.07162058212358063
exploration/Rewards Max        0.9785096539526604
exploration/Rewards Min        0.4777567605344126
exploration/Returns Mean       475.51911261246477
exploration/Returns Std        3.6866470605562656
exploration/Returns Max        479.3786968528713
exploration/Returns Min        468.0723917251478
exploration/Actions Mean       0.0006937576
exploration/Actions Std        0.61497784
exploration/Actions Max        0.9995137
exploration/Actions Min        -0.99987894
exploration/Num Paths          10
exploration/Average Returns    475.51911261246477
evaluation/num steps total     1010000
evaluation/num paths total     2020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9484174016795
evaluation/Rewards Std         0.07599944376243767
evaluation/Rewards Max         0.9783627635782919
evaluation/Rewards Min         0.49405339942537546
evaluation/Returns Mean        474.20870083974995
evaluation/Returns Std         0.7933710212561453
evaluation/Returns Max         475.6382255959522
evaluation/Returns Min         472.97195723154294
evaluation/ExplReturns Mean    474.20870083974995
evaluation/ExplReturns Std     0.7933710212561453
evaluation/ExplReturns Max     475.6382255959522
evaluation/ExplReturns Min     472.97195723154294
evaluation/Actions Mean        0.0001367521
evaluation/Actions Std         0.5628812
evaluation/Actions Max         0.9956962
evaluation/Actions Min         -0.999584
evaluation/Num Paths           10
evaluation/Average Returns     474.20870083974995
time/data storing (s)          0.032307395711541176
time/evaluation sampling (s)   110.53605484869331
time/exploration sampling (s)  112.12563407886773
time/logging (s)               0.030589282512664795
time/saving (s)                0.010325617156922817
time/training (s)              9.682443203404546
time/epoch (s)                 232.41735442634672
time/total (s)                 47309.84278536774
Epoch                          201
-----------------------------  --------------------
2023-08-01 07:06:27.729813 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 202 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3335.25]
trainer/QF1 Loss               0.13347106
trainer/QF2 Loss               0.15491587
trainer/Policy Loss            -76.19159
trainer/Q1 Predictions Mean    89.24465
trainer/Q1 Predictions Std     9.045506
trainer/Q1 Predictions Max     100.494316
trainer/Q1 Predictions Min     56.18706
trainer/Q2 Predictions Mean    89.20535
trainer/Q2 Predictions Std     9.079599
trainer/Q2 Predictions Max     100.3359
trainer/Q2 Predictions Min     56.634045
trainer/Q Targets Mean         89.20662
trainer/Q Targets Std          9.017939
trainer/Q Targets Max          100.593475
trainer/Q Targets Min          56.755573
trainer/Log Pis Mean           13.23408
trainer/Log Pis Std            7.934694
trainer/Log Pis Max            40.672653
trainer/Log Pis Min            -4.0665903
trainer/Policy mu Mean         -0.119866215
trainer/Policy mu Std          1.672885
trainer/Policy mu Max          4.696724
trainer/Policy mu Min          -4.863461
trainer/Policy log std Mean    -0.6625131
trainer/Policy log std Std     0.22043297
trainer/Policy log std Max     0.10665792
trainer/Policy log std Min     -1.5684189
trainer/Alpha                  0.003135901177302003
trainer/Alpha Loss             7.114576816558838
exploration/num steps total    1016000
exploration/num paths total    2032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9064074328076995
exploration/Rewards Std        0.11287699171892017
exploration/Rewards Max        0.9789720308266455
exploration/Rewards Min        0.48779993878226424
exploration/Returns Mean       453.20371640384974
exploration/Returns Std        33.464840124873575
exploration/Returns Max        471.3576064849292
exploration/Returns Min        368.0065133906571
exploration/Actions Mean       -0.014097312
exploration/Actions Std        0.617824
exploration/Actions Max        0.9997836
exploration/Actions Min        -0.9998792
exploration/Num Paths          10
exploration/Average Returns    453.20371640384974
evaluation/num steps total     1015000
evaluation/num paths total     2030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9488083534015262
evaluation/Rewards Std         0.07144586656597122
evaluation/Rewards Max         0.9764712968348704
evaluation/Rewards Min         0.4978665133491939
evaluation/Returns Mean        474.4041767007631
evaluation/Returns Std         1.724963369567289
evaluation/Returns Max         476.83174224400165
evaluation/Returns Min         471.51331054050394
evaluation/ExplReturns Mean    474.4041767007631
evaluation/ExplReturns Std     1.724963369567289
evaluation/ExplReturns Max     476.83174224400165
evaluation/ExplReturns Min     471.51331054050394
evaluation/Actions Mean        -0.03056317
evaluation/Actions Std         0.56691813
evaluation/Actions Max         0.9981819
evaluation/Actions Min         -0.99815255
evaluation/Num Paths           10
evaluation/Average Returns     474.4041767007631
time/data storing (s)          0.0323227234184742
time/evaluation sampling (s)   109.76957506686449
time/exploration sampling (s)  110.54421968013048
time/logging (s)               0.03050217591226101
time/saving (s)                0.012784851714968681
time/training (s)              9.176513052545488
time/epoch (s)                 229.56591755058616
time/total (s)                 47539.41123396903
Epoch                          202
-----------------------------  --------------------
2023-08-01 07:10:17.962508 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 203 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3393.8394]
trainer/QF1 Loss               0.13046324
trainer/QF2 Loss               0.13092658
trainer/Policy Loss            -77.909485
trainer/Q1 Predictions Mean    90.237076
trainer/Q1 Predictions Std     8.07165
trainer/Q1 Predictions Max     101.15532
trainer/Q1 Predictions Min     62.64402
trainer/Q2 Predictions Mean    90.21869
trainer/Q2 Predictions Std     8.060415
trainer/Q2 Predictions Max     101.05378
trainer/Q2 Predictions Min     62.71734
trainer/Q Targets Mean         90.16511
trainer/Q Targets Std          8.069985
trainer/Q Targets Max          100.58435
trainer/Q Targets Min          63.453407
trainer/Log Pis Mean           12.53195
trainer/Log Pis Std            7.0417128
trainer/Log Pis Max            32.822117
trainer/Log Pis Min            -3.95135
trainer/Policy mu Mean         -0.08400392
trainer/Policy mu Std          1.6200979
trainer/Policy mu Max          4.2562785
trainer/Policy mu Min          -6.4077015
trainer/Policy log std Mean    -0.6494294
trainer/Policy log std Std     0.2266399
trainer/Policy log std Max     0.5733957
trainer/Policy log std Min     -1.4980401
trainer/Alpha                  0.003159745829179883
trainer/Alpha Loss             3.062493324279785
exploration/num steps total    1021000
exploration/num paths total    2042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9322951418885743
exploration/Rewards Std        0.09393398700602872
exploration/Rewards Max        0.9790587237144325
exploration/Rewards Min        0.5002197821660873
exploration/Returns Mean       466.14757094428705
exploration/Returns Std        7.9993075465382
exploration/Returns Max        475.9261492262332
exploration/Returns Min        450.58333212779206
exploration/Actions Mean       -0.016571743
exploration/Actions Std        0.6163056
exploration/Actions Max        0.99974686
exploration/Actions Min        -0.9999987
exploration/Num Paths          10
exploration/Average Returns    466.14757094428705
evaluation/num steps total     1020000
evaluation/num paths total     2040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9375271678473961
evaluation/Rewards Std         0.08570880919566773
evaluation/Rewards Max         0.978902494199081
evaluation/Rewards Min         0.4966402255289893
evaluation/Returns Mean        468.76358392369804
evaluation/Returns Std         7.889656342932903
evaluation/Returns Max         476.37166501982125
evaluation/Returns Min         452.19084210252817
evaluation/ExplReturns Mean    468.76358392369804
evaluation/ExplReturns Std     7.889656342932903
evaluation/ExplReturns Max     476.37166501982125
evaluation/ExplReturns Min     452.19084210252817
evaluation/Actions Mean        -0.013409897
evaluation/Actions Std         0.5409895
evaluation/Actions Max         0.9987149
evaluation/Actions Min         -0.99982363
evaluation/Num Paths           10
evaluation/Average Returns     468.76358392369804
time/data storing (s)          0.031969317235052586
time/evaluation sampling (s)   109.99298437219113
time/exploration sampling (s)  110.5280252667144
time/logging (s)               0.030570944771170616
time/saving (s)                0.010776772163808346
time/training (s)              9.634044625796378
time/epoch (s)                 230.22837129887193
time/total (s)                 47769.642014499754
Epoch                          203
-----------------------------  --------------------
2023-08-01 07:14:08.912389 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 204 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3686.9062]
trainer/QF1 Loss               0.1844826
trainer/QF2 Loss               0.19315034
trainer/Policy Loss            -77.8949
trainer/Q1 Predictions Mean    90.0078
trainer/Q1 Predictions Std     7.9682293
trainer/Q1 Predictions Max     100.094986
trainer/Q1 Predictions Min     62.862896
trainer/Q2 Predictions Mean    89.9585
trainer/Q2 Predictions Std     7.920665
trainer/Q2 Predictions Max     100.01264
trainer/Q2 Predictions Min     63.115356
trainer/Q Targets Mean         90.15109
trainer/Q Targets Std          7.9161143
trainer/Q Targets Max          100.50658
trainer/Q Targets Min          62.64742
trainer/Log Pis Mean           12.258187
trainer/Log Pis Std            8.103592
trainer/Log Pis Max            42.441456
trainer/Log Pis Min            -11.075398
trainer/Policy mu Mean         0.08578062
trainer/Policy mu Std          1.6327503
trainer/Policy mu Max          4.8465424
trainer/Policy mu Min          -4.8040013
trainer/Policy log std Mean    -0.66790706
trainer/Policy log std Std     0.2185918
trainer/Policy log std Max     -0.05714807
trainer/Policy log std Min     -1.4947453
trainer/Alpha                  0.0031360238790512085
trainer/Alpha Loss             1.4884014129638672
exploration/num steps total    1026000
exploration/num paths total    2052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8956057834077974
exploration/Rewards Std        0.11640537141578904
exploration/Rewards Max        0.9789392844432572
exploration/Rewards Min        0.4964988252205402
exploration/Returns Mean       447.8028917038987
exploration/Returns Std        33.776762481352854
exploration/Returns Max        468.72626980519766
exploration/Returns Min        363.3706877691909
exploration/Actions Mean       0.032098245
exploration/Actions Std        0.6472611
exploration/Actions Max        0.9996957
exploration/Actions Min        -0.999952
exploration/Num Paths          10
exploration/Average Returns    447.8028917038987
evaluation/num steps total     1025000
evaluation/num paths total     2050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.884125101142251
evaluation/Rewards Std         0.11883594373516944
evaluation/Rewards Max         0.9784616322168121
evaluation/Rewards Min         0.4893613355413511
evaluation/Returns Mean        442.06255057112566
evaluation/Returns Std         40.1660320681599
evaluation/Returns Max         472.61145115882425
evaluation/Returns Min         349.65562961413207
evaluation/ExplReturns Mean    442.06255057112566
evaluation/ExplReturns Std     40.1660320681599
evaluation/ExplReturns Max     472.61145115882425
evaluation/ExplReturns Min     349.65562961413207
evaluation/Actions Mean        0.09198146
evaluation/Actions Std         0.5936964
evaluation/Actions Max         0.99617946
evaluation/Actions Min         -0.9986468
evaluation/Num Paths           10
evaluation/Average Returns     442.06255057112566
time/data storing (s)          0.031889268197119236
time/evaluation sampling (s)   110.26619127299637
time/exploration sampling (s)  110.94148193579167
time/logging (s)               0.031624989584088326
time/saving (s)                0.012434677220880985
time/training (s)              9.662814300507307
time/epoch (s)                 230.94643644429743
time/total (s)                 48000.59086044505
Epoch                          204
-----------------------------  ---------------------
2023-08-01 07:17:59.924576 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 205 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3488.9875]
trainer/QF1 Loss               0.19475868
trainer/QF2 Loss               0.15457597
trainer/Policy Loss            -77.065735
trainer/Q1 Predictions Mean    89.17261
trainer/Q1 Predictions Std     9.370565
trainer/Q1 Predictions Max     99.36584
trainer/Q1 Predictions Min     51.787514
trainer/Q2 Predictions Mean    89.26375
trainer/Q2 Predictions Std     9.36974
trainer/Q2 Predictions Max     99.45603
trainer/Q2 Predictions Min     51.856285
trainer/Q Targets Mean         89.39804
trainer/Q Targets Std          9.345312
trainer/Q Targets Max          99.559784
trainer/Q Targets Min          52.651733
trainer/Log Pis Mean           12.333892
trainer/Log Pis Std            8.629141
trainer/Log Pis Max            43.21091
trainer/Log Pis Min            -6.8994184
trainer/Policy mu Mean         0.037564997
trainer/Policy mu Std          1.6355145
trainer/Policy mu Max          5.4557037
trainer/Policy mu Min          -6.076597
trainer/Policy log std Mean    -0.67016345
trainer/Policy log std Std     0.22895055
trainer/Policy log std Max     0.021908522
trainer/Policy log std Min     -1.5056331
trainer/Alpha                  0.0030061814468353987
trainer/Alpha Loss             1.9388806819915771
exploration/num steps total    1031000
exploration/num paths total    2062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9340958347598242
exploration/Rewards Std        0.08659507203274155
exploration/Rewards Max        0.9786064737169133
exploration/Rewards Min        0.5003996960982662
exploration/Returns Mean       467.047917379912
exploration/Returns Std        24.36407132282498
exploration/Returns Max        478.49978516379593
exploration/Returns Min        394.3284407839311
exploration/Actions Mean       0.038478024
exploration/Actions Std        0.62967944
exploration/Actions Max        0.9998764
exploration/Actions Min        -0.9999702
exploration/Num Paths          10
exploration/Average Returns    467.047917379912
evaluation/num steps total     1030000
evaluation/num paths total     2060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9471249950855768
evaluation/Rewards Std         0.07857418387137466
evaluation/Rewards Max         0.9782544219735837
evaluation/Rewards Min         0.4906704881189664
evaluation/Returns Mean        473.5624975427883
evaluation/Returns Std         4.243717624176493
evaluation/Returns Max         477.3569156744981
evaluation/Returns Min         466.1858377702807
evaluation/ExplReturns Mean    473.5624975427883
evaluation/ExplReturns Std     4.243717624176493
evaluation/ExplReturns Max     477.3569156744981
evaluation/ExplReturns Min     466.1858377702807
evaluation/Actions Mean        0.038769674
evaluation/Actions Std         0.5866506
evaluation/Actions Max         0.99898076
evaluation/Actions Min         -0.99940586
evaluation/Num Paths           10
evaluation/Average Returns     473.5624975427883
time/data storing (s)          0.03226462472230196
time/evaluation sampling (s)   109.95586286764592
time/exploration sampling (s)  111.36562750954181
time/logging (s)               0.030364815145730972
time/saving (s)                0.010240420699119568
time/training (s)              9.612027546390891
time/epoch (s)                 231.00638778414577
time/total (s)                 48231.599739368074
Epoch                          205
-----------------------------  ---------------------
2023-08-01 07:21:50.444122 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 206 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3499.0842]
trainer/QF1 Loss               0.1331468
trainer/QF2 Loss               0.1190901
trainer/Policy Loss            -78.49154
trainer/Q1 Predictions Mean    90.09491
trainer/Q1 Predictions Std     8.824103
trainer/Q1 Predictions Max     100.00193
trainer/Q1 Predictions Min     56.352085
trainer/Q2 Predictions Mean    89.93219
trainer/Q2 Predictions Std     8.830232
trainer/Q2 Predictions Max     99.876366
trainer/Q2 Predictions Min     56.43328
trainer/Q Targets Mean         89.983185
trainer/Q Targets Std          8.815076
trainer/Q Targets Max          100.11489
trainer/Q Targets Min          55.75966
trainer/Log Pis Mean           11.680762
trainer/Log Pis Std            7.33581
trainer/Log Pis Max            36.069622
trainer/Log Pis Min            -6.6837077
trainer/Policy mu Mean         -0.12322166
trainer/Policy mu Std          1.5729873
trainer/Policy mu Max          4.4413505
trainer/Policy mu Min          -5.8224435
trainer/Policy log std Mean    -0.6883049
trainer/Policy log std Std     0.23318082
trainer/Policy log std Max     0.017983317
trainer/Policy log std Min     -1.6335689
trainer/Alpha                  0.0030965732876211405
trainer/Alpha Loss             -1.8443913459777832
exploration/num steps total    1036000
exploration/num paths total    2072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9136881064298512
exploration/Rewards Std        0.10339166185908982
exploration/Rewards Max        0.9785603329335388
exploration/Rewards Min        0.5030988444433458
exploration/Returns Mean       456.8440532149255
exploration/Returns Std        14.994895887822556
exploration/Returns Max        469.50851418664985
exploration/Returns Min        424.8650558727896
exploration/Actions Mean       0.017800393
exploration/Actions Std        0.6354494
exploration/Actions Max        0.9993569
exploration/Actions Min        -0.99989
exploration/Num Paths          10
exploration/Average Returns    456.8440532149255
evaluation/num steps total     1035000
evaluation/num paths total     2070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9434490687240042
evaluation/Rewards Std         0.06731080330948526
evaluation/Rewards Max         0.9763641347468769
evaluation/Rewards Min         0.502341397274858
evaluation/Returns Mean        471.72453436200203
evaluation/Returns Std         1.731498535492861
evaluation/Returns Max         473.48660411714735
evaluation/Returns Min         467.8204487580704
evaluation/ExplReturns Mean    471.72453436200203
evaluation/ExplReturns Std     1.731498535492861
evaluation/ExplReturns Max     473.48660411714735
evaluation/ExplReturns Min     467.8204487580704
evaluation/Actions Mean        0.06661375
evaluation/Actions Std         0.5803323
evaluation/Actions Max         0.99243593
evaluation/Actions Min         -0.9988884
evaluation/Num Paths           10
evaluation/Average Returns     471.72453436200203
time/data storing (s)          0.03253065049648285
time/evaluation sampling (s)   109.91406610328704
time/exploration sampling (s)  110.87726730015129
time/logging (s)               0.030799192376434803
time/saving (s)                0.01156759262084961
time/training (s)              9.649170439690351
time/epoch (s)                 230.51540127862245
time/total (s)                 48462.1176384408
Epoch                          206
-----------------------------  ---------------------
2023-08-01 07:25:43.027458 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 207 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3793.0146]
trainer/QF1 Loss               0.15064168
trainer/QF2 Loss               0.15323862
trainer/Policy Loss            -78.93067
trainer/Q1 Predictions Mean    90.57707
trainer/Q1 Predictions Std     8.875412
trainer/Q1 Predictions Max     100.27589
trainer/Q1 Predictions Min     59.61112
trainer/Q2 Predictions Mean    90.604935
trainer/Q2 Predictions Std     8.838718
trainer/Q2 Predictions Max     100.28128
trainer/Q2 Predictions Min     59.647953
trainer/Q Targets Mean         90.6754
trainer/Q Targets Std          8.90419
trainer/Q Targets Max          100.436676
trainer/Q Targets Min          59.80874
trainer/Log Pis Mean           11.79709
trainer/Log Pis Std            7.9178047
trainer/Log Pis Max            40.73623
trainer/Log Pis Min            -4.067486
trainer/Policy mu Mean         0.017303219
trainer/Policy mu Std          1.5905015
trainer/Policy mu Max          4.6097965
trainer/Policy mu Min          -5.69359
trainer/Policy log std Mean    -0.68604916
trainer/Policy log std Std     0.23292698
trainer/Policy log std Max     0.3620382
trainer/Policy log std Min     -1.5178498
trainer/Alpha                  0.003078196197748184
trainer/Alpha Loss             -1.1734511852264404
exploration/num steps total    1041000
exploration/num paths total    2082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9368490749432232
exploration/Rewards Std        0.07935002624105124
exploration/Rewards Max        0.9796774335188817
exploration/Rewards Min        0.49814069838569747
exploration/Returns Mean       468.4245374716118
exploration/Returns Std        3.5739600258557003
exploration/Returns Max        473.121788364206
exploration/Returns Min        461.8002265423261
exploration/Actions Mean       -0.016272368
exploration/Actions Std        0.59850293
exploration/Actions Max        0.99982613
exploration/Actions Min        -0.99970114
exploration/Num Paths          10
exploration/Average Returns    468.4245374716118
evaluation/num steps total     1040000
evaluation/num paths total     2080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9451696933842537
evaluation/Rewards Std         0.07052199838042861
evaluation/Rewards Max         0.9787180336888316
evaluation/Rewards Min         0.49688001885798444
evaluation/Returns Mean        472.58484669212686
evaluation/Returns Std         1.3442908001873162
evaluation/Returns Max         474.73009459717656
evaluation/Returns Min         470.2910452455193
evaluation/ExplReturns Mean    472.58484669212686
evaluation/ExplReturns Std     1.3442908001873162
evaluation/ExplReturns Max     474.73009459717656
evaluation/ExplReturns Min     470.2910452455193
evaluation/Actions Mean        -0.008039829
evaluation/Actions Std         0.50171596
evaluation/Actions Max         0.99613786
evaluation/Actions Min         -0.9974115
evaluation/Num Paths           10
evaluation/Average Returns     472.58484669212686
time/data storing (s)          0.032492926344275475
time/evaluation sampling (s)   110.79817231185734
time/exploration sampling (s)  112.12235873285681
time/logging (s)               0.030420055612921715
time/saving (s)                0.011666950769722462
time/training (s)              9.58331242389977
time/epoch (s)                 232.57842340134084
time/total (s)                 48694.69852538407
Epoch                          207
-----------------------------  --------------------
2023-08-01 07:29:31.202346 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 208 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3494.4165]
trainer/QF1 Loss               0.15669127
trainer/QF2 Loss               0.12706903
trainer/Policy Loss            -78.7023
trainer/Q1 Predictions Mean    90.68184
trainer/Q1 Predictions Std     8.040207
trainer/Q1 Predictions Max     100.33956
trainer/Q1 Predictions Min     68.5714
trainer/Q2 Predictions Mean    90.80955
trainer/Q2 Predictions Std     8.088652
trainer/Q2 Predictions Max     100.199165
trainer/Q2 Predictions Min     68.20734
trainer/Q Targets Mean         90.792244
trainer/Q Targets Std          8.066652
trainer/Q Targets Max          100.1525
trainer/Q Targets Min          68.71182
trainer/Log Pis Mean           12.204871
trainer/Log Pis Std            8.43882
trainer/Log Pis Max            44.732224
trainer/Log Pis Min            -5.6771746
trainer/Policy mu Mean         -0.027647087
trainer/Policy mu Std          1.6028328
trainer/Policy mu Max          4.129013
trainer/Policy mu Min          -4.851102
trainer/Policy log std Mean    -0.6947047
trainer/Policy log std Std     0.23019367
trainer/Policy log std Max     0.00389719
trainer/Policy log std Min     -1.5560617
trainer/Alpha                  0.0030174897983670235
trainer/Alpha Loss             1.1889535188674927
exploration/num steps total    1046000
exploration/num paths total    2092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9528026325431547
exploration/Rewards Std        0.07077674875556299
exploration/Rewards Max        0.9799173704916836
exploration/Rewards Min        0.4926035089049995
exploration/Returns Mean       476.40131627157723
exploration/Returns Std        3.691347541757435
exploration/Returns Max        480.74702675612167
exploration/Returns Min        469.6710878545412
exploration/Actions Mean       0.031586424
exploration/Actions Std        0.6261624
exploration/Actions Max        0.999569
exploration/Actions Min        -0.99980253
exploration/Num Paths          10
exploration/Average Returns    476.40131627157723
evaluation/num steps total     1045000
evaluation/num paths total     2090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.947010845613656
evaluation/Rewards Std         0.07637845675593996
evaluation/Rewards Max         0.9792764741142218
evaluation/Rewards Min         0.4994957971760918
evaluation/Returns Mean        473.50542280682794
evaluation/Returns Std         1.7650085449406616
evaluation/Returns Max         475.7050954925374
evaluation/Returns Min         470.06992709214063
evaluation/ExplReturns Mean    473.50542280682794
evaluation/ExplReturns Std     1.7650085449406616
evaluation/ExplReturns Max     475.7050954925374
evaluation/ExplReturns Min     470.06992709214063
evaluation/Actions Mean        0.06380534
evaluation/Actions Std         0.5675328
evaluation/Actions Max         0.99473935
evaluation/Actions Min         -0.9991167
evaluation/Num Paths           10
evaluation/Average Returns     473.50542280682794
time/data storing (s)          0.032071303576231
time/evaluation sampling (s)   108.5892186826095
time/exploration sampling (s)  109.86200077272952
time/logging (s)               0.030332354828715324
time/saving (s)                0.012826350517570972
time/training (s)              9.643825491890311
time/epoch (s)                 228.17027495615184
time/total (s)                 48922.871271549724
Epoch                          208
-----------------------------  ---------------------
2023-08-01 07:33:24.370926 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 209 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4028.7258]
trainer/QF1 Loss               0.14623629
trainer/QF2 Loss               0.171648
trainer/Policy Loss            -77.57428
trainer/Q1 Predictions Mean    90.51703
trainer/Q1 Predictions Std     8.17204
trainer/Q1 Predictions Max     100.05266
trainer/Q1 Predictions Min     66.74925
trainer/Q2 Predictions Mean    90.608406
trainer/Q2 Predictions Std     8.19182
trainer/Q2 Predictions Max     100.13222
trainer/Q2 Predictions Min     66.66398
trainer/Q Targets Mean         90.413666
trainer/Q Targets Std          8.215613
trainer/Q Targets Max          100.21757
trainer/Q Targets Min          66.48835
trainer/Log Pis Mean           13.132568
trainer/Log Pis Std            8.048287
trainer/Log Pis Max            32.96519
trainer/Log Pis Min            -4.272994
trainer/Policy mu Mean         0.094210535
trainer/Policy mu Std          1.6523529
trainer/Policy mu Max          4.2080417
trainer/Policy mu Min          -4.499027
trainer/Policy log std Mean    -0.69351536
trainer/Policy log std Std     0.24301574
trainer/Policy log std Max     0.16389942
trainer/Policy log std Min     -1.511724
trainer/Alpha                  0.0030191708356142044
trainer/Alpha Loss             6.572405815124512
exploration/num steps total    1051000
exploration/num paths total    2102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9515798321286199
exploration/Rewards Std        0.07332710229756775
exploration/Rewards Max        0.9800122589661368
exploration/Rewards Min        0.49846533479180843
exploration/Returns Mean       475.78991606431
exploration/Returns Std        4.091821102441675
exploration/Returns Max        480.20671443043693
exploration/Returns Min        467.2449092399218
exploration/Actions Mean       0.06459516
exploration/Actions Std        0.6025288
exploration/Actions Max        0.99971324
exploration/Actions Min        -0.99995923
exploration/Num Paths          10
exploration/Average Returns    475.78991606431
evaluation/num steps total     1050000
evaluation/num paths total     2100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.93421312139434
evaluation/Rewards Std         0.080979058955762
evaluation/Rewards Max         0.9794976415602336
evaluation/Rewards Min         0.501697111980908
evaluation/Returns Mean        467.10656069717
evaluation/Returns Std         25.416460430266213
evaluation/Returns Max         477.8064830719307
evaluation/Returns Min         390.9487423255705
evaluation/ExplReturns Mean    467.10656069717
evaluation/ExplReturns Std     25.416460430266213
evaluation/ExplReturns Max     477.8064830719307
evaluation/ExplReturns Min     390.9487423255705
evaluation/Actions Mean        0.08624603
evaluation/Actions Std         0.50622916
evaluation/Actions Max         0.9984065
evaluation/Actions Min         -0.9978994
evaluation/Num Paths           10
evaluation/Average Returns     467.10656069717
time/data storing (s)          0.03231050539761782
time/evaluation sampling (s)   112.05949650984257
time/exploration sampling (s)  111.08204195741564
time/logging (s)               0.03039933368563652
time/saving (s)                0.010237348265945911
time/training (s)              9.949608112685382
time/epoch (s)                 233.1640937672928
time/total (s)                 49156.037860902026
Epoch                          209
-----------------------------  ---------------------
2023-08-01 07:37:14.809081 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 210 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3347.1963]
trainer/QF1 Loss               0.11685321
trainer/QF2 Loss               0.12252656
trainer/Policy Loss            -79.012
trainer/Q1 Predictions Mean    90.65938
trainer/Q1 Predictions Std     8.601961
trainer/Q1 Predictions Max     99.474556
trainer/Q1 Predictions Min     57.65718
trainer/Q2 Predictions Mean    90.73571
trainer/Q2 Predictions Std     8.650868
trainer/Q2 Predictions Max     99.564255
trainer/Q2 Predictions Min     57.64358
trainer/Q Targets Mean         90.69109
trainer/Q Targets Std          8.589152
trainer/Q Targets Max          99.43487
trainer/Q Targets Min          58.021393
trainer/Log Pis Mean           11.845855
trainer/Log Pis Std            8.144173
trainer/Log Pis Max            38.737965
trainer/Log Pis Min            -5.192069
trainer/Policy mu Mean         0.02668907
trainer/Policy mu Std          1.6043977
trainer/Policy mu Max          4.9551783
trainer/Policy mu Min          -7.720878
trainer/Policy log std Mean    -0.69141287
trainer/Policy log std Std     0.22984105
trainer/Policy log std Max     0.13802904
trainer/Policy log std Min     -1.5390284
trainer/Alpha                  0.0029377941973507404
trainer/Alpha Loss             -0.8986533284187317
exploration/num steps total    1056000
exploration/num paths total    2112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9477250018596561
exploration/Rewards Std        0.0676231528588974
exploration/Rewards Max        0.979766982537649
exploration/Rewards Min        0.49761321577816764
exploration/Returns Mean       473.8625009298282
exploration/Returns Std        4.907832258187671
exploration/Returns Max        479.0311664588735
exploration/Returns Min        463.97862899516923
exploration/Actions Mean       0.054768346
exploration/Actions Std        0.62624717
exploration/Actions Max        0.999244
exploration/Actions Min        -0.99973303
exploration/Num Paths          10
exploration/Average Returns    473.8625009298282
evaluation/num steps total     1055000
evaluation/num paths total     2110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9120589732297018
evaluation/Rewards Std         0.08771137345332501
evaluation/Rewards Max         0.9791976392857867
evaluation/Rewards Min         0.4983649306029224
evaluation/Returns Mean        456.0294866148507
evaluation/Returns Std         10.881780096662496
evaluation/Returns Max         469.0786625625009
evaluation/Returns Min         431.82549712823953
evaluation/ExplReturns Mean    456.0294866148507
evaluation/ExplReturns Std     10.881780096662496
evaluation/ExplReturns Max     469.0786625625009
evaluation/ExplReturns Min     431.82549712823953
evaluation/Actions Mean        0.094132185
evaluation/Actions Std         0.5225359
evaluation/Actions Max         0.9950888
evaluation/Actions Min         -0.9975113
evaluation/Num Paths           10
evaluation/Average Returns     456.0294866148507
time/data storing (s)          0.03213834669440985
time/evaluation sampling (s)   109.19909521751106
time/exploration sampling (s)  111.50785161275417
time/logging (s)               0.030319204553961754
time/saving (s)                0.012301675044000149
time/training (s)              9.651714651845396
time/epoch (s)                 230.433420708403
time/total (s)                 49386.473841378465
Epoch                          210
-----------------------------  ---------------------
2023-08-01 07:41:06.201475 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 211 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3336.738]
trainer/QF1 Loss               0.1112832
trainer/QF2 Loss               0.113402456
trainer/Policy Loss            -81.007935
trainer/Q1 Predictions Mean    91.81868
trainer/Q1 Predictions Std     7.733802
trainer/Q1 Predictions Max     100.013535
trainer/Q1 Predictions Min     64.97871
trainer/Q2 Predictions Mean    91.77869
trainer/Q2 Predictions Std     7.719528
trainer/Q2 Predictions Max     99.996796
trainer/Q2 Predictions Min     64.39748
trainer/Q Targets Mean         91.852104
trainer/Q Targets Std          7.784829
trainer/Q Targets Max          100.17235
trainer/Q Targets Min          64.10321
trainer/Log Pis Mean           10.947855
trainer/Log Pis Std            8.2655325
trainer/Log Pis Max            32.207222
trainer/Log Pis Min            -7.8549066
trainer/Policy mu Mean         0.0844349
trainer/Policy mu Std          1.5502425
trainer/Policy mu Max          5.431239
trainer/Policy mu Min          -5.154791
trainer/Policy log std Mean    -0.7157114
trainer/Policy log std Std     0.2472228
trainer/Policy log std Max     0.1209746
trainer/Policy log std Min     -1.619206
trainer/Alpha                  0.002915653632953763
trainer/Alpha Loss             -6.14193058013916
exploration/num steps total    1061000
exploration/num paths total    2122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9438231166996275
exploration/Rewards Std        0.07465489536712414
exploration/Rewards Max        0.9788285986068731
exploration/Rewards Min        0.5000453124944643
exploration/Returns Mean       471.91155834981373
exploration/Returns Std        10.764928885994935
exploration/Returns Max        478.3264908198319
exploration/Returns Min        442.36829171313366
exploration/Actions Mean       0.021302788
exploration/Actions Std        0.6014349
exploration/Actions Max        0.99972457
exploration/Actions Min        -0.99967647
exploration/Num Paths          10
exploration/Average Returns    471.91155834981373
evaluation/num steps total     1060000
evaluation/num paths total     2120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9507519150961634
evaluation/Rewards Std         0.060016557760902534
evaluation/Rewards Max         0.9779528264324372
evaluation/Rewards Min         0.49074328147146806
evaluation/Returns Mean        475.3759575480817
evaluation/Returns Std         5.089758114857125
evaluation/Returns Max         478.73764334881656
evaluation/Returns Min         461.26201373619244
evaluation/ExplReturns Mean    475.3759575480817
evaluation/ExplReturns Std     5.089758114857125
evaluation/ExplReturns Max     478.73764334881656
evaluation/ExplReturns Min     461.26201373619244
evaluation/Actions Mean        0.040803153
evaluation/Actions Std         0.53036696
evaluation/Actions Max         0.9975266
evaluation/Actions Min         -0.99778014
evaluation/Num Paths           10
evaluation/Average Returns     475.3759575480817
time/data storing (s)          0.03246929030865431
time/evaluation sampling (s)   109.8943719509989
time/exploration sampling (s)  111.80026685725898
time/logging (s)               0.030615828931331635
time/saving (s)                0.010275628417730331
time/training (s)              9.620145762339234
time/epoch (s)                 231.38814531825483
time/total (s)                 49617.86445389222
Epoch                          211
-----------------------------  --------------------
2023-08-01 07:44:57.751655 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 212 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3578.1694]
trainer/QF1 Loss               0.11756637
trainer/QF2 Loss               0.084376484
trainer/Policy Loss            -80.27658
trainer/Q1 Predictions Mean    91.86513
trainer/Q1 Predictions Std     7.422665
trainer/Q1 Predictions Max     99.87181
trainer/Q1 Predictions Min     65.86918
trainer/Q2 Predictions Mean    91.832535
trainer/Q2 Predictions Std     7.4483504
trainer/Q2 Predictions Max     99.72929
trainer/Q2 Predictions Min     65.73544
trainer/Q Targets Mean         91.82578
trainer/Q Targets Std          7.428325
trainer/Q Targets Max          99.984375
trainer/Q Targets Min          65.91875
trainer/Log Pis Mean           11.744985
trainer/Log Pis Std            8.103225
trainer/Log Pis Max            42.57496
trainer/Log Pis Min            -3.256053
trainer/Policy mu Mean         0.16308925
trainer/Policy mu Std          1.596277
trainer/Policy mu Max          10.8042555
trainer/Policy mu Min          -4.930017
trainer/Policy log std Mean    -0.7196875
trainer/Policy log std Std     0.24493155
trainer/Policy log std Max     0.71550107
trainer/Policy log std Min     -1.60705
trainer/Alpha                  0.0028799762949347496
trainer/Alpha Loss             -1.4918383359909058
exploration/num steps total    1066000
exploration/num paths total    2132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.950801146150526
exploration/Rewards Std        0.06438333042160424
exploration/Rewards Max        0.9796919548540036
exploration/Rewards Min        0.49988988793527156
exploration/Returns Mean       475.400573075263
exploration/Returns Std        2.195176484042308
exploration/Returns Max        477.73617465123334
exploration/Returns Min        469.8753947583447
exploration/Actions Mean       0.026067873
exploration/Actions Std        0.5767717
exploration/Actions Max        0.9999747
exploration/Actions Min        -0.9998811
exploration/Num Paths          10
exploration/Average Returns    475.400573075263
evaluation/num steps total     1065000
evaluation/num paths total     2130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9032637238528438
evaluation/Rewards Std         0.10281634896375011
evaluation/Rewards Max         0.9789790842682553
evaluation/Rewards Min         0.49263667031072506
evaluation/Returns Mean        451.63186192642195
evaluation/Returns Std         40.43263809381307
evaluation/Returns Max         476.44767818592396
evaluation/Returns Min         370.8169613541104
evaluation/ExplReturns Mean    451.63186192642195
evaluation/ExplReturns Std     40.43263809381307
evaluation/ExplReturns Max     476.44767818592396
evaluation/ExplReturns Min     370.8169613541104
evaluation/Actions Mean        0.07071055
evaluation/Actions Std         0.48255554
evaluation/Actions Max         0.99854404
evaluation/Actions Min         -0.99913996
evaluation/Num Paths           10
evaluation/Average Returns     451.63186192642195
time/data storing (s)          0.032198178581893444
time/evaluation sampling (s)   111.41016514971852
time/exploration sampling (s)  110.44931807368994
time/logging (s)               0.031088056974112988
time/saving (s)                0.010677624493837357
time/training (s)              9.612563096918166
time/epoch (s)                 231.54601018037647
time/total (s)                 49849.41295449063
Epoch                          212
-----------------------------  ---------------------
2023-08-01 07:48:49.907762 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 213 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3441.016]
trainer/QF1 Loss               0.14422265
trainer/QF2 Loss               0.14247605
trainer/Policy Loss            -78.581085
trainer/Q1 Predictions Mean    91.25574
trainer/Q1 Predictions Std     8.34302
trainer/Q1 Predictions Max     99.90956
trainer/Q1 Predictions Min     62.41827
trainer/Q2 Predictions Mean    91.29443
trainer/Q2 Predictions Std     8.326616
trainer/Q2 Predictions Max     100.041855
trainer/Q2 Predictions Min     62.629772
trainer/Q Targets Mean         91.27694
trainer/Q Targets Std          8.36001
trainer/Q Targets Max          100.06698
trainer/Q Targets Min          62.52992
trainer/Log Pis Mean           12.870747
trainer/Log Pis Std            7.774594
trainer/Log Pis Max            41.27517
trainer/Log Pis Min            -2.2982395
trainer/Policy mu Mean         -0.07001367
trainer/Policy mu Std          1.6312927
trainer/Policy mu Max          5.040947
trainer/Policy mu Min          -4.4754653
trainer/Policy log std Mean    -0.70210886
trainer/Policy log std Std     0.25577664
trainer/Policy log std Max     0.11262578
trainer/Policy log std Min     -1.5788914
trainer/Alpha                  0.0029028006829321384
trainer/Alpha Loss             5.087160110473633
exploration/num steps total    1071000
exploration/num paths total    2142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9415015532378509
exploration/Rewards Std        0.08163883480746274
exploration/Rewards Max        0.9796358243150401
exploration/Rewards Min        0.49357917587329037
exploration/Returns Mean       470.7507766189254
exploration/Returns Std        14.446373070458305
exploration/Returns Max        479.51794341867577
exploration/Returns Min        427.8267636910948
exploration/Actions Mean       0.06067863
exploration/Actions Std        0.61279494
exploration/Actions Max        0.99967086
exploration/Actions Min        -0.9998928
exploration/Num Paths          10
exploration/Average Returns    470.7507766189254
evaluation/num steps total     1070000
evaluation/num paths total     2140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9433798363647166
evaluation/Rewards Std         0.06996840964419049
evaluation/Rewards Max         0.9777565654079571
evaluation/Rewards Min         0.504649223941327
evaluation/Returns Mean        471.68991818235816
evaluation/Returns Std         1.8353548821192862
evaluation/Returns Max         475.9130575109792
evaluation/Returns Min         468.87947352098223
evaluation/ExplReturns Mean    471.68991818235816
evaluation/ExplReturns Std     1.8353548821192862
evaluation/ExplReturns Max     475.9130575109792
evaluation/ExplReturns Min     468.87947352098223
evaluation/Actions Mean        0.087157845
evaluation/Actions Std         0.51364785
evaluation/Actions Max         0.99909526
evaluation/Actions Min         -0.99930745
evaluation/Num Paths           10
evaluation/Average Returns     471.68991818235816
time/data storing (s)          0.03186669293791056
time/evaluation sampling (s)   110.85361642111093
time/exploration sampling (s)  111.55871873535216
time/logging (s)               0.030514678917825222
time/saving (s)                0.012515967711806297
time/training (s)              9.663686821237206
time/epoch (s)                 232.15091931726784
time/total (s)                 50081.5663759578
Epoch                          213
-----------------------------  ---------------------
2023-08-01 07:52:39.827859 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 214 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3611.9536]
trainer/QF1 Loss               0.1486794
trainer/QF2 Loss               0.17039588
trainer/Policy Loss            -78.09822
trainer/Q1 Predictions Mean    91.032074
trainer/Q1 Predictions Std     8.3234415
trainer/Q1 Predictions Max     100.1851
trainer/Q1 Predictions Min     54.593967
trainer/Q2 Predictions Mean    90.950226
trainer/Q2 Predictions Std     8.327813
trainer/Q2 Predictions Max     99.87362
trainer/Q2 Predictions Min     54.8417
trainer/Q Targets Mean         91.0796
trainer/Q Targets Std          8.291719
trainer/Q Targets Max          100.04139
trainer/Q Targets Min          54.955315
trainer/Log Pis Mean           13.050634
trainer/Log Pis Std            8.64002
trainer/Log Pis Max            38.141727
trainer/Log Pis Min            -3.9880085
trainer/Policy mu Mean         0.118711375
trainer/Policy mu Std          1.643685
trainer/Policy mu Max          5.0022182
trainer/Policy mu Min          -5.4446106
trainer/Policy log std Mean    -0.71074134
trainer/Policy log std Std     0.24992211
trainer/Policy log std Max     0.10711077
trainer/Policy log std Min     -1.5863191
trainer/Alpha                  0.0028771942015737295
trainer/Alpha Loss             6.147406578063965
exploration/num steps total    1076000
exploration/num paths total    2152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9555222055432212
exploration/Rewards Std        0.06236481597211834
exploration/Rewards Max        0.9792955712239575
exploration/Rewards Min        0.5034820243643877
exploration/Returns Mean       477.7611027716107
exploration/Returns Std        2.5941869430312208
exploration/Returns Max        481.2574360151586
exploration/Returns Min        473.32660018564906
exploration/Actions Mean       0.029769007
exploration/Actions Std        0.5913458
exploration/Actions Max        0.9994727
exploration/Actions Min        -0.9998902
exploration/Num Paths          10
exploration/Average Returns    477.7611027716107
evaluation/num steps total     1075000
evaluation/num paths total     2150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9524977371201437
evaluation/Rewards Std         0.06799947572319276
evaluation/Rewards Max         0.9784777460999898
evaluation/Rewards Min         0.4983782029914656
evaluation/Returns Mean        476.2488685600718
evaluation/Returns Std         8.93975329454876
evaluation/Returns Max         482.22684692589604
evaluation/Returns Min         451.04216747780015
evaluation/ExplReturns Mean    476.2488685600718
evaluation/ExplReturns Std     8.93975329454876
evaluation/ExplReturns Max     482.22684692589604
evaluation/ExplReturns Min     451.04216747780015
evaluation/Actions Mean        0.06739696
evaluation/Actions Std         0.5148789
evaluation/Actions Max         0.99769336
evaluation/Actions Min         -0.9969095
evaluation/Num Paths           10
evaluation/Average Returns     476.2488685600718
time/data storing (s)          0.03246215730905533
time/evaluation sampling (s)   109.61720474995673
time/exploration sampling (s)  110.76141603570431
time/logging (s)               0.030469119548797607
time/saving (s)                0.010265628807246685
time/training (s)              9.463592174462974
time/epoch (s)                 229.91540986578912
time/total (s)                 50311.48433318734
Epoch                          214
-----------------------------  ---------------------
2023-08-01 07:56:30.332191 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 215 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3579.9048]
trainer/QF1 Loss               0.16394229
trainer/QF2 Loss               0.14224137
trainer/Policy Loss            -79.913025
trainer/Q1 Predictions Mean    91.55322
trainer/Q1 Predictions Std     8.143393
trainer/Q1 Predictions Max     100.13095
trainer/Q1 Predictions Min     68.85646
trainer/Q2 Predictions Mean    91.59797
trainer/Q2 Predictions Std     8.188312
trainer/Q2 Predictions Max     100.21031
trainer/Q2 Predictions Min     68.404655
trainer/Q Targets Mean         91.68217
trainer/Q Targets Std          8.216208
trainer/Q Targets Max          100.40264
trainer/Q Targets Min          68.39531
trainer/Log Pis Mean           11.825023
trainer/Log Pis Std            7.725889
trainer/Log Pis Max            33.66902
trainer/Log Pis Min            -3.547135
trainer/Policy mu Mean         0.120390974
trainer/Policy mu Std          1.5804766
trainer/Policy mu Max          5.408255
trainer/Policy mu Min          -4.7397375
trainer/Policy log std Mean    -0.72472477
trainer/Policy log std Std     0.24998754
trainer/Policy log std Max     0.10776335
trainer/Policy log std Min     -1.6564677
trainer/Alpha                  0.0028195520862936974
trainer/Alpha Loss             -1.0273330211639404
exploration/num steps total    1081000
exploration/num paths total    2162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9548276585606603
exploration/Rewards Std        0.06648100451178238
exploration/Rewards Max        0.9799675330253728
exploration/Rewards Min        0.5010052845011556
exploration/Returns Mean       477.4138292803301
exploration/Returns Std        2.289599781673822
exploration/Returns Max        480.91337351294504
exploration/Returns Min        472.38694051156773
exploration/Actions Mean       0.08613543
exploration/Actions Std        0.62949187
exploration/Actions Max        0.9998583
exploration/Actions Min        -0.99975985
exploration/Num Paths          10
exploration/Average Returns    477.4138292803301
evaluation/num steps total     1080000
evaluation/num paths total     2160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9432779918636602
evaluation/Rewards Std         0.07235960810015327
evaluation/Rewards Max         0.9797920106259368
evaluation/Rewards Min         0.5018968098529218
evaluation/Returns Mean        471.63899593183004
evaluation/Returns Std         3.162144167790868
evaluation/Returns Max         475.9156652370244
evaluation/Returns Min         465.23572021596976
evaluation/ExplReturns Mean    471.63899593183004
evaluation/ExplReturns Std     3.162144167790868
evaluation/ExplReturns Max     475.9156652370244
evaluation/ExplReturns Min     465.23572021596976
evaluation/Actions Mean        0.09773257
evaluation/Actions Std         0.5562809
evaluation/Actions Max         0.9970229
evaluation/Actions Min         -0.998806
evaluation/Num Paths           10
evaluation/Average Returns     471.63899593183004
time/data storing (s)          0.032426186837255955
time/evaluation sampling (s)   110.04528602864593
time/exploration sampling (s)  110.69411113113165
time/logging (s)               0.030461518093943596
time/saving (s)                0.010292025282979012
time/training (s)              9.687168820761144
time/epoch (s)                 230.4997457107529
time/total (s)                 50541.986560598016
Epoch                          215
-----------------------------  ---------------------
2023-08-01 08:00:20.363654 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 216 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3321.925]
trainer/QF1 Loss               0.14279975
trainer/QF2 Loss               0.14957955
trainer/Policy Loss            -80.64317
trainer/Q1 Predictions Mean    92.30734
trainer/Q1 Predictions Std     7.883083
trainer/Q1 Predictions Max     100.785065
trainer/Q1 Predictions Min     55.87647
trainer/Q2 Predictions Mean    92.2805
trainer/Q2 Predictions Std     7.8657193
trainer/Q2 Predictions Max     100.66117
trainer/Q2 Predictions Min     55.51562
trainer/Q Targets Mean         92.27818
trainer/Q Targets Std          7.871123
trainer/Q Targets Max          100.30598
trainer/Q Targets Min          56.620594
trainer/Log Pis Mean           11.810666
trainer/Log Pis Std            7.3244543
trainer/Log Pis Max            33.333233
trainer/Log Pis Min            -5.1996536
trainer/Policy mu Mean         -0.029131373
trainer/Policy mu Std          1.5683284
trainer/Policy mu Max          4.4864426
trainer/Policy mu Min          -4.353941
trainer/Policy log std Mean    -0.7247928
trainer/Policy log std Std     0.26019743
trainer/Policy log std Max     0.03096795
trainer/Policy log std Min     -1.6665063
trainer/Alpha                  0.0028859120793640614
trainer/Alpha Loss             -1.1071984767913818
exploration/num steps total    1086000
exploration/num paths total    2172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9392069822059963
exploration/Rewards Std        0.07874599621685363
exploration/Rewards Max        0.9797005729350444
exploration/Rewards Min        0.49727675341605526
exploration/Returns Mean       469.6034911029982
exploration/Returns Std        7.929994326793582
exploration/Returns Max        478.1729750381332
exploration/Returns Min        447.64678875257295
exploration/Actions Mean       0.039130386
exploration/Actions Std        0.6337827
exploration/Actions Max        0.9995706
exploration/Actions Min        -0.9998844
exploration/Num Paths          10
exploration/Average Returns    469.6034911029982
evaluation/num steps total     1085000
evaluation/num paths total     2170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9399948358270224
evaluation/Rewards Std         0.07483260399503332
evaluation/Rewards Max         0.9793342348703171
evaluation/Rewards Min         0.49458334236262724
evaluation/Returns Mean        469.99741791351096
evaluation/Returns Std         1.1877827394954452
evaluation/Returns Max         471.6192145862899
evaluation/Returns Min         468.0122849612506
evaluation/ExplReturns Mean    469.99741791351096
evaluation/ExplReturns Std     1.1877827394954452
evaluation/ExplReturns Max     471.6192145862899
evaluation/ExplReturns Min     468.0122849612506
evaluation/Actions Mean        0.055451054
evaluation/Actions Std         0.57340217
evaluation/Actions Max         0.9959534
evaluation/Actions Min         -0.99901867
evaluation/Num Paths           10
evaluation/Average Returns     469.99741791351096
time/data storing (s)          0.03189734369516373
time/evaluation sampling (s)   109.18641772959381
time/exploration sampling (s)  111.07194750383496
time/logging (s)               0.030389776453375816
time/saving (s)                0.012513712048530579
time/training (s)              9.693531157448888
time/epoch (s)                 230.02669722307473
time/total (s)                 50772.015851142816
Epoch                          216
-----------------------------  ---------------------
2023-08-01 08:04:10.688136 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 217 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3391.7502]
trainer/QF1 Loss               0.15589273
trainer/QF2 Loss               0.13607499
trainer/Policy Loss            -79.501816
trainer/Q1 Predictions Mean    91.612755
trainer/Q1 Predictions Std     7.262071
trainer/Q1 Predictions Max     100.90783
trainer/Q1 Predictions Min     66.77539
trainer/Q2 Predictions Mean    91.58276
trainer/Q2 Predictions Std     7.2343493
trainer/Q2 Predictions Max     100.87248
trainer/Q2 Predictions Min     67.25583
trainer/Q Targets Mean         91.520035
trainer/Q Targets Std          7.2626095
trainer/Q Targets Max          100.811005
trainer/Q Targets Min          66.8425
trainer/Log Pis Mean           12.287138
trainer/Log Pis Std            7.9887495
trainer/Log Pis Max            37.154816
trainer/Log Pis Min            -4.0322075
trainer/Policy mu Mean         0.018760337
trainer/Policy mu Std          1.5854056
trainer/Policy mu Max          5.962704
trainer/Policy mu Min          -4.8726845
trainer/Policy log std Mean    -0.728113
trainer/Policy log std Std     0.2526005
trainer/Policy log std Max     0.12244129
trainer/Policy log std Min     -1.8264838
trainer/Alpha                  0.0027782239485532045
trainer/Alpha Loss             1.6900407075881958
exploration/num steps total    1091000
exploration/num paths total    2182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9552242487390904
exploration/Rewards Std        0.06655125258898581
exploration/Rewards Max        0.97954976202555
exploration/Rewards Min        0.49702935805982373
exploration/Returns Mean       477.6121243695451
exploration/Returns Std        2.4887476701536593
exploration/Returns Max        480.8900823315664
exploration/Returns Min        474.71242268254304
exploration/Actions Mean       0.033197608
exploration/Actions Std        0.62169904
exploration/Actions Max        0.99922127
exploration/Actions Min        -0.9999338
exploration/Num Paths          10
exploration/Average Returns    477.6121243695451
evaluation/num steps total     1090000
evaluation/num paths total     2180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9503522805966113
evaluation/Rewards Std         0.07231839837117363
evaluation/Rewards Max         0.9789713920936176
evaluation/Rewards Min         0.49788357090235924
evaluation/Returns Mean        475.17614029830565
evaluation/Returns Std         1.2387565511596919
evaluation/Returns Max         477.13738409411206
evaluation/Returns Min         472.01891248235626
evaluation/ExplReturns Mean    475.17614029830565
evaluation/ExplReturns Std     1.2387565511596919
evaluation/ExplReturns Max     477.13738409411206
evaluation/ExplReturns Min     472.01891248235626
evaluation/Actions Mean        0.044614203
evaluation/Actions Std         0.5526372
evaluation/Actions Max         0.99622786
evaluation/Actions Min         -0.99948806
evaluation/Num Paths           10
evaluation/Average Returns     475.17614029830565
time/data storing (s)          0.03219327703118324
time/evaluation sampling (s)   109.90884732548147
time/exploration sampling (s)  111.22260371781886
time/logging (s)               0.030970453284680843
time/saving (s)                0.012715933844447136
time/training (s)              9.113109695725143
time/epoch (s)                 230.32044040318578
time/total (s)                 51002.338746587746
Epoch                          217
-----------------------------  ---------------------
2023-08-01 08:08:01.208133 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 218 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3599.0728]
trainer/QF1 Loss               0.13959019
trainer/QF2 Loss               0.1572018
trainer/Policy Loss            -79.22276
trainer/Q1 Predictions Mean    91.38122
trainer/Q1 Predictions Std     7.869182
trainer/Q1 Predictions Max     100.690285
trainer/Q1 Predictions Min     69.12125
trainer/Q2 Predictions Mean    91.362686
trainer/Q2 Predictions Std     7.8357573
trainer/Q2 Predictions Max     100.88369
trainer/Q2 Predictions Min     68.8658
trainer/Q Targets Mean         91.30818
trainer/Q Targets Std          7.800446
trainer/Q Targets Max          100.611145
trainer/Q Targets Min          69.133514
trainer/Log Pis Mean           12.311801
trainer/Log Pis Std            8.393534
trainer/Log Pis Max            34.60735
trainer/Log Pis Min            -3.282094
trainer/Policy mu Mean         -0.054035995
trainer/Policy mu Std          1.6011282
trainer/Policy mu Max          5.8259783
trainer/Policy mu Min          -4.1281066
trainer/Policy log std Mean    -0.7380996
trainer/Policy log std Std     0.27928385
trainer/Policy log std Max     0.010496914
trainer/Policy log std Min     -1.7046602
trainer/Alpha                  0.0028453106060624123
trainer/Alpha Loss             1.8277814388275146
exploration/num steps total    1096000
exploration/num paths total    2192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9300974505636427
exploration/Rewards Std        0.09248126351330573
exploration/Rewards Max        0.9797281579913174
exploration/Rewards Min        0.48823683430695974
exploration/Returns Mean       465.0487252818213
exploration/Returns Std        18.87086239918148
exploration/Returns Max        478.8484071083917
exploration/Returns Min        411.3531657893589
exploration/Actions Mean       0.039431278
exploration/Actions Std        0.6017882
exploration/Actions Max        0.999954
exploration/Actions Min        -0.9998978
exploration/Num Paths          10
exploration/Average Returns    465.0487252818213
evaluation/num steps total     1095000
evaluation/num paths total     2190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9152054662932944
evaluation/Rewards Std         0.0979573660875753
evaluation/Rewards Max         0.9778322646944771
evaluation/Rewards Min         0.4889825922611728
evaluation/Returns Mean        457.6027331466474
evaluation/Returns Std         31.984608996425038
evaluation/Returns Max         477.11345158418345
evaluation/Returns Min         364.6082458743678
evaluation/ExplReturns Mean    457.6027331466474
evaluation/ExplReturns Std     31.984608996425038
evaluation/ExplReturns Max     477.11345158418345
evaluation/ExplReturns Min     364.6082458743678
evaluation/Actions Mean        0.043160878
evaluation/Actions Std         0.5000446
evaluation/Actions Max         0.9991559
evaluation/Actions Min         -0.99856985
evaluation/Num Paths           10
evaluation/Average Returns     457.6027331466474
time/data storing (s)          0.03244058042764664
time/evaluation sampling (s)   110.39406274165958
time/exploration sampling (s)  110.75438733585179
time/logging (s)               0.030404777266085148
time/saving (s)                0.012536984868347645
time/training (s)              9.29099004715681
time/epoch (s)                 230.51482246723026
time/total (s)                 51232.8560461849
Epoch                          218
-----------------------------  ---------------------
2023-08-01 08:11:52.152888 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 219 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3705.9312]
trainer/QF1 Loss               0.134145
trainer/QF2 Loss               0.12987849
trainer/Policy Loss            -80.7149
trainer/Q1 Predictions Mean    92.1412
trainer/Q1 Predictions Std     7.786179
trainer/Q1 Predictions Max     100.97639
trainer/Q1 Predictions Min     58.56307
trainer/Q2 Predictions Mean    92.19383
trainer/Q2 Predictions Std     7.7756143
trainer/Q2 Predictions Max     101.22833
trainer/Q2 Predictions Min     58.27363
trainer/Q Targets Mean         92.01221
trainer/Q Targets Std          7.749289
trainer/Q Targets Max          100.76894
trainer/Q Targets Min          58.657413
trainer/Log Pis Mean           11.6219225
trainer/Log Pis Std            8.147355
trainer/Log Pis Max            48.19106
trainer/Log Pis Min            -6.2926884
trainer/Policy mu Mean         0.03284819
trainer/Policy mu Std          1.5472307
trainer/Policy mu Max          5.514489
trainer/Policy mu Min          -5.1862936
trainer/Policy log std Mean    -0.7590197
trainer/Policy log std Std     0.2717171
trainer/Policy log std Max     0.14834559
trainer/Policy log std Min     -1.7939467
trainer/Alpha                  0.002786441473290324
trainer/Alpha Loss             -2.224119186401367
exploration/num steps total    1101000
exploration/num paths total    2202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9426937602768217
exploration/Rewards Std        0.08170101929673919
exploration/Rewards Max        0.9797040113753142
exploration/Rewards Min        0.496498726491709
exploration/Returns Mean       471.34688013841094
exploration/Returns Std        2.8907753273946315
exploration/Returns Max        476.22168172258597
exploration/Returns Min        467.3142956235827
exploration/Actions Mean       0.04271368
exploration/Actions Std        0.60914403
exploration/Actions Max        0.99969524
exploration/Actions Min        -0.99986196
exploration/Num Paths          10
exploration/Average Returns    471.34688013841094
evaluation/num steps total     1100000
evaluation/num paths total     2200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9495454961998694
evaluation/Rewards Std         0.07043178207597452
evaluation/Rewards Max         0.9792647108933746
evaluation/Rewards Min         0.4946870380343711
evaluation/Returns Mean        474.7727480999347
evaluation/Returns Std         2.0201277980962287
evaluation/Returns Max         477.84915824452156
evaluation/Returns Min         470.91905773307974
evaluation/ExplReturns Mean    474.7727480999347
evaluation/ExplReturns Std     2.0201277980962287
evaluation/ExplReturns Max     477.84915824452156
evaluation/ExplReturns Min     470.91905773307974
evaluation/Actions Mean        0.057147693
evaluation/Actions Std         0.5384945
evaluation/Actions Max         0.9961065
evaluation/Actions Min         -0.9986275
evaluation/Num Paths           10
evaluation/Average Returns     474.7727480999347
time/data storing (s)          0.03238997049629688
time/evaluation sampling (s)   110.4217489566654
time/exploration sampling (s)  111.06650321744382
time/logging (s)               0.030486231669783592
time/saving (s)                0.010269297286868095
time/training (s)              9.378750002011657
time/epoch (s)                 230.94014767557383
time/total (s)                 51463.798764555715
Epoch                          219
-----------------------------  --------------------
2023-08-01 08:15:44.078363 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 220 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3330.2234]
trainer/QF1 Loss               0.14389136
trainer/QF2 Loss               0.14076278
trainer/Policy Loss            -80.39256
trainer/Q1 Predictions Mean    91.62666
trainer/Q1 Predictions Std     7.5030937
trainer/Q1 Predictions Max     100.6109
trainer/Q1 Predictions Min     73.16769
trainer/Q2 Predictions Mean    91.64075
trainer/Q2 Predictions Std     7.536723
trainer/Q2 Predictions Max     100.654495
trainer/Q2 Predictions Min     72.53999
trainer/Q Targets Mean         91.841354
trainer/Q Targets Std          7.4804263
trainer/Q Targets Max          100.979546
trainer/Q Targets Min          73.39473
trainer/Log Pis Mean           11.418988
trainer/Log Pis Std            7.9239616
trainer/Log Pis Max            37.488503
trainer/Log Pis Min            -6.532571
trainer/Policy mu Mean         0.13447787
trainer/Policy mu Std          1.5652499
trainer/Policy mu Max          5.9052496
trainer/Policy mu Min          -5.3083324
trainer/Policy log std Mean    -0.7345962
trainer/Policy log std Std     0.2555501
trainer/Policy log std Max     0.055001974
trainer/Policy log std Min     -1.6777707
trainer/Alpha                  0.0027932182420045137
trainer/Alpha Loss             -3.4166855812072754
exploration/num steps total    1106000
exploration/num paths total    2212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9348358441486582
exploration/Rewards Std        0.09123738953818393
exploration/Rewards Max        0.9795743676809775
exploration/Rewards Min        0.4980809264817884
exploration/Returns Mean       467.4179220743293
exploration/Returns Std        6.8463087107974845
exploration/Returns Max        471.98476176604595
exploration/Returns Min        447.99777835845936
exploration/Actions Mean       0.07412674
exploration/Actions Std        0.62066364
exploration/Actions Max        0.9996611
exploration/Actions Min        -0.9998594
exploration/Num Paths          10
exploration/Average Returns    467.4179220743293
evaluation/num steps total     1105000
evaluation/num paths total     2210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8489473202727813
evaluation/Rewards Std         0.125568461482174
evaluation/Rewards Max         0.9786427456925662
evaluation/Rewards Min         0.4905980484861429
evaluation/Returns Mean        424.4736601363905
evaluation/Returns Std         51.59927841835238
evaluation/Returns Max         469.5366764405574
evaluation/Returns Min         360.91863166257167
evaluation/ExplReturns Mean    424.4736601363905
evaluation/ExplReturns Std     51.59927841835238
evaluation/ExplReturns Max     469.5366764405574
evaluation/ExplReturns Min     360.91863166257167
evaluation/Actions Mean        0.06844696
evaluation/Actions Std         0.5273158
evaluation/Actions Max         0.99844146
evaluation/Actions Min         -0.9992259
evaluation/Num Paths           10
evaluation/Average Returns     424.4736601363905
time/data storing (s)          0.03200595173984766
time/evaluation sampling (s)   111.27881087269634
time/exploration sampling (s)  110.92484598979354
time/logging (s)               0.030399230308830738
time/saving (s)                0.011882100254297256
time/training (s)              9.642742832191288
time/epoch (s)                 231.92068697698414
time/total (s)                 51695.72201561555
Epoch                          220
-----------------------------  ---------------------
2023-08-01 08:19:33.799257 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 221 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3337.8225]
trainer/QF1 Loss               0.16271792
trainer/QF2 Loss               0.12691107
trainer/Policy Loss            -81.32922
trainer/Q1 Predictions Mean    93.07779
trainer/Q1 Predictions Std     6.685981
trainer/Q1 Predictions Max     100.556885
trainer/Q1 Predictions Min     72.59987
trainer/Q2 Predictions Mean    93.15755
trainer/Q2 Predictions Std     6.713587
trainer/Q2 Predictions Max     100.76185
trainer/Q2 Predictions Min     73.801865
trainer/Q Targets Mean         93.30189
trainer/Q Targets Std          6.7205944
trainer/Q Targets Max          100.80808
trainer/Q Targets Min          73.82459
trainer/Log Pis Mean           11.932745
trainer/Log Pis Std            7.5184746
trainer/Log Pis Max            32.107746
trainer/Log Pis Min            -3.1353614
trainer/Policy mu Mean         -0.12874411
trainer/Policy mu Std          1.5621796
trainer/Policy mu Max          5.5406027
trainer/Policy mu Min          -4.5576353
trainer/Policy log std Mean    -0.76885253
trainer/Policy log std Std     0.27426094
trainer/Policy log std Max     0.020256877
trainer/Policy log std Min     -1.6717885
trainer/Alpha                  0.0027255562599748373
trainer/Alpha Loss             -0.39716780185699463
exploration/num steps total    1111000
exploration/num paths total    2222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9448377719316486
exploration/Rewards Std        0.06853800652013273
exploration/Rewards Max        0.9783977904479775
exploration/Rewards Min        0.49947628537532557
exploration/Returns Mean       472.41888596582413
exploration/Returns Std        3.385826410791103
exploration/Returns Max        477.01385412325135
exploration/Returns Min        465.83909142826883
exploration/Actions Mean       0.020315494
exploration/Actions Std        0.624967
exploration/Actions Max        0.9998996
exploration/Actions Min        -0.99985564
exploration/Num Paths          10
exploration/Average Returns    472.41888596582413
evaluation/num steps total     1110000
evaluation/num paths total     2220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9434181579569683
evaluation/Rewards Std         0.0677909319813639
evaluation/Rewards Max         0.9738284134612938
evaluation/Rewards Min         0.5040357160498717
evaluation/Returns Mean        471.70907897848394
evaluation/Returns Std         3.215063538159516
evaluation/Returns Max         476.00283341157234
evaluation/Returns Min         465.64236825001876
evaluation/ExplReturns Mean    471.70907897848394
evaluation/ExplReturns Std     3.215063538159516
evaluation/ExplReturns Max     476.00283341157234
evaluation/ExplReturns Min     465.64236825001876
evaluation/Actions Mean        0.02609073
evaluation/Actions Std         0.5799405
evaluation/Actions Max         0.99853194
evaluation/Actions Min         -0.9988258
evaluation/Num Paths           10
evaluation/Average Returns     471.70907897848394
time/data storing (s)          0.032229628413915634
time/evaluation sampling (s)   109.65405761543661
time/exploration sampling (s)  110.31861831620336
time/logging (s)               0.030543033964931965
time/saving (s)                0.010391912423074245
time/training (s)              9.670561452396214
time/epoch (s)                 229.7164019588381
time/total (s)                 51925.4408934433
Epoch                          221
-----------------------------  ---------------------
2023-08-01 08:23:24.494064 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 222 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3356.2937]
trainer/QF1 Loss               0.114286676
trainer/QF2 Loss               0.111383915
trainer/Policy Loss            -80.60019
trainer/Q1 Predictions Mean    92.7027
trainer/Q1 Predictions Std     6.9219775
trainer/Q1 Predictions Max     100.71585
trainer/Q1 Predictions Min     67.85254
trainer/Q2 Predictions Mean    92.71079
trainer/Q2 Predictions Std     6.9206033
trainer/Q2 Predictions Max     100.90653
trainer/Q2 Predictions Min     67.77262
trainer/Q Targets Mean         92.768074
trainer/Q Targets Std          6.8250527
trainer/Q Targets Max          100.77053
trainer/Q Targets Min          68.4407
trainer/Log Pis Mean           12.276609
trainer/Log Pis Std            8.478847
trainer/Log Pis Max            42.71196
trainer/Log Pis Min            -4.180539
trainer/Policy mu Mean         -0.030955905
trainer/Policy mu Std          1.6027352
trainer/Policy mu Max          4.635026
trainer/Policy mu Min          -4.696593
trainer/Policy log std Mean    -0.74905586
trainer/Policy log std Std     0.26960662
trainer/Policy log std Max     0.22358179
trainer/Policy log std Min     -1.7971345
trainer/Alpha                  0.0027973433025181293
trainer/Alpha Loss             1.6262180805206299
exploration/num steps total    1116000
exploration/num paths total    2232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9548021221054176
exploration/Rewards Std        0.05307739403562676
exploration/Rewards Max        0.9794231363502942
exploration/Rewards Min        0.49281850786716624
exploration/Returns Mean       477.40106105270877
exploration/Returns Std        1.4841076912648752
exploration/Returns Max        478.70729409429055
exploration/Returns Min        474.0446339531562
exploration/Actions Mean       0.020235611
exploration/Actions Std        0.60742587
exploration/Actions Max        0.9992726
exploration/Actions Min        -0.99996334
exploration/Num Paths          10
exploration/Average Returns    477.40106105270877
evaluation/num steps total     1115000
evaluation/num paths total     2230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9022045312155784
evaluation/Rewards Std         0.11058147637223632
evaluation/Rewards Max         0.977091397227455
evaluation/Rewards Min         0.5028824461845629
evaluation/Returns Mean        451.1022656077892
evaluation/Returns Std         47.860862868588626
evaluation/Returns Max         478.40625462097205
evaluation/Returns Min         355.40540260767466
evaluation/ExplReturns Mean    451.1022656077892
evaluation/ExplReturns Std     47.860862868588626
evaluation/ExplReturns Max     478.40625462097205
evaluation/ExplReturns Min     355.40540260767466
evaluation/Actions Mean        0.00673631
evaluation/Actions Std         0.55153495
evaluation/Actions Max         0.9967017
evaluation/Actions Min         -0.99932206
evaluation/Num Paths           10
evaluation/Average Returns     451.1022656077892
time/data storing (s)          0.03160057310014963
time/evaluation sampling (s)   110.33798941224813
time/exploration sampling (s)  110.68514344003052
time/logging (s)               0.031471370719373226
time/saving (s)                0.012729437090456486
time/training (s)              9.592157051898539
time/epoch (s)                 230.69109128508717
time/total (s)                 52156.13447266817
Epoch                          222
-----------------------------  ---------------------
2023-08-01 08:27:14.886782 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 223 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4571.2075]
trainer/QF1 Loss               0.11056009
trainer/QF2 Loss               0.11425905
trainer/Policy Loss            -81.60045
trainer/Q1 Predictions Mean    92.75501
trainer/Q1 Predictions Std     7.3436007
trainer/Q1 Predictions Max     101.511856
trainer/Q1 Predictions Min     67.146416
trainer/Q2 Predictions Mean    92.72872
trainer/Q2 Predictions Std     7.3634515
trainer/Q2 Predictions Max     101.46829
trainer/Q2 Predictions Min     66.95052
trainer/Q Targets Mean         92.824104
trainer/Q Targets Std          7.360477
trainer/Q Targets Max          101.23628
trainer/Q Targets Min          67.0804
trainer/Log Pis Mean           11.3077135
trainer/Log Pis Std            8.343998
trainer/Log Pis Max            36.119377
trainer/Log Pis Min            -4.0936995
trainer/Policy mu Mean         -0.06309697
trainer/Policy mu Std          1.5610957
trainer/Policy mu Max          4.595484
trainer/Policy mu Min          -5.0380144
trainer/Policy log std Mean    -0.7247395
trainer/Policy log std Std     0.2813479
trainer/Policy log std Max     0.25729173
trainer/Policy log std Min     -1.6904093
trainer/Alpha                  0.002843889407813549
trainer/Alpha Loss             -4.058602809906006
exploration/num steps total    1121000
exploration/num paths total    2242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9536169308662579
exploration/Rewards Std        0.05576949835463721
exploration/Rewards Max        0.9797478758326105
exploration/Rewards Min        0.49686166352384087
exploration/Returns Mean       476.8084654331289
exploration/Returns Std        2.7335020802832224
exploration/Returns Max        480.77899532023315
exploration/Returns Min        469.5055855979659
exploration/Actions Mean       0.026300382
exploration/Actions Std        0.5966023
exploration/Actions Max        0.9998778
exploration/Actions Min        -0.99998486
exploration/Num Paths          10
exploration/Average Returns    476.8084654331289
evaluation/num steps total     1120000
evaluation/num paths total     2240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9499913448989824
evaluation/Rewards Std         0.05507885734366105
evaluation/Rewards Max         0.9774897307358454
evaluation/Rewards Min         0.49846111538554105
evaluation/Returns Mean        474.9956724494913
evaluation/Returns Std         1.676758842513912
evaluation/Returns Max         476.641043410484
evaluation/Returns Min         471.9622829334386
evaluation/ExplReturns Mean    474.9956724494913
evaluation/ExplReturns Std     1.676758842513912
evaluation/ExplReturns Max     476.641043410484
evaluation/ExplReturns Min     471.9622829334386
evaluation/Actions Mean        0.0367684
evaluation/Actions Std         0.468949
evaluation/Actions Max         0.99926573
evaluation/Actions Min         -0.9991874
evaluation/Num Paths           10
evaluation/Average Returns     474.9956724494913
time/data storing (s)          0.031804769299924374
time/evaluation sampling (s)   109.34326725266874
time/exploration sampling (s)  111.35397196840495
time/logging (s)               0.030608140863478184
time/saving (s)                0.012611417099833488
time/training (s)              9.61484697367996
time/epoch (s)                 230.38711052201688
time/total (s)                 52386.52417171467
Epoch                          223
-----------------------------  --------------------
2023-08-01 08:31:06.675365 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 224 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4488.63]
trainer/QF1 Loss               0.12031673
trainer/QF2 Loss               0.111858845
trainer/Policy Loss            -79.96972
trainer/Q1 Predictions Mean    91.803696
trainer/Q1 Predictions Std     7.871668
trainer/Q1 Predictions Max     100.42046
trainer/Q1 Predictions Min     62.446697
trainer/Q2 Predictions Mean    91.87466
trainer/Q2 Predictions Std     7.9219604
trainer/Q2 Predictions Max     100.3273
trainer/Q2 Predictions Min     62.424156
trainer/Q Targets Mean         91.8591
trainer/Q Targets Std          7.9598556
trainer/Q Targets Max          100.88742
trainer/Q Targets Min          61.912033
trainer/Log Pis Mean           12.043222
trainer/Log Pis Std            8.559943
trainer/Log Pis Max            40.217213
trainer/Log Pis Min            -3.2957215
trainer/Policy mu Mean         0.12907384
trainer/Policy mu Std          1.6025892
trainer/Policy mu Max          5.769891
trainer/Policy mu Min          -6.0338717
trainer/Policy log std Mean    -0.7278101
trainer/Policy log std Std     0.26743796
trainer/Policy log std Max     0.110456586
trainer/Policy log std Min     -1.6685132
trainer/Alpha                  0.002663170453161001
trainer/Alpha Loss             0.25622832775115967
exploration/num steps total    1126000
exploration/num paths total    2252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9582479287990918
exploration/Rewards Std        0.0571932330959141
exploration/Rewards Max        0.9797371724705987
exploration/Rewards Min        0.4950628879287763
exploration/Returns Mean       479.1239643995459
exploration/Returns Std        1.1838761642274247
exploration/Returns Max        480.8427316505637
exploration/Returns Min        477.2682051505405
exploration/Actions Mean       0.0034773569
exploration/Actions Std        0.58978075
exploration/Actions Max        0.9995608
exploration/Actions Min        -0.9999161
exploration/Num Paths          10
exploration/Average Returns    479.1239643995459
evaluation/num steps total     1125000
evaluation/num paths total     2250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9598418421544382
evaluation/Rewards Std         0.058121013577594485
evaluation/Rewards Max         0.9795372366108824
evaluation/Rewards Min         0.4895834387204396
evaluation/Returns Mean        479.920921077219
evaluation/Returns Std         0.743676799512196
evaluation/Returns Max         481.4559659200175
evaluation/Returns Min         478.62202964975336
evaluation/ExplReturns Mean    479.920921077219
evaluation/ExplReturns Std     0.743676799512196
evaluation/ExplReturns Max     481.4559659200175
evaluation/ExplReturns Min     478.62202964975336
evaluation/Actions Mean        0.004046292
evaluation/Actions Std         0.49462733
evaluation/Actions Max         0.99618435
evaluation/Actions Min         -0.9991463
evaluation/Num Paths           10
evaluation/Average Returns     479.920921077219
time/data storing (s)          0.031937479972839355
time/evaluation sampling (s)   110.11386411543936
time/exploration sampling (s)  111.90061436034739
time/logging (s)               0.031038397923111916
time/saving (s)                0.010824725963175297
time/training (s)              9.696032717823982
time/epoch (s)                 231.78431179746985
time/total (s)                 52618.310961678624
Epoch                          224
-----------------------------  --------------------
2023-08-01 08:34:56.809402 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 225 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4442.8984]
trainer/QF1 Loss               0.11234562
trainer/QF2 Loss               0.11900836
trainer/Policy Loss            -81.5807
trainer/Q1 Predictions Mean    92.915115
trainer/Q1 Predictions Std     7.1324687
trainer/Q1 Predictions Max     100.910286
trainer/Q1 Predictions Min     68.73739
trainer/Q2 Predictions Mean    92.83859
trainer/Q2 Predictions Std     7.151836
trainer/Q2 Predictions Max     100.73179
trainer/Q2 Predictions Min     68.62173
trainer/Q Targets Mean         92.88114
trainer/Q Targets Std          7.105825
trainer/Q Targets Max          100.80338
trainer/Q Targets Min          68.20838
trainer/Log Pis Mean           11.474524
trainer/Log Pis Std            8.6043625
trainer/Log Pis Max            43.35058
trainer/Log Pis Min            -9.208028
trainer/Policy mu Mean         0.017940097
trainer/Policy mu Std          1.5833029
trainer/Policy mu Max          5.8543553
trainer/Policy mu Min          -5.6559544
trainer/Policy log std Mean    -0.74022985
trainer/Policy log std Std     0.26648882
trainer/Policy log std Max     0.07297692
trainer/Policy log std Min     -1.7170506
trainer/Alpha                  0.002635848941281438
trainer/Alpha Loss             -3.120565414428711
exploration/num steps total    1131000
exploration/num paths total    2262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9498942333396834
exploration/Rewards Std        0.06726702935333974
exploration/Rewards Max        0.9796391780021161
exploration/Rewards Min        0.49222088236470934
exploration/Returns Mean       474.9471166698415
exploration/Returns Std        2.697207455078319
exploration/Returns Max        478.8620355239431
exploration/Returns Min        470.47622901292453
exploration/Actions Mean       0.015537441
exploration/Actions Std        0.60182816
exploration/Actions Max        0.99965805
exploration/Actions Min        -0.99979866
exploration/Num Paths          10
exploration/Average Returns    474.9471166698415
evaluation/num steps total     1130000
evaluation/num paths total     2260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9506748076844564
evaluation/Rewards Std         0.06703665032493658
evaluation/Rewards Max         0.9783011384849382
evaluation/Rewards Min         0.4889014113057196
evaluation/Returns Mean        475.3374038422282
evaluation/Returns Std         2.3356613024050987
evaluation/Returns Max         478.7208614878459
evaluation/Returns Min         470.2517841892442
evaluation/ExplReturns Mean    475.3374038422282
evaluation/ExplReturns Std     2.3356613024050987
evaluation/ExplReturns Max     478.7208614878459
evaluation/ExplReturns Min     470.2517841892442
evaluation/Actions Mean        0.006264454
evaluation/Actions Std         0.5402568
evaluation/Actions Max         0.99662226
evaluation/Actions Min         -0.9987246
evaluation/Num Paths           10
evaluation/Average Returns     475.3374038422282
time/data storing (s)          0.032520001754164696
time/evaluation sampling (s)   109.8501334991306
time/exploration sampling (s)  110.54846708569676
time/logging (s)               0.031995161436498165
time/saving (s)                0.011821702122688293
time/training (s)              9.655282561667264
time/epoch (s)                 230.13022001180798
time/total (s)                 52848.443698551506
Epoch                          225
-----------------------------  --------------------
2023-08-01 08:38:48.555344 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 226 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4525.403]
trainer/QF1 Loss               0.12762739
trainer/QF2 Loss               0.12214509
trainer/Policy Loss            -82.16391
trainer/Q1 Predictions Mean    93.97571
trainer/Q1 Predictions Std     7.007479
trainer/Q1 Predictions Max     101.29415
trainer/Q1 Predictions Min     71.5523
trainer/Q2 Predictions Mean    93.977936
trainer/Q2 Predictions Std     6.9880576
trainer/Q2 Predictions Max     101.10364
trainer/Q2 Predictions Min     71.19872
trainer/Q Targets Mean         93.81587
trainer/Q Targets Std          6.940614
trainer/Q Targets Max          101.30718
trainer/Q Targets Min          71.549904
trainer/Log Pis Mean           11.987872
trainer/Log Pis Std            8.890411
trainer/Log Pis Max            40.98797
trainer/Log Pis Min            -6.586161
trainer/Policy mu Mean         0.025675364
trainer/Policy mu Std          1.5773902
trainer/Policy mu Max          7.230894
trainer/Policy mu Min          -4.424555
trainer/Policy log std Mean    -0.77067906
trainer/Policy log std Std     0.28261438
trainer/Policy log std Max     0.12178375
trainer/Policy log std Min     -1.7362771
trainer/Alpha                  0.0026491256430745125
trainer/Alpha Loss             -0.07196056842803955
exploration/num steps total    1136000
exploration/num paths total    2272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9521467176096347
exploration/Rewards Std        0.06916208714507845
exploration/Rewards Max        0.9795172157774072
exploration/Rewards Min        0.4929356891746112
exploration/Returns Mean       476.0733588048173
exploration/Returns Std        2.424571565882304
exploration/Returns Max        481.0914310674789
exploration/Returns Min        472.540189675411
exploration/Actions Mean       0.07246573
exploration/Actions Std        0.60631245
exploration/Actions Max        0.9997793
exploration/Actions Min        -0.99977607
exploration/Num Paths          10
exploration/Average Returns    476.0733588048173
evaluation/num steps total     1135000
evaluation/num paths total     2270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9519998864910438
evaluation/Rewards Std         0.07080823682916772
evaluation/Rewards Max         0.9789779645355865
evaluation/Rewards Min         0.48927364031853743
evaluation/Returns Mean        475.9999432455219
evaluation/Returns Std         2.717778485455941
evaluation/Returns Max         481.38969343255894
evaluation/Returns Min         474.0287465660926
evaluation/ExplReturns Mean    475.9999432455219
evaluation/ExplReturns Std     2.717778485455941
evaluation/ExplReturns Max     481.38969343255894
evaluation/ExplReturns Min     474.0287465660926
evaluation/Actions Mean        0.07503508
evaluation/Actions Std         0.5319211
evaluation/Actions Max         0.9984008
evaluation/Actions Min         -0.9988337
evaluation/Num Paths           10
evaluation/Average Returns     475.9999432455219
time/data storing (s)          0.032082254998385906
time/evaluation sampling (s)   110.7521051587537
time/exploration sampling (s)  111.79477994889021
time/logging (s)               0.03088628128170967
time/saving (s)                0.010233544744551182
time/training (s)              9.119945269078016
time/epoch (s)                 231.74003245774657
time/total (s)                 53080.18633143604
Epoch                          226
-----------------------------  ---------------------
2023-08-01 08:42:40.493917 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 227 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4489.945]
trainer/QF1 Loss               0.17083193
trainer/QF2 Loss               0.1368261
trainer/Policy Loss            -81.16586
trainer/Q1 Predictions Mean    93.182014
trainer/Q1 Predictions Std     6.324261
trainer/Q1 Predictions Max     102.034325
trainer/Q1 Predictions Min     75.78802
trainer/Q2 Predictions Mean    93.27431
trainer/Q2 Predictions Std     6.2874913
trainer/Q2 Predictions Max     102.28688
trainer/Q2 Predictions Min     75.69171
trainer/Q Targets Mean         93.38248
trainer/Q Targets Std          6.33862
trainer/Q Targets Max          102.22372
trainer/Q Targets Min          75.828995
trainer/Log Pis Mean           12.221279
trainer/Log Pis Std            8.5897455
trainer/Log Pis Max            46.430634
trainer/Log Pis Min            -5.6572165
trainer/Policy mu Mean         -0.028587177
trainer/Policy mu Std          1.6316516
trainer/Policy mu Max          5.6301284
trainer/Policy mu Min          -4.989279
trainer/Policy log std Mean    -0.73563594
trainer/Policy log std Std     0.27907988
trainer/Policy log std Max     0.087527364
trainer/Policy log std Min     -1.7397321
trainer/Alpha                  0.0026225983165204525
trainer/Alpha Loss             1.3152059316635132
exploration/num steps total    1141000
exploration/num paths total    2282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.95610605794718
exploration/Rewards Std        0.05949233860189598
exploration/Rewards Max        0.9797704976982292
exploration/Rewards Min        0.4925475523984165
exploration/Returns Mean       478.05302897358996
exploration/Returns Std        1.484500034560846
exploration/Returns Max        479.79176810784355
exploration/Returns Min        475.5770518397827
exploration/Actions Mean       0.04101143
exploration/Actions Std        0.6478866
exploration/Actions Max        0.999755
exploration/Actions Min        -0.99968183
exploration/Num Paths          10
exploration/Average Returns    478.05302897358996
evaluation/num steps total     1140000
evaluation/num paths total     2280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9547868721914762
evaluation/Rewards Std         0.06250212836865235
evaluation/Rewards Max         0.9798762306391025
evaluation/Rewards Min         0.48751219943795726
evaluation/Returns Mean        477.39343609573797
evaluation/Returns Std         0.8355731509955825
evaluation/Returns Max         479.00828633690475
evaluation/Returns Min         476.43091267291055
evaluation/ExplReturns Mean    477.39343609573797
evaluation/ExplReturns Std     0.8355731509955825
evaluation/ExplReturns Max     479.00828633690475
evaluation/ExplReturns Min     476.43091267291055
evaluation/Actions Mean        0.06432218
evaluation/Actions Std         0.52836394
evaluation/Actions Max         0.99803483
evaluation/Actions Min         -0.99893636
evaluation/Num Paths           10
evaluation/Average Returns     477.39343609573797
time/data storing (s)          0.03216252941638231
time/evaluation sampling (s)   109.63718001637608
time/exploration sampling (s)  112.56485643982887
time/logging (s)               0.030399683862924576
time/saving (s)                0.012093818746507168
time/training (s)              9.656671807169914
time/epoch (s)                 231.93336429540068
time/total (s)                 53312.12221309263
Epoch                          227
-----------------------------  ---------------------
2023-08-01 08:46:33.488738 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 228 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4468.694]
trainer/QF1 Loss               0.0881095
trainer/QF2 Loss               0.08395313
trainer/Policy Loss            -81.639725
trainer/Q1 Predictions Mean    93.41757
trainer/Q1 Predictions Std     6.8368764
trainer/Q1 Predictions Max     101.2775
trainer/Q1 Predictions Min     69.730286
trainer/Q2 Predictions Mean    93.385956
trainer/Q2 Predictions Std     6.853953
trainer/Q2 Predictions Max     101.36091
trainer/Q2 Predictions Min     69.73317
trainer/Q Targets Mean         93.40805
trainer/Q Targets Std          6.865827
trainer/Q Targets Max          101.81703
trainer/Q Targets Min          69.08001
trainer/Log Pis Mean           11.890044
trainer/Log Pis Std            7.5768785
trainer/Log Pis Max            33.420593
trainer/Log Pis Min            -4.2974052
trainer/Policy mu Mean         -0.21469109
trainer/Policy mu Std          1.5421367
trainer/Policy mu Max          4.5408306
trainer/Policy mu Min          -4.825672
trainer/Policy log std Mean    -0.7591339
trainer/Policy log std Std     0.28111652
trainer/Policy log std Max     0.048866868
trainer/Policy log std Min     -1.6811184
trainer/Alpha                  0.00274991849437356
trainer/Alpha Loss             -0.6483235955238342
exploration/num steps total    1146000
exploration/num paths total    2292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.945815969505278
exploration/Rewards Std        0.0658479210833931
exploration/Rewards Max        0.9764217152152878
exploration/Rewards Min        0.5026464268645661
exploration/Returns Mean       472.907984752639
exploration/Returns Std        2.426800499335758
exploration/Returns Max        477.0678951992417
exploration/Returns Min        469.9305245681748
exploration/Actions Mean       0.04019679
exploration/Actions Std        0.6072106
exploration/Actions Max        0.99978495
exploration/Actions Min        -0.99995106
exploration/Num Paths          10
exploration/Average Returns    472.907984752639
evaluation/num steps total     1145000
evaluation/num paths total     2290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9436791047255855
evaluation/Rewards Std         0.07021783217271564
evaluation/Rewards Max         0.9740976082413142
evaluation/Rewards Min         0.49248850761885543
evaluation/Returns Mean        471.83955236279263
evaluation/Returns Std         0.70808611530184
evaluation/Returns Max         472.70273173854866
evaluation/Returns Min         470.3560911112656
evaluation/ExplReturns Mean    471.83955236279263
evaluation/ExplReturns Std     0.70808611530184
evaluation/ExplReturns Max     472.70273173854866
evaluation/ExplReturns Min     470.3560911112656
evaluation/Actions Mean        0.04245727
evaluation/Actions Std         0.52557236
evaluation/Actions Max         0.99547315
evaluation/Actions Min         -0.999154
evaluation/Num Paths           10
evaluation/Average Returns     471.83955236279263
time/data storing (s)          0.032363275066018105
time/evaluation sampling (s)   111.25120305921882
time/exploration sampling (s)  112.0207833731547
time/logging (s)               0.030554138123989105
time/saving (s)                0.010213402099907398
time/training (s)              9.645217567682266
time/epoch (s)                 232.9903348153457
time/total (s)                 53545.11498649884
Epoch                          228
-----------------------------  --------------------
2023-08-01 08:50:23.805158 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 229 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4510.1875]
trainer/QF1 Loss               0.07903136
trainer/QF2 Loss               0.08514311
trainer/Policy Loss            -83.30702
trainer/Q1 Predictions Mean    94.26477
trainer/Q1 Predictions Std     6.664489
trainer/Q1 Predictions Max     101.79808
trainer/Q1 Predictions Min     74.456
trainer/Q2 Predictions Mean    94.17578
trainer/Q2 Predictions Std     6.639009
trainer/Q2 Predictions Max     101.58498
trainer/Q2 Predictions Min     74.49431
trainer/Q Targets Mean         94.23932
trainer/Q Targets Std          6.705348
trainer/Q Targets Max          101.778114
trainer/Q Targets Min          74.56643
trainer/Log Pis Mean           11.086992
trainer/Log Pis Std            8.747223
trainer/Log Pis Max            33.348923
trainer/Log Pis Min            -6.4344325
trainer/Policy mu Mean         0.10830781
trainer/Policy mu Std          1.526539
trainer/Policy mu Max          5.2480946
trainer/Policy mu Min          -5.8659825
trainer/Policy log std Mean    -0.75038606
trainer/Policy log std Std     0.28167352
trainer/Policy log std Max     0.3917861
trainer/Policy log std Min     -1.7074564
trainer/Alpha                  0.0026810506824404
trainer/Alpha Loss             -5.406380653381348
exploration/num steps total    1151000
exploration/num paths total    2302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9603715770758061
exploration/Rewards Std        0.061429613754309054
exploration/Rewards Max        0.9799677920708337
exploration/Rewards Min        0.4945694842697761
exploration/Returns Mean       480.185788537903
exploration/Returns Std        2.6551940149691324
exploration/Returns Max        482.8676687355991
exploration/Returns Min        474.10870779781965
exploration/Actions Mean       0.038457654
exploration/Actions Std        0.5985393
exploration/Actions Max        0.99965006
exploration/Actions Min        -0.9998383
exploration/Num Paths          10
exploration/Average Returns    480.185788537903
evaluation/num steps total     1150000
evaluation/num paths total     2300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9586135240166291
evaluation/Rewards Std         0.06833861827282683
evaluation/Rewards Max         0.9800235541057973
evaluation/Rewards Min         0.4872653378488059
evaluation/Returns Mean        479.3067620083144
evaluation/Returns Std         3.0956025004096457
evaluation/Returns Max         483.9635211856959
evaluation/Returns Min         475.92208661951094
evaluation/ExplReturns Mean    479.3067620083144
evaluation/ExplReturns Std     3.0956025004096457
evaluation/ExplReturns Max     483.9635211856959
evaluation/ExplReturns Min     475.92208661951094
evaluation/Actions Mean        0.032513056
evaluation/Actions Std         0.5343583
evaluation/Actions Max         0.9981229
evaluation/Actions Min         -0.9987361
evaluation/Num Paths           10
evaluation/Average Returns     479.3067620083144
time/data storing (s)          0.03207938652485609
time/evaluation sampling (s)   109.65637672878802
time/exploration sampling (s)  110.90512564964592
time/logging (s)               0.030707024037837982
time/saving (s)                0.010275558568537235
time/training (s)              9.67731131799519
time/epoch (s)                 230.31187566556036
time/total (s)                 53775.42934557982
Epoch                          229
-----------------------------  --------------------
2023-08-01 08:54:14.190045 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 230 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4488.145]
trainer/QF1 Loss               0.10255936
trainer/QF2 Loss               0.088068485
trainer/Policy Loss            -81.65312
trainer/Q1 Predictions Mean    93.94867
trainer/Q1 Predictions Std     6.508165
trainer/Q1 Predictions Max     102.19177
trainer/Q1 Predictions Min     66.50226
trainer/Q2 Predictions Mean    93.99599
trainer/Q2 Predictions Std     6.5138936
trainer/Q2 Predictions Max     101.93314
trainer/Q2 Predictions Min     67.04202
trainer/Q Targets Mean         93.94413
trainer/Q Targets Std          6.5155497
trainer/Q Targets Max          102.02151
trainer/Q Targets Min          67.06413
trainer/Log Pis Mean           12.479086
trainer/Log Pis Std            8.598302
trainer/Log Pis Max            48.79854
trainer/Log Pis Min            -6.3380547
trainer/Policy mu Mean         0.026177248
trainer/Policy mu Std          1.5912452
trainer/Policy mu Max          4.529906
trainer/Policy mu Min          -4.6231027
trainer/Policy log std Mean    -0.75652057
trainer/Policy log std Std     0.27494574
trainer/Policy log std Max     0.110918105
trainer/Policy log std Min     -1.7308042
trainer/Alpha                  0.0026283585466444492
trainer/Alpha Loss             2.84633731842041
exploration/num steps total    1156000
exploration/num paths total    2312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9574470329869303
exploration/Rewards Std        0.0641447849065782
exploration/Rewards Max        0.9798807852923807
exploration/Rewards Min        0.49345725821287134
exploration/Returns Mean       478.7235164934652
exploration/Returns Std        1.0301786575140839
exploration/Returns Max        480.2875644590632
exploration/Returns Min        476.87945832851113
exploration/Actions Mean       0.028416542
exploration/Actions Std        0.6042501
exploration/Actions Max        0.9996526
exploration/Actions Min        -0.9998749
exploration/Num Paths          10
exploration/Average Returns    478.7235164934652
evaluation/num steps total     1155000
evaluation/num paths total     2310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9602332162188358
evaluation/Rewards Std         0.06176892327833323
evaluation/Rewards Max         0.9799043592246597
evaluation/Rewards Min         0.49670033676195735
evaluation/Returns Mean        480.1166081094178
evaluation/Returns Std         1.70969027968791
evaluation/Returns Max         481.5680178766629
evaluation/Returns Min         475.40500945696857
evaluation/ExplReturns Mean    480.1166081094178
evaluation/ExplReturns Std     1.70969027968791
evaluation/ExplReturns Max     481.5680178766629
evaluation/ExplReturns Min     475.40500945696857
evaluation/Actions Mean        0.032145895
evaluation/Actions Std         0.52741677
evaluation/Actions Max         0.99830127
evaluation/Actions Min         -0.9995735
evaluation/Num Paths           10
evaluation/Average Returns     480.1166081094178
time/data storing (s)          0.031923841685056686
time/evaluation sampling (s)   109.67194129899144
time/exploration sampling (s)  110.978989161551
time/logging (s)               0.03035144880414009
time/saving (s)                0.010895079001784325
time/training (s)              9.65575999300927
time/epoch (s)                 230.3798608230427
time/total (s)                 54005.81165250391
Epoch                          230
-----------------------------  ---------------------
2023-08-01 08:58:04.850074 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 231 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4308.9185]
trainer/QF1 Loss               0.0787026
trainer/QF2 Loss               0.07525389
trainer/Policy Loss            -82.64226
trainer/Q1 Predictions Mean    94.50939
trainer/Q1 Predictions Std     5.8874993
trainer/Q1 Predictions Max     102.29719
trainer/Q1 Predictions Min     73.73763
trainer/Q2 Predictions Mean    94.4757
trainer/Q2 Predictions Std     5.907787
trainer/Q2 Predictions Max     102.273674
trainer/Q2 Predictions Min     73.30876
trainer/Q Targets Mean         94.47342
trainer/Q Targets Std          5.9187407
trainer/Q Targets Max          102.27476
trainer/Q Targets Min          74.12556
trainer/Log Pis Mean           12.0057535
trainer/Log Pis Std            8.5365305
trainer/Log Pis Max            36.442707
trainer/Log Pis Min            -3.331996
trainer/Policy mu Mean         0.0688983
trainer/Policy mu Std          1.57015
trainer/Policy mu Max          5.6527863
trainer/Policy mu Min          -4.8114643
trainer/Policy log std Mean    -0.76019675
trainer/Policy log std Std     0.28464654
trainer/Policy log std Max     0.09777868
trainer/Policy log std Min     -1.7199264
trainer/Alpha                  0.002625357359647751
trainer/Alpha Loss             0.0341930091381073
exploration/num steps total    1161000
exploration/num paths total    2322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9393160461826977
exploration/Rewards Std        0.08223139308031209
exploration/Rewards Max        0.9791613393782888
exploration/Rewards Min        0.48726392170115107
exploration/Returns Mean       469.6580230913488
exploration/Returns Std        7.433925175871598
exploration/Returns Max        478.6891927929901
exploration/Returns Min        450.1723772877576
exploration/Actions Mean       0.051796984
exploration/Actions Std        0.59695154
exploration/Actions Max        0.99987894
exploration/Actions Min        -0.99989253
exploration/Num Paths          10
exploration/Average Returns    469.6580230913488
evaluation/num steps total     1160000
evaluation/num paths total     2320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9548615968477209
evaluation/Rewards Std         0.06292999901054969
evaluation/Rewards Max         0.9789814944195513
evaluation/Rewards Min         0.5025178027120959
evaluation/Returns Mean        477.4307984238603
evaluation/Returns Std         0.806548100099488
evaluation/Returns Max         478.3405636889793
evaluation/Returns Min         475.25463756548976
evaluation/ExplReturns Mean    477.4307984238603
evaluation/ExplReturns Std     0.806548100099488
evaluation/ExplReturns Max     478.3405636889793
evaluation/ExplReturns Min     475.25463756548976
evaluation/Actions Mean        0.05703675
evaluation/Actions Std         0.52158153
evaluation/Actions Max         0.99696255
evaluation/Actions Min         -0.9993452
evaluation/Num Paths           10
evaluation/Average Returns     477.4307984238603
time/data storing (s)          0.03206912614405155
time/evaluation sampling (s)   109.76824045740068
time/exploration sampling (s)  111.11301596369594
time/logging (s)               0.030361153185367584
time/saving (s)                0.012850268743932247
time/training (s)              9.698706501163542
time/epoch (s)                 230.65524347033352
time/total (s)                 54236.46946071368
Epoch                          231
-----------------------------  --------------------
2023-08-01 09:01:57.587298 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 232 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4318.432]
trainer/QF1 Loss               0.107354686
trainer/QF2 Loss               0.10012421
trainer/Policy Loss            -83.32626
trainer/Q1 Predictions Mean    94.63809
trainer/Q1 Predictions Std     6.490524
trainer/Q1 Predictions Max     102.02906
trainer/Q1 Predictions Min     64.67824
trainer/Q2 Predictions Mean    94.677284
trainer/Q2 Predictions Std     6.491866
trainer/Q2 Predictions Max     102.12807
trainer/Q2 Predictions Min     64.03036
trainer/Q Targets Mean         94.675934
trainer/Q Targets Std          6.5219684
trainer/Q Targets Max          101.81534
trainer/Q Targets Min          64.503265
trainer/Log Pis Mean           11.464491
trainer/Log Pis Std            8.579864
trainer/Log Pis Max            50.06594
trainer/Log Pis Min            -5.2384043
trainer/Policy mu Mean         0.09016629
trainer/Policy mu Std          1.5554417
trainer/Policy mu Max          8.70713
trainer/Policy mu Min          -4.8544145
trainer/Policy log std Mean    -0.7400215
trainer/Policy log std Std     0.27780098
trainer/Policy log std Max     0.1147207
trainer/Policy log std Min     -1.824871
trainer/Alpha                  0.002691800706088543
trainer/Alpha Loss             -3.1689391136169434
exploration/num steps total    1166000
exploration/num paths total    2332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8308806080453204
exploration/Rewards Std        0.11027703024547655
exploration/Rewards Max        0.9690293050745837
exploration/Rewards Min        0.48461776073484936
exploration/Returns Mean       415.44030402266014
exploration/Returns Std        9.175538338638853
exploration/Returns Max        432.2048560888603
exploration/Returns Min        402.04944462702633
exploration/Actions Mean       0.039724484
exploration/Actions Std        0.6078507
exploration/Actions Max        0.99990815
exploration/Actions Min        -0.99997485
exploration/Num Paths          10
exploration/Average Returns    415.44030402266014
evaluation/num steps total     1165000
evaluation/num paths total     2330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9000718650096402
evaluation/Rewards Std         0.11635988855838889
evaluation/Rewards Max         0.974426779037567
evaluation/Rewards Min         0.49042932171238285
evaluation/Returns Mean        450.03593250482
evaluation/Returns Std         36.73503386016483
evaluation/Returns Max         472.7727811576459
evaluation/Returns Min         341.61672483238846
evaluation/ExplReturns Mean    450.03593250482
evaluation/ExplReturns Std     36.73503386016483
evaluation/ExplReturns Max     472.7727811576459
evaluation/ExplReturns Min     341.61672483238846
evaluation/Actions Mean        0.0012488383
evaluation/Actions Std         0.5715962
evaluation/Actions Max         0.99937165
evaluation/Actions Min         -0.99993944
evaluation/Num Paths           10
evaluation/Average Returns     450.03593250482
time/data storing (s)          0.03238010313361883
time/evaluation sampling (s)   111.03487212583423
time/exploration sampling (s)  111.99995784368366
time/logging (s)               0.030240372754633427
time/saving (s)                0.012614207342267036
time/training (s)              9.622356805950403
time/epoch (s)                 232.7324214586988
time/total (s)                 54469.20433297381
Epoch                          232
-----------------------------  --------------------
2023-08-01 09:05:48.026691 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 233 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4542.328]
trainer/QF1 Loss               0.10929175
trainer/QF2 Loss               0.098650515
trainer/Policy Loss            -82.4052
trainer/Q1 Predictions Mean    94.4534
trainer/Q1 Predictions Std     6.080525
trainer/Q1 Predictions Max     102.41463
trainer/Q1 Predictions Min     73.761536
trainer/Q2 Predictions Mean    94.43874
trainer/Q2 Predictions Std     6.0636444
trainer/Q2 Predictions Max     102.34135
trainer/Q2 Predictions Min     73.27279
trainer/Q Targets Mean         94.52034
trainer/Q Targets Std          6.1525154
trainer/Q Targets Max          102.22333
trainer/Q Targets Min          73.512085
trainer/Log Pis Mean           12.205919
trainer/Log Pis Std            8.4621
trainer/Log Pis Max            36.56418
trainer/Log Pis Min            -3.1686785
trainer/Policy mu Mean         0.065650344
trainer/Policy mu Std          1.597402
trainer/Policy mu Max          5.722516
trainer/Policy mu Min          -5.7503943
trainer/Policy log std Mean    -0.7426853
trainer/Policy log std Std     0.2796923
trainer/Policy log std Max     0.1777143
trainer/Policy log std Min     -1.7560067
trainer/Alpha                  0.0026032153982669115
trainer/Alpha Loss             1.225407600402832
exploration/num steps total    1171000
exploration/num paths total    2342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9543988459273584
exploration/Rewards Std        0.06282522128602519
exploration/Rewards Max        0.9797306099107141
exploration/Rewards Min        0.49621560680339005
exploration/Returns Mean       477.19942296367924
exploration/Returns Std        2.1598764737451095
exploration/Returns Max        480.0113074525395
exploration/Returns Min        473.1232810131838
exploration/Actions Mean       0.05343196
exploration/Actions Std        0.5674492
exploration/Actions Max        0.9997144
exploration/Actions Min        -0.9999164
exploration/Num Paths          10
exploration/Average Returns    477.19942296367924
evaluation/num steps total     1170000
evaluation/num paths total     2340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9595208917694199
evaluation/Rewards Std         0.05462845240506093
evaluation/Rewards Max         0.9790825243982533
evaluation/Rewards Min         0.5034380808115009
evaluation/Returns Mean        479.76044588470995
evaluation/Returns Std         1.180386584219091
evaluation/Returns Max         480.7187448356223
evaluation/Returns Min         476.692401085601
evaluation/ExplReturns Mean    479.76044588470995
evaluation/ExplReturns Std     1.180386584219091
evaluation/ExplReturns Max     480.7187448356223
evaluation/ExplReturns Min     476.692401085601
evaluation/Actions Mean        0.064812295
evaluation/Actions Std         0.45678562
evaluation/Actions Max         0.99885935
evaluation/Actions Min         -0.9993222
evaluation/Num Paths           10
evaluation/Average Returns     479.76044588470995
time/data storing (s)          0.03239466715604067
time/evaluation sampling (s)   109.42566120997071
time/exploration sampling (s)  111.2416352443397
time/logging (s)               0.03055573720484972
time/saving (s)                0.010240240953862667
time/training (s)              9.694493782706559
time/epoch (s)                 230.43498088233173
time/total (s)                 54699.64180539176
Epoch                          233
-----------------------------  ---------------------
2023-08-01 09:09:40.271867 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 234 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3961.4229]
trainer/QF1 Loss               0.13025752
trainer/QF2 Loss               0.15193819
trainer/Policy Loss            -82.7237
trainer/Q1 Predictions Mean    94.43167
trainer/Q1 Predictions Std     5.953644
trainer/Q1 Predictions Max     102.71602
trainer/Q1 Predictions Min     75.670815
trainer/Q2 Predictions Mean    94.37152
trainer/Q2 Predictions Std     5.964628
trainer/Q2 Predictions Max     102.72285
trainer/Q2 Predictions Min     75.93263
trainer/Q Targets Mean         94.57127
trainer/Q Targets Std          6.0333576
trainer/Q Targets Max          102.67012
trainer/Q Targets Min          75.7979
trainer/Log Pis Mean           11.840369
trainer/Log Pis Std            8.74264
trainer/Log Pis Max            36.57788
trainer/Log Pis Min            -4.399999
trainer/Policy mu Mean         0.05666223
trainer/Policy mu Std          1.588151
trainer/Policy mu Max          5.3755383
trainer/Policy mu Min          -6.423375
trainer/Policy log std Mean    -0.75122863
trainer/Policy log std Std     0.27612552
trainer/Policy log std Max     0.21408197
trainer/Policy log std Min     -1.737469
trainer/Alpha                  0.0025286416057497263
trainer/Alpha Loss             -0.9545862674713135
exploration/num steps total    1176000
exploration/num paths total    2352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.940465327766999
exploration/Rewards Std        0.08452719360362244
exploration/Rewards Max        0.979265935008656
exploration/Rewards Min        0.49334403747501754
exploration/Returns Mean       470.2326638834996
exploration/Returns Std        6.095752070380873
exploration/Returns Max        478.6433484610718
exploration/Returns Min        458.4298995861837
exploration/Actions Mean       0.10307966
exploration/Actions Std        0.59371585
exploration/Actions Max        0.9998132
exploration/Actions Min        -0.9998926
exploration/Num Paths          10
exploration/Average Returns    470.2326638834996
evaluation/num steps total     1175000
evaluation/num paths total     2350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8917154713743004
evaluation/Rewards Std         0.10836750579107751
evaluation/Rewards Max         0.9775976501923849
evaluation/Rewards Min         0.4924158403583747
evaluation/Returns Mean        445.8577356871503
evaluation/Returns Std         27.8892281601125
evaluation/Returns Max         477.15632023569015
evaluation/Returns Min         405.027382652786
evaluation/ExplReturns Mean    445.8577356871503
evaluation/ExplReturns Std     27.8892281601125
evaluation/ExplReturns Max     477.15632023569015
evaluation/ExplReturns Min     405.027382652786
evaluation/Actions Mean        0.09809041
evaluation/Actions Std         0.4915975
evaluation/Actions Max         0.99948025
evaluation/Actions Min         -0.9997135
evaluation/Num Paths           10
evaluation/Average Returns     445.8577356871503
time/data storing (s)          0.03217652440071106
time/evaluation sampling (s)   111.10984628647566
time/exploration sampling (s)  111.41037557739764
time/logging (s)               0.030606349930167198
time/saving (s)                0.01025889627635479
time/training (s)              9.647271768189967
time/epoch (s)                 232.2405354026705
time/total (s)                 54931.88477042224
Epoch                          234
-----------------------------  ---------------------
2023-08-01 09:13:33.870590 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 235 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4122.9243]
trainer/QF1 Loss               0.0950782
trainer/QF2 Loss               0.12260443
trainer/Policy Loss            -82.62826
trainer/Q1 Predictions Mean    94.9393
trainer/Q1 Predictions Std     6.1179786
trainer/Q1 Predictions Max     102.9131
trainer/Q1 Predictions Min     68.254326
trainer/Q2 Predictions Mean    94.89903
trainer/Q2 Predictions Std     6.1084385
trainer/Q2 Predictions Max     102.83151
trainer/Q2 Predictions Min     68.27988
trainer/Q Targets Mean         94.8985
trainer/Q Targets Std          6.125887
trainer/Q Targets Max          102.95843
trainer/Q Targets Min          67.49826
trainer/Log Pis Mean           12.491081
trainer/Log Pis Std            8.384753
trainer/Log Pis Max            50.459755
trainer/Log Pis Min            -3.194403
trainer/Policy mu Mean         0.06890175
trainer/Policy mu Std          1.6072905
trainer/Policy mu Max          6.2212524
trainer/Policy mu Min          -6.0509458
trainer/Policy log std Mean    -0.7513611
trainer/Policy log std Std     0.29327643
trainer/Policy log std Max     0.64740855
trainer/Policy log std Min     -1.8218246
trainer/Alpha                  0.002571843331679702
trainer/Alpha Loss             2.928422689437866
exploration/num steps total    1181000
exploration/num paths total    2362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9441752370007708
exploration/Rewards Std        0.06838825355837161
exploration/Rewards Max        0.9774342847867854
exploration/Rewards Min        0.48884953067010645
exploration/Returns Mean       472.0876185003855
exploration/Returns Std        5.595077153494788
exploration/Returns Max        477.2310645177193
exploration/Returns Min        461.6907213325716
exploration/Actions Mean       0.12339885
exploration/Actions Std        0.56954515
exploration/Actions Max        0.9998768
exploration/Actions Min        -0.99993587
exploration/Num Paths          10
exploration/Average Returns    472.0876185003855
evaluation/num steps total     1180000
evaluation/num paths total     2360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8927747781969376
evaluation/Rewards Std         0.11183671041129865
evaluation/Rewards Max         0.976488982536398
evaluation/Rewards Min         0.4986426154045207
evaluation/Returns Mean        446.38738909846853
evaluation/Returns Std         49.60541881364811
evaluation/Returns Max         482.01294909539115
evaluation/Returns Min         360.67103115810795
evaluation/ExplReturns Mean    446.38738909846853
evaluation/ExplReturns Std     49.60541881364811
evaluation/ExplReturns Max     482.01294909539115
evaluation/ExplReturns Min     360.67103115810795
evaluation/Actions Mean        0.15999584
evaluation/Actions Std         0.5424961
evaluation/Actions Max         0.9988429
evaluation/Actions Min         -0.9988078
evaluation/Num Paths           10
evaluation/Average Returns     446.38738909846853
time/data storing (s)          0.032146161422133446
time/evaluation sampling (s)   112.18113585654646
time/exploration sampling (s)  111.70424272213131
time/logging (s)               0.03102402202785015
time/saving (s)                0.01196208130568266
time/training (s)              9.63374662771821
time/epoch (s)                 233.59425747115165
time/total (s)                 55165.48162901122
Epoch                          235
-----------------------------  --------------------
2023-08-01 09:17:26.863663 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 236 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3957.484]
trainer/QF1 Loss               0.14425683
trainer/QF2 Loss               0.106317
trainer/Policy Loss            -82.96239
trainer/Q1 Predictions Mean    94.85129
trainer/Q1 Predictions Std     5.926557
trainer/Q1 Predictions Max     101.90225
trainer/Q1 Predictions Min     60.596527
trainer/Q2 Predictions Mean    94.96614
trainer/Q2 Predictions Std     5.93492
trainer/Q2 Predictions Max     101.97907
trainer/Q2 Predictions Min     60.637875
trainer/Q Targets Mean         95.05472
trainer/Q Targets Std          5.924504
trainer/Q Targets Max          102.17546
trainer/Q Targets Min          60.87005
trainer/Log Pis Mean           12.093239
trainer/Log Pis Std            9.07597
trainer/Log Pis Max            40.46324
trainer/Log Pis Min            -4.601906
trainer/Policy mu Mean         0.24763177
trainer/Policy mu Std          1.5827008
trainer/Policy mu Max          5.941184
trainer/Policy mu Min          -4.7951937
trainer/Policy log std Mean    -0.72299784
trainer/Policy log std Std     0.26541004
trainer/Policy log std Max     0.23632479
trainer/Policy log std Min     -1.676936
trainer/Alpha                  0.0025097341276705265
trainer/Alpha Loss             0.5582675933837891
exploration/num steps total    1186000
exploration/num paths total    2372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9463226643654683
exploration/Rewards Std        0.07550907259958553
exploration/Rewards Max        0.9798812676231714
exploration/Rewards Min        0.49484768050721817
exploration/Returns Mean       473.1613321827341
exploration/Returns Std        8.20448033189593
exploration/Returns Max        479.49548838497736
exploration/Returns Min        457.91897724148777
exploration/Actions Mean       0.085681394
exploration/Actions Std        0.56567717
exploration/Actions Max        0.99930507
exploration/Actions Min        -0.9997356
exploration/Num Paths          10
exploration/Average Returns    473.1613321827341
evaluation/num steps total     1185000
evaluation/num paths total     2370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8655187088902083
evaluation/Rewards Std         0.12717478522725295
evaluation/Rewards Max         0.9797903470463649
evaluation/Rewards Min         0.4973951978945381
evaluation/Returns Mean        432.75935444510407
evaluation/Returns Std         43.02987727053532
evaluation/Returns Max         481.0157172641823
evaluation/Returns Min         362.5130314757225
evaluation/ExplReturns Mean    432.75935444510407
evaluation/ExplReturns Std     43.02987727053532
evaluation/ExplReturns Max     481.0157172641823
evaluation/ExplReturns Min     362.5130314757225
evaluation/Actions Mean        0.042103715
evaluation/Actions Std         0.476722
evaluation/Actions Max         0.99715996
evaluation/Actions Min         -0.99634224
evaluation/Num Paths           10
evaluation/Average Returns     432.75935444510407
time/data storing (s)          0.03220059908926487
time/evaluation sampling (s)   111.67281241808087
time/exploration sampling (s)  111.58928979374468
time/logging (s)               0.030664495192468166
time/saving (s)                0.012646883726119995
time/training (s)              9.650334091857076
time/epoch (s)                 232.98794828169048
time/total (s)                 55398.472062697634
Epoch                          236
-----------------------------  ---------------------
2023-08-01 09:21:18.067780 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 237 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4040.909]
trainer/QF1 Loss               0.099759944
trainer/QF2 Loss               0.10749324
trainer/Policy Loss            -82.99642
trainer/Q1 Predictions Mean    95.12369
trainer/Q1 Predictions Std     5.3281612
trainer/Q1 Predictions Max     103.21863
trainer/Q1 Predictions Min     78.965195
trainer/Q2 Predictions Mean    94.982155
trainer/Q2 Predictions Std     5.339848
trainer/Q2 Predictions Max     102.98834
trainer/Q2 Predictions Min     79.2198
trainer/Q Targets Mean         95.058105
trainer/Q Targets Std          5.289406
trainer/Q Targets Max          103.31407
trainer/Q Targets Min          79.01765
trainer/Log Pis Mean           12.178751
trainer/Log Pis Std            9.277458
trainer/Log Pis Max            42.931484
trainer/Log Pis Min            -4.7150493
trainer/Policy mu Mean         0.042719826
trainer/Policy mu Std          1.601524
trainer/Policy mu Max          6.0811973
trainer/Policy mu Min          -5.5895524
trainer/Policy log std Mean    -0.722738
trainer/Policy log std Std     0.26995552
trainer/Policy log std Max     0.28712654
trainer/Policy log std Min     -1.7003669
trainer/Alpha                  0.0024972225073724985
trainer/Alpha Loss             1.0711712837219238
exploration/num steps total    1191000
exploration/num paths total    2382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8565734507168287
exploration/Rewards Std        0.12512307570975337
exploration/Rewards Max        0.9792408866888211
exploration/Rewards Min        0.4944765845239493
exploration/Returns Mean       428.28672535841423
exploration/Returns Std        46.35975368852236
exploration/Returns Max        480.84448181155756
exploration/Returns Min        360.600038734324
exploration/Actions Mean       0.1100717
exploration/Actions Std        0.6018288
exploration/Actions Max        0.99975306
exploration/Actions Min        -0.99997616
exploration/Num Paths          10
exploration/Average Returns    428.28672535841423
evaluation/num steps total     1190000
evaluation/num paths total     2380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9348337293104702
evaluation/Rewards Std         0.09251015753475599
evaluation/Rewards Max         0.9796774192176388
evaluation/Rewards Min         0.49639257990843433
evaluation/Returns Mean        467.41686465523514
evaluation/Returns Std         33.860189061555296
evaluation/Returns Max         481.93347797807036
evaluation/Returns Min         366.3066936067623
evaluation/ExplReturns Mean    467.41686465523514
evaluation/ExplReturns Std     33.860189061555296
evaluation/ExplReturns Max     481.93347797807036
evaluation/ExplReturns Min     366.3066936067623
evaluation/Actions Mean        0.06915071
evaluation/Actions Std         0.49574006
evaluation/Actions Max         0.9983853
evaluation/Actions Min         -0.9980322
evaluation/Num Paths           10
evaluation/Average Returns     467.41686465523514
time/data storing (s)          0.032308767549693584
time/evaluation sampling (s)   110.1518937163055
time/exploration sampling (s)  111.35448412504047
time/logging (s)               0.030835573561489582
time/saving (s)                0.012742124497890472
time/training (s)              9.617195487953722
time/epoch (s)                 231.19945979490876
time/total (s)                 55629.674043929204
Epoch                          237
-----------------------------  ---------------------
2023-08-01 09:25:07.572022 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 238 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4093.5273]
trainer/QF1 Loss               0.117313795
trainer/QF2 Loss               0.09861164
trainer/Policy Loss            -83.51723
trainer/Q1 Predictions Mean    95.435196
trainer/Q1 Predictions Std     5.606921
trainer/Q1 Predictions Max     103.256744
trainer/Q1 Predictions Min     71.05674
trainer/Q2 Predictions Mean    95.54668
trainer/Q2 Predictions Std     5.611664
trainer/Q2 Predictions Max     103.18452
trainer/Q2 Predictions Min     71.05261
trainer/Q Targets Mean         95.6264
trainer/Q Targets Std          5.5872617
trainer/Q Targets Max          103.48051
trainer/Q Targets Min          71.562744
trainer/Log Pis Mean           12.075579
trainer/Log Pis Std            9.791421
trainer/Log Pis Max            40.13059
trainer/Log Pis Min            -3.876701
trainer/Policy mu Mean         0.06352962
trainer/Policy mu Std          1.5810517
trainer/Policy mu Max          4.5857725
trainer/Policy mu Min          -6.2820187
trainer/Policy log std Mean    -0.7447858
trainer/Policy log std Std     0.27524826
trainer/Policy log std Max     0.056952804
trainer/Policy log std Min     -1.9088112
trainer/Alpha                  0.0024899812415242195
trainer/Alpha Loss             0.4531252384185791
exploration/num steps total    1196000
exploration/num paths total    2392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9407781948312731
exploration/Rewards Std        0.08555381217871624
exploration/Rewards Max        0.9796423962444347
exploration/Rewards Min        0.49535498347022
exploration/Returns Mean       470.38909741563657
exploration/Returns Std        2.5619109681581627
exploration/Returns Max        473.74479940151076
exploration/Returns Min        465.47626499573533
exploration/Actions Mean       0.058872215
exploration/Actions Std        0.5886532
exploration/Actions Max        0.99991834
exploration/Actions Min        -0.99960566
exploration/Num Paths          10
exploration/Average Returns    470.38909741563657
evaluation/num steps total     1195000
evaluation/num paths total     2390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9349815004765267
evaluation/Rewards Std         0.09595320515951655
evaluation/Rewards Max         0.9794818591584158
evaluation/Rewards Min         0.49324693316510065
evaluation/Returns Mean        467.49075023826344
evaluation/Returns Std         2.797685584296642
evaluation/Returns Max         471.2522877163775
evaluation/Returns Min         462.84222337099703
evaluation/ExplReturns Mean    467.49075023826344
evaluation/ExplReturns Std     2.797685584296642
evaluation/ExplReturns Max     471.2522877163775
evaluation/ExplReturns Min     462.84222337099703
evaluation/Actions Mean        0.07156458
evaluation/Actions Std         0.52412367
evaluation/Actions Max         0.99882096
evaluation/Actions Min         -0.9980838
evaluation/Num Paths           10
evaluation/Average Returns     467.49075023826344
time/data storing (s)          0.03247859049588442
time/evaluation sampling (s)   109.39636268466711
time/exploration sampling (s)  110.45460571814328
time/logging (s)               0.030508318915963173
time/saving (s)                0.011461515910923481
time/training (s)              9.57361697871238
time/epoch (s)                 229.49903380684555
time/total (s)                 55859.1756788427
Epoch                          238
-----------------------------  ---------------------
2023-08-01 09:29:03.497619 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 239 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3968.0024]
trainer/QF1 Loss               0.10334571
trainer/QF2 Loss               0.08220397
trainer/Policy Loss            -83.363434
trainer/Q1 Predictions Mean    95.692444
trainer/Q1 Predictions Std     5.2547145
trainer/Q1 Predictions Max     103.50914
trainer/Q1 Predictions Min     76.14477
trainer/Q2 Predictions Mean    95.58467
trainer/Q2 Predictions Std     5.2757154
trainer/Q2 Predictions Max     103.53006
trainer/Q2 Predictions Min     76.234375
trainer/Q Targets Mean         95.54622
trainer/Q Targets Std          5.27872
trainer/Q Targets Max          103.55982
trainer/Q Targets Min          76.36322
trainer/Log Pis Mean           12.434012
trainer/Log Pis Std            7.881569
trainer/Log Pis Max            36.25004
trainer/Log Pis Min            -1.6474358
trainer/Policy mu Mean         0.15872696
trainer/Policy mu Std          1.6206523
trainer/Policy mu Max          5.9167414
trainer/Policy mu Min          -5.5873713
trainer/Policy log std Mean    -0.7576212
trainer/Policy log std Std     0.2868425
trainer/Policy log std Max     0.11073317
trainer/Policy log std Min     -1.8024253
trainer/Alpha                  0.002463767770677805
trainer/Alpha Loss             2.6068015098571777
exploration/num steps total    1201000
exploration/num paths total    2402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9374911492995401
exploration/Rewards Std        0.08996740529238163
exploration/Rewards Max        0.9790471292172033
exploration/Rewards Min        0.46908660480653697
exploration/Returns Mean       468.74557464977005
exploration/Returns Std        7.080620849562558
exploration/Returns Max        476.7486528446947
exploration/Returns Min        451.8599385158404
exploration/Actions Mean       -0.003995586
exploration/Actions Std        0.5922961
exploration/Actions Max        0.999872
exploration/Actions Min        -0.9999011
exploration/Num Paths          10
exploration/Average Returns    468.74557464977005
evaluation/num steps total     1200000
evaluation/num paths total     2400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9074320864759063
evaluation/Rewards Std         0.11307424959705746
evaluation/Rewards Max         0.9763422016546759
evaluation/Rewards Min         0.47185467857372976
evaluation/Returns Mean        453.71604323795316
evaluation/Returns Std         36.95755612471859
evaluation/Returns Max         470.34413611790654
evaluation/Returns Min         346.1790634871444
evaluation/ExplReturns Mean    453.71604323795316
evaluation/ExplReturns Std     36.95755612471859
evaluation/ExplReturns Max     470.34413611790654
evaluation/ExplReturns Min     346.1790634871444
evaluation/Actions Mean        -0.02690325
evaluation/Actions Std         0.455315
evaluation/Actions Max         0.99972016
evaluation/Actions Min         -0.9993807
evaluation/Num Paths           10
evaluation/Average Returns     453.71604323795316
time/data storing (s)          0.03225813806056976
time/evaluation sampling (s)   111.99528776295483
time/exploration sampling (s)  113.0172871677205
time/logging (s)               0.030994057655334473
time/saving (s)                0.012299802154302597
time/training (s)              10.832776983268559
time/epoch (s)                 235.9209039118141
time/total (s)                 56095.0994573459
Epoch                          239
-----------------------------  --------------------
2023-08-01 09:32:55.364329 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 240 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3905.3394]
trainer/QF1 Loss               0.08683803
trainer/QF2 Loss               0.1022823
trainer/Policy Loss            -83.21007
trainer/Q1 Predictions Mean    94.89931
trainer/Q1 Predictions Std     6.132858
trainer/Q1 Predictions Max     103.35556
trainer/Q1 Predictions Min     64.89534
trainer/Q2 Predictions Mean    94.80948
trainer/Q2 Predictions Std     6.157208
trainer/Q2 Predictions Max     103.45607
trainer/Q2 Predictions Min     65.032845
trainer/Q Targets Mean         94.89143
trainer/Q Targets Std          6.156411
trainer/Q Targets Max          102.86905
trainer/Q Targets Min          64.83102
trainer/Log Pis Mean           11.801056
trainer/Log Pis Std            8.867477
trainer/Log Pis Max            43.78028
trainer/Log Pis Min            -4.204979
trainer/Policy mu Mean         -0.113710284
trainer/Policy mu Std          1.6062387
trainer/Policy mu Max          4.273667
trainer/Policy mu Min          -6.1712766
trainer/Policy log std Mean    -0.7426529
trainer/Policy log std Std     0.28758797
trainer/Policy log std Max     0.27110064
trainer/Policy log std Min     -1.79637
trainer/Alpha                  0.002431774279102683
trainer/Alpha Loss             -1.1974636316299438
exploration/num steps total    1206000
exploration/num paths total    2412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9412151308892277
exploration/Rewards Std        0.08815643606515379
exploration/Rewards Max        0.9790620012942537
exploration/Rewards Min        0.4819188881598126
exploration/Returns Mean       470.6075654446137
exploration/Returns Std        6.931645864297243
exploration/Returns Max        479.41005559345416
exploration/Returns Min        451.95832317835277
exploration/Actions Mean       0.04630893
exploration/Actions Std        0.60712445
exploration/Actions Max        0.9997571
exploration/Actions Min        -0.9999558
exploration/Num Paths          10
exploration/Average Returns    470.6075654446137
evaluation/num steps total     1205000
evaluation/num paths total     2410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9468711694794314
evaluation/Rewards Std         0.07249408741924367
evaluation/Rewards Max         0.9773950491585703
evaluation/Rewards Min         0.4872734767053829
evaluation/Returns Mean        473.43558473971564
evaluation/Returns Std         1.3963652784446254
evaluation/Returns Max         476.51040574497324
evaluation/Returns Min         471.05518536103153
evaluation/ExplReturns Mean    473.43558473971564
evaluation/ExplReturns Std     1.3963652784446254
evaluation/ExplReturns Max     476.51040574497324
evaluation/ExplReturns Min     471.05518536103153
evaluation/Actions Mean        0.041962143
evaluation/Actions Std         0.51705927
evaluation/Actions Max         0.9991215
evaluation/Actions Min         -0.9994607
evaluation/Num Paths           10
evaluation/Average Returns     473.43558473971564
time/data storing (s)          0.03225846868008375
time/evaluation sampling (s)   109.88203793484718
time/exploration sampling (s)  111.9535155184567
time/logging (s)               0.030460983514785767
time/saving (s)                0.012377364560961723
time/training (s)              9.950653161853552
time/epoch (s)                 231.86130343191326
time/total (s)                 56326.96330356505
Epoch                          240
-----------------------------  --------------------
2023-08-01 09:36:45.082817 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 241 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4015.413]
trainer/QF1 Loss               0.17135927
trainer/QF2 Loss               0.15510602
trainer/Policy Loss            -82.61503
trainer/Q1 Predictions Mean    95.7392
trainer/Q1 Predictions Std     5.4246073
trainer/Q1 Predictions Max     103.487175
trainer/Q1 Predictions Min     71.513084
trainer/Q2 Predictions Mean    95.728424
trainer/Q2 Predictions Std     5.445994
trainer/Q2 Predictions Max     103.520454
trainer/Q2 Predictions Min     71.93363
trainer/Q Targets Mean         95.46869
trainer/Q Targets Std          5.467588
trainer/Q Targets Max          103.0318
trainer/Q Targets Min          71.69115
trainer/Log Pis Mean           13.222925
trainer/Log Pis Std            9.679413
trainer/Log Pis Max            43.74534
trainer/Log Pis Min            -8.990955
trainer/Policy mu Mean         0.011660141
trainer/Policy mu Std          1.669822
trainer/Policy mu Max          5.014791
trainer/Policy mu Min          -5.306494
trainer/Policy log std Mean    -0.7459428
trainer/Policy log std Std     0.30277488
trainer/Policy log std Max     0.6014497
trainer/Policy log std Min     -1.7860553
trainer/Alpha                  0.0022331939544528723
trainer/Alpha Loss             7.465432167053223
exploration/num steps total    1211000
exploration/num paths total    2422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8500242028085006
exploration/Rewards Std        0.1326581966302297
exploration/Rewards Max        0.9786446216667559
exploration/Rewards Min        0.49101035436737367
exploration/Returns Mean       425.01210140425036
exploration/Returns Std        52.99255626373014
exploration/Returns Max        472.55708542256735
exploration/Returns Min        341.87814814081
exploration/Actions Mean       0.026567325
exploration/Actions Std        0.61291087
exploration/Actions Max        0.9998368
exploration/Actions Min        -0.9998593
exploration/Num Paths          10
exploration/Average Returns    425.01210140425036
evaluation/num steps total     1210000
evaluation/num paths total     2420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8637752563529055
evaluation/Rewards Std         0.12821759825664517
evaluation/Rewards Max         0.9749515293272811
evaluation/Rewards Min         0.48870819826870515
evaluation/Returns Mean        431.8876281764527
evaluation/Returns Std         54.1574589000045
evaluation/Returns Max         471.96244491987153
evaluation/Returns Min         348.95701543364936
evaluation/ExplReturns Mean    431.8876281764527
evaluation/ExplReturns Std     54.1574589000045
evaluation/ExplReturns Max     471.96244491987153
evaluation/ExplReturns Min     348.95701543364936
evaluation/Actions Mean        0.013667597
evaluation/Actions Std         0.5492238
evaluation/Actions Max         0.9990677
evaluation/Actions Min         -0.9993925
evaluation/Num Paths           10
evaluation/Average Returns     431.8876281764527
time/data storing (s)          0.03201022185385227
time/evaluation sampling (s)   109.21503739990294
time/exploration sampling (s)  110.76199282333255
time/logging (s)               0.030470238998532295
time/saving (s)                0.012727995403110981
time/training (s)              9.661488455720246
time/epoch (s)                 229.71372713521123
time/total (s)                 56556.67950114515
Epoch                          241
-----------------------------  ---------------------
2023-08-01 09:40:38.380387 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 242 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4025.644]
trainer/QF1 Loss               0.119708896
trainer/QF2 Loss               0.15786907
trainer/Policy Loss            -83.319435
trainer/Q1 Predictions Mean    95.789
trainer/Q1 Predictions Std     5.46288
trainer/Q1 Predictions Max     104.12248
trainer/Q1 Predictions Min     72.43231
trainer/Q2 Predictions Mean    95.94359
trainer/Q2 Predictions Std     5.4622827
trainer/Q2 Predictions Max     104.17835
trainer/Q2 Predictions Min     71.93211
trainer/Q Targets Mean         95.69201
trainer/Q Targets Std          5.4941325
trainer/Q Targets Max          104.0592
trainer/Q Targets Min          71.62511
trainer/Log Pis Mean           12.653829
trainer/Log Pis Std            9.173847
trainer/Log Pis Max            41.507324
trainer/Log Pis Min            -6.224798
trainer/Policy mu Mean         -0.10024362
trainer/Policy mu Std          1.6084627
trainer/Policy mu Max          4.859887
trainer/Policy mu Min          -5.652472
trainer/Policy log std Mean    -0.76721144
trainer/Policy log std Std     0.32410192
trainer/Policy log std Max     0.09115662
trainer/Policy log std Min     -1.9490265
trainer/Alpha                  0.002255034167319536
trainer/Alpha Loss             3.9849042892456055
exploration/num steps total    1216000
exploration/num paths total    2432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.951891110455331
exploration/Rewards Std        0.0627037843661484
exploration/Rewards Max        0.9775042416980888
exploration/Rewards Min        0.4948406913381921
exploration/Returns Mean       475.9455552276655
exploration/Returns Std        2.3090737721349917
exploration/Returns Max        478.93536587867726
exploration/Returns Min        471.4693168101451
exploration/Actions Mean       0.1412817
exploration/Actions Std        0.57746065
exploration/Actions Max        0.99989474
exploration/Actions Min        -0.99999446
exploration/Num Paths          10
exploration/Average Returns    475.9455552276655
evaluation/num steps total     1215000
evaluation/num paths total     2430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9508511715282719
evaluation/Rewards Std         0.06261460616883605
evaluation/Rewards Max         0.9781589575991587
evaluation/Rewards Min         0.49616588236143716
evaluation/Returns Mean        475.42558576413603
evaluation/Returns Std         2.242969822046051
evaluation/Returns Max         477.94477781398604
evaluation/Returns Min         469.84327059359407
evaluation/ExplReturns Mean    475.42558576413603
evaluation/ExplReturns Std     2.242969822046051
evaluation/ExplReturns Max     477.94477781398604
evaluation/ExplReturns Min     469.84327059359407
evaluation/Actions Mean        0.15591438
evaluation/Actions Std         0.4980847
evaluation/Actions Max         0.9982363
evaluation/Actions Min         -0.9997165
evaluation/Num Paths           10
evaluation/Average Returns     475.42558576413603
time/data storing (s)          0.03470541909337044
time/evaluation sampling (s)   110.8984582554549
time/exploration sampling (s)  112.11488990113139
time/logging (s)               0.030800262466073036
time/saving (s)                0.012563413009047508
time/training (s)              10.201647949405015
time/epoch (s)                 233.2930652005598
time/total (s)                 56789.97504997905
Epoch                          242
-----------------------------  --------------------
2023-08-01 09:44:32.785651 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 243 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3706.6304]
trainer/QF1 Loss               0.085810676
trainer/QF2 Loss               0.06954595
trainer/Policy Loss            -84.14261
trainer/Q1 Predictions Mean    96.16495
trainer/Q1 Predictions Std     4.978999
trainer/Q1 Predictions Max     104.55663
trainer/Q1 Predictions Min     74.27647
trainer/Q2 Predictions Mean    96.27786
trainer/Q2 Predictions Std     4.953432
trainer/Q2 Predictions Max     104.581
trainer/Q2 Predictions Min     75.38969
trainer/Q Targets Mean         96.24481
trainer/Q Targets Std          4.9552608
trainer/Q Targets Max          104.03502
trainer/Q Targets Min          74.553406
trainer/Log Pis Mean           12.184302
trainer/Log Pis Std            9.371492
trainer/Log Pis Max            46.081577
trainer/Log Pis Min            -4.5147305
trainer/Policy mu Mean         -0.09792113
trainer/Policy mu Std          1.596783
trainer/Policy mu Max          5.132724
trainer/Policy mu Min          -5.365161
trainer/Policy log std Mean    -0.7577575
trainer/Policy log std Std     0.32323936
trainer/Policy log std Max     0.06535679
trainer/Policy log std Min     -1.8756417
trainer/Alpha                  0.0022932342253625393
trainer/Alpha Loss             1.12017023563385
exploration/num steps total    1221000
exploration/num paths total    2442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.952645510767946
exploration/Rewards Std        0.06890496984750345
exploration/Rewards Max        0.9780072439625456
exploration/Rewards Min        0.5000749074939458
exploration/Returns Mean       476.322755383973
exploration/Returns Std        4.767261832449246
exploration/Returns Max        481.6590389025275
exploration/Returns Min        468.3540155434038
exploration/Actions Mean       0.08843057
exploration/Actions Std        0.6043104
exploration/Actions Max        0.9999702
exploration/Actions Min        -0.9999354
exploration/Num Paths          10
exploration/Average Returns    476.322755383973
evaluation/num steps total     1220000
evaluation/num paths total     2440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.944261887826482
evaluation/Rewards Std         0.0717287438686036
evaluation/Rewards Max         0.9768650505334997
evaluation/Rewards Min         0.5007299625802125
evaluation/Returns Mean        472.1309439132409
evaluation/Returns Std         2.3500019520701003
evaluation/Returns Max         477.0513578201111
evaluation/Returns Min         469.5041643392205
evaluation/ExplReturns Mean    472.1309439132409
evaluation/ExplReturns Std     2.3500019520701003
evaluation/ExplReturns Max     477.0513578201111
evaluation/ExplReturns Min     469.5041643392205
evaluation/Actions Mean        0.054547116
evaluation/Actions Std         0.565522
evaluation/Actions Max         0.9993404
evaluation/Actions Min         -0.99970484
evaluation/Num Paths           10
evaluation/Average Returns     472.1309439132409
time/data storing (s)          0.03178788907825947
time/evaluation sampling (s)   110.66422660090029
time/exploration sampling (s)  113.22205381747335
time/logging (s)               0.0309664998203516
time/saving (s)                0.012269072234630585
time/training (s)              10.439209394156933
time/epoch (s)                 234.40051327366382
time/total (s)                 57024.37819556426
Epoch                          243
-----------------------------  ---------------------
2023-08-01 09:48:27.956574 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 244 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3812.4207]
trainer/QF1 Loss               0.0933665
trainer/QF2 Loss               0.0931754
trainer/Policy Loss            -83.64236
trainer/Q1 Predictions Mean    96.12033
trainer/Q1 Predictions Std     5.4158697
trainer/Q1 Predictions Max     104.566666
trainer/Q1 Predictions Min     76.045
trainer/Q2 Predictions Mean    96.16452
trainer/Q2 Predictions Std     5.448413
trainer/Q2 Predictions Max     104.597206
trainer/Q2 Predictions Min     75.79219
trainer/Q Targets Mean         96.217865
trainer/Q Targets Std          5.4314933
trainer/Q Targets Max          104.3009
trainer/Q Targets Min          76.109314
trainer/Log Pis Mean           12.645398
trainer/Log Pis Std            9.402014
trainer/Log Pis Max            38.97908
trainer/Log Pis Min            -5.2543893
trainer/Policy mu Mean         0.20124875
trainer/Policy mu Std          1.6008756
trainer/Policy mu Max          6.5902596
trainer/Policy mu Min          -5.6029363
trainer/Policy log std Mean    -0.7614755
trainer/Policy log std Std     0.31457034
trainer/Policy log std Max     0.4154249
trainer/Policy log std Min     -1.8661356
trainer/Alpha                  0.0021746945567429066
trainer/Alpha Loss             3.9569191932678223
exploration/num steps total    1226000
exploration/num paths total    2452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9467777445082786
exploration/Rewards Std        0.08245013862204503
exploration/Rewards Max        0.9785592362174378
exploration/Rewards Min        0.48751760588506976
exploration/Returns Mean       473.38887225413936
exploration/Returns Std        3.4682260968181007
exploration/Returns Max        478.3752215437017
exploration/Returns Min        466.6784955460515
exploration/Actions Mean       0.100492276
exploration/Actions Std        0.5666759
exploration/Actions Max        0.99999547
exploration/Actions Min        -0.9999909
exploration/Num Paths          10
exploration/Average Returns    473.38887225413936
evaluation/num steps total     1225000
evaluation/num paths total     2450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9487991457587878
evaluation/Rewards Std         0.07965970693509555
evaluation/Rewards Max         0.9738733618534279
evaluation/Rewards Min         0.49517023836485524
evaluation/Returns Mean        474.3995728793937
evaluation/Returns Std         2.3160150394713357
evaluation/Returns Max         478.82635983918226
evaluation/Returns Min         470.9323450214599
evaluation/ExplReturns Mean    474.3995728793937
evaluation/ExplReturns Std     2.3160150394713357
evaluation/ExplReturns Max     478.82635983918226
evaluation/ExplReturns Min     470.9323450214599
evaluation/Actions Mean        0.100619994
evaluation/Actions Std         0.5127643
evaluation/Actions Max         0.9999898
evaluation/Actions Min         -0.9999454
evaluation/Num Paths           10
evaluation/Average Returns     474.3995728793937
time/data storing (s)          0.03233594819903374
time/evaluation sampling (s)   113.09653437417
time/exploration sampling (s)  112.03493235632777
time/logging (s)               0.03060616645962
time/saving (s)                0.012843894772231579
time/training (s)              9.958083759993315
time/epoch (s)                 235.16533649992198
time/total (s)                 57259.54633895308
Epoch                          244
-----------------------------  ---------------------
2023-08-01 09:52:20.649921 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 245 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4088.7576]
trainer/QF1 Loss               0.07567969
trainer/QF2 Loss               0.057455305
trainer/Policy Loss            -85.18719
trainer/Q1 Predictions Mean    96.64693
trainer/Q1 Predictions Std     4.806242
trainer/Q1 Predictions Max     103.815315
trainer/Q1 Predictions Min     76.735985
trainer/Q2 Predictions Mean    96.66829
trainer/Q2 Predictions Std     4.8227124
trainer/Q2 Predictions Max     103.950455
trainer/Q2 Predictions Min     75.826454
trainer/Q Targets Mean         96.65105
trainer/Q Targets Std          4.849084
trainer/Q Targets Max          103.97291
trainer/Q Targets Min          75.76619
trainer/Log Pis Mean           11.612879
trainer/Log Pis Std            9.598184
trainer/Log Pis Max            44.52612
trainer/Log Pis Min            -4.863819
trainer/Policy mu Mean         0.086833976
trainer/Policy mu Std          1.5592315
trainer/Policy mu Max          4.712446
trainer/Policy mu Min          -5.418938
trainer/Policy log std Mean    -0.75108075
trainer/Policy log std Std     0.30075526
trainer/Policy log std Max     0.036456466
trainer/Policy log std Min     -1.9109871
trainer/Alpha                  0.00222917553037405
trainer/Alpha Loss             -2.363802433013916
exploration/num steps total    1231000
exploration/num paths total    2462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9441304984245329
exploration/Rewards Std        0.07710143893443147
exploration/Rewards Max        0.979645813557985
exploration/Rewards Min        0.494727361564397
exploration/Returns Mean       472.06524921226645
exploration/Returns Std        2.3868751651515336
exploration/Returns Max        475.24861314674956
exploration/Returns Min        468.97555606188183
exploration/Actions Mean       0.07158351
exploration/Actions Std        0.60261434
exploration/Actions Max        0.9999968
exploration/Actions Min        -0.99998695
exploration/Num Paths          10
exploration/Average Returns    472.06524921226645
evaluation/num steps total     1230000
evaluation/num paths total     2460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9536929879018157
evaluation/Rewards Std         0.06338029872469307
evaluation/Rewards Max         0.9771901591139189
evaluation/Rewards Min         0.4891241876083413
evaluation/Returns Mean        476.84649395090776
evaluation/Returns Std         1.083582490577795
evaluation/Returns Max         478.10073780140493
evaluation/Returns Min         474.0753271264446
evaluation/ExplReturns Mean    476.84649395090776
evaluation/ExplReturns Std     1.083582490577795
evaluation/ExplReturns Max     478.10073780140493
evaluation/ExplReturns Min     474.0753271264446
evaluation/Actions Mean        0.118168026
evaluation/Actions Std         0.4971806
evaluation/Actions Max         0.99999285
evaluation/Actions Min         -0.9999316
evaluation/Num Paths           10
evaluation/Average Returns     476.84649395090776
time/data storing (s)          0.03243000339716673
time/evaluation sampling (s)   111.15346291847527
time/exploration sampling (s)  111.82277394551784
time/logging (s)               0.03045191988348961
time/saving (s)                0.011988203972578049
time/training (s)              9.637083063833416
time/epoch (s)                 232.68819005507976
time/total (s)                 57492.23723866511
Epoch                          245
-----------------------------  --------------------
2023-08-01 09:56:16.274349 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 246 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3695.1626]
trainer/QF1 Loss               0.11129685
trainer/QF2 Loss               0.10606652
trainer/Policy Loss            -84.238625
trainer/Q1 Predictions Mean    95.882065
trainer/Q1 Predictions Std     5.243704
trainer/Q1 Predictions Max     104.07689
trainer/Q1 Predictions Min     78.556404
trainer/Q2 Predictions Mean    95.89151
trainer/Q2 Predictions Std     5.2483654
trainer/Q2 Predictions Max     103.891205
trainer/Q2 Predictions Min     78.25096
trainer/Q Targets Mean         96.04809
trainer/Q Targets Std          5.2830625
trainer/Q Targets Max          104.30434
trainer/Q Targets Min          78.67302
trainer/Log Pis Mean           11.800203
trainer/Log Pis Std            8.98505
trainer/Log Pis Max            40.772137
trainer/Log Pis Min            -4.864747
trainer/Policy mu Mean         0.052231506
trainer/Policy mu Std          1.5762783
trainer/Policy mu Max          6.0648675
trainer/Policy mu Min          -6.772094
trainer/Policy log std Mean    -0.7683523
trainer/Policy log std Std     0.29618654
trainer/Policy log std Max     0.50482696
trainer/Policy log std Min     -1.7644622
trainer/Alpha                  0.002135933842509985
trainer/Alpha Loss             -1.2284631729125977
exploration/num steps total    1236000
exploration/num paths total    2472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9504389363235421
exploration/Rewards Std        0.07091971694448973
exploration/Rewards Max        0.9787727439582374
exploration/Rewards Min        0.4853141205809772
exploration/Returns Mean       475.21946816177103
exploration/Returns Std        3.7422237640398297
exploration/Returns Max        479.5069751910991
exploration/Returns Min        469.3301548579978
exploration/Actions Mean       0.08444408
exploration/Actions Std        0.5910509
exploration/Actions Max        0.9999945
exploration/Actions Min        -0.99994403
exploration/Num Paths          10
exploration/Average Returns    475.21946816177103
evaluation/num steps total     1235000
evaluation/num paths total     2470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9499087093065215
evaluation/Rewards Std         0.07293366979880724
evaluation/Rewards Max         0.9773082014934181
evaluation/Rewards Min         0.4791394090224655
evaluation/Returns Mean        474.95435465326074
evaluation/Returns Std         3.413228407219831
evaluation/Returns Max         478.5283089049749
evaluation/Returns Min         467.51603831315197
evaluation/ExplReturns Mean    474.95435465326074
evaluation/ExplReturns Std     3.413228407219831
evaluation/ExplReturns Max     478.5283089049749
evaluation/ExplReturns Min     467.51603831315197
evaluation/Actions Mean        0.12915158
evaluation/Actions Std         0.5568372
evaluation/Actions Max         0.9999889
evaluation/Actions Min         -0.9998675
evaluation/Num Paths           10
evaluation/Average Returns     474.95435465326074
time/data storing (s)          0.03195286728441715
time/evaluation sampling (s)   113.33523810561746
time/exploration sampling (s)  112.60070842597634
time/logging (s)               0.030521959997713566
time/saving (s)                0.012017043307423592
time/training (s)              9.609169784933329
time/epoch (s)                 235.61960818711668
time/total (s)                 57727.859380665235
Epoch                          246
-----------------------------  --------------------
2023-08-01 10:00:11.724086 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 247 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3913.212]
trainer/QF1 Loss               0.08446653
trainer/QF2 Loss               0.07148823
trainer/Policy Loss            -85.12168
trainer/Q1 Predictions Mean    96.55797
trainer/Q1 Predictions Std     5.542157
trainer/Q1 Predictions Max     104.84331
trainer/Q1 Predictions Min     76.981995
trainer/Q2 Predictions Mean    96.50954
trainer/Q2 Predictions Std     5.5060134
trainer/Q2 Predictions Max     104.73225
trainer/Q2 Predictions Min     77.13623
trainer/Q Targets Mean         96.52296
trainer/Q Targets Std          5.5218725
trainer/Q Targets Max          104.859726
trainer/Q Targets Min          77.14241
trainer/Log Pis Mean           11.547362
trainer/Log Pis Std            8.950967
trainer/Log Pis Max            41.224342
trainer/Log Pis Min            -5.013871
trainer/Policy mu Mean         0.11905635
trainer/Policy mu Std          1.575466
trainer/Policy mu Max          5.8003263
trainer/Policy mu Min          -4.6463575
trainer/Policy log std Mean    -0.7435157
trainer/Policy log std Std     0.3134298
trainer/Policy log std Max     0.23306763
trainer/Policy log std Min     -1.9193876
trainer/Alpha                  0.0021542098838835955
trainer/Alpha Loss             -2.7793240547180176
exploration/num steps total    1241000
exploration/num paths total    2482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9468968488084213
exploration/Rewards Std        0.07537464337860449
exploration/Rewards Max        0.9791938832066391
exploration/Rewards Min        0.4985793193827059
exploration/Returns Mean       473.44842440421064
exploration/Returns Std        6.786691530772822
exploration/Returns Max        479.2690351213675
exploration/Returns Min        460.7637635606342
exploration/Actions Mean       0.016966227
exploration/Actions Std        0.58190346
exploration/Actions Max        0.999968
exploration/Actions Min        -0.99997807
exploration/Num Paths          10
exploration/Average Returns    473.44842440421064
evaluation/num steps total     1240000
evaluation/num paths total     2480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8739446363557839
evaluation/Rewards Std         0.150378094340848
evaluation/Rewards Max         0.9779325433446563
evaluation/Rewards Min         0.35391026312264934
evaluation/Returns Mean        436.97231817789196
evaluation/Returns Std         58.164624757393845
evaluation/Returns Max         476.95778543609634
evaluation/Returns Min         300.7099471618544
evaluation/ExplReturns Mean    436.97231817789196
evaluation/ExplReturns Std     58.164624757393845
evaluation/ExplReturns Max     476.95778543609634
evaluation/ExplReturns Min     300.7099471618544
evaluation/Actions Mean        0.0131381815
evaluation/Actions Std         0.59784025
evaluation/Actions Max         0.9999743
evaluation/Actions Min         -0.9996006
evaluation/Num Paths           10
evaluation/Average Returns     436.97231817789196
time/data storing (s)          0.032449967227876186
time/evaluation sampling (s)   113.25418248027563
time/exploration sampling (s)  112.50700941123068
time/logging (s)               0.03085646592080593
time/saving (s)                0.010371590033173561
time/training (s)              9.610362702049315
time/epoch (s)                 235.44523261673748
time/total (s)                 57963.307062704116
Epoch                          247
-----------------------------  ---------------------
2023-08-01 10:04:05.015200 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 248 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3785.9302]
trainer/QF1 Loss               0.11501976
trainer/QF2 Loss               0.10032818
trainer/Policy Loss            -83.67264
trainer/Q1 Predictions Mean    96.58598
trainer/Q1 Predictions Std     4.5107207
trainer/Q1 Predictions Max     103.97606
trainer/Q1 Predictions Min     80.78157
trainer/Q2 Predictions Mean    96.523254
trainer/Q2 Predictions Std     4.50582
trainer/Q2 Predictions Max     103.818695
trainer/Q2 Predictions Min     80.82392
trainer/Q Targets Mean         96.64748
trainer/Q Targets Std          4.5236087
trainer/Q Targets Max          103.81579
trainer/Q Targets Min          80.8677
trainer/Log Pis Mean           13.024625
trainer/Log Pis Std            10.354237
trainer/Log Pis Max            45.61551
trainer/Log Pis Min            -10.341714
trainer/Policy mu Mean         -0.013601375
trainer/Policy mu Std          1.6526359
trainer/Policy mu Max          5.6827884
trainer/Policy mu Min          -5.330735
trainer/Policy log std Mean    -0.7644946
trainer/Policy log std Std     0.30245373
trainer/Policy log std Max     0.23513275
trainer/Policy log std Min     -1.8399849
trainer/Alpha                  0.0021421280689537525
trainer/Alpha Loss             6.297420501708984
exploration/num steps total    1246000
exploration/num paths total    2492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9596526166520122
exploration/Rewards Std        0.05909229968359971
exploration/Rewards Max        0.9792858449178375
exploration/Rewards Min        0.4953852609891491
exploration/Returns Mean       479.8263083260061
exploration/Returns Std        2.0013165392403
exploration/Returns Max        481.55482200196525
exploration/Returns Min        474.04565787359866
exploration/Actions Mean       -0.019720962
exploration/Actions Std        0.5685924
exploration/Actions Max        0.99990755
exploration/Actions Min        -0.99999166
exploration/Num Paths          10
exploration/Average Returns    479.8263083260061
evaluation/num steps total     1245000
evaluation/num paths total     2490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9639152957374739
evaluation/Rewards Std         0.05346703136125928
evaluation/Rewards Max         0.978305149153875
evaluation/Rewards Min         0.49897853522046154
evaluation/Returns Mean        481.95764786873696
evaluation/Returns Std         0.41356806045259464
evaluation/Returns Max         482.75398236387866
evaluation/Returns Min         481.2360879983381
evaluation/ExplReturns Mean    481.95764786873696
evaluation/ExplReturns Std     0.41356806045259464
evaluation/ExplReturns Max     482.75398236387866
evaluation/ExplReturns Min     481.2360879983381
evaluation/Actions Mean        -0.02149412
evaluation/Actions Std         0.5300677
evaluation/Actions Max         0.9993896
evaluation/Actions Min         -0.9998338
evaluation/Num Paths           10
evaluation/Average Returns     481.95764786873696
time/data storing (s)          0.032322329469025135
time/evaluation sampling (s)   111.46368555817753
time/exploration sampling (s)  112.18664611130953
time/logging (s)               0.03091429080814123
time/saving (s)                0.010351265780627728
time/training (s)              9.562421233393252
time/epoch (s)                 233.2863407889381
time/total (s)                 58196.59584919177
Epoch                          248
-----------------------------  ---------------------
2023-08-01 10:08:02.932476 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 249 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3653.3167]
trainer/QF1 Loss               0.105476774
trainer/QF2 Loss               0.10985359
trainer/Policy Loss            -85.79211
trainer/Q1 Predictions Mean    96.844315
trainer/Q1 Predictions Std     4.8417807
trainer/Q1 Predictions Max     104.503395
trainer/Q1 Predictions Min     67.71016
trainer/Q2 Predictions Mean    96.911896
trainer/Q2 Predictions Std     4.83931
trainer/Q2 Predictions Max     104.626945
trainer/Q2 Predictions Min     67.968315
trainer/Q Targets Mean         96.72837
trainer/Q Targets Std          4.8121576
trainer/Q Targets Max          104.609314
trainer/Q Targets Min          67.44701
trainer/Log Pis Mean           11.204552
trainer/Log Pis Std            8.540076
trainer/Log Pis Max            40.869137
trainer/Log Pis Min            -4.2585435
trainer/Policy mu Mean         0.20048423
trainer/Policy mu Std          1.5295825
trainer/Policy mu Max          5.1915097
trainer/Policy mu Min          -4.5109854
trainer/Policy log std Mean    -0.7744449
trainer/Policy log std Std     0.2925031
trainer/Policy log std Max     -0.004187703
trainer/Policy log std Min     -1.7904111
trainer/Alpha                  0.0021765714045614004
trainer/Alpha Loss             -4.876023292541504
exploration/num steps total    1251000
exploration/num paths total    2502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.958083308786319
exploration/Rewards Std        0.061089068397487026
exploration/Rewards Max        0.9787338000037856
exploration/Rewards Min        0.49687829392989225
exploration/Returns Mean       479.04165439315955
exploration/Returns Std        2.1561983741524635
exploration/Returns Max        481.7469509213646
exploration/Returns Min        473.74122114930475
exploration/Actions Mean       0.035511672
exploration/Actions Std        0.5612635
exploration/Actions Max        0.99997
exploration/Actions Min        -0.9999225
exploration/Num Paths          10
exploration/Average Returns    479.04165439315955
evaluation/num steps total     1250000
evaluation/num paths total     2500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9594545288500732
evaluation/Rewards Std         0.06005516377077662
evaluation/Rewards Max         0.9796935618849987
evaluation/Rewards Min         0.4907630847221136
evaluation/Returns Mean        479.7272644250367
evaluation/Returns Std         1.3042660819884233
evaluation/Returns Max         481.6711301831221
evaluation/Returns Min         477.3548097233399
evaluation/ExplReturns Mean    479.7272644250367
evaluation/ExplReturns Std     1.3042660819884233
evaluation/ExplReturns Max     481.6711301831221
evaluation/ExplReturns Min     477.3548097233399
evaluation/Actions Mean        0.057242516
evaluation/Actions Std         0.4916222
evaluation/Actions Max         0.9997927
evaluation/Actions Min         -0.9991336
evaluation/Num Paths           10
evaluation/Average Returns     479.7272644250367
time/data storing (s)          0.03264159709215164
time/evaluation sampling (s)   114.97574806213379
time/exploration sampling (s)  112.96767826005816
time/logging (s)               0.031014474108815193
time/saving (s)                0.010410498827695847
time/training (s)              9.894966668449342
time/epoch (s)                 237.91245956066996
time/total (s)                 58434.51083163172
Epoch                          249
-----------------------------  ---------------------
2023-08-01 10:11:56.448808 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 250 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3788.6353]
trainer/QF1 Loss               0.082130484
trainer/QF2 Loss               0.083906904
trainer/Policy Loss            -86.53167
trainer/Q1 Predictions Mean    97.401535
trainer/Q1 Predictions Std     3.8984375
trainer/Q1 Predictions Max     104.34734
trainer/Q1 Predictions Min     82.47137
trainer/Q2 Predictions Mean    97.34715
trainer/Q2 Predictions Std     3.9047265
trainer/Q2 Predictions Max     104.42831
trainer/Q2 Predictions Min     82.60141
trainer/Q Targets Mean         97.43116
trainer/Q Targets Std          3.9781303
trainer/Q Targets Max          104.384865
trainer/Q Targets Min          82.24531
trainer/Log Pis Mean           10.964914
trainer/Log Pis Std            9.115629
trainer/Log Pis Max            50.583473
trainer/Log Pis Min            -8.108502
trainer/Policy mu Mean         0.3435866
trainer/Policy mu Std          1.5253413
trainer/Policy mu Max          7.415243
trainer/Policy mu Min          -5.205925
trainer/Policy log std Mean    -0.7335895
trainer/Policy log std Std     0.30011398
trainer/Policy log std Max     0.556631
trainer/Policy log std Min     -1.7093172
trainer/Alpha                  0.002162638120353222
trainer/Alpha Loss             -6.351510047912598
exploration/num steps total    1256000
exploration/num paths total    2512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.941956616733559
exploration/Rewards Std        0.07935247351186499
exploration/Rewards Max        0.9786293352672324
exploration/Rewards Min        0.49676997878668816
exploration/Returns Mean       470.9783083667796
exploration/Returns Std        5.220590831797777
exploration/Returns Max        478.26749326304054
exploration/Returns Min        464.52216652300365
exploration/Actions Mean       0.12166482
exploration/Actions Std        0.602204
exploration/Actions Max        0.99987423
exploration/Actions Min        -0.99981415
exploration/Num Paths          10
exploration/Average Returns    470.9783083667796
evaluation/num steps total     1255000
evaluation/num paths total     2510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.925407307019669
evaluation/Rewards Std         0.08869784233264139
evaluation/Rewards Max         0.9768062284106208
evaluation/Rewards Min         0.4907929086350265
evaluation/Returns Mean        462.7036535098344
evaluation/Returns Std         11.482297495724268
evaluation/Returns Max         478.71404074341393
evaluation/Returns Min         447.94031956678816
evaluation/ExplReturns Mean    462.7036535098344
evaluation/ExplReturns Std     11.482297495724268
evaluation/ExplReturns Max     478.71404074341393
evaluation/ExplReturns Min     447.94031956678816
evaluation/Actions Mean        0.0906164
evaluation/Actions Std         0.5388724
evaluation/Actions Max         0.99918467
evaluation/Actions Min         -0.99939847
evaluation/Num Paths           10
evaluation/Average Returns     462.7036535098344
time/data storing (s)          0.03173484094440937
time/evaluation sampling (s)   111.7621974144131
time/exploration sampling (s)  112.05947468336672
time/logging (s)               0.030489728786051273
time/saving (s)                0.01236066035926342
time/training (s)              9.61466458439827
time/epoch (s)                 233.5109219122678
time/total (s)                 58668.02426903602
Epoch                          250
-----------------------------  --------------------
2023-08-01 10:15:47.709982 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 251 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3556.5051]
trainer/QF1 Loss               0.071588434
trainer/QF2 Loss               0.08589473
trainer/Policy Loss            -85.89697
trainer/Q1 Predictions Mean    97.4072
trainer/Q1 Predictions Std     4.350202
trainer/Q1 Predictions Max     104.81274
trainer/Q1 Predictions Min     79.63636
trainer/Q2 Predictions Mean    97.275734
trainer/Q2 Predictions Std     4.3578596
trainer/Q2 Predictions Max     104.46183
trainer/Q2 Predictions Min     78.984245
trainer/Q Targets Mean         97.434654
trainer/Q Targets Std          4.3188415
trainer/Q Targets Max          104.6765
trainer/Q Targets Min          80.11346
trainer/Log Pis Mean           11.566343
trainer/Log Pis Std            9.21786
trainer/Log Pis Max            37.069748
trainer/Log Pis Min            -11.296038
trainer/Policy mu Mean         0.17274158
trainer/Policy mu Std          1.5653014
trainer/Policy mu Max          4.649465
trainer/Policy mu Min          -4.3812118
trainer/Policy log std Mean    -0.7451351
trainer/Policy log std Std     0.3055648
trainer/Policy log std Max     0.06716043
trainer/Policy log std Min     -1.8465993
trainer/Alpha                  0.0021386018488556147
trainer/Alpha Loss             -2.666008472442627
exploration/num steps total    1261000
exploration/num paths total    2522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9644070662921335
exploration/Rewards Std        0.05469124920186616
exploration/Rewards Max        0.9798511408152287
exploration/Rewards Min        0.49677197227884434
exploration/Returns Mean       482.20353314606655
exploration/Returns Std        0.7428498487073399
exploration/Returns Max        483.14359904771965
exploration/Returns Min        480.4125819799492
exploration/Actions Mean       0.17276555
exploration/Actions Std        0.6057523
exploration/Actions Max        0.9999532
exploration/Actions Min        -0.99992216
exploration/Num Paths          10
exploration/Average Returns    482.20353314606655
evaluation/num steps total     1260000
evaluation/num paths total     2520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9643793042238195
evaluation/Rewards Std         0.058301860573042465
evaluation/Rewards Max         0.9798099209010834
evaluation/Rewards Min         0.4938498287745248
evaluation/Returns Mean        482.1896521119097
evaluation/Returns Std         1.409518917757179
evaluation/Returns Max         483.5772288346739
evaluation/Returns Min         479.02182429926006
evaluation/ExplReturns Mean    482.1896521119097
evaluation/ExplReturns Std     1.409518917757179
evaluation/ExplReturns Max     483.5772288346739
evaluation/ExplReturns Min     479.02182429926006
evaluation/Actions Mean        0.18889965
evaluation/Actions Std         0.53371984
evaluation/Actions Max         0.99986714
evaluation/Actions Min         -0.9993537
evaluation/Num Paths           10
evaluation/Average Returns     482.1896521119097
time/data storing (s)          0.032022254541516304
time/evaluation sampling (s)   110.73498727101833
time/exploration sampling (s)  110.76825623959303
time/logging (s)               0.03135112673044205
time/saving (s)                0.01283561997115612
time/training (s)              9.677611520513892
time/epoch (s)                 231.25706403236836
time/total (s)                 58899.28392377123
Epoch                          251
-----------------------------  ---------------------
2023-08-01 10:19:43.928569 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 252 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3669.467]
trainer/QF1 Loss               0.08809526
trainer/QF2 Loss               0.07946386
trainer/Policy Loss            -86.17227
trainer/Q1 Predictions Mean    97.407974
trainer/Q1 Predictions Std     4.5150986
trainer/Q1 Predictions Max     104.65875
trainer/Q1 Predictions Min     76.8043
trainer/Q2 Predictions Mean    97.36436
trainer/Q2 Predictions Std     4.504406
trainer/Q2 Predictions Max     104.553375
trainer/Q2 Predictions Min     77.19187
trainer/Q Targets Mean         97.27759
trainer/Q Targets Std          4.5502787
trainer/Q Targets Max          104.52064
trainer/Q Targets Min          77.04468
trainer/Log Pis Mean           11.349041
trainer/Log Pis Std            8.383798
trainer/Log Pis Max            48.078323
trainer/Log Pis Min            -6.5046806
trainer/Policy mu Mean         0.118402384
trainer/Policy mu Std          1.5458778
trainer/Policy mu Max          5.767367
trainer/Policy mu Min          -6.694846
trainer/Policy log std Mean    -0.77152354
trainer/Policy log std Std     0.30508068
trainer/Policy log std Max     0.38598484
trainer/Policy log std Min     -1.8185253
trainer/Alpha                  0.0021723771933466196
trainer/Alpha Loss             -3.991511344909668
exploration/num steps total    1266000
exploration/num paths total    2532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9525423315393032
exploration/Rewards Std        0.05577131956120924
exploration/Rewards Max        0.977719163410947
exploration/Rewards Min        0.5007219653467917
exploration/Returns Mean       476.27116576965136
exploration/Returns Std        2.1139274601500775
exploration/Returns Max        478.39005718855236
exploration/Returns Min        470.9466264249313
exploration/Actions Mean       0.042231087
exploration/Actions Std        0.5389197
exploration/Actions Max        0.99998236
exploration/Actions Min        -0.999974
exploration/Num Paths          10
exploration/Average Returns    476.27116576965136
evaluation/num steps total     1265000
evaluation/num paths total     2530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9499204183625798
evaluation/Rewards Std         0.060781795661217414
evaluation/Rewards Max         0.9786132913866038
evaluation/Rewards Min         0.49910957787602295
evaluation/Returns Mean        474.9602091812899
evaluation/Returns Std         5.4676688543975605
evaluation/Returns Max         479.0008396842715
evaluation/Returns Min         458.80295213781625
evaluation/ExplReturns Mean    474.9602091812899
evaluation/ExplReturns Std     5.4676688543975605
evaluation/ExplReturns Max     479.0008396842715
evaluation/ExplReturns Min     458.80295213781625
evaluation/Actions Mean        0.045397952
evaluation/Actions Std         0.4482124
evaluation/Actions Max         0.99994564
evaluation/Actions Min         -0.9999391
evaluation/Num Paths           10
evaluation/Average Returns     474.9602091812899
time/data storing (s)          0.032564468681812286
time/evaluation sampling (s)   113.3798446552828
time/exploration sampling (s)  113.14303300250322
time/logging (s)               0.03041997831314802
time/saving (s)                0.012344981543719769
time/training (s)              9.61454917024821
time/epoch (s)                 236.2127562565729
time/total (s)                 59135.4991529081
Epoch                          252
-----------------------------  ---------------------
2023-08-01 10:23:34.504916 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 253 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3787.8022]
trainer/QF1 Loss               0.093122095
trainer/QF2 Loss               0.08027454
trainer/Policy Loss            -86.2215
trainer/Q1 Predictions Mean    97.47774
trainer/Q1 Predictions Std     4.62134
trainer/Q1 Predictions Max     104.659645
trainer/Q1 Predictions Min     74.29533
trainer/Q2 Predictions Mean    97.49415
trainer/Q2 Predictions Std     4.6421857
trainer/Q2 Predictions Max     104.72357
trainer/Q2 Predictions Min     74.345055
trainer/Q Targets Mean         97.66171
trainer/Q Targets Std          4.6437693
trainer/Q Targets Max          104.80054
trainer/Q Targets Min          74.681816
trainer/Log Pis Mean           11.42888
trainer/Log Pis Std            8.780272
trainer/Log Pis Max            34.436035
trainer/Log Pis Min            -3.9063184
trainer/Policy mu Mean         0.22093157
trainer/Policy mu Std          1.5736216
trainer/Policy mu Max          5.6161084
trainer/Policy mu Min          -5.099329
trainer/Policy log std Mean    -0.77145845
trainer/Policy log std Std     0.2911341
trainer/Policy log std Max     0.21346693
trainer/Policy log std Min     -1.7325414
trainer/Alpha                  0.0020725224167108536
trainer/Alpha Loss             -3.5290048122406006
exploration/num steps total    1271000
exploration/num paths total    2542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9575008274851229
exploration/Rewards Std        0.05795969636403155
exploration/Rewards Max        0.9789683008233823
exploration/Rewards Min        0.49692964345272456
exploration/Returns Mean       478.7504137425614
exploration/Returns Std        2.201716579929429
exploration/Returns Max        481.3910869220053
exploration/Returns Min        474.7275856559124
exploration/Actions Mean       0.12004792
exploration/Actions Std        0.5748564
exploration/Actions Max        0.99997765
exploration/Actions Min        -0.99992704
exploration/Num Paths          10
exploration/Average Returns    478.7504137425614
evaluation/num steps total     1270000
evaluation/num paths total     2540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9512924863662818
evaluation/Rewards Std         0.06673017320508612
evaluation/Rewards Max         0.9791691091668903
evaluation/Rewards Min         0.4928698120942337
evaluation/Returns Mean        475.6462431831408
evaluation/Returns Std         2.084792697031339
evaluation/Returns Max         478.4868112501326
evaluation/Returns Min         471.7664090328185
evaluation/ExplReturns Mean    475.6462431831408
evaluation/ExplReturns Std     2.084792697031339
evaluation/ExplReturns Max     478.4868112501326
evaluation/ExplReturns Min     471.7664090328185
evaluation/Actions Mean        0.14364883
evaluation/Actions Std         0.5012556
evaluation/Actions Max         0.99896777
evaluation/Actions Min         -0.99958074
evaluation/Num Paths           10
evaluation/Average Returns     475.6462431831408
time/data storing (s)          0.03239927347749472
time/evaluation sampling (s)   110.06835834309459
time/exploration sampling (s)  110.78375118412077
time/logging (s)               0.030395730398595333
time/saving (s)                0.011249043047428131
time/training (s)              9.645296972244978
time/epoch (s)                 230.57145054638386
time/total (s)                 59366.07309235819
Epoch                          253
-----------------------------  ---------------------
2023-08-01 10:27:29.675499 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 254 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3901.4062]
trainer/QF1 Loss               0.096700326
trainer/QF2 Loss               0.07734543
trainer/Policy Loss            -86.51645
trainer/Q1 Predictions Mean    98.03017
trainer/Q1 Predictions Std     4.1220284
trainer/Q1 Predictions Max     104.678406
trainer/Q1 Predictions Min     80.93251
trainer/Q2 Predictions Mean    97.97322
trainer/Q2 Predictions Std     4.1237726
trainer/Q2 Predictions Max     104.57715
trainer/Q2 Predictions Min     80.73377
trainer/Q Targets Mean         97.90469
trainer/Q Targets Std          4.0962057
trainer/Q Targets Max          104.39569
trainer/Q Targets Min          80.80676
trainer/Log Pis Mean           11.606409
trainer/Log Pis Std            9.226654
trainer/Log Pis Max            41.317013
trainer/Log Pis Min            -9.029177
trainer/Policy mu Mean         0.25916955
trainer/Policy mu Std          1.5560111
trainer/Policy mu Max          5.0207167
trainer/Policy mu Min          -4.9702277
trainer/Policy log std Mean    -0.7358616
trainer/Policy log std Std     0.31231555
trainer/Policy log std Max     0.10695636
trainer/Policy log std Min     -1.7976375
trainer/Alpha                  0.002025814028456807
trainer/Alpha Loss             -2.4408228397369385
exploration/num steps total    1276000
exploration/num paths total    2552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.939348646516795
exploration/Rewards Std        0.07138918081404566
exploration/Rewards Max        0.9780569276777125
exploration/Rewards Min        0.4919915157455601
exploration/Returns Mean       469.67432325839764
exploration/Returns Std        3.4642473793145645
exploration/Returns Max        475.84622841701344
exploration/Returns Min        464.30989725504406
exploration/Actions Mean       -0.026426433
exploration/Actions Std        0.56893826
exploration/Actions Max        0.9998068
exploration/Actions Min        -0.99993795
exploration/Num Paths          10
exploration/Average Returns    469.67432325839764
evaluation/num steps total     1275000
evaluation/num paths total     2550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9379337763631156
evaluation/Rewards Std         0.07500956465916668
evaluation/Rewards Max         0.9790132685782427
evaluation/Rewards Min         0.4873051600535834
evaluation/Returns Mean        468.96688818155764
evaluation/Returns Std         5.724311790285564
evaluation/Returns Max         475.69528648281505
evaluation/Returns Min         454.51799710480236
evaluation/ExplReturns Mean    468.96688818155764
evaluation/ExplReturns Std     5.724311790285564
evaluation/ExplReturns Max     475.69528648281505
evaluation/ExplReturns Min     454.51799710480236
evaluation/Actions Mean        -0.03884039
evaluation/Actions Std         0.43922874
evaluation/Actions Max         0.9992002
evaluation/Actions Min         -0.99953187
evaluation/Num Paths           10
evaluation/Average Returns     468.96688818155764
time/data storing (s)          0.03208959009498358
time/evaluation sampling (s)   112.34298942517489
time/exploration sampling (s)  113.14643682632595
time/logging (s)               0.030463792383670807
time/saving (s)                0.012585517950356007
time/training (s)              9.601214776746929
time/epoch (s)                 235.16577992867678
time/total (s)                 59601.24134808779
Epoch                          254
-----------------------------  --------------------
2023-08-01 10:31:23.348993 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 255 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3655.2842]
trainer/QF1 Loss               0.10695228
trainer/QF2 Loss               0.09337942
trainer/Policy Loss            -85.23975
trainer/Q1 Predictions Mean    97.844536
trainer/Q1 Predictions Std     4.045332
trainer/Q1 Predictions Max     104.665375
trainer/Q1 Predictions Min     83.23174
trainer/Q2 Predictions Mean    97.82216
trainer/Q2 Predictions Std     4.0873904
trainer/Q2 Predictions Max     104.508865
trainer/Q2 Predictions Min     83.33072
trainer/Q Targets Mean         97.892845
trainer/Q Targets Std          4.120124
trainer/Q Targets Max          104.506355
trainer/Q Targets Min          83.27301
trainer/Log Pis Mean           12.750941
trainer/Log Pis Std            7.7967277
trainer/Log Pis Max            44.897903
trainer/Log Pis Min            -6.1898155
trainer/Policy mu Mean         0.27325037
trainer/Policy mu Std          1.5467811
trainer/Policy mu Max          5.1305566
trainer/Policy mu Min          -4.1034117
trainer/Policy log std Mean    -0.8149862
trainer/Policy log std Std     0.30587295
trainer/Policy log std Max     0.07664865
trainer/Policy log std Min     -1.8991977
trainer/Alpha                  0.0020538975950330496
trainer/Alpha Loss             4.647051811218262
exploration/num steps total    1281000
exploration/num paths total    2562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9526897803043423
exploration/Rewards Std        0.05211550439099208
exploration/Rewards Max        0.9791047421177428
exploration/Rewards Min        0.489572162843585
exploration/Returns Mean       476.34489015217133
exploration/Returns Std        0.9670989040577704
exploration/Returns Max        477.7227161870714
exploration/Returns Min        474.5841018626411
exploration/Actions Mean       0.17729393
exploration/Actions Std        0.5854321
exploration/Actions Max        0.9999373
exploration/Actions Min        -0.9999679
exploration/Num Paths          10
exploration/Average Returns    476.34489015217133
evaluation/num steps total     1280000
evaluation/num paths total     2560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9550980137325421
evaluation/Rewards Std         0.05046137363382485
evaluation/Rewards Max         0.9767326182992863
evaluation/Rewards Min         0.4867540641254996
evaluation/Returns Mean        477.54900686627104
evaluation/Returns Std         0.8898688645064075
evaluation/Returns Max         478.57500580085235
evaluation/Returns Min         476.15421285761084
evaluation/ExplReturns Mean    477.54900686627104
evaluation/ExplReturns Std     0.8898688645064075
evaluation/ExplReturns Max     478.57500580085235
evaluation/ExplReturns Min     476.15421285761084
evaluation/Actions Mean        0.17192082
evaluation/Actions Std         0.5392559
evaluation/Actions Max         0.9996853
evaluation/Actions Min         -0.9997971
evaluation/Num Paths           10
evaluation/Average Returns     477.54900686627104
time/data storing (s)          0.03213987313210964
time/evaluation sampling (s)   111.64613351877779
time/exploration sampling (s)  112.31802111957222
time/logging (s)               0.030616620555520058
time/saving (s)                0.011223687790334225
time/training (s)              9.630568603985012
time/epoch (s)                 233.66870342381299
time/total (s)                 59834.91260614339
Epoch                          255
-----------------------------  ---------------------
2023-08-01 10:35:14.505156 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 256 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3716.8887]
trainer/QF1 Loss               0.110002995
trainer/QF2 Loss               0.124174826
trainer/Policy Loss            -85.15001
trainer/Q1 Predictions Mean    97.81412
trainer/Q1 Predictions Std     4.290061
trainer/Q1 Predictions Max     104.43916
trainer/Q1 Predictions Min     73.7543
trainer/Q2 Predictions Mean    97.748184
trainer/Q2 Predictions Std     4.2718596
trainer/Q2 Predictions Max     104.165
trainer/Q2 Predictions Min     73.3682
trainer/Q Targets Mean         97.95218
trainer/Q Targets Std          4.2990613
trainer/Q Targets Max          104.41125
trainer/Q Targets Min          73.90515
trainer/Log Pis Mean           12.76664
trainer/Log Pis Std            8.88338
trainer/Log Pis Max            39.64383
trainer/Log Pis Min            -3.7731495
trainer/Policy mu Mean         0.3256807
trainer/Policy mu Std          1.5918794
trainer/Policy mu Max          5.7198305
trainer/Policy mu Min          -5.370098
trainer/Policy log std Mean    -0.7686332
trainer/Policy log std Std     0.31064618
trainer/Policy log std Max     0.04975331
trainer/Policy log std Min     -1.7674057
trainer/Alpha                  0.0020241127349436283
trainer/Alpha Loss             4.755296230316162
exploration/num steps total    1286000
exploration/num paths total    2572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9514247635867374
exploration/Rewards Std        0.061642940776368754
exploration/Rewards Max        0.9786557454381235
exploration/Rewards Min        0.5014129599534178
exploration/Returns Mean       475.7123817933689
exploration/Returns Std        2.7278159662331367
exploration/Returns Max        480.0325772823927
exploration/Returns Min        472.1727428603564
exploration/Actions Mean       -0.07674097
exploration/Actions Std        0.5692666
exploration/Actions Max        0.9999022
exploration/Actions Min        -0.9999962
exploration/Num Paths          10
exploration/Average Returns    475.7123817933689
evaluation/num steps total     1285000
evaluation/num paths total     2570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9528260700791754
evaluation/Rewards Std         0.05323668819865183
evaluation/Rewards Max         0.9768648131116218
evaluation/Rewards Min         0.489668861582751
evaluation/Returns Mean        476.4130350395878
evaluation/Returns Std         3.7905832266521435
evaluation/Returns Max         478.15824332677755
evaluation/Returns Min         465.07058139266263
evaluation/ExplReturns Mean    476.4130350395878
evaluation/ExplReturns Std     3.7905832266521435
evaluation/ExplReturns Max     478.15824332677755
evaluation/ExplReturns Min     465.07058139266263
evaluation/Actions Mean        -0.032220595
evaluation/Actions Std         0.476699
evaluation/Actions Max         0.9998138
evaluation/Actions Min         -0.9999557
evaluation/Num Paths           10
evaluation/Average Returns     476.4130350395878
time/data storing (s)          0.032215507701039314
time/evaluation sampling (s)   109.93555504735559
time/exploration sampling (s)  111.48324306402355
time/logging (s)               0.030476651154458523
time/saving (s)                0.011166336946189404
time/training (s)              9.658435217104852
time/epoch (s)                 231.1510918242857
time/total (s)                 60066.066224189475
Epoch                          256
-----------------------------  ---------------------
2023-08-01 10:39:06.366326 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 257 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3851.4714]
trainer/QF1 Loss               0.087535895
trainer/QF2 Loss               0.07278897
trainer/Policy Loss            -86.54245
trainer/Q1 Predictions Mean    98.138885
trainer/Q1 Predictions Std     4.5598865
trainer/Q1 Predictions Max     104.47341
trainer/Q1 Predictions Min     61.969696
trainer/Q2 Predictions Mean    98.14314
trainer/Q2 Predictions Std     4.5847983
trainer/Q2 Predictions Max     104.467735
trainer/Q2 Predictions Min     61.288105
trainer/Q Targets Mean         98.08388
trainer/Q Targets Std          4.567062
trainer/Q Targets Max          104.248535
trainer/Q Targets Min          61.861835
trainer/Log Pis Mean           11.76428
trainer/Log Pis Std            8.047728
trainer/Log Pis Max            40.860703
trainer/Log Pis Min            -6.3284574
trainer/Policy mu Mean         0.27991506
trainer/Policy mu Std          1.5182607
trainer/Policy mu Max          6.059742
trainer/Policy mu Min          -4.537004
trainer/Policy log std Mean    -0.7763526
trainer/Policy log std Std     0.30185667
trainer/Policy log std Max     0.30128622
trainer/Policy log std Min     -1.7949499
trainer/Alpha                  0.002053819363936782
trainer/Alpha Loss             -1.4586329460144043
exploration/num steps total    1291000
exploration/num paths total    2582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.954382392928299
exploration/Rewards Std        0.06177815443250311
exploration/Rewards Max        0.9787179140378603
exploration/Rewards Min        0.4893146398461933
exploration/Returns Mean       477.1911964641492
exploration/Returns Std        1.499622571124993
exploration/Returns Max        479.4719879177902
exploration/Returns Min        474.0651317934108
exploration/Actions Mean       0.116182014
exploration/Actions Std        0.5714066
exploration/Actions Max        0.99998903
exploration/Actions Min        -0.99994516
exploration/Num Paths          10
exploration/Average Returns    477.1911964641492
evaluation/num steps total     1290000
evaluation/num paths total     2580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9494339094442895
evaluation/Rewards Std         0.06905749810224257
evaluation/Rewards Max         0.9791471340483963
evaluation/Rewards Min         0.49672798771643223
evaluation/Returns Mean        474.7169547221448
evaluation/Returns Std         4.6405650338109465
evaluation/Returns Max         478.02553956445746
evaluation/Returns Min         461.3386524244219
evaluation/ExplReturns Mean    474.7169547221448
evaluation/ExplReturns Std     4.6405650338109465
evaluation/ExplReturns Max     478.02553956445746
evaluation/ExplReturns Min     461.3386524244219
evaluation/Actions Mean        0.11111226
evaluation/Actions Std         0.476853
evaluation/Actions Max         0.9999532
evaluation/Actions Min         -0.998954
evaluation/Num Paths           10
evaluation/Average Returns     474.7169547221448
time/data storing (s)          0.03223286662250757
time/evaluation sampling (s)   111.11069231014699
time/exploration sampling (s)  111.5746444016695
time/logging (s)               0.03054032102227211
time/saving (s)                0.010859859175980091
time/training (s)              9.097293457947671
time/epoch (s)                 231.85626321658492
time/total (s)                 60297.92502232175
Epoch                          257
-----------------------------  --------------------
2023-08-01 10:43:00.998134 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 258 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3826.064]
trainer/QF1 Loss               0.058827825
trainer/QF2 Loss               0.043736823
trainer/Policy Loss            -84.46211
trainer/Q1 Predictions Mean    98.08244
trainer/Q1 Predictions Std     3.8574164
trainer/Q1 Predictions Max     104.12816
trainer/Q1 Predictions Min     75.11408
trainer/Q2 Predictions Mean    98.16469
trainer/Q2 Predictions Std     3.8661122
trainer/Q2 Predictions Max     104.258995
trainer/Q2 Predictions Min     75.6238
trainer/Q Targets Mean         98.19183
trainer/Q Targets Std          3.8480334
trainer/Q Targets Max          104.29392
trainer/Q Targets Min          75.846756
trainer/Log Pis Mean           13.827536
trainer/Log Pis Std            7.9092283
trainer/Log Pis Max            40.02223
trainer/Log Pis Min            -5.525742
trainer/Policy mu Mean         0.19089635
trainer/Policy mu Std          1.6488554
trainer/Policy mu Max          5.872411
trainer/Policy mu Min          -5.186883
trainer/Policy log std Mean    -0.76347184
trainer/Policy log std Std     0.31329736
trainer/Policy log std Max     0.25073647
trainer/Policy log std Min     -1.8977729
trainer/Alpha                  0.002233610488474369
trainer/Alpha Loss             11.156185150146484
exploration/num steps total    1296000
exploration/num paths total    2592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9459731292317695
exploration/Rewards Std        0.0734541779116906
exploration/Rewards Max        0.9797714384282371
exploration/Rewards Min        0.4874156635216525
exploration/Returns Mean       472.9865646158846
exploration/Returns Std        2.813558963799096
exploration/Returns Max        478.7435198897674
exploration/Returns Min        468.6900318652298
exploration/Actions Mean       -0.0885696
exploration/Actions Std        0.6079944
exploration/Actions Max        0.9999681
exploration/Actions Min        -0.9999846
exploration/Num Paths          10
exploration/Average Returns    472.9865646158846
evaluation/num steps total     1295000
evaluation/num paths total     2590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9370047943530059
evaluation/Rewards Std         0.08225449938283745
evaluation/Rewards Max         0.9790709151280009
evaluation/Rewards Min         0.4867338613846852
evaluation/Returns Mean        468.50239717650294
evaluation/Returns Std         8.541510709303703
evaluation/Returns Max         478.92482821833204
evaluation/Returns Min         453.74752385828754
evaluation/ExplReturns Mean    468.50239717650294
evaluation/ExplReturns Std     8.541510709303703
evaluation/ExplReturns Max     478.92482821833204
evaluation/ExplReturns Min     453.74752385828754
evaluation/Actions Mean        -0.062421113
evaluation/Actions Std         0.5517473
evaluation/Actions Max         0.9999109
evaluation/Actions Min         -0.99942774
evaluation/Num Paths           10
evaluation/Average Returns     468.50239717650294
time/data storing (s)          0.03202958032488823
time/evaluation sampling (s)   111.8580544218421
time/exploration sampling (s)  113.05896429810673
time/logging (s)               0.03038077149540186
time/saving (s)                0.012842940166592598
time/training (s)              9.634466051124036
time/epoch (s)                 234.62673806305975
time/total (s)                 60532.55425035488
Epoch                          258
-----------------------------  --------------------
2023-08-01 10:46:54.887284 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 259 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3711.509]
trainer/QF1 Loss               0.057404183
trainer/QF2 Loss               0.046576276
trainer/Policy Loss            -87.23893
trainer/Q1 Predictions Mean    98.55931
trainer/Q1 Predictions Std     3.9607804
trainer/Q1 Predictions Max     104.56108
trainer/Q1 Predictions Min     84.464516
trainer/Q2 Predictions Mean    98.57788
trainer/Q2 Predictions Std     3.9635391
trainer/Q2 Predictions Max     104.36911
trainer/Q2 Predictions Min     84.47267
trainer/Q Targets Mean         98.58469
trainer/Q Targets Std          3.941731
trainer/Q Targets Max          104.42312
trainer/Q Targets Min          84.26749
trainer/Log Pis Mean           11.4666195
trainer/Log Pis Std            8.380156
trainer/Log Pis Max            42.108486
trainer/Log Pis Min            -3.3845773
trainer/Policy mu Mean         0.24431205
trainer/Policy mu Std          1.5094744
trainer/Policy mu Max          4.987693
trainer/Policy mu Min          -5.237403
trainer/Policy log std Mean    -0.8116942
trainer/Policy log std Std     0.3149967
trainer/Policy log std Max     0.43006393
trainer/Policy log std Min     -1.8938875
trainer/Alpha                  0.002168942941352725
trainer/Alpha Loss             -3.2715320587158203
exploration/num steps total    1301000
exploration/num paths total    2602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9343813684062595
exploration/Rewards Std        0.07995445448814338
exploration/Rewards Max        0.9779177710092096
exploration/Rewards Min        0.5005165950690548
exploration/Returns Mean       467.19068420312976
exploration/Returns Std        3.007372877310985
exploration/Returns Max        473.44567375412146
exploration/Returns Min        463.6320526510269
exploration/Actions Mean       0.14414781
exploration/Actions Std        0.6280724
exploration/Actions Max        0.99998724
exploration/Actions Min        -0.9999743
exploration/Num Paths          10
exploration/Average Returns    467.19068420312976
evaluation/num steps total     1300000
evaluation/num paths total     2600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9287266768881587
evaluation/Rewards Std         0.08637707922536358
evaluation/Rewards Max         0.9767090739474615
evaluation/Rewards Min         0.48970147074178405
evaluation/Returns Mean        464.36333844407943
evaluation/Returns Std         2.730233223322002
evaluation/Returns Max         467.4001027576377
evaluation/Returns Min         459.8599741296491
evaluation/ExplReturns Mean    464.36333844407943
evaluation/ExplReturns Std     2.730233223322002
evaluation/ExplReturns Max     467.4001027576377
evaluation/ExplReturns Min     459.8599741296491
evaluation/Actions Mean        0.15206662
evaluation/Actions Std         0.5578942
evaluation/Actions Max         0.9999392
evaluation/Actions Min         -0.9995316
evaluation/Num Paths           10
evaluation/Average Returns     464.36333844407943
time/data storing (s)          0.03226140048354864
time/evaluation sampling (s)   111.67396615073085
time/exploration sampling (s)  112.65480609145015
time/logging (s)               0.03038011584430933
time/saving (s)                0.01025664433836937
time/training (s)              9.482147469185293
time/epoch (s)                 233.88381787203252
time/total (s)                 60766.4409717191
Epoch                          259
-----------------------------  --------------------
2023-08-01 10:50:47.028638 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 260 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3616.0562]
trainer/QF1 Loss               0.062457
trainer/QF2 Loss               0.056976996
trainer/Policy Loss            -86.62131
trainer/Q1 Predictions Mean    98.50593
trainer/Q1 Predictions Std     4.142621
trainer/Q1 Predictions Max     104.41409
trainer/Q1 Predictions Min     71.65561
trainer/Q2 Predictions Mean    98.52182
trainer/Q2 Predictions Std     4.1359725
trainer/Q2 Predictions Max     104.170235
trainer/Q2 Predictions Min     71.89796
trainer/Q Targets Mean         98.51751
trainer/Q Targets Std          4.183666
trainer/Q Targets Max          104.2618
trainer/Q Targets Min          71.26696
trainer/Log Pis Mean           12.082948
trainer/Log Pis Std            7.83741
trainer/Log Pis Max            42.11488
trainer/Log Pis Min            -4.564263
trainer/Policy mu Mean         0.36071566
trainer/Policy mu Std          1.5283397
trainer/Policy mu Max          4.7638516
trainer/Policy mu Min          -8.093059
trainer/Policy log std Mean    -0.7806235
trainer/Policy log std Std     0.3006796
trainer/Policy log std Max     0.31679618
trainer/Policy log std Min     -1.8768864
trainer/Alpha                  0.0022466485388576984
trainer/Alpha Loss             0.5058373808860779
exploration/num steps total    1306000
exploration/num paths total    2612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9335690583744944
exploration/Rewards Std        0.0932866370514316
exploration/Rewards Max        0.9797780697711751
exploration/Rewards Min        0.5003407418556038
exploration/Returns Mean       466.78452918724724
exploration/Returns Std        4.791439685347422
exploration/Returns Max        474.0322971163071
exploration/Returns Min        459.4375038334051
exploration/Actions Mean       0.057245936
exploration/Actions Std        0.6278212
exploration/Actions Max        0.99995375
exploration/Actions Min        -0.9999584
exploration/Num Paths          10
exploration/Average Returns    466.78452918724724
evaluation/num steps total     1305000
evaluation/num paths total     2610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8878959144545734
evaluation/Rewards Std         0.12188328159416068
evaluation/Rewards Max         0.9777127330945206
evaluation/Rewards Min         0.49663924132350856
evaluation/Returns Mean        443.94795722728657
evaluation/Returns Std         25.987356726943503
evaluation/Returns Max         472.42758328064525
evaluation/Returns Min         383.2600319063141
evaluation/ExplReturns Mean    443.94795722728657
evaluation/ExplReturns Std     25.987356726943503
evaluation/ExplReturns Max     472.42758328064525
evaluation/ExplReturns Min     383.2600319063141
evaluation/Actions Mean        0.027663153
evaluation/Actions Std         0.55114204
evaluation/Actions Max         0.9998068
evaluation/Actions Min         -0.998582
evaluation/Num Paths           10
evaluation/Average Returns     443.94795722728657
time/data storing (s)          0.03199537191540003
time/evaluation sampling (s)   111.0623087817803
time/exploration sampling (s)  111.4509180271998
time/logging (s)               0.031022639013826847
time/saving (s)                0.012774958275258541
time/training (s)              9.547958867624402
time/epoch (s)                 232.136978645809
time/total (s)                 60998.58048695978
Epoch                          260
-----------------------------  ---------------------
2023-08-01 10:54:42.203263 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 261 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3607.964]
trainer/QF1 Loss               0.07122943
trainer/QF2 Loss               0.0723817
trainer/Policy Loss            -86.848236
trainer/Q1 Predictions Mean    98.74667
trainer/Q1 Predictions Std     3.8588562
trainer/Q1 Predictions Max     104.292206
trainer/Q1 Predictions Min     83.969086
trainer/Q2 Predictions Mean    98.808365
trainer/Q2 Predictions Std     3.8632264
trainer/Q2 Predictions Max     104.29646
trainer/Q2 Predictions Min     84.9319
trainer/Q Targets Mean         98.70545
trainer/Q Targets Std          3.8777094
trainer/Q Targets Max          104.20744
trainer/Q Targets Min          84.51868
trainer/Log Pis Mean           12.094084
trainer/Log Pis Std            7.9998245
trainer/Log Pis Max            49.418983
trainer/Log Pis Min            -4.372487
trainer/Policy mu Mean         0.36819503
trainer/Policy mu Std          1.5258619
trainer/Policy mu Max          5.8620486
trainer/Policy mu Min          -4.9690113
trainer/Policy log std Mean    -0.7569807
trainer/Policy log std Std     0.30151764
trainer/Policy log std Max     0.19725679
trainer/Policy log std Min     -1.7483425
trainer/Alpha                  0.002447755541652441
trainer/Alpha Loss             0.5656995177268982
exploration/num steps total    1311000
exploration/num paths total    2622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9471287096704831
exploration/Rewards Std        0.07076440672653299
exploration/Rewards Max        0.9780448265442203
exploration/Rewards Min        0.48779562558352574
exploration/Returns Mean       473.56435483524155
exploration/Returns Std        6.536168334428894
exploration/Returns Max        479.0908231324699
exploration/Returns Min        461.81203448936736
exploration/Actions Mean       0.10034534
exploration/Actions Std        0.6269596
exploration/Actions Max        0.99998784
exploration/Actions Min        -0.9999871
exploration/Num Paths          10
exploration/Average Returns    473.56435483524155
evaluation/num steps total     1310000
evaluation/num paths total     2620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9094629534842305
evaluation/Rewards Std         0.10822998234570408
evaluation/Rewards Max         0.9794176667646639
evaluation/Rewards Min         0.4922137080794897
evaluation/Returns Mean        454.7314767421152
evaluation/Returns Std         13.918749712198064
evaluation/Returns Max         478.8021401168426
evaluation/Returns Min         436.76617144042444
evaluation/ExplReturns Mean    454.7314767421152
evaluation/ExplReturns Std     13.918749712198064
evaluation/ExplReturns Max     478.8021401168426
evaluation/ExplReturns Min     436.76617144042444
evaluation/Actions Mean        0.04717737
evaluation/Actions Std         0.5891693
evaluation/Actions Max         0.9997504
evaluation/Actions Min         -0.99996984
evaluation/Num Paths           10
evaluation/Average Returns     454.7314767421152
time/data storing (s)          0.0324432123452425
time/evaluation sampling (s)   112.09738590940833
time/exploration sampling (s)  113.29354971367866
time/logging (s)               0.03067966364324093
time/saving (s)                0.01260379422456026
time/training (s)              9.702496263198555
time/epoch (s)                 235.1691585564986
time/total (s)                 61233.752301729284
Epoch                          261
-----------------------------  --------------------
2023-08-01 10:58:32.531195 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 262 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4181.3667]
trainer/QF1 Loss               0.06968176
trainer/QF2 Loss               0.066790365
trainer/Policy Loss            -86.19414
trainer/Q1 Predictions Mean    98.23035
trainer/Q1 Predictions Std     4.2752104
trainer/Q1 Predictions Max     104.2347
trainer/Q1 Predictions Min     70.808075
trainer/Q2 Predictions Mean    98.186676
trainer/Q2 Predictions Std     4.269411
trainer/Q2 Predictions Max     104.09538
trainer/Q2 Predictions Min     70.94875
trainer/Q Targets Mean         98.21265
trainer/Q Targets Std          4.2656426
trainer/Q Targets Max          104.18925
trainer/Q Targets Min          70.75459
trainer/Log Pis Mean           12.237648
trainer/Log Pis Std            7.3865848
trainer/Log Pis Max            35.756443
trainer/Log Pis Min            -2.4827335
trainer/Policy mu Mean         0.23350777
trainer/Policy mu Std          1.5701574
trainer/Policy mu Max          5.938024
trainer/Policy mu Min          -7.4458857
trainer/Policy log std Mean    -0.76970524
trainer/Policy log std Std     0.2876397
trainer/Policy log std Max     0.52290535
trainer/Policy log std Min     -1.9053336
trainer/Alpha                  0.002486232202500105
trainer/Alpha Loss             1.425155758857727
exploration/num steps total    1316000
exploration/num paths total    2632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9378658585210061
exploration/Rewards Std        0.07959147798848858
exploration/Rewards Max        0.9796401780538408
exploration/Rewards Min        0.49265806764583164
exploration/Returns Mean       468.9329292605031
exploration/Returns Std        6.429863603098825
exploration/Returns Max        476.71259917091345
exploration/Returns Min        459.01018496428094
exploration/Actions Mean       0.08359833
exploration/Actions Std        0.5726015
exploration/Actions Max        0.99997383
exploration/Actions Min        -0.9999308
exploration/Num Paths          10
exploration/Average Returns    468.9329292605031
evaluation/num steps total     1315000
evaluation/num paths total     2630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9140113031555688
evaluation/Rewards Std         0.10025939778857214
evaluation/Rewards Max         0.9789946477335371
evaluation/Rewards Min         0.4894851479679817
evaluation/Returns Mean        457.0056515777843
evaluation/Returns Std         32.749611948162084
evaluation/Returns Max         475.5061285460405
evaluation/Returns Min         360.34208685180755
evaluation/ExplReturns Mean    457.0056515777843
evaluation/ExplReturns Std     32.749611948162084
evaluation/ExplReturns Max     475.5061285460405
evaluation/ExplReturns Min     360.34208685180755
evaluation/Actions Mean        0.097199395
evaluation/Actions Std         0.5038031
evaluation/Actions Max         0.999883
evaluation/Actions Min         -0.9993626
evaluation/Num Paths           10
evaluation/Average Returns     457.0056515777843
time/data storing (s)          0.03202808275818825
time/evaluation sampling (s)   109.30979033559561
time/exploration sampling (s)  111.27502502221614
time/logging (s)               0.03057271335273981
time/saving (s)                0.01067356113344431
time/training (s)              9.664784628897905
time/epoch (s)                 230.32287434395403
time/total (s)                 61464.07768190373
Epoch                          262
-----------------------------  --------------------
2023-08-01 11:02:24.285557 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 263 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4102.1084]
trainer/QF1 Loss               0.07548366
trainer/QF2 Loss               0.05876339
trainer/Policy Loss            -87.90944
trainer/Q1 Predictions Mean    99.371414
trainer/Q1 Predictions Std     3.5089319
trainer/Q1 Predictions Max     104.35134
trainer/Q1 Predictions Min     87.58671
trainer/Q2 Predictions Mean    99.32683
trainer/Q2 Predictions Std     3.5183213
trainer/Q2 Predictions Max     104.16888
trainer/Q2 Predictions Min     86.999886
trainer/Q Targets Mean         99.25389
trainer/Q Targets Std          3.4678586
trainer/Q Targets Max          104.14828
trainer/Q Targets Min          86.61456
trainer/Log Pis Mean           11.608911
trainer/Log Pis Std            7.0415025
trainer/Log Pis Max            41.32103
trainer/Log Pis Min            -2.9870572
trainer/Policy mu Mean         0.46367255
trainer/Policy mu Std          1.445899
trainer/Policy mu Max          4.765119
trainer/Policy mu Min          -4.3612847
trainer/Policy log std Mean    -0.8069144
trainer/Policy log std Std     0.3026194
trainer/Policy log std Max     0.048871756
trainer/Policy log std Min     -1.8583517
trainer/Alpha                  0.00235962076112628
trainer/Alpha Loss             -2.365814685821533
exploration/num steps total    1321000
exploration/num paths total    2642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9329958789190901
exploration/Rewards Std        0.08854845023552889
exploration/Rewards Max        0.9792144719845428
exploration/Rewards Min        0.48471726160766215
exploration/Returns Mean       466.4979394595449
exploration/Returns Std        5.763877892743329
exploration/Returns Max        475.958376131456
exploration/Returns Min        456.83705140757576
exploration/Actions Mean       0.06478767
exploration/Actions Std        0.5822734
exploration/Actions Max        0.9999751
exploration/Actions Min        -0.9997398
exploration/Num Paths          10
exploration/Average Returns    466.4979394595449
evaluation/num steps total     1320000
evaluation/num paths total     2640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9107899369473965
evaluation/Rewards Std         0.10510940601253381
evaluation/Rewards Max         0.9791174059912247
evaluation/Rewards Min         0.49213814028336683
evaluation/Returns Mean        455.3949684736982
evaluation/Returns Std         4.539061511910535
evaluation/Returns Max         462.0418816092452
evaluation/Returns Min         450.3826351535652
evaluation/ExplReturns Mean    455.3949684736982
evaluation/ExplReturns Std     4.539061511910535
evaluation/ExplReturns Max     462.0418816092452
evaluation/ExplReturns Min     450.3826351535652
evaluation/Actions Mean        0.09691755
evaluation/Actions Std         0.52598894
evaluation/Actions Max         0.9998249
evaluation/Actions Min         -0.9997571
evaluation/Num Paths           10
evaluation/Average Returns     455.3949684736982
time/data storing (s)          0.0317890839651227
time/evaluation sampling (s)   110.7511086454615
time/exploration sampling (s)  111.15669106598943
time/logging (s)               0.03035436663776636
time/saving (s)                0.012080353684723377
time/training (s)              9.767178148031235
time/epoch (s)                 231.74920166376978
time/total (s)                 61695.82940513641
Epoch                          263
-----------------------------  --------------------
2023-08-01 11:06:16.968968 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 264 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4337.6978]
trainer/QF1 Loss               0.048503198
trainer/QF2 Loss               0.03957694
trainer/Policy Loss            -86.96391
trainer/Q1 Predictions Mean    99.14429
trainer/Q1 Predictions Std     3.6738155
trainer/Q1 Predictions Max     104.0945
trainer/Q1 Predictions Min     89.58488
trainer/Q2 Predictions Mean    99.203476
trainer/Q2 Predictions Std     3.662964
trainer/Q2 Predictions Max     104.03608
trainer/Q2 Predictions Min     89.91901
trainer/Q Targets Mean         99.20743
trainer/Q Targets Std          3.6904137
trainer/Q Targets Max          104.05775
trainer/Q Targets Min          89.84065
trainer/Log Pis Mean           12.335875
trainer/Log Pis Std            7.210617
trainer/Log Pis Max            38.43883
trainer/Log Pis Min            -7.03391
trainer/Policy mu Mean         0.33373204
trainer/Policy mu Std          1.5310935
trainer/Policy mu Max          5.093992
trainer/Policy mu Min          -4.6594386
trainer/Policy log std Mean    -0.76302624
trainer/Policy log std Std     0.27592006
trainer/Policy log std Max     0.07514584
trainer/Policy log std Min     -1.7498213
trainer/Alpha                  0.002469633473083377
trainer/Alpha Loss             2.0164847373962402
exploration/num steps total    1326000
exploration/num paths total    2652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.930449219962518
exploration/Rewards Std        0.0964652701872038
exploration/Rewards Max        0.9798158964905433
exploration/Rewards Min        0.4866243323184196
exploration/Returns Mean       465.2246099812589
exploration/Returns Std        4.671381081760195
exploration/Returns Max        471.13414645805733
exploration/Returns Min        455.61516025772374
exploration/Actions Mean       -0.00025795837
exploration/Actions Std        0.58540386
exploration/Actions Max        0.9999956
exploration/Actions Min        -0.9998105
exploration/Num Paths          10
exploration/Average Returns    465.2246099812589
evaluation/num steps total     1325000
evaluation/num paths total     2650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9244374851201704
evaluation/Rewards Std         0.10042995087971353
evaluation/Rewards Max         0.9789921514146965
evaluation/Rewards Min         0.49275517984238243
evaluation/Returns Mean        462.21874256008493
evaluation/Returns Std         2.9322677176394834
evaluation/Returns Max         467.04945164497843
evaluation/Returns Min         457.06371534498334
evaluation/ExplReturns Mean    462.21874256008493
evaluation/ExplReturns Std     2.9322677176394834
evaluation/ExplReturns Max     467.04945164497843
evaluation/ExplReturns Min     457.06371534498334
evaluation/Actions Mean        0.011309588
evaluation/Actions Std         0.5080202
evaluation/Actions Max         0.99969536
evaluation/Actions Min         -0.9993317
evaluation/Num Paths           10
evaluation/Average Returns     462.21874256008493
time/data storing (s)          0.032187397591769695
time/evaluation sampling (s)   110.9586027925834
time/exploration sampling (s)  112.07481707446277
time/logging (s)               0.03064890205860138
time/saving (s)                0.012377339415252209
time/training (s)              9.569646192714572
time/epoch (s)                 232.67827969882637
time/total (s)                 61928.51061899867
Epoch                          264
-----------------------------  --------------------
2023-08-01 11:10:11.637467 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 265 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4112.5327]
trainer/QF1 Loss               0.06814547
trainer/QF2 Loss               0.06206984
trainer/Policy Loss            -86.513
trainer/Q1 Predictions Mean    99.19534
trainer/Q1 Predictions Std     3.755162
trainer/Q1 Predictions Max     104.14378
trainer/Q1 Predictions Min     84.54722
trainer/Q2 Predictions Mean    99.15448
trainer/Q2 Predictions Std     3.7327588
trainer/Q2 Predictions Max     104.024216
trainer/Q2 Predictions Min     84.96764
trainer/Q Targets Mean         99.25708
trainer/Q Targets Std          3.7504077
trainer/Q Targets Max          103.95036
trainer/Q Targets Min          84.23112
trainer/Log Pis Mean           12.826197
trainer/Log Pis Std            6.9028306
trainer/Log Pis Max            43.261284
trainer/Log Pis Min            -3.4691947
trainer/Policy mu Mean         0.4351611
trainer/Policy mu Std          1.5134456
trainer/Policy mu Max          5.6679683
trainer/Policy mu Min          -5.571173
trainer/Policy log std Mean    -0.79005986
trainer/Policy log std Std     0.29405978
trainer/Policy log std Max     0.351821
trainer/Policy log std Min     -1.8124079
trainer/Alpha                  0.002306534443050623
trainer/Alpha Loss             5.016702651977539
exploration/num steps total    1331000
exploration/num paths total    2662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9608287215655841
exploration/Rewards Std        0.061691524022019405
exploration/Rewards Max        0.9798020620733188
exploration/Rewards Min        0.49786264336114333
exploration/Returns Mean       480.41436078279185
exploration/Returns Std        1.0375602007578513
exploration/Returns Max        482.31563685445695
exploration/Returns Min        478.82803026581064
exploration/Actions Mean       0.059443716
exploration/Actions Std        0.6243682
exploration/Actions Max        0.99998623
exploration/Actions Min        -0.99985385
exploration/Num Paths          10
exploration/Average Returns    480.41436078279185
evaluation/num steps total     1330000
evaluation/num paths total     2660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9618664640753295
evaluation/Rewards Std         0.06328067223621126
evaluation/Rewards Max         0.9795493274088072
evaluation/Rewards Min         0.49618141015717643
evaluation/Returns Mean        480.9332320376646
evaluation/Returns Std         1.0691753243860418
evaluation/Returns Max         482.2273841000505
evaluation/Returns Min         479.4565138618791
evaluation/ExplReturns Mean    480.9332320376646
evaluation/ExplReturns Std     1.0691753243860418
evaluation/ExplReturns Max     482.2273841000505
evaluation/ExplReturns Min     479.4565138618791
evaluation/Actions Mean        0.075242065
evaluation/Actions Std         0.57211524
evaluation/Actions Max         0.999833
evaluation/Actions Min         -0.99913895
evaluation/Num Paths           10
evaluation/Average Returns     480.9332320376646
time/data storing (s)          0.033921023830771446
time/evaluation sampling (s)   111.63732386659831
time/exploration sampling (s)  113.33327134884894
time/logging (s)               0.030721071176230907
time/saving (s)                0.012842764146625996
time/training (s)              9.615402254275978
time/epoch (s)                 234.66348232887685
time/total (s)                 62163.176668738946
Epoch                          265
-----------------------------  --------------------
2023-08-01 11:14:08.669960 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 266 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3984.6758]
trainer/QF1 Loss               0.05284152
trainer/QF2 Loss               0.05812577
trainer/Policy Loss            -86.39374
trainer/Q1 Predictions Mean    99.118065
trainer/Q1 Predictions Std     4.158264
trainer/Q1 Predictions Max     104.1701
trainer/Q1 Predictions Min     71.72988
trainer/Q2 Predictions Mean    99.06003
trainer/Q2 Predictions Std     4.1603084
trainer/Q2 Predictions Max     103.99387
trainer/Q2 Predictions Min     70.535904
trainer/Q Targets Mean         99.13669
trainer/Q Targets Std          4.1429625
trainer/Q Targets Max          104.02586
trainer/Q Targets Min          70.96343
trainer/Log Pis Mean           12.857836
trainer/Log Pis Std            7.385096
trainer/Log Pis Max            40.071774
trainer/Log Pis Min            -5.948638
trainer/Policy mu Mean         0.38024488
trainer/Policy mu Std          1.5340852
trainer/Policy mu Max          4.5039244
trainer/Policy mu Min          -4.943909
trainer/Policy log std Mean    -0.7968185
trainer/Policy log std Std     0.31902763
trainer/Policy log std Max     0.056236148
trainer/Policy log std Min     -2.0799048
trainer/Alpha                  0.0022614928893744946
trainer/Alpha Loss             5.225885391235352
exploration/num steps total    1336000
exploration/num paths total    2672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9458014203146887
exploration/Rewards Std        0.08209872243593391
exploration/Rewards Max        0.9796557889724854
exploration/Rewards Min        0.48805022499388206
exploration/Returns Mean       472.9007101573444
exploration/Returns Std        10.347544018323244
exploration/Returns Max        479.3767021323867
exploration/Returns Min        442.67259202609097
exploration/Actions Mean       0.09031234
exploration/Actions Std        0.6260379
exploration/Actions Max        0.99998796
exploration/Actions Min        -0.9999909
exploration/Num Paths          10
exploration/Average Returns    472.9007101573444
evaluation/num steps total     1335000
evaluation/num paths total     2670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9261828668003327
evaluation/Rewards Std         0.10610044442838583
evaluation/Rewards Max         0.9776906828880805
evaluation/Rewards Min         0.49595668763571166
evaluation/Returns Mean        463.09143340016624
evaluation/Returns Std         38.95884725918362
evaluation/Returns Max         479.3695987096989
evaluation/Returns Min         346.51691144435165
evaluation/ExplReturns Mean    463.09143340016624
evaluation/ExplReturns Std     38.95884725918362
evaluation/ExplReturns Max     479.3695987096989
evaluation/ExplReturns Min     346.51691144435165
evaluation/Actions Mean        0.102791205
evaluation/Actions Std         0.6012164
evaluation/Actions Max         0.9997342
evaluation/Actions Min         -0.999543
evaluation/Num Paths           10
evaluation/Average Returns     463.09143340016624
time/data storing (s)          0.03218856733292341
time/evaluation sampling (s)   113.60668688081205
time/exploration sampling (s)  113.76477120630443
time/logging (s)               0.0304400697350502
time/saving (s)                0.011875716038048267
time/training (s)              9.581017019227147
time/epoch (s)                 237.02697945944965
time/total (s)                 62400.206415206194
Epoch                          266
-----------------------------  ---------------------
2023-08-01 11:18:02.147521 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 267 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4065.5115]
trainer/QF1 Loss               0.04310439
trainer/QF2 Loss               0.04659538
trainer/Policy Loss            -87.56909
trainer/Q1 Predictions Mean    99.413574
trainer/Q1 Predictions Std     4.3210287
trainer/Q1 Predictions Max     104.26642
trainer/Q1 Predictions Min     70.611496
trainer/Q2 Predictions Mean    99.482956
trainer/Q2 Predictions Std     4.3013234
trainer/Q2 Predictions Max     104.29566
trainer/Q2 Predictions Min     70.25771
trainer/Q Targets Mean         99.41195
trainer/Q Targets Std          4.301712
trainer/Q Targets Max          104.33971
trainer/Q Targets Min          70.35686
trainer/Log Pis Mean           11.9908085
trainer/Log Pis Std            7.5975137
trainer/Log Pis Max            42.278473
trainer/Log Pis Min            -1.8409338
trainer/Policy mu Mean         0.1780709
trainer/Policy mu Std          1.53028
trainer/Policy mu Max          4.9383326
trainer/Policy mu Min          -5.1983647
trainer/Policy log std Mean    -0.8270566
trainer/Policy log std Std     0.31779227
trainer/Policy log std Max     0.09830149
trainer/Policy log std Min     -2.2676072
trainer/Alpha                  0.002130522159859538
trainer/Alpha Loss             -0.056539297103881836
exploration/num steps total    1341000
exploration/num paths total    2682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9645764910790513
exploration/Rewards Std        0.05945005772952538
exploration/Rewards Max        0.9798141452056225
exploration/Rewards Min        0.48277780298989753
exploration/Returns Mean       482.2882455395255
exploration/Returns Std        0.687305214508303
exploration/Returns Max        483.06195935008276
exploration/Returns Min        480.99107364045176
exploration/Actions Mean       0.07833701
exploration/Actions Std        0.6317643
exploration/Actions Max        0.9999918
exploration/Actions Min        -0.999977
exploration/Num Paths          10
exploration/Average Returns    482.2882455395255
evaluation/num steps total     1340000
evaluation/num paths total     2680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9654286537474364
evaluation/Rewards Std         0.05775614167053276
evaluation/Rewards Max         0.978985420379983
evaluation/Rewards Min         0.49152117640666965
evaluation/Returns Mean        482.71432687371816
evaluation/Returns Std         0.377836396944302
evaluation/Returns Max         483.17379022788015
evaluation/Returns Min         482.03507360359333
evaluation/ExplReturns Mean    482.71432687371816
evaluation/ExplReturns Std     0.377836396944302
evaluation/ExplReturns Max     483.17379022788015
evaluation/ExplReturns Min     482.03507360359333
evaluation/Actions Mean        0.09697133
evaluation/Actions Std         0.5740932
evaluation/Actions Max         0.9999587
evaluation/Actions Min         -0.99960536
evaluation/Num Paths           10
evaluation/Average Returns     482.71432687371816
time/data storing (s)          0.03226748015731573
time/evaluation sampling (s)   111.67577514052391
time/exploration sampling (s)  112.36482415068895
time/logging (s)               0.031186564825475216
time/saving (s)                0.012198048643767834
time/training (s)              9.356775413267314
time/epoch (s)                 233.47302679810673
time/total (s)                 62633.682217611
Epoch                          267
-----------------------------  ---------------------
2023-08-01 11:21:55.794608 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 268 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4066.216]
trainer/QF1 Loss               0.058778077
trainer/QF2 Loss               0.040738646
trainer/Policy Loss            -88.337814
trainer/Q1 Predictions Mean    99.73871
trainer/Q1 Predictions Std     3.7220368
trainer/Q1 Predictions Max     104.002075
trainer/Q1 Predictions Min     76.63335
trainer/Q2 Predictions Mean    99.77357
trainer/Q2 Predictions Std     3.7362845
trainer/Q2 Predictions Max     104.22238
trainer/Q2 Predictions Min     76.709755
trainer/Q Targets Mean         99.79689
trainer/Q Targets Std          3.7070658
trainer/Q Targets Max          104.25779
trainer/Q Targets Min          76.94612
trainer/Log Pis Mean           11.528875
trainer/Log Pis Std            6.6265264
trainer/Log Pis Max            38.136673
trainer/Log Pis Min            -0.7480844
trainer/Policy mu Mean         0.22551346
trainer/Policy mu Std          1.4517523
trainer/Policy mu Max          5.159959
trainer/Policy mu Min          -3.9117923
trainer/Policy log std Mean    -0.9011728
trainer/Policy log std Std     0.3478762
trainer/Policy log std Max     0.092344165
trainer/Policy log std Min     -2.292328
trainer/Alpha                  0.001977925654500723
trainer/Alpha Loss             -2.9330575466156006
exploration/num steps total    1346000
exploration/num paths total    2692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9631634999945887
exploration/Rewards Std        0.05657942054405137
exploration/Rewards Max        0.9796865349592224
exploration/Rewards Min        0.49807252388127427
exploration/Returns Mean       481.58174999729437
exploration/Returns Std        0.576885921235418
exploration/Returns Max        482.2730675458418
exploration/Returns Min        480.5121921335749
exploration/Actions Mean       0.19793276
exploration/Actions Std        0.59605247
exploration/Actions Max        0.9999851
exploration/Actions Min        -0.99990404
exploration/Num Paths          10
exploration/Average Returns    481.58174999729437
evaluation/num steps total     1345000
evaluation/num paths total     2690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.963333917939131
evaluation/Rewards Std         0.057757833698130895
evaluation/Rewards Max         0.9786096374275636
evaluation/Rewards Min         0.4812664255616206
evaluation/Returns Mean        481.6669589695654
evaluation/Returns Std         0.6335200140203735
evaluation/Returns Max         482.68952047807625
evaluation/Returns Min         480.8779121481102
evaluation/ExplReturns Mean    481.6669589695654
evaluation/ExplReturns Std     0.6335200140203735
evaluation/ExplReturns Max     482.68952047807625
evaluation/ExplReturns Min     480.8779121481102
evaluation/Actions Mean        0.20558816
evaluation/Actions Std         0.5361293
evaluation/Actions Max         0.99992955
evaluation/Actions Min         -0.9995191
evaluation/Num Paths           10
evaluation/Average Returns     481.6669589695654
time/data storing (s)          0.032102735713124275
time/evaluation sampling (s)   112.1935807466507
time/exploration sampling (s)  112.05772406980395
time/logging (s)               0.030438478104770184
time/saving (s)                0.010766655206680298
time/training (s)              9.31677649449557
time/epoch (s)                 233.6413891799748
time/total (s)                 62867.32605400309
Epoch                          268
-----------------------------  --------------------
2023-08-01 11:25:48.078328 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 269 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4025.657]
trainer/QF1 Loss               0.04842421
trainer/QF2 Loss               0.038713485
trainer/Policy Loss            -87.380135
trainer/Q1 Predictions Mean    99.637314
trainer/Q1 Predictions Std     3.4702919
trainer/Q1 Predictions Max     103.992256
trainer/Q1 Predictions Min     89.17384
trainer/Q2 Predictions Mean    99.65396
trainer/Q2 Predictions Std     3.465751
trainer/Q2 Predictions Max     103.98031
trainer/Q2 Predictions Min     89.31974
trainer/Q Targets Mean         99.63251
trainer/Q Targets Std          3.5168657
trainer/Q Targets Max          104.007164
trainer/Q Targets Min          89.29878
trainer/Log Pis Mean           12.406136
trainer/Log Pis Std            7.623666
trainer/Log Pis Max            38.307045
trainer/Log Pis Min            -9.015134
trainer/Policy mu Mean         0.25093064
trainer/Policy mu Std          1.5016941
trainer/Policy mu Max          4.7160745
trainer/Policy mu Min          -4.570952
trainer/Policy log std Mean    -0.870915
trainer/Policy log std Std     0.3459762
trainer/Policy log std Max     0.27946907
trainer/Policy log std Min     -2.291609
trainer/Alpha                  0.0019762173760682344
trainer/Alpha Loss             2.528899669647217
exploration/num steps total    1351000
exploration/num paths total    2702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9564844504418248
exploration/Rewards Std        0.06005816921813265
exploration/Rewards Max        0.9791376216093998
exploration/Rewards Min        0.4911555314278185
exploration/Returns Mean       478.2422252209124
exploration/Returns Std        0.9586806259355054
exploration/Returns Max        480.16368232106163
exploration/Returns Min        476.6897911063751
exploration/Actions Mean       0.1375212
exploration/Actions Std        0.59164464
exploration/Actions Max        0.9999963
exploration/Actions Min        -0.9997539
exploration/Num Paths          10
exploration/Average Returns    478.2422252209124
evaluation/num steps total     1350000
evaluation/num paths total     2700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9566168499287447
evaluation/Rewards Std         0.05957661003238355
evaluation/Rewards Max         0.9789673296029818
evaluation/Rewards Min         0.4887821727061953
evaluation/Returns Mean        478.3084249643722
evaluation/Returns Std         0.6660649013483099
evaluation/Returns Max         480.1388818343641
evaluation/Returns Min         477.52705868157165
evaluation/ExplReturns Mean    478.3084249643722
evaluation/ExplReturns Std     0.6660649013483099
evaluation/ExplReturns Max     480.1388818343641
evaluation/ExplReturns Min     477.52705868157165
evaluation/Actions Mean        0.16994275
evaluation/Actions Std         0.51924324
evaluation/Actions Max         0.99982685
evaluation/Actions Min         -0.99886525
evaluation/Num Paths           10
evaluation/Average Returns     478.3084249643722
time/data storing (s)          0.03207928687334061
time/evaluation sampling (s)   110.52962951827794
time/exploration sampling (s)  112.06042449455708
time/logging (s)               0.03155256900936365
time/saving (s)                0.012781117111444473
time/training (s)              9.613345194607973
time/epoch (s)                 232.27981218043715
time/total (s)                 63099.6083843559
Epoch                          269
-----------------------------  ---------------------
2023-08-01 11:29:40.835987 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 270 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3958.2168]
trainer/QF1 Loss               0.0502329
trainer/QF2 Loss               0.047008626
trainer/Policy Loss            -87.47932
trainer/Q1 Predictions Mean    99.85455
trainer/Q1 Predictions Std     3.6798217
trainer/Q1 Predictions Max     103.82772
trainer/Q1 Predictions Min     75.04192
trainer/Q2 Predictions Mean    99.80783
trainer/Q2 Predictions Std     3.6748197
trainer/Q2 Predictions Max     103.727554
trainer/Q2 Predictions Min     75.41358
trainer/Q Targets Mean         99.77229
trainer/Q Targets Std          3.6783073
trainer/Q Targets Max          103.68602
trainer/Q Targets Min          75.2207
trainer/Log Pis Mean           12.47889
trainer/Log Pis Std            7.62103
trainer/Log Pis Max            44.77813
trainer/Log Pis Min            -3.6685846
trainer/Policy mu Mean         0.24910176
trainer/Policy mu Std          1.5319352
trainer/Policy mu Max          6.368576
trainer/Policy mu Min          -6.842013
trainer/Policy log std Mean    -0.84879327
trainer/Policy log std Std     0.33731797
trainer/Policy log std Max     0.60522604
trainer/Policy log std Min     -2.2350514
trainer/Alpha                  0.0018731222953647375
trainer/Alpha Loss             3.0075302124023438
exploration/num steps total    1356000
exploration/num paths total    2712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9546621097517258
exploration/Rewards Std        0.06103851817143228
exploration/Rewards Max        0.9786932279856008
exploration/Rewards Min        0.4913598633134202
exploration/Returns Mean       477.3310548758629
exploration/Returns Std        0.9510034895786103
exploration/Returns Max        478.56975696478185
exploration/Returns Min        475.22692741381826
exploration/Actions Mean       0.051641475
exploration/Actions Std        0.6326323
exploration/Actions Max        0.9999942
exploration/Actions Min        -0.9998684
exploration/Num Paths          10
exploration/Average Returns    477.3310548758629
evaluation/num steps total     1355000
evaluation/num paths total     2710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9566822952606165
evaluation/Rewards Std         0.05848682762386598
evaluation/Rewards Max         0.9770179458453943
evaluation/Rewards Min         0.4901709002207172
evaluation/Returns Mean        478.3411476303083
evaluation/Returns Std         0.7375993120274873
evaluation/Returns Max         479.19044467899306
evaluation/Returns Min         476.71323142420323
evaluation/ExplReturns Mean    478.3411476303083
evaluation/ExplReturns Std     0.7375993120274873
evaluation/ExplReturns Max     479.19044467899306
evaluation/ExplReturns Min     476.71323142420323
evaluation/Actions Mean        0.045941323
evaluation/Actions Std         0.5700862
evaluation/Actions Max         0.9998296
evaluation/Actions Min         -0.99918365
evaluation/Num Paths           10
evaluation/Average Returns     478.3411476303083
time/data storing (s)          0.0328454477712512
time/evaluation sampling (s)   111.42628525290638
time/exploration sampling (s)  111.47265060525388
time/logging (s)               0.030786636285483837
time/saving (s)                0.012654103338718414
time/training (s)              9.776651808060706
time/epoch (s)                 232.75187385361642
time/total (s)                 63332.36275575403
Epoch                          270
-----------------------------  ---------------------
2023-08-01 11:33:35.107828 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 271 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4006.822]
trainer/QF1 Loss               0.079030246
trainer/QF2 Loss               0.069440864
trainer/Policy Loss            -87.595314
trainer/Q1 Predictions Mean    99.8235
trainer/Q1 Predictions Std     3.4688077
trainer/Q1 Predictions Max     103.783226
trainer/Q1 Predictions Min     89.024765
trainer/Q2 Predictions Mean    99.823364
trainer/Q2 Predictions Std     3.4670436
trainer/Q2 Predictions Max     103.758
trainer/Q2 Predictions Min     88.20237
trainer/Q Targets Mean         99.70183
trainer/Q Targets Std          3.4805653
trainer/Q Targets Max          103.75706
trainer/Q Targets Min          86.93585
trainer/Log Pis Mean           12.3883505
trainer/Log Pis Std            6.836611
trainer/Log Pis Max            40.08139
trainer/Log Pis Min            -1.2757568
trainer/Policy mu Mean         0.11663556
trainer/Policy mu Std          1.5514538
trainer/Policy mu Max          6.319763
trainer/Policy mu Min          -4.3447175
trainer/Policy log std Mean    -0.84097385
trainer/Policy log std Std     0.31798312
trainer/Policy log std Max     0.07950419
trainer/Policy log std Min     -2.2182388
trainer/Alpha                  0.0020213464740663767
trainer/Alpha Loss             2.4094200134277344
exploration/num steps total    1361000
exploration/num paths total    2722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9434697203152748
exploration/Rewards Std        0.07820645005466528
exploration/Rewards Max        0.97951881618863
exploration/Rewards Min        0.48767603013673794
exploration/Returns Mean       471.7348601576373
exploration/Returns Std        4.200997105705567
exploration/Returns Max        477.6135479293528
exploration/Returns Min        464.21724293951826
exploration/Actions Mean       0.010920647
exploration/Actions Std        0.5759821
exploration/Actions Max        0.9999322
exploration/Actions Min        -0.9998377
exploration/Num Paths          10
exploration/Average Returns    471.7348601576373
evaluation/num steps total     1360000
evaluation/num paths total     2720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9211686899268711
evaluation/Rewards Std         0.10058050148759778
evaluation/Rewards Max         0.9773005266398553
evaluation/Rewards Min         0.4905581703906573
evaluation/Returns Mean        460.58434496343546
evaluation/Returns Std         11.961497044975173
evaluation/Returns Max         475.99664915116483
evaluation/Returns Min         443.710801139086
evaluation/ExplReturns Mean    460.58434496343546
evaluation/ExplReturns Std     11.961497044975173
evaluation/ExplReturns Max     475.99664915116483
evaluation/ExplReturns Min     443.710801139086
evaluation/Actions Mean        -0.012340929
evaluation/Actions Std         0.48781747
evaluation/Actions Max         0.9995538
evaluation/Actions Min         -0.9996678
evaluation/Num Paths           10
evaluation/Average Returns     460.58434496343546
time/data storing (s)          0.032102519646286964
time/evaluation sampling (s)   111.83953957632184
time/exploration sampling (s)  112.81936993822455
time/logging (s)               0.03043952863663435
time/saving (s)                0.012549429200589657
time/training (s)              9.53242658637464
time/epoch (s)                 234.26642757840455
time/total (s)                 63566.63173301704
Epoch                          271
-----------------------------  ---------------------
2023-08-01 11:37:29.324951 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 272 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4049.9053]
trainer/QF1 Loss               0.036125336
trainer/QF2 Loss               0.03876792
trainer/Policy Loss            -86.22694
trainer/Q1 Predictions Mean    99.0961
trainer/Q1 Predictions Std     3.8732703
trainer/Q1 Predictions Max     103.46555
trainer/Q1 Predictions Min     78.23475
trainer/Q2 Predictions Mean    99.12843
trainer/Q2 Predictions Std     3.862563
trainer/Q2 Predictions Max     103.39826
trainer/Q2 Predictions Min     78.04962
trainer/Q Targets Mean         99.13411
trainer/Q Targets Std          3.854214
trainer/Q Targets Max          103.27367
trainer/Q Targets Min          78.56811
trainer/Log Pis Mean           13.069566
trainer/Log Pis Std            7.429663
trainer/Log Pis Max            37.164967
trainer/Log Pis Min            -1.4912901
trainer/Policy mu Mean         0.10159099
trainer/Policy mu Std          1.5673642
trainer/Policy mu Max          5.6256704
trainer/Policy mu Min          -4.2247667
trainer/Policy log std Mean    -0.8408861
trainer/Policy log std Std     0.33287928
trainer/Policy log std Max     0.21527421
trainer/Policy log std Min     -2.3334646
trainer/Alpha                  0.002016680082306266
trainer/Alpha Loss             6.63817834854126
exploration/num steps total    1366000
exploration/num paths total    2732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9444327022684654
exploration/Rewards Std        0.06882845057200107
exploration/Rewards Max        0.9790891875153682
exploration/Rewards Min        0.4916175806590247
exploration/Returns Mean       472.2163511342328
exploration/Returns Std        3.836055070382109
exploration/Returns Max        476.6090791549082
exploration/Returns Min        463.2527484504558
exploration/Actions Mean       0.024371698
exploration/Actions Std        0.5918512
exploration/Actions Max        0.9999122
exploration/Actions Min        -0.9999894
exploration/Num Paths          10
exploration/Average Returns    472.2163511342328
evaluation/num steps total     1365000
evaluation/num paths total     2730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.93764096492391
evaluation/Rewards Std         0.07708186478615363
evaluation/Rewards Max         0.9785528147667798
evaluation/Rewards Min         0.4881607417451854
evaluation/Returns Mean        468.82048246195507
evaluation/Returns Std         8.431276852657478
evaluation/Returns Max         473.61810847358817
evaluation/Returns Min         443.9747365649034
evaluation/ExplReturns Mean    468.82048246195507
evaluation/ExplReturns Std     8.431276852657478
evaluation/ExplReturns Max     473.61810847358817
evaluation/ExplReturns Min     443.9747365649034
evaluation/Actions Mean        0.016796473
evaluation/Actions Std         0.52005374
evaluation/Actions Max         0.999954
evaluation/Actions Min         -0.99986714
evaluation/Num Paths           10
evaluation/Average Returns     468.82048246195507
time/data storing (s)          0.032268633134663105
time/evaluation sampling (s)   112.26230867952108
time/exploration sampling (s)  112.37748263310641
time/logging (s)               0.030624105595052242
time/saving (s)                0.012217974290251732
time/training (s)              9.497455934993923
time/epoch (s)                 234.21235796064138
time/total (s)                 63800.846530413255
Epoch                          272
-----------------------------  --------------------
2023-08-01 11:41:21.315840 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 273 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4576.481]
trainer/QF1 Loss               0.04936537
trainer/QF2 Loss               0.05265343
trainer/Policy Loss            -88.96154
trainer/Q1 Predictions Mean    100.13809
trainer/Q1 Predictions Std     3.3073199
trainer/Q1 Predictions Max     103.17097
trainer/Q1 Predictions Min     89.11399
trainer/Q2 Predictions Mean    100.10439
trainer/Q2 Predictions Std     3.3024943
trainer/Q2 Predictions Max     103.101425
trainer/Q2 Predictions Min     89.19009
trainer/Q Targets Mean         100.26303
trainer/Q Targets Std          3.3049247
trainer/Q Targets Max          103.26147
trainer/Q Targets Min          89.180984
trainer/Log Pis Mean           11.324271
trainer/Log Pis Std            6.868063
trainer/Log Pis Max            36.478558
trainer/Log Pis Min            -4.0641804
trainer/Policy mu Mean         0.1521756
trainer/Policy mu Std          1.480649
trainer/Policy mu Max          4.824093
trainer/Policy mu Min          -5.095756
trainer/Policy log std Mean    -0.85609895
trainer/Policy log std Std     0.34447017
trainer/Policy log std Max     0.22921157
trainer/Policy log std Min     -2.2584589
trainer/Alpha                  0.0020435017067939043
trainer/Alpha Loss             -4.184918403625488
exploration/num steps total    1371000
exploration/num paths total    2742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8717650697402627
exploration/Rewards Std        0.13155425417538938
exploration/Rewards Max        0.976851632737314
exploration/Rewards Min        0.2785061079860546
exploration/Returns Mean       435.88253487013134
exploration/Returns Std        36.26649363931909
exploration/Returns Max        455.26062836553524
exploration/Returns Min        327.65478533665697
exploration/Actions Mean       0.048784245
exploration/Actions Std        0.5945414
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.9999994
exploration/Num Paths          10
exploration/Average Returns    435.88253487013134
evaluation/num steps total     1370000
evaluation/num paths total     2740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9228211860487654
evaluation/Rewards Std         0.07505152486588476
evaluation/Rewards Max         0.978420920746618
evaluation/Rewards Min         0.5031522479578108
evaluation/Returns Mean        461.4105930243826
evaluation/Returns Std         3.7343233498646153
evaluation/Returns Max         469.774652472414
evaluation/Returns Min         457.21574578714024
evaluation/ExplReturns Mean    461.4105930243826
evaluation/ExplReturns Std     3.7343233498646153
evaluation/ExplReturns Max     469.774652472414
evaluation/ExplReturns Min     457.21574578714024
evaluation/Actions Mean        0.04520653
evaluation/Actions Std         0.48590907
evaluation/Actions Max         0.999984
evaluation/Actions Min         -0.9999492
evaluation/Num Paths           10
evaluation/Average Returns     461.4105930243826
time/data storing (s)          0.03238190338015556
time/evaluation sampling (s)   110.70281274337322
time/exploration sampling (s)  111.5515679558739
time/logging (s)               0.031008180230855942
time/saving (s)                0.012821243144571781
time/training (s)              9.655658063478768
time/epoch (s)                 231.98625008948147
time/total (s)                 64032.835237013176
Epoch                          273
-----------------------------  ---------------------
2023-08-01 11:45:14.365720 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 274 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4526.508]
trainer/QF1 Loss               0.046138182
trainer/QF2 Loss               0.051595956
trainer/Policy Loss            -87.8226
trainer/Q1 Predictions Mean    100.23877
trainer/Q1 Predictions Std     3.1939976
trainer/Q1 Predictions Max     103.32695
trainer/Q1 Predictions Min     90.00276
trainer/Q2 Predictions Mean    100.206276
trainer/Q2 Predictions Std     3.165084
trainer/Q2 Predictions Max     103.21444
trainer/Q2 Predictions Min     90.19285
trainer/Q Targets Mean         100.30702
trainer/Q Targets Std          3.202535
trainer/Q Targets Max          103.391335
trainer/Q Targets Min          89.95438
trainer/Log Pis Mean           12.564004
trainer/Log Pis Std            6.8188977
trainer/Log Pis Max            36.631462
trainer/Log Pis Min            -4.145959
trainer/Policy mu Mean         0.1782797
trainer/Policy mu Std          1.5825728
trainer/Policy mu Max          5.6994615
trainer/Policy mu Min          -4.6409025
trainer/Policy log std Mean    -0.8058916
trainer/Policy log std Std     0.3258004
trainer/Policy log std Max     0.3356638
trainer/Policy log std Min     -2.2655506
trainer/Alpha                  0.0021867193281650543
trainer/Alpha Loss             3.45497727394104
exploration/num steps total    1376000
exploration/num paths total    2752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9378655934115239
exploration/Rewards Std        0.06846204880545412
exploration/Rewards Max        0.9780335412111644
exploration/Rewards Min        0.49312609799227075
exploration/Returns Mean       468.93279670576203
exploration/Returns Std        3.009591417005797
exploration/Returns Max        472.06327482702363
exploration/Returns Min        462.10468955962233
exploration/Actions Mean       0.014005034
exploration/Actions Std        0.6302518
exploration/Actions Max        1.0
exploration/Actions Min        -0.99995255
exploration/Num Paths          10
exploration/Average Returns    468.93279670576203
evaluation/num steps total     1375000
evaluation/num paths total     2750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9478257445843261
evaluation/Rewards Std         0.0684242034655988
evaluation/Rewards Max         0.9777613838185639
evaluation/Rewards Min         0.4903753220427676
evaluation/Returns Mean        473.9128722921629
evaluation/Returns Std         4.828554559783904
evaluation/Returns Max         478.39794369190315
evaluation/Returns Min         462.6739613379862
evaluation/ExplReturns Mean    473.9128722921629
evaluation/ExplReturns Std     4.828554559783904
evaluation/ExplReturns Max     478.39794369190315
evaluation/ExplReturns Min     462.6739613379862
evaluation/Actions Mean        -0.10578449
evaluation/Actions Std         0.6061238
evaluation/Actions Max         0.9999987
evaluation/Actions Min         -0.9995205
evaluation/Num Paths           10
evaluation/Average Returns     473.9128722921629
time/data storing (s)          0.032224022783339024
time/evaluation sampling (s)   111.12176018022001
time/exploration sampling (s)  112.21139176841825
time/logging (s)               0.0307828476652503
time/saving (s)                0.012075084261596203
time/training (s)              9.636404705233872
time/epoch (s)                 233.04463860858232
time/total (s)                 64265.88236553967
Epoch                          274
-----------------------------  ---------------------
2023-08-01 11:49:07.320294 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 275 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3938.223]
trainer/QF1 Loss               0.0625443
trainer/QF2 Loss               0.05949332
trainer/Policy Loss            -89.6556
trainer/Q1 Predictions Mean    100.48305
trainer/Q1 Predictions Std     3.2566407
trainer/Q1 Predictions Max     103.282974
trainer/Q1 Predictions Min     90.861336
trainer/Q2 Predictions Mean    100.46677
trainer/Q2 Predictions Std     3.2403185
trainer/Q2 Predictions Max     103.2775
trainer/Q2 Predictions Min     90.85168
trainer/Q Targets Mean         100.43564
trainer/Q Targets Std          3.2592733
trainer/Q Targets Max          103.42277
trainer/Q Targets Min          90.80127
trainer/Log Pis Mean           10.978415
trainer/Log Pis Std            7.0510654
trainer/Log Pis Max            31.577572
trainer/Log Pis Min            -6.8886795
trainer/Policy mu Mean         0.1669702
trainer/Policy mu Std          1.4863102
trainer/Policy mu Max          4.2642612
trainer/Policy mu Min          -4.475776
trainer/Policy log std Mean    -0.79681283
trainer/Policy log std Std     0.3076094
trainer/Policy log std Max     -0.0046945214
trainer/Policy log std Min     -2.1463764
trainer/Alpha                  0.002140715718269348
trainer/Alpha Loss             -6.279106140136719
exploration/num steps total    1381000
exploration/num paths total    2762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9549398111706094
exploration/Rewards Std        0.06445154265926356
exploration/Rewards Max        0.9798674031026704
exploration/Rewards Min        0.4984134035078552
exploration/Returns Mean       477.4699055853045
exploration/Returns Std        3.313732300455592
exploration/Returns Max        481.60648433294386
exploration/Returns Min        470.99809737081614
exploration/Actions Mean       0.068109885
exploration/Actions Std        0.58782727
exploration/Actions Max        0.99997133
exploration/Actions Min        -0.9998057
exploration/Num Paths          10
exploration/Average Returns    477.4699055853045
evaluation/num steps total     1380000
evaluation/num paths total     2760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9244001637921611
evaluation/Rewards Std         0.0994060490824522
evaluation/Rewards Max         0.9782820923498591
evaluation/Rewards Min         0.4901604396180106
evaluation/Returns Mean        462.2000818960804
evaluation/Returns Std         16.361658866394247
evaluation/Returns Max         477.0577668482795
evaluation/Returns Min         434.0939275117707
evaluation/ExplReturns Mean    462.2000818960804
evaluation/ExplReturns Std     16.361658866394247
evaluation/ExplReturns Max     477.0577668482795
evaluation/ExplReturns Min     434.0939275117707
evaluation/Actions Mean        -0.00656356
evaluation/Actions Std         0.54120636
evaluation/Actions Max         0.99973255
evaluation/Actions Min         -0.99965006
evaluation/Num Paths           10
evaluation/Average Returns     462.2000818960804
time/data storing (s)          0.031954227946698666
time/evaluation sampling (s)   111.59725914336741
time/exploration sampling (s)  111.64366969559342
time/logging (s)               0.030436565168201923
time/saving (s)                0.012547881342470646
time/training (s)              9.63323784712702
time/epoch (s)                 232.94910536054522
time/total (s)                 64498.83403506223
Epoch                          275
-----------------------------  --------------------
2023-08-01 11:53:01.365385 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 276 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4549.865]
trainer/QF1 Loss               0.041897845
trainer/QF2 Loss               0.040095095
trainer/Policy Loss            -89.22572
trainer/Q1 Predictions Mean    100.60457
trainer/Q1 Predictions Std     3.2026377
trainer/Q1 Predictions Max     104.02645
trainer/Q1 Predictions Min     91.49166
trainer/Q2 Predictions Mean    100.54161
trainer/Q2 Predictions Std     3.237595
trainer/Q2 Predictions Max     103.51647
trainer/Q2 Predictions Min     91.773155
trainer/Q Targets Mean         100.55974
trainer/Q Targets Std          3.231793
trainer/Q Targets Max          103.75138
trainer/Q Targets Min          91.37343
trainer/Log Pis Mean           11.501713
trainer/Log Pis Std            6.793537
trainer/Log Pis Max            34.410583
trainer/Log Pis Min            -3.4742267
trainer/Policy mu Mean         0.0314937
trainer/Policy mu Std          1.481185
trainer/Policy mu Max          4.6360373
trainer/Policy mu Min          -4.739622
trainer/Policy log std Mean    -0.8642202
trainer/Policy log std Std     0.3442585
trainer/Policy log std Max     0.013337374
trainer/Policy log std Min     -2.4393666
trainer/Alpha                  0.0020448965951800346
trainer/Alpha Loss             -3.0855660438537598
exploration/num steps total    1386000
exploration/num paths total    2772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9477597201939089
exploration/Rewards Std        0.05573749284369322
exploration/Rewards Max        0.9788789164263726
exploration/Rewards Min        0.487686651639061
exploration/Returns Mean       473.8798600969543
exploration/Returns Std        2.075828091367283
exploration/Returns Max        476.6002390408187
exploration/Returns Min        468.522301975449
exploration/Actions Mean       -0.045703556
exploration/Actions Std        0.65622866
exploration/Actions Max        0.999824
exploration/Actions Min        -0.9999907
exploration/Num Paths          10
exploration/Average Returns    473.8798600969543
evaluation/num steps total     1385000
evaluation/num paths total     2770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9541151877778561
evaluation/Rewards Std         0.05464342450552122
evaluation/Rewards Max         0.9776952507576896
evaluation/Rewards Min         0.4937442259879736
evaluation/Returns Mean        477.057593888928
evaluation/Returns Std         3.7580664408479207
evaluation/Returns Max         483.274843774965
evaluation/Returns Min         472.03210792751986
evaluation/ExplReturns Mean    477.057593888928
evaluation/ExplReturns Std     3.7580664408479207
evaluation/ExplReturns Max     483.274843774965
evaluation/ExplReturns Min     472.03210792751986
evaluation/Actions Mean        -0.075860165
evaluation/Actions Std         0.5546633
evaluation/Actions Max         0.99953604
evaluation/Actions Min         -0.99977607
evaluation/Num Paths           10
evaluation/Average Returns     477.057593888928
time/data storing (s)          0.032122302800416946
time/evaluation sampling (s)   111.36121567897499
time/exploration sampling (s)  112.93643322587013
time/logging (s)               0.030688402242958546
time/saving (s)                0.01224472839385271
time/training (s)              9.667401138693094
time/epoch (s)                 234.04010547697544
time/total (s)                 64732.8768467186
Epoch                          276
-----------------------------  ---------------------
2023-08-01 11:56:59.480758 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 277 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4468.115]
trainer/QF1 Loss               0.042111002
trainer/QF2 Loss               0.045761723
trainer/Policy Loss            -89.65051
trainer/Q1 Predictions Mean    101.135056
trainer/Q1 Predictions Std     2.7806606
trainer/Q1 Predictions Max     103.16809
trainer/Q1 Predictions Min     90.972206
trainer/Q2 Predictions Mean    101.2008
trainer/Q2 Predictions Std     2.818014
trainer/Q2 Predictions Max     103.22916
trainer/Q2 Predictions Min     90.59468
trainer/Q Targets Mean         101.100044
trainer/Q Targets Std          2.8117764
trainer/Q Targets Max          103.17419
trainer/Q Targets Min          90.23097
trainer/Log Pis Mean           11.64291
trainer/Log Pis Std            7.124552
trainer/Log Pis Max            44.867973
trainer/Log Pis Min            -6.0719743
trainer/Policy mu Mean         0.13099131
trainer/Policy mu Std          1.4891561
trainer/Policy mu Max          4.610459
trainer/Policy mu Min          -4.583804
trainer/Policy log std Mean    -0.8479161
trainer/Policy log std Std     0.35230017
trainer/Policy log std Max     0.16885722
trainer/Policy log std Min     -2.3311522
trainer/Alpha                  0.0020170656498521566
trainer/Alpha Loss             -2.216106414794922
exploration/num steps total    1391000
exploration/num paths total    2782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.920976567443143
exploration/Rewards Std        0.09980140751371352
exploration/Rewards Max        0.9796234912956877
exploration/Rewards Min        0.4920639020708298
exploration/Returns Mean       460.4882837215716
exploration/Returns Std        15.331828018259536
exploration/Returns Max        481.0797174365984
exploration/Returns Min        419.3555071694851
exploration/Actions Mean       -0.03550589
exploration/Actions Std        0.6562864
exploration/Actions Max        0.99999946
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    460.4882837215716
evaluation/num steps total     1390000
evaluation/num paths total     2780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9571809625320035
evaluation/Rewards Std         0.05548135941704456
evaluation/Rewards Max         0.9759599043522368
evaluation/Rewards Min         0.48437126244583606
evaluation/Returns Mean        478.5904812660018
evaluation/Returns Std         1.931444878079407
evaluation/Returns Max         482.73032220843544
evaluation/Returns Min         475.82537381360873
evaluation/ExplReturns Mean    478.5904812660018
evaluation/ExplReturns Std     1.931444878079407
evaluation/ExplReturns Max     482.73032220843544
evaluation/ExplReturns Min     475.82537381360873
evaluation/Actions Mean        -0.15151227
evaluation/Actions Std         0.6985567
evaluation/Actions Max         0.99964637
evaluation/Actions Min         -0.99948233
evaluation/Num Paths           10
evaluation/Average Returns     478.5904812660018
time/data storing (s)          0.032349685207009315
time/evaluation sampling (s)   114.81570928916335
time/exploration sampling (s)  113.5149909555912
time/logging (s)               0.030503513291478157
time/saving (s)                0.011146878823637962
time/training (s)              9.70503019914031
time/epoch (s)                 238.109730521217
time/total (s)                 64970.9894569898
Epoch                          277
-----------------------------  ---------------------
2023-08-01 12:00:54.730514 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 278 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3751.149]
trainer/QF1 Loss               0.036460433
trainer/QF2 Loss               0.040182944
trainer/Policy Loss            -89.428825
trainer/Q1 Predictions Mean    100.737274
trainer/Q1 Predictions Std     3.0896208
trainer/Q1 Predictions Max     103.13521
trainer/Q1 Predictions Min     91.07824
trainer/Q2 Predictions Mean    100.71036
trainer/Q2 Predictions Std     3.108711
trainer/Q2 Predictions Max     103.095314
trainer/Q2 Predictions Min     90.78855
trainer/Q Targets Mean         100.761826
trainer/Q Targets Std          3.0822449
trainer/Q Targets Max          103.173965
trainer/Q Targets Min          91.13169
trainer/Log Pis Mean           11.456675
trainer/Log Pis Std            6.7984414
trainer/Log Pis Max            43.748512
trainer/Log Pis Min            -5.624214
trainer/Policy mu Mean         0.14626366
trainer/Policy mu Std          1.4618737
trainer/Policy mu Max          3.9328804
trainer/Policy mu Min          -4.511147
trainer/Policy log std Mean    -0.8379504
trainer/Policy log std Std     0.32305115
trainer/Policy log std Max     0.1322552
trainer/Policy log std Min     -2.487647
trainer/Alpha                  0.0018083385657519102
trainer/Alpha Loss             -3.4311769008636475
exploration/num steps total    1396000
exploration/num paths total    2792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9474858094286843
exploration/Rewards Std        0.07080738727165506
exploration/Rewards Max        0.9781896503470835
exploration/Rewards Min        0.49299502050188804
exploration/Returns Mean       473.74290471434216
exploration/Returns Std        5.277665218640522
exploration/Returns Max        477.09168198966864
exploration/Returns Min        458.4737681935565
exploration/Actions Mean       -0.03753312
exploration/Actions Std        0.66417843
exploration/Actions Max        0.99999756
exploration/Actions Min        -0.99994004
exploration/Num Paths          10
exploration/Average Returns    473.74290471434216
evaluation/num steps total     1395000
evaluation/num paths total     2790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9549831202186452
evaluation/Rewards Std         0.06132317940147701
evaluation/Rewards Max         0.9773566347037996
evaluation/Rewards Min         0.497670190640277
evaluation/Returns Mean        477.49156010932256
evaluation/Returns Std         1.4746232458341246
evaluation/Returns Max         479.3376942281212
evaluation/Returns Min         474.69887051892135
evaluation/ExplReturns Mean    477.49156010932256
evaluation/ExplReturns Std     1.4746232458341246
evaluation/ExplReturns Max     479.3376942281212
evaluation/ExplReturns Min     474.69887051892135
evaluation/Actions Mean        -0.06854961
evaluation/Actions Std         0.6646962
evaluation/Actions Max         0.99985445
evaluation/Actions Min         -0.9999443
evaluation/Num Paths           10
evaluation/Average Returns     477.49156010932256
time/data storing (s)          0.03269363287836313
time/evaluation sampling (s)   112.76625836454332
time/exploration sampling (s)  113.22151901107281
time/logging (s)               0.03032844979315996
time/saving (s)                0.012710081413388252
time/training (s)              9.180931997485459
time/epoch (s)                 235.2444415371865
time/total (s)                 65206.23648896627
Epoch                          278
-----------------------------  ---------------------
2023-08-01 12:04:49.755853 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 279 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3926.573]
trainer/QF1 Loss               0.041388445
trainer/QF2 Loss               0.04736403
trainer/Policy Loss            -89.090546
trainer/Q1 Predictions Mean    100.70716
trainer/Q1 Predictions Std     3.1214793
trainer/Q1 Predictions Max     103.29346
trainer/Q1 Predictions Min     89.910995
trainer/Q2 Predictions Mean    100.72293
trainer/Q2 Predictions Std     3.1184533
trainer/Q2 Predictions Max     103.326965
trainer/Q2 Predictions Min     89.986145
trainer/Q Targets Mean         100.637665
trainer/Q Targets Std          3.1000705
trainer/Q Targets Max          103.10121
trainer/Q Targets Min          89.786835
trainer/Log Pis Mean           11.740097
trainer/Log Pis Std            8.435664
trainer/Log Pis Max            38.068874
trainer/Log Pis Min            -6.8448534
trainer/Policy mu Mean         0.19521506
trainer/Policy mu Std          1.5093136
trainer/Policy mu Max          5.231665
trainer/Policy mu Min          -5.288129
trainer/Policy log std Mean    -0.83149606
trainer/Policy log std Std     0.31352222
trainer/Policy log std Max     0.1322073
trainer/Policy log std Min     -2.452073
trainer/Alpha                  0.0016553428722545505
trainer/Alpha Loss             -1.664294719696045
exploration/num steps total    1401000
exploration/num paths total    2802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9614478956373845
exploration/Rewards Std        0.04925432998007602
exploration/Rewards Max        0.9784221636700079
exploration/Rewards Min        0.4999605301607248
exploration/Returns Mean       480.72394781869224
exploration/Returns Std        1.4883398670805208
exploration/Returns Max        482.2575168795824
exploration/Returns Min        477.4147008571759
exploration/Actions Mean       -0.018886333
exploration/Actions Std        0.63315964
exploration/Actions Max        0.9999814
exploration/Actions Min        -0.99996185
exploration/Num Paths          10
exploration/Average Returns    480.72394781869224
evaluation/num steps total     1400000
evaluation/num paths total     2800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9601550092477604
evaluation/Rewards Std         0.05177525363622768
evaluation/Rewards Max         0.9780021187939388
evaluation/Rewards Min         0.49443753416103586
evaluation/Returns Mean        480.0775046238803
evaluation/Returns Std         2.003703692100518
evaluation/Returns Max         482.619587956214
evaluation/Returns Min         477.2039738169695
evaluation/ExplReturns Mean    480.0775046238803
evaluation/ExplReturns Std     2.003703692100518
evaluation/ExplReturns Max     482.619587956214
evaluation/ExplReturns Min     477.2039738169695
evaluation/Actions Mean        -0.0039367364
evaluation/Actions Std         0.5698165
evaluation/Actions Max         0.99992955
evaluation/Actions Min         -0.9997995
evaluation/Num Paths           10
evaluation/Average Returns     480.0775046238803
time/data storing (s)          0.032381318509578705
time/evaluation sampling (s)   112.13167176116258
time/exploration sampling (s)  113.08222102560103
time/logging (s)               0.030284064821898937
time/saving (s)                0.011429721489548683
time/training (s)              9.73233640845865
time/epoch (s)                 235.02032430004328
time/total (s)                 65441.25924280472
Epoch                          279
-----------------------------  ---------------------
2023-08-01 12:08:42.155421 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 280 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4503.27]
trainer/QF1 Loss               0.042537507
trainer/QF2 Loss               0.03780786
trainer/Policy Loss            -88.09232
trainer/Q1 Predictions Mean    100.59412
trainer/Q1 Predictions Std     3.1534598
trainer/Q1 Predictions Max     103.4353
trainer/Q1 Predictions Min     90.1578
trainer/Q2 Predictions Mean    100.49623
trainer/Q2 Predictions Std     3.1514976
trainer/Q2 Predictions Max     103.303
trainer/Q2 Predictions Min     90.09108
trainer/Q Targets Mean         100.56464
trainer/Q Targets Std          3.1642191
trainer/Q Targets Max          103.43438
trainer/Q Targets Min          90.23901
trainer/Log Pis Mean           12.571469
trainer/Log Pis Std            8.135554
trainer/Log Pis Max            52.536724
trainer/Log Pis Min            -2.754423
trainer/Policy mu Mean         0.0853388
trainer/Policy mu Std          1.57664
trainer/Policy mu Max          6.103393
trainer/Policy mu Min          -4.5072794
trainer/Policy log std Mean    -0.829576
trainer/Policy log std Std     0.3305369
trainer/Policy log std Max     0.2756498
trainer/Policy log std Min     -2.1851711
trainer/Alpha                  0.0016899470938369632
trainer/Alpha Loss             3.647704601287842
exploration/num steps total    1406000
exploration/num paths total    2812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9531011651065553
exploration/Rewards Std        0.05248510888176693
exploration/Rewards Max        0.9788988426272044
exploration/Rewards Min        0.48030154660223134
exploration/Returns Mean       476.55058255327765
exploration/Returns Std        1.1283409953678452
exploration/Returns Max        478.32568737579305
exploration/Returns Min        474.15977990426785
exploration/Actions Mean       0.07209229
exploration/Actions Std        0.5817666
exploration/Actions Max        0.99999833
exploration/Actions Min        -0.9998824
exploration/Num Paths          10
exploration/Average Returns    476.55058255327765
evaluation/num steps total     1405000
evaluation/num paths total     2810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9109185210126319
evaluation/Rewards Std         0.13834945234877696
evaluation/Rewards Max         0.9784509162308904
evaluation/Rewards Min         0.11884320686257346
evaluation/Returns Mean        455.4592605063159
evaluation/Returns Std         49.11311180956365
evaluation/Returns Max         476.19303758469437
evaluation/Returns Min         312.026665863122
evaluation/ExplReturns Mean    455.4592605063159
evaluation/ExplReturns Std     49.11311180956365
evaluation/ExplReturns Max     476.19303758469437
evaluation/ExplReturns Min     312.026665863122
evaluation/Actions Mean        0.04827933
evaluation/Actions Std         0.4834616
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     455.4592605063159
time/data storing (s)          0.03191478829830885
time/evaluation sampling (s)   110.9531365390867
time/exploration sampling (s)  111.47946352232248
time/logging (s)               0.03038202505558729
time/saving (s)                0.010363204404711723
time/training (s)              9.889435808174312
time/epoch (s)                 232.3946958873421
time/total (s)                 65673.6563720759
Epoch                          280
-----------------------------  ---------------------
2023-08-01 12:12:32.608329 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 281 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3705.5977]
trainer/QF1 Loss               0.027952641
trainer/QF2 Loss               0.03679429
trainer/Policy Loss            -88.87063
trainer/Q1 Predictions Mean    100.771835
trainer/Q1 Predictions Std     3.0072415
trainer/Q1 Predictions Max     103.67036
trainer/Q1 Predictions Min     91.93449
trainer/Q2 Predictions Mean    100.674805
trainer/Q2 Predictions Std     2.98458
trainer/Q2 Predictions Max     103.51845
trainer/Q2 Predictions Min     92.09403
trainer/Q Targets Mean         100.776245
trainer/Q Targets Std          2.9911273
trainer/Q Targets Max          103.68466
trainer/Q Targets Min          92.98237
trainer/Log Pis Mean           11.937595
trainer/Log Pis Std            8.548156
trainer/Log Pis Max            34.95214
trainer/Log Pis Min            -5.9441185
trainer/Policy mu Mean         0.12802868
trainer/Policy mu Std          1.5393076
trainer/Policy mu Max          5.1554847
trainer/Policy mu Min          -4.6723366
trainer/Policy log std Mean    -0.8351156
trainer/Policy log std Std     0.3350105
trainer/Policy log std Max     0.13924861
trainer/Policy log std Min     -2.2454283
trainer/Alpha                  0.001663538976572454
trainer/Alpha Loss             -0.3993232250213623
exploration/num steps total    1411000
exploration/num paths total    2822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9412722270489629
exploration/Rewards Std        0.06810651225338904
exploration/Rewards Max        0.979039696592757
exploration/Rewards Min        0.4925884853344184
exploration/Returns Mean       470.6361135244815
exploration/Returns Std        15.648887548825495
exploration/Returns Max        477.8594169839715
exploration/Returns Min        423.84149101102975
exploration/Actions Mean       0.049145047
exploration/Actions Std        0.5736888
exploration/Actions Max        0.9999071
exploration/Actions Min        -0.9999813
exploration/Num Paths          10
exploration/Average Returns    470.6361135244815
evaluation/num steps total     1410000
evaluation/num paths total     2820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9518542515553606
evaluation/Rewards Std         0.049691499339853555
evaluation/Rewards Max         0.9786689085514548
evaluation/Rewards Min         0.4909525395052473
evaluation/Returns Mean        475.92712577768026
evaluation/Returns Std         1.0644798400705608
evaluation/Returns Max         478.01124743681015
evaluation/Returns Min         474.568890220324
evaluation/ExplReturns Mean    475.92712577768026
evaluation/ExplReturns Std     1.0644798400705608
evaluation/ExplReturns Max     478.01124743681015
evaluation/ExplReturns Min     474.568890220324
evaluation/Actions Mean        0.06944476
evaluation/Actions Std         0.46653277
evaluation/Actions Max         0.9978778
evaluation/Actions Min         -0.9995562
evaluation/Num Paths           10
evaluation/Average Returns     475.92712577768026
time/data storing (s)          0.03168727271258831
time/evaluation sampling (s)   108.98135440889746
time/exploration sampling (s)  111.66781296674162
time/logging (s)               0.030555568635463715
time/saving (s)                0.01254109013825655
time/training (s)              9.723881548270583
time/epoch (s)                 230.44783285539597
time/total (s)                 65904.10687940195
Epoch                          281
-----------------------------  --------------------
2023-08-01 12:16:25.895238 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 282 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4190.0073]
trainer/QF1 Loss               0.04060333
trainer/QF2 Loss               0.024851657
trainer/Policy Loss            -90.20949
trainer/Q1 Predictions Mean    101.09467
trainer/Q1 Predictions Std     2.8822293
trainer/Q1 Predictions Max     104.194244
trainer/Q1 Predictions Min     91.57517
trainer/Q2 Predictions Mean    101.03579
trainer/Q2 Predictions Std     2.895352
trainer/Q2 Predictions Max     104.02435
trainer/Q2 Predictions Min     90.865265
trainer/Q Targets Mean         100.97823
trainer/Q Targets Std          2.875179
trainer/Q Targets Max          103.903145
trainer/Q Targets Min          90.753944
trainer/Log Pis Mean           10.967251
trainer/Log Pis Std            8.858768
trainer/Log Pis Max            54.538536
trainer/Log Pis Min            -6.731688
trainer/Policy mu Mean         0.031767804
trainer/Policy mu Std          1.5139339
trainer/Policy mu Max          5.4279137
trainer/Policy mu Min          -5.2897735
trainer/Policy log std Mean    -0.76761746
trainer/Policy log std Std     0.3311633
trainer/Policy log std Max     0.2674042
trainer/Policy log std Min     -2.338696
trainer/Alpha                  0.0015751542523503304
trainer/Alpha Loss             -6.664386749267578
exploration/num steps total    1416000
exploration/num paths total    2832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9520641456042258
exploration/Rewards Std        0.060454129962973856
exploration/Rewards Max        0.9791983056223978
exploration/Rewards Min        0.47932604516709426
exploration/Returns Mean       476.0320728021128
exploration/Returns Std        1.630611574380958
exploration/Returns Max        478.33466078167334
exploration/Returns Min        473.001390445352
exploration/Actions Mean       0.02203059
exploration/Actions Std        0.5912795
exploration/Actions Max        0.99997
exploration/Actions Min        -0.99989396
exploration/Num Paths          10
exploration/Average Returns    476.0320728021128
evaluation/num steps total     1415000
evaluation/num paths total     2830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9591181721711398
evaluation/Rewards Std         0.04932113792173288
evaluation/Rewards Max         0.978846066388719
evaluation/Rewards Min         0.49148648922848254
evaluation/Returns Mean        479.5590860855699
evaluation/Returns Std         1.2947927174589848
evaluation/Returns Max         480.41278633904346
evaluation/Returns Min         475.8828762112377
evaluation/ExplReturns Mean    479.5590860855699
evaluation/ExplReturns Std     1.2947927174589848
evaluation/ExplReturns Max     480.41278633904346
evaluation/ExplReturns Min     475.8828762112377
evaluation/Actions Mean        0.04280355
evaluation/Actions Std         0.5010546
evaluation/Actions Max         0.9988952
evaluation/Actions Min         -0.9988231
evaluation/Num Paths           10
evaluation/Average Returns     479.5590860855699
time/data storing (s)          0.0323144868016243
time/evaluation sampling (s)   110.81858507543802
time/exploration sampling (s)  112.74527080263942
time/logging (s)               0.030960913747549057
time/saving (s)                0.010798435658216476
time/training (s)              9.644250510260463
time/epoch (s)                 233.2821802245453
time/total (s)                 66137.39155743271
Epoch                          282
-----------------------------  ---------------------
2023-08-01 12:20:16.327953 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 283 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4246.154]
trainer/QF1 Loss               0.061952524
trainer/QF2 Loss               0.059091672
trainer/Policy Loss            -90.42657
trainer/Q1 Predictions Mean    101.248
trainer/Q1 Predictions Std     2.5706651
trainer/Q1 Predictions Max     103.886604
trainer/Q1 Predictions Min     91.13091
trainer/Q2 Predictions Mean    101.2451
trainer/Q2 Predictions Std     2.5548155
trainer/Q2 Predictions Max     103.874146
trainer/Q2 Predictions Min     91.32421
trainer/Q Targets Mean         101.1202
trainer/Q Targets Std          2.607144
trainer/Q Targets Max          103.688614
trainer/Q Targets Min          91.69514
trainer/Log Pis Mean           10.914643
trainer/Log Pis Std            8.28458
trainer/Log Pis Max            37.59661
trainer/Log Pis Min            -4.830817
trainer/Policy mu Mean         0.30063045
trainer/Policy mu Std          1.4571425
trainer/Policy mu Max          4.816638
trainer/Policy mu Min          -5.9219303
trainer/Policy log std Mean    -0.7922221
trainer/Policy log std Std     0.31409395
trainer/Policy log std Max     0.2779497
trainer/Policy log std Min     -2.2870378
trainer/Alpha                  0.0015322081744670868
trainer/Alpha Loss             -7.034049987792969
exploration/num steps total    1421000
exploration/num paths total    2842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9583463282011526
exploration/Rewards Std        0.05519856762947305
exploration/Rewards Max        0.9792548751268232
exploration/Rewards Min        0.4915475480016164
exploration/Returns Mean       479.1731641005763
exploration/Returns Std        0.40687699706625613
exploration/Returns Max        479.86642619803297
exploration/Returns Min        478.43814490796296
exploration/Actions Mean       0.021934519
exploration/Actions Std        0.55149937
exploration/Actions Max        0.99980366
exploration/Actions Min        -0.9999449
exploration/Num Paths          10
exploration/Average Returns    479.1731641005763
evaluation/num steps total     1420000
evaluation/num paths total     2840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9614553975181352
evaluation/Rewards Std         0.05136822391586377
evaluation/Rewards Max         0.9779717306415465
evaluation/Rewards Min         0.5015312943740201
evaluation/Returns Mean        480.7276987590677
evaluation/Returns Std         0.44341955980405284
evaluation/Returns Max         481.6774688890292
evaluation/Returns Min         480.24156575514627
evaluation/ExplReturns Mean    480.7276987590677
evaluation/ExplReturns Std     0.44341955980405284
evaluation/ExplReturns Max     481.6774688890292
evaluation/ExplReturns Min     480.24156575514627
evaluation/Actions Mean        0.012744425
evaluation/Actions Std         0.4173055
evaluation/Actions Max         0.998689
evaluation/Actions Min         -0.9996589
evaluation/Num Paths           10
evaluation/Average Returns     480.7276987590677
time/data storing (s)          0.03178604133427143
time/evaluation sampling (s)   110.15627274755388
time/exploration sampling (s)  110.57707756012678
time/logging (s)               0.031037072651088238
time/saving (s)                0.0128240454941988
time/training (s)              9.618646948598325
time/epoch (s)                 230.42764441575855
time/total (s)                 66367.821699352
Epoch                          283
-----------------------------  ---------------------
2023-08-01 12:24:06.218302 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 284 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4020.4878]
trainer/QF1 Loss               0.04923412
trainer/QF2 Loss               0.053097483
trainer/Policy Loss            -87.43614
trainer/Q1 Predictions Mean    100.54895
trainer/Q1 Predictions Std     2.906616
trainer/Q1 Predictions Max     103.959335
trainer/Q1 Predictions Min     91.63644
trainer/Q2 Predictions Mean    100.52779
trainer/Q2 Predictions Std     2.8933158
trainer/Q2 Predictions Max     103.93039
trainer/Q2 Predictions Min     91.7467
trainer/Q Targets Mean         100.65763
trainer/Q Targets Std          2.9127495
trainer/Q Targets Max          103.88402
trainer/Q Targets Min          91.95269
trainer/Log Pis Mean           13.254541
trainer/Log Pis Std            9.709629
trainer/Log Pis Max            74.72183
trainer/Log Pis Min            -8.582388
trainer/Policy mu Mean         0.22535004
trainer/Policy mu Std          1.6039337
trainer/Policy mu Max          11.027817
trainer/Policy mu Min          -6.704717
trainer/Policy log std Mean    -0.80304146
trainer/Policy log std Std     0.33010176
trainer/Policy log std Max     0.8656096
trainer/Policy log std Min     -2.4509647
trainer/Alpha                  0.0015042673330754042
trainer/Alpha Loss             8.154056549072266
exploration/num steps total    1426000
exploration/num paths total    2852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9594268162856552
exploration/Rewards Std        0.053547817971138216
exploration/Rewards Max        0.979348616764869
exploration/Rewards Min        0.4879949224637103
exploration/Returns Mean       479.71340814282746
exploration/Returns Std        1.1307697101020548
exploration/Returns Max        480.5681798194868
exploration/Returns Min        476.82171424390737
exploration/Actions Mean       0.023472559
exploration/Actions Std        0.6085453
exploration/Actions Max        0.9999358
exploration/Actions Min        -0.9998746
exploration/Num Paths          10
exploration/Average Returns    479.71340814282746
evaluation/num steps total     1425000
evaluation/num paths total     2850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9623590715492466
evaluation/Rewards Std         0.051962883095873616
evaluation/Rewards Max         0.9793630035267304
evaluation/Rewards Min         0.48326979341271
evaluation/Returns Mean        481.1795357746234
evaluation/Returns Std         0.34153137705522124
evaluation/Returns Max         481.83389627435395
evaluation/Returns Min         480.5209330469239
evaluation/ExplReturns Mean    481.1795357746234
evaluation/ExplReturns Std     0.34153137705522124
evaluation/ExplReturns Max     481.83389627435395
evaluation/ExplReturns Min     480.5209330469239
evaluation/Actions Mean        0.024804574
evaluation/Actions Std         0.50350994
evaluation/Actions Max         0.99931896
evaluation/Actions Min         -0.99909663
evaluation/Num Paths           10
evaluation/Average Returns     481.1795357746234
time/data storing (s)          0.03233822342008352
time/evaluation sampling (s)   109.54951845295727
time/exploration sampling (s)  110.59376016724855
time/logging (s)               0.031065892428159714
time/saving (s)                0.012250708416104317
time/training (s)              9.666190105490386
time/epoch (s)                 229.88512354996055
time/total (s)                 66597.70942712203
Epoch                          284
-----------------------------  ---------------------
2023-08-01 12:27:59.698991 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 285 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4049.5618]
trainer/QF1 Loss               0.037400804
trainer/QF2 Loss               0.040734608
trainer/Policy Loss            -88.5812
trainer/Q1 Predictions Mean    100.803185
trainer/Q1 Predictions Std     2.6789773
trainer/Q1 Predictions Max     103.93568
trainer/Q1 Predictions Min     92.474655
trainer/Q2 Predictions Mean    100.866394
trainer/Q2 Predictions Std     2.7065217
trainer/Q2 Predictions Max     103.89965
trainer/Q2 Predictions Min     92.40382
trainer/Q Targets Mean         100.7944
trainer/Q Targets Std          2.6879137
trainer/Q Targets Max          103.691414
trainer/Q Targets Min          92.481064
trainer/Log Pis Mean           12.359901
trainer/Log Pis Std            8.451815
trainer/Log Pis Max            53.28892
trainer/Log Pis Min            -6.913345
trainer/Policy mu Mean         0.1390026
trainer/Policy mu Std          1.5547233
trainer/Policy mu Max          6.177403
trainer/Policy mu Min          -6.555676
trainer/Policy log std Mean    -0.8113141
trainer/Policy log std Std     0.32930103
trainer/Policy log std Max     0.5745605
trainer/Policy log std Min     -2.3792424
trainer/Alpha                  0.0015686274273321033
trainer/Alpha Loss             2.324106454849243
exploration/num steps total    1431000
exploration/num paths total    2862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9466769086866068
exploration/Rewards Std        0.0605064590943269
exploration/Rewards Max        0.9775776435913172
exploration/Rewards Min        0.49465571764555777
exploration/Returns Mean       473.3384543433034
exploration/Returns Std        3.8263791007866135
exploration/Returns Max        477.55542595649996
exploration/Returns Min        465.4787153931589
exploration/Actions Mean       0.022919592
exploration/Actions Std        0.54447705
exploration/Actions Max        0.9999785
exploration/Actions Min        -0.99999833
exploration/Num Paths          10
exploration/Average Returns    473.3384543433034
evaluation/num steps total     1430000
evaluation/num paths total     2860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9409454215385463
evaluation/Rewards Std         0.06752184744908864
evaluation/Rewards Max         0.9786815769908037
evaluation/Rewards Min         0.4922521144454268
evaluation/Returns Mean        470.4727107692732
evaluation/Returns Std         5.498866347793256
evaluation/Returns Max         476.2648169174002
evaluation/Returns Min         462.765214700415
evaluation/ExplReturns Mean    470.4727107692732
evaluation/ExplReturns Std     5.498866347793256
evaluation/ExplReturns Max     476.2648169174002
evaluation/ExplReturns Min     462.765214700415
evaluation/Actions Mean        0.048415117
evaluation/Actions Std         0.54431725
evaluation/Actions Max         0.9998061
evaluation/Actions Min         -0.99993587
evaluation/Num Paths           10
evaluation/Average Returns     470.4727107692732
time/data storing (s)          0.03224575147032738
time/evaluation sampling (s)   111.43088775873184
time/exploration sampling (s)  112.24546359293163
time/logging (s)               0.030396107584238052
time/saving (s)                0.010667470283806324
time/training (s)              9.72523769363761
time/epoch (s)                 233.47489837463945
time/total (s)                 66831.1868186947
Epoch                          285
-----------------------------  ---------------------
2023-08-01 12:31:53.874948 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 286 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4232.155]
trainer/QF1 Loss               0.04365165
trainer/QF2 Loss               0.035544008
trainer/Policy Loss            -88.100204
trainer/Q1 Predictions Mean    100.82904
trainer/Q1 Predictions Std     2.8068626
trainer/Q1 Predictions Max     103.83202
trainer/Q1 Predictions Min     90.209274
trainer/Q2 Predictions Mean    100.79117
trainer/Q2 Predictions Std     2.823589
trainer/Q2 Predictions Max     103.85014
trainer/Q2 Predictions Min     89.78714
trainer/Q Targets Mean         100.731155
trainer/Q Targets Std          2.8254216
trainer/Q Targets Max          103.83588
trainer/Q Targets Min          90.50261
trainer/Log Pis Mean           12.808963
trainer/Log Pis Std            9.892474
trainer/Log Pis Max            72.82427
trainer/Log Pis Min            -3.824111
trainer/Policy mu Mean         0.18520178
trainer/Policy mu Std          1.6244552
trainer/Policy mu Max          12.877596
trainer/Policy mu Min          -9.651802
trainer/Policy log std Mean    -0.77608687
trainer/Policy log std Std     0.3188396
trainer/Policy log std Max     1.0151331
trainer/Policy log std Min     -2.5028236
trainer/Alpha                  0.0015623061917722225
trainer/Alpha Loss             5.22720193862915
exploration/num steps total    1436000
exploration/num paths total    2872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9209156760000565
exploration/Rewards Std        0.08959647641608649
exploration/Rewards Max        0.9792446834796635
exploration/Rewards Min        0.5002303654764675
exploration/Returns Mean       460.45783800002835
exploration/Returns Std        12.936858833537617
exploration/Returns Max        476.55563103308714
exploration/Returns Min        436.22246082736757
exploration/Actions Mean       0.020267397
exploration/Actions Std        0.55425495
exploration/Actions Max        0.999903
exploration/Actions Min        -0.9999429
exploration/Num Paths          10
exploration/Average Returns    460.45783800002835
evaluation/num steps total     1435000
evaluation/num paths total     2870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9096504147743671
evaluation/Rewards Std         0.0965761830595969
evaluation/Rewards Max         0.9781205154046401
evaluation/Rewards Min         0.4988784550123937
evaluation/Returns Mean        454.82520738718347
evaluation/Returns Std         29.69397572034095
evaluation/Returns Max         474.0916658757107
evaluation/Returns Min         388.55224184075803
evaluation/ExplReturns Mean    454.82520738718347
evaluation/ExplReturns Std     29.69397572034095
evaluation/ExplReturns Max     474.0916658757107
evaluation/ExplReturns Min     388.55224184075803
evaluation/Actions Mean        0.010421773
evaluation/Actions Std         0.45000714
evaluation/Actions Max         0.99987596
evaluation/Actions Min         -0.9999118
evaluation/Num Paths           10
evaluation/Average Returns     454.82520738718347
time/data storing (s)          0.031653137877583504
time/evaluation sampling (s)   111.95793032087386
time/exploration sampling (s)  112.44820272643119
time/logging (s)               0.030428491532802582
time/saving (s)                0.012686040252447128
time/training (s)              9.690045312978327
time/epoch (s)                 234.1709460299462
time/total (s)                 67065.3602160979
Epoch                          286
-----------------------------  ---------------------
2023-08-01 12:35:46.174188 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 287 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4182.36]
trainer/QF1 Loss               0.0576436
trainer/QF2 Loss               0.047879107
trainer/Policy Loss            -88.83566
trainer/Q1 Predictions Mean    100.86189
trainer/Q1 Predictions Std     2.7476413
trainer/Q1 Predictions Max     103.87793
trainer/Q1 Predictions Min     91.52307
trainer/Q2 Predictions Mean    100.834496
trainer/Q2 Predictions Std     2.7542276
trainer/Q2 Predictions Max     103.82954
trainer/Q2 Predictions Min     91.459175
trainer/Q Targets Mean         100.687294
trainer/Q Targets Std          2.76769
trainer/Q Targets Max          103.59159
trainer/Q Targets Min          91.62818
trainer/Log Pis Mean           12.123162
trainer/Log Pis Std            9.130399
trainer/Log Pis Max            40.641262
trainer/Log Pis Min            -4.9881682
trainer/Policy mu Mean         0.13871016
trainer/Policy mu Std          1.5471941
trainer/Policy mu Max          4.7917423
trainer/Policy mu Min          -5.4690676
trainer/Policy log std Mean    -0.8385439
trainer/Policy log std Std     0.32384917
trainer/Policy log std Max     0.22944623
trainer/Policy log std Min     -2.4984918
trainer/Alpha                  0.001510454574599862
trainer/Alpha Loss             0.7999811172485352
exploration/num steps total    1441000
exploration/num paths total    2882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9490698343908672
exploration/Rewards Std        0.05907715119453714
exploration/Rewards Max        0.9790840529465931
exploration/Rewards Min        0.5010144070702539
exploration/Returns Mean       474.53491719543365
exploration/Returns Std        1.994781559088468
exploration/Returns Max        476.54801361689323
exploration/Returns Min        470.507476630916
exploration/Actions Mean       0.011375473
exploration/Actions Std        0.5708481
exploration/Actions Max        0.9999875
exploration/Actions Min        -0.9999384
exploration/Num Paths          10
exploration/Average Returns    474.53491719543365
evaluation/num steps total     1440000
evaluation/num paths total     2880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9483122991789431
evaluation/Rewards Std         0.05984461356699406
evaluation/Rewards Max         0.9759149545569304
evaluation/Rewards Min         0.501545102423297
evaluation/Returns Mean        474.1561495894715
evaluation/Returns Std         0.972539064075636
evaluation/Returns Max         476.0850286913544
evaluation/Returns Min         472.82573337421564
evaluation/ExplReturns Mean    474.1561495894715
evaluation/ExplReturns Std     0.972539064075636
evaluation/ExplReturns Max     476.0850286913544
evaluation/ExplReturns Min     472.82573337421564
evaluation/Actions Mean        0.0065175323
evaluation/Actions Std         0.44713637
evaluation/Actions Max         0.9996378
evaluation/Actions Min         -0.999502
evaluation/Num Paths           10
evaluation/Average Returns     474.1561495894715
time/data storing (s)          0.03188034147024155
time/evaluation sampling (s)   110.89654211048037
time/exploration sampling (s)  111.81301799509674
time/logging (s)               0.030457730405032635
time/saving (s)                0.01084957830607891
time/training (s)              9.511420941911638
time/epoch (s)                 232.2941686976701
time/total (s)                 67297.6568777617
Epoch                          287
-----------------------------  --------------------
2023-08-01 12:39:45.017530 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 288 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4122.9478]
trainer/QF1 Loss               0.080312796
trainer/QF2 Loss               0.048656054
trainer/Policy Loss            -86.94207
trainer/Q1 Predictions Mean    100.438614
trainer/Q1 Predictions Std     3.2132215
trainer/Q1 Predictions Max     103.67835
trainer/Q1 Predictions Min     84.16995
trainer/Q2 Predictions Mean    100.48631
trainer/Q2 Predictions Std     3.2412968
trainer/Q2 Predictions Max     103.65663
trainer/Q2 Predictions Min     81.52961
trainer/Q Targets Mean         100.51544
trainer/Q Targets Std          3.3026512
trainer/Q Targets Max          103.71651
trainer/Q Targets Min          82.54126
trainer/Log Pis Mean           13.609119
trainer/Log Pis Std            10.602064
trainer/Log Pis Max            63.17377
trainer/Log Pis Min            -6.728118
trainer/Policy mu Mean         0.23521145
trainer/Policy mu Std          1.6815456
trainer/Policy mu Max          12.562683
trainer/Policy mu Min          -5.938848
trainer/Policy log std Mean    -0.8126367
trainer/Policy log std Std     0.35797465
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.671778
trainer/Alpha                  0.0015695641050115228
trainer/Alpha Loss             10.39008903503418
exploration/num steps total    1446000
exploration/num paths total    2892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.4907235966867213
exploration/Rewards Std        0.09466079365758262
exploration/Rewards Max        0.928384658169227
exploration/Rewards Min        0.18424694144600223
exploration/Returns Mean       245.36179834336062
exploration/Returns Std        10.588291075374412
exploration/Returns Max        262.3300199438645
exploration/Returns Min        231.66172252664146
exploration/Actions Mean       0.12658907
exploration/Actions Std        0.84473664
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    245.36179834336062
evaluation/num steps total     1445000
evaluation/num paths total     2890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.5173108002622105
evaluation/Rewards Std         0.1562685868594514
evaluation/Rewards Max         0.9755381891532837
evaluation/Rewards Min         0.1980734467613118
evaluation/Returns Mean        258.65540013110524
evaluation/Returns Std         58.58545688390131
evaluation/Returns Max         429.33031700586497
evaluation/Returns Min         214.26557766017663
evaluation/ExplReturns Mean    258.65540013110524
evaluation/ExplReturns Std     58.58545688390131
evaluation/ExplReturns Max     429.33031700586497
evaluation/ExplReturns Min     214.26557766017663
evaluation/Actions Mean        0.15924643
evaluation/Actions Std         0.792677
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     258.65540013110524
time/data storing (s)          0.03192767966538668
time/evaluation sampling (s)   114.15120000764728
time/exploration sampling (s)  114.98661466129124
time/logging (s)               0.030565342865884304
time/saving (s)                0.011065024882555008
time/training (s)              9.626961884088814
time/epoch (s)                 238.83833460044116
time/total (s)                 67536.49771749973
Epoch                          288
-----------------------------  ---------------------
2023-08-01 12:43:42.098277 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 289 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4189.764]
trainer/QF1 Loss               0.029462613
trainer/QF2 Loss               0.03654351
trainer/Policy Loss            -88.98706
trainer/Q1 Predictions Mean    100.84909
trainer/Q1 Predictions Std     3.068355
trainer/Q1 Predictions Max     103.62348
trainer/Q1 Predictions Min     82.7053
trainer/Q2 Predictions Mean    100.79858
trainer/Q2 Predictions Std     3.0621352
trainer/Q2 Predictions Max     103.55466
trainer/Q2 Predictions Min     82.52828
trainer/Q Targets Mean         100.87029
trainer/Q Targets Std          3.060676
trainer/Q Targets Max          103.6131
trainer/Q Targets Min          83.90562
trainer/Log Pis Mean           11.94751
trainer/Log Pis Std            8.1517105
trainer/Log Pis Max            42.69703
trainer/Log Pis Min            -8.857998
trainer/Policy mu Mean         0.22729047
trainer/Policy mu Std          1.547971
trainer/Policy mu Max          7.8988404
trainer/Policy mu Min          -4.5165997
trainer/Policy log std Mean    -0.80493593
trainer/Policy log std Std     0.3494319
trainer/Policy log std Max     1.3978348
trainer/Policy log std Min     -2.5049753
trainer/Alpha                  0.0015998929738998413
trainer/Alpha Loss             -0.33793509006500244
exploration/num steps total    1451000
exploration/num paths total    2902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.6305480583665829
exploration/Rewards Std        0.18112643942603832
exploration/Rewards Max        0.978044683125776
exploration/Rewards Min        0.047046215894968525
exploration/Returns Mean       315.27402918329153
exploration/Returns Std        40.37232234623857
exploration/Returns Max        376.6290747259852
exploration/Returns Min        246.7670493918333
exploration/Actions Mean       0.10142435
exploration/Actions Std        0.7780374
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    315.27402918329153
evaluation/num steps total     1450000
evaluation/num paths total     2900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6119458315803178
evaluation/Rewards Std         0.20832527239633908
evaluation/Rewards Max         0.9780049030859449
evaluation/Rewards Min         0.060029232075097944
evaluation/Returns Mean        305.97291579015894
evaluation/Returns Std         65.12235924222472
evaluation/Returns Max         420.93980403967436
evaluation/Returns Min         217.3965133175199
evaluation/ExplReturns Mean    305.97291579015894
evaluation/ExplReturns Std     65.12235924222472
evaluation/ExplReturns Max     420.93980403967436
evaluation/ExplReturns Min     217.3965133175199
evaluation/Actions Mean        0.09758965
evaluation/Actions Std         0.7676468
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     305.97291579015894
time/data storing (s)          0.0318275885656476
time/evaluation sampling (s)   113.4367837337777
time/exploration sampling (s)  113.87309757899493
time/logging (s)               0.03062308207154274
time/saving (s)                0.012775846756994724
time/training (s)              9.69057628326118
time/epoch (s)                 237.075684113428
time/total (s)                 67773.5758557627
Epoch                          289
-----------------------------  ---------------------
2023-08-01 12:47:38.898570 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 290 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3944.3093]
trainer/QF1 Loss               0.03018199
trainer/QF2 Loss               0.044177674
trainer/Policy Loss            -88.088005
trainer/Q1 Predictions Mean    100.77516
trainer/Q1 Predictions Std     3.0012593
trainer/Q1 Predictions Max     103.39457
trainer/Q1 Predictions Min     82.7204
trainer/Q2 Predictions Mean    100.83269
trainer/Q2 Predictions Std     2.9572725
trainer/Q2 Predictions Max     103.35962
trainer/Q2 Predictions Min     83.50098
trainer/Q Targets Mean         100.7274
trainer/Q Targets Std          2.9837039
trainer/Q Targets Max          103.404915
trainer/Q Targets Min          83.11056
trainer/Log Pis Mean           12.827524
trainer/Log Pis Std            8.303386
trainer/Log Pis Max            44.179726
trainer/Log Pis Min            -3.7886412
trainer/Policy mu Mean         0.1645066
trainer/Policy mu Std          1.6047312
trainer/Policy mu Max          5.894036
trainer/Policy mu Min          -5.667574
trainer/Policy log std Mean    -0.76910704
trainer/Policy log std Std     0.32753012
trainer/Policy log std Max     0.10575226
trainer/Policy log std Min     -2.310828
trainer/Alpha                  0.0018311507301405072
trainer/Alpha Loss             5.215841293334961
exploration/num steps total    1456000
exploration/num paths total    2912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7085967148378571
exploration/Rewards Std        0.2105794517875701
exploration/Rewards Max        0.979514742409543
exploration/Rewards Min        0.05489721351441179
exploration/Returns Mean       354.29835741892856
exploration/Returns Std        50.87031960584832
exploration/Returns Max        403.4460476678006
exploration/Returns Min        248.41918519787305
exploration/Actions Mean       0.07562982
exploration/Actions Std        0.73325616
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    354.29835741892856
evaluation/num steps total     1455000
evaluation/num paths total     2910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.6876883148469184
evaluation/Rewards Std         0.25087995525687495
evaluation/Rewards Max         0.9798995850594404
evaluation/Rewards Min         0.08417497416096152
evaluation/Returns Mean        343.8441574234592
evaluation/Returns Std         72.46877253223195
evaluation/Returns Max         434.5025673175456
evaluation/Returns Min         236.24127062265657
evaluation/ExplReturns Mean    343.8441574234592
evaluation/ExplReturns Std     72.46877253223195
evaluation/ExplReturns Max     434.5025673175456
evaluation/ExplReturns Min     236.24127062265657
evaluation/Actions Mean        0.05006648
evaluation/Actions Std         0.69434047
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     343.8441574234592
time/data storing (s)          0.03171235788613558
time/evaluation sampling (s)   111.86433675512671
time/exploration sampling (s)  114.59392153285444
time/logging (s)               0.031411098316311836
time/saving (s)                0.012835273519158363
time/training (s)              10.26170149911195
time/epoch (s)                 236.7959185168147
time/total (s)                 68010.37426344398
Epoch                          290
-----------------------------  ---------------------
2023-08-01 12:51:34.528614 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 291 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4006.542]
trainer/QF1 Loss               0.027794324
trainer/QF2 Loss               0.020680562
trainer/Policy Loss            -89.22345
trainer/Q1 Predictions Mean    100.77639
trainer/Q1 Predictions Std     2.9631548
trainer/Q1 Predictions Max     103.37268
trainer/Q1 Predictions Min     87.9754
trainer/Q2 Predictions Mean    100.83813
trainer/Q2 Predictions Std     2.9717133
trainer/Q2 Predictions Max     103.45378
trainer/Q2 Predictions Min     87.32811
trainer/Q Targets Mean         100.82728
trainer/Q Targets Std          2.9552262
trainer/Q Targets Max          103.48789
trainer/Q Targets Min          87.54414
trainer/Log Pis Mean           11.689022
trainer/Log Pis Std            5.860143
trainer/Log Pis Max            39.593872
trainer/Log Pis Min            0.15486884
trainer/Policy mu Mean         0.11495856
trainer/Policy mu Std          1.5534718
trainer/Policy mu Max          5.9829617
trainer/Policy mu Min          -5.53901
trainer/Policy log std Mean    -0.7591136
trainer/Policy log std Std     0.3053237
trainer/Policy log std Max     0.4618668
trainer/Policy log std Min     -2.269793
trainer/Alpha                  0.001956513151526451
trainer/Alpha Loss             -1.9394607543945312
exploration/num steps total    1461000
exploration/num paths total    2922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8458441823977353
exploration/Rewards Std        0.11289220824270002
exploration/Rewards Max        0.9796703042442856
exploration/Rewards Min        0.5001966694468328
exploration/Returns Mean       422.9220911988676
exploration/Returns Std        17.265531474202426
exploration/Returns Max        454.40248443545477
exploration/Returns Min        392.9169170667869
exploration/Actions Mean       0.12518334
exploration/Actions Std        0.619061
exploration/Actions Max        0.99999946
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    422.9220911988676
evaluation/num steps total     1460000
evaluation/num paths total     2920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8035811420706217
evaluation/Rewards Std         0.1216901254062022
evaluation/Rewards Max         0.9795562346281401
evaluation/Rewards Min         0.4206190235905049
evaluation/Returns Mean        401.7905710353107
evaluation/Returns Std         25.0578596420406
evaluation/Returns Max         441.50563263158415
evaluation/Returns Min         349.8396147799939
evaluation/ExplReturns Mean    401.7905710353107
evaluation/ExplReturns Std     25.0578596420406
evaluation/ExplReturns Max     441.50563263158415
evaluation/ExplReturns Min     349.8396147799939
evaluation/Actions Mean        0.10962612
evaluation/Actions Std         0.59403515
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -0.9999995
evaluation/Num Paths           10
evaluation/Average Returns     401.7905710353107
time/data storing (s)          0.03210245259106159
time/evaluation sampling (s)   112.60211402270943
time/exploration sampling (s)  112.60617895144969
time/logging (s)               0.03043519239872694
time/saving (s)                0.01246361993253231
time/training (s)              10.340591228567064
time/epoch (s)                 235.6238854676485
time/total (s)                 68246.00069368817
Epoch                          291
-----------------------------  --------------------
2023-08-01 12:55:31.141075 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 292 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3829.48]
trainer/QF1 Loss               0.030762143
trainer/QF2 Loss               0.027484354
trainer/Policy Loss            -88.878654
trainer/Q1 Predictions Mean    101.29831
trainer/Q1 Predictions Std     2.8144236
trainer/Q1 Predictions Max     103.45489
trainer/Q1 Predictions Min     85.962906
trainer/Q2 Predictions Mean    101.23175
trainer/Q2 Predictions Std     2.7992787
trainer/Q2 Predictions Max     103.36109
trainer/Q2 Predictions Min     86.82273
trainer/Q Targets Mean         101.27465
trainer/Q Targets Std          2.825761
trainer/Q Targets Max          103.405815
trainer/Q Targets Min          85.94787
trainer/Log Pis Mean           12.536719
trainer/Log Pis Std            6.524662
trainer/Log Pis Max            38.706936
trainer/Log Pis Min            -3.2531629
trainer/Policy mu Mean         0.34727728
trainer/Policy mu Std          1.5466603
trainer/Policy mu Max          5.428593
trainer/Policy mu Min          -5.2303724
trainer/Policy log std Mean    -0.7686394
trainer/Policy log std Std     0.29780537
trainer/Policy log std Max     0.3948143
trainer/Policy log std Min     -2.228667
trainer/Alpha                  0.0018872220534831285
trainer/Alpha Loss             3.3667707443237305
exploration/num steps total    1466000
exploration/num paths total    2932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8181444827490468
exploration/Rewards Std        0.12864952416200454
exploration/Rewards Max        0.9787067424896616
exploration/Rewards Min        0.3857612988540291
exploration/Returns Mean       409.0722413745233
exploration/Returns Std        19.60487906367241
exploration/Returns Max        435.57527152229926
exploration/Returns Min        382.94258410815735
exploration/Actions Mean       0.19578019
exploration/Actions Std        0.6872382
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999942
exploration/Num Paths          10
exploration/Average Returns    409.0722413745233
evaluation/num steps total     1465000
evaluation/num paths total     2930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7500128001627173
evaluation/Rewards Std         0.16373301537822627
evaluation/Rewards Max         0.9777929761666583
evaluation/Rewards Min         0.17422264193438808
evaluation/Returns Mean        375.0064000813585
evaluation/Returns Std         38.37885752259729
evaluation/Returns Max         417.0969876053112
evaluation/Returns Min         309.6194625413866
evaluation/ExplReturns Mean    375.0064000813585
evaluation/ExplReturns Std     38.37885752259729
evaluation/ExplReturns Max     417.0969876053112
evaluation/ExplReturns Min     309.6194625413866
evaluation/Actions Mean        0.1499162
evaluation/Actions Std         0.696936
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     375.0064000813585
time/data storing (s)          0.03204724192619324
time/evaluation sampling (s)   112.89731589425355
time/exploration sampling (s)  114.04661592002958
time/logging (s)               0.030486630275845528
time/saving (s)                0.012379874475300312
time/training (s)              9.588614265434444
time/epoch (s)                 236.60745982639492
time/total (s)                 68482.61058221385
Epoch                          292
-----------------------------  ---------------------
2023-08-01 12:59:32.352888 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 293 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3780.6748]
trainer/QF1 Loss               0.03088723
trainer/QF2 Loss               0.035169758
trainer/Policy Loss            -89.475395
trainer/Q1 Predictions Mean    101.1732
trainer/Q1 Predictions Std     3.0199313
trainer/Q1 Predictions Max     103.47857
trainer/Q1 Predictions Min     78.858154
trainer/Q2 Predictions Mean    101.1238
trainer/Q2 Predictions Std     3.029932
trainer/Q2 Predictions Max     103.4018
trainer/Q2 Predictions Min     78.59672
trainer/Q Targets Mean         101.217575
trainer/Q Targets Std          3.0265236
trainer/Q Targets Max          103.45916
trainer/Q Targets Min          79.5219
trainer/Log Pis Mean           11.8179245
trainer/Log Pis Std            7.90147
trainer/Log Pis Max            43.35759
trainer/Log Pis Min            -4.3854527
trainer/Policy mu Mean         0.14938574
trainer/Policy mu Std          1.5556233
trainer/Policy mu Max          7.638389
trainer/Policy mu Min          -5.134249
trainer/Policy log std Mean    -0.75419396
trainer/Policy log std Std     0.29890636
trainer/Policy log std Max     0.13819218
trainer/Policy log std Min     -2.3336484
trainer/Alpha                  0.0018712325254455209
trainer/Alpha Loss             -1.1436395645141602
exploration/num steps total    1471000
exploration/num paths total    2942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8793453284574209
exploration/Rewards Std        0.11644992594980609
exploration/Rewards Max        0.9793381941984519
exploration/Rewards Min        0.5002586075035981
exploration/Returns Mean       439.6726642287105
exploration/Returns Std        19.568892991303017
exploration/Returns Max        464.4924111556782
exploration/Returns Min        401.7764516660151
exploration/Actions Mean       0.015153247
exploration/Actions Std        0.6840792
exploration/Actions Max        0.9999989
exploration/Actions Min        -0.99999845
exploration/Num Paths          10
exploration/Average Returns    439.6726642287105
evaluation/num steps total     1470000
evaluation/num paths total     2940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8173577835639703
evaluation/Rewards Std         0.12561647140828436
evaluation/Rewards Max         0.9795317674599539
evaluation/Rewards Min         0.5036552519345039
evaluation/Returns Mean        408.67889178198504
evaluation/Returns Std         30.559497238261812
evaluation/Returns Max         452.67585401280496
evaluation/Returns Min         365.84183472941663
evaluation/ExplReturns Mean    408.67889178198504
evaluation/ExplReturns Std     30.559497238261812
evaluation/ExplReturns Max     452.67585401280496
evaluation/ExplReturns Min     365.84183472941663
evaluation/Actions Mean        -0.019571042
evaluation/Actions Std         0.6745964
evaluation/Actions Max         0.9999992
evaluation/Actions Min         -0.99999183
evaluation/Num Paths           10
evaluation/Average Returns     408.67889178198504
time/data storing (s)          0.03182411380112171
time/evaluation sampling (s)   116.66853893455118
time/exploration sampling (s)  114.83653540164232
time/logging (s)               0.03062264248728752
time/saving (s)                0.011214515194296837
time/training (s)              9.628056003712118
time/epoch (s)                 241.20679161138833
time/total (s)                 68723.81987627223
Epoch                          293
-----------------------------  ---------------------
2023-08-01 13:03:26.822476 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 294 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4029.7695]
trainer/QF1 Loss               0.028348235
trainer/QF2 Loss               0.029337851
trainer/Policy Loss            -90.61496
trainer/Q1 Predictions Mean    101.56845
trainer/Q1 Predictions Std     2.3823607
trainer/Q1 Predictions Max     103.64632
trainer/Q1 Predictions Min     91.67029
trainer/Q2 Predictions Mean    101.5649
trainer/Q2 Predictions Std     2.378641
trainer/Q2 Predictions Max     103.54213
trainer/Q2 Predictions Min     91.68099
trainer/Q Targets Mean         101.651764
trainer/Q Targets Std          2.3736827
trainer/Q Targets Max          103.536476
trainer/Q Targets Min          91.72465
trainer/Log Pis Mean           11.0567
trainer/Log Pis Std            7.575329
trainer/Log Pis Max            42.318356
trainer/Log Pis Min            -4.300692
trainer/Policy mu Mean         0.281043
trainer/Policy mu Std          1.4951261
trainer/Policy mu Max          5.697049
trainer/Policy mu Min          -4.687941
trainer/Policy log std Mean    -0.75290745
trainer/Policy log std Std     0.2808676
trainer/Policy log std Max     0.16296452
trainer/Policy log std Min     -2.2585568
trainer/Alpha                  0.0018800788093358278
trainer/Alpha Loss             -5.920559406280518
exploration/num steps total    1476000
exploration/num paths total    2952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9399369943426904
exploration/Rewards Std        0.08078110997714952
exploration/Rewards Max        0.9796113369289663
exploration/Rewards Min        0.5034513003154233
exploration/Returns Mean       469.9684971713451
exploration/Returns Std        11.900091868424472
exploration/Returns Max        476.69368289268897
exploration/Returns Min        434.6676128384254
exploration/Actions Mean       0.10095799
exploration/Actions Std        0.63288665
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.99997044
exploration/Num Paths          10
exploration/Average Returns    469.9684971713451
evaluation/num steps total     1475000
evaluation/num paths total     2950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9374339033493677
evaluation/Rewards Std         0.08448597970940326
evaluation/Rewards Max         0.9783423234110189
evaluation/Rewards Min         0.4979735328974922
evaluation/Returns Mean        468.7169516746837
evaluation/Returns Std         25.49425737708264
evaluation/Returns Max         479.7816506981528
evaluation/Returns Min         392.5213961189049
evaluation/ExplReturns Mean    468.7169516746837
evaluation/ExplReturns Std     25.49425737708264
evaluation/ExplReturns Max     479.7816506981528
evaluation/ExplReturns Min     392.5213961189049
evaluation/Actions Mean        0.1473714
evaluation/Actions Std         0.5522098
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.9999978
evaluation/Num Paths           10
evaluation/Average Returns     468.7169516746837
time/data storing (s)          0.032328405417501926
time/evaluation sampling (s)   112.02337507903576
time/exploration sampling (s)  112.76987553574145
time/logging (s)               0.030379321426153183
time/saving (s)                0.012839213013648987
time/training (s)              9.595418655313551
time/epoch (s)                 234.46421620994806
time/total (s)                 68958.28656298015
Epoch                          294
-----------------------------  ---------------------
2023-08-01 13:07:19.843005 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 295 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3705.896]
trainer/QF1 Loss               0.03344983
trainer/QF2 Loss               0.027897403
trainer/Policy Loss            -89.656876
trainer/Q1 Predictions Mean    101.393005
trainer/Q1 Predictions Std     3.3174672
trainer/Q1 Predictions Max     103.89363
trainer/Q1 Predictions Min     76.65144
trainer/Q2 Predictions Mean    101.398605
trainer/Q2 Predictions Std     3.3164804
trainer/Q2 Predictions Max     103.85704
trainer/Q2 Predictions Min     75.94461
trainer/Q Targets Mean         101.36427
trainer/Q Targets Std          3.3666
trainer/Q Targets Max          103.83551
trainer/Q Targets Min          75.38174
trainer/Log Pis Mean           11.869179
trainer/Log Pis Std            7.6277304
trainer/Log Pis Max            37.282204
trainer/Log Pis Min            -15.482895
trainer/Policy mu Mean         0.25931358
trainer/Policy mu Std          1.5251706
trainer/Policy mu Max          5.2641406
trainer/Policy mu Min          -6.361494
trainer/Policy log std Mean    -0.77074975
trainer/Policy log std Std     0.29664597
trainer/Policy log std Max     0.6376969
trainer/Policy log std Min     -2.3735023
trainer/Alpha                  0.0017062538536265492
trainer/Alpha Loss             -0.8337969779968262
exploration/num steps total    1481000
exploration/num paths total    2962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9220612060367551
exploration/Rewards Std        0.09838711502435733
exploration/Rewards Max        0.9789059673885003
exploration/Rewards Min        0.5010790594360973
exploration/Returns Mean       461.0306030183775
exploration/Returns Std        22.795423298759378
exploration/Returns Max        480.6715639187322
exploration/Returns Min        408.7260651336541
exploration/Actions Mean       0.062885545
exploration/Actions Std        0.640858
exploration/Actions Max        0.99999934
exploration/Actions Min        -0.99999964
exploration/Num Paths          10
exploration/Average Returns    461.0306030183775
evaluation/num steps total     1480000
evaluation/num paths total     2960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9480408912437677
evaluation/Rewards Std         0.06818617004237282
evaluation/Rewards Max         0.9794411808978736
evaluation/Rewards Min         0.5026145156204666
evaluation/Returns Mean        474.0204456218838
evaluation/Returns Std         11.796609910798644
evaluation/Returns Max         480.94411924247294
evaluation/Returns Min         439.5541166434576
evaluation/ExplReturns Mean    474.0204456218838
evaluation/ExplReturns Std     11.796609910798644
evaluation/ExplReturns Max     480.94411924247294
evaluation/ExplReturns Min     439.5541166434576
evaluation/Actions Mean        0.09025268
evaluation/Actions Std         0.5757241
evaluation/Actions Max         0.9999743
evaluation/Actions Min         -0.9999996
evaluation/Num Paths           10
evaluation/Average Returns     474.0204456218838
time/data storing (s)          0.031900253146886826
time/evaluation sampling (s)   111.12322750594467
time/exploration sampling (s)  112.17794180009514
time/logging (s)               0.03125640470534563
time/saving (s)                0.012878317385911942
time/training (s)              9.638941694051027
time/epoch (s)                 233.01614597532898
time/total (s)                 69191.3052164698
Epoch                          295
-----------------------------  ---------------------
2023-08-01 13:11:09.112675 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 296 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3783.8599]
trainer/QF1 Loss               0.033849046
trainer/QF2 Loss               0.028585508
trainer/Policy Loss            -90.733444
trainer/Q1 Predictions Mean    101.398346
trainer/Q1 Predictions Std     3.4331634
trainer/Q1 Predictions Max     103.88028
trainer/Q1 Predictions Min     73.44027
trainer/Q2 Predictions Mean    101.39525
trainer/Q2 Predictions Std     3.4214756
trainer/Q2 Predictions Max     103.808426
trainer/Q2 Predictions Min     73.897766
trainer/Q Targets Mean         101.47362
trainer/Q Targets Std          3.44146
trainer/Q Targets Max          103.84793
trainer/Q Targets Min          73.89027
trainer/Log Pis Mean           10.772945
trainer/Log Pis Std            8.993168
trainer/Log Pis Max            65.59529
trainer/Log Pis Min            -4.895252
trainer/Policy mu Mean         0.10959176
trainer/Policy mu Std          1.4971664
trainer/Policy mu Max          6.6030207
trainer/Policy mu Min          -6.543922
trainer/Policy log std Mean    -0.810309
trainer/Policy log std Std     0.2912917
trainer/Policy log std Max     0.5044261
trainer/Policy log std Min     -2.4788904
trainer/Alpha                  0.001734366873279214
trainer/Alpha Loss             -7.800287246704102
exploration/num steps total    1486000
exploration/num paths total    2972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9145078627387185
exploration/Rewards Std        0.09707333486451726
exploration/Rewards Max        0.9796992383532755
exploration/Rewards Min        0.5047986726499157
exploration/Returns Mean       457.2539313693593
exploration/Returns Std        37.12723487788124
exploration/Returns Max        477.12198734377256
exploration/Returns Min        380.2435904324338
exploration/Actions Mean       0.06834578
exploration/Actions Std        0.6060862
exploration/Actions Max        0.9999955
exploration/Actions Min        -0.99999684
exploration/Num Paths          10
exploration/Average Returns    457.2539313693593
evaluation/num steps total     1485000
evaluation/num paths total     2970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9512052021322441
evaluation/Rewards Std         0.04831344317933775
evaluation/Rewards Max         0.9799327780732906
evaluation/Rewards Min         0.5030642403736775
evaluation/Returns Mean        475.60260106612213
evaluation/Returns Std         1.757664408769313
evaluation/Returns Max         476.87166782651724
evaluation/Returns Min         470.6939264368633
evaluation/ExplReturns Mean    475.60260106612213
evaluation/ExplReturns Std     1.757664408769313
evaluation/ExplReturns Max     476.87166782651724
evaluation/ExplReturns Min     470.6939264368633
evaluation/Actions Mean        0.04942327
evaluation/Actions Std         0.5013993
evaluation/Actions Max         0.9997441
evaluation/Actions Min         -0.99988157
evaluation/Num Paths           10
evaluation/Average Returns     475.60260106612213
time/data storing (s)          0.03196784295141697
time/evaluation sampling (s)   108.31145738530904
time/exploration sampling (s)  111.12904920987785
time/logging (s)               0.030658869072794914
time/saving (s)                0.012918095104396343
time/training (s)              9.747717754915357
time/epoch (s)                 229.26376915723085
time/total (s)                 69420.57161337696
Epoch                          296
-----------------------------  --------------------
2023-08-01 13:14:58.068229 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 297 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3633.8875]
trainer/QF1 Loss               0.030622168
trainer/QF2 Loss               0.035549402
trainer/Policy Loss            -88.54841
trainer/Q1 Predictions Mean    101.06256
trainer/Q1 Predictions Std     3.7766368
trainer/Q1 Predictions Max     103.86945
trainer/Q1 Predictions Min     69.97314
trainer/Q2 Predictions Mean    101.07408
trainer/Q2 Predictions Std     3.8010733
trainer/Q2 Predictions Max     103.787636
trainer/Q2 Predictions Min     69.144516
trainer/Q Targets Mean         101.04407
trainer/Q Targets Std          3.785649
trainer/Q Targets Max          103.82653
trainer/Q Targets Min          69.79731
trainer/Log Pis Mean           12.670072
trainer/Log Pis Std            8.202646
trainer/Log Pis Max            41.720932
trainer/Log Pis Min            -3.4772782
trainer/Policy mu Mean         0.26038304
trainer/Policy mu Std          1.593761
trainer/Policy mu Max          5.5451803
trainer/Policy mu Min          -5.283705
trainer/Policy log std Mean    -0.7767184
trainer/Policy log std Std     0.3004605
trainer/Policy log std Max     0.3040315
trainer/Policy log std Min     -2.2246957
trainer/Alpha                  0.001693733036518097
trainer/Alpha Loss             4.27579927444458
exploration/num steps total    1491000
exploration/num paths total    2982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9537751253938619
exploration/Rewards Std        0.04889314789396477
exploration/Rewards Max        0.9788283401991364
exploration/Rewards Min        0.4932920758999411
exploration/Returns Mean       476.88756269693096
exploration/Returns Std        0.8438660240779478
exploration/Returns Max        478.15819505642753
exploration/Returns Min        475.4339595188122
exploration/Actions Mean       0.059757035
exploration/Actions Std        0.57811755
exploration/Actions Max        0.9997304
exploration/Actions Min        -0.9999775
exploration/Num Paths          10
exploration/Average Returns    476.88756269693096
evaluation/num steps total     1490000
evaluation/num paths total     2980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9539856615264438
evaluation/Rewards Std         0.04702850336105156
evaluation/Rewards Max         0.9785676848157906
evaluation/Rewards Min         0.4957342626827438
evaluation/Returns Mean        476.992830763222
evaluation/Returns Std         0.5787302991847799
evaluation/Returns Max         477.5460716446042
evaluation/Returns Min         475.50179495388755
evaluation/ExplReturns Mean    476.992830763222
evaluation/ExplReturns Std     0.5787302991847799
evaluation/ExplReturns Max     477.5460716446042
evaluation/ExplReturns Min     475.50179495388755
evaluation/Actions Mean        0.061632782
evaluation/Actions Std         0.49774772
evaluation/Actions Max         0.9985918
evaluation/Actions Min         -0.999291
evaluation/Num Paths           10
evaluation/Average Returns     476.992830763222
time/data storing (s)          0.03226599283516407
time/evaluation sampling (s)   108.85939208511263
time/exploration sampling (s)  110.48258059378713
time/logging (s)               0.030483780428767204
time/saving (s)                0.012518432922661304
time/training (s)              9.532977529801428
time/epoch (s)                 228.9502184148878
time/total (s)                 69649.52432318218
Epoch                          297
-----------------------------  --------------------
2023-08-01 13:18:52.942635 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 298 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3440.4653]
trainer/QF1 Loss               0.029837353
trainer/QF2 Loss               0.029199071
trainer/Policy Loss            -90.264145
trainer/Q1 Predictions Mean    101.50584
trainer/Q1 Predictions Std     3.0137842
trainer/Q1 Predictions Max     103.92252
trainer/Q1 Predictions Min     78.34752
trainer/Q2 Predictions Mean    101.47795
trainer/Q2 Predictions Std     3.008724
trainer/Q2 Predictions Max     103.926125
trainer/Q2 Predictions Min     78.23042
trainer/Q Targets Mean         101.48762
trainer/Q Targets Std          2.9565253
trainer/Q Targets Max          103.992645
trainer/Q Targets Min          79.04261
trainer/Log Pis Mean           11.3161745
trainer/Log Pis Std            7.979795
trainer/Log Pis Max            45.643456
trainer/Log Pis Min            -2.8835554
trainer/Policy mu Mean         0.3136473
trainer/Policy mu Std          1.5499184
trainer/Policy mu Max          5.634507
trainer/Policy mu Min          -6.6999273
trainer/Policy log std Mean    -0.73379564
trainer/Policy log std Std     0.28385642
trainer/Policy log std Max     0.24772301
trainer/Policy log std Min     -2.22645
trainer/Alpha                  0.0018287284765392542
trainer/Alpha Loss             -4.310811519622803
exploration/num steps total    1496000
exploration/num paths total    2992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8900680699525434
exploration/Rewards Std        0.10888523813712518
exploration/Rewards Max        0.9793963607272987
exploration/Rewards Min        0.4942412319744855
exploration/Returns Mean       445.0340349762715
exploration/Returns Std        22.656944371821268
exploration/Returns Max        479.23902603342094
exploration/Returns Min        412.72273094547427
exploration/Actions Mean       0.06833156
exploration/Actions Std        0.64846194
exploration/Actions Max        0.99999934
exploration/Actions Min        -0.999983
exploration/Num Paths          10
exploration/Average Returns    445.0340349762715
evaluation/num steps total     1495000
evaluation/num paths total     2990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9122067409825803
evaluation/Rewards Std         0.10090360826557304
evaluation/Rewards Max         0.9790912195905689
evaluation/Rewards Min         0.4883223006358322
evaluation/Returns Mean        456.1033704912901
evaluation/Returns Std         18.72717280377744
evaluation/Returns Max         478.8385937528727
evaluation/Returns Min         427.6053313000212
evaluation/ExplReturns Mean    456.1033704912901
evaluation/ExplReturns Std     18.72717280377744
evaluation/ExplReturns Max     478.8385937528727
evaluation/ExplReturns Min     427.6053313000212
evaluation/Actions Mean        0.055894386
evaluation/Actions Std         0.556404
evaluation/Actions Max         0.9999809
evaluation/Actions Min         -0.9999746
evaluation/Num Paths           10
evaluation/Average Returns     456.1033704912901
time/data storing (s)          0.032173928804695606
time/evaluation sampling (s)   111.78851789049804
time/exploration sampling (s)  113.3163257194683
time/logging (s)               0.030852441675961018
time/saving (s)                0.010859313420951366
time/training (s)              9.69072303827852
time/epoch (s)                 234.86945233214647
time/total (s)                 69884.39636171609
Epoch                          298
-----------------------------  ---------------------
2023-08-01 13:22:47.858887 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 299 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3793.6533]
trainer/QF1 Loss               0.04273186
trainer/QF2 Loss               0.03453087
trainer/Policy Loss            -89.959564
trainer/Q1 Predictions Mean    101.272354
trainer/Q1 Predictions Std     2.760803
trainer/Q1 Predictions Max     103.84729
trainer/Q1 Predictions Min     92.849594
trainer/Q2 Predictions Mean    101.325905
trainer/Q2 Predictions Std     2.7628615
trainer/Q2 Predictions Max     103.82025
trainer/Q2 Predictions Min     92.90136
trainer/Q Targets Mean         101.37741
trainer/Q Targets Std          2.7723737
trainer/Q Targets Max          103.83391
trainer/Q Targets Min          93.079445
trainer/Log Pis Mean           11.446732
trainer/Log Pis Std            8.56307
trainer/Log Pis Max            45.34465
trainer/Log Pis Min            -6.5829015
trainer/Policy mu Mean         0.22816797
trainer/Policy mu Std          1.5190251
trainer/Policy mu Max          5.2383204
trainer/Policy mu Min          -4.866669
trainer/Policy log std Mean    -0.7790076
trainer/Policy log std Std     0.288631
trainer/Policy log std Max     0.07615352
trainer/Policy log std Min     -2.2575371
trainer/Alpha                  0.0017037237994372845
trainer/Alpha Loss             -3.526912212371826
exploration/num steps total    1501000
exploration/num paths total    3002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8664596602959062
exploration/Rewards Std        0.12066774003826106
exploration/Rewards Max        0.9797843166403212
exploration/Rewards Min        0.4825175155284203
exploration/Returns Mean       433.22983014795307
exploration/Returns Std        35.46365223849411
exploration/Returns Max        482.0472190168835
exploration/Returns Min        392.4086207576042
exploration/Actions Mean       0.08787887
exploration/Actions Std        0.6405311
exploration/Actions Max        0.9999985
exploration/Actions Min        -0.99995273
exploration/Num Paths          10
exploration/Average Returns    433.22983014795307
evaluation/num steps total     1500000
evaluation/num paths total     3000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9035887768810993
evaluation/Rewards Std         0.11153979741358765
evaluation/Rewards Max         0.9796566779369583
evaluation/Rewards Min         0.4949922010176865
evaluation/Returns Mean        451.79438844054965
evaluation/Returns Std         39.45563795620577
evaluation/Returns Max         482.95407548450373
evaluation/Returns Min         387.0465803510921
evaluation/ExplReturns Mean    451.79438844054965
evaluation/ExplReturns Std     39.45563795620577
evaluation/ExplReturns Max     482.95407548450373
evaluation/ExplReturns Min     387.0465803510921
evaluation/Actions Mean        0.102258995
evaluation/Actions Std         0.5532972
evaluation/Actions Max         0.9995299
evaluation/Actions Min         -0.9998543
evaluation/Num Paths           10
evaluation/Average Returns     451.79438844054965
time/data storing (s)          0.031794823706150055
time/evaluation sampling (s)   111.14606792014092
time/exploration sampling (s)  114.0739446207881
time/logging (s)               0.03037483524531126
time/saving (s)                0.010731808841228485
time/training (s)              9.617663176730275
time/epoch (s)                 234.91057718545198
time/total (s)                 70119.30943861417
Epoch                          299
-----------------------------  ---------------------
2023-08-01 13:26:42.449475 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 300 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3717.1143]
trainer/QF1 Loss               0.06826337
trainer/QF2 Loss               0.06953953
trainer/Policy Loss            -88.29254
trainer/Q1 Predictions Mean    101.0944
trainer/Q1 Predictions Std     4.171024
trainer/Q1 Predictions Max     103.91914
trainer/Q1 Predictions Min     62.724922
trainer/Q2 Predictions Mean    101.088104
trainer/Q2 Predictions Std     4.097059
trainer/Q2 Predictions Max     103.75272
trainer/Q2 Predictions Min     64.14901
trainer/Q Targets Mean         101.19783
trainer/Q Targets Std          4.14317
trainer/Q Targets Max          103.97512
trainer/Q Targets Min          62.840797
trainer/Log Pis Mean           12.917188
trainer/Log Pis Std            8.963254
trainer/Log Pis Max            45.636017
trainer/Log Pis Min            -5.0885935
trainer/Policy mu Mean         0.20697851
trainer/Policy mu Std          1.6064352
trainer/Policy mu Max          7.0753865
trainer/Policy mu Min          -8.877493
trainer/Policy log std Mean    -0.7625769
trainer/Policy log std Std     0.30360022
trainer/Policy log std Max     0.56764674
trainer/Policy log std Min     -2.3675673
trainer/Alpha                  0.001695002312771976
trainer/Alpha Loss             5.851743698120117
exploration/num steps total    1506000
exploration/num paths total    3012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8893840557688746
exploration/Rewards Std        0.11621730305138585
exploration/Rewards Max        0.9794815909795404
exploration/Rewards Min        0.4855075567178695
exploration/Returns Mean       444.69202788443715
exploration/Returns Std        34.4255255970113
exploration/Returns Max        481.424482574677
exploration/Returns Min        385.3740855878048
exploration/Actions Mean       0.020503527
exploration/Actions Std        0.6290622
exploration/Actions Max        0.99999905
exploration/Actions Min        -0.99990976
exploration/Num Paths          10
exploration/Average Returns    444.69202788443715
evaluation/num steps total     1505000
evaluation/num paths total     3010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.878300500238347
evaluation/Rewards Std         0.12232319752819093
evaluation/Rewards Max         0.9790323670399751
evaluation/Rewards Min         0.4795121234373394
evaluation/Returns Mean        439.1502501191735
evaluation/Returns Std         37.76031563283173
evaluation/Returns Max         481.8296873300528
evaluation/Returns Min         392.3866304787441
evaluation/ExplReturns Mean    439.1502501191735
evaluation/ExplReturns Std     37.76031563283173
evaluation/ExplReturns Max     481.8296873300528
evaluation/ExplReturns Min     392.3866304787441
evaluation/Actions Mean        0.020826166
evaluation/Actions Std         0.5555721
evaluation/Actions Max         0.9999326
evaluation/Actions Min         -0.99988973
evaluation/Num Paths           10
evaluation/Average Returns     439.1502501191735
time/data storing (s)          0.03220994584262371
time/evaluation sampling (s)   111.80856819264591
time/exploration sampling (s)  112.9885467523709
time/logging (s)               0.030547560192644596
time/saving (s)                0.010365862399339676
time/training (s)              9.715353230014443
time/epoch (s)                 234.58559154346585
time/total (s)                 70353.89750915952
Epoch                          300
-----------------------------  --------------------
2023-08-01 13:30:37.443948 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 301 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3651.0005]
trainer/QF1 Loss               0.03674231
trainer/QF2 Loss               0.042609878
trainer/Policy Loss            -89.30319
trainer/Q1 Predictions Mean    101.724106
trainer/Q1 Predictions Std     2.4645066
trainer/Q1 Predictions Max     104.32613
trainer/Q1 Predictions Min     84.81239
trainer/Q2 Predictions Mean    101.5856
trainer/Q2 Predictions Std     2.4452627
trainer/Q2 Predictions Max     103.966286
trainer/Q2 Predictions Min     85.060486
trainer/Q Targets Mean         101.66848
trainer/Q Targets Std          2.4979844
trainer/Q Targets Max          104.116035
trainer/Q Targets Min          84.531815
trainer/Log Pis Mean           12.432818
trainer/Log Pis Std            8.121761
trainer/Log Pis Max            49.157543
trainer/Log Pis Min            -5.675364
trainer/Policy mu Mean         0.07423621
trainer/Policy mu Std          1.588995
trainer/Policy mu Max          7.2422037
trainer/Policy mu Min          -4.8237014
trainer/Policy log std Mean    -0.761542
trainer/Policy log std Std     0.313943
trainer/Policy log std Max     0.3413065
trainer/Policy log std Min     -2.2777426
trainer/Alpha                  0.0016309028724208474
trainer/Alpha Loss             2.778104782104492
exploration/num steps total    1511000
exploration/num paths total    3022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9612570861842272
exploration/Rewards Std        0.057464071324244505
exploration/Rewards Max        0.9797062114410988
exploration/Rewards Min        0.4851918825912995
exploration/Returns Mean       480.6285430921133
exploration/Returns Std        1.1666266549546225
exploration/Returns Max        482.0536625172964
exploration/Returns Min        477.78978891733925
exploration/Actions Mean       0.0020634886
exploration/Actions Std        0.59621876
exploration/Actions Max        0.9998288
exploration/Actions Min        -0.99991316
exploration/Num Paths          10
exploration/Average Returns    480.6285430921133
evaluation/num steps total     1510000
evaluation/num paths total     3020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.962031606052923
evaluation/Rewards Std         0.056124703367386515
evaluation/Rewards Max         0.9797766807369049
evaluation/Rewards Min         0.4943781297595911
evaluation/Returns Mean        481.01580302646164
evaluation/Returns Std         0.35993212216583914
evaluation/Returns Max         481.6424539470412
evaluation/Returns Min         480.4268762530178
evaluation/ExplReturns Mean    481.01580302646164
evaluation/ExplReturns Std     0.35993212216583914
evaluation/ExplReturns Max     481.6424539470412
evaluation/ExplReturns Min     480.4268762530178
evaluation/Actions Mean        0.010992278
evaluation/Actions Std         0.52905416
evaluation/Actions Max         0.99919087
evaluation/Actions Min         -0.9985338
evaluation/Num Paths           10
evaluation/Average Returns     481.01580302646164
time/data storing (s)          0.03224792890250683
time/evaluation sampling (s)   112.75339845009148
time/exploration sampling (s)  112.50894606858492
time/logging (s)               0.031315709464251995
time/saving (s)                0.012995962984859943
time/training (s)              9.65109165944159
time/epoch (s)                 234.9899957794696
time/total (s)                 70588.88995205052
Epoch                          301
-----------------------------  ---------------------
2023-08-01 13:34:32.057560 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 302 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3811.5125]
trainer/QF1 Loss               0.032946154
trainer/QF2 Loss               0.023890687
trainer/Policy Loss            -89.10716
trainer/Q1 Predictions Mean    101.34395
trainer/Q1 Predictions Std     3.3617747
trainer/Q1 Predictions Max     104.10462
trainer/Q1 Predictions Min     79.67555
trainer/Q2 Predictions Mean    101.34259
trainer/Q2 Predictions Std     3.3865304
trainer/Q2 Predictions Max     103.967476
trainer/Q2 Predictions Min     78.511284
trainer/Q Targets Mean         101.31278
trainer/Q Targets Std          3.3524823
trainer/Q Targets Max          103.91572
trainer/Q Targets Min          79.14662
trainer/Log Pis Mean           12.361847
trainer/Log Pis Std            7.651014
trainer/Log Pis Max            44.301323
trainer/Log Pis Min            -1.402873
trainer/Policy mu Mean         0.005029481
trainer/Policy mu Std          1.6309565
trainer/Policy mu Max          6.2342844
trainer/Policy mu Min          -7.682357
trainer/Policy log std Mean    -0.72274685
trainer/Policy log std Std     0.29812664
trainer/Policy log std Max     1.3073994
trainer/Policy log std Min     -2.3561196
trainer/Alpha                  0.0016870179679244757
trainer/Alpha Loss             2.310368537902832
exploration/num steps total    1516000
exploration/num paths total    3032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9521789251105329
exploration/Rewards Std        0.05918525520273627
exploration/Rewards Max        0.9793272310265583
exploration/Rewards Min        0.485601581903639
exploration/Returns Mean       476.08946255526655
exploration/Returns Std        1.2810924508096
exploration/Returns Max        477.5374387592467
exploration/Returns Min        473.66214738751876
exploration/Actions Mean       0.025837017
exploration/Actions Std        0.61389565
exploration/Actions Max        0.9998843
exploration/Actions Min        -0.9998958
exploration/Num Paths          10
exploration/Average Returns    476.08946255526655
evaluation/num steps total     1515000
evaluation/num paths total     3030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9522488581760111
evaluation/Rewards Std         0.05171345104050065
evaluation/Rewards Max         0.9778594746358119
evaluation/Rewards Min         0.4920030530174677
evaluation/Returns Mean        476.12442908800557
evaluation/Returns Std         0.6710080009803269
evaluation/Returns Max         477.6714057179943
evaluation/Returns Min         475.1816175612758
evaluation/ExplReturns Mean    476.12442908800557
evaluation/ExplReturns Std     0.6710080009803269
evaluation/ExplReturns Max     477.6714057179943
evaluation/ExplReturns Min     475.1816175612758
evaluation/Actions Mean        0.04453375
evaluation/Actions Std         0.54577166
evaluation/Actions Max         0.9994435
evaluation/Actions Min         -0.9990643
evaluation/Num Paths           10
evaluation/Average Returns     476.12442908800557
time/data storing (s)          0.03230918198823929
time/evaluation sampling (s)   112.34287057910115
time/exploration sampling (s)  112.49649774562567
time/logging (s)               0.03128377068787813
time/saving (s)                0.012749615125358105
time/training (s)              9.692714671604335
time/epoch (s)                 234.60842556413263
time/total (s)                 70823.50080601219
Epoch                          302
-----------------------------  ---------------------
2023-08-01 13:38:26.329267 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 303 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4180.8027]
trainer/QF1 Loss               0.056849778
trainer/QF2 Loss               0.049687184
trainer/Policy Loss            -90.01957
trainer/Q1 Predictions Mean    101.352516
trainer/Q1 Predictions Std     3.1380064
trainer/Q1 Predictions Max     103.84268
trainer/Q1 Predictions Min     82.21552
trainer/Q2 Predictions Mean    101.31816
trainer/Q2 Predictions Std     3.1258624
trainer/Q2 Predictions Max     103.76576
trainer/Q2 Predictions Min     81.827736
trainer/Q Targets Mean         101.396324
trainer/Q Targets Std          3.0701077
trainer/Q Targets Max          103.814896
trainer/Q Targets Min          83.035355
trainer/Log Pis Mean           11.410955
trainer/Log Pis Std            8.8997555
trainer/Log Pis Max            45.75052
trainer/Log Pis Min            -6.177045
trainer/Policy mu Mean         0.04932959
trainer/Policy mu Std          1.5590506
trainer/Policy mu Max          5.503648
trainer/Policy mu Min          -6.19013
trainer/Policy log std Mean    -0.76022774
trainer/Policy log std Std     0.30078602
trainer/Policy log std Max     0.9113651
trainer/Policy log std Min     -2.3181903
trainer/Alpha                  0.0016659434186294675
trainer/Alpha Loss             -3.7682933807373047
exploration/num steps total    1521000
exploration/num paths total    3042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9605855525664275
exploration/Rewards Std        0.05190865455966337
exploration/Rewards Max        0.9794244760652012
exploration/Rewards Min        0.48714603519500177
exploration/Returns Mean       480.292776283214
exploration/Returns Std        1.0103221111357765
exploration/Returns Max        481.0836115405689
exploration/Returns Min        478.02373429208353
exploration/Actions Mean       0.020288901
exploration/Actions Std        0.57079655
exploration/Actions Max        0.9999289
exploration/Actions Min        -0.9999904
exploration/Num Paths          10
exploration/Average Returns    480.292776283214
evaluation/num steps total     1520000
evaluation/num paths total     3040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9589516676793153
evaluation/Rewards Std         0.05327463178922071
evaluation/Rewards Max         0.9793192227399283
evaluation/Rewards Min         0.4961838284099293
evaluation/Returns Mean        479.47583383965764
evaluation/Returns Std         1.1321801527219348
evaluation/Returns Max         481.6244076282274
evaluation/Returns Min         477.2732493306173
evaluation/ExplReturns Mean    479.47583383965764
evaluation/ExplReturns Std     1.1321801527219348
evaluation/ExplReturns Max     481.6244076282274
evaluation/ExplReturns Min     477.2732493306173
evaluation/Actions Mean        0.05484666
evaluation/Actions Std         0.4474461
evaluation/Actions Max         0.9994035
evaluation/Actions Min         -0.99958843
evaluation/Num Paths           10
evaluation/Average Returns     479.47583383965764
time/data storing (s)          0.03211069293320179
time/evaluation sampling (s)   111.59871387202293
time/exploration sampling (s)  112.94569766055793
time/logging (s)               0.030926749110221863
time/saving (s)                0.012427464127540588
time/training (s)              9.646267942152917
time/epoch (s)                 234.26614438090473
time/total (s)                 71057.7694086628
Epoch                          303
-----------------------------  ---------------------
2023-08-01 13:42:19.914176 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 304 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4153.488]
trainer/QF1 Loss               0.025824293
trainer/QF2 Loss               0.026260514
trainer/Policy Loss            -90.28382
trainer/Q1 Predictions Mean    101.66464
trainer/Q1 Predictions Std     3.284843
trainer/Q1 Predictions Max     103.78881
trainer/Q1 Predictions Min     68.20462
trainer/Q2 Predictions Mean    101.63573
trainer/Q2 Predictions Std     3.2624106
trainer/Q2 Predictions Max     103.69846
trainer/Q2 Predictions Min     68.87032
trainer/Q Targets Mean         101.67657
trainer/Q Targets Std          3.3059907
trainer/Q Targets Max          103.80825
trainer/Q Targets Min          68.46061
trainer/Log Pis Mean           11.483728
trainer/Log Pis Std            9.095399
trainer/Log Pis Max            49.870472
trainer/Log Pis Min            -4.560329
trainer/Policy mu Mean         0.032836866
trainer/Policy mu Std          1.5856049
trainer/Policy mu Max          8.295457
trainer/Policy mu Min          -5.7427216
trainer/Policy log std Mean    -0.73857546
trainer/Policy log std Std     0.28296214
trainer/Policy log std Max     0.74504745
trainer/Policy log std Min     -2.5739462
trainer/Alpha                  0.0016563653480261564
trainer/Alpha Loss             -3.3058249950408936
exploration/num steps total    1526000
exploration/num paths total    3052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9499395183144032
exploration/Rewards Std        0.05242535384863201
exploration/Rewards Max        0.9766627497836886
exploration/Rewards Min        0.49800091373704736
exploration/Returns Mean       474.96975915720157
exploration/Returns Std        0.7034104737414717
exploration/Returns Max        476.087132691502
exploration/Returns Min        474.1212548398006
exploration/Actions Mean       0.008373666
exploration/Actions Std        0.5979287
exploration/Actions Max        0.99980336
exploration/Actions Min        -0.9999012
exploration/Num Paths          10
exploration/Average Returns    474.96975915720157
evaluation/num steps total     1525000
evaluation/num paths total     3050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.944744434815864
evaluation/Rewards Std         0.06298375952934522
evaluation/Rewards Max         0.9764997271989373
evaluation/Rewards Min         0.48938004439953525
evaluation/Returns Mean        472.37221740793194
evaluation/Returns Std         2.6200011122791538
evaluation/Returns Max         476.21061675317804
evaluation/Returns Min         466.86010905604394
evaluation/ExplReturns Mean    472.37221740793194
evaluation/ExplReturns Std     2.6200011122791538
evaluation/ExplReturns Max     476.21061675317804
evaluation/ExplReturns Min     466.86010905604394
evaluation/Actions Mean        -0.04053098
evaluation/Actions Std         0.5543672
evaluation/Actions Max         0.9994815
evaluation/Actions Min         -0.99962246
evaluation/Num Paths           10
evaluation/Average Returns     472.37221740793194
time/data storing (s)          0.031974040903151035
time/evaluation sampling (s)   111.7090043220669
time/exploration sampling (s)  112.85801635310054
time/logging (s)               0.031252190470695496
time/saving (s)                0.012811902910470963
time/training (s)              8.936794316396117
time/epoch (s)                 233.57985312584788
time/total (s)                 71291.3518470116
Epoch                          304
-----------------------------  ---------------------
2023-08-01 13:46:13.751773 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 305 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3741.7705]
trainer/QF1 Loss               0.041115522
trainer/QF2 Loss               0.040353425
trainer/Policy Loss            -88.77519
trainer/Q1 Predictions Mean    101.53157
trainer/Q1 Predictions Std     3.4608169
trainer/Q1 Predictions Max     103.76677
trainer/Q1 Predictions Min     73.89291
trainer/Q2 Predictions Mean    101.579834
trainer/Q2 Predictions Std     3.475826
trainer/Q2 Predictions Max     103.81222
trainer/Q2 Predictions Min     73.09071
trainer/Q Targets Mean         101.51813
trainer/Q Targets Std          3.3944807
trainer/Q Targets Max          103.719345
trainer/Q Targets Min          74.39551
trainer/Log Pis Mean           12.877615
trainer/Log Pis Std            8.282594
trainer/Log Pis Max            50.041885
trainer/Log Pis Min            -2.9357147
trainer/Policy mu Mean         -0.09251648
trainer/Policy mu Std          1.6691993
trainer/Policy mu Max          8.503281
trainer/Policy mu Min          -5.318774
trainer/Policy log std Mean    -0.6850233
trainer/Policy log std Std     0.2895106
trainer/Policy log std Max     0.12277414
trainer/Policy log std Min     -2.2092173
trainer/Alpha                  0.0017426193226128817
trainer/Alpha Loss             5.575338363647461
exploration/num steps total    1531000
exploration/num paths total    3062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9547843408190265
exploration/Rewards Std        0.053313930369502986
exploration/Rewards Max        0.9795610827222012
exploration/Rewards Min        0.48832996041470245
exploration/Returns Mean       477.39217040951337
exploration/Returns Std        0.7626045505044747
exploration/Returns Max        478.38584698516934
exploration/Returns Min        475.605903352935
exploration/Actions Mean       -0.048497148
exploration/Actions Std        0.621792
exploration/Actions Max        0.9998503
exploration/Actions Min        -0.9998756
exploration/Num Paths          10
exploration/Average Returns    477.39217040951337
evaluation/num steps total     1530000
evaluation/num paths total     3060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9543815053226772
evaluation/Rewards Std         0.05361348960753844
evaluation/Rewards Max         0.9766932392264288
evaluation/Rewards Min         0.4933916966930303
evaluation/Returns Mean        477.1907526613385
evaluation/Returns Std         0.9177562604997495
evaluation/Returns Max         478.5323082216171
evaluation/Returns Min         475.5002517587531
evaluation/ExplReturns Mean    477.1907526613385
evaluation/ExplReturns Std     0.9177562604997495
evaluation/ExplReturns Max     478.5323082216171
evaluation/ExplReturns Min     475.5002517587531
evaluation/Actions Mean        -0.0763442
evaluation/Actions Std         0.49330977
evaluation/Actions Max         0.99907994
evaluation/Actions Min         -0.999402
evaluation/Num Paths           10
evaluation/Average Returns     477.1907526613385
time/data storing (s)          0.03228612709790468
time/evaluation sampling (s)   112.35064088180661
time/exploration sampling (s)  111.87539347819984
time/logging (s)               0.030472291633486748
time/saving (s)                0.01145715732127428
time/training (s)              9.531347780488431
time/epoch (s)                 233.83159771654755
time/total (s)                 71525.18591779005
Epoch                          305
-----------------------------  ---------------------
2023-08-01 13:50:10.100222 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 306 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4030.1897]
trainer/QF1 Loss               0.04333817
trainer/QF2 Loss               0.038203828
trainer/Policy Loss            -90.35539
trainer/Q1 Predictions Mean    101.67343
trainer/Q1 Predictions Std     3.2760875
trainer/Q1 Predictions Max     103.95401
trainer/Q1 Predictions Min     69.9801
trainer/Q2 Predictions Mean    101.67287
trainer/Q2 Predictions Std     3.3052547
trainer/Q2 Predictions Max     103.964134
trainer/Q2 Predictions Min     69.50278
trainer/Q Targets Mean         101.6162
trainer/Q Targets Std          3.2239256
trainer/Q Targets Max          103.881905
trainer/Q Targets Min          70.84645
trainer/Log Pis Mean           11.457342
trainer/Log Pis Std            8.686997
trainer/Log Pis Max            71.50525
trainer/Log Pis Min            -5.1088314
trainer/Policy mu Mean         0.17964037
trainer/Policy mu Std          1.5626959
trainer/Policy mu Max          8.244554
trainer/Policy mu Min          -4.3461018
trainer/Policy log std Mean    -0.70947105
trainer/Policy log std Std     0.29264876
trainer/Policy log std Max     0.7375611
trainer/Policy log std Min     -2.4647586
trainer/Alpha                  0.0016275770030915737
trainer/Alpha Loss             -3.4841198921203613
exploration/num steps total    1536000
exploration/num paths total    3072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8883062713098446
exploration/Rewards Std        0.13503484681755729
exploration/Rewards Max        0.9786742659435271
exploration/Rewards Min        0.4939481043193619
exploration/Returns Mean       444.15313565492227
exploration/Returns Std        39.3762376624315
exploration/Returns Max        478.91405501239365
exploration/Returns Min        384.9755855079411
exploration/Actions Mean       0.2086808
exploration/Actions Std        0.63117653
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999813
exploration/Num Paths          10
exploration/Average Returns    444.15313565492227
evaluation/num steps total     1535000
evaluation/num paths total     3070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9218283157015797
evaluation/Rewards Std         0.1024153855091717
evaluation/Rewards Max         0.9792423907874664
evaluation/Rewards Min         0.5017066053621914
evaluation/Returns Mean        460.9141578507899
evaluation/Returns Std         24.00272716502239
evaluation/Returns Max         478.04211115752344
evaluation/Returns Min         403.4216357772531
evaluation/ExplReturns Mean    460.9141578507899
evaluation/ExplReturns Std     24.00272716502239
evaluation/ExplReturns Max     478.04211115752344
evaluation/ExplReturns Min     403.4216357772531
evaluation/Actions Mean        0.1884397
evaluation/Actions Std         0.5330993
evaluation/Actions Max         0.9999994
evaluation/Actions Min         -0.99987656
evaluation/Num Paths           10
evaluation/Average Returns     460.9141578507899
time/data storing (s)          0.032351343892514706
time/evaluation sampling (s)   112.9486253540963
time/exploration sampling (s)  113.66421821434051
time/logging (s)               0.03044217638671398
time/saving (s)                0.011517459526658058
time/training (s)              9.656123124994338
time/epoch (s)                 236.34327767323703
time/total (s)                 71761.53159745876
Epoch                          306
-----------------------------  ---------------------
2023-08-01 13:54:04.405697 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 307 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3975.4277]
trainer/QF1 Loss               0.024337485
trainer/QF2 Loss               0.02424447
trainer/Policy Loss            -89.03402
trainer/Q1 Predictions Mean    101.44429
trainer/Q1 Predictions Std     4.9191804
trainer/Q1 Predictions Max     103.77588
trainer/Q1 Predictions Min     63.302376
trainer/Q2 Predictions Mean    101.394196
trainer/Q2 Predictions Std     4.905426
trainer/Q2 Predictions Max     103.68804
trainer/Q2 Predictions Min     63.679684
trainer/Q Targets Mean         101.4314
trainer/Q Targets Std          4.8825765
trainer/Q Targets Max          103.81852
trainer/Q Targets Min          63.994694
trainer/Log Pis Mean           12.512159
trainer/Log Pis Std            8.386008
trainer/Log Pis Max            50.86608
trainer/Log Pis Min            -7.35505
trainer/Policy mu Mean         -0.106873274
trainer/Policy mu Std          1.6176875
trainer/Policy mu Max          6.513056
trainer/Policy mu Min          -8.76678
trainer/Policy log std Mean    -0.734153
trainer/Policy log std Std     0.31616887
trainer/Policy log std Max     0.61065316
trainer/Policy log std Min     -2.3052797
trainer/Alpha                  0.0015860828571021557
trainer/Alpha Loss             3.301738739013672
exploration/num steps total    1541000
exploration/num paths total    3082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9500302499144598
exploration/Rewards Std        0.05636100151904721
exploration/Rewards Max        0.9793607446344268
exploration/Rewards Min        0.49943688834132693
exploration/Returns Mean       475.01512495722983
exploration/Returns Std        2.342956375216038
exploration/Returns Max        477.3265671390093
exploration/Returns Min        468.5571261214669
exploration/Actions Mean       0.038460802
exploration/Actions Std        0.5953782
exploration/Actions Max        0.99991953
exploration/Actions Min        -0.99991244
exploration/Num Paths          10
exploration/Average Returns    475.01512495722983
evaluation/num steps total     1540000
evaluation/num paths total     3080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9159999714169021
evaluation/Rewards Std         0.09082815986906537
evaluation/Rewards Max         0.9796979993751962
evaluation/Rewards Min         0.4931660811700126
evaluation/Returns Mean        457.999985708451
evaluation/Returns Std         19.215743095815164
evaluation/Returns Max         475.39241478963766
evaluation/Returns Min         420.00828847280656
evaluation/ExplReturns Mean    457.999985708451
evaluation/ExplReturns Std     19.215743095815164
evaluation/ExplReturns Max     475.39241478963766
evaluation/ExplReturns Min     420.00828847280656
evaluation/Actions Mean        0.044776063
evaluation/Actions Std         0.520196
evaluation/Actions Max         0.99951506
evaluation/Actions Min         -0.999639
evaluation/Num Paths           10
evaluation/Average Returns     457.999985708451
time/data storing (s)          0.03233604598790407
time/evaluation sampling (s)   111.88419298268855
time/exploration sampling (s)  112.51915120426565
time/logging (s)               0.030746632255613804
time/saving (s)                0.01113446056842804
time/training (s)              9.82302017789334
time/epoch (s)                 234.3005815036595
time/total (s)                 71995.83464594278
Epoch                          307
-----------------------------  ---------------------
2023-08-01 13:57:56.081395 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 308 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3714.6665]
trainer/QF1 Loss               0.037084393
trainer/QF2 Loss               0.033064265
trainer/Policy Loss            -88.78584
trainer/Q1 Predictions Mean    101.60077
trainer/Q1 Predictions Std     2.8604982
trainer/Q1 Predictions Max     103.66264
trainer/Q1 Predictions Min     73.09997
trainer/Q2 Predictions Mean    101.711975
trainer/Q2 Predictions Std     2.8432403
trainer/Q2 Predictions Max     103.67625
trainer/Q2 Predictions Min     72.88819
trainer/Q Targets Mean         101.69092
trainer/Q Targets Std          2.8041904
trainer/Q Targets Max          103.71429
trainer/Q Targets Min          73.637245
trainer/Log Pis Mean           12.952396
trainer/Log Pis Std            9.002235
trainer/Log Pis Max            43.7856
trainer/Log Pis Min            -4.477164
trainer/Policy mu Mean         0.19929202
trainer/Policy mu Std          1.6665072
trainer/Policy mu Max          6.284185
trainer/Policy mu Min          -6.07213
trainer/Policy log std Mean    -0.69045955
trainer/Policy log std Std     0.29744768
trainer/Policy log std Max     0.20405933
trainer/Policy log std Min     -2.2610393
trainer/Alpha                  0.0016352799721062183
trainer/Alpha Loss             6.110474586486816
exploration/num steps total    1546000
exploration/num paths total    3092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9582669769227153
exploration/Rewards Std        0.053212996797396474
exploration/Rewards Max        0.9798352526540527
exploration/Rewards Min        0.49322285356438356
exploration/Returns Mean       479.1334884613577
exploration/Returns Std        3.4955432220103653
exploration/Returns Max        483.0631616644785
exploration/Returns Min        473.41181192672855
exploration/Actions Mean       0.07859724
exploration/Actions Std        0.5971977
exploration/Actions Max        0.9997636
exploration/Actions Min        -0.9999212
exploration/Num Paths          10
exploration/Average Returns    479.1334884613577
evaluation/num steps total     1545000
evaluation/num paths total     3090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9614246704071953
evaluation/Rewards Std         0.05363312989047298
evaluation/Rewards Max         0.979860611979955
evaluation/Rewards Min         0.4832908982787807
evaluation/Returns Mean        480.71233520359755
evaluation/Returns Std         2.4291995898586807
evaluation/Returns Max         482.8080637841351
evaluation/Returns Min         474.66669425343946
evaluation/ExplReturns Mean    480.71233520359755
evaluation/ExplReturns Std     2.4291995898586807
evaluation/ExplReturns Max     482.8080637841351
evaluation/ExplReturns Min     474.66669425343946
evaluation/Actions Mean        0.10354738
evaluation/Actions Std         0.5437264
evaluation/Actions Max         0.9991881
evaluation/Actions Min         -0.99998504
evaluation/Num Paths           10
evaluation/Average Returns     480.71233520359755
time/data storing (s)          0.03192483074963093
time/evaluation sampling (s)   110.14073805324733
time/exploration sampling (s)  111.76555135659873
time/logging (s)               0.03034592606127262
time/saving (s)                0.012177981436252594
time/training (s)              9.689225165173411
time/epoch (s)                 231.66996331326663
time/total (s)                 72227.50717806909
Epoch                          308
-----------------------------  ---------------------
2023-08-01 14:01:48.124664 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 309 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3897.0237]
trainer/QF1 Loss               0.070549816
trainer/QF2 Loss               0.02302422
trainer/Policy Loss            -89.92935
trainer/Q1 Predictions Mean    101.76366
trainer/Q1 Predictions Std     1.8403635
trainer/Q1 Predictions Max     103.420715
trainer/Q1 Predictions Min     94.14346
trainer/Q2 Predictions Mean    101.90193
trainer/Q2 Predictions Std     1.8230585
trainer/Q2 Predictions Max     103.55918
trainer/Q2 Predictions Min     94.44274
trainer/Q Targets Mean         101.95463
trainer/Q Targets Std          1.8508899
trainer/Q Targets Max          103.58094
trainer/Q Targets Min          94.62744
trainer/Log Pis Mean           11.969677
trainer/Log Pis Std            7.395371
trainer/Log Pis Max            39.53017
trainer/Log Pis Min            -2.3875592
trainer/Policy mu Mean         -0.11843107
trainer/Policy mu Std          1.6019366
trainer/Policy mu Max          5.1607003
trainer/Policy mu Min          -5.2472067
trainer/Policy log std Mean    -0.7175226
trainer/Policy log std Std     0.30542955
trainer/Policy log std Max     0.13737589
trainer/Policy log std Min     -2.4294367
trainer/Alpha                  0.001532138092443347
trainer/Alpha Loss             -0.1965179443359375
exploration/num steps total    1551000
exploration/num paths total    3102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9287295278900132
exploration/Rewards Std        0.0770965805626087
exploration/Rewards Max        0.9792882786559262
exploration/Rewards Min        0.49438503596254296
exploration/Returns Mean       464.36476394500676
exploration/Returns Std        4.069433585154191
exploration/Returns Max        470.8825085376242
exploration/Returns Min        456.97004273925074
exploration/Actions Mean       0.072467
exploration/Actions Std        0.6219806
exploration/Actions Max        0.9998273
exploration/Actions Min        -0.9999743
exploration/Num Paths          10
exploration/Average Returns    464.36476394500676
evaluation/num steps total     1550000
evaluation/num paths total     3100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9041609885548498
evaluation/Rewards Std         0.09520032645795205
evaluation/Rewards Max         0.9789417405796836
evaluation/Rewards Min         0.49115179241152884
evaluation/Returns Mean        452.0804942774249
evaluation/Returns Std         6.18213797879089
evaluation/Returns Max         461.446601785141
evaluation/Returns Min         436.1233248260141
evaluation/ExplReturns Mean    452.0804942774249
evaluation/ExplReturns Std     6.18213797879089
evaluation/ExplReturns Max     461.446601785141
evaluation/ExplReturns Min     436.1233248260141
evaluation/Actions Mean        0.043650746
evaluation/Actions Std         0.5545327
evaluation/Actions Max         0.9991192
evaluation/Actions Min         -0.9999912
evaluation/Num Paths           10
evaluation/Average Returns     452.0804942774249
time/data storing (s)          0.0321436645463109
time/evaluation sampling (s)   110.23932320717722
time/exploration sampling (s)  112.09429987333715
time/logging (s)               0.030635956674814224
time/saving (s)                0.010227303020656109
time/training (s)              9.631672967225313
time/epoch (s)                 232.03830297198147
time/total (s)                 72459.54796195123
Epoch                          309
-----------------------------  --------------------
2023-08-01 14:05:42.599935 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 310 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3782.7375]
trainer/QF1 Loss               0.025617197
trainer/QF2 Loss               0.06414489
trainer/Policy Loss            -90.11105
trainer/Q1 Predictions Mean    101.7841
trainer/Q1 Predictions Std     3.2960634
trainer/Q1 Predictions Max     103.57288
trainer/Q1 Predictions Min     62.509872
trainer/Q2 Predictions Mean    101.92763
trainer/Q2 Predictions Std     3.3126905
trainer/Q2 Predictions Max     103.84499
trainer/Q2 Predictions Min     62.358154
trainer/Q Targets Mean         101.73061
trainer/Q Targets Std          3.3063219
trainer/Q Targets Max          103.69551
trainer/Q Targets Min          62.42559
trainer/Log Pis Mean           11.801451
trainer/Log Pis Std            9.300469
trainer/Log Pis Max            64.919266
trainer/Log Pis Min            -3.7789237
trainer/Policy mu Mean         -0.1439731
trainer/Policy mu Std          1.6029805
trainer/Policy mu Max          6.489503
trainer/Policy mu Min          -6.0623126
trainer/Policy log std Mean    -0.7115434
trainer/Policy log std Std     0.29850736
trainer/Policy log std Max     0.806885
trainer/Policy log std Min     -2.502295
trainer/Alpha                  0.0014975413214415312
trainer/Alpha Loss             -1.2913663387298584
exploration/num steps total    1556000
exploration/num paths total    3112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9597236074009031
exploration/Rewards Std        0.050004626774617124
exploration/Rewards Max        0.9788360742042015
exploration/Rewards Min        0.4932853026930234
exploration/Returns Mean       479.8618037004517
exploration/Returns Std        0.7918709200010539
exploration/Returns Max        480.52218130947017
exploration/Returns Min        477.54696976429017
exploration/Actions Mean       0.14797042
exploration/Actions Std        0.6327494
exploration/Actions Max        0.99994296
exploration/Actions Min        -0.999906
exploration/Num Paths          10
exploration/Average Returns    479.8618037004517
evaluation/num steps total     1555000
evaluation/num paths total     3110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9593519531665126
evaluation/Rewards Std         0.05166858438065493
evaluation/Rewards Max         0.9789413891497629
evaluation/Rewards Min         0.49529296107206533
evaluation/Returns Mean        479.6759765832565
evaluation/Returns Std         1.1488457963555583
evaluation/Returns Max         480.99916445069226
evaluation/Returns Min         477.4072879024293
evaluation/ExplReturns Mean    479.6759765832565
evaluation/ExplReturns Std     1.1488457963555583
evaluation/ExplReturns Max     480.99916445069226
evaluation/ExplReturns Min     477.4072879024293
evaluation/Actions Mean        0.13779229
evaluation/Actions Std         0.533415
evaluation/Actions Max         0.99975026
evaluation/Actions Min         -0.99926585
evaluation/Num Paths           10
evaluation/Average Returns     479.6759765832565
time/data storing (s)          0.03213262092322111
time/evaluation sampling (s)   111.91976535879076
time/exploration sampling (s)  112.75482498016208
time/logging (s)               0.03043746668845415
time/saving (s)                0.012575834058225155
time/training (s)              9.720071155577898
time/epoch (s)                 234.46980741620064
time/total (s)                 72694.02020871267
Epoch                          310
-----------------------------  ---------------------
2023-08-01 14:09:37.824015 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 311 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3948.7388]
trainer/QF1 Loss               0.016224474
trainer/QF2 Loss               0.01409584
trainer/Policy Loss            -90.02353
trainer/Q1 Predictions Mean    101.88607
trainer/Q1 Predictions Std     2.0017123
trainer/Q1 Predictions Max     103.627
trainer/Q1 Predictions Min     94.36019
trainer/Q2 Predictions Mean    101.87619
trainer/Q2 Predictions Std     2.0175648
trainer/Q2 Predictions Max     103.59933
trainer/Q2 Predictions Min     94.00228
trainer/Q Targets Mean         101.86488
trainer/Q Targets Std          2.0150368
trainer/Q Targets Max          103.61728
trainer/Q Targets Min          94.1629
trainer/Log Pis Mean           11.974972
trainer/Log Pis Std            7.999665
trainer/Log Pis Max            37.748894
trainer/Log Pis Min            -2.5112677
trainer/Policy mu Mean         -0.056030303
trainer/Policy mu Std          1.5781697
trainer/Policy mu Max          4.457932
trainer/Policy mu Min          -5.406848
trainer/Policy log std Mean    -0.72480553
trainer/Policy log std Std     0.32246238
trainer/Policy log std Max     0.17616773
trainer/Policy log std Min     -2.4413629
trainer/Alpha                  0.0014927127631381154
trainer/Alpha Loss             -0.16286271810531616
exploration/num steps total    1561000
exploration/num paths total    3122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9605776388679462
exploration/Rewards Std        0.05434289114950681
exploration/Rewards Max        0.9781890266150107
exploration/Rewards Min        0.49656969771806625
exploration/Returns Mean       480.2888194339729
exploration/Returns Std        1.2984147518602078
exploration/Returns Max        481.5592036376546
exploration/Returns Min        476.99981866891477
exploration/Actions Mean       0.015945587
exploration/Actions Std        0.6203976
exploration/Actions Max        0.9999312
exploration/Actions Min        -0.99988526
exploration/Num Paths          10
exploration/Average Returns    480.2888194339729
evaluation/num steps total     1560000
evaluation/num paths total     3120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9577752386398377
evaluation/Rewards Std         0.05354246351514216
evaluation/Rewards Max         0.9769752053275952
evaluation/Rewards Min         0.48840706392026983
evaluation/Returns Mean        478.88761931991905
evaluation/Returns Std         1.3209135462492707
evaluation/Returns Max         480.70448751978375
evaluation/Returns Min         476.68337003147985
evaluation/ExplReturns Mean    478.88761931991905
evaluation/ExplReturns Std     1.3209135462492707
evaluation/ExplReturns Max     480.70448751978375
evaluation/ExplReturns Min     476.68337003147985
evaluation/Actions Mean        0.020334631
evaluation/Actions Std         0.54240215
evaluation/Actions Max         0.99929094
evaluation/Actions Min         -0.9997252
evaluation/Num Paths           10
evaluation/Average Returns     478.88761931991905
time/data storing (s)          0.031963035464286804
time/evaluation sampling (s)   112.37619936466217
time/exploration sampling (s)  113.09877998474985
time/logging (s)               0.030919834971427917
time/saving (s)                0.012792670167982578
time/training (s)              9.668397377245128
time/epoch (s)                 235.21905226726085
time/total (s)                 72929.24194096681
Epoch                          311
-----------------------------  ---------------------
2023-08-01 14:13:31.679076 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 312 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3890.0793]
trainer/QF1 Loss               0.03750115
trainer/QF2 Loss               0.025901295
trainer/Policy Loss            -90.14951
trainer/Q1 Predictions Mean    101.66701
trainer/Q1 Predictions Std     2.181838
trainer/Q1 Predictions Max     103.47126
trainer/Q1 Predictions Min     85.01044
trainer/Q2 Predictions Mean    101.83353
trainer/Q2 Predictions Std     2.166027
trainer/Q2 Predictions Max     103.53134
trainer/Q2 Predictions Min     85.0161
trainer/Q Targets Mean         101.80504
trainer/Q Targets Std          2.2071443
trainer/Q Targets Max          103.61137
trainer/Q Targets Min          85.15334
trainer/Log Pis Mean           11.687271
trainer/Log Pis Std            8.69996
trainer/Log Pis Max            42.5147
trainer/Log Pis Min            -7.4032164
trainer/Policy mu Mean         -0.032051507
trainer/Policy mu Std          1.5743351
trainer/Policy mu Max          6.7931976
trainer/Policy mu Min          -4.437573
trainer/Policy log std Mean    -0.71487814
trainer/Policy log std Std     0.33211014
trainer/Policy log std Max     0.5647727
trainer/Policy log std Min     -2.462655
trainer/Alpha                  0.0015279182698577642
trainer/Alpha Loss             -2.027726888656616
exploration/num steps total    1566000
exploration/num paths total    3132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.95871120899384
exploration/Rewards Std        0.05333136819071849
exploration/Rewards Max        0.9793244119955313
exploration/Rewards Min        0.4912526916080386
exploration/Returns Mean       479.35560449692
exploration/Returns Std        1.2286069846689596
exploration/Returns Max        481.18765584279527
exploration/Returns Min        476.31065434114663
exploration/Actions Mean       -0.032569584
exploration/Actions Std        0.6045464
exploration/Actions Max        0.99985015
exploration/Actions Min        -0.9999248
exploration/Num Paths          10
exploration/Average Returns    479.35560449692
evaluation/num steps total     1565000
evaluation/num paths total     3130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9429600830917884
evaluation/Rewards Std         0.07451769963083583
evaluation/Rewards Max         0.9780364452712608
evaluation/Rewards Min         0.49694222383144626
evaluation/Returns Mean        471.48004154589427
evaluation/Returns Std         12.820203761751223
evaluation/Returns Max         480.22561889303614
evaluation/Returns Min         441.35756761315776
evaluation/ExplReturns Mean    471.48004154589427
evaluation/ExplReturns Std     12.820203761751223
evaluation/ExplReturns Max     480.22561889303614
evaluation/ExplReturns Min     441.35756761315776
evaluation/Actions Mean        -0.06092464
evaluation/Actions Std         0.5040332
evaluation/Actions Max         0.9997892
evaluation/Actions Min         -0.9998537
evaluation/Num Paths           10
evaluation/Average Returns     471.48004154589427
time/data storing (s)          0.031775773502886295
time/evaluation sampling (s)   111.67727274168283
time/exploration sampling (s)  112.4293427374214
time/logging (s)               0.030558795668184757
time/saving (s)                0.010634543374180794
time/training (s)              9.669871694408357
time/epoch (s)                 233.84945628605783
time/total (s)                 73163.09386384394
Epoch                          312
-----------------------------  ---------------------
2023-08-01 14:17:28.026661 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 313 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3910.4158]
trainer/QF1 Loss               0.02240088
trainer/QF2 Loss               0.023610046
trainer/Policy Loss            -90.1996
trainer/Q1 Predictions Mean    101.87718
trainer/Q1 Predictions Std     2.5653496
trainer/Q1 Predictions Max     103.42926
trainer/Q1 Predictions Min     80.13241
trainer/Q2 Predictions Mean    101.83067
trainer/Q2 Predictions Std     2.5972147
trainer/Q2 Predictions Max     103.41817
trainer/Q2 Predictions Min     80.21898
trainer/Q Targets Mean         101.87837
trainer/Q Targets Std          2.5619059
trainer/Q Targets Max          103.34235
trainer/Q Targets Min          80.49255
trainer/Log Pis Mean           11.743111
trainer/Log Pis Std            7.5458097
trainer/Log Pis Max            54.52678
trainer/Log Pis Min            -5.806368
trainer/Policy mu Mean         -0.1818315
trainer/Policy mu Std          1.5708915
trainer/Policy mu Max          7.8140836
trainer/Policy mu Min          -7.798999
trainer/Policy log std Mean    -0.7174799
trainer/Policy log std Std     0.29307285
trainer/Policy log std Max     0.21536857
trainer/Policy log std Min     -2.4138308
trainer/Alpha                  0.0017080992693081498
trainer/Alpha Loss             -1.6369558572769165
exploration/num steps total    1571000
exploration/num paths total    3142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.960356901067025
exploration/Rewards Std        0.05122798657690979
exploration/Rewards Max        0.9785274836288166
exploration/Rewards Min        0.49559657536694096
exploration/Returns Mean       480.1784505335122
exploration/Returns Std        0.9267000911383177
exploration/Returns Max        481.76956684117425
exploration/Returns Min        478.49404844134824
exploration/Actions Mean       -0.10495878
exploration/Actions Std        0.6108136
exploration/Actions Max        0.99993736
exploration/Actions Min        -0.99967617
exploration/Num Paths          10
exploration/Average Returns    480.1784505335122
evaluation/num steps total     1570000
evaluation/num paths total     3140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9549322306682254
evaluation/Rewards Std         0.054231599404071906
evaluation/Rewards Max         0.9782736040867654
evaluation/Rewards Min         0.4939584902639633
evaluation/Returns Mean        477.4661153341126
evaluation/Returns Std         2.2716702829915074
evaluation/Returns Max         479.9306679779742
evaluation/Returns Min         471.3110309777511
evaluation/ExplReturns Mean    477.4661153341126
evaluation/ExplReturns Std     2.2716702829915074
evaluation/ExplReturns Max     479.9306679779742
evaluation/ExplReturns Min     471.3110309777511
evaluation/Actions Mean        -0.13504495
evaluation/Actions Std         0.5161564
evaluation/Actions Max         0.9995144
evaluation/Actions Min         -0.9993249
evaluation/Num Paths           10
evaluation/Average Returns     477.4661153341126
time/data storing (s)          0.03207153268158436
time/evaluation sampling (s)   112.2745449738577
time/exploration sampling (s)  114.34534614533186
time/logging (s)               0.03053672518581152
time/saving (s)                0.012679653242230415
time/training (s)              9.647122018039227
time/epoch (s)                 236.3423010483384
time/total (s)                 73399.4386265073
Epoch                          313
-----------------------------  ---------------------
2023-08-01 14:21:24.492934 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 314 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4083.9695]
trainer/QF1 Loss               0.027252797
trainer/QF2 Loss               0.021990012
trainer/Policy Loss            -89.65425
trainer/Q1 Predictions Mean    101.867096
trainer/Q1 Predictions Std     2.2381687
trainer/Q1 Predictions Max     103.470245
trainer/Q1 Predictions Min     88.95471
trainer/Q2 Predictions Mean    101.8932
trainer/Q2 Predictions Std     2.250305
trainer/Q2 Predictions Max     103.56869
trainer/Q2 Predictions Min     89.02373
trainer/Q Targets Mean         101.88832
trainer/Q Targets Std          2.2243125
trainer/Q Targets Max          103.460106
trainer/Q Targets Min          89.08854
trainer/Log Pis Mean           12.358958
trainer/Log Pis Std            8.006677
trainer/Log Pis Max            60.69895
trainer/Log Pis Min            -1.9130496
trainer/Policy mu Mean         -0.26980323
trainer/Policy mu Std          1.5894032
trainer/Policy mu Max          8.27993
trainer/Policy mu Min          -6.0861716
trainer/Policy log std Mean    -0.74030226
trainer/Policy log std Std     0.31875375
trainer/Policy log std Max     0.5131691
trainer/Policy log std Min     -2.3276722
trainer/Alpha                  0.001746334251947701
trainer/Alpha Loss             2.279486656188965
exploration/num steps total    1576000
exploration/num paths total    3152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9414563163677733
exploration/Rewards Std        0.057296748519608066
exploration/Rewards Max        0.9698980432271149
exploration/Rewards Min        0.4929607774795291
exploration/Returns Mean       470.7281581838864
exploration/Returns Std        2.049185704895898
exploration/Returns Max        472.9136462200536
exploration/Returns Min        466.8227982049739
exploration/Actions Mean       -0.09166446
exploration/Actions Std        0.6095903
exploration/Actions Max        0.99985564
exploration/Actions Min        -0.99967295
exploration/Num Paths          10
exploration/Average Returns    470.7281581838864
evaluation/num steps total     1575000
evaluation/num paths total     3150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9280348519508036
evaluation/Rewards Std         0.08029804981938292
evaluation/Rewards Max         0.9789091860758381
evaluation/Rewards Min         0.49373361532882165
evaluation/Returns Mean        464.0174259754018
evaluation/Returns Std         24.769472116401083
evaluation/Returns Max         479.0040086993466
evaluation/Returns Min         395.49767380818196
evaluation/ExplReturns Mean    464.0174259754018
evaluation/ExplReturns Std     24.769472116401083
evaluation/ExplReturns Max     479.0040086993466
evaluation/ExplReturns Min     395.49767380818196
evaluation/Actions Mean        -0.07557825
evaluation/Actions Std         0.5480867
evaluation/Actions Max         0.99969864
evaluation/Actions Min         -0.99953246
evaluation/Num Paths           10
evaluation/Average Returns     464.0174259754018
time/data storing (s)          0.032159244641661644
time/evaluation sampling (s)   112.80333100631833
time/exploration sampling (s)  113.96554623078555
time/logging (s)               0.030542644672095776
time/saving (s)                0.012296303175389767
time/training (s)              9.61706763599068
time/epoch (s)                 236.4609430655837
time/total (s)                 73635.90211369097
Epoch                          314
-----------------------------  --------------------
2023-08-01 14:25:19.674482 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 315 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4339.719]
trainer/QF1 Loss               0.025368523
trainer/QF2 Loss               0.026867425
trainer/Policy Loss            -89.465
trainer/Q1 Predictions Mean    101.686676
trainer/Q1 Predictions Std     3.4758086
trainer/Q1 Predictions Max     103.51622
trainer/Q1 Predictions Min     67.49995
trainer/Q2 Predictions Mean    101.74722
trainer/Q2 Predictions Std     3.512548
trainer/Q2 Predictions Max     103.47761
trainer/Q2 Predictions Min     67.49946
trainer/Q Targets Mean         101.70307
trainer/Q Targets Std          3.4685786
trainer/Q Targets Max          103.46361
trainer/Q Targets Min          67.3837
trainer/Log Pis Mean           12.371069
trainer/Log Pis Std            6.667212
trainer/Log Pis Max            34.77789
trainer/Log Pis Min            -2.7934952
trainer/Policy mu Mean         -0.11994738
trainer/Policy mu Std          1.5822855
trainer/Policy mu Max          5.4225755
trainer/Policy mu Min          -4.937185
trainer/Policy log std Mean    -0.75378186
trainer/Policy log std Std     0.34535456
trainer/Policy log std Max     0.09032001
trainer/Policy log std Min     -2.6387057
trainer/Alpha                  0.0017195245018228889
trainer/Alpha Loss             2.3621060848236084
exploration/num steps total    1581000
exploration/num paths total    3162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9480724122892247
exploration/Rewards Std        0.054661698558729654
exploration/Rewards Max        0.979236016355239
exploration/Rewards Min        0.4910384933107137
exploration/Returns Mean       474.0362061446123
exploration/Returns Std        1.2795776743299903
exploration/Returns Max        476.30199687748154
exploration/Returns Min        472.5601616771808
exploration/Actions Mean       0.02326576
exploration/Actions Std        0.579611
exploration/Actions Max        0.99995786
exploration/Actions Min        -0.99994445
exploration/Num Paths          10
exploration/Average Returns    474.0362061446123
evaluation/num steps total     1580000
evaluation/num paths total     3160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9355470668106489
evaluation/Rewards Std         0.08662958674476448
evaluation/Rewards Max         0.9785395851513012
evaluation/Rewards Min         0.4996349713978041
evaluation/Returns Mean        467.77353340532426
evaluation/Returns Std         32.29253094695147
evaluation/Returns Max         480.9807419332003
evaluation/Returns Min         371.0049670958015
evaluation/ExplReturns Mean    467.77353340532426
evaluation/ExplReturns Std     32.29253094695147
evaluation/ExplReturns Max     480.9807419332003
evaluation/ExplReturns Min     371.0049670958015
evaluation/Actions Mean        0.04286697
evaluation/Actions Std         0.54383796
evaluation/Actions Max         0.9999652
evaluation/Actions Min         -0.9999892
evaluation/Num Paths           10
evaluation/Average Returns     467.77353340532426
time/data storing (s)          0.03213881608098745
time/evaluation sampling (s)   112.29440981522202
time/exploration sampling (s)  113.03527234401554
time/logging (s)               0.030925466679036617
time/saving (s)                0.011980288662016392
time/training (s)              9.771896651014686
time/epoch (s)                 235.1766233816743
time/total (s)                 73871.081181176
Epoch                          315
-----------------------------  ---------------------
2023-08-01 14:29:17.676568 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 316 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3679.2646]
trainer/QF1 Loss               0.021792931
trainer/QF2 Loss               0.03108632
trainer/Policy Loss            -90.819786
trainer/Q1 Predictions Mean    102.065155
trainer/Q1 Predictions Std     2.581611
trainer/Q1 Predictions Max     103.66088
trainer/Q1 Predictions Min     78.676216
trainer/Q2 Predictions Mean    102.14211
trainer/Q2 Predictions Std     2.5774841
trainer/Q2 Predictions Max     103.75811
trainer/Q2 Predictions Min     79.17987
trainer/Q Targets Mean         102.08759
trainer/Q Targets Std          2.5949273
trainer/Q Targets Max          103.916504
trainer/Q Targets Min          78.452805
trainer/Log Pis Mean           11.400447
trainer/Log Pis Std            7.9343457
trainer/Log Pis Max            78.795715
trainer/Log Pis Min            -1.9091985
trainer/Policy mu Mean         -0.25879812
trainer/Policy mu Std          1.5009838
trainer/Policy mu Max          6.6451163
trainer/Policy mu Min          -6.998721
trainer/Policy log std Mean    -0.7617771
trainer/Policy log std Std     0.33168328
trainer/Policy log std Max     0.29592532
trainer/Policy log std Min     -2.3508246
trainer/Alpha                  0.0017383343074470758
trainer/Alpha Loss             -3.8097665309906006
exploration/num steps total    1586000
exploration/num paths total    3172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.880433099784685
exploration/Rewards Std        0.12379916617644995
exploration/Rewards Max        0.9789257688225679
exploration/Rewards Min        0.49293911913540844
exploration/Returns Mean       440.2165498923426
exploration/Returns Std        34.18350659511646
exploration/Returns Max        481.1337057066643
exploration/Returns Min        394.1859832604438
exploration/Actions Mean       -0.019139199
exploration/Actions Std        0.6093824
exploration/Actions Max        0.99999386
exploration/Actions Min        -0.9999845
exploration/Num Paths          10
exploration/Average Returns    440.2165498923426
evaluation/num steps total     1585000
evaluation/num paths total     3170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.939788330974305
evaluation/Rewards Std         0.08695677807389379
evaluation/Rewards Max         0.9745352334210706
evaluation/Rewards Min         0.49321957232370717
evaluation/Returns Mean        469.89416548715246
evaluation/Returns Std         33.06121251220145
evaluation/Returns Max         481.4891251848942
evaluation/Returns Min         370.7209037466647
evaluation/ExplReturns Mean    469.89416548715246
evaluation/ExplReturns Std     33.06121251220145
evaluation/ExplReturns Max     481.4891251848942
evaluation/ExplReturns Min     370.7209037466647
evaluation/Actions Mean        0.020115567
evaluation/Actions Std         0.4905782
evaluation/Actions Max         0.9996479
evaluation/Actions Min         -0.99913096
evaluation/Num Paths           10
evaluation/Average Returns     469.89416548715246
time/data storing (s)          0.032245345413684845
time/evaluation sampling (s)   114.20770326908678
time/exploration sampling (s)  114.07242557499558
time/logging (s)               0.03035261109471321
time/saving (s)                0.011312808841466904
time/training (s)              9.642130659893155
time/epoch (s)                 237.99617026932538
time/total (s)                 74109.07985375915
Epoch                          316
-----------------------------  ---------------------
2023-08-01 14:33:10.442477 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 317 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3672.4639]
trainer/QF1 Loss               0.031892374
trainer/QF2 Loss               0.022804424
trainer/Policy Loss            -90.06271
trainer/Q1 Predictions Mean    102.27817
trainer/Q1 Predictions Std     2.4864373
trainer/Q1 Predictions Max     103.703606
trainer/Q1 Predictions Min     79.57922
trainer/Q2 Predictions Mean    102.15821
trainer/Q2 Predictions Std     2.4800425
trainer/Q2 Predictions Max     103.579056
trainer/Q2 Predictions Min     79.51006
trainer/Q Targets Mean         102.20497
trainer/Q Targets Std          2.5095723
trainer/Q Targets Max          103.68717
trainer/Q Targets Min          79.341965
trainer/Log Pis Mean           12.26601
trainer/Log Pis Std            7.10613
trainer/Log Pis Max            41.27458
trainer/Log Pis Min            -3.608028
trainer/Policy mu Mean         -0.4120222
trainer/Policy mu Std          1.5274954
trainer/Policy mu Max          4.7370543
trainer/Policy mu Min          -5.598012
trainer/Policy log std Mean    -0.7782426
trainer/Policy log std Std     0.35214582
trainer/Policy log std Max     0.18752751
trainer/Policy log std Min     -2.62951
trainer/Alpha                  0.001587999053299427
trainer/Alpha Loss             1.71463942527771
exploration/num steps total    1591000
exploration/num paths total    3182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9589426169974963
exploration/Rewards Std        0.05423393986480631
exploration/Rewards Max        0.9796463180551123
exploration/Rewards Min        0.49114141857370347
exploration/Returns Mean       479.4713084987481
exploration/Returns Std        1.0464198458508744
exploration/Returns Max        481.4929155636961
exploration/Returns Min        477.8857722288314
exploration/Actions Mean       -0.00861592
exploration/Actions Std        0.5847848
exploration/Actions Max        0.9999105
exploration/Actions Min        -0.99990016
exploration/Num Paths          10
exploration/Average Returns    479.4713084987481
evaluation/num steps total     1590000
evaluation/num paths total     3180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9580875774742678
evaluation/Rewards Std         0.05363080123355588
evaluation/Rewards Max         0.9786905545211679
evaluation/Rewards Min         0.5063643167782831
evaluation/Returns Mean        479.0437887371339
evaluation/Returns Std         0.8651077632268965
evaluation/Returns Max         480.0813781110458
evaluation/Returns Min         477.58481685904906
evaluation/ExplReturns Mean    479.0437887371339
evaluation/ExplReturns Std     0.8651077632268965
evaluation/ExplReturns Max     480.0813781110458
evaluation/ExplReturns Min     477.58481685904906
evaluation/Actions Mean        -0.00651985
evaluation/Actions Std         0.51974565
evaluation/Actions Max         0.99933857
evaluation/Actions Min         -0.99945676
evaluation/Num Paths           10
evaluation/Average Returns     479.0437887371339
time/data storing (s)          0.03211197257041931
time/evaluation sampling (s)   111.47409053053707
time/exploration sampling (s)  112.01667298004031
time/logging (s)               0.030176235362887383
time/saving (s)                0.010697447694838047
time/training (s)              9.19667531736195
time/epoch (s)                 232.76042448356748
time/total (s)                 74341.8428080501
Epoch                          317
-----------------------------  --------------------
2023-08-01 14:37:04.239863 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 318 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3728.5193]
trainer/QF1 Loss               0.032448884
trainer/QF2 Loss               0.024166018
trainer/Policy Loss            -89.00203
trainer/Q1 Predictions Mean    102.18302
trainer/Q1 Predictions Std     2.7936628
trainer/Q1 Predictions Max     103.79797
trainer/Q1 Predictions Min     73.831764
trainer/Q2 Predictions Mean    102.17502
trainer/Q2 Predictions Std     2.8935366
trainer/Q2 Predictions Max     103.85078
trainer/Q2 Predictions Min     71.93264
trainer/Q Targets Mean         102.22247
trainer/Q Targets Std          2.8859105
trainer/Q Targets Max          103.856094
trainer/Q Targets Min          72.09342
trainer/Log Pis Mean           13.29632
trainer/Log Pis Std            8.400098
trainer/Log Pis Max            45.021362
trainer/Log Pis Min            -2.5305715
trainer/Policy mu Mean         0.03231037
trainer/Policy mu Std          1.6480299
trainer/Policy mu Max          5.567079
trainer/Policy mu Min          -6.3587403
trainer/Policy log std Mean    -0.7748716
trainer/Policy log std Std     0.3301053
trainer/Policy log std Max     0.04994288
trainer/Policy log std Min     -2.5144987
trainer/Alpha                  0.0015511944657191634
trainer/Alpha Loss             8.386024475097656
exploration/num steps total    1596000
exploration/num paths total    3192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9617783542739984
exploration/Rewards Std        0.05287622867417091
exploration/Rewards Max        0.9795921198171176
exploration/Rewards Min        0.49035469883594857
exploration/Returns Mean       480.88917713699885
exploration/Returns Std        1.4964582357840155
exploration/Returns Max        482.3059353638706
exploration/Returns Min        477.1782815739639
exploration/Actions Mean       0.056901336
exploration/Actions Std        0.5921959
exploration/Actions Max        0.99998057
exploration/Actions Min        -0.9999965
exploration/Num Paths          10
exploration/Average Returns    480.88917713699885
evaluation/num steps total     1595000
evaluation/num paths total     3190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9624104265854845
evaluation/Rewards Std         0.05237176278533461
evaluation/Rewards Max         0.979931870885379
evaluation/Rewards Min         0.49590435949058087
evaluation/Returns Mean        481.20521329274226
evaluation/Returns Std         1.1000726767500264
evaluation/Returns Max         482.39954772563266
evaluation/Returns Min         479.3366630555457
evaluation/ExplReturns Mean    481.20521329274226
evaluation/ExplReturns Std     1.1000726767500264
evaluation/ExplReturns Max     482.39954772563266
evaluation/ExplReturns Min     479.3366630555457
evaluation/Actions Mean        0.023606893
evaluation/Actions Std         0.51066047
evaluation/Actions Max         0.9991992
evaluation/Actions Min         -0.99958
evaluation/Num Paths           10
evaluation/Average Returns     481.20521329274226
time/data storing (s)          0.03206165228039026
time/evaluation sampling (s)   111.23014179803431
time/exploration sampling (s)  112.86374416202307
time/logging (s)               0.03030863031744957
time/saving (s)                0.012665623798966408
time/training (s)              9.623167756944895
time/epoch (s)                 233.79208962339908
time/total (s)                 74575.6373293167
Epoch                          318
-----------------------------  ---------------------
2023-08-01 14:40:55.842983 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 319 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3758.9414]
trainer/QF1 Loss               0.040496472
trainer/QF2 Loss               0.04941357
trainer/Policy Loss            -91.068565
trainer/Q1 Predictions Mean    102.23068
trainer/Q1 Predictions Std     3.4635892
trainer/Q1 Predictions Max     104.58692
trainer/Q1 Predictions Min     69.911545
trainer/Q2 Predictions Mean    102.248764
trainer/Q2 Predictions Std     3.4696343
trainer/Q2 Predictions Max     104.55624
trainer/Q2 Predictions Min     69.59066
trainer/Q Targets Mean         102.08457
trainer/Q Targets Std          3.5048184
trainer/Q Targets Max          104.3697
trainer/Q Targets Min          69.30264
trainer/Log Pis Mean           11.28191
trainer/Log Pis Std            8.234004
trainer/Log Pis Max            44.392628
trainer/Log Pis Min            -4.213583
trainer/Policy mu Mean         -0.10028711
trainer/Policy mu Std          1.5395314
trainer/Policy mu Max          5.22282
trainer/Policy mu Min          -8.374286
trainer/Policy log std Mean    -0.7940841
trainer/Policy log std Std     0.35323808
trainer/Policy log std Max     0.3545114
trainer/Policy log std Min     -2.3411467
trainer/Alpha                  0.0016181099927052855
trainer/Alpha Loss             -4.614776611328125
exploration/num steps total    1601000
exploration/num paths total    3202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9544879000746005
exploration/Rewards Std        0.050993974503344974
exploration/Rewards Max        0.9792925336660325
exploration/Rewards Min        0.4978148068591497
exploration/Returns Mean       477.2439500373001
exploration/Returns Std        0.5149563077202405
exploration/Returns Max        478.00838213765263
exploration/Returns Min        476.34531329022946
exploration/Actions Mean       0.018159583
exploration/Actions Std        0.59586924
exploration/Actions Max        0.9998119
exploration/Actions Min        -0.9999413
exploration/Num Paths          10
exploration/Average Returns    477.2439500373001
evaluation/num steps total     1600000
evaluation/num paths total     3200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9554428989633974
evaluation/Rewards Std         0.050544807374960185
evaluation/Rewards Max         0.9793345715656866
evaluation/Rewards Min         0.499093561728154
evaluation/Returns Mean        477.72144948169864
evaluation/Returns Std         0.5278875451923037
evaluation/Returns Max         478.3162942346694
evaluation/Returns Min         476.49274779650796
evaluation/ExplReturns Mean    477.72144948169864
evaluation/ExplReturns Std     0.5278875451923037
evaluation/ExplReturns Max     478.3162942346694
evaluation/ExplReturns Min     476.49274779650796
evaluation/Actions Mean        0.012813183
evaluation/Actions Std         0.51229465
evaluation/Actions Max         0.9975465
evaluation/Actions Min         -0.9989419
evaluation/Num Paths           10
evaluation/Average Returns     477.72144948169864
time/data storing (s)          0.03218466509133577
time/evaluation sampling (s)   110.5392409004271
time/exploration sampling (s)  111.35811381414533
time/logging (s)               0.030331204645335674
time/saving (s)                0.011670593172311783
time/training (s)              9.626193860545754
time/epoch (s)                 231.59773503802717
time/total (s)                 74807.23763970006
Epoch                          319
-----------------------------  ---------------------
2023-08-01 14:44:47.128672 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 320 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3527.714]
trainer/QF1 Loss               0.02586271
trainer/QF2 Loss               0.028180517
trainer/Policy Loss            -90.998795
trainer/Q1 Predictions Mean    102.24314
trainer/Q1 Predictions Std     2.9580758
trainer/Q1 Predictions Max     104.66832
trainer/Q1 Predictions Min     68.886566
trainer/Q2 Predictions Mean    102.24925
trainer/Q2 Predictions Std     2.9947014
trainer/Q2 Predictions Max     104.6779
trainer/Q2 Predictions Min     68.207184
trainer/Q Targets Mean         102.27661
trainer/Q Targets Std          2.9909897
trainer/Q Targets Max          104.76554
trainer/Q Targets Min          68.15869
trainer/Log Pis Mean           11.358922
trainer/Log Pis Std            7.553068
trainer/Log Pis Max            50.75922
trainer/Log Pis Min            -1.7407478
trainer/Policy mu Mean         -0.2853314
trainer/Policy mu Std          1.4747669
trainer/Policy mu Max          7.994704
trainer/Policy mu Min          -5.530216
trainer/Policy log std Mean    -0.8019832
trainer/Policy log std Std     0.3594964
trainer/Policy log std Max     0.2316303
trainer/Policy log std Min     -2.1852982
trainer/Alpha                  0.0016316238325089216
trainer/Alpha Loss             -4.11460018157959
exploration/num steps total    1606000
exploration/num paths total    3212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.960604052438711
exploration/Rewards Std        0.04853022825580958
exploration/Rewards Max        0.9794259039454056
exploration/Rewards Min        0.4976864553061776
exploration/Returns Mean       480.3020262193553
exploration/Returns Std        0.4719494939355568
exploration/Returns Max        481.1057483754137
exploration/Returns Min        479.290318944436
exploration/Actions Mean       0.0072659673
exploration/Actions Std        0.5908969
exploration/Actions Max        0.99989694
exploration/Actions Min        -0.99993646
exploration/Num Paths          10
exploration/Average Returns    480.3020262193553
evaluation/num steps total     1605000
evaluation/num paths total     3210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9606496113664144
evaluation/Rewards Std         0.04839142562692611
evaluation/Rewards Max         0.9786331204758293
evaluation/Rewards Min         0.49213177615340564
evaluation/Returns Mean        480.3248056832073
evaluation/Returns Std         0.523933209328886
evaluation/Returns Max         481.0348714712039
evaluation/Returns Min         479.419544586291
evaluation/ExplReturns Mean    480.3248056832073
evaluation/ExplReturns Std     0.523933209328886
evaluation/ExplReturns Max     481.0348714712039
evaluation/ExplReturns Min     479.419544586291
evaluation/Actions Mean        0.011291781
evaluation/Actions Std         0.50574374
evaluation/Actions Max         0.99921525
evaluation/Actions Min         -0.99943
evaluation/Num Paths           10
evaluation/Average Returns     480.3248056832073
time/data storing (s)          0.0318336421623826
time/evaluation sampling (s)   110.13194179628044
time/exploration sampling (s)  111.40706207416952
time/logging (s)               0.030375661328434944
time/saving (s)                0.012308563105762005
time/training (s)              9.666966499760747
time/epoch (s)                 231.2804882368073
time/total (s)                 75038.52053706907
Epoch                          320
-----------------------------  ---------------------
2023-08-01 14:48:42.133092 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 321 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4269.5146]
trainer/QF1 Loss               0.03416715
trainer/QF2 Loss               0.034899008
trainer/Policy Loss            -90.5918
trainer/Q1 Predictions Mean    102.33043
trainer/Q1 Predictions Std     3.1711173
trainer/Q1 Predictions Max     104.68707
trainer/Q1 Predictions Min     70.46807
trainer/Q2 Predictions Mean    102.27806
trainer/Q2 Predictions Std     3.1825278
trainer/Q2 Predictions Max     104.58382
trainer/Q2 Predictions Min     70.00566
trainer/Q Targets Mean         102.26551
trainer/Q Targets Std          3.1535742
trainer/Q Targets Max          104.55065
trainer/Q Targets Min          70.508514
trainer/Log Pis Mean           11.811962
trainer/Log Pis Std            8.564895
trainer/Log Pis Max            66.181206
trainer/Log Pis Min            -8.601233
trainer/Policy mu Mean         0.051000293
trainer/Policy mu Std          1.6040107
trainer/Policy mu Max          11.075407
trainer/Policy mu Min          -10.311064
trainer/Policy log std Mean    -0.76016927
trainer/Policy log std Std     0.33789364
trainer/Policy log std Max     1.2495669
trainer/Policy log std Min     -2.1762607
trainer/Alpha                  0.0016688009491190314
trainer/Alpha Loss             -1.2026437520980835
exploration/num steps total    1611000
exploration/num paths total    3222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9429988478174537
exploration/Rewards Std        0.08382463663084337
exploration/Rewards Max        0.9794967004637201
exploration/Rewards Min        0.5049598307821386
exploration/Returns Mean       471.49942390872667
exploration/Returns Std        19.73247642798615
exploration/Returns Max        481.9376866834772
exploration/Returns Min        422.14315884591275
exploration/Actions Mean       0.0033455943
exploration/Actions Std        0.61312574
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999941
exploration/Num Paths          10
exploration/Average Returns    471.49942390872667
evaluation/num steps total     1610000
evaluation/num paths total     3220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609772154382452
evaluation/Rewards Std         0.05288644425260983
evaluation/Rewards Max         0.9775108423444734
evaluation/Rewards Min         0.49577086702467127
evaluation/Returns Mean        480.4886077191225
evaluation/Returns Std         1.8470967334121737
evaluation/Returns Max         482.14765072049664
evaluation/Returns Min         477.1772436995797
evaluation/ExplReturns Mean    480.4886077191225
evaluation/ExplReturns Std     1.8470967334121737
evaluation/ExplReturns Max     482.14765072049664
evaluation/ExplReturns Min     477.1772436995797
evaluation/Actions Mean        -0.036346383
evaluation/Actions Std         0.51603884
evaluation/Actions Max         0.99918795
evaluation/Actions Min         -0.99935114
evaluation/Num Paths           10
evaluation/Average Returns     480.4886077191225
time/data storing (s)          0.03175346739590168
time/evaluation sampling (s)   111.98395709507167
time/exploration sampling (s)  113.29876689612865
time/logging (s)               0.03060158248990774
time/saving (s)                0.012209565378725529
time/training (s)              9.642044538632035
time/epoch (s)                 234.9993331450969
time/total (s)                 75273.52235933952
Epoch                          321
-----------------------------  ---------------------
2023-08-01 14:52:33.978726 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 322 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4311.329]
trainer/QF1 Loss               0.023225447
trainer/QF2 Loss               0.015423846
trainer/Policy Loss            -92.02688
trainer/Q1 Predictions Mean    102.69101
trainer/Q1 Predictions Std     1.8329318
trainer/Q1 Predictions Max     105.501656
trainer/Q1 Predictions Min     92.13124
trainer/Q2 Predictions Mean    102.66234
trainer/Q2 Predictions Std     1.8475236
trainer/Q2 Predictions Max     105.369484
trainer/Q2 Predictions Min     91.99074
trainer/Q Targets Mean         102.68193
trainer/Q Targets Std          1.8608468
trainer/Q Targets Max          105.49493
trainer/Q Targets Min          92.07314
trainer/Log Pis Mean           10.776177
trainer/Log Pis Std            7.4198976
trainer/Log Pis Max            37.62799
trainer/Log Pis Min            -5.001768
trainer/Policy mu Mean         0.1197027
trainer/Policy mu Std          1.5210882
trainer/Policy mu Max          5.2855053
trainer/Policy mu Min          -7.636377
trainer/Policy log std Mean    -0.76752406
trainer/Policy log std Std     0.3395974
trainer/Policy log std Max     0.39148968
trainer/Policy log std Min     -2.340993
trainer/Alpha                  0.0017462460091337562
trainer/Alpha Loss             -7.771402359008789
exploration/num steps total    1616000
exploration/num paths total    3232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9560368018909258
exploration/Rewards Std        0.05408429187290628
exploration/Rewards Max        0.9786317357185086
exploration/Rewards Min        0.4927942049510501
exploration/Returns Mean       478.01840094546276
exploration/Returns Std        1.018060164985021
exploration/Returns Max        479.39424305264964
exploration/Returns Min        476.3921699297728
exploration/Actions Mean       -0.017027786
exploration/Actions Std        0.58786964
exploration/Actions Max        0.9999912
exploration/Actions Min        -0.9999414
exploration/Num Paths          10
exploration/Average Returns    478.01840094546276
evaluation/num steps total     1615000
evaluation/num paths total     3230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9568076205552934
evaluation/Rewards Std         0.051911430937233397
evaluation/Rewards Max         0.9782326672875231
evaluation/Rewards Min         0.4941895981910618
evaluation/Returns Mean        478.4038102776466
evaluation/Returns Std         0.6164492763770805
evaluation/Returns Max         479.9356766561155
evaluation/Returns Min         477.7614578047253
evaluation/ExplReturns Mean    478.4038102776466
evaluation/ExplReturns Std     0.6164492763770805
evaluation/ExplReturns Max     479.9356766561155
evaluation/ExplReturns Min     477.7614578047253
evaluation/Actions Mean        -0.022763193
evaluation/Actions Std         0.47017002
evaluation/Actions Max         0.99974847
evaluation/Actions Min         -0.9990105
evaluation/Num Paths           10
evaluation/Average Returns     478.4038102776466
time/data storing (s)          0.032205686904489994
time/evaluation sampling (s)   111.20324021857232
time/exploration sampling (s)  111.17790875118226
time/logging (s)               0.030393125489354134
time/saving (s)                0.010234689339995384
time/training (s)              9.385921705514193
time/epoch (s)                 231.8399041770026
time/total (s)                 75505.36492945347
Epoch                          322
-----------------------------  ---------------------
2023-08-01 14:56:28.415480 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 323 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4323.563]
trainer/QF1 Loss               0.019474205
trainer/QF2 Loss               0.02141387
trainer/Policy Loss            -91.90127
trainer/Q1 Predictions Mean    102.670456
trainer/Q1 Predictions Std     3.1657457
trainer/Q1 Predictions Max     105.69927
trainer/Q1 Predictions Min     71.94907
trainer/Q2 Predictions Mean    102.672485
trainer/Q2 Predictions Std     3.1549513
trainer/Q2 Predictions Max     105.62969
trainer/Q2 Predictions Min     71.84577
trainer/Q Targets Mean         102.66696
trainer/Q Targets Std          3.2214177
trainer/Q Targets Max          105.70564
trainer/Q Targets Min          70.91311
trainer/Log Pis Mean           10.852208
trainer/Log Pis Std            7.0298686
trainer/Log Pis Max            48.89267
trainer/Log Pis Min            -6.7445793
trainer/Policy mu Mean         0.19968338
trainer/Policy mu Std          1.5040772
trainer/Policy mu Max          8.411524
trainer/Policy mu Min          -6.5009794
trainer/Policy log std Mean    -0.7316249
trainer/Policy log std Std     0.32272604
trainer/Policy log std Max     0.6153592
trainer/Policy log std Min     -2.0662816
trainer/Alpha                  0.0018487987108528614
trainer/Alpha Loss             -7.2230939865112305
exploration/num steps total    1621000
exploration/num paths total    3242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9586640267238905
exploration/Rewards Std        0.053627863339526835
exploration/Rewards Max        0.9782351593450591
exploration/Rewards Min        0.4948301527465935
exploration/Returns Mean       479.3320133619453
exploration/Returns Std        0.891472792058183
exploration/Returns Max        480.8131545163958
exploration/Returns Min        477.88208034593964
exploration/Actions Mean       -0.028640598
exploration/Actions Std        0.57392955
exploration/Actions Max        0.99962527
exploration/Actions Min        -0.99982923
exploration/Num Paths          10
exploration/Average Returns    479.3320133619453
evaluation/num steps total     1620000
evaluation/num paths total     3240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9605098284880332
evaluation/Rewards Std         0.052678791874949026
evaluation/Rewards Max         0.9796788437353752
evaluation/Rewards Min         0.48952217807374243
evaluation/Returns Mean        480.2549142440168
evaluation/Returns Std         1.0741316901271811
evaluation/Returns Max         481.8653039516862
evaluation/Returns Min         478.01873677634444
evaluation/ExplReturns Mean    480.2549142440168
evaluation/ExplReturns Std     1.0741316901271811
evaluation/ExplReturns Max     481.8653039516862
evaluation/ExplReturns Min     478.01873677634444
evaluation/Actions Mean        -0.01622499
evaluation/Actions Std         0.4590718
evaluation/Actions Max         0.9990459
evaluation/Actions Min         -0.9987621
evaluation/Num Paths           10
evaluation/Average Returns     480.2549142440168
time/data storing (s)          0.03225324582308531
time/evaluation sampling (s)   112.29208985157311
time/exploration sampling (s)  112.45123590994626
time/logging (s)               0.03058066964149475
time/saving (s)                0.012587150558829308
time/training (s)              9.612770421430469
time/epoch (s)                 234.43151724897325
time/total (s)                 75739.79891470075
Epoch                          323
-----------------------------  ---------------------
2023-08-01 15:00:21.056469 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 324 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4282.815]
trainer/QF1 Loss               0.035591193
trainer/QF2 Loss               0.031409632
trainer/Policy Loss            -89.852455
trainer/Q1 Predictions Mean    102.707596
trainer/Q1 Predictions Std     2.930662
trainer/Q1 Predictions Max     105.78562
trainer/Q1 Predictions Min     73.841225
trainer/Q2 Predictions Mean    102.70076
trainer/Q2 Predictions Std     2.8857038
trainer/Q2 Predictions Max     105.73119
trainer/Q2 Predictions Min     74.55495
trainer/Q Targets Mean         102.61601
trainer/Q Targets Std          2.8984246
trainer/Q Targets Max          105.64736
trainer/Q Targets Min          73.85437
trainer/Log Pis Mean           12.9813795
trainer/Log Pis Std            7.5945935
trainer/Log Pis Max            44.41511
trainer/Log Pis Min            -2.868434
trainer/Policy mu Mean         0.3863624
trainer/Policy mu Std          1.5904428
trainer/Policy mu Max          8.71845
trainer/Policy mu Min          -5.9829483
trainer/Policy log std Mean    -0.7399106
trainer/Policy log std Std     0.3159778
trainer/Policy log std Max     0.6010282
trainer/Policy log std Min     -2.2709618
trainer/Alpha                  0.00191974057815969
trainer/Alpha Loss             6.139113426208496
exploration/num steps total    1626000
exploration/num paths total    3252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9473772418689277
exploration/Rewards Std        0.07166341811184355
exploration/Rewards Max        0.9793481364384848
exploration/Rewards Min        0.49575759700667166
exploration/Returns Mean       473.688620934464
exploration/Returns Std        11.770251631266227
exploration/Returns Max        480.8815162179437
exploration/Returns Min        441.1298116529938
exploration/Actions Mean       0.030445341
exploration/Actions Std        0.5329544
exploration/Actions Max        0.9998541
exploration/Actions Min        -0.9997495
exploration/Num Paths          10
exploration/Average Returns    473.688620934464
evaluation/num steps total     1625000
evaluation/num paths total     3250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9575862717022299
evaluation/Rewards Std         0.06207790147968006
evaluation/Rewards Max         0.9772700585636767
evaluation/Rewards Min         0.4935174989852943
evaluation/Returns Mean        478.7931358511149
evaluation/Returns Std         4.281188267345725
evaluation/Returns Max         481.4699056169761
evaluation/Returns Min         467.62482375485257
evaluation/ExplReturns Mean    478.7931358511149
evaluation/ExplReturns Std     4.281188267345725
evaluation/ExplReturns Max     481.4699056169761
evaluation/ExplReturns Min     467.62482375485257
evaluation/Actions Mean        0.014154777
evaluation/Actions Std         0.41713884
evaluation/Actions Max         0.9986882
evaluation/Actions Min         -0.99881005
evaluation/Num Paths           10
evaluation/Average Returns     478.7931358511149
time/data storing (s)          0.032093595713377
time/evaluation sampling (s)   111.12475652247667
time/exploration sampling (s)  111.79414956923574
time/logging (s)               0.030552872456610203
time/saving (s)                0.011298411525785923
time/training (s)              9.642522539943457
time/epoch (s)                 232.63537351135164
time/total (s)                 75972.43698741682
Epoch                          324
-----------------------------  --------------------
2023-08-01 15:04:20.579252 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 325 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4259.628]
trainer/QF1 Loss               0.023553926
trainer/QF2 Loss               0.020124622
trainer/Policy Loss            -91.884796
trainer/Q1 Predictions Mean    102.83154
trainer/Q1 Predictions Std     2.1670568
trainer/Q1 Predictions Max     105.84648
trainer/Q1 Predictions Min     93.96674
trainer/Q2 Predictions Mean    102.79976
trainer/Q2 Predictions Std     2.1789134
trainer/Q2 Predictions Max     105.693596
trainer/Q2 Predictions Min     92.97785
trainer/Q Targets Mean         102.8231
trainer/Q Targets Std          2.192004
trainer/Q Targets Max          105.847206
trainer/Q Targets Min          93.53194
trainer/Log Pis Mean           11.050499
trainer/Log Pis Std            6.703676
trainer/Log Pis Max            32.226456
trainer/Log Pis Min            -2.701654
trainer/Policy mu Mean         0.22573698
trainer/Policy mu Std          1.50673
trainer/Policy mu Max          5.543218
trainer/Policy mu Min          -4.704337
trainer/Policy log std Mean    -0.78196883
trainer/Policy log std Std     0.321826
trainer/Policy log std Max     -8.845329e-05
trainer/Policy log std Min     -2.2233934
trainer/Alpha                  0.0017174440436065197
trainer/Alpha Loss             -6.045161247253418
exploration/num steps total    1631000
exploration/num paths total    3262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9260745060783436
exploration/Rewards Std        0.08548868868219962
exploration/Rewards Max        0.9789813866792682
exploration/Rewards Min        0.49875668417178
exploration/Returns Mean       463.0372530391718
exploration/Returns Std        7.4286715763247875
exploration/Returns Max        472.29655165975106
exploration/Returns Min        451.840842316595
exploration/Actions Mean       0.1353455
exploration/Actions Std        0.63592136
exploration/Actions Max        0.99999064
exploration/Actions Min        -0.99990916
exploration/Num Paths          10
exploration/Average Returns    463.0372530391718
evaluation/num steps total     1630000
evaluation/num paths total     3260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9516250659556285
evaluation/Rewards Std         0.06630785132592987
evaluation/Rewards Max         0.9773083353414962
evaluation/Rewards Min         0.4964389383034535
evaluation/Returns Mean        475.81253297781416
evaluation/Returns Std         1.2861619119052867
evaluation/Returns Max         477.084588389747
evaluation/Returns Min         472.7632192464679
evaluation/ExplReturns Mean    475.81253297781416
evaluation/ExplReturns Std     1.2861619119052867
evaluation/ExplReturns Max     477.084588389747
evaluation/ExplReturns Min     472.7632192464679
evaluation/Actions Mean        0.21348217
evaluation/Actions Std         0.52643573
evaluation/Actions Max         0.99894387
evaluation/Actions Min         -0.9998517
evaluation/Num Paths           10
evaluation/Average Returns     475.81253297781416
time/data storing (s)          0.03220526035875082
time/evaluation sampling (s)   116.13639358337969
time/exploration sampling (s)  113.70359188877046
time/logging (s)               0.03039154503494501
time/saving (s)                0.011583471670746803
time/training (s)              9.602902689017355
time/epoch (s)                 239.51706843823195
time/total (s)                 76211.95671698451
Epoch                          325
-----------------------------  ---------------------
2023-08-01 15:08:19.873272 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 326 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4138.155]
trainer/QF1 Loss               0.048722412
trainer/QF2 Loss               0.053759973
trainer/Policy Loss            -90.43378
trainer/Q1 Predictions Mean    102.66791
trainer/Q1 Predictions Std     4.0681534
trainer/Q1 Predictions Max     105.904045
trainer/Q1 Predictions Min     67.0902
trainer/Q2 Predictions Mean    102.67734
trainer/Q2 Predictions Std     4.0753584
trainer/Q2 Predictions Max     105.80882
trainer/Q2 Predictions Min     66.95989
trainer/Q Targets Mean         102.56649
trainer/Q Targets Std          4.1440077
trainer/Q Targets Max          105.77907
trainer/Q Targets Min          66.72626
trainer/Log Pis Mean           12.315342
trainer/Log Pis Std            7.611997
trainer/Log Pis Max            44.92401
trainer/Log Pis Min            -3.4206767
trainer/Policy mu Mean         0.22257769
trainer/Policy mu Std          1.5894479
trainer/Policy mu Max          8.8271055
trainer/Policy mu Min          -7.1960235
trainer/Policy log std Mean    -0.7371397
trainer/Policy log std Std     0.3539576
trainer/Policy log std Max     0.7508187
trainer/Policy log std Min     -2.2962413
trainer/Alpha                  0.0016484899679198861
trainer/Alpha Loss             2.020730972290039
exploration/num steps total    1636000
exploration/num paths total    3272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9473686893473259
exploration/Rewards Std        0.06694906269978755
exploration/Rewards Max        0.9789974583599815
exploration/Rewards Min        0.48530428051778873
exploration/Returns Mean       473.68434467366285
exploration/Returns Std        2.8276125298910455
exploration/Returns Max        477.95378645429616
exploration/Returns Min        468.84325635584474
exploration/Actions Mean       0.17175676
exploration/Actions Std        0.63423026
exploration/Actions Max        0.9999508
exploration/Actions Min        -0.99995553
exploration/Num Paths          10
exploration/Average Returns    473.68434467366285
evaluation/num steps total     1635000
evaluation/num paths total     3270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9505224717241261
evaluation/Rewards Std         0.05839443813596726
evaluation/Rewards Max         0.9768888759172913
evaluation/Rewards Min         0.4928460870100099
evaluation/Returns Mean        475.26123586206296
evaluation/Returns Std         1.6352385598066923
evaluation/Returns Max         478.1534239160526
evaluation/Returns Min         472.29474544132165
evaluation/ExplReturns Mean    475.26123586206296
evaluation/ExplReturns Std     1.6352385598066923
evaluation/ExplReturns Max     478.1534239160526
evaluation/ExplReturns Min     472.29474544132165
evaluation/Actions Mean        0.21808538
evaluation/Actions Std         0.5689759
evaluation/Actions Max         0.99967074
evaluation/Actions Min         -0.99992955
evaluation/Num Paths           10
evaluation/Average Returns     475.26123586206296
time/data storing (s)          0.03224385157227516
time/evaluation sampling (s)   115.1357101611793
time/exploration sampling (s)  114.5305226482451
time/logging (s)               0.03054593689739704
time/saving (s)                0.010297317989170551
time/training (s)              9.5494518103078
time/epoch (s)                 239.28877172619104
time/total (s)                 76451.24801145494
Epoch                          326
-----------------------------  ---------------------
2023-08-01 15:12:14.378257 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 327 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4360.0405]
trainer/QF1 Loss               0.02457988
trainer/QF2 Loss               0.02982254
trainer/Policy Loss            -91.09384
trainer/Q1 Predictions Mean    103.058876
trainer/Q1 Predictions Std     1.7657796
trainer/Q1 Predictions Max     105.7728
trainer/Q1 Predictions Min     93.912186
trainer/Q2 Predictions Mean    103.0324
trainer/Q2 Predictions Std     1.7580914
trainer/Q2 Predictions Max     105.72378
trainer/Q2 Predictions Min     93.704926
trainer/Q Targets Mean         103.03996
trainer/Q Targets Std          1.7648842
trainer/Q Targets Max          105.723526
trainer/Q Targets Min          93.681046
trainer/Log Pis Mean           12.037164
trainer/Log Pis Std            7.793097
trainer/Log Pis Max            37.329166
trainer/Log Pis Min            -6.856367
trainer/Policy mu Mean         0.13405186
trainer/Policy mu Std          1.5566703
trainer/Policy mu Max          5.314289
trainer/Policy mu Min          -6.1509714
trainer/Policy log std Mean    -0.79000765
trainer/Policy log std Std     0.35143456
trainer/Policy log std Max     0.2839045
trainer/Policy log std Min     -2.1844902
trainer/Alpha                  0.001556115923449397
trainer/Alpha Loss             0.24029040336608887
exploration/num steps total    1641000
exploration/num paths total    3282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9517431453020192
exploration/Rewards Std        0.05814278702133684
exploration/Rewards Max        0.9790546398101526
exploration/Rewards Min        0.4944721904560956
exploration/Returns Mean       475.8715726510096
exploration/Returns Std        1.7344655537008977
exploration/Returns Max        478.5627795120265
exploration/Returns Min        473.7849077471126
exploration/Actions Mean       0.08678997
exploration/Actions Std        0.61325806
exploration/Actions Max        0.999994
exploration/Actions Min        -0.9999997
exploration/Num Paths          10
exploration/Average Returns    475.8715726510096
evaluation/num steps total     1640000
evaluation/num paths total     3280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9481560282069249
evaluation/Rewards Std         0.06072323883616166
evaluation/Rewards Max         0.9793372186880577
evaluation/Rewards Min         0.4923637741515525
evaluation/Returns Mean        474.0780141034626
evaluation/Returns Std         1.7555430033110013
evaluation/Returns Max         477.4193709789727
evaluation/Returns Min         471.4596350714997
evaluation/ExplReturns Mean    474.0780141034626
evaluation/ExplReturns Std     1.7555430033110013
evaluation/ExplReturns Max     477.4193709789727
evaluation/ExplReturns Min     471.4596350714997
evaluation/Actions Mean        0.08653215
evaluation/Actions Std         0.5340352
evaluation/Actions Max         0.999963
evaluation/Actions Min         -0.99999475
evaluation/Num Paths           10
evaluation/Average Returns     474.0780141034626
time/data storing (s)          0.03228690568357706
time/evaluation sampling (s)   112.46028222516179
time/exploration sampling (s)  112.32111284602433
time/logging (s)               0.030590975657105446
time/saving (s)                0.011844971217215061
time/training (s)              9.643489900045097
time/epoch (s)                 234.49960782378912
time/total (s)                 76685.75011240784
Epoch                          327
-----------------------------  --------------------
2023-08-01 15:16:06.941485 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 328 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4334.0356]
trainer/QF1 Loss               0.037779912
trainer/QF2 Loss               0.033756115
trainer/Policy Loss            -90.99756
trainer/Q1 Predictions Mean    102.95651
trainer/Q1 Predictions Std     2.0195277
trainer/Q1 Predictions Max     105.87447
trainer/Q1 Predictions Min     91.64115
trainer/Q2 Predictions Mean    102.90292
trainer/Q2 Predictions Std     2.0247202
trainer/Q2 Predictions Max     105.82813
trainer/Q2 Predictions Min     91.86919
trainer/Q Targets Mean         102.892654
trainer/Q Targets Std          2.06175
trainer/Q Targets Max          105.775635
trainer/Q Targets Min          90.74251
trainer/Log Pis Mean           12.015056
trainer/Log Pis Std            8.526046
trainer/Log Pis Max            45.65242
trainer/Log Pis Min            -3.5747833
trainer/Policy mu Mean         0.055288713
trainer/Policy mu Std          1.5795643
trainer/Policy mu Max          7.441618
trainer/Policy mu Min          -5.4872437
trainer/Policy log std Mean    -0.7774969
trainer/Policy log std Std     0.3551424
trainer/Policy log std Max     1.1320715
trainer/Policy log std Min     -2.4100666
trainer/Alpha                  0.0014176624827086926
trainer/Alpha Loss             0.09874534606933594
exploration/num steps total    1646000
exploration/num paths total    3292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9657561577810994
exploration/Rewards Std        0.05105210912838904
exploration/Rewards Max        0.9799410830864157
exploration/Rewards Min        0.49360174007385904
exploration/Returns Mean       482.8780788905498
exploration/Returns Std        0.5138874289839716
exploration/Returns Max        483.59216597207273
exploration/Returns Min        481.9419511409163
exploration/Actions Mean       0.046291478
exploration/Actions Std        0.58500695
exploration/Actions Max        0.99998105
exploration/Actions Min        -0.99999106
exploration/Num Paths          10
exploration/Average Returns    482.8780788905498
evaluation/num steps total     1645000
evaluation/num paths total     3290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9614652406836761
evaluation/Rewards Std         0.05605332153466678
evaluation/Rewards Max         0.9779840929171599
evaluation/Rewards Min         0.49674389227969074
evaluation/Returns Mean        480.73262034183807
evaluation/Returns Std         1.8042421749591253
evaluation/Returns Max         483.2696146914583
evaluation/Returns Min         476.9458689932987
evaluation/ExplReturns Mean    480.73262034183807
evaluation/ExplReturns Std     1.8042421749591253
evaluation/ExplReturns Max     483.2696146914583
evaluation/ExplReturns Min     476.9458689932987
evaluation/Actions Mean        0.017061826
evaluation/Actions Std         0.5332736
evaluation/Actions Max         0.99996454
evaluation/Actions Min         -0.9999889
evaluation/Num Paths           10
evaluation/Average Returns     480.73262034183807
time/data storing (s)          0.032137210480868816
time/evaluation sampling (s)   111.03216248750687
time/exploration sampling (s)  112.05618459638208
time/logging (s)               0.031008617021143436
time/saving (s)                0.010361181572079659
time/training (s)              9.396373836323619
time/epoch (s)                 232.55822792928666
time/total (s)                 76918.31082198583
Epoch                          328
-----------------------------  ---------------------
2023-08-01 15:19:58.499678 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 329 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4122.39]
trainer/QF1 Loss               0.03325997
trainer/QF2 Loss               0.02659899
trainer/Policy Loss            -91.754486
trainer/Q1 Predictions Mean    103.015045
trainer/Q1 Predictions Std     3.1771786
trainer/Q1 Predictions Max     105.90882
trainer/Q1 Predictions Min     63.31459
trainer/Q2 Predictions Mean    102.925735
trainer/Q2 Predictions Std     3.236542
trainer/Q2 Predictions Max     105.68495
trainer/Q2 Predictions Min     61.97265
trainer/Q Targets Mean         102.94005
trainer/Q Targets Std          3.1990302
trainer/Q Targets Max          105.64067
trainer/Q Targets Min          62.909237
trainer/Log Pis Mean           11.296098
trainer/Log Pis Std            8.826379
trainer/Log Pis Max            63.868317
trainer/Log Pis Min            -5.545383
trainer/Policy mu Mean         -0.100204654
trainer/Policy mu Std          1.5326527
trainer/Policy mu Max          5.459282
trainer/Policy mu Min          -8.370587
trainer/Policy log std Mean    -0.8003451
trainer/Policy log std Std     0.35051498
trainer/Policy log std Max     0.29786313
trainer/Policy log std Min     -2.4189672
trainer/Alpha                  0.001341716735623777
trainer/Alpha Loss             -4.655427932739258
exploration/num steps total    1651000
exploration/num paths total    3302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9548584577635287
exploration/Rewards Std        0.05757843058723285
exploration/Rewards Max        0.9796367892764156
exploration/Rewards Min        0.49036979365700406
exploration/Returns Mean       477.4292288817643
exploration/Returns Std        4.602292396659199
exploration/Returns Max        480.0976212360945
exploration/Returns Min        466.2289895644046
exploration/Actions Mean       0.008453677
exploration/Actions Std        0.5748949
exploration/Actions Max        0.999998
exploration/Actions Min        -0.99999267
exploration/Num Paths          10
exploration/Average Returns    477.4292288817643
evaluation/num steps total     1650000
evaluation/num paths total     3300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9579535901195253
evaluation/Rewards Std         0.05316776319265091
evaluation/Rewards Max         0.9771095317365778
evaluation/Rewards Min         0.4917988132695043
evaluation/Returns Mean        478.97679505976265
evaluation/Returns Std         3.4641450254669985
evaluation/Returns Max         480.46623903823263
evaluation/Returns Min         468.67133829186366
evaluation/ExplReturns Mean    478.97679505976265
evaluation/ExplReturns Std     3.4641450254669985
evaluation/ExplReturns Max     480.46623903823263
evaluation/ExplReturns Min     468.67133829186366
evaluation/Actions Mean        0.030669045
evaluation/Actions Std         0.45263794
evaluation/Actions Max         0.9999891
evaluation/Actions Min         -0.9999647
evaluation/Num Paths           10
evaluation/Average Returns     478.97679505976265
time/data storing (s)          0.03238683380186558
time/evaluation sampling (s)   110.67340781539679
time/exploration sampling (s)  111.11734198685735
time/logging (s)               0.030828626826405525
time/saving (s)                0.011524762958288193
time/training (s)              9.686745733954012
time/epoch (s)                 231.5522357597947
time/total (s)                 77149.86590039823
Epoch                          329
-----------------------------  --------------------
2023-08-01 15:23:51.540982 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 330 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4109.9365]
trainer/QF1 Loss               0.019181527
trainer/QF2 Loss               0.018970918
trainer/Policy Loss            -91.33031
trainer/Q1 Predictions Mean    103.08519
trainer/Q1 Predictions Std     2.9736369
trainer/Q1 Predictions Max     105.85261
trainer/Q1 Predictions Min     66.93443
trainer/Q2 Predictions Mean    103.1298
trainer/Q2 Predictions Std     2.9925303
trainer/Q2 Predictions Max     105.853584
trainer/Q2 Predictions Min     67.14671
trainer/Q Targets Mean         103.07674
trainer/Q Targets Std          3.0225453
trainer/Q Targets Max          105.79351
trainer/Q Targets Min          66.21208
trainer/Log Pis Mean           11.899433
trainer/Log Pis Std            7.655728
trainer/Log Pis Max            39.47085
trainer/Log Pis Min            -8.975911
trainer/Policy mu Mean         -0.22244547
trainer/Policy mu Std          1.5472702
trainer/Policy mu Max          5.2453275
trainer/Policy mu Min          -5.509042
trainer/Policy log std Mean    -0.7800748
trainer/Policy log std Std     0.32718647
trainer/Policy log std Max     0.75203764
trainer/Policy log std Min     -2.4153163
trainer/Alpha                  0.0014981169952079654
trainer/Alpha Loss             -0.6540476083755493
exploration/num steps total    1656000
exploration/num paths total    3312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9520611877751387
exploration/Rewards Std        0.05436046074641221
exploration/Rewards Max        0.9789775148142038
exploration/Rewards Min        0.4955205027027238
exploration/Returns Mean       476.0305938875692
exploration/Returns Std        1.8269612248300935
exploration/Returns Max        477.6965335484995
exploration/Returns Min        471.3386858431296
exploration/Actions Mean       0.10103818
exploration/Actions Std        0.56827664
exploration/Actions Max        0.99999493
exploration/Actions Min        -0.9998788
exploration/Num Paths          10
exploration/Average Returns    476.0305938875692
evaluation/num steps total     1655000
evaluation/num paths total     3310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9485666085209105
evaluation/Rewards Std         0.05397857019806463
evaluation/Rewards Max         0.9778680172567867
evaluation/Rewards Min         0.5016807822871792
evaluation/Returns Mean        474.28330426045534
evaluation/Returns Std         2.496547543743929
evaluation/Returns Max         476.9297407735917
evaluation/Returns Min         470.47401024563504
evaluation/ExplReturns Mean    474.28330426045534
evaluation/ExplReturns Std     2.496547543743929
evaluation/ExplReturns Max     476.9297407735917
evaluation/ExplReturns Min     470.47401024563504
evaluation/Actions Mean        -0.0059888796
evaluation/Actions Std         0.52969474
evaluation/Actions Max         0.99974495
evaluation/Actions Min         -0.9996466
evaluation/Num Paths           10
evaluation/Average Returns     474.28330426045534
time/data storing (s)          0.032169945538043976
time/evaluation sampling (s)   111.3746652584523
time/exploration sampling (s)  112.4864254463464
time/logging (s)               0.031053691171109676
time/saving (s)                0.011438023298978806
time/training (s)              9.100275308825076
time/epoch (s)                 233.0360276736319
time/total (s)                 77382.90450919233
Epoch                          330
-----------------------------  ---------------------
2023-08-01 15:27:47.610424 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 331 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4203.1724]
trainer/QF1 Loss               0.020435218
trainer/QF2 Loss               0.016009059
trainer/Policy Loss            -90.56392
trainer/Q1 Predictions Mean    103.00776
trainer/Q1 Predictions Std     2.6579711
trainer/Q1 Predictions Max     105.60196
trainer/Q1 Predictions Min     74.31306
trainer/Q2 Predictions Mean    102.95441
trainer/Q2 Predictions Std     2.6460712
trainer/Q2 Predictions Max     105.4855
trainer/Q2 Predictions Min     74.83417
trainer/Q Targets Mean         102.95527
trainer/Q Targets Std          2.6403673
trainer/Q Targets Max          105.63023
trainer/Q Targets Min          74.80335
trainer/Log Pis Mean           12.541355
trainer/Log Pis Std            7.212104
trainer/Log Pis Max            41.38874
trainer/Log Pis Min            -5.824524
trainer/Policy mu Mean         -0.28513828
trainer/Policy mu Std          1.5811388
trainer/Policy mu Max          6.3780594
trainer/Policy mu Min          -6.7352715
trainer/Policy log std Mean    -0.7478797
trainer/Policy log std Std     0.32763866
trainer/Policy log std Max     0.7310903
trainer/Policy log std Min     -2.3482425
trainer/Alpha                  0.001778922276571393
trainer/Alpha Loss             3.4278059005737305
exploration/num steps total    1661000
exploration/num paths total    3322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9625721370030406
exploration/Rewards Std        0.04920234869141031
exploration/Rewards Max        0.9798885319326449
exploration/Rewards Min        0.49429864012870345
exploration/Returns Mean       481.2860685015203
exploration/Returns Std        0.6033129605850704
exploration/Returns Max        482.0127968732208
exploration/Returns Min        479.81908329946987
exploration/Actions Mean       -0.007136475
exploration/Actions Std        0.599538
exploration/Actions Max        0.99999213
exploration/Actions Min        -0.9998875
exploration/Num Paths          10
exploration/Average Returns    481.2860685015203
evaluation/num steps total     1660000
evaluation/num paths total     3320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9590215877751911
evaluation/Rewards Std         0.05498234815736219
evaluation/Rewards Max         0.9796592402866676
evaluation/Rewards Min         0.49582078317443945
evaluation/Returns Mean        479.51079388759564
evaluation/Returns Std         3.619332778120173
evaluation/Returns Max         481.5041629919154
evaluation/Returns Min         472.21533253989855
evaluation/ExplReturns Mean    479.51079388759564
evaluation/ExplReturns Std     3.619332778120173
evaluation/ExplReturns Max     481.5041629919154
evaluation/ExplReturns Min     472.21533253989855
evaluation/Actions Mean        -0.029929249
evaluation/Actions Std         0.4753507
evaluation/Actions Max         0.99990106
evaluation/Actions Min         -0.9993988
evaluation/Num Paths           10
evaluation/Average Returns     479.51079388759564
time/data storing (s)          0.03229289408773184
time/evaluation sampling (s)   113.81197642628103
time/exploration sampling (s)  112.66202187351882
time/logging (s)               0.030531723983585835
time/saving (s)                0.010819383896887302
time/training (s)              9.515800615772605
time/epoch (s)                 236.06344291754067
time/total (s)                 77618.97047099564
Epoch                          331
-----------------------------  --------------------
2023-08-01 15:31:42.571235 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 332 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4009.8904]
trainer/QF1 Loss               0.028448937
trainer/QF2 Loss               0.018933624
trainer/Policy Loss            -91.62294
trainer/Q1 Predictions Mean    103.107
trainer/Q1 Predictions Std     2.2752085
trainer/Q1 Predictions Max     105.62186
trainer/Q1 Predictions Min     91.124664
trainer/Q2 Predictions Mean    103.163025
trainer/Q2 Predictions Std     2.2582266
trainer/Q2 Predictions Max     105.45375
trainer/Q2 Predictions Min     91.12849
trainer/Q Targets Mean         103.191376
trainer/Q Targets Std          2.2591214
trainer/Q Targets Max          105.62344
trainer/Q Targets Min          91.41493
trainer/Log Pis Mean           11.627639
trainer/Log Pis Std            6.714456
trainer/Log Pis Max            51.124916
trainer/Log Pis Min            -4.2359753
trainer/Policy mu Mean         -0.27018628
trainer/Policy mu Std          1.5188324
trainer/Policy mu Max          5.289159
trainer/Policy mu Min          -5.242704
trainer/Policy log std Mean    -0.793279
trainer/Policy log std Std     0.3240486
trainer/Policy log std Max     0.09813093
trainer/Policy log std Min     -2.380581
trainer/Alpha                  0.001792105264030397
trainer/Alpha Loss             -2.3549768924713135
exploration/num steps total    1666000
exploration/num paths total    3332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9499464462618793
exploration/Rewards Std        0.07550874798786274
exploration/Rewards Max        0.9797527953535493
exploration/Rewards Min        0.49979009295763466
exploration/Returns Mean       474.97322313093946
exploration/Returns Std        15.849070389518976
exploration/Returns Max        481.9693651851701
exploration/Returns Min        427.483841531226
exploration/Actions Mean       -0.05724807
exploration/Actions Std        0.62489146
exploration/Actions Max        0.99996734
exploration/Actions Min        -0.9999902
exploration/Num Paths          10
exploration/Average Returns    474.97322313093946
evaluation/num steps total     1665000
evaluation/num paths total     3330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9584831615675529
evaluation/Rewards Std         0.058171742341886865
evaluation/Rewards Max         0.9770348636138773
evaluation/Rewards Min         0.5032322819802955
evaluation/Returns Mean        479.2415807837763
evaluation/Returns Std         2.1006526936011074
evaluation/Returns Max         481.4738381640726
evaluation/Returns Min         473.6621611939966
evaluation/ExplReturns Mean    479.2415807837763
evaluation/ExplReturns Std     2.1006526936011074
evaluation/ExplReturns Max     481.4738381640726
evaluation/ExplReturns Min     473.6621611939966
evaluation/Actions Mean        -0.09738444
evaluation/Actions Std         0.501914
evaluation/Actions Max         0.99952585
evaluation/Actions Min         -0.9998439
evaluation/Num Paths           10
evaluation/Average Returns     479.2415807837763
time/data storing (s)          0.0322704678401351
time/evaluation sampling (s)   112.53535388223827
time/exploration sampling (s)  112.20982132013887
time/logging (s)               0.0307717090472579
time/saving (s)                0.01033137459307909
time/training (s)              10.136857406236231
time/epoch (s)                 234.95540616009384
time/total (s)                 77853.92855929956
Epoch                          332
-----------------------------  --------------------
2023-08-01 15:35:36.819908 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 333 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3830.4595]
trainer/QF1 Loss               0.02838229
trainer/QF2 Loss               0.026632272
trainer/Policy Loss            -90.49193
trainer/Q1 Predictions Mean    102.99117
trainer/Q1 Predictions Std     3.9234986
trainer/Q1 Predictions Max     105.358185
trainer/Q1 Predictions Min     56.255653
trainer/Q2 Predictions Mean    102.97438
trainer/Q2 Predictions Std     3.9404085
trainer/Q2 Predictions Max     105.29776
trainer/Q2 Predictions Min     56.221592
trainer/Q Targets Mean         103.02431
trainer/Q Targets Std          3.9804535
trainer/Q Targets Max          105.37666
trainer/Q Targets Min          55.69625
trainer/Log Pis Mean           12.622511
trainer/Log Pis Std            8.015307
trainer/Log Pis Max            82.68171
trainer/Log Pis Min            -11.206639
trainer/Policy mu Mean         -0.2177649
trainer/Policy mu Std          1.5720195
trainer/Policy mu Max          9.089694
trainer/Policy mu Min          -5.2050276
trainer/Policy log std Mean    -0.7994089
trainer/Policy log std Std     0.34996152
trainer/Policy log std Max     0.91164637
trainer/Policy log std Min     -2.354145
trainer/Alpha                  0.0017767021199688315
trainer/Alpha Loss             3.9424657821655273
exploration/num steps total    1671000
exploration/num paths total    3342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9626758142579973
exploration/Rewards Std        0.05470861346734875
exploration/Rewards Max        0.9796665401437924
exploration/Rewards Min        0.49525044165662413
exploration/Returns Mean       481.3379071289987
exploration/Returns Std        0.8614742410555198
exploration/Returns Max        482.7592057512516
exploration/Returns Min        480.00711455963796
exploration/Actions Mean       -0.014852919
exploration/Actions Std        0.6299323
exploration/Actions Max        0.99991876
exploration/Actions Min        -0.99999636
exploration/Num Paths          10
exploration/Average Returns    481.3379071289987
evaluation/num steps total     1670000
evaluation/num paths total     3340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9526244090171702
evaluation/Rewards Std         0.06834168132388921
evaluation/Rewards Max         0.978892617980266
evaluation/Rewards Min         0.5043777761570726
evaluation/Returns Mean        476.3122045085853
evaluation/Returns Std         6.474508603771346
evaluation/Returns Max         482.6223580072337
evaluation/Returns Min         460.4435717027232
evaluation/ExplReturns Mean    476.3122045085853
evaluation/ExplReturns Std     6.474508603771346
evaluation/ExplReturns Max     482.6223580072337
evaluation/ExplReturns Min     460.4435717027232
evaluation/Actions Mean        -0.051470958
evaluation/Actions Std         0.5089364
evaluation/Actions Max         0.9997069
evaluation/Actions Min         -0.9996903
evaluation/Num Paths           10
evaluation/Average Returns     476.3122045085853
time/data storing (s)          0.032008349895477295
time/evaluation sampling (s)   112.44031936489046
time/exploration sampling (s)  112.66402625385672
time/logging (s)               0.03050837852060795
time/saving (s)                0.010215215384960175
time/training (s)              9.065908555872738
time/epoch (s)                 234.24298611842096
time/total (s)                 78088.17402355932
Epoch                          333
-----------------------------  ---------------------
2023-08-01 15:39:30.303331 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 334 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4091.1978]
trainer/QF1 Loss               0.04899922
trainer/QF2 Loss               0.025461739
trainer/Policy Loss            -92.53818
trainer/Q1 Predictions Mean    103.5012
trainer/Q1 Predictions Std     2.189527
trainer/Q1 Predictions Max     105.4813
trainer/Q1 Predictions Min     86.77034
trainer/Q2 Predictions Mean    103.43676
trainer/Q2 Predictions Std     2.214242
trainer/Q2 Predictions Max     105.31942
trainer/Q2 Predictions Min     87.03766
trainer/Q Targets Mean         103.33388
trainer/Q Targets Std          2.2221525
trainer/Q Targets Max          105.5468
trainer/Q Targets Min          86.72348
trainer/Log Pis Mean           11.043847
trainer/Log Pis Std            7.2356462
trainer/Log Pis Max            40.94349
trainer/Log Pis Min            -7.2393174
trainer/Policy mu Mean         -0.22855411
trainer/Policy mu Std          1.5052897
trainer/Policy mu Max          5.517712
trainer/Policy mu Min          -5.5878024
trainer/Policy log std Mean    -0.75998265
trainer/Policy log std Std     0.34263912
trainer/Policy log std Max     0.670293
trainer/Policy log std Min     -2.221038
trainer/Alpha                  0.001777825877070427
trainer/Alpha Loss             -6.054592132568359
exploration/num steps total    1676000
exploration/num paths total    3352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557928176830143
exploration/Rewards Std        0.06238949020865748
exploration/Rewards Max        0.979520887751656
exploration/Rewards Min        0.4977332875037621
exploration/Returns Mean       477.8964088415072
exploration/Returns Std        2.896185281916828
exploration/Returns Max        481.5632047049447
exploration/Returns Min        470.57520755139126
exploration/Actions Mean       0.018385973
exploration/Actions Std        0.60768247
exploration/Actions Max        0.99986345
exploration/Actions Min        -0.99996823
exploration/Num Paths          10
exploration/Average Returns    477.8964088415072
evaluation/num steps total     1675000
evaluation/num paths total     3350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9535826611807828
evaluation/Rewards Std         0.0680791060638029
evaluation/Rewards Max         0.9781888314865003
evaluation/Rewards Min         0.5012674319578705
evaluation/Returns Mean        476.7913305903915
evaluation/Returns Std         7.014688780143231
evaluation/Returns Max         481.846617785565
evaluation/Returns Min         458.2003221247457
evaluation/ExplReturns Mean    476.7913305903915
evaluation/ExplReturns Std     7.014688780143231
evaluation/ExplReturns Max     481.846617785565
evaluation/ExplReturns Min     458.2003221247457
evaluation/Actions Mean        0.020137392
evaluation/Actions Std         0.5055817
evaluation/Actions Max         0.9998971
evaluation/Actions Min         -0.9995967
evaluation/Num Paths           10
evaluation/Average Returns     476.7913305903915
time/data storing (s)          0.031762704253196716
time/evaluation sampling (s)   112.52840696368366
time/exploration sampling (s)  111.30012733116746
time/logging (s)               0.030437232926487923
time/saving (s)                0.01060744933784008
time/training (s)              9.576555925421417
time/epoch (s)                 233.47789760679007
time/total (s)                 78321.654449353
Epoch                          334
-----------------------------  --------------------
2023-08-01 15:43:27.142833 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 335 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3796.8757]
trainer/QF1 Loss               0.025188152
trainer/QF2 Loss               0.02278838
trainer/Policy Loss            -91.50451
trainer/Q1 Predictions Mean    103.407875
trainer/Q1 Predictions Std     1.8321294
trainer/Q1 Predictions Max     105.050644
trainer/Q1 Predictions Min     90.66983
trainer/Q2 Predictions Mean    103.410065
trainer/Q2 Predictions Std     1.7846359
trainer/Q2 Predictions Max     105.18783
trainer/Q2 Predictions Min     91.37265
trainer/Q Targets Mean         103.43502
trainer/Q Targets Std          1.8248053
trainer/Q Targets Max          105.10759
trainer/Q Targets Min          91.3376
trainer/Log Pis Mean           12.01079
trainer/Log Pis Std            6.488432
trainer/Log Pis Max            37.308792
trainer/Log Pis Min            -7.0853252
trainer/Policy mu Mean         -0.15856251
trainer/Policy mu Std          1.5470333
trainer/Policy mu Max          4.583319
trainer/Policy mu Min          -4.811839
trainer/Policy log std Mean    -0.735068
trainer/Policy log std Std     0.29825997
trainer/Policy log std Max     0.076171875
trainer/Policy log std Min     -2.2542274
trainer/Alpha                  0.0018141692271456122
trainer/Alpha Loss             0.06811022758483887
exploration/num steps total    1681000
exploration/num paths total    3362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9537884507812054
exploration/Rewards Std        0.06944085119448594
exploration/Rewards Max        0.9790266275946877
exploration/Rewards Min        0.498395733496222
exploration/Returns Mean       476.8942253906028
exploration/Returns Std        8.73437354960733
exploration/Returns Max        482.6714125971977
exploration/Returns Min        459.2669906112447
exploration/Actions Mean       0.020716509
exploration/Actions Std        0.6364728
exploration/Actions Max        0.99999255
exploration/Actions Min        -0.9999982
exploration/Num Paths          10
exploration/Average Returns    476.8942253906028
evaluation/num steps total     1680000
evaluation/num paths total     3360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9588637191422157
evaluation/Rewards Std         0.05876056073324453
evaluation/Rewards Max         0.9771494585722028
evaluation/Rewards Min         0.4902450072707458
evaluation/Returns Mean        479.4318595711079
evaluation/Returns Std         3.35814471487036
evaluation/Returns Max         482.55546844435537
evaluation/Returns Min         470.5028604532234
evaluation/ExplReturns Mean    479.4318595711079
evaluation/ExplReturns Std     3.35814471487036
evaluation/ExplReturns Max     482.55546844435537
evaluation/ExplReturns Min     470.5028604532234
evaluation/Actions Mean        0.00015306835
evaluation/Actions Std         0.5395572
evaluation/Actions Max         0.9989022
evaluation/Actions Min         -0.999869
evaluation/Num Paths           10
evaluation/Average Returns     479.4318595711079
time/data storing (s)          0.03206823579967022
time/evaluation sampling (s)   113.40790417045355
time/exploration sampling (s)  113.67663760110736
time/logging (s)               0.030566693283617496
time/saving (s)                0.01029212586581707
time/training (s)              9.676723875105381
time/epoch (s)                 236.8341927016154
time/total (s)                 78558.49115770962
Epoch                          335
-----------------------------  ---------------------
2023-08-01 15:47:19.720476 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 336 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3746.559]
trainer/QF1 Loss               0.03322573
trainer/QF2 Loss               0.03884031
trainer/Policy Loss            -89.419945
trainer/Q1 Predictions Mean    102.93837
trainer/Q1 Predictions Std     4.362528
trainer/Q1 Predictions Max     108.36407
trainer/Q1 Predictions Min     54.912994
trainer/Q2 Predictions Mean    102.900696
trainer/Q2 Predictions Std     4.3501835
trainer/Q2 Predictions Max     107.89994
trainer/Q2 Predictions Min     54.965763
trainer/Q Targets Mean         102.94829
trainer/Q Targets Std          4.41152
trainer/Q Targets Max          108.02899
trainer/Q Targets Min          54.27039
trainer/Log Pis Mean           13.635979
trainer/Log Pis Std            9.348063
trainer/Log Pis Max            76.35694
trainer/Log Pis Min            -5.895072
trainer/Policy mu Mean         -0.17368717
trainer/Policy mu Std          1.6916186
trainer/Policy mu Max          8.894167
trainer/Policy mu Min          -10.71185
trainer/Policy log std Mean    -0.7238407
trainer/Policy log std Std     0.30351624
trainer/Policy log std Max     0.4734161
trainer/Policy log std Min     -2.145998
trainer/Alpha                  0.001709713600575924
trainer/Alpha Loss             10.424091339111328
exploration/num steps total    1686000
exploration/num paths total    3372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9573703901501596
exploration/Rewards Std        0.05837939390442021
exploration/Rewards Max        0.9797819061910126
exploration/Rewards Min        0.5018889598653595
exploration/Returns Mean       478.6851950750799
exploration/Returns Std        3.2758013980539507
exploration/Returns Max        481.32260519591165
exploration/Returns Min        472.2619738537829
exploration/Actions Mean       0.046028294
exploration/Actions Std        0.6025574
exploration/Actions Max        0.99997526
exploration/Actions Min        -0.99992275
exploration/Num Paths          10
exploration/Average Returns    478.6851950750799
evaluation/num steps total     1685000
evaluation/num paths total     3370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9569805144587464
evaluation/Rewards Std         0.05816041233344963
evaluation/Rewards Max         0.9794648104110264
evaluation/Rewards Min         0.48596412489970986
evaluation/Returns Mean        478.49025722937324
evaluation/Returns Std         6.025801360353483
evaluation/Returns Max         481.63032311197315
evaluation/Returns Min         460.534173949705
evaluation/ExplReturns Mean    478.49025722937324
evaluation/ExplReturns Std     6.025801360353483
evaluation/ExplReturns Max     481.63032311197315
evaluation/ExplReturns Min     460.534173949705
evaluation/Actions Mean        0.04921839
evaluation/Actions Std         0.5522748
evaluation/Actions Max         0.99976647
evaluation/Actions Min         -0.9994764
evaluation/Num Paths           10
evaluation/Average Returns     478.49025722937324
time/data storing (s)          0.03212579432874918
time/evaluation sampling (s)   111.89551041088998
time/exploration sampling (s)  111.87301073782146
time/logging (s)               0.03050560038536787
time/saving (s)                0.010293829254806042
time/training (s)              8.730297653004527
time/epoch (s)                 232.5717440256849
time/total (s)                 78791.0658179149
Epoch                          336
-----------------------------  --------------------
2023-08-01 15:51:14.838762 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 337 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3792.8794]
trainer/QF1 Loss               0.023503566
trainer/QF2 Loss               0.025115637
trainer/Policy Loss            -92.17087
trainer/Q1 Predictions Mean    103.51549
trainer/Q1 Predictions Std     1.7532578
trainer/Q1 Predictions Max     106.60172
trainer/Q1 Predictions Min     92.49076
trainer/Q2 Predictions Mean    103.50851
trainer/Q2 Predictions Std     1.7558515
trainer/Q2 Predictions Max     106.87919
trainer/Q2 Predictions Min     92.38737
trainer/Q Targets Mean         103.53666
trainer/Q Targets Std          1.7595553
trainer/Q Targets Max          107.10065
trainer/Q Targets Min          92.39861
trainer/Log Pis Mean           11.463893
trainer/Log Pis Std            6.975668
trainer/Log Pis Max            39.009434
trainer/Log Pis Min            -12.3783245
trainer/Policy mu Mean         -0.20228775
trainer/Policy mu Std          1.5539211
trainer/Policy mu Max          5.0993004
trainer/Policy mu Min          -5.173319
trainer/Policy log std Mean    -0.70387906
trainer/Policy log std Std     0.2930437
trainer/Policy log std Max     0.15349294
trainer/Policy log std Min     -2.0419736
trainer/Alpha                  0.001794384908862412
trainer/Alpha Loss             -3.389857292175293
exploration/num steps total    1691000
exploration/num paths total    3382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9569056514601619
exploration/Rewards Std        0.04890109108902705
exploration/Rewards Max        0.9782624353901378
exploration/Rewards Min        0.49538614127501596
exploration/Returns Mean       478.4528257300809
exploration/Returns Std        0.48965212326749474
exploration/Returns Max        479.1154241621838
exploration/Returns Min        477.65507371111414
exploration/Actions Mean       0.037509676
exploration/Actions Std        0.588062
exploration/Actions Max        0.999958
exploration/Actions Min        -0.9999608
exploration/Num Paths          10
exploration/Average Returns    478.4528257300809
evaluation/num steps total     1690000
evaluation/num paths total     3380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9560486988635283
evaluation/Rewards Std         0.04756334054438193
evaluation/Rewards Max         0.9749982560245796
evaluation/Rewards Min         0.5043536183518386
evaluation/Returns Mean        478.02434943176405
evaluation/Returns Std         0.44222541145386074
evaluation/Returns Max         478.9564168263791
evaluation/Returns Min         477.1802832502016
evaluation/ExplReturns Mean    478.02434943176405
evaluation/ExplReturns Std     0.44222541145386074
evaluation/ExplReturns Max     478.9564168263791
evaluation/ExplReturns Min     477.1802832502016
evaluation/Actions Mean        0.08626326
evaluation/Actions Std         0.4182544
evaluation/Actions Max         0.99887764
evaluation/Actions Min         -0.9987822
evaluation/Num Paths           10
evaluation/Average Returns     478.02434943176405
time/data storing (s)          0.03185439668595791
time/evaluation sampling (s)   112.81740752607584
time/exploration sampling (s)  112.40579772274941
time/logging (s)               0.035012722946703434
time/saving (s)                0.014085311442613602
time/training (s)              9.81309584248811
time/epoch (s)                 235.11725352238864
time/total (s)                 79026.18552740384
Epoch                          337
-----------------------------  --------------------
2023-08-01 15:55:06.756734 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 338 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3829.4526]
trainer/QF1 Loss               0.052245125
trainer/QF2 Loss               0.022943906
trainer/Policy Loss            -89.68324
trainer/Q1 Predictions Mean    103.05348
trainer/Q1 Predictions Std     2.946012
trainer/Q1 Predictions Max     105.34787
trainer/Q1 Predictions Min     77.70891
trainer/Q2 Predictions Mean    103.227005
trainer/Q2 Predictions Std     2.9542358
trainer/Q2 Predictions Max     105.49174
trainer/Q2 Predictions Min     78.20653
trainer/Q Targets Mean         103.21119
trainer/Q Targets Std          2.9938326
trainer/Q Targets Max          105.45503
trainer/Q Targets Min          78.03221
trainer/Log Pis Mean           13.549711
trainer/Log Pis Std            9.143553
trainer/Log Pis Max            75.7731
trainer/Log Pis Min            -2.4627128
trainer/Policy mu Mean         -0.21612962
trainer/Policy mu Std          1.6743011
trainer/Policy mu Max          7.405105
trainer/Policy mu Min          -7.355188
trainer/Policy log std Mean    -0.6983755
trainer/Policy log std Std     0.28694788
trainer/Policy log std Max     0.51347184
trainer/Policy log std Min     -2.2914748
trainer/Alpha                  0.001743447151966393
trainer/Alpha Loss             9.844043731689453
exploration/num steps total    1696000
exploration/num paths total    3392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.951509562142655
exploration/Rewards Std        0.05522561339660266
exploration/Rewards Max        0.97845806413821
exploration/Rewards Min        0.49349578528691795
exploration/Returns Mean       475.7547810713275
exploration/Returns Std        2.2691483452846577
exploration/Returns Max        479.6182659695073
exploration/Returns Min        472.70413445990397
exploration/Actions Mean       0.082261786
exploration/Actions Std        0.6167252
exploration/Actions Max        0.9999545
exploration/Actions Min        -0.9999948
exploration/Num Paths          10
exploration/Average Returns    475.7547810713275
evaluation/num steps total     1695000
evaluation/num paths total     3390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9555942158122595
evaluation/Rewards Std         0.05270431415027828
evaluation/Rewards Max         0.975878616308288
evaluation/Rewards Min         0.49212839679659814
evaluation/Returns Mean        477.7971079061296
evaluation/Returns Std         1.1270450360943525
evaluation/Returns Max         479.72884467084475
evaluation/Returns Min         476.2811639968228
evaluation/ExplReturns Mean    477.7971079061296
evaluation/ExplReturns Std     1.1270450360943525
evaluation/ExplReturns Max     479.72884467084475
evaluation/ExplReturns Min     476.2811639968228
evaluation/Actions Mean        0.10278134
evaluation/Actions Std         0.5047553
evaluation/Actions Max         0.9998409
evaluation/Actions Min         -0.9999494
evaluation/Num Paths           10
evaluation/Average Returns     477.7971079061296
time/data storing (s)          0.032059190794825554
time/evaluation sampling (s)   110.90408115182072
time/exploration sampling (s)  111.39042963832617
time/logging (s)               0.03042923379689455
time/saving (s)                0.011335089802742004
time/training (s)              9.53961361758411
time/epoch (s)                 231.90794792212546
time/total (s)                 79258.09596092906
Epoch                          338
-----------------------------  --------------------
2023-08-01 15:58:58.389004 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 339 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3727.6838]
trainer/QF1 Loss               0.021985684
trainer/QF2 Loss               0.0299846
trainer/Policy Loss            -92.37697
trainer/Q1 Predictions Mean    103.64704
trainer/Q1 Predictions Std     1.8850471
trainer/Q1 Predictions Max     106.57892
trainer/Q1 Predictions Min     88.81527
trainer/Q2 Predictions Mean    103.56516
trainer/Q2 Predictions Std     1.840915
trainer/Q2 Predictions Max     106.479416
trainer/Q2 Predictions Min     89.52533
trainer/Q Targets Mean         103.64635
trainer/Q Targets Std          1.8713857
trainer/Q Targets Max          106.41179
trainer/Q Targets Min          89.10148
trainer/Log Pis Mean           11.393904
trainer/Log Pis Std            7.8674054
trainer/Log Pis Max            43.783253
trainer/Log Pis Min            -5.8120127
trainer/Policy mu Mean         -0.005054275
trainer/Policy mu Std          1.6006069
trainer/Policy mu Max          5.2172947
trainer/Policy mu Min          -5.6890283
trainer/Policy log std Mean    -0.66839725
trainer/Policy log std Std     0.3019012
trainer/Policy log std Max     0.6221185
trainer/Policy log std Min     -1.9645633
trainer/Alpha                  0.0018271072767674923
trainer/Alpha Loss             -3.8213064670562744
exploration/num steps total    1701000
exploration/num paths total    3402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9425167480380214
exploration/Rewards Std        0.0670614120754723
exploration/Rewards Max        0.9778600159921091
exploration/Rewards Min        0.4920102608392891
exploration/Returns Mean       471.2583740190106
exploration/Returns Std        5.466757390602686
exploration/Returns Max        477.323531224142
exploration/Returns Min        464.33271169862456
exploration/Actions Mean       0.041267004
exploration/Actions Std        0.548966
exploration/Actions Max        0.99989897
exploration/Actions Min        -0.99996215
exploration/Num Paths          10
exploration/Average Returns    471.2583740190106
evaluation/num steps total     1700000
evaluation/num paths total     3400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9516994098423139
evaluation/Rewards Std         0.048470766012384245
evaluation/Rewards Max         0.9666696420263915
evaluation/Rewards Min         0.4875296120264949
evaluation/Returns Mean        475.8497049211569
evaluation/Returns Std         0.42566270168999837
evaluation/Returns Max         476.4438071322611
evaluation/Returns Min         474.85793356174327
evaluation/ExplReturns Mean    475.8497049211569
evaluation/ExplReturns Std     0.42566270168999837
evaluation/ExplReturns Max     476.4438071322611
evaluation/ExplReturns Min     474.85793356174327
evaluation/Actions Mean        0.058477685
evaluation/Actions Std         0.41089547
evaluation/Actions Max         0.99751073
evaluation/Actions Min         -0.9990741
evaluation/Num Paths           10
evaluation/Average Returns     475.8497049211569
time/data storing (s)          0.03219196852296591
time/evaluation sampling (s)   110.44003585726023
time/exploration sampling (s)  111.46825801022351
time/logging (s)               0.03072563372552395
time/saving (s)                0.012322841212153435
time/training (s)              9.643515957519412
time/epoch (s)                 231.6270502684638
time/total (s)                 79489.72551115137
Epoch                          339
-----------------------------  ---------------------
2023-08-01 16:02:50.777590 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 340 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3856.6519]
trainer/QF1 Loss               0.01977688
trainer/QF2 Loss               0.02723274
trainer/Policy Loss            -91.871826
trainer/Q1 Predictions Mean    103.71705
trainer/Q1 Predictions Std     1.6101978
trainer/Q1 Predictions Max     105.60278
trainer/Q1 Predictions Min     93.59036
trainer/Q2 Predictions Mean    103.69287
trainer/Q2 Predictions Std     1.6159118
trainer/Q2 Predictions Max     105.43342
trainer/Q2 Predictions Min     92.953156
trainer/Q Targets Mean         103.75455
trainer/Q Targets Std          1.5803552
trainer/Q Targets Max          105.39417
trainer/Q Targets Min          93.89751
trainer/Log Pis Mean           11.949252
trainer/Log Pis Std            7.8673706
trainer/Log Pis Max            44.431503
trainer/Log Pis Min            -1.7578306
trainer/Policy mu Mean         -0.20382063
trainer/Policy mu Std          1.5833418
trainer/Policy mu Max          5.0363207
trainer/Policy mu Min          -5.4948683
trainer/Policy log std Mean    -0.6507102
trainer/Policy log std Std     0.28094563
trainer/Policy log std Max     0.59276485
trainer/Policy log std Min     -1.8694166
trainer/Alpha                  0.001877096714451909
trainer/Alpha Loss             -0.31860044598579407
exploration/num steps total    1706000
exploration/num paths total    3412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9634336155733632
exploration/Rewards Std        0.051013810373638474
exploration/Rewards Max        0.9785841856720465
exploration/Rewards Min        0.49457257856071923
exploration/Returns Mean       481.7168077866818
exploration/Returns Std        0.3683739467784412
exploration/Returns Max        482.38324478814593
exploration/Returns Min        481.27496454967775
exploration/Actions Mean       0.079465926
exploration/Actions Std        0.60175097
exploration/Actions Max        0.9999633
exploration/Actions Min        -0.99997777
exploration/Num Paths          10
exploration/Average Returns    481.7168077866818
evaluation/num steps total     1705000
evaluation/num paths total     3410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9643328784723483
evaluation/Rewards Std         0.051421827075576604
evaluation/Rewards Max         0.9761284867486124
evaluation/Rewards Min         0.49378455301479474
evaluation/Returns Mean        482.166439236174
evaluation/Returns Std         0.591902241771013
evaluation/Returns Max         482.82438737456437
evaluation/Returns Min         480.984560890135
evaluation/ExplReturns Mean    482.166439236174
evaluation/ExplReturns Std     0.591902241771013
evaluation/ExplReturns Max     482.82438737456437
evaluation/ExplReturns Min     480.984560890135
evaluation/Actions Mean        0.0645403
evaluation/Actions Std         0.5373265
evaluation/Actions Max         0.999374
evaluation/Actions Min         -0.9997898
evaluation/Num Paths           10
evaluation/Average Returns     482.166439236174
time/data storing (s)          0.032493227161467075
time/evaluation sampling (s)   110.92184011824429
time/exploration sampling (s)  111.69074275065213
time/logging (s)               0.03084667958319187
time/saving (s)                0.010369936935603619
time/training (s)              9.696871987544
time/epoch (s)                 232.3831647001207
time/total (s)                 79722.11119238473
Epoch                          340
-----------------------------  --------------------
2023-08-01 16:06:43.651786 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 341 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3878.2393]
trainer/QF1 Loss               0.025994767
trainer/QF2 Loss               0.017678736
trainer/Policy Loss            -92.027725
trainer/Q1 Predictions Mean    103.79164
trainer/Q1 Predictions Std     1.6404403
trainer/Q1 Predictions Max     105.632164
trainer/Q1 Predictions Min     95.11578
trainer/Q2 Predictions Mean    103.80279
trainer/Q2 Predictions Std     1.6269698
trainer/Q2 Predictions Max     105.66012
trainer/Q2 Predictions Min     94.87849
trainer/Q Targets Mean         103.861176
trainer/Q Targets Std          1.6361676
trainer/Q Targets Max          105.6984
trainer/Q Targets Min          94.12425
trainer/Log Pis Mean           11.878618
trainer/Log Pis Std            6.3234134
trainer/Log Pis Max            41.307774
trainer/Log Pis Min            -5.159027
trainer/Policy mu Mean         -0.11933675
trainer/Policy mu Std          1.6100428
trainer/Policy mu Max          4.528414
trainer/Policy mu Min          -4.406521
trainer/Policy log std Mean    -0.6582708
trainer/Policy log std Std     0.26997787
trainer/Policy log std Max     0.17598438
trainer/Policy log std Min     -1.8848866
trainer/Alpha                  0.0018596900627017021
trainer/Alpha Loss             -0.7631644606590271
exploration/num steps total    1711000
exploration/num paths total    3422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.961234585406294
exploration/Rewards Std        0.055627908922948166
exploration/Rewards Max        0.9781446590776183
exploration/Rewards Min        0.4913870707271378
exploration/Returns Mean       480.6172927031471
exploration/Returns Std        0.9095017923207237
exploration/Returns Max        481.77757503506126
exploration/Returns Min        478.1330943334671
exploration/Actions Mean       0.03579435
exploration/Actions Std        0.5560507
exploration/Actions Max        0.9999418
exploration/Actions Min        -0.9999384
exploration/Num Paths          10
exploration/Average Returns    480.6172927031471
evaluation/num steps total     1710000
evaluation/num paths total     3420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9632693832413326
evaluation/Rewards Std         0.05349303431132251
evaluation/Rewards Max         0.9764560789029977
evaluation/Rewards Min         0.49364599282051497
evaluation/Returns Mean        481.63469162066633
evaluation/Returns Std         0.6251681188228636
evaluation/Returns Max         482.1394316936944
evaluation/Returns Min         479.8428109373939
evaluation/ExplReturns Mean    481.63469162066633
evaluation/ExplReturns Std     0.6251681188228636
evaluation/ExplReturns Max     482.1394316936944
evaluation/ExplReturns Min     479.8428109373939
evaluation/Actions Mean        0.02901411
evaluation/Actions Std         0.46106902
evaluation/Actions Max         0.9976194
evaluation/Actions Min         -0.9995531
evaluation/Num Paths           10
evaluation/Average Returns     481.63469162066633
time/data storing (s)          0.03230980224907398
time/evaluation sampling (s)   111.44484473578632
time/exploration sampling (s)  111.7553188111633
time/logging (s)               0.03083457611501217
time/saving (s)                0.01057466957718134
time/training (s)              9.594727166928351
time/epoch (s)                 232.86860976181924
time/total (s)                 79954.98233304359
Epoch                          341
-----------------------------  ---------------------
2023-08-01 16:10:34.819738 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 342 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3703.8757]
trainer/QF1 Loss               0.029653931
trainer/QF2 Loss               0.05115898
trainer/Policy Loss            -92.10333
trainer/Q1 Predictions Mean    103.54422
trainer/Q1 Predictions Std     2.6458914
trainer/Q1 Predictions Max     105.505325
trainer/Q1 Predictions Min     79.32206
trainer/Q2 Predictions Mean    103.470825
trainer/Q2 Predictions Std     2.6008816
trainer/Q2 Predictions Max     105.509865
trainer/Q2 Predictions Min     79.43638
trainer/Q Targets Mean         103.58039
trainer/Q Targets Std          2.6283264
trainer/Q Targets Max          105.56598
trainer/Q Targets Min          79.491295
trainer/Log Pis Mean           11.486593
trainer/Log Pis Std            7.7395196
trainer/Log Pis Max            52.875313
trainer/Log Pis Min            -3.1664352
trainer/Policy mu Mean         -0.079438806
trainer/Policy mu Std          1.5979879
trainer/Policy mu Max          9.184923
trainer/Policy mu Min          -10.012266
trainer/Policy log std Mean    -0.69774693
trainer/Policy log std Std     0.28757873
trainer/Policy log std Max     1.1605358
trainer/Policy log std Min     -2.085647
trainer/Alpha                  0.001806248794309795
trainer/Alpha Loss             -3.2429416179656982
exploration/num steps total    1716000
exploration/num paths total    3432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9415337043105825
exploration/Rewards Std        0.05357947984397049
exploration/Rewards Max        0.9781962471510761
exploration/Rewards Min        0.4874770049062456
exploration/Returns Mean       470.7668521552914
exploration/Returns Std        2.226240687214867
exploration/Returns Max        473.6410111711786
exploration/Returns Min        466.36829077161616
exploration/Actions Mean       -0.009240979
exploration/Actions Std        0.5567521
exploration/Actions Max        0.99965394
exploration/Actions Min        -0.9998938
exploration/Num Paths          10
exploration/Average Returns    470.7668521552914
evaluation/num steps total     1715000
evaluation/num paths total     3430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9394432524967169
evaluation/Rewards Std         0.05020683803429531
evaluation/Rewards Max         0.9776727465855202
evaluation/Rewards Min         0.48942774540948486
evaluation/Returns Mean        469.72162624835835
evaluation/Returns Std         2.7142436261276006
evaluation/Returns Max         471.09424675276017
evaluation/Returns Min         461.6476310720682
evaluation/ExplReturns Mean    469.72162624835835
evaluation/ExplReturns Std     2.7142436261276006
evaluation/ExplReturns Max     471.09424675276017
evaluation/ExplReturns Min     461.6476310720682
evaluation/Actions Mean        -0.020818703
evaluation/Actions Std         0.45997518
evaluation/Actions Max         0.9984298
evaluation/Actions Min         -0.99932086
evaluation/Num Paths           10
evaluation/Average Returns     469.72162624835835
time/data storing (s)          0.032404934987425804
time/evaluation sampling (s)   110.57856445107609
time/exploration sampling (s)  110.46661427430809
time/logging (s)               0.030360257253050804
time/saving (s)                0.012510470114648342
time/training (s)              10.041572474874556
time/epoch (s)                 231.16202686261386
time/total (s)                 80186.1468159277
Epoch                          342
-----------------------------  --------------------
2023-08-01 16:14:26.904071 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 343 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3921.8977]
trainer/QF1 Loss               0.02801295
trainer/QF2 Loss               0.030420473
trainer/Policy Loss            -91.110054
trainer/Q1 Predictions Mean    103.624176
trainer/Q1 Predictions Std     2.816138
trainer/Q1 Predictions Max     105.491936
trainer/Q1 Predictions Min     75.20371
trainer/Q2 Predictions Mean    103.62694
trainer/Q2 Predictions Std     2.8110116
trainer/Q2 Predictions Max     105.516884
trainer/Q2 Predictions Min     75.190674
trainer/Q Targets Mean         103.56975
trainer/Q Targets Std          2.8395746
trainer/Q Targets Max          105.53559
trainer/Q Targets Min          75.10165
trainer/Log Pis Mean           12.602493
trainer/Log Pis Std            8.0033655
trainer/Log Pis Max            46.160637
trainer/Log Pis Min            -1.8480967
trainer/Policy mu Mean         0.058929175
trainer/Policy mu Std          1.6186296
trainer/Policy mu Max          7.5314374
trainer/Policy mu Min          -4.926811
trainer/Policy log std Mean    -0.700609
trainer/Policy log std Std     0.27934763
trainer/Policy log std Max     0.8577326
trainer/Policy log std Min     -2.0646222
trainer/Alpha                  0.001658760360442102
trainer/Alpha Loss             3.8569633960723877
exploration/num steps total    1721000
exploration/num paths total    3442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9634008009083534
exploration/Rewards Std        0.05068987921275101
exploration/Rewards Max        0.9788469464523699
exploration/Rewards Min        0.49595063508473275
exploration/Returns Mean       481.7004004541767
exploration/Returns Std        0.5549164171491562
exploration/Returns Max        482.72462168418764
exploration/Returns Min        480.6589401867001
exploration/Actions Mean       0.08230379
exploration/Actions Std        0.6198564
exploration/Actions Max        0.99979043
exploration/Actions Min        -0.9997798
exploration/Num Paths          10
exploration/Average Returns    481.7004004541767
evaluation/num steps total     1720000
evaluation/num paths total     3440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9602373401435965
evaluation/Rewards Std         0.049685152686203445
evaluation/Rewards Max         0.9767618456336635
evaluation/Rewards Min         0.4915916289252762
evaluation/Returns Mean        480.11867007179825
evaluation/Returns Std         0.3981145963413063
evaluation/Returns Max         480.7156273513766
evaluation/Returns Min         479.260988828953
evaluation/ExplReturns Mean    480.11867007179825
evaluation/ExplReturns Std     0.3981145963413063
evaluation/ExplReturns Max     480.7156273513766
evaluation/ExplReturns Min     479.260988828953
evaluation/Actions Mean        0.09142386
evaluation/Actions Std         0.58975315
evaluation/Actions Max         0.9987114
evaluation/Actions Min         -0.99860424
evaluation/Num Paths           10
evaluation/Average Returns     480.11867007179825
time/data storing (s)          0.03267793636769056
time/evaluation sampling (s)   110.58846926502883
time/exploration sampling (s)  111.8531390344724
time/logging (s)               0.030939391814172268
time/saving (s)                0.011460531502962112
time/training (s)              9.562497395090759
time/epoch (s)                 232.07918355427682
time/total (s)                 80418.22869691253
Epoch                          343
-----------------------------  --------------------
2023-08-01 16:18:18.486267 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 344 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3684.906]
trainer/QF1 Loss               0.03468033
trainer/QF2 Loss               0.014827266
trainer/Policy Loss            -92.10179
trainer/Q1 Predictions Mean    104.01562
trainer/Q1 Predictions Std     1.9934824
trainer/Q1 Predictions Max     105.83863
trainer/Q1 Predictions Min     89.62937
trainer/Q2 Predictions Mean    103.853455
trainer/Q2 Predictions Std     1.9807436
trainer/Q2 Predictions Max     105.62411
trainer/Q2 Predictions Min     89.81756
trainer/Q Targets Mean         103.88095
trainer/Q Targets Std          2.0108473
trainer/Q Targets Max          105.72099
trainer/Q Targets Min          89.40366
trainer/Log Pis Mean           11.915991
trainer/Log Pis Std            7.2250004
trainer/Log Pis Max            48.328293
trainer/Log Pis Min            -2.7369885
trainer/Policy mu Mean         -0.014549836
trainer/Policy mu Std          1.5967176
trainer/Policy mu Max          6.2103677
trainer/Policy mu Min          -4.3748074
trainer/Policy log std Mean    -0.7031388
trainer/Policy log std Std     0.28618878
trainer/Policy log std Max     0.32976002
trainer/Policy log std Min     -2.055772
trainer/Alpha                  0.001512874965555966
trainer/Alpha Loss             -0.5455392599105835
exploration/num steps total    1726000
exploration/num paths total    3452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9650952866065292
exploration/Rewards Std        0.052756895542966815
exploration/Rewards Max        0.9798686769504354
exploration/Rewards Min        0.4882266302691174
exploration/Returns Mean       482.5476433032645
exploration/Returns Std        0.418127373801846
exploration/Returns Max        483.23065698611134
exploration/Returns Min        481.7767853058723
exploration/Actions Mean       0.056607947
exploration/Actions Std        0.6269235
exploration/Actions Max        0.99993074
exploration/Actions Min        -0.99983805
exploration/Num Paths          10
exploration/Average Returns    482.5476433032645
evaluation/num steps total     1725000
evaluation/num paths total     3450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9657295171093452
evaluation/Rewards Std         0.053121665406357134
evaluation/Rewards Max         0.9790979438381978
evaluation/Rewards Min         0.49114594890753865
evaluation/Returns Mean        482.8647585546727
evaluation/Returns Std         0.3792210558423796
evaluation/Returns Max         483.34128299388914
evaluation/Returns Min         482.15477998165034
evaluation/ExplReturns Mean    482.8647585546727
evaluation/ExplReturns Std     0.3792210558423796
evaluation/ExplReturns Max     483.34128299388914
evaluation/ExplReturns Min     482.15477998165034
evaluation/Actions Mean        0.06417012
evaluation/Actions Std         0.5506812
evaluation/Actions Max         0.9992043
evaluation/Actions Min         -0.9987122
evaluation/Num Paths           10
evaluation/Average Returns     482.8647585546727
time/data storing (s)          0.03192379977554083
time/evaluation sampling (s)   110.35772240813822
time/exploration sampling (s)  111.86246428918093
time/logging (s)               0.030604207888245583
time/saving (s)                0.012885280884802341
time/training (s)              9.280550986528397
time/epoch (s)                 231.57615097239614
time/total (s)                 80649.8075467078
Epoch                          344
-----------------------------  --------------------
2023-08-01 16:22:09.536384 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 345 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3752.502]
trainer/QF1 Loss               0.023709858
trainer/QF2 Loss               0.013017852
trainer/Policy Loss            -91.89198
trainer/Q1 Predictions Mean    104.0794
trainer/Q1 Predictions Std     1.4363602
trainer/Q1 Predictions Max     105.62502
trainer/Q1 Predictions Min     95.810196
trainer/Q2 Predictions Mean    103.994965
trainer/Q2 Predictions Std     1.4347899
trainer/Q2 Predictions Max     105.58384
trainer/Q2 Predictions Min     95.40265
trainer/Q Targets Mean         103.998566
trainer/Q Targets Std          1.4241725
trainer/Q Targets Max          105.48808
trainer/Q Targets Min          95.42754
trainer/Log Pis Mean           12.2729435
trainer/Log Pis Std            7.8435974
trainer/Log Pis Max            43.92093
trainer/Log Pis Min            -2.3282936
trainer/Policy mu Mean         -0.056564257
trainer/Policy mu Std          1.6294456
trainer/Policy mu Max          5.1013317
trainer/Policy mu Min          -5.461406
trainer/Policy log std Mean    -0.6741228
trainer/Policy log std Std     0.27878428
trainer/Policy log std Max     0.009211779
trainer/Policy log std Min     -2.4265547
trainer/Alpha                  0.0015911876689642668
trainer/Alpha Loss             1.7586919069290161
exploration/num steps total    1731000
exploration/num paths total    3462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9572914835595042
exploration/Rewards Std        0.053582732297750846
exploration/Rewards Max        0.9780920493875449
exploration/Rewards Min        0.48586593360073005
exploration/Returns Mean       478.6457417797522
exploration/Returns Std        0.6866289627268425
exploration/Returns Max        479.43624596895734
exploration/Returns Min        477.3729800931794
exploration/Actions Mean       0.03934557
exploration/Actions Std        0.6183639
exploration/Actions Max        0.9996873
exploration/Actions Min        -0.99989027
exploration/Num Paths          10
exploration/Average Returns    478.6457417797522
evaluation/num steps total     1730000
evaluation/num paths total     3460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9589062571165421
evaluation/Rewards Std         0.04951899847728898
evaluation/Rewards Max         0.9770265358208281
evaluation/Rewards Min         0.4928349855695759
evaluation/Returns Mean        479.453128558271
evaluation/Returns Std         0.27989847174133986
evaluation/Returns Max         479.9599479488939
evaluation/Returns Min         479.0080103343834
evaluation/ExplReturns Mean    479.453128558271
evaluation/ExplReturns Std     0.27989847174133986
evaluation/ExplReturns Max     479.9599479488939
evaluation/ExplReturns Min     479.0080103343834
evaluation/Actions Mean        0.040368963
evaluation/Actions Std         0.53021306
evaluation/Actions Max         0.9985268
evaluation/Actions Min         -0.9986972
evaluation/Num Paths           10
evaluation/Average Returns     479.453128558271
time/data storing (s)          0.03217316512018442
time/evaluation sampling (s)   110.12774872779846
time/exploration sampling (s)  111.1855045678094
time/logging (s)               0.030342651531100273
time/saving (s)                0.011387314647436142
time/training (s)              9.65720958262682
time/epoch (s)                 231.0443660095334
time/total (s)                 80880.8543877881
Epoch                          345
-----------------------------  ---------------------
2023-08-01 16:25:59.830309 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 346 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3935.096]
trainer/QF1 Loss               0.025255322
trainer/QF2 Loss               0.018996306
trainer/Policy Loss            -91.81772
trainer/Q1 Predictions Mean    103.50372
trainer/Q1 Predictions Std     3.6897109
trainer/Q1 Predictions Max     107.404015
trainer/Q1 Predictions Min     70.15683
trainer/Q2 Predictions Mean    103.500824
trainer/Q2 Predictions Std     3.6928012
trainer/Q2 Predictions Max     107.52042
trainer/Q2 Predictions Min     70.7647
trainer/Q Targets Mean         103.57656
trainer/Q Targets Std          3.68829
trainer/Q Targets Max          107.73348
trainer/Q Targets Min          70.291374
trainer/Log Pis Mean           11.823643
trainer/Log Pis Std            9.168797
trainer/Log Pis Max            55.633877
trainer/Log Pis Min            -3.7527251
trainer/Policy mu Mean         -0.030004663
trainer/Policy mu Std          1.6278223
trainer/Policy mu Max          12.808653
trainer/Policy mu Min          -5.3390646
trainer/Policy log std Mean    -0.7018214
trainer/Policy log std Std     0.2888634
trainer/Policy log std Max     1.5062656
trainer/Policy log std Min     -2.4564614
trainer/Alpha                  0.0016339541180059314
trainer/Alpha Loss             -1.131633996963501
exploration/num steps total    1736000
exploration/num paths total    3472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9604241182125265
exploration/Rewards Std        0.05366073364757716
exploration/Rewards Max        0.9795679711040921
exploration/Rewards Min        0.4949942513029444
exploration/Returns Mean       480.21205910626304
exploration/Returns Std        0.18216968686733445
exploration/Returns Max        480.589061739516
exploration/Returns Min        479.9384225494979
exploration/Actions Mean       -1.0613759e-06
exploration/Actions Std        0.6053288
exploration/Actions Max        0.99988776
exploration/Actions Min        -0.99985474
exploration/Num Paths          10
exploration/Average Returns    480.21205910626304
evaluation/num steps total     1735000
evaluation/num paths total     3470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9636162010628672
evaluation/Rewards Std         0.0554331896753955
evaluation/Rewards Max         0.979455981430216
evaluation/Rewards Min         0.4807056888302368
evaluation/Returns Mean        481.8081005314337
evaluation/Returns Std         1.0629044669167447
evaluation/Returns Max         482.9167453240719
evaluation/Returns Min         479.71672706524555
evaluation/ExplReturns Mean    481.8081005314337
evaluation/ExplReturns Std     1.0629044669167447
evaluation/ExplReturns Max     482.9167453240719
evaluation/ExplReturns Min     479.71672706524555
evaluation/Actions Mean        -0.03644398
evaluation/Actions Std         0.5292545
evaluation/Actions Max         0.999327
evaluation/Actions Min         -0.99902683
evaluation/Num Paths           10
evaluation/Average Returns     481.8081005314337
time/data storing (s)          0.031756420619785786
time/evaluation sampling (s)   109.22492401394993
time/exploration sampling (s)  111.35255502909422
time/logging (s)               0.030472288839519024
time/saving (s)                0.011949236504733562
time/training (s)              9.63683501072228
time/epoch (s)                 230.28849199973047
time/total (s)                 81111.14543856494
Epoch                          346
-----------------------------  ---------------------
2023-08-01 16:29:49.056340 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 347 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4052.0723]
trainer/QF1 Loss               0.027615082
trainer/QF2 Loss               0.03183683
trainer/Policy Loss            -91.53874
trainer/Q1 Predictions Mean    103.61104
trainer/Q1 Predictions Std     3.7513015
trainer/Q1 Predictions Max     105.322235
trainer/Q1 Predictions Min     54.899014
trainer/Q2 Predictions Mean    103.64719
trainer/Q2 Predictions Std     3.7697334
trainer/Q2 Predictions Max     105.24218
trainer/Q2 Predictions Min     54.57966
trainer/Q Targets Mean         103.58476
trainer/Q Targets Std          3.7520487
trainer/Q Targets Max          105.2473
trainer/Q Targets Min          55.12533
trainer/Log Pis Mean           12.220862
trainer/Log Pis Std            8.508027
trainer/Log Pis Max            51.958225
trainer/Log Pis Min            -4.699019
trainer/Policy mu Mean         -0.07972387
trainer/Policy mu Std          1.6400076
trainer/Policy mu Max          6.762739
trainer/Policy mu Min          -4.633718
trainer/Policy log std Mean    -0.6729836
trainer/Policy log std Std     0.28973922
trainer/Policy log std Max     0.11270361
trainer/Policy log std Min     -2.2465198
trainer/Alpha                  0.0016596874920651317
trainer/Alpha Loss             1.4137811660766602
exploration/num steps total    1741000
exploration/num paths total    3482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9507941165884591
exploration/Rewards Std        0.05836545842159808
exploration/Rewards Max        0.9790788246896795
exploration/Rewards Min        0.4999145875498043
exploration/Returns Mean       475.39705829422945
exploration/Returns Std        1.4096217570581229
exploration/Returns Max        477.2643006760183
exploration/Returns Min        473.4668027218832
exploration/Actions Mean       -0.021373212
exploration/Actions Std        0.5998206
exploration/Actions Max        0.9999041
exploration/Actions Min        -0.999703
exploration/Num Paths          10
exploration/Average Returns    475.39705829422945
evaluation/num steps total     1740000
evaluation/num paths total     3480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9525052374927316
evaluation/Rewards Std         0.053922747596472684
evaluation/Rewards Max         0.9797879483385636
evaluation/Rewards Min         0.4945472797532565
evaluation/Returns Mean        476.2526187463658
evaluation/Returns Std         0.901656928483507
evaluation/Returns Max         478.028769082297
evaluation/Returns Min         474.9064450330543
evaluation/ExplReturns Mean    476.2526187463658
evaluation/ExplReturns Std     0.901656928483507
evaluation/ExplReturns Max     478.028769082297
evaluation/ExplReturns Min     474.9064450330543
evaluation/Actions Mean        -0.03634966
evaluation/Actions Std         0.54071677
evaluation/Actions Max         0.99881375
evaluation/Actions Min         -0.9991319
evaluation/Num Paths           10
evaluation/Average Returns     476.2526187463658
time/data storing (s)          0.03230433817952871
time/evaluation sampling (s)   109.16288830619305
time/exploration sampling (s)  110.31754864752293
time/logging (s)               0.03050488978624344
time/saving (s)                0.01129334419965744
time/training (s)              9.666033589281142
time/epoch (s)                 229.22057311516255
time/total (s)                 81340.36845329497
Epoch                          347
-----------------------------  ---------------------
2023-08-01 16:33:40.529068 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 348 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3870.8728]
trainer/QF1 Loss               0.020911787
trainer/QF2 Loss               0.023697812
trainer/Policy Loss            -92.40057
trainer/Q1 Predictions Mean    103.98088
trainer/Q1 Predictions Std     3.3336313
trainer/Q1 Predictions Max     105.76892
trainer/Q1 Predictions Min     55.501385
trainer/Q2 Predictions Mean    104.030754
trainer/Q2 Predictions Std     3.3172107
trainer/Q2 Predictions Max     105.84415
trainer/Q2 Predictions Min     55.806763
trainer/Q Targets Mean         103.98936
trainer/Q Targets Std          3.3540242
trainer/Q Targets Max          105.74927
trainer/Q Targets Min          55.346313
trainer/Log Pis Mean           11.696175
trainer/Log Pis Std            7.9892693
trainer/Log Pis Max            58.49832
trainer/Log Pis Min            -4.2827477
trainer/Policy mu Mean         -0.06684306
trainer/Policy mu Std          1.6123806
trainer/Policy mu Max          7.0710616
trainer/Policy mu Min          -5.3878965
trainer/Policy log std Mean    -0.6523096
trainer/Policy log std Std     0.2758137
trainer/Policy log std Max     0.33053786
trainer/Policy log std Min     -1.92694
trainer/Alpha                  0.001714493497274816
trainer/Alpha Loss             -1.9349442720413208
exploration/num steps total    1746000
exploration/num paths total    3492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8808741721347949
exploration/Rewards Std        0.1067252954379356
exploration/Rewards Max        0.9785150467388322
exploration/Rewards Min        0.4999104176217829
exploration/Returns Mean       440.43708606739756
exploration/Returns Std        16.003790509334483
exploration/Returns Max        466.7123721340125
exploration/Returns Min        407.75684847278444
exploration/Actions Mean       0.027496276
exploration/Actions Std        0.5912298
exploration/Actions Max        0.9999873
exploration/Actions Min        -0.99985164
exploration/Num Paths          10
exploration/Average Returns    440.43708606739756
evaluation/num steps total     1745000
evaluation/num paths total     3490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8509825488250117
evaluation/Rewards Std         0.11300139229266264
evaluation/Rewards Max         0.9752875768709024
evaluation/Rewards Min         0.49471807270408724
evaluation/Returns Mean        425.49127441250585
evaluation/Returns Std         23.96580546623099
evaluation/Returns Max         471.7890874469273
evaluation/Returns Min         398.5220230208128
evaluation/ExplReturns Mean    425.49127441250585
evaluation/ExplReturns Std     23.96580546623099
evaluation/ExplReturns Max     471.7890874469273
evaluation/ExplReturns Min     398.5220230208128
evaluation/Actions Mean        0.04850319
evaluation/Actions Std         0.5259339
evaluation/Actions Max         0.99980867
evaluation/Actions Min         -0.9993351
evaluation/Num Paths           10
evaluation/Average Returns     425.49127441250585
time/data storing (s)          0.03285701293498278
time/evaluation sampling (s)   110.56463270820677
time/exploration sampling (s)  110.99871044140309
time/logging (s)               0.03038288000971079
time/saving (s)                0.012170207686722279
time/training (s)              9.828300565481186
time/epoch (s)                 231.46705381572247
time/total (s)                 81571.83805222064
Epoch                          348
-----------------------------  --------------------
2023-08-01 16:37:32.073071 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 349 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4004.7224]
trainer/QF1 Loss               0.030901529
trainer/QF2 Loss               0.020351797
trainer/Policy Loss            -92.82708
trainer/Q1 Predictions Mean    103.97119
trainer/Q1 Predictions Std     2.1451845
trainer/Q1 Predictions Max     107.53047
trainer/Q1 Predictions Min     81.67021
trainer/Q2 Predictions Mean    104.04618
trainer/Q2 Predictions Std     2.1394012
trainer/Q2 Predictions Max     107.461624
trainer/Q2 Predictions Min     81.68768
trainer/Q Targets Mean         104.05791
trainer/Q Targets Std          2.131122
trainer/Q Targets Max          107.68667
trainer/Q Targets Min          81.64852
trainer/Log Pis Mean           11.303086
trainer/Log Pis Std            6.968328
trainer/Log Pis Max            36.38669
trainer/Log Pis Min            -4.5628858
trainer/Policy mu Mean         -0.021509675
trainer/Policy mu Std          1.5564464
trainer/Policy mu Max          4.248682
trainer/Policy mu Min          -4.7016087
trainer/Policy log std Mean    -0.6797371
trainer/Policy log std Std     0.2628352
trainer/Policy log std Max     -0.038287193
trainer/Policy log std Min     -1.8731906
trainer/Alpha                  0.001731134601868689
trainer/Alpha Loss             -4.431571960449219
exploration/num steps total    1751000
exploration/num paths total    3502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9571134081421753
exploration/Rewards Std        0.05339084467862087
exploration/Rewards Max        0.9794195667994409
exploration/Rewards Min        0.49344973841110784
exploration/Returns Mean       478.55670407108744
exploration/Returns Std        1.5113590226884077
exploration/Returns Max        479.72755923234524
exploration/Returns Min        474.34439160870426
exploration/Actions Mean       0.0010194923
exploration/Actions Std        0.58648556
exploration/Actions Max        0.9999758
exploration/Actions Min        -0.99986327
exploration/Num Paths          10
exploration/Average Returns    478.55670407108744
evaluation/num steps total     1750000
evaluation/num paths total     3500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9605316108607515
evaluation/Rewards Std         0.05284605035922388
evaluation/Rewards Max         0.9789227974309784
evaluation/Rewards Min         0.49148863169105894
evaluation/Returns Mean        480.26580543037574
evaluation/Returns Std         0.957170068565501
evaluation/Returns Max         481.79070854860015
evaluation/Returns Min         479.09181815916446
evaluation/ExplReturns Mean    480.26580543037574
evaluation/ExplReturns Std     0.957170068565501
evaluation/ExplReturns Max     481.79070854860015
evaluation/ExplReturns Min     479.09181815916446
evaluation/Actions Mean        -0.02695282
evaluation/Actions Std         0.4246414
evaluation/Actions Max         0.999546
evaluation/Actions Min         -0.9995206
evaluation/Num Paths           10
evaluation/Average Returns     480.26580543037574
time/data storing (s)          0.03230160940438509
time/evaluation sampling (s)   110.89865362271667
time/exploration sampling (s)  110.47195931151509
time/logging (s)               0.030340236611664295
time/saving (s)                0.011137556284666061
time/training (s)              10.093911628238857
time/epoch (s)                 231.53830396477133
time/total (s)                 81803.37895812653
Epoch                          349
-----------------------------  --------------------
2023-08-01 16:41:26.933443 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 350 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3754.0034]
trainer/QF1 Loss               0.050801538
trainer/QF2 Loss               0.027549142
trainer/Policy Loss            -92.873726
trainer/Q1 Predictions Mean    103.97151
trainer/Q1 Predictions Std     1.8939351
trainer/Q1 Predictions Max     108.01867
trainer/Q1 Predictions Min     89.46959
trainer/Q2 Predictions Mean    104.048904
trainer/Q2 Predictions Std     1.8712071
trainer/Q2 Predictions Max     108.040764
trainer/Q2 Predictions Min     90.27939
trainer/Q Targets Mean         104.139114
trainer/Q Targets Std          1.9049246
trainer/Q Targets Max          107.98953
trainer/Q Targets Min          90.043884
trainer/Log Pis Mean           11.250198
trainer/Log Pis Std            8.485056
trainer/Log Pis Max            45.499844
trainer/Log Pis Min            -4.0155373
trainer/Policy mu Mean         -0.09715787
trainer/Policy mu Std          1.5819924
trainer/Policy mu Max          8.610756
trainer/Policy mu Min          -5.446084
trainer/Policy log std Mean    -0.65102667
trainer/Policy log std Std     0.2719947
trainer/Policy log std Max     0.3982147
trainer/Policy log std Min     -1.9868457
trainer/Alpha                  0.0015999899478629231
trainer/Alpha Loss             -4.8267693519592285
exploration/num steps total    1756000
exploration/num paths total    3512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7812183033105164
exploration/Rewards Std        0.10216044100242595
exploration/Rewards Max        0.9787707865410185
exploration/Rewards Min        0.4941403198335488
exploration/Returns Mean       390.6091516552582
exploration/Returns Std        13.724651255435154
exploration/Returns Max        413.7751123172366
exploration/Returns Min        371.0217484316928
exploration/Actions Mean       -0.0318932
exploration/Actions Std        0.61118597
exploration/Actions Max        0.9999643
exploration/Actions Min        -0.99998075
exploration/Num Paths          10
exploration/Average Returns    390.6091516552582
evaluation/num steps total     1755000
evaluation/num paths total     3510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7960533510609681
evaluation/Rewards Std         0.10544204691338852
evaluation/Rewards Max         0.9764270993576196
evaluation/Rewards Min         0.49757547320285656
evaluation/Returns Mean        398.02667553048406
evaluation/Returns Std         11.229530759476704
evaluation/Returns Max         416.82677886190675
evaluation/Returns Min         380.3773494716053
evaluation/ExplReturns Mean    398.02667553048406
evaluation/ExplReturns Std     11.229530759476704
evaluation/ExplReturns Max     416.82677886190675
evaluation/ExplReturns Min     380.3773494716053
evaluation/Actions Mean        -0.0129938945
evaluation/Actions Std         0.529248
evaluation/Actions Max         0.9998152
evaluation/Actions Min         -0.99994886
evaluation/Num Paths           10
evaluation/Average Returns     398.02667553048406
time/data storing (s)          0.03203954640775919
time/evaluation sampling (s)   112.67409970797598
time/exploration sampling (s)  111.69732080027461
time/logging (s)               0.03064175881445408
time/saving (s)                0.012181895785033703
time/training (s)              10.408831786364317
time/epoch (s)                 234.85511549562216
time/total (s)                 82038.23655905481
Epoch                          350
-----------------------------  ---------------------
2023-08-01 16:45:22.926731 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 351 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3881.4233]
trainer/QF1 Loss               0.021571167
trainer/QF2 Loss               0.021191616
trainer/Policy Loss            -92.37334
trainer/Q1 Predictions Mean    104.038795
trainer/Q1 Predictions Std     2.2129796
trainer/Q1 Predictions Max     106.04782
trainer/Q1 Predictions Min     79.745415
trainer/Q2 Predictions Mean    103.99431
trainer/Q2 Predictions Std     2.1909494
trainer/Q2 Predictions Max     105.95883
trainer/Q2 Predictions Min     80.49181
trainer/Q Targets Mean         104.03676
trainer/Q Targets Std          2.2225664
trainer/Q Targets Max          106.012146
trainer/Q Targets Min          79.72609
trainer/Log Pis Mean           11.727288
trainer/Log Pis Std            8.511398
trainer/Log Pis Max            57.283367
trainer/Log Pis Min            -7.2927923
trainer/Policy mu Mean         -0.13606666
trainer/Policy mu Std          1.5652438
trainer/Policy mu Max          8.95625
trainer/Policy mu Min          -5.9419594
trainer/Policy log std Mean    -0.7334728
trainer/Policy log std Std     0.2841162
trainer/Policy log std Max     0.4208498
trainer/Policy log std Min     -2.5692158
trainer/Alpha                  0.0014610292855650187
trainer/Alpha Loss             -1.780441403388977
exploration/num steps total    1761000
exploration/num paths total    3522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9448111582447105
exploration/Rewards Std        0.07513768189402746
exploration/Rewards Max        0.9799946378835456
exploration/Rewards Min        0.5052882484239082
exploration/Returns Mean       472.4055791223553
exploration/Returns Std        6.6042074187232425
exploration/Returns Max        478.7105267105221
exploration/Returns Min        454.4137516977953
exploration/Actions Mean       -0.012374278
exploration/Actions Std        0.574288
exploration/Actions Max        0.99997634
exploration/Actions Min        -0.99997354
exploration/Num Paths          10
exploration/Average Returns    472.4055791223553
evaluation/num steps total     1760000
evaluation/num paths total     3520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9569902670025302
evaluation/Rewards Std         0.06359477078271863
evaluation/Rewards Max         0.9761904233825384
evaluation/Rewards Min         0.4930079525467174
evaluation/Returns Mean        478.49513350126506
evaluation/Returns Std         2.680298458660823
evaluation/Returns Max         480.65898965907746
evaluation/Returns Min         471.0190910861635
evaluation/ExplReturns Mean    478.49513350126506
evaluation/ExplReturns Std     2.680298458660823
evaluation/ExplReturns Max     480.65898965907746
evaluation/ExplReturns Min     471.0190910861635
evaluation/Actions Mean        -0.005213612
evaluation/Actions Std         0.4353356
evaluation/Actions Max         0.999764
evaluation/Actions Min         -0.99943894
evaluation/Num Paths           10
evaluation/Average Returns     478.49513350126506
time/data storing (s)          0.032352250069379807
time/evaluation sampling (s)   112.95722376927733
time/exploration sampling (s)  113.34678982384503
time/logging (s)               0.030448898673057556
time/saving (s)                0.010300819762051105
time/training (s)              9.610286355018616
time/epoch (s)                 235.98740191664547
time/total (s)                 82274.22655347548
Epoch                          351
-----------------------------  ---------------------
2023-08-01 16:49:14.463712 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 352 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4199.921]
trainer/QF1 Loss               0.029839285
trainer/QF2 Loss               0.01714304
trainer/Policy Loss            -92.93584
trainer/Q1 Predictions Mean    104.22711
trainer/Q1 Predictions Std     2.1869166
trainer/Q1 Predictions Max     106.05147
trainer/Q1 Predictions Min     76.92718
trainer/Q2 Predictions Mean    104.17014
trainer/Q2 Predictions Std     2.1444829
trainer/Q2 Predictions Max     106.022644
trainer/Q2 Predictions Min     77.75582
trainer/Q Targets Mean         104.11003
trainer/Q Targets Std          2.1785517
trainer/Q Targets Max          105.95392
trainer/Q Targets Min          77.0893
trainer/Log Pis Mean           11.346176
trainer/Log Pis Std            8.313507
trainer/Log Pis Max            50.102993
trainer/Log Pis Min            -5.800295
trainer/Policy mu Mean         -0.010625973
trainer/Policy mu Std          1.5774463
trainer/Policy mu Max          7.7326207
trainer/Policy mu Min          -5.380201
trainer/Policy log std Mean    -0.6988664
trainer/Policy log std Std     0.2754405
trainer/Policy log std Max     0.6557681
trainer/Policy log std Min     -1.8382392
trainer/Alpha                  0.0014420042280107737
trainer/Alpha Loss             -4.277062892913818
exploration/num steps total    1766000
exploration/num paths total    3532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9478914830888371
exploration/Rewards Std        0.06173678371301699
exploration/Rewards Max        0.9784393670577892
exploration/Rewards Min        0.4967182015218177
exploration/Returns Mean       473.9457415444185
exploration/Returns Std        2.4394391550756604
exploration/Returns Max        477.0745777643972
exploration/Returns Min        468.46902311077054
exploration/Actions Mean       -0.0017541287
exploration/Actions Std        0.61547196
exploration/Actions Max        0.9999971
exploration/Actions Min        -0.99998206
exploration/Num Paths          10
exploration/Average Returns    473.9457415444185
evaluation/num steps total     1765000
evaluation/num paths total     3530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9503219582404531
evaluation/Rewards Std         0.054854380516942
evaluation/Rewards Max         0.9776706090975369
evaluation/Rewards Min         0.4853058542608693
evaluation/Returns Mean        475.16097912022633
evaluation/Returns Std         1.5517510177434755
evaluation/Returns Max         476.4915378100532
evaluation/Returns Min         471.01161032332845
evaluation/ExplReturns Mean    475.16097912022633
evaluation/ExplReturns Std     1.5517510177434755
evaluation/ExplReturns Max     476.4915378100532
evaluation/ExplReturns Min     471.01161032332845
evaluation/Actions Mean        -0.012485513
evaluation/Actions Std         0.51677907
evaluation/Actions Max         0.99996483
evaluation/Actions Min         -0.9993474
evaluation/Num Paths           10
evaluation/Average Returns     475.16097912022633
time/data storing (s)          0.03194207791239023
time/evaluation sampling (s)   109.76641681231558
time/exploration sampling (s)  111.83723088912666
time/logging (s)               0.030410390347242355
time/saving (s)                0.01261228509247303
time/training (s)              9.852802283130586
time/epoch (s)                 231.53141473792493
time/total (s)                 82505.76041889656
Epoch                          352
-----------------------------  ---------------------
2023-08-01 16:53:03.538080 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 353 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4157.513]
trainer/QF1 Loss               0.020661294
trainer/QF2 Loss               0.028065734
trainer/Policy Loss            -92.44658
trainer/Q1 Predictions Mean    104.07161
trainer/Q1 Predictions Std     1.5718089
trainer/Q1 Predictions Max     106.613304
trainer/Q1 Predictions Min     97.65939
trainer/Q2 Predictions Mean    104.00627
trainer/Q2 Predictions Std     1.5480604
trainer/Q2 Predictions Max     106.52297
trainer/Q2 Predictions Min     97.442116
trainer/Q Targets Mean         104.11206
trainer/Q Targets Std          1.5654504
trainer/Q Targets Max          106.24382
trainer/Q Targets Min          97.60244
trainer/Log Pis Mean           11.659075
trainer/Log Pis Std            7.8028874
trainer/Log Pis Max            36.835533
trainer/Log Pis Min            -4.6622396
trainer/Policy mu Mean         -0.060843945
trainer/Policy mu Std          1.556607
trainer/Policy mu Max          5.841807
trainer/Policy mu Min          -5.226959
trainer/Policy log std Mean    -0.72823715
trainer/Policy log std Std     0.26575935
trainer/Policy log std Max     0.45818472
trainer/Policy log std Min     -2.3988464
trainer/Alpha                  0.0015040342696011066
trainer/Alpha Loss             -2.2158851623535156
exploration/num steps total    1771000
exploration/num paths total    3542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.956242610583743
exploration/Rewards Std        0.0514241588576009
exploration/Rewards Max        0.979871429306818
exploration/Rewards Min        0.5040272219055016
exploration/Returns Mean       478.12130529187164
exploration/Returns Std        1.4835564414070792
exploration/Returns Max        479.21701120196036
exploration/Returns Min        473.77283399042506
exploration/Actions Mean       -0.015029797
exploration/Actions Std        0.5892213
exploration/Actions Max        0.9999754
exploration/Actions Min        -0.9998876
exploration/Num Paths          10
exploration/Average Returns    478.12130529187164
evaluation/num steps total     1770000
evaluation/num paths total     3540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9591020381882815
evaluation/Rewards Std         0.04989331838855803
evaluation/Rewards Max         0.9791765153139727
evaluation/Rewards Min         0.4923461305548375
evaluation/Returns Mean        479.5510190941407
evaluation/Returns Std         0.7620986875911484
evaluation/Returns Max         481.0024814115588
evaluation/Returns Min         478.6331618902528
evaluation/ExplReturns Mean    479.5510190941407
evaluation/ExplReturns Std     0.7620986875911484
evaluation/ExplReturns Max     481.0024814115588
evaluation/ExplReturns Min     478.6331618902528
evaluation/Actions Mean        -0.021171216
evaluation/Actions Std         0.4579957
evaluation/Actions Max         0.9996971
evaluation/Actions Min         -0.9996958
evaluation/Num Paths           10
evaluation/Average Returns     479.5510190941407
time/data storing (s)          0.031992590986192226
time/evaluation sampling (s)   108.8997959131375
time/exploration sampling (s)  111.2452046694234
time/logging (s)               0.030270159244537354
time/saving (s)                0.012820000760257244
time/training (s)              8.848524823784828
time/epoch (s)                 229.0686081573367
time/total (s)                 82734.83158546686
Epoch                          353
-----------------------------  ---------------------
2023-08-01 16:56:58.513092 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 354 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4154.025]
trainer/QF1 Loss               0.028075265
trainer/QF2 Loss               0.030345712
trainer/Policy Loss            -91.4145
trainer/Q1 Predictions Mean    104.13428
trainer/Q1 Predictions Std     1.4811958
trainer/Q1 Predictions Max     105.770454
trainer/Q1 Predictions Min     92.68253
trainer/Q2 Predictions Mean    104.14152
trainer/Q2 Predictions Std     1.4852772
trainer/Q2 Predictions Max     105.75974
trainer/Q2 Predictions Min     92.766884
trainer/Q Targets Mean         104.07385
trainer/Q Targets Std          1.5271912
trainer/Q Targets Max          105.658005
trainer/Q Targets Min          92.98702
trainer/Log Pis Mean           12.786276
trainer/Log Pis Std            8.184413
trainer/Log Pis Max            55.145004
trainer/Log Pis Min            -6.656902
trainer/Policy mu Mean         -0.25693128
trainer/Policy mu Std          1.639258
trainer/Policy mu Max          6.0941114
trainer/Policy mu Min          -5.1321955
trainer/Policy log std Mean    -0.6993397
trainer/Policy log std Std     0.26810703
trainer/Policy log std Max     0.09496462
trainer/Policy log std Min     -1.7775831
trainer/Alpha                  0.0015030126087367535
trainer/Alpha Loss             5.111353874206543
exploration/num steps total    1776000
exploration/num paths total    3552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9398232226974679
exploration/Rewards Std        0.08145535078019595
exploration/Rewards Max        0.9773247610346574
exploration/Rewards Min        0.40294940948192504
exploration/Returns Mean       469.9116113487338
exploration/Returns Std        14.570353892790736
exploration/Returns Max        477.4454593628658
exploration/Returns Min        430.4249103260054
exploration/Actions Mean       0.014998019
exploration/Actions Std        0.6320124
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999815
exploration/Num Paths          10
exploration/Average Returns    469.9116113487338
evaluation/num steps total     1775000
evaluation/num paths total     3550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9080692189872279
evaluation/Rewards Std         0.12206813773146964
evaluation/Rewards Max         0.9794340841489192
evaluation/Rewards Min         0.3601482801855646
evaluation/Returns Mean        454.03460949361397
evaluation/Returns Std         44.423338728305566
evaluation/Returns Max         477.8954866599814
evaluation/Returns Min         354.18784211292717
evaluation/ExplReturns Mean    454.03460949361397
evaluation/ExplReturns Std     44.423338728305566
evaluation/ExplReturns Max     477.8954866599814
evaluation/ExplReturns Min     354.18784211292717
evaluation/Actions Mean        0.05661545
evaluation/Actions Std         0.5624447
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.9999957
evaluation/Num Paths           10
evaluation/Average Returns     454.03460949361397
time/data storing (s)          0.03169353865087032
time/evaluation sampling (s)   112.55334035679698
time/exploration sampling (s)  112.5511909276247
time/logging (s)               0.030454098246991634
time/saving (s)                0.01234982255846262
time/training (s)              9.790505858138204
time/epoch (s)                 234.9695346020162
time/total (s)                 82969.80365243834
Epoch                          354
-----------------------------  ---------------------
2023-08-01 17:00:50.057648 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 355 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3826.411]
trainer/QF1 Loss               0.034604307
trainer/QF2 Loss               0.016041175
trainer/Policy Loss            -91.77389
trainer/Q1 Predictions Mean    103.531815
trainer/Q1 Predictions Std     4.393074
trainer/Q1 Predictions Max     105.48767
trainer/Q1 Predictions Min     55.280724
trainer/Q2 Predictions Mean    103.56923
trainer/Q2 Predictions Std     4.4058204
trainer/Q2 Predictions Max     105.589806
trainer/Q2 Predictions Min     55.144176
trainer/Q Targets Mean         103.59437
trainer/Q Targets Std          4.387102
trainer/Q Targets Max          105.52946
trainer/Q Targets Min          55.7419
trainer/Log Pis Mean           11.877387
trainer/Log Pis Std            7.647159
trainer/Log Pis Max            52.687183
trainer/Log Pis Min            -4.561126
trainer/Policy mu Mean         -0.07406319
trainer/Policy mu Std          1.5861071
trainer/Policy mu Max          5.7856417
trainer/Policy mu Min          -6.522895
trainer/Policy log std Mean    -0.72219306
trainer/Policy log std Std     0.28196618
trainer/Policy log std Max     0.2694075
trainer/Policy log std Min     -1.9098203
trainer/Alpha                  0.0015252692392095923
trainer/Alpha Loss             -0.7952127456665039
exploration/num steps total    1781000
exploration/num paths total    3562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9145741650147671
exploration/Rewards Std        0.09696496205774759
exploration/Rewards Max        0.9782287274248038
exploration/Rewards Min        0.48346575115693274
exploration/Returns Mean       457.28708250738373
exploration/Returns Std        20.147852928342214
exploration/Returns Max        480.7816343022225
exploration/Returns Min        432.0343501679359
exploration/Actions Mean       0.034795675
exploration/Actions Std        0.57576954
exploration/Actions Max        0.99986374
exploration/Actions Min        -0.9999677
exploration/Num Paths          10
exploration/Average Returns    457.28708250738373
evaluation/num steps total     1780000
evaluation/num paths total     3560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8365588196326523
evaluation/Rewards Std         0.10716284751818018
evaluation/Rewards Max         0.9784765927111178
evaluation/Rewards Min         0.4934863208134395
evaluation/Returns Mean        418.27940981632617
evaluation/Returns Std         41.279459843075365
evaluation/Returns Max         481.5217569026716
evaluation/Returns Min         387.22930691964416
evaluation/ExplReturns Mean    418.27940981632617
evaluation/ExplReturns Std     41.279459843075365
evaluation/ExplReturns Max     481.5217569026716
evaluation/ExplReturns Min     387.22930691964416
evaluation/Actions Mean        0.065706044
evaluation/Actions Std         0.46863335
evaluation/Actions Max         0.9991262
evaluation/Actions Min         -0.9998363
evaluation/Num Paths           10
evaluation/Average Returns     418.27940981632617
time/data storing (s)          0.03168335743248463
time/evaluation sampling (s)   110.1500947708264
time/exploration sampling (s)  111.45819142088294
time/logging (s)               0.030692431144416332
time/saving (s)                0.01289608608931303
time/training (s)              9.855647212825716
time/epoch (s)                 231.53920527920127
time/total (s)                 83201.3453298686
Epoch                          355
-----------------------------  ---------------------
2023-08-01 17:04:48.221907 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 356 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3969.5247]
trainer/QF1 Loss               0.035312824
trainer/QF2 Loss               0.022079319
trainer/Policy Loss            -92.254745
trainer/Q1 Predictions Mean    103.86655
trainer/Q1 Predictions Std     1.9880003
trainer/Q1 Predictions Max     105.39887
trainer/Q1 Predictions Min     82.0579
trainer/Q2 Predictions Mean    103.95297
trainer/Q2 Predictions Std     1.9554851
trainer/Q2 Predictions Max     105.524765
trainer/Q2 Predictions Min     82.48931
trainer/Q Targets Mean         103.96953
trainer/Q Targets Std          1.9309686
trainer/Q Targets Max          105.42749
trainer/Q Targets Min          82.862114
trainer/Log Pis Mean           11.740337
trainer/Log Pis Std            7.739402
trainer/Log Pis Max            43.87878
trainer/Log Pis Min            -4.3237114
trainer/Policy mu Mean         0.11572621
trainer/Policy mu Std          1.6250226
trainer/Policy mu Max          6.616475
trainer/Policy mu Min          -5.5520763
trainer/Policy log std Mean    -0.6625977
trainer/Policy log std Std     0.28481677
trainer/Policy log std Max     0.21753442
trainer/Policy log std Min     -2.0749362
trainer/Alpha                  0.001665708376094699
trainer/Alpha Loss             -1.661177635192871
exploration/num steps total    1786000
exploration/num paths total    3572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8379008813156282
exploration/Rewards Std        0.1392590688338918
exploration/Rewards Max        0.9780097700235681
exploration/Rewards Min        0.5043629122311246
exploration/Returns Mean       418.95044065781406
exploration/Returns Std        47.54639925356417
exploration/Returns Max        481.4202170073366
exploration/Returns Min        362.586359990578
exploration/Actions Mean       0.05027294
exploration/Actions Std        0.70915604
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    418.95044065781406
evaluation/num steps total     1785000
evaluation/num paths total     3570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8752446406930827
evaluation/Rewards Std         0.13831368068975142
evaluation/Rewards Max         0.9796569096704384
evaluation/Rewards Min         0.3880065367185062
evaluation/Returns Mean        437.62232034654136
evaluation/Returns Std         48.48464387597103
evaluation/Returns Max         481.13137103056584
evaluation/Returns Min         363.03784940792656
evaluation/ExplReturns Mean    437.62232034654136
evaluation/ExplReturns Std     48.48464387597103
evaluation/ExplReturns Max     481.13137103056584
evaluation/ExplReturns Min     363.03784940792656
evaluation/Actions Mean        0.04434803
evaluation/Actions Std         0.62727374
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     437.62232034654136
time/data storing (s)          0.032295770943164825
time/evaluation sampling (s)   113.79066289775074
time/exploration sampling (s)  114.77916203252971
time/logging (s)               0.030532972887158394
time/saving (s)                0.01081691775470972
time/training (s)              9.515057759359479
time/epoch (s)                 238.15852835122496
time/total (s)                 83439.50633509364
Epoch                          356
-----------------------------  --------------------
2023-08-01 17:08:42.020107 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 357 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4139.9688]
trainer/QF1 Loss               0.038589526
trainer/QF2 Loss               0.029763408
trainer/Policy Loss            -91.236176
trainer/Q1 Predictions Mean    103.745636
trainer/Q1 Predictions Std     2.5802822
trainer/Q1 Predictions Max     107.46498
trainer/Q1 Predictions Min     79.6669
trainer/Q2 Predictions Mean    103.76657
trainer/Q2 Predictions Std     2.5817144
trainer/Q2 Predictions Max     107.811104
trainer/Q2 Predictions Min     79.60113
trainer/Q Targets Mean         103.78656
trainer/Q Targets Std          2.6162539
trainer/Q Targets Max          107.35342
trainer/Q Targets Min          80.387474
trainer/Log Pis Mean           12.621466
trainer/Log Pis Std            9.122839
trainer/Log Pis Max            67.09677
trainer/Log Pis Min            -1.3197894
trainer/Policy mu Mean         0.009807881
trainer/Policy mu Std          1.6492581
trainer/Policy mu Max          8.755178
trainer/Policy mu Min          -5.815639
trainer/Policy log std Mean    -0.68744373
trainer/Policy log std Std     0.2947458
trainer/Policy log std Max     0.43521708
trainer/Policy log std Min     -2.2789233
trainer/Alpha                  0.0016494484152644873
trainer/Alpha Loss             3.9819865226745605
exploration/num steps total    1791000
exploration/num paths total    3582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8937719147679507
exploration/Rewards Std        0.14068690557087601
exploration/Rewards Max        0.9796486323698599
exploration/Rewards Min        0.3009411357696132
exploration/Returns Mean       446.88595738397527
exploration/Returns Std        51.41775404619956
exploration/Returns Max        478.54102759039495
exploration/Returns Min        315.8207438634276
exploration/Actions Mean       0.075179406
exploration/Actions Std        0.64786136
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999992
exploration/Num Paths          10
exploration/Average Returns    446.88595738397527
evaluation/num steps total     1790000
evaluation/num paths total     3580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9379431726711864
evaluation/Rewards Std         0.08286100923844161
evaluation/Rewards Max         0.9787319618645122
evaluation/Rewards Min         0.48612742641305556
evaluation/Returns Mean        468.97158633559303
evaluation/Returns Std         28.79320355174358
evaluation/Returns Max         480.1263540637968
evaluation/Returns Min         383.0135964124415
evaluation/ExplReturns Mean    468.97158633559303
evaluation/ExplReturns Std     28.79320355174358
evaluation/ExplReturns Max     480.1263540637968
evaluation/ExplReturns Min     383.0135964124415
evaluation/Actions Mean        0.0287676
evaluation/Actions Std         0.5196017
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999464
evaluation/Num Paths           10
evaluation/Average Returns     468.97158633559303
time/data storing (s)          0.03210835065692663
time/evaluation sampling (s)   111.51179960463196
time/exploration sampling (s)  112.60574871115386
time/logging (s)               0.030601459555327892
time/saving (s)                0.01032299641519785
time/training (s)              9.602029461413622
time/epoch (s)                 233.7926105838269
time/total (s)                 83673.30152885336
Epoch                          357
-----------------------------  ---------------------
2023-08-01 17:12:35.302656 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 358 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3930.2302]
trainer/QF1 Loss               0.033557765
trainer/QF2 Loss               0.027806792
trainer/Policy Loss            -92.11989
trainer/Q1 Predictions Mean    103.91547
trainer/Q1 Predictions Std     1.6847446
trainer/Q1 Predictions Max     106.56612
trainer/Q1 Predictions Min     92.445885
trainer/Q2 Predictions Mean    103.95087
trainer/Q2 Predictions Std     1.6516601
trainer/Q2 Predictions Max     106.558685
trainer/Q2 Predictions Min     93.36945
trainer/Q Targets Mean         104.02306
trainer/Q Targets Std          1.6916258
trainer/Q Targets Max          106.39245
trainer/Q Targets Min          92.17304
trainer/Log Pis Mean           11.909069
trainer/Log Pis Std            7.3736687
trainer/Log Pis Max            38.575703
trainer/Log Pis Min            -3.6587107
trainer/Policy mu Mean         0.117954575
trainer/Policy mu Std          1.5862609
trainer/Policy mu Max          6.0713143
trainer/Policy mu Min          -5.9388757
trainer/Policy log std Mean    -0.6897357
trainer/Policy log std Std     0.28092638
trainer/Policy log std Max     0.6820863
trainer/Policy log std Min     -2.1650448
trainer/Alpha                  0.001606450416147709
trainer/Alpha Loss             -0.5850415229797363
exploration/num steps total    1796000
exploration/num paths total    3592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9542956219156811
exploration/Rewards Std        0.059776689620027974
exploration/Rewards Max        0.9779495904081532
exploration/Rewards Min        0.4939279724322595
exploration/Returns Mean       477.14781095784076
exploration/Returns Std        2.2825355482536507
exploration/Returns Max        478.9924699291921
exploration/Returns Min        470.70166258460245
exploration/Actions Mean       -0.0016628479
exploration/Actions Std        0.58653694
exploration/Actions Max        0.9999656
exploration/Actions Min        -0.9999801
exploration/Num Paths          10
exploration/Average Returns    477.14781095784076
evaluation/num steps total     1795000
evaluation/num paths total     3590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9589796006865364
evaluation/Rewards Std         0.05510872323380795
evaluation/Rewards Max         0.9788266336558238
evaluation/Rewards Min         0.49686262579206925
evaluation/Returns Mean        479.48980034326826
evaluation/Returns Std         0.46935249028311404
evaluation/Returns Max         479.9581595974521
evaluation/Returns Min         478.2203196217603
evaluation/ExplReturns Mean    479.48980034326826
evaluation/ExplReturns Std     0.46935249028311404
evaluation/ExplReturns Max     479.9581595974521
evaluation/ExplReturns Min     478.2203196217603
evaluation/Actions Mean        -0.018738914
evaluation/Actions Std         0.4433002
evaluation/Actions Max         0.9999462
evaluation/Actions Min         -0.99967396
evaluation/Num Paths           10
evaluation/Average Returns     479.48980034326826
time/data storing (s)          0.03197985701262951
time/evaluation sampling (s)   111.16655790712684
time/exploration sampling (s)  112.36840922292322
time/logging (s)               0.03050416149199009
time/saving (s)                0.012740873731672764
time/training (s)              9.666512755677104
time/epoch (s)                 233.27670477796346
time/total (s)                 83906.58086758759
Epoch                          358
-----------------------------  --------------------
2023-08-01 17:16:25.256143 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 359 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3818.6655]
trainer/QF1 Loss               0.036715314
trainer/QF2 Loss               0.029908903
trainer/Policy Loss            -91.27746
trainer/Q1 Predictions Mean    103.63772
trainer/Q1 Predictions Std     3.6544752
trainer/Q1 Predictions Max     105.295906
trainer/Q1 Predictions Min     65.87551
trainer/Q2 Predictions Mean    103.61259
trainer/Q2 Predictions Std     3.6635993
trainer/Q2 Predictions Max     105.29584
trainer/Q2 Predictions Min     65.049484
trainer/Q Targets Mean         103.58069
trainer/Q Targets Std          3.5865111
trainer/Q Targets Max          105.22522
trainer/Q Targets Min          65.64774
trainer/Log Pis Mean           12.425292
trainer/Log Pis Std            8.524405
trainer/Log Pis Max            48.428726
trainer/Log Pis Min            -8.057484
trainer/Policy mu Mean         0.025727084
trainer/Policy mu Std          1.6424323
trainer/Policy mu Max          8.64003
trainer/Policy mu Min          -5.3660355
trainer/Policy log std Mean    -0.68356246
trainer/Policy log std Std     0.27377772
trainer/Policy log std Max     1.211073
trainer/Policy log std Min     -1.9112066
trainer/Alpha                  0.001610020874068141
trainer/Alpha Loss             2.735356092453003
exploration/num steps total    1801000
exploration/num paths total    3602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9576348104306824
exploration/Rewards Std        0.05484538654299656
exploration/Rewards Max        0.9789304409932866
exploration/Rewards Min        0.4872406866863952
exploration/Returns Mean       478.8174052153412
exploration/Returns Std        1.5835186258416074
exploration/Returns Max        480.68473653981437
exploration/Returns Min        475.4714523438671
exploration/Actions Mean       -0.00385667
exploration/Actions Std        0.56306726
exploration/Actions Max        0.99989456
exploration/Actions Min        -0.9999633
exploration/Num Paths          10
exploration/Average Returns    478.8174052153412
evaluation/num steps total     1800000
evaluation/num paths total     3600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9585828789626983
evaluation/Rewards Std         0.05158266139741933
evaluation/Rewards Max         0.9781122429249369
evaluation/Rewards Min         0.4831287695602369
evaluation/Returns Mean        479.2914394813491
evaluation/Returns Std         2.2149969528899605
evaluation/Returns Max         482.77046849987994
evaluation/Returns Min         477.38112955274175
evaluation/ExplReturns Mean    479.2914394813491
evaluation/ExplReturns Std     2.2149969528899605
evaluation/ExplReturns Max     482.77046849987994
evaluation/ExplReturns Min     477.38112955274175
evaluation/Actions Mean        -0.018689143
evaluation/Actions Std         0.37659726
evaluation/Actions Max         0.9991831
evaluation/Actions Min         -0.99944425
evaluation/Num Paths           10
evaluation/Average Returns     479.2914394813491
time/data storing (s)          0.032436832785606384
time/evaluation sampling (s)   109.8512267805636
time/exploration sampling (s)  110.39549441076815
time/logging (s)               0.03077811747789383
time/saving (s)                0.011597566306591034
time/training (s)              9.626570359803736
time/epoch (s)                 229.94810406770557
time/total (s)                 84136.53147685714
Epoch                          359
-----------------------------  --------------------
2023-08-01 17:20:18.171129 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 360 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3705.383]
trainer/QF1 Loss               0.032141343
trainer/QF2 Loss               0.016912729
trainer/Policy Loss            -92.63786
trainer/Q1 Predictions Mean    104.15898
trainer/Q1 Predictions Std     2.2540514
trainer/Q1 Predictions Max     106.14104
trainer/Q1 Predictions Min     76.30772
trainer/Q2 Predictions Mean    103.99882
trainer/Q2 Predictions Std     2.2004483
trainer/Q2 Predictions Max     106.14362
trainer/Q2 Predictions Min     76.968765
trainer/Q Targets Mean         104.03284
trainer/Q Targets Std          2.2433748
trainer/Q Targets Max          106.32611
trainer/Q Targets Min          76.109886
trainer/Log Pis Mean           11.485811
trainer/Log Pis Std            8.08609
trainer/Log Pis Max            62.555058
trainer/Log Pis Min            -4.223376
trainer/Policy mu Mean         -0.06582902
trainer/Policy mu Std          1.5522854
trainer/Policy mu Max          8.476039
trainer/Policy mu Min          -5.3370895
trainer/Policy log std Mean    -0.71150523
trainer/Policy log std Std     0.28167623
trainer/Policy log std Max     0.38809344
trainer/Policy log std Min     -1.8521398
trainer/Alpha                  0.0015432678628712893
trainer/Alpha Loss             -3.3288052082061768
exploration/num steps total    1806000
exploration/num paths total    3612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9506940724160817
exploration/Rewards Std        0.05641091610014568
exploration/Rewards Max        0.9779463129597714
exploration/Rewards Min        0.4965037475752281
exploration/Returns Mean       475.34703620804095
exploration/Returns Std        1.367891621809835
exploration/Returns Max        477.35647770542784
exploration/Returns Min        472.2253848685339
exploration/Actions Mean       0.029820012
exploration/Actions Std        0.5866025
exploration/Actions Max        0.9999772
exploration/Actions Min        -0.99991274
exploration/Num Paths          10
exploration/Average Returns    475.34703620804095
evaluation/num steps total     1805000
evaluation/num paths total     3610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9517251795440207
evaluation/Rewards Std         0.0527427213242727
evaluation/Rewards Max         0.9777100863559485
evaluation/Rewards Min         0.4953879449181005
evaluation/Returns Mean        475.86258977201044
evaluation/Returns Std         1.0118063441220955
evaluation/Returns Max         476.33908220436393
evaluation/Returns Min         472.8484641606834
evaluation/ExplReturns Mean    475.86258977201044
evaluation/ExplReturns Std     1.0118063441220955
evaluation/ExplReturns Max     476.33908220436393
evaluation/ExplReturns Min     472.8484641606834
evaluation/Actions Mean        0.045973346
evaluation/Actions Std         0.40997288
evaluation/Actions Max         0.99967754
evaluation/Actions Min         -0.99936616
evaluation/Num Paths           10
evaluation/Average Returns     475.86258977201044
time/data storing (s)          0.03249678947031498
time/evaluation sampling (s)   112.44320010021329
time/exploration sampling (s)  111.59244219679385
time/logging (s)               0.030331464484333992
time/saving (s)                0.010561160743236542
time/training (s)              8.799901878461242
time/epoch (s)                 232.90893359016627
time/total (s)                 84369.44291412458
Epoch                          360
-----------------------------  ---------------------
2023-08-01 17:24:09.511625 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 361 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3891.6726]
trainer/QF1 Loss               0.035372756
trainer/QF2 Loss               0.032397747
trainer/Policy Loss            -92.283775
trainer/Q1 Predictions Mean    103.80403
trainer/Q1 Predictions Std     2.2245889
trainer/Q1 Predictions Max     105.13657
trainer/Q1 Predictions Min     84.47205
trainer/Q2 Predictions Mean    103.66895
trainer/Q2 Predictions Std     2.2159655
trainer/Q2 Predictions Max     105.070724
trainer/Q2 Predictions Min     85.09509
trainer/Q Targets Mean         103.681114
trainer/Q Targets Std          2.2821743
trainer/Q Targets Max          105.06288
trainer/Q Targets Min          83.639984
trainer/Log Pis Mean           11.476363
trainer/Log Pis Std            7.797374
trainer/Log Pis Max            41.892975
trainer/Log Pis Min            -3.5572197
trainer/Policy mu Mean         0.0319502
trainer/Policy mu Std          1.5771695
trainer/Policy mu Max          5.9358153
trainer/Policy mu Min          -6.0156455
trainer/Policy log std Mean    -0.71846896
trainer/Policy log std Std     0.29082382
trainer/Policy log std Max     0.15851831
trainer/Policy log std Min     -2.1056206
trainer/Alpha                  0.0014622845919802785
trainer/Alpha Loss             -3.418177366256714
exploration/num steps total    1811000
exploration/num paths total    3622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9523412184551798
exploration/Rewards Std        0.05052793021093621
exploration/Rewards Max        0.9795824881890479
exploration/Rewards Min        0.4986392639751356
exploration/Returns Mean       476.1706092275898
exploration/Returns Std        1.0725303498527985
exploration/Returns Max        477.23531112548693
exploration/Returns Min        473.26322559411824
exploration/Actions Mean       0.0015539061
exploration/Actions Std        0.6276882
exploration/Actions Max        0.9999986
exploration/Actions Min        -0.99991095
exploration/Num Paths          10
exploration/Average Returns    476.1706092275898
evaluation/num steps total     1810000
evaluation/num paths total     3620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9493670546957182
evaluation/Rewards Std         0.048205144596897474
evaluation/Rewards Max         0.9785763517393093
evaluation/Rewards Min         0.493935407453093
evaluation/Returns Mean        474.6835273478591
evaluation/Returns Std         0.8305485710679111
evaluation/Returns Max         475.64726162098754
evaluation/Returns Min         473.0190517602098
evaluation/ExplReturns Mean    474.6835273478591
evaluation/ExplReturns Std     0.8305485710679111
evaluation/ExplReturns Max     475.64726162098754
evaluation/ExplReturns Min     473.0190517602098
evaluation/Actions Mean        0.029147733
evaluation/Actions Std         0.44418898
evaluation/Actions Max         0.99980336
evaluation/Actions Min         -0.99957216
evaluation/Num Paths           10
evaluation/Average Returns     474.6835273478591
time/data storing (s)          0.03218643367290497
time/evaluation sampling (s)   110.50082631781697
time/exploration sampling (s)  111.16189710609615
time/logging (s)               0.030981499701738358
time/saving (s)                0.010416326113045216
time/training (s)              9.5992112737149
time/epoch (s)                 231.3355189571157
time/total (s)                 84600.78091958724
Epoch                          361
-----------------------------  ---------------------
2023-08-01 17:28:00.551441 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 362 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3888.2646]
trainer/QF1 Loss               0.03103062
trainer/QF2 Loss               0.023632228
trainer/Policy Loss            -90.670395
trainer/Q1 Predictions Mean    103.37792
trainer/Q1 Predictions Std     2.7742982
trainer/Q1 Predictions Max     105.01552
trainer/Q1 Predictions Min     74.20157
trainer/Q2 Predictions Mean    103.43269
trainer/Q2 Predictions Std     2.7945373
trainer/Q2 Predictions Max     105.02744
trainer/Q2 Predictions Min     73.948975
trainer/Q Targets Mean         103.4914
trainer/Q Targets Std          2.816939
trainer/Q Targets Max          105.04243
trainer/Q Targets Min          74.078224
trainer/Log Pis Mean           12.831108
trainer/Log Pis Std            9.2086115
trainer/Log Pis Max            76.82875
trainer/Log Pis Min            -4.9721737
trainer/Policy mu Mean         0.09458343
trainer/Policy mu Std          1.6682855
trainer/Policy mu Max          15.778133
trainer/Policy mu Min          -5.098505
trainer/Policy log std Mean    -0.7499271
trainer/Policy log std Std     0.32084844
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.9137497
trainer/Alpha                  0.0013696125242859125
trainer/Alpha Loss             5.479681968688965
exploration/num steps total    1816000
exploration/num paths total    3632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9554361901836456
exploration/Rewards Std        0.05461038871786227
exploration/Rewards Max        0.9784482289435896
exploration/Rewards Min        0.4801565097092711
exploration/Returns Mean       477.71809509182305
exploration/Returns Std        0.8639775454093778
exploration/Returns Max        478.706050920332
exploration/Returns Min        476.0911618946936
exploration/Actions Mean       -0.02024839
exploration/Actions Std        0.61630744
exploration/Actions Max        0.99993265
exploration/Actions Min        -0.9999245
exploration/Num Paths          10
exploration/Average Returns    477.71809509182305
evaluation/num steps total     1815000
evaluation/num paths total     3630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9559906176953314
evaluation/Rewards Std         0.052443718479714796
evaluation/Rewards Max         0.9791849391141594
evaluation/Rewards Min         0.4864274501287952
evaluation/Returns Mean        477.9953088476656
evaluation/Returns Std         0.5402537100574081
evaluation/Returns Max         478.84890013109174
evaluation/Returns Min         477.2996207197518
evaluation/ExplReturns Mean    477.9953088476656
evaluation/ExplReturns Std     0.5402537100574081
evaluation/ExplReturns Max     478.84890013109174
evaluation/ExplReturns Min     477.2996207197518
evaluation/Actions Mean        -0.02997797
evaluation/Actions Std         0.5327414
evaluation/Actions Max         0.9998821
evaluation/Actions Min         -0.9995792
evaluation/Num Paths           10
evaluation/Average Returns     477.9953088476656
time/data storing (s)          0.032416364178061485
time/evaluation sampling (s)   109.87375438027084
time/exploration sampling (s)  110.92370023019612
time/logging (s)               0.030783974565565586
time/saving (s)                0.010353738442063332
time/training (s)              10.162972463294864
time/epoch (s)                 231.0339811509475
time/total (s)                 84831.8173788609
Epoch                          362
-----------------------------  ---------------------
2023-08-01 17:31:53.940388 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 363 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3801.2983]
trainer/QF1 Loss               0.01838741
trainer/QF2 Loss               0.019804247
trainer/Policy Loss            -90.65611
trainer/Q1 Predictions Mean    103.50197
trainer/Q1 Predictions Std     2.1483219
trainer/Q1 Predictions Max     104.90958
trainer/Q1 Predictions Min     81.395905
trainer/Q2 Predictions Mean    103.52397
trainer/Q2 Predictions Std     2.1416953
trainer/Q2 Predictions Max     104.89243
trainer/Q2 Predictions Min     81.50393
trainer/Q Targets Mean         103.50752
trainer/Q Targets Std          2.173324
trainer/Q Targets Max          104.945465
trainer/Q Targets Min          80.842445
trainer/Log Pis Mean           12.9450245
trainer/Log Pis Std            7.6605616
trainer/Log Pis Max            36.212395
trainer/Log Pis Min            -7.3225737
trainer/Policy mu Mean         0.07322962
trainer/Policy mu Std          1.6165435
trainer/Policy mu Max          5.8666596
trainer/Policy mu Min          -5.3858533
trainer/Policy log std Mean    -0.7700121
trainer/Policy log std Std     0.3117502
trainer/Policy log std Max     0.022498906
trainer/Policy log std Min     -2.0104582
trainer/Alpha                  0.0013204385759308934
trainer/Alpha Loss             6.265582084655762
exploration/num steps total    1821000
exploration/num paths total    3642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9535518082625358
exploration/Rewards Std        0.04956677529287777
exploration/Rewards Max        0.9782963915701588
exploration/Rewards Min        0.49186511027061325
exploration/Returns Mean       476.7759041312678
exploration/Returns Std        0.9743523014829576
exploration/Returns Max        478.1581057954925
exploration/Returns Min        475.0310197462242
exploration/Actions Mean       -0.024674544
exploration/Actions Std        0.56658065
exploration/Actions Max        0.9999768
exploration/Actions Min        -0.99995476
exploration/Num Paths          10
exploration/Average Returns    476.7759041312678
evaluation/num steps total     1820000
evaluation/num paths total     3640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.951731653912849
evaluation/Rewards Std         0.04923579428434791
evaluation/Rewards Max         0.9765975548096503
evaluation/Rewards Min         0.4918614769019598
evaluation/Returns Mean        475.86582695642437
evaluation/Returns Std         0.5766549420940691
evaluation/Returns Max         476.2931501856437
evaluation/Returns Min         474.2737244304909
evaluation/ExplReturns Mean    475.86582695642437
evaluation/ExplReturns Std     0.5766549420940691
evaluation/ExplReturns Max     476.2931501856437
evaluation/ExplReturns Min     474.2737244304909
evaluation/Actions Mean        -0.027538875
evaluation/Actions Std         0.42335576
evaluation/Actions Max         0.99983543
evaluation/Actions Min         -0.9995399
evaluation/Num Paths           10
evaluation/Average Returns     475.86582695642437
time/data storing (s)          0.03204487729817629
time/evaluation sampling (s)   111.44120426848531
time/exploration sampling (s)  112.24878518097103
time/logging (s)               0.030920200049877167
time/saving (s)                0.01260411273688078
time/training (s)              9.617837908677757
time/epoch (s)                 233.38339654821903
time/total (s)                 85065.20328347664
Epoch                          363
-----------------------------  ---------------------
2023-08-01 17:35:49.502477 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 364 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3698.894]
trainer/QF1 Loss               0.03734385
trainer/QF2 Loss               0.024232715
trainer/Policy Loss            -93.71208
trainer/Q1 Predictions Mean    103.77771
trainer/Q1 Predictions Std     2.080488
trainer/Q1 Predictions Max     104.96704
trainer/Q1 Predictions Min     76.72457
trainer/Q2 Predictions Mean    103.70829
trainer/Q2 Predictions Std     2.114884
trainer/Q2 Predictions Max     104.75098
trainer/Q2 Predictions Min     76.191734
trainer/Q Targets Mean         103.63733
trainer/Q Targets Std          2.0773497
trainer/Q Targets Max          104.7364
trainer/Q Targets Min          76.87117
trainer/Log Pis Mean           10.103037
trainer/Log Pis Std            7.6325665
trainer/Log Pis Max            43.75733
trainer/Log Pis Min            -3.498801
trainer/Policy mu Mean         0.019359242
trainer/Policy mu Std          1.4930974
trainer/Policy mu Max          6.3095264
trainer/Policy mu Min          -5.8074026
trainer/Policy log std Mean    -0.7402137
trainer/Policy log std Std     0.30106902
trainer/Policy log std Max     0.104539394
trainer/Policy log std Min     -2.120908
trainer/Alpha                  0.001333146821707487
trainer/Alpha Loss             -12.557955741882324
exploration/num steps total    1826000
exploration/num paths total    3652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9577082237700947
exploration/Rewards Std        0.05103407445556682
exploration/Rewards Max        0.9797971326011545
exploration/Rewards Min        0.4821422447091089
exploration/Returns Mean       478.8541118850473
exploration/Returns Std        2.1316897287896217
exploration/Returns Max        480.45028567720726
exploration/Returns Min        472.56085113375804
exploration/Actions Mean       -0.03228945
exploration/Actions Std        0.6063159
exploration/Actions Max        0.9999663
exploration/Actions Min        -0.99994993
exploration/Num Paths          10
exploration/Average Returns    478.8541118850473
evaluation/num steps total     1825000
evaluation/num paths total     3650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.959862765511468
evaluation/Rewards Std         0.05051277533603637
evaluation/Rewards Max         0.9785977914867292
evaluation/Rewards Min         0.4957609123577369
evaluation/Returns Mean        479.9313827557338
evaluation/Returns Std         0.16514229837661318
evaluation/Returns Max         480.2932915344538
evaluation/Returns Min         479.6574661348151
evaluation/ExplReturns Mean    479.9313827557338
evaluation/ExplReturns Std     0.16514229837661318
evaluation/ExplReturns Max     480.2932915344538
evaluation/ExplReturns Min     479.6574661348151
evaluation/Actions Mean        -0.04215288
evaluation/Actions Std         0.45526147
evaluation/Actions Max         0.9994338
evaluation/Actions Min         -0.9991932
evaluation/Num Paths           10
evaluation/Average Returns     479.9313827557338
time/data storing (s)          0.03202714119106531
time/evaluation sampling (s)   112.73737270850688
time/exploration sampling (s)  113.08638401702046
time/logging (s)               0.03089282289147377
time/saving (s)                0.011927391402423382
time/training (s)              9.657828953117132
time/epoch (s)                 235.55643303412944
time/total (s)                 85300.76214370131
Epoch                          364
-----------------------------  --------------------
2023-08-01 17:39:44.447815 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 365 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3823.2812]
trainer/QF1 Loss               0.029893976
trainer/QF2 Loss               0.020796709
trainer/Policy Loss            -92.58276
trainer/Q1 Predictions Mean    103.48575
trainer/Q1 Predictions Std     1.746215
trainer/Q1 Predictions Max     104.95696
trainer/Q1 Predictions Min     92.66926
trainer/Q2 Predictions Mean    103.36161
trainer/Q2 Predictions Std     1.7284327
trainer/Q2 Predictions Max     104.781746
trainer/Q2 Predictions Min     92.43603
trainer/Q Targets Mean         103.40749
trainer/Q Targets Std          1.711236
trainer/Q Targets Max          104.8118
trainer/Q Targets Min          92.55003
trainer/Log Pis Mean           10.880857
trainer/Log Pis Std            8.929104
trainer/Log Pis Max            50.26707
trainer/Log Pis Min            -5.3280277
trainer/Policy mu Mean         -0.092880666
trainer/Policy mu Std          1.5521487
trainer/Policy mu Max          9.396203
trainer/Policy mu Min          -5.940765
trainer/Policy log std Mean    -0.72931886
trainer/Policy log std Std     0.30977413
trainer/Policy log std Max     0.36970174
trainer/Policy log std Min     -2.406037
trainer/Alpha                  0.0012473211390897632
trainer/Alpha Loss             -7.483095169067383
exploration/num steps total    1831000
exploration/num paths total    3662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9353699921102824
exploration/Rewards Std        0.07145853666129331
exploration/Rewards Max        0.9796389860373064
exploration/Rewards Min        0.4952620435777905
exploration/Returns Mean       467.68499605514114
exploration/Returns Std        6.667986103767592
exploration/Returns Max        480.92253591204206
exploration/Returns Min        458.1778462142325
exploration/Actions Mean       0.022758752
exploration/Actions Std        0.61924475
exploration/Actions Max        0.99987596
exploration/Actions Min        -0.9999924
exploration/Num Paths          10
exploration/Average Returns    467.68499605514114
evaluation/num steps total     1830000
evaluation/num paths total     3660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.942830705749035
evaluation/Rewards Std         0.08396912295150293
evaluation/Rewards Max         0.9793941064321615
evaluation/Rewards Min         0.4932511080502578
evaluation/Returns Mean        471.41535287451745
evaluation/Returns Std         26.69200402594212
evaluation/Returns Max         482.42022488388585
evaluation/Returns Min         392.62067107843706
evaluation/ExplReturns Mean    471.41535287451745
evaluation/ExplReturns Std     26.69200402594212
evaluation/ExplReturns Max     482.42022488388585
evaluation/ExplReturns Min     392.62067107843706
evaluation/Actions Mean        -0.00011994858
evaluation/Actions Std         0.47358668
evaluation/Actions Max         0.99918365
evaluation/Actions Min         -0.9999184
evaluation/Num Paths           10
evaluation/Average Returns     471.41535287451745
time/data storing (s)          0.032347061671316624
time/evaluation sampling (s)   112.24811787717044
time/exploration sampling (s)  112.95220343302935
time/logging (s)               0.031026463024318218
time/saving (s)                0.01271519809961319
time/training (s)              9.663246468640864
time/epoch (s)                 234.9396565016359
time/total (s)                 85535.70431309007
Epoch                          365
-----------------------------  ---------------------
2023-08-01 17:43:35.603665 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 366 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3670.0342]
trainer/QF1 Loss               0.035007127
trainer/QF2 Loss               0.035176814
trainer/Policy Loss            -91.441864
trainer/Q1 Predictions Mean    103.44497
trainer/Q1 Predictions Std     1.8918748
trainer/Q1 Predictions Max     105.1163
trainer/Q1 Predictions Min     89.40228
trainer/Q2 Predictions Mean    103.24139
trainer/Q2 Predictions Std     1.8993798
trainer/Q2 Predictions Max     104.79596
trainer/Q2 Predictions Min     88.770096
trainer/Q Targets Mean         103.354675
trainer/Q Targets Std          1.9289093
trainer/Q Targets Max          104.86398
trainer/Q Targets Min          88.22913
trainer/Log Pis Mean           11.905907
trainer/Log Pis Std            8.7716675
trainer/Log Pis Max            55.970577
trainer/Log Pis Min            -3.0300784
trainer/Policy mu Mean         -0.012494731
trainer/Policy mu Std          1.6033586
trainer/Policy mu Max          5.313031
trainer/Policy mu Min          -9.979984
trainer/Policy log std Mean    -0.72275877
trainer/Policy log std Std     0.31136563
trainer/Policy log std Max     0.26983365
trainer/Policy log std Min     -2.267023
trainer/Alpha                  0.0012566586956381798
trainer/Alpha Loss             -0.6284704208374023
exploration/num steps total    1836000
exploration/num paths total    3672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557139925476047
exploration/Rewards Std        0.05392409115053462
exploration/Rewards Max        0.9797229399625975
exploration/Rewards Min        0.48859447627022956
exploration/Returns Mean       477.85699627380257
exploration/Returns Std        0.7387462676155324
exploration/Returns Max        478.7773795388794
exploration/Returns Min        476.4099792524037
exploration/Actions Mean       -0.03856973
exploration/Actions Std        0.6210558
exploration/Actions Max        0.999855
exploration/Actions Min        -0.99992913
exploration/Num Paths          10
exploration/Average Returns    477.85699627380257
evaluation/num steps total     1835000
evaluation/num paths total     3670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9557413074325943
evaluation/Rewards Std         0.052372703075119535
evaluation/Rewards Max         0.978977316780331
evaluation/Rewards Min         0.4944718815854491
evaluation/Returns Mean        477.8706537162972
evaluation/Returns Std         0.42786465300755566
evaluation/Returns Max         478.5827580525785
evaluation/Returns Min         477.2178565275021
evaluation/ExplReturns Mean    477.8706537162972
evaluation/ExplReturns Std     0.42786465300755566
evaluation/ExplReturns Max     478.5827580525785
evaluation/ExplReturns Min     477.2178565275021
evaluation/Actions Mean        -0.055992056
evaluation/Actions Std         0.47381696
evaluation/Actions Max         0.99936646
evaluation/Actions Min         -0.9992516
evaluation/Num Paths           10
evaluation/Average Returns     477.8706537162972
time/data storing (s)          0.032086572609841824
time/evaluation sampling (s)   110.21113527007401
time/exploration sampling (s)  111.18053839169443
time/logging (s)               0.030983148142695427
time/saving (s)                0.012754085473716259
time/training (s)              9.682544454932213
time/epoch (s)                 231.1500419229269
time/total (s)                 85766.85691909958
Epoch                          366
-----------------------------  ---------------------
2023-08-01 17:47:30.703023 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 367 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3675.0923]
trainer/QF1 Loss               0.03626249
trainer/QF2 Loss               0.03217519
trainer/Policy Loss            -91.45085
trainer/Q1 Predictions Mean    103.226494
trainer/Q1 Predictions Std     2.109968
trainer/Q1 Predictions Max     104.65558
trainer/Q1 Predictions Min     80.48021
trainer/Q2 Predictions Mean    103.23728
trainer/Q2 Predictions Std     2.1254253
trainer/Q2 Predictions Max     104.69125
trainer/Q2 Predictions Min     80.10066
trainer/Q Targets Mean         103.23508
trainer/Q Targets Std          2.110253
trainer/Q Targets Max          104.74631
trainer/Q Targets Min          80.982834
trainer/Log Pis Mean           11.861249
trainer/Log Pis Std            7.680588
trainer/Log Pis Max            61.958237
trainer/Log Pis Min            -2.782347
trainer/Policy mu Mean         0.012727849
trainer/Policy mu Std          1.5804154
trainer/Policy mu Max          8.274769
trainer/Policy mu Min          -5.774151
trainer/Policy log std Mean    -0.7435522
trainer/Policy log std Std     0.31906223
trainer/Policy log std Max     0.33866143
trainer/Policy log std Min     -2.4432232
trainer/Alpha                  0.0012120320461690426
trainer/Alpha Loss             -0.9317678213119507
exploration/num steps total    1841000
exploration/num paths total    3682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9335217706045054
exploration/Rewards Std        0.07831956853224202
exploration/Rewards Max        0.979470863945968
exploration/Rewards Min        0.4969958053036281
exploration/Returns Mean       466.760885302253
exploration/Returns Std        11.20697787358585
exploration/Returns Max        474.9841113121727
exploration/Returns Min        434.1706489162775
exploration/Actions Mean       -0.05136527
exploration/Actions Std        0.67958736
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999961
exploration/Num Paths          10
exploration/Average Returns    466.760885302253
evaluation/num steps total     1840000
evaluation/num paths total     3680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9312814057984194
evaluation/Rewards Std         0.08450644338589589
evaluation/Rewards Max         0.9794886122374303
evaluation/Rewards Min         0.4928188185065566
evaluation/Returns Mean        465.6407028992095
evaluation/Returns Std         17.290720500678855
evaluation/Returns Max         473.40113389535287
evaluation/Returns Min         413.95845101105016
evaluation/ExplReturns Mean    465.6407028992095
evaluation/ExplReturns Std     17.290720500678855
evaluation/ExplReturns Max     473.40113389535287
evaluation/ExplReturns Min     413.95845101105016
evaluation/Actions Mean        -0.04038041
evaluation/Actions Std         0.6637402
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99998975
evaluation/Num Paths           10
evaluation/Average Returns     465.6407028992095
time/data storing (s)          0.03237013518810272
time/evaluation sampling (s)   112.36423184443265
time/exploration sampling (s)  113.00011735409498
time/logging (s)               0.030921077355742455
time/saving (s)                0.010759892873466015
time/training (s)              9.655219588428736
time/epoch (s)                 235.09361989237368
time/total (s)                 86001.95300123096
Epoch                          367
-----------------------------  ---------------------
2023-08-01 17:51:24.748238 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 368 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3854.6816]
trainer/QF1 Loss               0.023261823
trainer/QF2 Loss               0.023182398
trainer/Policy Loss            -90.69977
trainer/Q1 Predictions Mean    103.08736
trainer/Q1 Predictions Std     2.1030014
trainer/Q1 Predictions Max     105.595245
trainer/Q1 Predictions Min     84.10169
trainer/Q2 Predictions Mean    103.16443
trainer/Q2 Predictions Std     2.1229298
trainer/Q2 Predictions Max     105.71753
trainer/Q2 Predictions Min     84.06648
trainer/Q Targets Mean         103.08894
trainer/Q Targets Std          2.142328
trainer/Q Targets Max          105.22046
trainer/Q Targets Min          83.53142
trainer/Log Pis Mean           12.495511
trainer/Log Pis Std            9.137792
trainer/Log Pis Max            49.88157
trainer/Log Pis Min            -4.3931417
trainer/Policy mu Mean         0.037827823
trainer/Policy mu Std          1.6215731
trainer/Policy mu Max          7.160186
trainer/Policy mu Min          -6.218628
trainer/Policy log std Mean    -0.777606
trainer/Policy log std Std     0.33226064
trainer/Policy log std Max     0.5310787
trainer/Policy log std Min     -2.1423972
trainer/Alpha                  0.0012927694479003549
trainer/Alpha Loss             3.2957491874694824
exploration/num steps total    1846000
exploration/num paths total    3692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9473033781610651
exploration/Rewards Std        0.06000323550350797
exploration/Rewards Max        0.9785419985717705
exploration/Rewards Min        0.49147453984019995
exploration/Returns Mean       473.6516890805324
exploration/Returns Std        1.3402818610781069
exploration/Returns Max        475.28845897879665
exploration/Returns Min        470.9918873677203
exploration/Actions Mean       -0.12154628
exploration/Actions Std        0.6559911
exploration/Actions Max        0.9999925
exploration/Actions Min        -0.9999861
exploration/Num Paths          10
exploration/Average Returns    473.6516890805324
evaluation/num steps total     1845000
evaluation/num paths total     3690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9506171281039518
evaluation/Rewards Std         0.05816312376783217
evaluation/Rewards Max         0.9784104463497023
evaluation/Rewards Min         0.4916371321692203
evaluation/Returns Mean        475.3085640519759
evaluation/Returns Std         1.407871231352166
evaluation/Returns Max         477.2889734077513
evaluation/Returns Min         472.57275849396507
evaluation/ExplReturns Mean    475.3085640519759
evaluation/ExplReturns Std     1.407871231352166
evaluation/ExplReturns Max     477.2889734077513
evaluation/ExplReturns Min     472.57275849396507
evaluation/Actions Mean        -0.13626811
evaluation/Actions Std         0.5842045
evaluation/Actions Max         0.9999387
evaluation/Actions Min         -0.9998244
evaluation/Num Paths           10
evaluation/Average Returns     475.3085640519759
time/data storing (s)          0.03178143687546253
time/evaluation sampling (s)   111.58498021122068
time/exploration sampling (s)  112.7322820071131
time/logging (s)               0.031130150891840458
time/saving (s)                0.011708260513842106
time/training (s)              9.647805686108768
time/epoch (s)                 234.0396877527237
time/total (s)                 86235.99519990571
Epoch                          368
-----------------------------  ---------------------
2023-08-01 17:55:20.164256 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 369 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3971.5337]
trainer/QF1 Loss               0.014871134
trainer/QF2 Loss               0.014439921
trainer/Policy Loss            -91.57306
trainer/Q1 Predictions Mean    103.203964
trainer/Q1 Predictions Std     1.516331
trainer/Q1 Predictions Max     104.689766
trainer/Q1 Predictions Min     89.64406
trainer/Q2 Predictions Mean    103.191025
trainer/Q2 Predictions Std     1.5126659
trainer/Q2 Predictions Max     104.63677
trainer/Q2 Predictions Min     89.53948
trainer/Q Targets Mean         103.19363
trainer/Q Targets Std          1.4970183
trainer/Q Targets Max          104.59033
trainer/Q Targets Min          89.76394
trainer/Log Pis Mean           11.713532
trainer/Log Pis Std            9.457724
trainer/Log Pis Max            55.1545
trainer/Log Pis Min            -4.777584
trainer/Policy mu Mean         0.034344863
trainer/Policy mu Std          1.5762385
trainer/Policy mu Max          5.942381
trainer/Policy mu Min          -4.566879
trainer/Policy log std Mean    -0.8001092
trainer/Policy log std Std     0.32560673
trainer/Policy log std Max     0.3859476
trainer/Policy log std Min     -2.244057
trainer/Alpha                  0.0012505186023190618
trainer/Alpha Loss             -1.9147799015045166
exploration/num steps total    1851000
exploration/num paths total    3702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8792142870403769
exploration/Rewards Std        0.13229393621384455
exploration/Rewards Max        0.9788564012713498
exploration/Rewards Min        0.42227638366666187
exploration/Returns Mean       439.6071435201883
exploration/Returns Std        27.278692417083867
exploration/Returns Max        477.4549163558824
exploration/Returns Min        384.38779456350005
exploration/Actions Mean       0.11901849
exploration/Actions Std        0.6992627
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    439.6071435201883
evaluation/num steps total     1850000
evaluation/num paths total     3700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9292553067518591
evaluation/Rewards Std         0.08734461968211642
evaluation/Rewards Max         0.9791245456584694
evaluation/Rewards Min         0.4845514566947876
evaluation/Returns Mean        464.62765337592975
evaluation/Returns Std         29.482724446873547
evaluation/Returns Max         478.94075460825604
evaluation/Returns Min         377.1102790207042
evaluation/ExplReturns Mean    464.62765337592975
evaluation/ExplReturns Std     29.482724446873547
evaluation/ExplReturns Max     478.94075460825604
evaluation/ExplReturns Min     377.1102790207042
evaluation/Actions Mean        0.058858447
evaluation/Actions Std         0.6276537
evaluation/Actions Max         0.9999899
evaluation/Actions Min         -0.99990946
evaluation/Num Paths           10
evaluation/Average Returns     464.62765337592975
time/data storing (s)          0.0323793264105916
time/evaluation sampling (s)   111.54045072663575
time/exploration sampling (s)  113.93769189622253
time/logging (s)               0.03093435149639845
time/saving (s)                0.012706748209893703
time/training (s)              9.855747437104583
time/epoch (s)                 235.40991048607975
time/total (s)                 86471.40781500004
Epoch                          369
-----------------------------  ---------------------
2023-08-01 17:59:16.651147 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 370 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3655.8093]
trainer/QF1 Loss               0.03710494
trainer/QF2 Loss               0.055014938
trainer/Policy Loss            -90.54173
trainer/Q1 Predictions Mean    102.88994
trainer/Q1 Predictions Std     3.2654467
trainer/Q1 Predictions Max     105.86172
trainer/Q1 Predictions Min     72.364944
trainer/Q2 Predictions Mean    102.91368
trainer/Q2 Predictions Std     3.3125618
trainer/Q2 Predictions Max     105.69594
trainer/Q2 Predictions Min     71.49598
trainer/Q Targets Mean         102.763626
trainer/Q Targets Std          3.257123
trainer/Q Targets Max          105.262146
trainer/Q Targets Min          72.34642
trainer/Log Pis Mean           12.414852
trainer/Log Pis Std            9.692054
trainer/Log Pis Max            67.46063
trainer/Log Pis Min            -4.2818003
trainer/Policy mu Mean         0.15126991
trainer/Policy mu Std          1.5947337
trainer/Policy mu Max          6.662831
trainer/Policy mu Min          -6.350378
trainer/Policy log std Mean    -0.79512
trainer/Policy log std Std     0.3534966
trainer/Policy log std Max     0.40324295
trainer/Policy log std Min     -2.4421198
trainer/Alpha                  0.0012495624832808971
trainer/Alpha Loss             2.7732298374176025
exploration/num steps total    1856000
exploration/num paths total    3712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9533245275872758
exploration/Rewards Std        0.06658944575944013
exploration/Rewards Max        0.9782076504973185
exploration/Rewards Min        0.5010610029234887
exploration/Returns Mean       476.662263793638
exploration/Returns Std        3.3656091360762286
exploration/Returns Max        480.3886271979781
exploration/Returns Min        469.7316067000205
exploration/Actions Mean       -0.012490485
exploration/Actions Std        0.6759421
exploration/Actions Max        1.0
exploration/Actions Min        -0.99997914
exploration/Num Paths          10
exploration/Average Returns    476.662263793638
evaluation/num steps total     1855000
evaluation/num paths total     3710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9455076290340603
evaluation/Rewards Std         0.08189344085222412
evaluation/Rewards Max         0.9794468016862794
evaluation/Rewards Min         0.49403162253417765
evaluation/Returns Mean        472.75381451703015
evaluation/Returns Std         12.093077674196302
evaluation/Returns Max         483.6692825120179
evaluation/Returns Min         448.5354106136913
evaluation/ExplReturns Mean    472.75381451703015
evaluation/ExplReturns Std     12.093077674196302
evaluation/ExplReturns Max     483.6692825120179
evaluation/ExplReturns Min     448.5354106136913
evaluation/Actions Mean        -0.0834959
evaluation/Actions Std         0.61948216
evaluation/Actions Max         0.9999992
evaluation/Actions Min         -0.9999878
evaluation/Num Paths           10
evaluation/Average Returns     472.75381451703015
time/data storing (s)          0.03194236382842064
time/evaluation sampling (s)   112.88900358881801
time/exploration sampling (s)  113.83751517068595
time/logging (s)               0.030203831382095814
time/saving (s)                0.010524610057473183
time/training (s)              9.681296726688743
time/epoch (s)                 236.4804862914607
time/total (s)                 86707.89074488077
Epoch                          370
-----------------------------  ---------------------
2023-08-01 18:03:09.519388 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 371 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3881.446]
trainer/QF1 Loss               0.06973127
trainer/QF2 Loss               0.02317813
trainer/Policy Loss            -90.988716
trainer/Q1 Predictions Mean    102.78668
trainer/Q1 Predictions Std     1.9293323
trainer/Q1 Predictions Max     104.52448
trainer/Q1 Predictions Min     78.3018
trainer/Q2 Predictions Mean    102.916855
trainer/Q2 Predictions Std     1.9564048
trainer/Q2 Predictions Max     104.66891
trainer/Q2 Predictions Min     77.742485
trainer/Q Targets Mean         102.987144
trainer/Q Targets Std          2.0120685
trainer/Q Targets Max          104.865425
trainer/Q Targets Min          77.21081
trainer/Log Pis Mean           11.907617
trainer/Log Pis Std            7.489453
trainer/Log Pis Max            36.3178
trainer/Log Pis Min            -5.916364
trainer/Policy mu Mean         0.045620915
trainer/Policy mu Std          1.5354352
trainer/Policy mu Max          4.961508
trainer/Policy mu Min          -4.9107957
trainer/Policy log std Mean    -0.8204868
trainer/Policy log std Std     0.33142865
trainer/Policy log std Max     0.17894745
trainer/Policy log std Min     -2.128724
trainer/Alpha                  0.0013387227663770318
trainer/Alpha Loss             -0.6112254858016968
exploration/num steps total    1861000
exploration/num paths total    3722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.922604926513616
exploration/Rewards Std        0.08110562530475666
exploration/Rewards Max        0.9791896677911565
exploration/Rewards Min        0.4961800289819112
exploration/Returns Mean       461.3024632568082
exploration/Returns Std        5.103706873889446
exploration/Returns Max        466.8517870952594
exploration/Returns Min        452.9171050642663
exploration/Actions Mean       -0.18903068
exploration/Actions Std        0.6043259
exploration/Actions Max        0.9999068
exploration/Actions Min        -0.9999664
exploration/Num Paths          10
exploration/Average Returns    461.3024632568082
evaluation/num steps total     1860000
evaluation/num paths total     3720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9126315179722507
evaluation/Rewards Std         0.09037618590421857
evaluation/Rewards Max         0.9786842551000721
evaluation/Rewards Min         0.4889532481918766
evaluation/Returns Mean        456.3157589861254
evaluation/Returns Std         22.140023157120478
evaluation/Returns Max         474.1403234262145
evaluation/Returns Min         393.58495893470183
evaluation/ExplReturns Mean    456.3157589861254
evaluation/ExplReturns Std     22.140023157120478
evaluation/ExplReturns Max     474.1403234262145
evaluation/ExplReturns Min     393.58495893470183
evaluation/Actions Mean        -0.16565132
evaluation/Actions Std         0.58196366
evaluation/Actions Max         0.9996054
evaluation/Actions Min         -0.9999181
evaluation/Num Paths           10
evaluation/Average Returns     456.3157589861254
time/data storing (s)          0.03219930175691843
time/evaluation sampling (s)   111.03036971762776
time/exploration sampling (s)  112.15811740141362
time/logging (s)               0.03030747640877962
time/saving (s)                0.011722865514457226
time/training (s)              9.599939779378474
time/epoch (s)                 232.8626565421
time/total (s)                 86940.75585186016
Epoch                          371
-----------------------------  ---------------------
2023-08-01 18:07:02.645877 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 372 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3958.5454]
trainer/QF1 Loss               0.03349111
trainer/QF2 Loss               0.020436656
trainer/Policy Loss            -90.32248
trainer/Q1 Predictions Mean    102.88733
trainer/Q1 Predictions Std     1.5518594
trainer/Q1 Predictions Max     104.962006
trainer/Q1 Predictions Min     93.0605
trainer/Q2 Predictions Mean    102.91189
trainer/Q2 Predictions Std     1.5699475
trainer/Q2 Predictions Max     104.6022
trainer/Q2 Predictions Min     92.878685
trainer/Q Targets Mean         102.98549
trainer/Q Targets Std          1.5589224
trainer/Q Targets Max          104.697876
trainer/Q Targets Min          93.396164
trainer/Log Pis Mean           12.680822
trainer/Log Pis Std            7.978749
trainer/Log Pis Max            44.57097
trainer/Log Pis Min            -0.57467747
trainer/Policy mu Mean         0.053943407
trainer/Policy mu Std          1.6072273
trainer/Policy mu Max          6.5705175
trainer/Policy mu Min          -4.753191
trainer/Policy log std Mean    -0.7761031
trainer/Policy log std Std     0.316177
trainer/Policy log std Max     0.15839869
trainer/Policy log std Min     -2.248408
trainer/Alpha                  0.001443302957341075
trainer/Alpha Loss             4.453305721282959
exploration/num steps total    1866000
exploration/num paths total    3732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9623477430306235
exploration/Rewards Std        0.05579631272225678
exploration/Rewards Max        0.9796685630753701
exploration/Rewards Min        0.4962854196328926
exploration/Returns Mean       481.1738715153118
exploration/Returns Std        4.942699312516034
exploration/Returns Max        483.521878351018
exploration/Returns Min        466.42212294558436
exploration/Actions Mean       0.004676245
exploration/Actions Std        0.5979636
exploration/Actions Max        0.99997747
exploration/Actions Min        -0.99995947
exploration/Num Paths          10
exploration/Average Returns    481.1738715153118
evaluation/num steps total     1865000
evaluation/num paths total     3730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9655033514679024
evaluation/Rewards Std         0.05004807799762993
evaluation/Rewards Max         0.97928215652284
evaluation/Rewards Min         0.49211911262469005
evaluation/Returns Mean        482.7516757339511
evaluation/Returns Std         0.2287387382680542
evaluation/Returns Max         483.1689297187311
evaluation/Returns Min         482.41736239677635
evaluation/ExplReturns Mean    482.7516757339511
evaluation/ExplReturns Std     0.2287387382680542
evaluation/ExplReturns Max     483.1689297187311
evaluation/ExplReturns Min     482.41736239677635
evaluation/Actions Mean        -0.0024965378
evaluation/Actions Std         0.5021913
evaluation/Actions Max         0.9995112
evaluation/Actions Min         -0.9994225
evaluation/Num Paths           10
evaluation/Average Returns     482.7516757339511
time/data storing (s)          0.03212739992886782
time/evaluation sampling (s)   111.13046207744628
time/exploration sampling (s)  112.18425940535963
time/logging (s)               0.030973725952208042
time/saving (s)                0.012191727757453918
time/training (s)              9.731429628096521
time/epoch (s)                 233.12144396454096
time/total (s)                 87173.87972945254
Epoch                          372
-----------------------------  --------------------
2023-08-01 18:10:57.150217 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 373 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3839.3457]
trainer/QF1 Loss               0.016249653
trainer/QF2 Loss               0.014628634
trainer/Policy Loss            -91.63678
trainer/Q1 Predictions Mean    103.018936
trainer/Q1 Predictions Std     1.7161328
trainer/Q1 Predictions Max     104.63241
trainer/Q1 Predictions Min     89.0442
trainer/Q2 Predictions Mean    103.02832
trainer/Q2 Predictions Std     1.7758341
trainer/Q2 Predictions Max     104.56544
trainer/Q2 Predictions Min     88.84127
trainer/Q Targets Mean         103.0401
trainer/Q Targets Std          1.7442274
trainer/Q Targets Max          104.57688
trainer/Q Targets Min          89.0723
trainer/Log Pis Mean           11.444084
trainer/Log Pis Std            7.448989
trainer/Log Pis Max            61.364437
trainer/Log Pis Min            -4.952676
trainer/Policy mu Mean         0.29001358
trainer/Policy mu Std          1.524684
trainer/Policy mu Max          6.852986
trainer/Policy mu Min          -6.9167266
trainer/Policy log std Mean    -0.76728606
trainer/Policy log std Std     0.32678726
trainer/Policy log std Max     0.986575
trainer/Policy log std Min     -2.1864274
trainer/Alpha                  0.0015591285191476345
trainer/Alpha Loss             -3.5932044982910156
exploration/num steps total    1871000
exploration/num paths total    3742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.894813226206676
exploration/Rewards Std        0.10413731885141211
exploration/Rewards Max        0.9790242355260498
exploration/Rewards Min        0.484860377364919
exploration/Returns Mean       447.4066131033378
exploration/Returns Std        21.055484986350475
exploration/Returns Max        479.6386923579961
exploration/Returns Min        419.6063378252828
exploration/Actions Mean       0.046865094
exploration/Actions Std        0.66450554
exploration/Actions Max        0.99999875
exploration/Actions Min        -0.9999543
exploration/Num Paths          10
exploration/Average Returns    447.4066131033378
evaluation/num steps total     1870000
evaluation/num paths total     3740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9421380311513425
evaluation/Rewards Std         0.0729588113909176
evaluation/Rewards Max         0.9791495735891511
evaluation/Rewards Min         0.49125372003882106
evaluation/Returns Mean        471.06901557567124
evaluation/Returns Std         13.164867778494006
evaluation/Returns Max         480.37135923471567
evaluation/Returns Min         439.1549498557743
evaluation/ExplReturns Mean    471.06901557567124
evaluation/ExplReturns Std     13.164867778494006
evaluation/ExplReturns Max     480.37135923471567
evaluation/ExplReturns Min     439.1549498557743
evaluation/Actions Mean        0.040167455
evaluation/Actions Std         0.5787135
evaluation/Actions Max         0.9999596
evaluation/Actions Min         -0.9999243
evaluation/Num Paths           10
evaluation/Average Returns     471.06901557567124
time/data storing (s)          0.032433923333883286
time/evaluation sampling (s)   110.88058196008205
time/exploration sampling (s)  113.91573258116841
time/logging (s)               0.030559511855244637
time/saving (s)                0.010793264023959637
time/training (s)              9.628003294579685
time/epoch (s)                 234.49810453504324
time/total (s)                 87408.38043292053
Epoch                          373
-----------------------------  ---------------------
2023-08-01 18:14:57.080985 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 374 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3908.3098]
trainer/QF1 Loss               0.023759428
trainer/QF2 Loss               0.017061364
trainer/Policy Loss            -91.18172
trainer/Q1 Predictions Mean    102.999886
trainer/Q1 Predictions Std     2.0443265
trainer/Q1 Predictions Max     104.44318
trainer/Q1 Predictions Min     81.74165
trainer/Q2 Predictions Mean    103.05439
trainer/Q2 Predictions Std     2.0415113
trainer/Q2 Predictions Max     104.534966
trainer/Q2 Predictions Min     81.878654
trainer/Q Targets Mean         103.03522
trainer/Q Targets Std          2.0291288
trainer/Q Targets Max          104.466194
trainer/Q Targets Min          82.32744
trainer/Log Pis Mean           11.919487
trainer/Log Pis Std            7.3444247
trainer/Log Pis Max            49.64313
trainer/Log Pis Min            -2.4843087
trainer/Policy mu Mean         0.39072168
trainer/Policy mu Std          1.5032712
trainer/Policy mu Max          6.670278
trainer/Policy mu Min          -5.406723
trainer/Policy log std Mean    -0.8050332
trainer/Policy log std Std     0.32843563
trainer/Policy log std Max     0.3049218
trainer/Policy log std Min     -2.122728
trainer/Alpha                  0.0014986773021519184
trainer/Alpha Loss             -0.5236066579818726
exploration/num steps total    1876000
exploration/num paths total    3752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7855322850156641
exploration/Rewards Std        0.08759810968072786
exploration/Rewards Max        0.9796108980313994
exploration/Rewards Min        0.4875725910434796
exploration/Returns Mean       392.76614250783217
exploration/Returns Std        3.713526468335401
exploration/Returns Max        400.38234587630586
exploration/Returns Min        389.0410149800476
exploration/Actions Mean       0.11992054
exploration/Actions Std        0.6785792
exploration/Actions Max        0.999972
exploration/Actions Min        -0.9999571
exploration/Num Paths          10
exploration/Average Returns    392.76614250783217
evaluation/num steps total     1875000
evaluation/num paths total     3750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7819732362305941
evaluation/Rewards Std         0.08320181216271817
evaluation/Rewards Max         0.9794332464840411
evaluation/Rewards Min         0.48977638176079363
evaluation/Returns Mean        390.986618115297
evaluation/Returns Std         13.344562186371768
evaluation/Returns Max         430.76075228841927
evaluation/Returns Min         384.4483283661229
evaluation/ExplReturns Mean    390.986618115297
evaluation/ExplReturns Std     13.344562186371768
evaluation/ExplReturns Max     430.76075228841927
evaluation/ExplReturns Min     384.4483283661229
evaluation/Actions Mean        0.13711391
evaluation/Actions Std         0.6485972
evaluation/Actions Max         0.9996391
evaluation/Actions Min         -0.99965245
evaluation/Num Paths           10
evaluation/Average Returns     390.986618115297
time/data storing (s)          0.03207027446478605
time/evaluation sampling (s)   114.60559561755508
time/exploration sampling (s)  115.58633675612509
time/logging (s)               0.03104130830615759
time/saving (s)                0.010245555080473423
time/training (s)              9.66024615522474
time/epoch (s)                 239.92553566675633
time/total (s)                 87648.30848897714
Epoch                          374
-----------------------------  ---------------------
2023-08-01 18:18:54.478888 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 375 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3521.4004]
trainer/QF1 Loss               0.025127977
trainer/QF2 Loss               0.027111242
trainer/Policy Loss            -92.67853
trainer/Q1 Predictions Mean    103.01553
trainer/Q1 Predictions Std     2.1114633
trainer/Q1 Predictions Max     104.20237
trainer/Q1 Predictions Min     80.35167
trainer/Q2 Predictions Mean    103.08048
trainer/Q2 Predictions Std     2.1236835
trainer/Q2 Predictions Max     104.33381
trainer/Q2 Predictions Min     80.87004
trainer/Q Targets Mean         103.09102
trainer/Q Targets Std          2.145049
trainer/Q Targets Max          104.32518
trainer/Q Targets Min          79.722115
trainer/Log Pis Mean           10.444439
trainer/Log Pis Std            7.477321
trainer/Log Pis Max            50.08914
trainer/Log Pis Min            -4.3644915
trainer/Policy mu Mean         0.30667117
trainer/Policy mu Std          1.4239463
trainer/Policy mu Max          6.6451445
trainer/Policy mu Min          -6.6461153
trainer/Policy log std Mean    -0.853851
trainer/Policy log std Std     0.32072574
trainer/Policy log std Max     0.31478
trainer/Policy log std Min     -2.288877
trainer/Alpha                  0.0014883700059726834
trainer/Alpha Loss             -10.126374244689941
exploration/num steps total    1881000
exploration/num paths total    3762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9349966268121294
exploration/Rewards Std        0.06411450598133116
exploration/Rewards Max        0.9795051605609258
exploration/Rewards Min        0.48047321366673307
exploration/Returns Mean       467.4983134060649
exploration/Returns Std        4.444965709399136
exploration/Returns Max        471.94366466582073
exploration/Returns Min        456.3986156607052
exploration/Actions Mean       0.13520966
exploration/Actions Std        0.6761267
exploration/Actions Max        0.99996406
exploration/Actions Min        -0.9999605
exploration/Num Paths          10
exploration/Average Returns    467.4983134060649
evaluation/num steps total     1880000
evaluation/num paths total     3760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9460383248829477
evaluation/Rewards Std         0.04840867578874776
evaluation/Rewards Max         0.9794953444471007
evaluation/Rewards Min         0.4907694954364223
evaluation/Returns Mean        473.0191624414739
evaluation/Returns Std         0.49269388667582426
evaluation/Returns Max         473.741306029129
evaluation/Returns Min         472.0157980070386
evaluation/ExplReturns Mean    473.0191624414739
evaluation/ExplReturns Std     0.49269388667582426
evaluation/ExplReturns Max     473.741306029129
evaluation/ExplReturns Min     472.0157980070386
evaluation/Actions Mean        0.13885286
evaluation/Actions Std         0.59292436
evaluation/Actions Max         0.9994207
evaluation/Actions Min         -0.9996842
evaluation/Num Paths           10
evaluation/Average Returns     473.0191624414739
time/data storing (s)          0.03193608205765486
time/evaluation sampling (s)   113.9695338839665
time/exploration sampling (s)  113.68929627723992
time/logging (s)               0.03051982168108225
time/saving (s)                0.012783273123204708
time/training (s)              9.65755053050816
time/epoch (s)                 237.39161986857653
time/total (s)                 87885.70260955766
Epoch                          375
-----------------------------  ---------------------
2023-08-01 18:22:55.926447 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 376 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4217.1343]
trainer/QF1 Loss               0.02369611
trainer/QF2 Loss               0.018507427
trainer/Policy Loss            -91.10083
trainer/Q1 Predictions Mean    103.14125
trainer/Q1 Predictions Std     1.2675781
trainer/Q1 Predictions Max     104.29113
trainer/Q1 Predictions Min     96.73515
trainer/Q2 Predictions Mean    103.14214
trainer/Q2 Predictions Std     1.2703
trainer/Q2 Predictions Max     104.29821
trainer/Q2 Predictions Min     97.16086
trainer/Q Targets Mean         103.20224
trainer/Q Targets Std          1.2585404
trainer/Q Targets Max          104.318634
trainer/Q Targets Min          97.444695
trainer/Log Pis Mean           12.1188965
trainer/Log Pis Std            6.221633
trainer/Log Pis Max            44.85433
trainer/Log Pis Min            -0.12797272
trainer/Policy mu Mean         0.33424196
trainer/Policy mu Std          1.4946666
trainer/Policy mu Max          4.4391413
trainer/Policy mu Min          -5.0791655
trainer/Policy log std Mean    -0.82482415
trainer/Policy log std Std     0.31912258
trainer/Policy log std Max     0.061766863
trainer/Policy log std Min     -1.9508868
trainer/Alpha                  0.0014879903756082058
trainer/Alpha Loss             0.7740689516067505
exploration/num steps total    1886000
exploration/num paths total    3772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9554898546891473
exploration/Rewards Std        0.05614390328228694
exploration/Rewards Max        0.9791372912465843
exploration/Rewards Min        0.49039405827865823
exploration/Returns Mean       477.7449273445736
exploration/Returns Std        2.5025235977364524
exploration/Returns Max        479.75366984883493
exploration/Returns Min        471.75344754498894
exploration/Actions Mean       0.13817066
exploration/Actions Std        0.64911747
exploration/Actions Max        0.99988765
exploration/Actions Min        -0.99996
exploration/Num Paths          10
exploration/Average Returns    477.7449273445736
evaluation/num steps total     1885000
evaluation/num paths total     3770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9583839087108923
evaluation/Rewards Std         0.05330701880265732
evaluation/Rewards Max         0.9792370294549338
evaluation/Rewards Min         0.48986636345135387
evaluation/Returns Mean        479.19195435544617
evaluation/Returns Std         0.5483961223085032
evaluation/Returns Max         479.82960632600106
evaluation/Returns Min         478.4856486372705
evaluation/ExplReturns Mean    479.19195435544617
evaluation/ExplReturns Std     0.5483961223085032
evaluation/ExplReturns Max     479.82960632600106
evaluation/ExplReturns Min     478.4856486372705
evaluation/Actions Mean        0.21285003
evaluation/Actions Std         0.5799641
evaluation/Actions Max         0.9995155
evaluation/Actions Min         -0.99979514
evaluation/Num Paths           10
evaluation/Average Returns     479.19195435544617
time/data storing (s)          0.03196092136204243
time/evaluation sampling (s)   116.17092557623982
time/exploration sampling (s)  115.29951935634017
time/logging (s)               0.030550784431397915
time/saving (s)                0.013017884455621243
time/training (s)              9.895750855095685
time/epoch (s)                 241.44172537792474
time/total (s)                 88127.14694510028
Epoch                          376
-----------------------------  ---------------------
2023-08-01 18:26:51.134819 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 377 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4243.812]
trainer/QF1 Loss               0.031426556
trainer/QF2 Loss               0.033780113
trainer/Policy Loss            -91.22795
trainer/Q1 Predictions Mean    102.90878
trainer/Q1 Predictions Std     3.465536
trainer/Q1 Predictions Max     104.30248
trainer/Q1 Predictions Min     62.109325
trainer/Q2 Predictions Mean    102.895004
trainer/Q2 Predictions Std     3.440749
trainer/Q2 Predictions Max     104.24906
trainer/Q2 Predictions Min     61.153194
trainer/Q Targets Mean         102.804436
trainer/Q Targets Std          3.4784555
trainer/Q Targets Max          104.17605
trainer/Q Targets Min          61.384354
trainer/Log Pis Mean           11.7668495
trainer/Log Pis Std            7.929388
trainer/Log Pis Max            66.26101
trainer/Log Pis Min            -2.3117888
trainer/Policy mu Mean         0.39511612
trainer/Policy mu Std          1.4998387
trainer/Policy mu Max          5.7956824
trainer/Policy mu Min          -8.00712
trainer/Policy log std Mean    -0.80192417
trainer/Policy log std Std     0.33124846
trainer/Policy log std Max     0.17908025
trainer/Policy log std Min     -2.159015
trainer/Alpha                  0.0015109205851331353
trainer/Alpha Loss             -1.5142998695373535
exploration/num steps total    1891000
exploration/num paths total    3782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9654392404709586
exploration/Rewards Std        0.05280452607668628
exploration/Rewards Max        0.97979603238468
exploration/Rewards Min        0.5027471715032047
exploration/Returns Mean       482.7196202354792
exploration/Returns Std        0.3958452762520274
exploration/Returns Max        483.3103807037789
exploration/Returns Min        481.92507144369193
exploration/Actions Mean       0.1361419
exploration/Actions Std        0.60730493
exploration/Actions Max        0.9999057
exploration/Actions Min        -0.99998105
exploration/Num Paths          10
exploration/Average Returns    482.7196202354792
evaluation/num steps total     1890000
evaluation/num paths total     3780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9656018818589873
evaluation/Rewards Std         0.05235685936067751
evaluation/Rewards Max         0.9784089936115118
evaluation/Rewards Min         0.4917664794652109
evaluation/Returns Mean        482.80094092949366
evaluation/Returns Std         0.385486504134042
evaluation/Returns Max         483.2402777694162
evaluation/Returns Min         481.7516760406215
evaluation/ExplReturns Mean    482.80094092949366
evaluation/ExplReturns Std     0.385486504134042
evaluation/ExplReturns Max     483.2402777694162
evaluation/ExplReturns Min     481.7516760406215
evaluation/Actions Mean        0.15872711
evaluation/Actions Std         0.56416225
evaluation/Actions Max         0.99819344
evaluation/Actions Min         -0.9997358
evaluation/Num Paths           10
evaluation/Average Returns     482.80094092949366
time/data storing (s)          0.03231736924499273
time/evaluation sampling (s)   112.31497721001506
time/exploration sampling (s)  113.23616378754377
time/logging (s)               0.030928018502891064
time/saving (s)                0.010755066759884357
time/training (s)              9.57787991501391
time/epoch (s)                 235.2030213670805
time/total (s)                 88362.35245533288
Epoch                          377
-----------------------------  ---------------------
2023-08-01 18:30:44.422700 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 378 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3738.445]
trainer/QF1 Loss               0.038890243
trainer/QF2 Loss               0.03239034
trainer/Policy Loss            -90.01592
trainer/Q1 Predictions Mean    102.762405
trainer/Q1 Predictions Std     2.5438616
trainer/Q1 Predictions Max     104.224304
trainer/Q1 Predictions Min     82.83383
trainer/Q2 Predictions Mean    102.71625
trainer/Q2 Predictions Std     2.5393424
trainer/Q2 Predictions Max     104.15318
trainer/Q2 Predictions Min     82.34776
trainer/Q Targets Mean         102.78682
trainer/Q Targets Std          2.491251
trainer/Q Targets Max          104.158966
trainer/Q Targets Min          83.92779
trainer/Log Pis Mean           12.812423
trainer/Log Pis Std            9.519579
trainer/Log Pis Max            54.977417
trainer/Log Pis Min            -5.583408
trainer/Policy mu Mean         0.35916582
trainer/Policy mu Std          1.6299677
trainer/Policy mu Max          10.900386
trainer/Policy mu Min          -7.105803
trainer/Policy log std Mean    -0.76001716
trainer/Policy log std Std     0.3254969
trainer/Policy log std Max     1.6188102
trainer/Policy log std Min     -2.1332912
trainer/Alpha                  0.0014363679802045226
trainer/Alpha Loss             5.318009853363037
exploration/num steps total    1896000
exploration/num paths total    3792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9503851114423276
exploration/Rewards Std        0.07725740243496068
exploration/Rewards Max        0.9796153226097792
exploration/Rewards Min        0.4880178317582705
exploration/Returns Mean       475.1925557211636
exploration/Returns Std        4.04024882409815
exploration/Returns Max        482.0883974749187
exploration/Returns Min        471.55222240346393
exploration/Actions Mean       0.09949165
exploration/Actions Std        0.56174225
exploration/Actions Max        0.9998239
exploration/Actions Min        -0.9998978
exploration/Num Paths          10
exploration/Average Returns    475.1925557211636
evaluation/num steps total     1895000
evaluation/num paths total     3790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9503064382252614
evaluation/Rewards Std         0.07638876426294962
evaluation/Rewards Max         0.9783648150530937
evaluation/Rewards Min         0.48939657833577876
evaluation/Returns Mean        475.1532191126306
evaluation/Returns Std         2.6907933234940273
evaluation/Returns Max         480.45488518928084
evaluation/Returns Min         472.52476207870507
evaluation/ExplReturns Mean    475.1532191126306
evaluation/ExplReturns Std     2.6907933234940273
evaluation/ExplReturns Max     480.45488518928084
evaluation/ExplReturns Min     472.52476207870507
evaluation/Actions Mean        0.10388676
evaluation/Actions Std         0.49775994
evaluation/Actions Max         0.9991358
evaluation/Actions Min         -0.9997801
evaluation/Num Paths           10
evaluation/Average Returns     475.1532191126306
time/data storing (s)          0.032033911906182766
time/evaluation sampling (s)   112.1399737317115
time/exploration sampling (s)  111.72603687364608
time/logging (s)               0.030660287477076054
time/saving (s)                0.010771231725811958
time/training (s)              9.34232712443918
time/epoch (s)                 233.28180316090584
time/total (s)                 88595.63679246046
Epoch                          378
-----------------------------  ---------------------
2023-08-01 18:34:41.528242 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 379 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3416.5344]
trainer/QF1 Loss               0.022608923
trainer/QF2 Loss               0.017561456
trainer/Policy Loss            -91.117195
trainer/Q1 Predictions Mean    102.89513
trainer/Q1 Predictions Std     2.5852675
trainer/Q1 Predictions Max     104.50214
trainer/Q1 Predictions Min     71.642494
trainer/Q2 Predictions Mean    102.922
trainer/Q2 Predictions Std     2.5879347
trainer/Q2 Predictions Max     104.62292
trainer/Q2 Predictions Min     71.388954
trainer/Q Targets Mean         102.941895
trainer/Q Targets Std          2.6110258
trainer/Q Targets Max          105.11033
trainer/Q Targets Min          71.66721
trainer/Log Pis Mean           11.868081
trainer/Log Pis Std            8.259987
trainer/Log Pis Max            54.546555
trainer/Log Pis Min            -3.9653997
trainer/Policy mu Mean         0.28537467
trainer/Policy mu Std          1.5034193
trainer/Policy mu Max          5.8583694
trainer/Policy mu Min          -5.1956425
trainer/Policy log std Mean    -0.77994746
trainer/Policy log std Std     0.31610736
trainer/Policy log std Max     0.19066799
trainer/Policy log std Min     -2.0029852
trainer/Alpha                  0.0014222626341506839
trainer/Alpha Loss             -0.8647620677947998
exploration/num steps total    1901000
exploration/num paths total    3802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9637355054094169
exploration/Rewards Std        0.04769665724856124
exploration/Rewards Max        0.9797710549934857
exploration/Rewards Min        0.4991365062081443
exploration/Returns Mean       481.8677527047087
exploration/Returns Std        0.4089642174364615
exploration/Returns Max        482.4752231128598
exploration/Returns Min        481.18645387645876
exploration/Actions Mean       -0.010776229
exploration/Actions Std        0.57117695
exploration/Actions Max        0.9999289
exploration/Actions Min        -0.99992675
exploration/Num Paths          10
exploration/Average Returns    481.8677527047087
evaluation/num steps total     1900000
evaluation/num paths total     3800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9637509180290992
evaluation/Rewards Std         0.04943193821202351
evaluation/Rewards Max         0.9781671999235254
evaluation/Rewards Min         0.48498642651938556
evaluation/Returns Mean        481.8754590145496
evaluation/Returns Std         0.25297448159904645
evaluation/Returns Max         482.35863481461473
evaluation/Returns Min         481.55998932802385
evaluation/ExplReturns Mean    481.8754590145496
evaluation/ExplReturns Std     0.25297448159904645
evaluation/ExplReturns Max     482.35863481461473
evaluation/ExplReturns Min     481.55998932802385
evaluation/Actions Mean        -0.049665526
evaluation/Actions Std         0.539582
evaluation/Actions Max         0.9986713
evaluation/Actions Min         -0.9995763
evaluation/Num Paths           10
evaluation/Average Returns     481.8754590145496
time/data storing (s)          0.032336313277482986
time/evaluation sampling (s)   113.85514404717833
time/exploration sampling (s)  113.8472393983975
time/logging (s)               0.031135020777583122
time/saving (s)                0.011487436480820179
time/training (s)              9.32291019987315
time/epoch (s)                 237.10025241598487
time/total (s)                 88832.73960126936
Epoch                          379
-----------------------------  ---------------------
2023-08-01 18:38:36.632600 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 380 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4213.167]
trainer/QF1 Loss               0.040248144
trainer/QF2 Loss               0.052811634
trainer/Policy Loss            -91.68048
trainer/Q1 Predictions Mean    102.81735
trainer/Q1 Predictions Std     2.5890777
trainer/Q1 Predictions Max     104.39369
trainer/Q1 Predictions Min     73.60705
trainer/Q2 Predictions Mean    102.68703
trainer/Q2 Predictions Std     2.541458
trainer/Q2 Predictions Max     104.23791
trainer/Q2 Predictions Min     74.86749
trainer/Q Targets Mean         102.75766
trainer/Q Targets Std          2.527801
trainer/Q Targets Max          104.26559
trainer/Q Targets Min          74.25607
trainer/Log Pis Mean           11.146406
trainer/Log Pis Std            8.679985
trainer/Log Pis Max            53.796852
trainer/Log Pis Min            -5.6596813
trainer/Policy mu Mean         0.2838242
trainer/Policy mu Std          1.5184672
trainer/Policy mu Max          6.4335346
trainer/Policy mu Min          -7.2752714
trainer/Policy log std Mean    -0.7728174
trainer/Policy log std Std     0.30206883
trainer/Policy log std Max     0.3342049
trainer/Policy log std Min     -1.9982554
trainer/Alpha                  0.0013862957712262869
trainer/Alpha Loss             -5.617396354675293
exploration/num steps total    1906000
exploration/num paths total    3812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9628910999035792
exploration/Rewards Std        0.05086218542075936
exploration/Rewards Max        0.9793726263252633
exploration/Rewards Min        0.48665891596258154
exploration/Returns Mean       481.44554995178953
exploration/Returns Std        0.5612925690130964
exploration/Returns Max        482.31057817013124
exploration/Returns Min        480.3773486756552
exploration/Actions Mean       -0.015918542
exploration/Actions Std        0.5374672
exploration/Actions Max        0.99990815
exploration/Actions Min        -0.9998509
exploration/Num Paths          10
exploration/Average Returns    481.44554995178953
evaluation/num steps total     1905000
evaluation/num paths total     3810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9642436875285428
evaluation/Rewards Std         0.049958362823192715
evaluation/Rewards Max         0.9783832678156239
evaluation/Rewards Min         0.49195062385171967
evaluation/Returns Mean        482.1218437642713
evaluation/Returns Std         0.43260512533178647
evaluation/Returns Max         483.03304733131097
evaluation/Returns Min         481.4458479042107
evaluation/ExplReturns Mean    482.1218437642713
evaluation/ExplReturns Std     0.43260512533178647
evaluation/ExplReturns Max     483.03304733131097
evaluation/ExplReturns Min     481.4458479042107
evaluation/Actions Mean        -0.03844918
evaluation/Actions Std         0.40312195
evaluation/Actions Max         0.9994692
evaluation/Actions Min         -0.99915814
evaluation/Num Paths           10
evaluation/Average Returns     482.1218437642713
time/data storing (s)          0.03187071159482002
time/evaluation sampling (s)   112.60107347741723
time/exploration sampling (s)  112.69410929549485
time/logging (s)               0.030873476527631283
time/saving (s)                0.012898020446300507
time/training (s)              9.727117754518986
time/epoch (s)                 235.09794273599982
time/total (s)                 89067.84037058055
Epoch                          380
-----------------------------  ---------------------
2023-08-01 18:42:26.832907 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 381 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3522.0183]
trainer/QF1 Loss               0.017329004
trainer/QF2 Loss               0.014953421
trainer/Policy Loss            -90.362526
trainer/Q1 Predictions Mean    102.747734
trainer/Q1 Predictions Std     2.8170938
trainer/Q1 Predictions Max     104.35161
trainer/Q1 Predictions Min     76.057434
trainer/Q2 Predictions Mean    102.75974
trainer/Q2 Predictions Std     2.8021672
trainer/Q2 Predictions Max     104.348114
trainer/Q2 Predictions Min     76.088974
trainer/Q Targets Mean         102.75841
trainer/Q Targets Std          2.836359
trainer/Q Targets Max          104.40887
trainer/Q Targets Min          75.37347
trainer/Log Pis Mean           12.470079
trainer/Log Pis Std            8.669599
trainer/Log Pis Max            62.141087
trainer/Log Pis Min            -4.1181545
trainer/Policy mu Mean         0.41130105
trainer/Policy mu Std          1.5598929
trainer/Policy mu Max          7.45554
trainer/Policy mu Min          -8.90197
trainer/Policy log std Mean    -0.7909975
trainer/Policy log std Std     0.33367643
trainer/Policy log std Max     0.36780345
trainer/Policy log std Min     -2.2538924
trainer/Alpha                  0.0013085365062579513
trainer/Alpha Loss             3.120779514312744
exploration/num steps total    1911000
exploration/num paths total    3822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9598854990990722
exploration/Rewards Std        0.05065735879250912
exploration/Rewards Max        0.9797308427122648
exploration/Rewards Min        0.48956403469944026
exploration/Returns Mean       479.94274954953596
exploration/Returns Std        0.29258098762900275
exploration/Returns Max        480.48325984264585
exploration/Returns Min        479.479781865771
exploration/Actions Mean       0.053497452
exploration/Actions Std        0.56656533
exploration/Actions Max        0.99992055
exploration/Actions Min        -0.9999483
exploration/Num Paths          10
exploration/Average Returns    479.94274954953596
evaluation/num steps total     1910000
evaluation/num paths total     3820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9600372555127391
evaluation/Rewards Std         0.050369868175662046
evaluation/Rewards Max         0.9780377221955595
evaluation/Rewards Min         0.4898640960122834
evaluation/Returns Mean        480.01862775636954
evaluation/Returns Std         0.2014303616329636
evaluation/Returns Max         480.3176839411781
evaluation/Returns Min         479.71366294204824
evaluation/ExplReturns Mean    480.01862775636954
evaluation/ExplReturns Std     0.2014303616329636
evaluation/ExplReturns Max     480.3176839411781
evaluation/ExplReturns Min     479.71366294204824
evaluation/Actions Mean        0.059866298
evaluation/Actions Std         0.47745103
evaluation/Actions Max         0.99953353
evaluation/Actions Min         -0.9995795
evaluation/Num Paths           10
evaluation/Average Returns     480.01862775636954
time/data storing (s)          0.03229902591556311
time/evaluation sampling (s)   109.54900575336069
time/exploration sampling (s)  110.8173165153712
time/logging (s)               0.030435843393206596
time/saving (s)                0.012458243407309055
time/training (s)              9.752623734995723
time/epoch (s)                 230.1941391164437
time/total (s)                 89298.03693793807
Epoch                          381
-----------------------------  ---------------------
2023-08-01 18:46:19.449257 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 382 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3926.5718]
trainer/QF1 Loss               0.025090396
trainer/QF2 Loss               0.027412292
trainer/Policy Loss            -90.923584
trainer/Q1 Predictions Mean    102.63385
trainer/Q1 Predictions Std     2.4375803
trainer/Q1 Predictions Max     104.47007
trainer/Q1 Predictions Min     80.26962
trainer/Q2 Predictions Mean    102.58902
trainer/Q2 Predictions Std     2.4531443
trainer/Q2 Predictions Max     104.52013
trainer/Q2 Predictions Min     79.784645
trainer/Q Targets Mean         102.62991
trainer/Q Targets Std          2.4340944
trainer/Q Targets Max          104.4592
trainer/Q Targets Min          80.36515
trainer/Log Pis Mean           11.754555
trainer/Log Pis Std            8.247206
trainer/Log Pis Max            45.956314
trainer/Log Pis Min            -2.6993628
trainer/Policy mu Mean         0.14750558
trainer/Policy mu Std          1.5888252
trainer/Policy mu Max          6.374393
trainer/Policy mu Min          -5.272951
trainer/Policy log std Mean    -0.7616679
trainer/Policy log std Std     0.31216586
trainer/Policy log std Max     0.19348317
trainer/Policy log std Min     -1.9645154
trainer/Alpha                  0.0013871011324226856
trainer/Alpha Loss             -1.6152048110961914
exploration/num steps total    1916000
exploration/num paths total    3832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9546221354627378
exploration/Rewards Std        0.0469455878310815
exploration/Rewards Max        0.9791170224311729
exploration/Rewards Min        0.49718538997950407
exploration/Returns Mean       477.311067731369
exploration/Returns Std        0.21199581527062109
exploration/Returns Max        477.83106129368815
exploration/Returns Min        477.0509583765157
exploration/Actions Mean       0.018217642
exploration/Actions Std        0.5759425
exploration/Actions Max        0.9998817
exploration/Actions Min        -0.999858
exploration/Num Paths          10
exploration/Average Returns    477.311067731369
evaluation/num steps total     1915000
evaluation/num paths total     3830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9542248624214299
evaluation/Rewards Std         0.0464378283991423
evaluation/Rewards Max         0.9776615372748548
evaluation/Rewards Min         0.494378641821223
evaluation/Returns Mean        477.1124312107148
evaluation/Returns Std         0.6818612067764565
evaluation/Returns Max         478.5819046522913
evaluation/Returns Min         475.8235376803667
evaluation/ExplReturns Mean    477.1124312107148
evaluation/ExplReturns Std     0.6818612067764565
evaluation/ExplReturns Max     478.5819046522913
evaluation/ExplReturns Min     475.8235376803667
evaluation/Actions Mean        0.012920979
evaluation/Actions Std         0.46575767
evaluation/Actions Max         0.99881995
evaluation/Actions Min         -0.998991
evaluation/Num Paths           10
evaluation/Average Returns     477.1124312107148
time/data storing (s)          0.03208576515316963
time/evaluation sampling (s)   110.86545704118907
time/exploration sampling (s)  112.14293054491282
time/logging (s)               0.03066957090049982
time/saving (s)                0.010421577841043472
time/training (s)              9.529227579943836
time/epoch (s)                 232.61079207994044
time/total (s)                 89530.6502211513
Epoch                          382
-----------------------------  ---------------------
2023-08-01 18:50:14.572486 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 383 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3800.6248]
trainer/QF1 Loss               0.022657752
trainer/QF2 Loss               0.04378098
trainer/Policy Loss            -89.70688
trainer/Q1 Predictions Mean    102.61759
trainer/Q1 Predictions Std     1.9802375
trainer/Q1 Predictions Max     104.343094
trainer/Q1 Predictions Min     85.17544
trainer/Q2 Predictions Mean    102.57605
trainer/Q2 Predictions Std     2.0279431
trainer/Q2 Predictions Max     104.28166
trainer/Q2 Predictions Min     83.79578
trainer/Q Targets Mean         102.64632
trainer/Q Targets Std          1.9467862
trainer/Q Targets Max          104.39668
trainer/Q Targets Min          85.87255
trainer/Log Pis Mean           12.965152
trainer/Log Pis Std            7.645672
trainer/Log Pis Max            42.42961
trainer/Log Pis Min            -2.6226482
trainer/Policy mu Mean         0.32005724
trainer/Policy mu Std          1.6168461
trainer/Policy mu Max          5.8200264
trainer/Policy mu Min          -7.0991993
trainer/Policy log std Mean    -0.74154025
trainer/Policy log std Std     0.327786
trainer/Policy log std Max     0.62724257
trainer/Policy log std Min     -2.2296658
trainer/Alpha                  0.0013451785780489445
trainer/Alpha Loss             6.381147384643555
exploration/num steps total    1921000
exploration/num paths total    3842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9614791200340475
exploration/Rewards Std        0.04873485719998766
exploration/Rewards Max        0.9789972183875518
exploration/Rewards Min        0.4976974981014971
exploration/Returns Mean       480.73956001702373
exploration/Returns Std        0.315242414780409
exploration/Returns Max        481.3861057499578
exploration/Returns Min        480.052100964388
exploration/Actions Mean       0.020444417
exploration/Actions Std        0.6043757
exploration/Actions Max        0.99978125
exploration/Actions Min        -0.99990493
exploration/Num Paths          10
exploration/Average Returns    480.73956001702373
evaluation/num steps total     1920000
evaluation/num paths total     3840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9620254783794655
evaluation/Rewards Std         0.049027326359814105
evaluation/Rewards Max         0.9784344943839287
evaluation/Rewards Min         0.4857490948335042
evaluation/Returns Mean        481.01273918973254
evaluation/Returns Std         0.2887948911663158
evaluation/Returns Max         481.40661774611317
evaluation/Returns Min         480.58967045798244
evaluation/ExplReturns Mean    481.01273918973254
evaluation/ExplReturns Std     0.2887948911663158
evaluation/ExplReturns Max     481.40661774611317
evaluation/ExplReturns Min     480.58967045798244
evaluation/Actions Mean        0.0063651693
evaluation/Actions Std         0.5292171
evaluation/Actions Max         0.9984333
evaluation/Actions Min         -0.99919385
evaluation/Num Paths           10
evaluation/Average Returns     481.01273918973254
time/data storing (s)          0.03199369180947542
time/evaluation sampling (s)   112.4008962335065
time/exploration sampling (s)  113.22230657655746
time/logging (s)               0.03050455078482628
time/saving (s)                0.01247989572584629
time/training (s)              9.419072207063437
time/epoch (s)                 235.11725315544754
time/total (s)                 89765.7700152006
Epoch                          383
-----------------------------  ---------------------
2023-08-01 18:54:10.288534 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 384 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3441.447]
trainer/QF1 Loss               0.018663893
trainer/QF2 Loss               0.02663765
trainer/Policy Loss            -91.26362
trainer/Q1 Predictions Mean    102.54905
trainer/Q1 Predictions Std     3.1281476
trainer/Q1 Predictions Max     104.25255
trainer/Q1 Predictions Min     65.521545
trainer/Q2 Predictions Mean    102.59328
trainer/Q2 Predictions Std     3.1301193
trainer/Q2 Predictions Max     104.26324
trainer/Q2 Predictions Min     66.94452
trainer/Q Targets Mean         102.55984
trainer/Q Targets Std          3.1453824
trainer/Q Targets Max          104.21848
trainer/Q Targets Min          65.67085
trainer/Log Pis Mean           11.365405
trainer/Log Pis Std            9.131046
trainer/Log Pis Max            72.65348
trainer/Log Pis Min            -6.2434254
trainer/Policy mu Mean         0.08753938
trainer/Policy mu Std          1.5921006
trainer/Policy mu Max          9.811178
trainer/Policy mu Min          -5.968622
trainer/Policy log std Mean    -0.7134759
trainer/Policy log std Std     0.32684237
trainer/Policy log std Max     1.1938543
trainer/Policy log std Min     -2.0489922
trainer/Alpha                  0.0013667080784216523
trainer/Alpha Loss             -4.185262203216553
exploration/num steps total    1926000
exploration/num paths total    3852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9628077523915864
exploration/Rewards Std        0.04972406746907234
exploration/Rewards Max        0.9798696232388819
exploration/Rewards Min        0.4956980872461887
exploration/Returns Mean       481.40387619579326
exploration/Returns Std        0.6606981370524584
exploration/Returns Max        482.2270713845966
exploration/Returns Min        480.16650498450525
exploration/Actions Mean       0.02726896
exploration/Actions Std        0.6330722
exploration/Actions Max        0.99983335
exploration/Actions Min        -0.99991584
exploration/Num Paths          10
exploration/Average Returns    481.40387619579326
evaluation/num steps total     1925000
evaluation/num paths total     3850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9642715391960737
evaluation/Rewards Std         0.05002301464052336
evaluation/Rewards Max         0.9797684485657463
evaluation/Rewards Min         0.4908330507195448
evaluation/Returns Mean        482.135769598037
evaluation/Returns Std         0.6147846109583264
evaluation/Returns Max         483.06758018811774
evaluation/Returns Min         481.01255671057083
evaluation/ExplReturns Mean    482.135769598037
evaluation/ExplReturns Std     0.6147846109583264
evaluation/ExplReturns Max     483.06758018811774
evaluation/ExplReturns Min     481.01255671057083
evaluation/Actions Mean        0.02464488
evaluation/Actions Std         0.5412984
evaluation/Actions Max         0.9995322
evaluation/Actions Min         -0.9995618
evaluation/Num Paths           10
evaluation/Average Returns     482.135769598037
time/data storing (s)          0.03222515806555748
time/evaluation sampling (s)   112.92905573640019
time/exploration sampling (s)  113.01316208858043
time/logging (s)               0.032404594123363495
time/saving (s)                0.015011436305940151
time/training (s)              9.69023313280195
time/epoch (s)                 235.71209214627743
time/total (s)                 90001.48463035002
Epoch                          384
-----------------------------  ---------------------
2023-08-01 18:58:03.189458 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 385 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3714.9094]
trainer/QF1 Loss               0.017657757
trainer/QF2 Loss               0.01719583
trainer/Policy Loss            -90.712845
trainer/Q1 Predictions Mean    102.59687
trainer/Q1 Predictions Std     1.9276158
trainer/Q1 Predictions Max     104.502975
trainer/Q1 Predictions Min     87.080605
trainer/Q2 Predictions Mean    102.63823
trainer/Q2 Predictions Std     1.9211478
trainer/Q2 Predictions Max     104.83416
trainer/Q2 Predictions Min     87.63786
trainer/Q Targets Mean         102.63623
trainer/Q Targets Std          1.9097092
trainer/Q Targets Max          104.536446
trainer/Q Targets Min          87.364105
trainer/Log Pis Mean           11.970424
trainer/Log Pis Std            8.729706
trainer/Log Pis Max            68.18947
trainer/Log Pis Min            -4.9245534
trainer/Policy mu Mean         0.2898878
trainer/Policy mu Std          1.5694876
trainer/Policy mu Max          7.4517875
trainer/Policy mu Min          -8.600919
trainer/Policy log std Mean    -0.7185011
trainer/Policy log std Std     0.3268918
trainer/Policy log std Max     0.1745671
trainer/Policy log std Min     -2.079923
trainer/Alpha                  0.0013608306180685759
trainer/Alpha Loss             -0.19519615173339844
exploration/num steps total    1931000
exploration/num paths total    3862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639175849701127
exploration/Rewards Std        0.05068963402698348
exploration/Rewards Max        0.9798312156155058
exploration/Rewards Min        0.4900656311231011
exploration/Returns Mean       481.95879248505616
exploration/Returns Std        0.4511258842049774
exploration/Returns Max        482.81074828865405
exploration/Returns Min        481.22484254129733
exploration/Actions Mean       0.07151188
exploration/Actions Std        0.6277131
exploration/Actions Max        0.9999158
exploration/Actions Min        -0.99994695
exploration/Num Paths          10
exploration/Average Returns    481.95879248505616
evaluation/num steps total     1930000
evaluation/num paths total     3860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9662661418307703
evaluation/Rewards Std         0.04885269088498527
evaluation/Rewards Max         0.9794437920717493
evaluation/Rewards Min         0.48931430974872314
evaluation/Returns Mean        483.1330709153851
evaluation/Returns Std         0.11089159521399948
evaluation/Returns Max         483.280651570365
evaluation/Returns Min         482.9598039352071
evaluation/ExplReturns Mean    483.1330709153851
evaluation/ExplReturns Std     0.11089159521399948
evaluation/ExplReturns Max     483.280651570365
evaluation/ExplReturns Min     482.9598039352071
evaluation/Actions Mean        0.06653341
evaluation/Actions Std         0.55315655
evaluation/Actions Max         0.9993
evaluation/Actions Min         -0.9995345
evaluation/Num Paths           10
evaluation/Average Returns     483.1330709153851
time/data storing (s)          0.03196007013320923
time/evaluation sampling (s)   110.85761490371078
time/exploration sampling (s)  112.30752012412995
time/logging (s)               0.030545398592948914
time/saving (s)                0.01037189457565546
time/training (s)              9.655262748710811
time/epoch (s)                 232.89327513985336
time/total (s)                 90234.38042448182
Epoch                          385
-----------------------------  ---------------------
2023-08-01 19:01:58.790869 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 386 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3605.387]
trainer/QF1 Loss               0.027094096
trainer/QF2 Loss               0.019627891
trainer/Policy Loss            -90.974754
trainer/Q1 Predictions Mean    102.690414
trainer/Q1 Predictions Std     1.9236127
trainer/Q1 Predictions Max     104.15062
trainer/Q1 Predictions Min     87.78794
trainer/Q2 Predictions Mean    102.62582
trainer/Q2 Predictions Std     1.9483137
trainer/Q2 Predictions Max     104.16081
trainer/Q2 Predictions Min     87.55028
trainer/Q Targets Mean         102.60384
trainer/Q Targets Std          1.9370856
trainer/Q Targets Max          104.0416
trainer/Q Targets Min          88.08347
trainer/Log Pis Mean           11.749377
trainer/Log Pis Std            7.8948774
trainer/Log Pis Max            42.402664
trainer/Log Pis Min            -6.7711973
trainer/Policy mu Mean         0.035064206
trainer/Policy mu Std          1.5707049
trainer/Policy mu Max          7.1311455
trainer/Policy mu Min          -9.1606
trainer/Policy log std Mean    -0.73744226
trainer/Policy log std Std     0.31244543
trainer/Policy log std Max     0.853783
trainer/Policy log std Min     -2.0974247
trainer/Alpha                  0.0013545025140047073
trainer/Alpha Loss             -1.6552228927612305
exploration/num steps total    1936000
exploration/num paths total    3872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9606317395964299
exploration/Rewards Std        0.051340863715290945
exploration/Rewards Max        0.9794775095453336
exploration/Rewards Min        0.49502933370167634
exploration/Returns Mean       480.31586979821486
exploration/Returns Std        1.599235049256718
exploration/Returns Max        482.1114903589024
exploration/Returns Min        476.382509492085
exploration/Actions Mean       0.017812373
exploration/Actions Std        0.6147115
exploration/Actions Max        0.99993765
exploration/Actions Min        -0.99990946
exploration/Num Paths          10
exploration/Average Returns    480.31586979821486
evaluation/num steps total     1935000
evaluation/num paths total     3870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9650585902503662
evaluation/Rewards Std         0.04778159562099572
evaluation/Rewards Max         0.9787889343273012
evaluation/Rewards Min         0.4949668008958864
evaluation/Returns Mean        482.52929512518324
evaluation/Returns Std         0.5668197856080018
evaluation/Returns Max         483.0938549142607
evaluation/Returns Min         481.3123860992062
evaluation/ExplReturns Mean    482.52929512518324
evaluation/ExplReturns Std     0.5668197856080018
evaluation/ExplReturns Max     483.0938549142607
evaluation/ExplReturns Min     481.3123860992062
evaluation/Actions Mean        0.045472875
evaluation/Actions Std         0.5301012
evaluation/Actions Max         0.9994176
evaluation/Actions Min         -0.9994054
evaluation/Num Paths           10
evaluation/Average Returns     482.52929512518324
time/data storing (s)          0.032011644914746284
time/evaluation sampling (s)   113.25705130957067
time/exploration sampling (s)  113.42808601818979
time/logging (s)               0.030864203348755836
time/saving (s)                0.012812964618206024
time/training (s)              8.835112817585468
time/epoch (s)                 235.59593895822763
time/total (s)                 90469.97883824352
Epoch                          386
-----------------------------  ---------------------
2023-08-01 19:05:52.602150 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 387 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3806.48]
trainer/QF1 Loss               0.03635326
trainer/QF2 Loss               0.032729615
trainer/Policy Loss            -89.2245
trainer/Q1 Predictions Mean    102.24617
trainer/Q1 Predictions Std     3.282166
trainer/Q1 Predictions Max     106.04527
trainer/Q1 Predictions Min     73.79442
trainer/Q2 Predictions Mean    102.29789
trainer/Q2 Predictions Std     3.276082
trainer/Q2 Predictions Max     106.12098
trainer/Q2 Predictions Min     73.47941
trainer/Q Targets Mean         102.306625
trainer/Q Targets Std          3.2850616
trainer/Q Targets Max          106.42572
trainer/Q Targets Min          74.18976
trainer/Log Pis Mean           13.11764
trainer/Log Pis Std            9.484665
trainer/Log Pis Max            61.646324
trainer/Log Pis Min            -2.0405684
trainer/Policy mu Mean         0.22143756
trainer/Policy mu Std          1.6447064
trainer/Policy mu Max          10.9713745
trainer/Policy mu Min          -5.4180365
trainer/Policy log std Mean    -0.7768287
trainer/Policy log std Std     0.34847498
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.2740133
trainer/Alpha                  0.0012295892229303718
trainer/Alpha Loss             7.489592552185059
exploration/num steps total    1941000
exploration/num paths total    3882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9432745013872731
exploration/Rewards Std        0.050145694555970406
exploration/Rewards Max        0.9726615730816586
exploration/Rewards Min        0.49446214685517786
exploration/Returns Mean       471.6372506936367
exploration/Returns Std        1.3840569262220164
exploration/Returns Max        473.4982805607513
exploration/Returns Min        468.04750013413906
exploration/Actions Mean       0.009167215
exploration/Actions Std        0.6103569
exploration/Actions Max        0.9999203
exploration/Actions Min        -0.9999538
exploration/Num Paths          10
exploration/Average Returns    471.6372506936367
evaluation/num steps total     1940000
evaluation/num paths total     3880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9459551745729193
evaluation/Rewards Std         0.049308400287878085
evaluation/Rewards Max         0.9738591116582946
evaluation/Rewards Min         0.4947499458495206
evaluation/Returns Mean        472.97758728645977
evaluation/Returns Std         2.988845885370747
evaluation/Returns Max         477.19523700625325
evaluation/Returns Min         468.7869313490032
evaluation/ExplReturns Mean    472.97758728645977
evaluation/ExplReturns Std     2.988845885370747
evaluation/ExplReturns Max     477.19523700625325
evaluation/ExplReturns Min     468.7869313490032
evaluation/Actions Mean        0.0055005555
evaluation/Actions Std         0.55493814
evaluation/Actions Max         0.99953336
evaluation/Actions Min         -0.99985784
evaluation/Num Paths           10
evaluation/Average Returns     472.97758728645977
time/data storing (s)          0.032070592045784
time/evaluation sampling (s)   112.3470628997311
time/exploration sampling (s)  112.57549252640456
time/logging (s)               0.030560653656721115
time/saving (s)                0.012756314128637314
time/training (s)              8.807158999145031
time/epoch (s)                 233.80510198511183
time/total (s)                 90703.78650248237
Epoch                          387
-----------------------------  ---------------------
2023-08-01 19:09:44.453011 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 388 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3459.4036]
trainer/QF1 Loss               0.042003263
trainer/QF2 Loss               0.03426998
trainer/Policy Loss            -90.02588
trainer/Q1 Predictions Mean    102.23386
trainer/Q1 Predictions Std     2.6640146
trainer/Q1 Predictions Max     103.93902
trainer/Q1 Predictions Min     76.73183
trainer/Q2 Predictions Mean    102.239296
trainer/Q2 Predictions Std     2.6889596
trainer/Q2 Predictions Max     103.86044
trainer/Q2 Predictions Min     76.12904
trainer/Q Targets Mean         102.35091
trainer/Q Targets Std          2.649212
trainer/Q Targets Max          103.927765
trainer/Q Targets Min          76.302246
trainer/Log Pis Mean           12.29521
trainer/Log Pis Std            10.879162
trainer/Log Pis Max            78.06143
trainer/Log Pis Min            -2.399112
trainer/Policy mu Mean         0.04519072
trainer/Policy mu Std          1.6299098
trainer/Policy mu Max          7.998886
trainer/Policy mu Min          -9.402361
trainer/Policy log std Mean    -0.7644162
trainer/Policy log std Std     0.33333328
trainer/Policy log std Max     0.84911126
trainer/Policy log std Min     -2.1825697
trainer/Alpha                  0.0012459040153771639
trainer/Alpha Loss             1.974302887916565
exploration/num steps total    1946000
exploration/num paths total    3892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9580057699527893
exploration/Rewards Std        0.04979392100257102
exploration/Rewards Max        0.979496738666934
exploration/Rewards Min        0.48983413782958274
exploration/Returns Mean       479.00288497639457
exploration/Returns Std        0.2924463344976248
exploration/Returns Max        479.577799630488
exploration/Returns Min        478.61376676494086
exploration/Actions Mean       0.005858903
exploration/Actions Std        0.59540653
exploration/Actions Max        0.999925
exploration/Actions Min        -0.99981207
exploration/Num Paths          10
exploration/Average Returns    479.00288497639457
evaluation/num steps total     1945000
evaluation/num paths total     3890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9592897646896982
evaluation/Rewards Std         0.050121843043104033
evaluation/Rewards Max         0.9791535719487021
evaluation/Rewards Min         0.48798250067152465
evaluation/Returns Mean        479.64488234484895
evaluation/Returns Std         0.23651698645809335
evaluation/Returns Max         480.20711437172383
evaluation/Returns Min         479.31434561357725
evaluation/ExplReturns Mean    479.64488234484895
evaluation/ExplReturns Std     0.23651698645809335
evaluation/ExplReturns Max     480.20711437172383
evaluation/ExplReturns Min     479.31434561357725
evaluation/Actions Mean        0.008902326
evaluation/Actions Std         0.53624606
evaluation/Actions Max         0.99961495
evaluation/Actions Min         -0.998786
evaluation/Num Paths           10
evaluation/Average Returns     479.64488234484895
time/data storing (s)          0.03227784391492605
time/evaluation sampling (s)   110.64441292453557
time/exploration sampling (s)  111.6367308916524
time/logging (s)               0.03117350023239851
time/saving (s)                0.012410953640937805
time/training (s)              9.488627005368471
time/epoch (s)                 231.8456331193447
time/total (s)                 90935.63463120908
Epoch                          388
-----------------------------  ---------------------
2023-08-01 19:13:38.007233 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 389 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3467.2158]
trainer/QF1 Loss               0.05664187
trainer/QF2 Loss               0.038657334
trainer/Policy Loss            -89.5282
trainer/Q1 Predictions Mean    101.93273
trainer/Q1 Predictions Std     4.288646
trainer/Q1 Predictions Max     108.05995
trainer/Q1 Predictions Min     64.28137
trainer/Q2 Predictions Mean    101.95311
trainer/Q2 Predictions Std     4.2879124
trainer/Q2 Predictions Max     108.13812
trainer/Q2 Predictions Min     63.812305
trainer/Q Targets Mean         102.04991
trainer/Q Targets Std          4.197971
trainer/Q Targets Max          108.3739
trainer/Q Targets Min          64.63497
trainer/Log Pis Mean           12.496557
trainer/Log Pis Std            10.139103
trainer/Log Pis Max            59.224518
trainer/Log Pis Min            -3.2705135
trainer/Policy mu Mean         -0.032756895
trainer/Policy mu Std          1.6477581
trainer/Policy mu Max          6.9503016
trainer/Policy mu Min          -7.3667126
trainer/Policy log std Mean    -0.71331316
trainer/Policy log std Std     0.31069422
trainer/Policy log std Max     0.54071957
trainer/Policy log std Min     -1.7613374
trainer/Alpha                  0.0013065007515251637
trainer/Alpha Loss             3.2973105907440186
exploration/num steps total    1951000
exploration/num paths total    3902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9573736346140072
exploration/Rewards Std        0.05492442195178059
exploration/Rewards Max        0.979906575521008
exploration/Rewards Min        0.49223806637279477
exploration/Returns Mean       478.6868173070037
exploration/Returns Std        1.1430870325210627
exploration/Returns Max        480.1010421487338
exploration/Returns Min        477.05299874738154
exploration/Actions Mean       0.101453565
exploration/Actions Std        0.583863
exploration/Actions Max        0.9999714
exploration/Actions Min        -0.9999268
exploration/Num Paths          10
exploration/Average Returns    478.6868173070037
evaluation/num steps total     1950000
evaluation/num paths total     3900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9485539141609992
evaluation/Rewards Std         0.05755589861260186
evaluation/Rewards Max         0.9793979537584854
evaluation/Rewards Min         0.4859211126130579
evaluation/Returns Mean        474.2769570804996
evaluation/Returns Std         1.0749688959783772
evaluation/Returns Max         475.64343745650706
evaluation/Returns Min         472.87895402413557
evaluation/ExplReturns Mean    474.2769570804996
evaluation/ExplReturns Std     1.0749688959783772
evaluation/ExplReturns Max     475.64343745650706
evaluation/ExplReturns Min     472.87895402413557
evaluation/Actions Mean        0.08995256
evaluation/Actions Std         0.46967706
evaluation/Actions Max         0.9995104
evaluation/Actions Min         -0.99967915
evaluation/Num Paths           10
evaluation/Average Returns     474.2769570804996
time/data storing (s)          0.03213516902178526
time/evaluation sampling (s)   112.67987903859466
time/exploration sampling (s)  111.1441722875461
time/logging (s)               0.031121780164539814
time/saving (s)                0.012845121324062347
time/training (s)              9.648084360174835
time/epoch (s)                 233.54823775682598
time/total (s)                 91169.18538638297
Epoch                          389
-----------------------------  ---------------------
2023-08-01 19:17:32.422780 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 390 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3586.293]
trainer/QF1 Loss               0.018486427
trainer/QF2 Loss               0.03252124
trainer/Policy Loss            -90.58326
trainer/Q1 Predictions Mean    102.274734
trainer/Q1 Predictions Std     2.200735
trainer/Q1 Predictions Max     103.8207
trainer/Q1 Predictions Min     78.8364
trainer/Q2 Predictions Mean    102.38279
trainer/Q2 Predictions Std     2.2295291
trainer/Q2 Predictions Max     103.86199
trainer/Q2 Predictions Min     78.336
trainer/Q Targets Mean         102.269516
trainer/Q Targets Std          2.2313662
trainer/Q Targets Max          103.78698
trainer/Q Targets Min          78.26005
trainer/Log Pis Mean           11.799957
trainer/Log Pis Std            8.203819
trainer/Log Pis Max            58.80625
trainer/Log Pis Min            -4.8603487
trainer/Policy mu Mean         -0.0020827346
trainer/Policy mu Std          1.6048219
trainer/Policy mu Max          5.865161
trainer/Policy mu Min          -7.307825
trainer/Policy log std Mean    -0.7031031
trainer/Policy log std Std     0.298946
trainer/Policy log std Max     0.7878109
trainer/Policy log std Min     -2.2793593
trainer/Alpha                  0.0013087911065667868
trainer/Alpha Loss             -1.3280129432678223
exploration/num steps total    1956000
exploration/num paths total    3912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9503478465862765
exploration/Rewards Std        0.049400397674378455
exploration/Rewards Max        0.9797288432194664
exploration/Rewards Min        0.4820783335732743
exploration/Returns Mean       475.17392329313805
exploration/Returns Std        0.7076347952579295
exploration/Returns Max        476.3179738932443
exploration/Returns Min        473.6546462971985
exploration/Actions Mean       0.07713627
exploration/Actions Std        0.60369515
exploration/Actions Max        0.9999725
exploration/Actions Min        -0.999977
exploration/Num Paths          10
exploration/Average Returns    475.17392329313805
evaluation/num steps total     1955000
evaluation/num paths total     3910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9521608744014258
evaluation/Rewards Std         0.049224405884863716
evaluation/Rewards Max         0.9794310583632599
evaluation/Rewards Min         0.4893826500651868
evaluation/Returns Mean        476.0804372007128
evaluation/Returns Std         1.0208307631333478
evaluation/Returns Max         477.6602376630599
evaluation/Returns Min         474.045852931713
evaluation/ExplReturns Mean    476.0804372007128
evaluation/ExplReturns Std     1.0208307631333478
evaluation/ExplReturns Max     477.6602376630599
evaluation/ExplReturns Min     474.045852931713
evaluation/Actions Mean        0.09955414
evaluation/Actions Std         0.5008078
evaluation/Actions Max         0.9998159
evaluation/Actions Min         -0.99955374
evaluation/Num Paths           10
evaluation/Average Returns     476.0804372007128
time/data storing (s)          0.032127201557159424
time/evaluation sampling (s)   111.93301673885435
time/exploration sampling (s)  112.66586739756167
time/logging (s)               0.030717816203832626
time/saving (s)                0.011559379287064075
time/training (s)              9.735967673361301
time/epoch (s)                 234.40925620682538
time/total (s)                 91403.5971701825
Epoch                          390
-----------------------------  ---------------------
2023-08-01 19:21:27.472915 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 391 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3606.6118]
trainer/QF1 Loss               0.044225916
trainer/QF2 Loss               0.037413277
trainer/Policy Loss            -91.160904
trainer/Q1 Predictions Mean    102.43741
trainer/Q1 Predictions Std     2.2013705
trainer/Q1 Predictions Max     109.07799
trainer/Q1 Predictions Min     80.46687
trainer/Q2 Predictions Mean    102.42499
trainer/Q2 Predictions Std     2.1861813
trainer/Q2 Predictions Max     109.306145
trainer/Q2 Predictions Min     80.77883
trainer/Q Targets Mean         102.31271
trainer/Q Targets Std          2.2070255
trainer/Q Targets Max          109.33106
trainer/Q Targets Min          80.01152
trainer/Log Pis Mean           11.363331
trainer/Log Pis Std            9.487266
trainer/Log Pis Max            50.95372
trainer/Log Pis Min            -3.9618354
trainer/Policy mu Mean         -0.18771446
trainer/Policy mu Std          1.5737807
trainer/Policy mu Max          5.930603
trainer/Policy mu Min          -6.6418543
trainer/Policy log std Mean    -0.73053485
trainer/Policy log std Std     0.313621
trainer/Policy log std Max     0.47885263
trainer/Policy log std Min     -1.9494498
trainer/Alpha                  0.0013040821067988873
trainer/Alpha Loss             -4.228882789611816
exploration/num steps total    1961000
exploration/num paths total    3922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9136292370721493
exploration/Rewards Std        0.10657574423557216
exploration/Rewards Max        0.9795660572985541
exploration/Rewards Min        0.4890491988898975
exploration/Returns Mean       456.81461853607453
exploration/Returns Std        35.01827487295335
exploration/Returns Max        482.1283182096063
exploration/Returns Min        372.3926685128605
exploration/Actions Mean       0.050880246
exploration/Actions Std        0.64846146
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.9999996
exploration/Num Paths          10
exploration/Average Returns    456.81461853607453
evaluation/num steps total     1960000
evaluation/num paths total     3920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9055974278184867
evaluation/Rewards Std         0.11178222864657335
evaluation/Rewards Max         0.9796566425740001
evaluation/Rewards Min         0.4433219377033174
evaluation/Returns Mean        452.7987139092435
evaluation/Returns Std         31.90423731830572
evaluation/Returns Max         483.82733442115335
evaluation/Returns Min         373.4834577646261
evaluation/ExplReturns Mean    452.7987139092435
evaluation/ExplReturns Std     31.90423731830572
evaluation/ExplReturns Max     483.82733442115335
evaluation/ExplReturns Min     373.4834577646261
evaluation/Actions Mean        0.0831835
evaluation/Actions Std         0.61317164
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -0.99999994
evaluation/Num Paths           10
evaluation/Average Returns     452.7987139092435
time/data storing (s)          0.03246556036174297
time/evaluation sampling (s)   112.03431294765323
time/exploration sampling (s)  113.28633059188724
time/logging (s)               0.03127605188637972
time/saving (s)                0.012736588716506958
time/training (s)              9.64766106940806
time/epoch (s)                 235.04478280991316
time/total (s)                 91638.64442873094
Epoch                          391
-----------------------------  ---------------------
2023-08-01 19:25:28.431318 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 392 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3864.3005]
trainer/QF1 Loss               0.025556188
trainer/QF2 Loss               0.02454022
trainer/Policy Loss            -89.57017
trainer/Q1 Predictions Mean    102.22778
trainer/Q1 Predictions Std     2.6685095
trainer/Q1 Predictions Max     104.7026
trainer/Q1 Predictions Min     71.15765
trainer/Q2 Predictions Mean    102.26137
trainer/Q2 Predictions Std     2.7030988
trainer/Q2 Predictions Max     104.89651
trainer/Q2 Predictions Min     70.6903
trainer/Q Targets Mean         102.212265
trainer/Q Targets Std          2.690557
trainer/Q Targets Max          105.12154
trainer/Q Targets Min          70.53096
trainer/Log Pis Mean           12.77203
trainer/Log Pis Std            10.228849
trainer/Log Pis Max            77.299805
trainer/Log Pis Min            -3.7592278
trainer/Policy mu Mean         0.021281563
trainer/Policy mu Std          1.6503283
trainer/Policy mu Max          5.620594
trainer/Policy mu Min          -10.157358
trainer/Policy log std Mean    -0.7101629
trainer/Policy log std Std     0.29385468
trainer/Policy log std Max     1.025848
trainer/Policy log std Min     -2.094009
trainer/Alpha                  0.0013702854048460722
trainer/Alpha Loss             5.0898284912109375
exploration/num steps total    1966000
exploration/num paths total    3932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7322160971290137
exploration/Rewards Std        0.15005072711675715
exploration/Rewards Max        0.9792226437883373
exploration/Rewards Min        0.2960994053373451
exploration/Returns Mean       366.10804856450693
exploration/Returns Std        35.33858057596959
exploration/Returns Max        425.8962955756189
exploration/Returns Min        306.8279380194557
exploration/Actions Mean       0.17434996
exploration/Actions Std        0.760989
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    366.10804856450693
evaluation/num steps total     1965000
evaluation/num paths total     3930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7612815967035602
evaluation/Rewards Std         0.12102127276781592
evaluation/Rewards Max         0.9784618172220988
evaluation/Rewards Min         0.34186711648372686
evaluation/Returns Mean        380.6407983517802
evaluation/Returns Std         18.467246306157737
evaluation/Returns Max         425.5171167367364
evaluation/Returns Min         362.6809633182519
evaluation/ExplReturns Mean    380.6407983517802
evaluation/ExplReturns Std     18.467246306157737
evaluation/ExplReturns Max     425.5171167367364
evaluation/ExplReturns Min     362.6809633182519
evaluation/Actions Mean        0.1960121
evaluation/Actions Std         0.74077725
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999994
evaluation/Num Paths           10
evaluation/Average Returns     380.6407983517802
time/data storing (s)          0.03227729722857475
time/evaluation sampling (s)   115.36951051466167
time/exploration sampling (s)  116.14381086174399
time/logging (s)               0.03041583113372326
time/saving (s)                0.012668387964367867
time/training (s)              9.363012277521193
time/epoch (s)                 240.95169517025352
time/total (s)                 91879.59866286069
Epoch                          392
-----------------------------  ---------------------
2023-08-01 19:29:26.711337 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 393 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3984.4954]
trainer/QF1 Loss               0.01901666
trainer/QF2 Loss               0.02245558
trainer/Policy Loss            -91.56059
trainer/Q1 Predictions Mean    102.25924
trainer/Q1 Predictions Std     2.914655
trainer/Q1 Predictions Max     107.72018
trainer/Q1 Predictions Min     71.07603
trainer/Q2 Predictions Mean    102.31171
trainer/Q2 Predictions Std     2.9030106
trainer/Q2 Predictions Max     108.21158
trainer/Q2 Predictions Min     70.78313
trainer/Q Targets Mean         102.317184
trainer/Q Targets Std          2.8759332
trainer/Q Targets Max          107.280655
trainer/Q Targets Min          71.37913
trainer/Log Pis Mean           10.816565
trainer/Log Pis Std            8.201276
trainer/Log Pis Max            49.628433
trainer/Log Pis Min            -5.7123046
trainer/Policy mu Mean         0.07760507
trainer/Policy mu Std          1.5502908
trainer/Policy mu Max          8.826535
trainer/Policy mu Min          -6.0859723
trainer/Policy log std Mean    -0.71292996
trainer/Policy log std Std     0.31520292
trainer/Policy log std Max     1.6115993
trainer/Policy log std Min     -2.1298616
trainer/Alpha                  0.0016172691248357296
trainer/Alpha Loss             -7.605926036834717
exploration/num steps total    1971000
exploration/num paths total    3942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8309378422013164
exploration/Rewards Std        0.15016846651036897
exploration/Rewards Max        0.978852032613909
exploration/Rewards Min        0.30218664345882656
exploration/Returns Mean       415.4689211006582
exploration/Returns Std        38.4025010657588
exploration/Returns Max        456.80543324169076
exploration/Returns Min        313.294204672923
exploration/Actions Mean       0.04672985
exploration/Actions Std        0.72708195
exploration/Actions Max        0.99999994
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    415.4689211006582
evaluation/num steps total     1970000
evaluation/num paths total     3940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8312837359982044
evaluation/Rewards Std         0.13430842483863095
evaluation/Rewards Max         0.9782801838306334
evaluation/Rewards Min         0.44487153582091854
evaluation/Returns Mean        415.6418679991023
evaluation/Returns Std         22.449727207937986
evaluation/Returns Max         463.9140770245455
evaluation/Returns Min         385.6509059921742
evaluation/ExplReturns Mean    415.6418679991023
evaluation/ExplReturns Std     22.449727207937986
evaluation/ExplReturns Max     463.9140770245455
evaluation/ExplReturns Min     385.6509059921742
evaluation/Actions Mean        0.04402537
evaluation/Actions Std         0.70037067
evaluation/Actions Max         0.9999999
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     415.6418679991023
time/data storing (s)          0.032226634211838245
time/evaluation sampling (s)   113.66376281157136
time/exploration sampling (s)  114.9973946660757
time/logging (s)               0.030398212373256683
time/saving (s)                0.012798160314559937
time/training (s)              9.537565497681499
time/epoch (s)                 238.27414598222822
time/total (s)                 92117.87527776789
Epoch                          393
-----------------------------  ---------------------
2023-08-01 19:33:34.932437 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 394 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3809.5825]
trainer/QF1 Loss               0.03712578
trainer/QF2 Loss               0.027633775
trainer/Policy Loss            -89.41684
trainer/Q1 Predictions Mean    102.27148
trainer/Q1 Predictions Std     2.5659618
trainer/Q1 Predictions Max     106.8285
trainer/Q1 Predictions Min     75.65017
trainer/Q2 Predictions Mean    102.38289
trainer/Q2 Predictions Std     2.5705404
trainer/Q2 Predictions Max     107.043144
trainer/Q2 Predictions Min     75.33783
trainer/Q Targets Mean         102.3519
trainer/Q Targets Std          2.5367026
trainer/Q Targets Max          107.1122
trainer/Q Targets Min          75.15881
trainer/Log Pis Mean           13.037739
trainer/Log Pis Std            9.533053
trainer/Log Pis Max            66.356964
trainer/Log Pis Min            -4.9398293
trainer/Policy mu Mean         0.020899907
trainer/Policy mu Std          1.7083029
trainer/Policy mu Max          5.400726
trainer/Policy mu Min          -8.003029
trainer/Policy log std Mean    -0.6569998
trainer/Policy log std Std     0.28098565
trainer/Policy log std Max     1.1598239
trainer/Policy log std Min     -1.8129613
trainer/Alpha                  0.002076299861073494
trainer/Alpha Loss             6.410622596740723
exploration/num steps total    1976000
exploration/num paths total    3952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7701198924018212
exploration/Rewards Std        0.13021691748444436
exploration/Rewards Max        0.9729716731462749
exploration/Rewards Min        0.20626646797930084
exploration/Returns Mean       385.05994620091053
exploration/Returns Std        33.20009280640273
exploration/Returns Max        440.18389503798744
exploration/Returns Min        313.39047125323094
exploration/Actions Mean       0.10997168
exploration/Actions Std        0.76894295
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    385.05994620091053
evaluation/num steps total     1975000
evaluation/num paths total     3950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7963744379591184
evaluation/Rewards Std         0.11795279076354087
evaluation/Rewards Max         0.977601172690918
evaluation/Rewards Min         0.24919998207642235
evaluation/Returns Mean        398.1872189795592
evaluation/Returns Std         24.999923466217176
evaluation/Returns Max         455.893004333486
evaluation/Returns Min         354.7501452314953
evaluation/ExplReturns Mean    398.1872189795592
evaluation/ExplReturns Std     24.999923466217176
evaluation/ExplReturns Max     455.893004333486
evaluation/ExplReturns Min     354.7501452314953
evaluation/Actions Mean        0.11224716
evaluation/Actions Std         0.75095725
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     398.1872189795592
time/data storing (s)          0.032007922418415546
time/evaluation sampling (s)   118.55404899548739
time/exploration sampling (s)  120.20247460436076
time/logging (s)               0.030787521973252296
time/saving (s)                0.01134182047098875
time/training (s)              9.384961862117052
time/epoch (s)                 248.21562272682786
time/total (s)                 92366.09342665039
Epoch                          394
-----------------------------  --------------------
2023-08-01 19:37:42.388384 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 395 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3811.721]
trainer/QF1 Loss               0.033224605
trainer/QF2 Loss               0.029331412
trainer/Policy Loss            -90.679855
trainer/Q1 Predictions Mean    102.95476
trainer/Q1 Predictions Std     2.4521027
trainer/Q1 Predictions Max     106.75057
trainer/Q1 Predictions Min     85.411736
trainer/Q2 Predictions Mean    102.96608
trainer/Q2 Predictions Std     2.4519446
trainer/Q2 Predictions Max     106.48547
trainer/Q2 Predictions Min     85.42256
trainer/Q Targets Mean         102.86702
trainer/Q Targets Std          2.4471526
trainer/Q Targets Max          106.520004
trainer/Q Targets Min          84.723755
trainer/Log Pis Mean           12.44729
trainer/Log Pis Std            8.851718
trainer/Log Pis Max            55.71036
trainer/Log Pis Min            -3.2938468
trainer/Policy mu Mean         0.07916096
trainer/Policy mu Std          1.5767182
trainer/Policy mu Max          6.3579865
trainer/Policy mu Min          -5.801241
trainer/Policy log std Mean    -0.71710855
trainer/Policy log std Std     0.2936214
trainer/Policy log std Max     0.13940027
trainer/Policy log std Min     -1.8977683
trainer/Alpha                  0.002319574821740389
trainer/Alpha Loss             2.7133994102478027
exploration/num steps total    1981000
exploration/num paths total    3962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7887491136191671
exploration/Rewards Std        0.09166979316546707
exploration/Rewards Max        0.9757944341308573
exploration/Rewards Min        0.497637577352623
exploration/Returns Mean       394.37455680958357
exploration/Returns Std        6.077360755327821
exploration/Returns Max        411.72003466365254
exploration/Returns Min        389.8530999528177
exploration/Actions Mean       0.120674014
exploration/Actions Std        0.70419365
exploration/Actions Max        0.999965
exploration/Actions Min        -0.99999845
exploration/Num Paths          10
exploration/Average Returns    394.37455680958357
evaluation/num steps total     1980000
evaluation/num paths total     3960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7939247815887316
evaluation/Rewards Std         0.08327157307227943
evaluation/Rewards Max         0.9771338825743519
evaluation/Rewards Min         0.49350366038099686
evaluation/Returns Mean        396.96239079436566
evaluation/Returns Std         2.8411380143663703
evaluation/Returns Max         399.6985405592606
evaluation/Returns Min         389.63787601650887
evaluation/ExplReturns Mean    396.96239079436566
evaluation/ExplReturns Std     2.8411380143663703
evaluation/ExplReturns Max     399.6985405592606
evaluation/ExplReturns Min     389.63787601650887
evaluation/Actions Mean        0.121595986
evaluation/Actions Std         0.6563313
evaluation/Actions Max         0.99967736
evaluation/Actions Min         -0.9999992
evaluation/Num Paths           10
evaluation/Average Returns     396.96239079436566
time/data storing (s)          0.03196069784462452
time/evaluation sampling (s)   116.51098654512316
time/exploration sampling (s)  121.57114394102246
time/logging (s)               0.030428973957896233
time/saving (s)                0.010229079984128475
time/training (s)              9.294950093142688
time/epoch (s)                 247.44969933107495
time/total (s)                 92613.54562650528
Epoch                          395
-----------------------------  --------------------
2023-08-01 19:41:45.574881 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 396 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4156.582]
trainer/QF1 Loss               0.039945867
trainer/QF2 Loss               0.039738625
trainer/Policy Loss            -90.62828
trainer/Q1 Predictions Mean    102.74533
trainer/Q1 Predictions Std     3.8627715
trainer/Q1 Predictions Max     107.198395
trainer/Q1 Predictions Min     73.24047
trainer/Q2 Predictions Mean    102.73366
trainer/Q2 Predictions Std     3.9076405
trainer/Q2 Predictions Max     106.93588
trainer/Q2 Predictions Min     73.16224
trainer/Q Targets Mean         102.81988
trainer/Q Targets Std          3.859618
trainer/Q Targets Max          107.0195
trainer/Q Targets Min          73.754005
trainer/Log Pis Mean           12.246956
trainer/Log Pis Std            8.012768
trainer/Log Pis Max            49.03624
trainer/Log Pis Min            -9.82874
trainer/Policy mu Mean         0.09416344
trainer/Policy mu Std          1.5825968
trainer/Policy mu Max          6.3212013
trainer/Policy mu Min          -6.604899
trainer/Policy log std Mean    -0.72593135
trainer/Policy log std Std     0.31131706
trainer/Policy log std Max     0.46718603
trainer/Policy log std Min     -1.9892004
trainer/Alpha                  0.0021605559159070253
trainer/Alpha Loss             1.5156810283660889
exploration/num steps total    1986000
exploration/num paths total    3972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.955203084167206
exploration/Rewards Std        0.04783471751437322
exploration/Rewards Max        0.977369123126249
exploration/Rewards Min        0.4974031820349707
exploration/Returns Mean       477.6015420836028
exploration/Returns Std        1.040935569783899
exploration/Returns Max        479.28795227536745
exploration/Returns Min        475.36179592669913
exploration/Actions Mean       0.101574734
exploration/Actions Std        0.6705494
exploration/Actions Max        0.9999588
exploration/Actions Min        -0.9999979
exploration/Num Paths          10
exploration/Average Returns    477.6015420836028
evaluation/num steps total     1985000
evaluation/num paths total     3970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9554427730072436
evaluation/Rewards Std         0.04776706012912561
evaluation/Rewards Max         0.9782466988484434
evaluation/Rewards Min         0.49892621892705513
evaluation/Returns Mean        477.72138650362166
evaluation/Returns Std         1.8538475997582624
evaluation/Returns Max         480.93634924371463
evaluation/Returns Min         473.36176147925414
evaluation/ExplReturns Mean    477.72138650362166
evaluation/ExplReturns Std     1.8538475997582624
evaluation/ExplReturns Max     480.93634924371463
evaluation/ExplReturns Min     473.36176147925414
evaluation/Actions Mean        0.11172927
evaluation/Actions Std         0.6369989
evaluation/Actions Max         0.9997946
evaluation/Actions Min         -0.99935836
evaluation/Num Paths           10
evaluation/Average Returns     477.72138650362166
time/data storing (s)          0.03234497644007206
time/evaluation sampling (s)   117.03912424482405
time/exploration sampling (s)  117.36933252681047
time/logging (s)               0.030594537034630775
time/saving (s)                0.012830719351768494
time/training (s)              8.696541855111718
time/epoch (s)                 243.1807688595727
time/total (s)                 92856.72891676892
Epoch                          396
-----------------------------  ---------------------
2023-08-01 19:45:50.336496 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 397 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3838.1174]
trainer/QF1 Loss               0.037954662
trainer/QF2 Loss               0.0416952
trainer/Policy Loss            -91.71821
trainer/Q1 Predictions Mean    103.302704
trainer/Q1 Predictions Std     3.7352698
trainer/Q1 Predictions Max     107.37215
trainer/Q1 Predictions Min     74.50282
trainer/Q2 Predictions Mean    103.3268
trainer/Q2 Predictions Std     3.718277
trainer/Q2 Predictions Max     107.3541
trainer/Q2 Predictions Min     74.4596
trainer/Q Targets Mean         103.35149
trainer/Q Targets Std          3.7110667
trainer/Q Targets Max          107.27359
trainer/Q Targets Min          73.93243
trainer/Log Pis Mean           11.796616
trainer/Log Pis Std            7.7135553
trainer/Log Pis Max            72.08773
trainer/Log Pis Min            -0.48054743
trainer/Policy mu Mean         0.072438985
trainer/Policy mu Std          1.5919322
trainer/Policy mu Max          7.700073
trainer/Policy mu Min          -10.008958
trainer/Policy log std Mean    -0.72481805
trainer/Policy log std Std     0.28118843
trainer/Policy log std Max     0.60881
trainer/Policy log std Min     -1.8483244
trainer/Alpha                  0.002231612103059888
trainer/Alpha Loss             -1.241645097732544
exploration/num steps total    1991000
exploration/num paths total    3982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9428908008359039
exploration/Rewards Std        0.06609117182536269
exploration/Rewards Max        0.9787254453112425
exploration/Rewards Min        0.4868781530022343
exploration/Returns Mean       471.4454004179521
exploration/Returns Std        4.19121509015841
exploration/Returns Max        478.4323273340235
exploration/Returns Min        463.2505723280455
exploration/Actions Mean       0.098550685
exploration/Actions Std        0.654692
exploration/Actions Max        0.9999783
exploration/Actions Min        -0.9999753
exploration/Num Paths          10
exploration/Average Returns    471.4454004179521
evaluation/num steps total     1990000
evaluation/num paths total     3980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9284740337969897
evaluation/Rewards Std         0.08788413641554742
evaluation/Rewards Max         0.9782298868491538
evaluation/Rewards Min         0.4899413511148672
evaluation/Returns Mean        464.23701689849474
evaluation/Returns Std         27.310251723315222
evaluation/Returns Max         482.3509477775413
evaluation/Returns Min         391.48791865050526
evaluation/ExplReturns Mean    464.23701689849474
evaluation/ExplReturns Std     27.310251723315222
evaluation/ExplReturns Max     482.3509477775413
evaluation/ExplReturns Min     391.48791865050526
evaluation/Actions Mean        0.10685984
evaluation/Actions Std         0.62653357
evaluation/Actions Max         0.9995106
evaluation/Actions Min         -0.99947894
evaluation/Num Paths           10
evaluation/Average Returns     464.23701689849474
time/data storing (s)          0.03199897147715092
time/evaluation sampling (s)   119.20145127177238
time/exploration sampling (s)  115.84877634514123
time/logging (s)               0.030520614236593246
time/saving (s)                0.012526871636509895
time/training (s)              9.6304652094841
time/epoch (s)                 244.75573928374797
time/total (s)                 93101.48710886389
Epoch                          397
-----------------------------  --------------------
2023-08-01 19:49:49.092619 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 398 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3765.2444]
trainer/QF1 Loss               0.04435814
trainer/QF2 Loss               0.02974456
trainer/Policy Loss            -91.40584
trainer/Q1 Predictions Mean    103.16144
trainer/Q1 Predictions Std     4.6641264
trainer/Q1 Predictions Max     107.39387
trainer/Q1 Predictions Min     65.54881
trainer/Q2 Predictions Mean    103.25609
trainer/Q2 Predictions Std     4.6192875
trainer/Q2 Predictions Max     107.490974
trainer/Q2 Predictions Min     66.38122
trainer/Q Targets Mean         103.28354
trainer/Q Targets Std          4.662148
trainer/Q Targets Max          107.487404
trainer/Q Targets Min          65.6973
trainer/Log Pis Mean           11.884653
trainer/Log Pis Std            7.473387
trainer/Log Pis Max            55.530827
trainer/Log Pis Min            -4.204911
trainer/Policy mu Mean         0.10823959
trainer/Policy mu Std          1.5915293
trainer/Policy mu Max          14.39918
trainer/Policy mu Min          -5.00213
trainer/Policy log std Mean    -0.73770124
trainer/Policy log std Std     0.30222464
trainer/Policy log std Max     0.66704094
trainer/Policy log std Min     -2.1764987
trainer/Alpha                  0.0020618734415620565
trainer/Alpha Loss             -0.7133272886276245
exploration/num steps total    1996000
exploration/num paths total    3992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8401463759832531
exploration/Rewards Std        0.11421574488279834
exploration/Rewards Max        0.9767249891345067
exploration/Rewards Min        0.48683006076074903
exploration/Returns Mean       420.0731879916266
exploration/Returns Std        14.540941713098565
exploration/Returns Max        443.61151561469023
exploration/Returns Min        398.4507598682577
exploration/Actions Mean       0.1560034
exploration/Actions Std        0.5968827
exploration/Actions Max        0.9997718
exploration/Actions Min        -0.999977
exploration/Num Paths          10
exploration/Average Returns    420.0731879916266
evaluation/num steps total     1995000
evaluation/num paths total     3990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8514484754556368
evaluation/Rewards Std         0.10978016185439925
evaluation/Rewards Max         0.9727834860628022
evaluation/Rewards Min         0.48788992065510456
evaluation/Returns Mean        425.7242377278184
evaluation/Returns Std         19.457432814037222
evaluation/Returns Max         469.09370641643994
evaluation/Returns Min         403.7890574940379
evaluation/ExplReturns Mean    425.7242377278184
evaluation/ExplReturns Std     19.457432814037222
evaluation/ExplReturns Max     469.09370641643994
evaluation/ExplReturns Min     403.7890574940379
evaluation/Actions Mean        0.17656898
evaluation/Actions Std         0.5877966
evaluation/Actions Max         0.9976211
evaluation/Actions Min         -0.9995896
evaluation/Num Paths           10
evaluation/Average Returns     425.7242377278184
time/data storing (s)          0.03221091814339161
time/evaluation sampling (s)   113.06308811903
time/exploration sampling (s)  115.84911439102143
time/logging (s)               0.03082563355565071
time/saving (s)                0.011416777037084103
time/training (s)              9.763867924921215
time/epoch (s)                 238.75052376370877
time/total (s)                 93340.24013623968
Epoch                          398
-----------------------------  ---------------------
2023-08-01 19:53:41.453949 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 399 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3756.6174]
trainer/QF1 Loss               0.027155403
trainer/QF2 Loss               0.049747657
trainer/Policy Loss            -93.20779
trainer/Q1 Predictions Mean    103.99783
trainer/Q1 Predictions Std     2.7135048
trainer/Q1 Predictions Max     107.22956
trainer/Q1 Predictions Min     82.77364
trainer/Q2 Predictions Mean    104.07597
trainer/Q2 Predictions Std     2.719502
trainer/Q2 Predictions Max     107.345116
trainer/Q2 Predictions Min     83.556
trainer/Q Targets Mean         103.95477
trainer/Q Targets Std          2.7588558
trainer/Q Targets Max          107.18582
trainer/Q Targets Min          81.47111
trainer/Log Pis Mean           10.992114
trainer/Log Pis Std            6.7462134
trainer/Log Pis Max            36.52733
trainer/Log Pis Min            -5.015697
trainer/Policy mu Mean         0.117526926
trainer/Policy mu Std          1.5414046
trainer/Policy mu Max          9.687412
trainer/Policy mu Min          -4.197382
trainer/Policy log std Mean    -0.71669704
trainer/Policy log std Std     0.28525025
trainer/Policy log std Max     1.0952097
trainer/Policy log std Min     -1.7791239
trainer/Alpha                  0.0020548745524138212
trainer/Alpha Loss             -6.235992431640625
exploration/num steps total    2001000
exploration/num paths total    4002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9510239015323124
exploration/Rewards Std        0.05078392896550724
exploration/Rewards Max        0.9760186885828341
exploration/Rewards Min        0.502728259683858
exploration/Returns Mean       475.51195076615613
exploration/Returns Std        0.5477941534038097
exploration/Returns Max        476.39953451147323
exploration/Returns Min        474.33687415914187
exploration/Actions Mean       0.101691425
exploration/Actions Std        0.58786035
exploration/Actions Max        0.99994063
exploration/Actions Min        -0.9999584
exploration/Num Paths          10
exploration/Average Returns    475.51195076615613
evaluation/num steps total     2000000
evaluation/num paths total     4000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9521316912274175
evaluation/Rewards Std         0.04935957719911797
evaluation/Rewards Max         0.9679555721099539
evaluation/Rewards Min         0.4955403000711844
evaluation/Returns Mean        476.06584561370875
evaluation/Returns Std         0.6366345754131992
evaluation/Returns Max         477.18462776306205
evaluation/Returns Min         474.8069524097306
evaluation/ExplReturns Mean    476.06584561370875
evaluation/ExplReturns Std     0.6366345754131992
evaluation/ExplReturns Max     477.18462776306205
evaluation/ExplReturns Min     474.8069524097306
evaluation/Actions Mean        0.106488906
evaluation/Actions Std         0.5400561
evaluation/Actions Max         0.9998525
evaluation/Actions Min         -0.99949545
evaluation/Num Paths           10
evaluation/Average Returns     476.06584561370875
time/data storing (s)          0.03221708908677101
time/evaluation sampling (s)   111.53918519802392
time/exploration sampling (s)  111.50232224725187
time/logging (s)               0.03079045470803976
time/saving (s)                0.010429421439766884
time/training (s)              9.240458514541388
time/epoch (s)                 232.35540292505175
time/total (s)                 93572.59802441113
Epoch                          399
-----------------------------  ---------------------
2023-08-01 19:57:36.156354 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 400 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3754.6384]
trainer/QF1 Loss               0.036106937
trainer/QF2 Loss               0.04620617
trainer/Policy Loss            -91.62803
trainer/Q1 Predictions Mean    103.821976
trainer/Q1 Predictions Std     3.373718
trainer/Q1 Predictions Max     106.72229
trainer/Q1 Predictions Min     74.37764
trainer/Q2 Predictions Mean    103.80213
trainer/Q2 Predictions Std     3.4059725
trainer/Q2 Predictions Max     106.7336
trainer/Q2 Predictions Min     74.329056
trainer/Q Targets Mean         103.90256
trainer/Q Targets Std          3.3298523
trainer/Q Targets Max          106.88317
trainer/Q Targets Min          75.58435
trainer/Log Pis Mean           12.333956
trainer/Log Pis Std            7.32073
trainer/Log Pis Max            51.260544
trainer/Log Pis Min            -4.411103
trainer/Policy mu Mean         0.10218516
trainer/Policy mu Std          1.5971804
trainer/Policy mu Max          9.062061
trainer/Policy mu Min          -5.670557
trainer/Policy log std Mean    -0.72574395
trainer/Policy log std Std     0.2990024
trainer/Policy log std Max     0.45820487
trainer/Policy log std Min     -2.1230457
trainer/Alpha                  0.002154582878574729
trainer/Alpha Loss             2.0505573749542236
exploration/num steps total    2006000
exploration/num paths total    4012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557789069805857
exploration/Rewards Std        0.04760491398319137
exploration/Rewards Max        0.9783761806680048
exploration/Rewards Min        0.4899571440886235
exploration/Returns Mean       477.88945349029274
exploration/Returns Std        0.7123347722602791
exploration/Returns Max        478.97253956197466
exploration/Returns Min        476.37299395844724
exploration/Actions Mean       0.09159905
exploration/Actions Std        0.5828986
exploration/Actions Max        0.9998805
exploration/Actions Min        -0.9999428
exploration/Num Paths          10
exploration/Average Returns    477.88945349029274
evaluation/num steps total     2005000
evaluation/num paths total     4010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9547570672215752
evaluation/Rewards Std         0.04910565957779164
evaluation/Rewards Max         0.9746821886759082
evaluation/Rewards Min         0.4843540905065002
evaluation/Returns Mean        477.3785336107876
evaluation/Returns Std         1.6587367797701142
evaluation/Returns Max         478.915868643493
evaluation/Returns Min         472.648035425827
evaluation/ExplReturns Mean    477.3785336107876
evaluation/ExplReturns Std     1.6587367797701142
evaluation/ExplReturns Max     478.915868643493
evaluation/ExplReturns Min     472.648035425827
evaluation/Actions Mean        0.09075479
evaluation/Actions Std         0.5139088
evaluation/Actions Max         0.9994711
evaluation/Actions Min         -0.9998645
evaluation/Num Paths           10
evaluation/Average Returns     477.3785336107876
time/data storing (s)          0.032267251051962376
time/evaluation sampling (s)   112.41031614784151
time/exploration sampling (s)  112.4991807397455
time/logging (s)               0.030751044861972332
time/saving (s)                0.012541485950350761
time/training (s)              9.71132520865649
time/epoch (s)                 234.6963818781078
time/total (s)                 93807.29693777207
Epoch                          400
-----------------------------  --------------------
2023-08-01 20:01:26.908631 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 401 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3774.3508]
trainer/QF1 Loss               0.050133906
trainer/QF2 Loss               0.05796215
trainer/Policy Loss            -89.69622
trainer/Q1 Predictions Mean    103.933
trainer/Q1 Predictions Std     3.9807525
trainer/Q1 Predictions Max     106.99766
trainer/Q1 Predictions Min     75.117516
trainer/Q2 Predictions Mean    103.955124
trainer/Q2 Predictions Std     3.9427536
trainer/Q2 Predictions Max     106.99442
trainer/Q2 Predictions Min     74.853065
trainer/Q Targets Mean         103.78845
trainer/Q Targets Std          3.9709136
trainer/Q Targets Max          106.92013
trainer/Q Targets Min          74.69401
trainer/Log Pis Mean           14.421787
trainer/Log Pis Std            8.79749
trainer/Log Pis Max            67.78191
trainer/Log Pis Min            -5.0431542
trainer/Policy mu Mean         0.037037615
trainer/Policy mu Std          1.7408093
trainer/Policy mu Max          9.341909
trainer/Policy mu Min          -7.1992764
trainer/Policy log std Mean    -0.7088439
trainer/Policy log std Std     0.27374172
trainer/Policy log std Max     0.68539536
trainer/Policy log std Min     -1.7042018
trainer/Alpha                  0.002334142802283168
trainer/Alpha Loss             14.67762565612793
exploration/num steps total    2011000
exploration/num paths total    4022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9608132534348477
exploration/Rewards Std        0.051359750745532895
exploration/Rewards Max        0.9794578924488306
exploration/Rewards Min        0.4900127149251685
exploration/Returns Mean       480.40662671742376
exploration/Returns Std        0.749846615393544
exploration/Returns Max        481.2466180011665
exploration/Returns Min        478.85894318756954
exploration/Actions Mean       0.06619619
exploration/Actions Std        0.6360208
exploration/Actions Max        0.9997861
exploration/Actions Min        -0.99999917
exploration/Num Paths          10
exploration/Average Returns    480.40662671742376
evaluation/num steps total     2010000
evaluation/num paths total     4020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9576413870590044
evaluation/Rewards Std         0.05214281804488864
evaluation/Rewards Max         0.9769418850476314
evaluation/Rewards Min         0.4932425987805722
evaluation/Returns Mean        478.82069352950214
evaluation/Returns Std         3.1704159909917586
evaluation/Returns Max         481.4966316987323
evaluation/Returns Min         469.85056168221934
evaluation/ExplReturns Mean    478.82069352950214
evaluation/ExplReturns Std     3.1704159909917586
evaluation/ExplReturns Max     481.4966316987323
evaluation/ExplReturns Min     469.85056168221934
evaluation/Actions Mean        0.049961567
evaluation/Actions Std         0.55767566
evaluation/Actions Max         0.9993286
evaluation/Actions Min         -0.99983424
evaluation/Num Paths           10
evaluation/Average Returns     478.82069352950214
time/data storing (s)          0.03220050875097513
time/evaluation sampling (s)   110.23344228230417
time/exploration sampling (s)  111.33537350874394
time/logging (s)               0.030927729792892933
time/saving (s)                0.012583982199430466
time/training (s)              9.101986066438258
time/epoch (s)                 230.74651407822967
time/total (s)                 94038.04593154695
Epoch                          401
-----------------------------  --------------------
2023-08-01 20:05:19.696539 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 402 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4211.924]
trainer/QF1 Loss               0.072311
trainer/QF2 Loss               0.071600124
trainer/Policy Loss            -91.867325
trainer/Q1 Predictions Mean    103.92342
trainer/Q1 Predictions Std     4.05731
trainer/Q1 Predictions Max     106.97341
trainer/Q1 Predictions Min     75.69804
trainer/Q2 Predictions Mean    103.84415
trainer/Q2 Predictions Std     4.103595
trainer/Q2 Predictions Max     106.804085
trainer/Q2 Predictions Min     75.251335
trainer/Q Targets Mean         103.94732
trainer/Q Targets Std          4.0855536
trainer/Q Targets Max          107.013855
trainer/Q Targets Min          75.59863
trainer/Log Pis Mean           12.17638
trainer/Log Pis Std            7.8764167
trainer/Log Pis Max            45.30857
trainer/Log Pis Min            -6.216864
trainer/Policy mu Mean         0.02938353
trainer/Policy mu Std          1.5907255
trainer/Policy mu Max          7.031073
trainer/Policy mu Min          -6.7304115
trainer/Policy log std Mean    -0.70373535
trainer/Policy log std Std     0.2671997
trainer/Policy log std Max     0.3924393
trainer/Policy log std Min     -1.7039902
trainer/Alpha                  0.0024048076011240482
trainer/Alpha Loss             1.0635915994644165
exploration/num steps total    2016000
exploration/num paths total    4032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9044150974668155
exploration/Rewards Std        0.09934030093248906
exploration/Rewards Max        0.9790486003414112
exploration/Rewards Min        0.49126924677532174
exploration/Returns Mean       452.2075487334076
exploration/Returns Std        5.84753997244168
exploration/Returns Max        463.07073679841716
exploration/Returns Min        445.3904229868579
exploration/Actions Mean       0.10841457
exploration/Actions Std        0.5698445
exploration/Actions Max        0.9998228
exploration/Actions Min        -0.9999788
exploration/Num Paths          10
exploration/Average Returns    452.2075487334076
evaluation/num steps total     2015000
evaluation/num paths total     4030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9536116889437202
evaluation/Rewards Std         0.0561101407829867
evaluation/Rewards Max         0.9742385845967478
evaluation/Rewards Min         0.5001688074340265
evaluation/Returns Mean        476.80584447186004
evaluation/Returns Std         3.806393974043574
evaluation/Returns Max         479.59215598744174
evaluation/Returns Min         466.27934175864306
evaluation/ExplReturns Mean    476.80584447186004
evaluation/ExplReturns Std     3.806393974043574
evaluation/ExplReturns Max     479.59215598744174
evaluation/ExplReturns Min     466.27934175864306
evaluation/Actions Mean        0.10794124
evaluation/Actions Std         0.45960587
evaluation/Actions Max         0.99779487
evaluation/Actions Min         -0.9986043
evaluation/Num Paths           10
evaluation/Average Returns     476.80584447186004
time/data storing (s)          0.03231742512434721
time/evaluation sampling (s)   111.01188040245324
time/exploration sampling (s)  112.15812646783888
time/logging (s)               0.03064008243381977
time/saving (s)                0.012689495459198952
time/training (s)              9.536077989265323
time/epoch (s)                 232.78173186257482
time/total (s)                 94270.83011772763
Epoch                          402
-----------------------------  ---------------------
2023-08-01 20:09:14.186418 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 403 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4054.723]
trainer/QF1 Loss               0.037734896
trainer/QF2 Loss               0.04618399
trainer/Policy Loss            -90.97708
trainer/Q1 Predictions Mean    104.3417
trainer/Q1 Predictions Std     3.0177915
trainer/Q1 Predictions Max     107.158966
trainer/Q1 Predictions Min     79.91318
trainer/Q2 Predictions Mean    104.37161
trainer/Q2 Predictions Std     3.0272021
trainer/Q2 Predictions Max     107.02065
trainer/Q2 Predictions Min     80.29921
trainer/Q Targets Mean         104.393524
trainer/Q Targets Std          3.064145
trainer/Q Targets Max          107.16823
trainer/Q Targets Min          78.51463
trainer/Log Pis Mean           13.5456085
trainer/Log Pis Std            8.278327
trainer/Log Pis Max            43.15551
trainer/Log Pis Min            -3.4018316
trainer/Policy mu Mean         -0.08599462
trainer/Policy mu Std          1.683368
trainer/Policy mu Max          5.561162
trainer/Policy mu Min          -5.950657
trainer/Policy log std Mean    -0.6948195
trainer/Policy log std Std     0.27833977
trainer/Policy log std Max     0.28032812
trainer/Policy log std Min     -1.7422221
trainer/Alpha                  0.0024819346144795418
trainer/Alpha Loss             9.27221393585205
exploration/num steps total    2021000
exploration/num paths total    4042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9309922720773891
exploration/Rewards Std        0.08773454349151205
exploration/Rewards Max        0.979186114079031
exploration/Rewards Min        0.4866529943596108
exploration/Returns Mean       465.49613603869466
exploration/Returns Std        3.3648475020252393
exploration/Returns Max        471.0349708826889
exploration/Returns Min        460.89501840218344
exploration/Actions Mean       -0.06128928
exploration/Actions Std        0.61595947
exploration/Actions Max        0.9999138
exploration/Actions Min        -0.9999741
exploration/Num Paths          10
exploration/Average Returns    465.49613603869466
evaluation/num steps total     2020000
evaluation/num paths total     4040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9350453849138485
evaluation/Rewards Std         0.07745081542561968
evaluation/Rewards Max         0.9732429881991284
evaluation/Rewards Min         0.49108494410677306
evaluation/Returns Mean        467.52269245692435
evaluation/Returns Std         3.755081411997075
evaluation/Returns Max         472.389832954204
evaluation/Returns Min         462.8680761394202
evaluation/ExplReturns Mean    467.52269245692435
evaluation/ExplReturns Std     3.755081411997075
evaluation/ExplReturns Max     472.389832954204
evaluation/ExplReturns Min     462.8680761394202
evaluation/Actions Mean        -0.17788431
evaluation/Actions Std         0.5337169
evaluation/Actions Max         0.9985181
evaluation/Actions Min         -0.9994072
evaluation/Num Paths           10
evaluation/Average Returns     467.52269245692435
time/data storing (s)          0.03206426277756691
time/evaluation sampling (s)   112.83646258059889
time/exploration sampling (s)  112.45235350355506
time/logging (s)               0.030518407933413982
time/saving (s)                0.010238418355584145
time/training (s)              9.122244335711002
time/epoch (s)                 234.48388150893152
time/total (s)                 94505.31643314287
Epoch                          403
-----------------------------  ---------------------
2023-08-01 20:13:11.133908 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 404 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4273.8784]
trainer/QF1 Loss               0.055627745
trainer/QF2 Loss               0.056558147
trainer/Policy Loss            -92.49446
trainer/Q1 Predictions Mean    104.7239
trainer/Q1 Predictions Std     2.5285232
trainer/Q1 Predictions Max     107.27985
trainer/Q1 Predictions Min     86.02633
trainer/Q2 Predictions Mean    104.7626
trainer/Q2 Predictions Std     2.4905555
trainer/Q2 Predictions Max     107.29834
trainer/Q2 Predictions Min     85.97598
trainer/Q Targets Mean         104.8503
trainer/Q Targets Std          2.551954
trainer/Q Targets Max          107.43222
trainer/Q Targets Min          85.63553
trainer/Log Pis Mean           12.439205
trainer/Log Pis Std            7.4440036
trainer/Log Pis Max            37.899734
trainer/Log Pis Min            -1.2408137
trainer/Policy mu Mean         -0.09066359
trainer/Policy mu Std          1.6019472
trainer/Policy mu Max          7.175315
trainer/Policy mu Min          -6.499836
trainer/Policy log std Mean    -0.6857116
trainer/Policy log std Std     0.27305758
trainer/Policy log std Max     0.9469917
trainer/Policy log std Min     -1.7825217
trainer/Alpha                  0.0024864987935870886
trainer/Alpha Loss             2.6338560581207275
exploration/num steps total    2026000
exploration/num paths total    4052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557561192013944
exploration/Rewards Std        0.05412755768040835
exploration/Rewards Max        0.9773580667273392
exploration/Rewards Min        0.4970769250392748
exploration/Returns Mean       477.87805960069716
exploration/Returns Std        1.790001839236664
exploration/Returns Max        480.7985621090795
exploration/Returns Min        474.24602532981487
exploration/Actions Mean       0.0114690745
exploration/Actions Std        0.58249986
exploration/Actions Max        0.99987006
exploration/Actions Min        -0.99995404
exploration/Num Paths          10
exploration/Average Returns    477.87805960069716
evaluation/num steps total     2025000
evaluation/num paths total     4050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9579000917711226
evaluation/Rewards Std         0.049583793208887464
evaluation/Rewards Max         0.9786833008143028
evaluation/Rewards Min         0.4925338204664571
evaluation/Returns Mean        478.9500458855612
evaluation/Returns Std         1.3375473490615009
evaluation/Returns Max         481.2745424925047
evaluation/Returns Min         476.77224459010114
evaluation/ExplReturns Mean    478.9500458855612
evaluation/ExplReturns Std     1.3375473490615009
evaluation/ExplReturns Max     481.2745424925047
evaluation/ExplReturns Min     476.77224459010114
evaluation/Actions Mean        0.016012505
evaluation/Actions Std         0.46262783
evaluation/Actions Max         0.99499613
evaluation/Actions Min         -0.99965745
evaluation/Num Paths           10
evaluation/Average Returns     478.9500458855612
time/data storing (s)          0.03249603509902954
time/evaluation sampling (s)   113.8247147295624
time/exploration sampling (s)  113.30469753406942
time/logging (s)               0.030826588161289692
time/saving (s)                0.012327345088124275
time/training (s)              9.736768908798695
time/epoch (s)                 236.94183114077896
time/total (s)                 94742.2607415244
Epoch                          404
-----------------------------  ---------------------
2023-08-01 20:17:04.362136 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 405 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4413.6987]
trainer/QF1 Loss               0.057051543
trainer/QF2 Loss               0.04567338
trainer/Policy Loss            -92.00831
trainer/Q1 Predictions Mean    104.666626
trainer/Q1 Predictions Std     4.0803456
trainer/Q1 Predictions Max     107.351036
trainer/Q1 Predictions Min     72.49947
trainer/Q2 Predictions Mean    104.661865
trainer/Q2 Predictions Std     4.037202
trainer/Q2 Predictions Max     107.270485
trainer/Q2 Predictions Min     73.83802
trainer/Q Targets Mean         104.565384
trainer/Q Targets Std          4.067138
trainer/Q Targets Max          107.208496
trainer/Q Targets Min          73.393105
trainer/Log Pis Mean           12.834391
trainer/Log Pis Std            8.276177
trainer/Log Pis Max            46.184185
trainer/Log Pis Min            -6.5265875
trainer/Policy mu Mean         0.020798774
trainer/Policy mu Std          1.6449573
trainer/Policy mu Max          7.815503
trainer/Policy mu Min          -5.6614037
trainer/Policy log std Mean    -0.7062853
trainer/Policy log std Std     0.27553564
trainer/Policy log std Max     0.65735954
trainer/Policy log std Min     -1.7364527
trainer/Alpha                  0.002416132716462016
trainer/Alpha Loss             5.027657985687256
exploration/num steps total    2031000
exploration/num paths total    4062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9595591670138001
exploration/Rewards Std        0.05379895657600977
exploration/Rewards Max        0.9778363125933744
exploration/Rewards Min        0.49855152834137223
exploration/Returns Mean       479.77958350690005
exploration/Returns Std        1.3873220943268114
exploration/Returns Max        482.0203173478262
exploration/Returns Min        477.95468613907263
exploration/Actions Mean       0.111605
exploration/Actions Std        0.6302016
exploration/Actions Max        0.99996966
exploration/Actions Min        -0.999824
exploration/Num Paths          10
exploration/Average Returns    479.77958350690005
evaluation/num steps total     2030000
evaluation/num paths total     4060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9582187577197676
evaluation/Rewards Std         0.050875166846257265
evaluation/Rewards Max         0.979492122126022
evaluation/Rewards Min         0.49199732598128865
evaluation/Returns Mean        479.10937885988386
evaluation/Returns Std         1.5397156594012191
evaluation/Returns Max         481.053240284597
evaluation/Returns Min         477.1444393590511
evaluation/ExplReturns Mean    479.10937885988386
evaluation/ExplReturns Std     1.5397156594012191
evaluation/ExplReturns Max     481.053240284597
evaluation/ExplReturns Min     477.1444393590511
evaluation/Actions Mean        0.12387734
evaluation/Actions Std         0.5591293
evaluation/Actions Max         0.9995561
evaluation/Actions Min         -0.999165
evaluation/Num Paths           10
evaluation/Average Returns     479.10937885988386
time/data storing (s)          0.03209213539958
time/evaluation sampling (s)   111.08910017833114
time/exploration sampling (s)  112.38872843701392
time/logging (s)               0.03046938870102167
time/saving (s)                0.012923775240778923
time/training (s)              9.668626775965095
time/epoch (s)                 233.22194069065154
time/total (s)                 94975.4851361243
Epoch                          405
-----------------------------  --------------------
2023-08-01 20:21:01.281708 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 406 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4073.9495]
trainer/QF1 Loss               0.045656312
trainer/QF2 Loss               0.061828524
trainer/Policy Loss            -92.438515
trainer/Q1 Predictions Mean    104.68126
trainer/Q1 Predictions Std     5.358146
trainer/Q1 Predictions Max     107.35509
trainer/Q1 Predictions Min     61.798557
trainer/Q2 Predictions Mean    104.71315
trainer/Q2 Predictions Std     5.335423
trainer/Q2 Predictions Max     107.342094
trainer/Q2 Predictions Min     62.340984
trainer/Q Targets Mean         104.61421
trainer/Q Targets Std          5.3146954
trainer/Q Targets Max          107.29015
trainer/Q Targets Min          62.88137
trainer/Log Pis Mean           12.395633
trainer/Log Pis Std            8.547682
trainer/Log Pis Max            53.56163
trainer/Log Pis Min            -5.8519716
trainer/Policy mu Mean         -0.006533886
trainer/Policy mu Std          1.623136
trainer/Policy mu Max          6.8298864
trainer/Policy mu Min          -7.453917
trainer/Policy log std Mean    -0.7048876
trainer/Policy log std Std     0.27994132
trainer/Policy log std Max     0.46168864
trainer/Policy log std Min     -1.8447435
trainer/Alpha                  0.002287611598148942
trainer/Alpha Loss             2.405543565750122
exploration/num steps total    2036000
exploration/num paths total    4072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9599333238547042
exploration/Rewards Std        0.0519202427630086
exploration/Rewards Max        0.9795185497465408
exploration/Rewards Min        0.4994646843053609
exploration/Returns Mean       479.9666619273521
exploration/Returns Std        0.8699132933523557
exploration/Returns Max        481.59566735190987
exploration/Returns Min        478.55084596990514
exploration/Actions Mean       -0.0002845141
exploration/Actions Std        0.65320003
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.99991137
exploration/Num Paths          10
exploration/Average Returns    479.9666619273521
evaluation/num steps total     2035000
evaluation/num paths total     4070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9617631545475724
evaluation/Rewards Std         0.05045325858926468
evaluation/Rewards Max         0.9770982323482453
evaluation/Rewards Min         0.4800690530703426
evaluation/Returns Mean        480.8815772737863
evaluation/Returns Std         0.63717491747041
evaluation/Returns Max         481.68563920003766
evaluation/Returns Min         479.69619380626403
evaluation/ExplReturns Mean    480.8815772737863
evaluation/ExplReturns Std     0.63717491747041
evaluation/ExplReturns Max     481.68563920003766
evaluation/ExplReturns Min     479.69619380626403
evaluation/Actions Mean        -0.025320705
evaluation/Actions Std         0.6249362
evaluation/Actions Max         0.99997556
evaluation/Actions Min         -0.9996427
evaluation/Num Paths           10
evaluation/Average Returns     480.8815772737863
time/data storing (s)          0.031552985310554504
time/evaluation sampling (s)   113.35099686402828
time/exploration sampling (s)  113.79799443483353
time/logging (s)               0.03131090383976698
time/saving (s)                0.012856265529990196
time/training (s)              9.689774809405208
time/epoch (s)                 236.91448626294732
time/total (s)                 95212.4021239588
Epoch                          406
-----------------------------  --------------------
2023-08-01 20:24:57.440439 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 407 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3979.6697]
trainer/QF1 Loss               0.038017847
trainer/QF2 Loss               0.03473186
trainer/Policy Loss            -92.11916
trainer/Q1 Predictions Mean    104.94148
trainer/Q1 Predictions Std     3.773279
trainer/Q1 Predictions Max     107.24884
trainer/Q1 Predictions Min     68.75545
trainer/Q2 Predictions Mean    104.90008
trainer/Q2 Predictions Std     3.87218
trainer/Q2 Predictions Max     107.3354
trainer/Q2 Predictions Min     67.597404
trainer/Q Targets Mean         104.92183
trainer/Q Targets Std          3.834649
trainer/Q Targets Max          107.2486
trainer/Q Targets Min          68.793465
trainer/Log Pis Mean           12.930883
trainer/Log Pis Std            7.578011
trainer/Log Pis Max            66.98801
trainer/Log Pis Min            -3.7541368
trainer/Policy mu Mean         0.015754325
trainer/Policy mu Std          1.6234214
trainer/Policy mu Max          5.7445374
trainer/Policy mu Min          -13.285761
trainer/Policy log std Mean    -0.7310391
trainer/Policy log std Std     0.2976271
trainer/Policy log std Max     0.57755834
trainer/Policy log std Min     -1.9072896
trainer/Alpha                  0.0021587826777249575
trainer/Alpha Loss             5.714113235473633
exploration/num steps total    2041000
exploration/num paths total    4082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.964396312340626
exploration/Rewards Std        0.05138997590853655
exploration/Rewards Max        0.9793398878552146
exploration/Rewards Min        0.4874876987458483
exploration/Returns Mean       482.1981561703131
exploration/Returns Std        0.8078280706887907
exploration/Returns Max        482.8204416518373
exploration/Returns Min        479.90632429999164
exploration/Actions Mean       0.11650156
exploration/Actions Std        0.61417717
exploration/Actions Max        0.9997701
exploration/Actions Min        -0.9999901
exploration/Num Paths          10
exploration/Average Returns    482.1981561703131
evaluation/num steps total     2040000
evaluation/num paths total     4080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609757692845542
evaluation/Rewards Std         0.05471579142166166
evaluation/Rewards Max         0.9774614888222946
evaluation/Rewards Min         0.49029622391787664
evaluation/Returns Mean        480.487884642277
evaluation/Returns Std         3.0805274380209138
evaluation/Returns Max         482.3447297848768
evaluation/Returns Min         471.6665123674708
evaluation/ExplReturns Mean    480.487884642277
evaluation/ExplReturns Std     3.0805274380209138
evaluation/ExplReturns Max     482.3447297848768
evaluation/ExplReturns Min     471.6665123674708
evaluation/Actions Mean        0.11371108
evaluation/Actions Std         0.57110626
evaluation/Actions Max         0.9970522
evaluation/Actions Min         -0.9988264
evaluation/Num Paths           10
evaluation/Average Returns     480.487884642277
time/data storing (s)          0.032067880034446716
time/evaluation sampling (s)   112.1299579758197
time/exploration sampling (s)  114.31141841225326
time/logging (s)               0.030273480340838432
time/saving (s)                0.012454287149012089
time/training (s)              9.635569766163826
time/epoch (s)                 236.1517418017611
time/total (s)                 95448.55637511052
Epoch                          407
-----------------------------  ---------------------
2023-08-01 20:28:50.923778 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 408 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4092.8]
trainer/QF1 Loss               0.045749344
trainer/QF2 Loss               0.047529206
trainer/Policy Loss            -93.243675
trainer/Q1 Predictions Mean    105.04395
trainer/Q1 Predictions Std     3.5500927
trainer/Q1 Predictions Max     107.28238
trainer/Q1 Predictions Min     71.0446
trainer/Q2 Predictions Mean    104.98282
trainer/Q2 Predictions Std     3.5792878
trainer/Q2 Predictions Max     107.16835
trainer/Q2 Predictions Min     70.94501
trainer/Q Targets Mean         105.03792
trainer/Q Targets Std          3.6239493
trainer/Q Targets Max          107.297035
trainer/Q Targets Min          69.88826
trainer/Log Pis Mean           11.897467
trainer/Log Pis Std            7.6341367
trainer/Log Pis Max            52.315266
trainer/Log Pis Min            -1.5131191
trainer/Policy mu Mean         0.046293724
trainer/Policy mu Std          1.5638937
trainer/Policy mu Max          6.63225
trainer/Policy mu Min          -6.3245068
trainer/Policy log std Mean    -0.72818184
trainer/Policy log std Std     0.29061836
trainer/Policy log std Max     0.6494024
trainer/Policy log std Min     -1.8730117
trainer/Alpha                  0.0020132490899413824
trainer/Alpha Loss             -0.6364942193031311
exploration/num steps total    2046000
exploration/num paths total    4092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9616554848380452
exploration/Rewards Std        0.04892297385234416
exploration/Rewards Max        0.9769378414669383
exploration/Rewards Min        0.48662478997978353
exploration/Returns Mean       480.82774241902246
exploration/Returns Std        0.41417927324148
exploration/Returns Max        481.40708555523935
exploration/Returns Min        479.9788535759458
exploration/Actions Mean       0.079461895
exploration/Actions Std        0.5959805
exploration/Actions Max        0.9997424
exploration/Actions Min        -0.99994296
exploration/Num Paths          10
exploration/Average Returns    480.82774241902246
evaluation/num steps total     2045000
evaluation/num paths total     4090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9611225034155355
evaluation/Rewards Std         0.04803992533347498
evaluation/Rewards Max         0.9760545031239396
evaluation/Rewards Min         0.4873512701256112
evaluation/Returns Mean        480.5612517077676
evaluation/Returns Std         0.6446960667058645
evaluation/Returns Max         481.46730551389027
evaluation/Returns Min         479.7974242415161
evaluation/ExplReturns Mean    480.5612517077676
evaluation/ExplReturns Std     0.6446960667058645
evaluation/ExplReturns Max     481.46730551389027
evaluation/ExplReturns Min     479.7974242415161
evaluation/Actions Mean        0.0780151
evaluation/Actions Std         0.49450293
evaluation/Actions Max         0.9981868
evaluation/Actions Min         -0.99861807
evaluation/Num Paths           10
evaluation/Average Returns     480.5612517077676
time/data storing (s)          0.03205932956188917
time/evaluation sampling (s)   111.79733643494546
time/exploration sampling (s)  112.97412041109055
time/logging (s)               0.03044785186648369
time/saving (s)                0.012509358115494251
time/training (s)              8.631108671426773
time/epoch (s)                 233.47758205700666
time/total (s)                 95682.0364436023
Epoch                          408
-----------------------------  ---------------------
2023-08-01 20:32:43.731491 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 409 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4033.0564]
trainer/QF1 Loss               0.025532085
trainer/QF2 Loss               0.036053218
trainer/Policy Loss            -93.96915
trainer/Q1 Predictions Mean    105.265
trainer/Q1 Predictions Std     3.1472814
trainer/Q1 Predictions Max     107.14883
trainer/Q1 Predictions Min     71.24223
trainer/Q2 Predictions Mean    105.195854
trainer/Q2 Predictions Std     3.1464744
trainer/Q2 Predictions Max     107.10813
trainer/Q2 Predictions Min     70.897835
trainer/Q Targets Mean         105.27753
trainer/Q Targets Std          3.170688
trainer/Q Targets Max          107.160355
trainer/Q Targets Min          71.22662
trainer/Log Pis Mean           11.382524
trainer/Log Pis Std            6.8720984
trainer/Log Pis Max            39.556828
trainer/Log Pis Min            -4.5868483
trainer/Policy mu Mean         0.061617564
trainer/Policy mu Std          1.5671718
trainer/Policy mu Max          5.7759447
trainer/Policy mu Min          -5.8867393
trainer/Policy log std Mean    -0.69297963
trainer/Policy log std Std     0.28375196
trainer/Policy log std Max     0.1878354
trainer/Policy log std Min     -2.230319
trainer/Alpha                  0.0020446048583835363
trainer/Alpha Loss             -3.8237853050231934
exploration/num steps total    2051000
exploration/num paths total    4102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9591958713036325
exploration/Rewards Std        0.04733002251168673
exploration/Rewards Max        0.9786157197899193
exploration/Rewards Min        0.4858539397977909
exploration/Returns Mean       479.59793565181616
exploration/Returns Std        0.4282869740391466
exploration/Returns Max        480.3204302568276
exploration/Returns Min        478.78571206870197
exploration/Actions Mean       0.06833036
exploration/Actions Std        0.59686357
exploration/Actions Max        0.999875
exploration/Actions Min        -0.9999705
exploration/Num Paths          10
exploration/Average Returns    479.59793565181616
evaluation/num steps total     2050000
evaluation/num paths total     4100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9589363701394308
evaluation/Rewards Std         0.04729986396842973
evaluation/Rewards Max         0.9730778786186104
evaluation/Rewards Min         0.49119989647511225
evaluation/Returns Mean        479.4681850697155
evaluation/Returns Std         0.45218502776682445
evaluation/Returns Max         479.9539011925703
evaluation/Returns Min         478.28950146862064
evaluation/ExplReturns Mean    479.4681850697155
evaluation/ExplReturns Std     0.45218502776682445
evaluation/ExplReturns Max     479.9539011925703
evaluation/ExplReturns Min     478.28950146862064
evaluation/Actions Mean        0.063535005
evaluation/Actions Std         0.50703174
evaluation/Actions Max         0.9986769
evaluation/Actions Min         -0.99950135
evaluation/Num Paths           10
evaluation/Average Returns     479.4681850697155
time/data storing (s)          0.03193585388362408
time/evaluation sampling (s)   111.59640020877123
time/exploration sampling (s)  111.52481326274574
time/logging (s)               0.03050559014081955
time/saving (s)                0.012556633912026882
time/training (s)              9.605652482248843
time/epoch (s)                 232.80186403170228
time/total (s)                 95914.84075803682
Epoch                          409
-----------------------------  ---------------------
2023-08-01 20:36:36.013227 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 410 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3778.2822]
trainer/QF1 Loss               0.024346925
trainer/QF2 Loss               0.03480201
trainer/Policy Loss            -94.18864
trainer/Q1 Predictions Mean    105.130264
trainer/Q1 Predictions Std     2.9408174
trainer/Q1 Predictions Max     107.32151
trainer/Q1 Predictions Min     82.29586
trainer/Q2 Predictions Mean    105.18793
trainer/Q2 Predictions Std     2.9097075
trainer/Q2 Predictions Max     107.322685
trainer/Q2 Predictions Min     82.58857
trainer/Q Targets Mean         105.06662
trainer/Q Targets Std          2.9304245
trainer/Q Targets Max          107.15116
trainer/Q Targets Min          81.8063
trainer/Log Pis Mean           11.073401
trainer/Log Pis Std            7.2402744
trainer/Log Pis Max            46.671482
trainer/Log Pis Min            -0.50137305
trainer/Policy mu Mean         0.15697609
trainer/Policy mu Std          1.5563612
trainer/Policy mu Max          6.8097076
trainer/Policy mu Min          -5.8030267
trainer/Policy log std Mean    -0.7117977
trainer/Policy log std Std     0.2931219
trainer/Policy log std Max     0.505098
trainer/Policy log std Min     -1.9540331
trainer/Alpha                  0.001812424510717392
trainer/Alpha Loss             -5.8492560386657715
exploration/num steps total    2056000
exploration/num paths total    4112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9635220976997896
exploration/Rewards Std        0.049617569689490895
exploration/Rewards Max        0.9780844056240037
exploration/Rewards Min        0.49140505943159135
exploration/Returns Mean       481.7610488498948
exploration/Returns Std        0.8912137273744247
exploration/Returns Max        482.84448127117633
exploration/Returns Min        479.6526907419443
exploration/Actions Mean       0.03460539
exploration/Actions Std        0.629424
exploration/Actions Max        0.9996066
exploration/Actions Min        -0.9998031
exploration/Num Paths          10
exploration/Average Returns    481.7610488498948
evaluation/num steps total     2055000
evaluation/num paths total     4110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9652343348397522
evaluation/Rewards Std         0.04873197208510826
evaluation/Rewards Max         0.975220645373131
evaluation/Rewards Min         0.4930250838909833
evaluation/Returns Mean        482.6171674198761
evaluation/Returns Std         0.37442982011081494
evaluation/Returns Max         483.16659696052625
evaluation/Returns Min         481.89037409950174
evaluation/ExplReturns Mean    482.6171674198761
evaluation/ExplReturns Std     0.37442982011081494
evaluation/ExplReturns Max     483.16659696052625
evaluation/ExplReturns Min     481.89037409950174
evaluation/Actions Mean        0.03020417
evaluation/Actions Std         0.51596093
evaluation/Actions Max         0.9991642
evaluation/Actions Min         -0.99950224
evaluation/Num Paths           10
evaluation/Average Returns     482.6171674198761
time/data storing (s)          0.032458869740366936
time/evaluation sampling (s)   110.41697443742305
time/exploration sampling (s)  112.17722216248512
time/logging (s)               0.030658884905278683
time/saving (s)                0.010264960117638111
time/training (s)              9.608340014703572
time/epoch (s)                 232.27591932937503
time/total (s)                 96147.11921575852
Epoch                          410
-----------------------------  --------------------
2023-08-01 20:40:26.569115 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 411 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4282.071]
trainer/QF1 Loss               0.02954009
trainer/QF2 Loss               0.025548909
trainer/Policy Loss            -92.536224
trainer/Q1 Predictions Mean    104.824684
trainer/Q1 Predictions Std     4.4917355
trainer/Q1 Predictions Max     107.108955
trainer/Q1 Predictions Min     55.024513
trainer/Q2 Predictions Mean    104.76682
trainer/Q2 Predictions Std     4.494694
trainer/Q2 Predictions Max     106.936386
trainer/Q2 Predictions Min     55.147156
trainer/Q Targets Mean         104.77783
trainer/Q Targets Std          4.4831095
trainer/Q Targets Max          106.88397
trainer/Q Targets Min          54.892582
trainer/Log Pis Mean           12.372031
trainer/Log Pis Std            8.652604
trainer/Log Pis Max            69.114334
trainer/Log Pis Min            -3.9014628
trainer/Policy mu Mean         0.20757687
trainer/Policy mu Std          1.6101931
trainer/Policy mu Max          11.070122
trainer/Policy mu Min          -6.955642
trainer/Policy log std Mean    -0.70809937
trainer/Policy log std Std     0.29631984
trainer/Policy log std Max     1.7806301
trainer/Policy log std Min     -1.7728639
trainer/Alpha                  0.001805270672775805
trainer/Alpha Loss             2.3500900268554688
exploration/num steps total    2061000
exploration/num paths total    4122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9574607402416272
exploration/Rewards Std        0.047944275514075284
exploration/Rewards Max        0.9767258766792815
exploration/Rewards Min        0.49479834032941145
exploration/Returns Mean       478.7303701208135
exploration/Returns Std        0.6233548286775893
exploration/Returns Max        479.28420386412796
exploration/Returns Min        477.3281804644807
exploration/Actions Mean       0.030487614
exploration/Actions Std        0.6080091
exploration/Actions Max        0.9996777
exploration/Actions Min        -0.9999879
exploration/Num Paths          10
exploration/Average Returns    478.7303701208135
evaluation/num steps total     2060000
evaluation/num paths total     4120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9567620417417269
evaluation/Rewards Std         0.047052659806146695
evaluation/Rewards Max         0.9683741212266782
evaluation/Rewards Min         0.4950215348414583
evaluation/Returns Mean        478.38102087086344
evaluation/Returns Std         0.4087403289154091
evaluation/Returns Max         479.1955854034422
evaluation/Returns Min         477.8572476701039
evaluation/ExplReturns Mean    478.38102087086344
evaluation/ExplReturns Std     0.4087403289154091
evaluation/ExplReturns Max     479.1955854034422
evaluation/ExplReturns Min     477.8572476701039
evaluation/Actions Mean        0.04977851
evaluation/Actions Std         0.4900837
evaluation/Actions Max         0.99849606
evaluation/Actions Min         -0.99975955
evaluation/Num Paths           10
evaluation/Average Returns     478.38102087086344
time/data storing (s)          0.03239918500185013
time/evaluation sampling (s)   110.39710180554539
time/exploration sampling (s)  111.37726830504835
time/logging (s)               0.03047044761478901
time/saving (s)                0.01024629082530737
time/training (s)              8.702219172380865
time/epoch (s)                 230.54970520641655
time/total (s)                 96377.67142201401
Epoch                          411
-----------------------------  --------------------
2023-08-01 20:44:19.344464 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 412 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4095.896]
trainer/QF1 Loss               0.032248802
trainer/QF2 Loss               0.028880656
trainer/Policy Loss            -93.05604
trainer/Q1 Predictions Mean    105.1738
trainer/Q1 Predictions Std     2.8576515
trainer/Q1 Predictions Max     107.080345
trainer/Q1 Predictions Min     75.66965
trainer/Q2 Predictions Mean    105.29148
trainer/Q2 Predictions Std     2.8719897
trainer/Q2 Predictions Max     107.26351
trainer/Q2 Predictions Min     75.56715
trainer/Q Targets Mean         105.23317
trainer/Q Targets Std          2.8126323
trainer/Q Targets Max          106.919624
trainer/Q Targets Min          76.93942
trainer/Log Pis Mean           12.302666
trainer/Log Pis Std            7.8340845
trainer/Log Pis Max            56.68064
trainer/Log Pis Min            -4.3935633
trainer/Policy mu Mean         0.109004736
trainer/Policy mu Std          1.6086224
trainer/Policy mu Max          8.124835
trainer/Policy mu Min          -7.7570024
trainer/Policy log std Mean    -0.71539336
trainer/Policy log std Std     0.2779345
trainer/Policy log std Max     0.78673756
trainer/Policy log std Min     -1.8376862
trainer/Alpha                  0.0017887389985844493
trainer/Alpha Loss             1.9147882461547852
exploration/num steps total    2066000
exploration/num paths total    4132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9586500068450227
exploration/Rewards Std        0.04781011027531369
exploration/Rewards Max        0.9794820140137024
exploration/Rewards Min        0.4934191829622466
exploration/Returns Mean       479.32500342251143
exploration/Returns Std        0.3406655908555289
exploration/Returns Max        479.83585978564014
exploration/Returns Min        478.72422090014635
exploration/Actions Mean       0.010493879
exploration/Actions Std        0.57739866
exploration/Actions Max        0.99981713
exploration/Actions Min        -0.9999086
exploration/Num Paths          10
exploration/Average Returns    479.32500342251143
evaluation/num steps total     2065000
evaluation/num paths total     4130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9534621308658953
evaluation/Rewards Std         0.046904181075655485
evaluation/Rewards Max         0.9769737857411553
evaluation/Rewards Min         0.4915496013530353
evaluation/Returns Mean        476.73106543294773
evaluation/Returns Std         0.8168467988581961
evaluation/Returns Max         478.2236986958131
evaluation/Returns Min         475.4829530521307
evaluation/ExplReturns Mean    476.73106543294773
evaluation/ExplReturns Std     0.8168467988581961
evaluation/ExplReturns Max     478.2236986958131
evaluation/ExplReturns Min     475.4829530521307
evaluation/Actions Mean        0.041992493
evaluation/Actions Std         0.4750345
evaluation/Actions Max         0.9991018
evaluation/Actions Min         -0.99915415
evaluation/Num Paths           10
evaluation/Average Returns     476.73106543294773
time/data storing (s)          0.03190665226429701
time/evaluation sampling (s)   111.66498084180057
time/exploration sampling (s)  111.31981498096138
time/logging (s)               0.030296997167170048
time/saving (s)                0.01254599541425705
time/training (s)              9.709658904001117
time/epoch (s)                 232.7692043716088
time/total (s)                 96610.4431134034
Epoch                          412
-----------------------------  ---------------------
2023-08-01 20:48:11.969985 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 413 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3962.218]
trainer/QF1 Loss               0.024935897
trainer/QF2 Loss               0.03495547
trainer/Policy Loss            -93.348465
trainer/Q1 Predictions Mean    104.97661
trainer/Q1 Predictions Std     3.6820955
trainer/Q1 Predictions Max     107.25946
trainer/Q1 Predictions Min     66.471054
trainer/Q2 Predictions Mean    105.01445
trainer/Q2 Predictions Std     3.6157427
trainer/Q2 Predictions Max     107.14375
trainer/Q2 Predictions Min     66.96918
trainer/Q Targets Mean         104.92209
trainer/Q Targets Std          3.6586962
trainer/Q Targets Max          107.113495
trainer/Q Targets Min          66.9462
trainer/Log Pis Mean           11.760097
trainer/Log Pis Std            8.239037
trainer/Log Pis Max            49.40938
trainer/Log Pis Min            -4.6650643
trainer/Policy mu Mean         0.08883748
trainer/Policy mu Std          1.6108333
trainer/Policy mu Max          10.874903
trainer/Policy mu Min          -7.9682474
trainer/Policy log std Mean    -0.7010226
trainer/Policy log std Std     0.2962109
trainer/Policy log std Max     0.8650265
trainer/Policy log std Min     -1.8259017
trainer/Alpha                  0.0017747165402397513
trainer/Alpha Loss             -1.5195083618164062
exploration/num steps total    2071000
exploration/num paths total    4142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9622783099399348
exploration/Rewards Std        0.052954442288211036
exploration/Rewards Max        0.9799467346178337
exploration/Rewards Min        0.49365120815041214
exploration/Returns Mean       481.13915496996725
exploration/Returns Std        1.7153930295609168
exploration/Returns Max        482.52662158463573
exploration/Returns Min        477.66910042993214
exploration/Actions Mean       0.012910115
exploration/Actions Std        0.57765543
exploration/Actions Max        0.99999964
exploration/Actions Min        -0.99995023
exploration/Num Paths          10
exploration/Average Returns    481.13915496996725
evaluation/num steps total     2070000
evaluation/num paths total     4140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.962380446283627
evaluation/Rewards Std         0.053219466591241514
evaluation/Rewards Max         0.978838500235352
evaluation/Rewards Min         0.48838803449745394
evaluation/Returns Mean        481.19022314181365
evaluation/Returns Std         2.986325267398974
evaluation/Returns Max         482.9101753879549
evaluation/Returns Min         472.31846969071916
evaluation/ExplReturns Mean    481.19022314181365
evaluation/ExplReturns Std     2.986325267398974
evaluation/ExplReturns Max     482.9101753879549
evaluation/ExplReturns Min     472.31846969071916
evaluation/Actions Mean        0.023291452
evaluation/Actions Std         0.47137862
evaluation/Actions Max         0.999777
evaluation/Actions Min         -0.9996427
evaluation/Num Paths           10
evaluation/Average Returns     481.19022314181365
time/data storing (s)          0.03224583063274622
time/evaluation sampling (s)   111.4490726403892
time/exploration sampling (s)  111.50337065849453
time/logging (s)               0.03029804304242134
time/saving (s)                0.010742890648543835
time/training (s)              9.59381795860827
time/epoch (s)                 232.61954802181572
time/total (s)                 96843.06514173187
Epoch                          413
-----------------------------  ---------------------
2023-08-01 20:52:03.895465 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 414 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3603.0537]
trainer/QF1 Loss               0.02790057
trainer/QF2 Loss               0.017848412
trainer/Policy Loss            -93.71063
trainer/Q1 Predictions Mean    105.073425
trainer/Q1 Predictions Std     2.7416842
trainer/Q1 Predictions Max     106.36244
trainer/Q1 Predictions Min     73.694984
trainer/Q2 Predictions Mean    105.13989
trainer/Q2 Predictions Std     2.7359586
trainer/Q2 Predictions Max     106.539986
trainer/Q2 Predictions Min     73.9213
trainer/Q Targets Mean         105.17751
trainer/Q Targets Std          2.7030616
trainer/Q Targets Max          106.48477
trainer/Q Targets Min          74.16905
trainer/Log Pis Mean           11.49815
trainer/Log Pis Std            7.9224696
trainer/Log Pis Max            53.429264
trainer/Log Pis Min            -4.000775
trainer/Policy mu Mean         0.020380901
trainer/Policy mu Std          1.5710641
trainer/Policy mu Max          5.4908023
trainer/Policy mu Min          -6.909215
trainer/Policy log std Mean    -0.67249507
trainer/Policy log std Std     0.29556412
trainer/Policy log std Max     0.35048166
trainer/Policy log std Min     -1.9388599
trainer/Alpha                  0.0017594551900401711
trainer/Alpha Loss             -3.1830055713653564
exploration/num steps total    2076000
exploration/num paths total    4152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9602400866186749
exploration/Rewards Std        0.05187346359419041
exploration/Rewards Max        0.9798946237757982
exploration/Rewards Min        0.4971149405156597
exploration/Returns Mean       480.1200433093376
exploration/Returns Std        1.07850922278398
exploration/Returns Max        481.234153523929
exploration/Returns Min        478.14229001188454
exploration/Actions Mean       0.0019413498
exploration/Actions Std        0.6372459
exploration/Actions Max        0.9999461
exploration/Actions Min        -0.99999416
exploration/Num Paths          10
exploration/Average Returns    480.1200433093376
evaluation/num steps total     2075000
evaluation/num paths total     4150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9595231182013093
evaluation/Rewards Std         0.05175479508297813
evaluation/Rewards Max         0.9794176390367252
evaluation/Rewards Min         0.4885596889038797
evaluation/Returns Mean        479.76155910065455
evaluation/Returns Std         1.2041000903430108
evaluation/Returns Max         481.32380435884943
evaluation/Returns Min         476.7017583386971
evaluation/ExplReturns Mean    479.76155910065455
evaluation/ExplReturns Std     1.2041000903430108
evaluation/ExplReturns Max     481.32380435884943
evaluation/ExplReturns Min     476.7017583386971
evaluation/Actions Mean        -0.009138814
evaluation/Actions Std         0.58309436
evaluation/Actions Max         0.99954534
evaluation/Actions Min         -0.9999133
evaluation/Num Paths           10
evaluation/Average Returns     479.76155910065455
time/data storing (s)          0.03191741183400154
time/evaluation sampling (s)   111.32932176068425
time/exploration sampling (s)  110.8878510016948
time/logging (s)               0.031138732098042965
time/saving (s)                0.010441669262945652
time/training (s)              9.629529398865998
time/epoch (s)                 231.92019997444004
time/total (s)                 97074.98794726655
Epoch                          414
-----------------------------  ---------------------
2023-08-01 20:56:00.311377 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 415 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4113.696]
trainer/QF1 Loss               0.027065517
trainer/QF2 Loss               0.015560141
trainer/Policy Loss            -93.719315
trainer/Q1 Predictions Mean    105.07675
trainer/Q1 Predictions Std     2.754736
trainer/Q1 Predictions Max     106.26186
trainer/Q1 Predictions Min     67.34813
trainer/Q2 Predictions Mean    105.14162
trainer/Q2 Predictions Std     2.7733061
trainer/Q2 Predictions Max     106.30805
trainer/Q2 Predictions Min     67.31825
trainer/Q Targets Mean         105.173965
trainer/Q Targets Std          2.7675917
trainer/Q Targets Max          106.43868
trainer/Q Targets Min          67.35175
trainer/Log Pis Mean           11.501651
trainer/Log Pis Std            7.4984303
trainer/Log Pis Max            46.118393
trainer/Log Pis Min            -2.4916735
trainer/Policy mu Mean         -0.07078824
trainer/Policy mu Std          1.5597838
trainer/Policy mu Max          4.359307
trainer/Policy mu Min          -5.311965
trainer/Policy log std Mean    -0.71674925
trainer/Policy log std Std     0.28963032
trainer/Policy log std Max     0.0604735
trainer/Policy log std Min     -1.9494743
trainer/Alpha                  0.001714280224405229
trainer/Alpha Loss             -3.1737563610076904
exploration/num steps total    2081000
exploration/num paths total    4162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9535023675191795
exploration/Rewards Std        0.048518037627045665
exploration/Rewards Max        0.9797380651842128
exploration/Rewards Min        0.4846570194697044
exploration/Returns Mean       476.7511837595897
exploration/Returns Std        0.8117834294409625
exploration/Returns Max        477.6255914626568
exploration/Returns Min        475.2056011256682
exploration/Actions Mean       -0.0012859778
exploration/Actions Std        0.60076755
exploration/Actions Max        0.9999776
exploration/Actions Min        -0.9999694
exploration/Num Paths          10
exploration/Average Returns    476.7511837595897
evaluation/num steps total     2080000
evaluation/num paths total     4160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9656204511017875
evaluation/Rewards Std         0.04835889913555036
evaluation/Rewards Max         0.9794290109041944
evaluation/Rewards Min         0.5045303666699651
evaluation/Returns Mean        482.81022555089385
evaluation/Returns Std         3.179478879237471
evaluation/Returns Max         485.30426566051455
evaluation/Returns Min         476.2887442043785
evaluation/ExplReturns Mean    482.81022555089385
evaluation/ExplReturns Std     3.179478879237471
evaluation/ExplReturns Max     485.30426566051455
evaluation/ExplReturns Min     476.2887442043785
evaluation/Actions Mean        0.024497475
evaluation/Actions Std         0.53284025
evaluation/Actions Max         0.9990618
evaluation/Actions Min         -0.9997039
evaluation/Num Paths           10
evaluation/Average Returns     482.81022555089385
time/data storing (s)          0.032463448122143745
time/evaluation sampling (s)   113.46314791589975
time/exploration sampling (s)  113.2531353700906
time/logging (s)               0.030670562759041786
time/saving (s)                0.012569794431328773
time/training (s)              9.617422891780734
time/epoch (s)                 236.4094099830836
time/total (s)                 97311.39986197092
Epoch                          415
-----------------------------  --------------------
2023-08-01 20:59:54.890258 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 416 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3872.7246]
trainer/QF1 Loss               0.08437985
trainer/QF2 Loss               0.06179664
trainer/Policy Loss            -92.768394
trainer/Q1 Predictions Mean    105.0656
trainer/Q1 Predictions Std     2.046221
trainer/Q1 Predictions Max     106.50737
trainer/Q1 Predictions Min     90.16364
trainer/Q2 Predictions Mean    104.98544
trainer/Q2 Predictions Std     1.9962838
trainer/Q2 Predictions Max     106.339355
trainer/Q2 Predictions Min     90.70515
trainer/Q Targets Mean         105.01756
trainer/Q Targets Std          1.9963055
trainer/Q Targets Max          106.34332
trainer/Q Targets Min          89.816956
trainer/Log Pis Mean           12.345152
trainer/Log Pis Std            7.6819067
trainer/Log Pis Max            49.441586
trainer/Log Pis Min            -6.4136553
trainer/Policy mu Mean         -0.16579024
trainer/Policy mu Std          1.6218034
trainer/Policy mu Max          7.546323
trainer/Policy mu Min          -5.787676
trainer/Policy log std Mean    -0.6917446
trainer/Policy log std Std     0.27995995
trainer/Policy log std Max     0.44214445
trainer/Policy log std Min     -1.9581921
trainer/Alpha                  0.0017890536691993475
trainer/Alpha Loss             2.1835505962371826
exploration/num steps total    2086000
exploration/num paths total    4172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.954166711465249
exploration/Rewards Std        0.05408860687625189
exploration/Rewards Max        0.9796090128110951
exploration/Rewards Min        0.4895397101468252
exploration/Returns Mean       477.08335573262445
exploration/Returns Std        1.1757912705661093
exploration/Returns Max        478.40079356003275
exploration/Returns Min        474.35334561166417
exploration/Actions Mean       0.012151499
exploration/Actions Std        0.62620205
exploration/Actions Max        0.9998738
exploration/Actions Min        -0.999961
exploration/Num Paths          10
exploration/Average Returns    477.08335573262445
evaluation/num steps total     2085000
evaluation/num paths total     4170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9560678100685484
evaluation/Rewards Std         0.04742697223068171
evaluation/Rewards Max         0.9781779765959588
evaluation/Rewards Min         0.4913942151774555
evaluation/Returns Mean        478.0339050342741
evaluation/Returns Std         0.3405833213091733
evaluation/Returns Max         478.57322356871816
evaluation/Returns Min         477.2792868290015
evaluation/ExplReturns Mean    478.0339050342741
evaluation/ExplReturns Std     0.3405833213091733
evaluation/ExplReturns Max     478.57322356871816
evaluation/ExplReturns Min     477.2792868290015
evaluation/Actions Mean        0.0018402487
evaluation/Actions Std         0.5159083
evaluation/Actions Max         0.99728334
evaluation/Actions Min         -0.999097
evaluation/Num Paths           10
evaluation/Average Returns     478.0339050342741
time/data storing (s)          0.032095327973365784
time/evaluation sampling (s)   111.78870561346412
time/exploration sampling (s)  113.04809101857245
time/logging (s)               0.030918749049305916
time/saving (s)                0.012034684419631958
time/training (s)              9.661264332011342
time/epoch (s)                 234.5731097254902
time/total (s)                 97545.97545823641
Epoch                          416
-----------------------------  ---------------------
2023-08-01 21:03:48.229608 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 417 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3840.2144]
trainer/QF1 Loss               0.021809973
trainer/QF2 Loss               0.03176156
trainer/Policy Loss            -92.27836
trainer/Q1 Predictions Mean    104.39907
trainer/Q1 Predictions Std     4.8012667
trainer/Q1 Predictions Max     106.27675
trainer/Q1 Predictions Min     65.19884
trainer/Q2 Predictions Mean    104.315475
trainer/Q2 Predictions Std     4.7693424
trainer/Q2 Predictions Max     106.20365
trainer/Q2 Predictions Min     65.06953
trainer/Q Targets Mean         104.41789
trainer/Q Targets Std          4.780068
trainer/Q Targets Max          106.38819
trainer/Q Targets Min          64.83026
trainer/Log Pis Mean           12.16795
trainer/Log Pis Std            8.931499
trainer/Log Pis Max            72.8296
trainer/Log Pis Min            -2.7851083
trainer/Policy mu Mean         0.030761724
trainer/Policy mu Std          1.6563425
trainer/Policy mu Max          9.198467
trainer/Policy mu Min          -13.952349
trainer/Policy log std Mean    -0.69831496
trainer/Policy log std Std     0.29077652
trainer/Policy log std Max     0.6679196
trainer/Policy log std Min     -1.9095563
trainer/Alpha                  0.0018156691221520305
trainer/Alpha Loss             1.0599795579910278
exploration/num steps total    2091000
exploration/num paths total    4182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9582095888940885
exploration/Rewards Std        0.04827732911411025
exploration/Rewards Max        0.97944358940532
exploration/Rewards Min        0.49711939608358835
exploration/Returns Mean       479.10479444704424
exploration/Returns Std        0.5279487679729097
exploration/Returns Max        480.0332104656603
exploration/Returns Min        478.16913326434593
exploration/Actions Mean       0.019123588
exploration/Actions Std        0.577248
exploration/Actions Max        0.9997898
exploration/Actions Min        -0.9999876
exploration/Num Paths          10
exploration/Average Returns    479.10479444704424
evaluation/num steps total     2090000
evaluation/num paths total     4180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9577500244638654
evaluation/Rewards Std         0.047863178573410964
evaluation/Rewards Max         0.9752461089279643
evaluation/Rewards Min         0.4879599796627714
evaluation/Returns Mean        478.87501223193266
evaluation/Returns Std         0.5032942112685928
evaluation/Returns Max         479.92742901160165
evaluation/Returns Min         478.1921798398994
evaluation/ExplReturns Mean    478.87501223193266
evaluation/ExplReturns Std     0.5032942112685928
evaluation/ExplReturns Max     479.92742901160165
evaluation/ExplReturns Min     478.1921798398994
evaluation/Actions Mean        0.03025327
evaluation/Actions Std         0.4632319
evaluation/Actions Max         0.9990091
evaluation/Actions Min         -0.9996985
evaluation/Num Paths           10
evaluation/Average Returns     478.87501223193266
time/data storing (s)          0.03214231692254543
time/evaluation sampling (s)   111.39035449549556
time/exploration sampling (s)  112.33367657475173
time/logging (s)               0.031014127656817436
time/saving (s)                0.012197964824736118
time/training (s)              9.533935090526938
time/epoch (s)                 233.33332057017833
time/total (s)                 97779.31132943183
Epoch                          417
-----------------------------  ---------------------
2023-08-01 21:07:51.229413 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 418 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4071.2488]
trainer/QF1 Loss               0.018976506
trainer/QF2 Loss               0.021525942
trainer/Policy Loss            -93.78569
trainer/Q1 Predictions Mean    104.81958
trainer/Q1 Predictions Std     3.0049868
trainer/Q1 Predictions Max     106.12589
trainer/Q1 Predictions Min     72.112915
trainer/Q2 Predictions Mean    104.887344
trainer/Q2 Predictions Std     3.014439
trainer/Q2 Predictions Max     106.25156
trainer/Q2 Predictions Min     71.9536
trainer/Q Targets Mean         104.84667
trainer/Q Targets Std          3.010707
trainer/Q Targets Max          106.2212
trainer/Q Targets Min          72.150826
trainer/Log Pis Mean           11.159786
trainer/Log Pis Std            7.312406
trainer/Log Pis Max            43.274117
trainer/Log Pis Min            -3.1303327
trainer/Policy mu Mean         -0.024973504
trainer/Policy mu Std          1.5549808
trainer/Policy mu Max          5.6836357
trainer/Policy mu Min          -5.4557614
trainer/Policy log std Mean    -0.6963591
trainer/Policy log std Std     0.27927992
trainer/Policy log std Max     0.18392026
trainer/Policy log std Min     -1.9625543
trainer/Alpha                  0.0017473105108365417
trainer/Alpha Loss             -5.334939956665039
exploration/num steps total    2096000
exploration/num paths total    4192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9564512030500834
exploration/Rewards Std        0.05030524972401191
exploration/Rewards Max        0.9796083111475294
exploration/Rewards Min        0.48974771106540893
exploration/Returns Mean       478.22560152504167
exploration/Returns Std        0.6079737980595377
exploration/Returns Max        478.9720900647688
exploration/Returns Min        477.1619033132573
exploration/Actions Mean       0.12317235
exploration/Actions Std        0.6027957
exploration/Actions Max        0.99991554
exploration/Actions Min        -0.99998516
exploration/Num Paths          10
exploration/Average Returns    478.22560152504167
evaluation/num steps total     2095000
evaluation/num paths total     4190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9555567640478233
evaluation/Rewards Std         0.04809475364145298
evaluation/Rewards Max         0.9783211768225487
evaluation/Rewards Min         0.4990936023695646
evaluation/Returns Mean        477.7783820239116
evaluation/Returns Std         0.4896999343048496
evaluation/Returns Max         478.70086150892524
evaluation/Returns Min         476.90102667893893
evaluation/ExplReturns Mean    477.7783820239116
evaluation/ExplReturns Std     0.4896999343048496
evaluation/ExplReturns Max     478.70086150892524
evaluation/ExplReturns Min     476.90102667893893
evaluation/Actions Mean        0.15497455
evaluation/Actions Std         0.51598
evaluation/Actions Max         0.99956626
evaluation/Actions Min         -0.9989398
evaluation/Num Paths           10
evaluation/Average Returns     477.7783820239116
time/data storing (s)          0.0319295572116971
time/evaluation sampling (s)   117.5226735631004
time/exploration sampling (s)  115.44937427714467
time/logging (s)               0.030540081672370434
time/saving (s)                0.010235976427793503
time/training (s)              9.948494283482432
time/epoch (s)                 242.99324773903936
time/total (s)                 98022.3071163632
Epoch                          418
-----------------------------  ---------------------
2023-08-01 21:11:46.882864 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 419 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3672.2324]
trainer/QF1 Loss               0.024932241
trainer/QF2 Loss               0.036620524
trainer/Policy Loss            -93.47002
trainer/Q1 Predictions Mean    104.94436
trainer/Q1 Predictions Std     2.1768785
trainer/Q1 Predictions Max     106.2217
trainer/Q1 Predictions Min     89.28518
trainer/Q2 Predictions Mean    104.999954
trainer/Q2 Predictions Std     2.1569726
trainer/Q2 Predictions Max     106.20771
trainer/Q2 Predictions Min     89.18662
trainer/Q Targets Mean         104.89067
trainer/Q Targets Std          2.1700845
trainer/Q Targets Max          106.11438
trainer/Q Targets Min          88.96444
trainer/Log Pis Mean           11.598281
trainer/Log Pis Std            8.067114
trainer/Log Pis Max            46.781666
trainer/Log Pis Min            -3.076281
trainer/Policy mu Mean         0.016972737
trainer/Policy mu Std          1.571197
trainer/Policy mu Max          5.6485176
trainer/Policy mu Min          -4.9173923
trainer/Policy log std Mean    -0.7191961
trainer/Policy log std Std     0.27992088
trainer/Policy log std Max     0.41662526
trainer/Policy log std Min     -1.8060073
trainer/Alpha                  0.0016470324480906129
trainer/Alpha Loss             -2.574556827545166
exploration/num steps total    2101000
exploration/num paths total    4202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9572261693000818
exploration/Rewards Std        0.04795361039099
exploration/Rewards Max        0.9785352326473076
exploration/Rewards Min        0.49071530525227613
exploration/Returns Mean       478.6130846500408
exploration/Returns Std        0.9025170709402381
exploration/Returns Max        480.2363111465936
exploration/Returns Min        477.1653099011605
exploration/Actions Mean       0.055140782
exploration/Actions Std        0.5720491
exploration/Actions Max        0.9999654
exploration/Actions Min        -0.99995244
exploration/Num Paths          10
exploration/Average Returns    478.6130846500408
evaluation/num steps total     2100000
evaluation/num paths total     4200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9573829882388032
evaluation/Rewards Std         0.04804224331535919
evaluation/Rewards Max         0.9790229393945717
evaluation/Rewards Min         0.48770455818101893
evaluation/Returns Mean        478.6914941194016
evaluation/Returns Std         0.6203569831115946
evaluation/Returns Max         479.79105528441175
evaluation/Returns Min         477.61633816591785
evaluation/ExplReturns Mean    478.6914941194016
evaluation/ExplReturns Std     0.6203569831115946
evaluation/ExplReturns Max     479.79105528441175
evaluation/ExplReturns Min     477.61633816591785
evaluation/Actions Mean        0.07210617
evaluation/Actions Std         0.43638426
evaluation/Actions Max         0.999748
evaluation/Actions Min         -0.9996982
evaluation/Num Paths           10
evaluation/Average Returns     478.6914941194016
time/data storing (s)          0.03192909434437752
time/evaluation sampling (s)   112.53905036952347
time/exploration sampling (s)  112.85381013527513
time/logging (s)               0.03050307184457779
time/saving (s)                0.01028731931000948
time/training (s)              10.181730941869318
time/epoch (s)                 235.64731093216687
time/total (s)                 98257.95700357296
Epoch                          419
-----------------------------  ---------------------
2023-08-01 21:15:43.665239 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 420 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3716.1257]
trainer/QF1 Loss               0.020933492
trainer/QF2 Loss               0.022744428
trainer/Policy Loss            -92.772964
trainer/Q1 Predictions Mean    104.59798
trainer/Q1 Predictions Std     3.4984033
trainer/Q1 Predictions Max     106.00848
trainer/Q1 Predictions Min     73.292534
trainer/Q2 Predictions Mean    104.59122
trainer/Q2 Predictions Std     3.4208817
trainer/Q2 Predictions Max     106.03812
trainer/Q2 Predictions Min     73.50207
trainer/Q Targets Mean         104.540665
trainer/Q Targets Std          3.4662135
trainer/Q Targets Max          105.95452
trainer/Q Targets Min          73.15963
trainer/Log Pis Mean           11.923158
trainer/Log Pis Std            8.072157
trainer/Log Pis Max            51.14432
trainer/Log Pis Min            -4.860902
trainer/Policy mu Mean         0.033003088
trainer/Policy mu Std          1.6127763
trainer/Policy mu Max          5.996259
trainer/Policy mu Min          -5.641429
trainer/Policy log std Mean    -0.6671243
trainer/Policy log std Std     0.2938972
trainer/Policy log std Max     0.7329131
trainer/Policy log std Min     -1.9652213
trainer/Alpha                  0.0016386691713705659
trainer/Alpha Loss             -0.49284929037094116
exploration/num steps total    2106000
exploration/num paths total    4212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9637366380110055
exploration/Rewards Std        0.048665845055313885
exploration/Rewards Max        0.979636494046877
exploration/Rewards Min        0.48433820129134064
exploration/Returns Mean       481.86831900550277
exploration/Returns Std        0.3496881508130238
exploration/Returns Max        482.470837501575
exploration/Returns Min        481.27141526274283
exploration/Actions Mean       0.010115214
exploration/Actions Std        0.56150365
exploration/Actions Max        0.9999627
exploration/Actions Min        -0.99996686
exploration/Num Paths          10
exploration/Average Returns    481.86831900550277
evaluation/num steps total     2105000
evaluation/num paths total     4210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9647814212491165
evaluation/Rewards Std         0.04798957767871502
evaluation/Rewards Max         0.9792070161446645
evaluation/Rewards Min         0.49497976395666776
evaluation/Returns Mean        482.39071062455815
evaluation/Returns Std         0.18031430824195746
evaluation/Returns Max         482.6178048114537
evaluation/Returns Min         482.0868310473935
evaluation/ExplReturns Mean    482.39071062455815
evaluation/ExplReturns Std     0.18031430824195746
evaluation/ExplReturns Max     482.6178048114537
evaluation/ExplReturns Min     482.0868310473935
evaluation/Actions Mean        0.0125676235
evaluation/Actions Std         0.3935889
evaluation/Actions Max         0.9992719
evaluation/Actions Min         -0.99965817
evaluation/Num Paths           10
evaluation/Average Returns     482.39071062455815
time/data storing (s)          0.03201717417687178
time/evaluation sampling (s)   112.79497614502907
time/exploration sampling (s)  113.35232913400978
time/logging (s)               0.030639571137726307
time/saving (s)                0.012118179351091385
time/training (s)              10.554345432668924
time/epoch (s)                 236.77642563637346
time/total (s)                 98494.73596129008
Epoch                          420
-----------------------------  ---------------------
2023-08-01 21:19:43.011553 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 421 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3805.4287]
trainer/QF1 Loss               0.028514624
trainer/QF2 Loss               0.057305977
trainer/Policy Loss            -92.391014
trainer/Q1 Predictions Mean    104.22121
trainer/Q1 Predictions Std     3.8019679
trainer/Q1 Predictions Max     105.83621
trainer/Q1 Predictions Min     71.74316
trainer/Q2 Predictions Mean    104.14171
trainer/Q2 Predictions Std     3.7512004
trainer/Q2 Predictions Max     105.82164
trainer/Q2 Predictions Min     71.868416
trainer/Q Targets Mean         104.31717
trainer/Q Targets Std          3.7721293
trainer/Q Targets Max          106.02336
trainer/Q Targets Min          72.542725
trainer/Log Pis Mean           11.86402
trainer/Log Pis Std            8.060658
trainer/Log Pis Max            45.794395
trainer/Log Pis Min            -6.0944295
trainer/Policy mu Mean         -0.075836375
trainer/Policy mu Std          1.6129774
trainer/Policy mu Max          5.3615766
trainer/Policy mu Min          -7.103675
trainer/Policy log std Mean    -0.6838484
trainer/Policy log std Std     0.27402833
trainer/Policy log std Max     0.19962439
trainer/Policy log std Min     -1.8846562
trainer/Alpha                  0.0015809701289981604
trainer/Alpha Loss             -0.8770555257797241
exploration/num steps total    2111000
exploration/num paths total    4222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9599086771638266
exploration/Rewards Std        0.051849054498948326
exploration/Rewards Max        0.9796450046190781
exploration/Rewards Min        0.4852689311736921
exploration/Returns Mean       479.9543385819132
exploration/Returns Std        0.9468411022212735
exploration/Returns Max        481.33624316959214
exploration/Returns Min        478.48169115661784
exploration/Actions Mean       0.032827158
exploration/Actions Std        0.61070985
exploration/Actions Max        0.99984396
exploration/Actions Min        -0.9999475
exploration/Num Paths          10
exploration/Average Returns    479.9543385819132
evaluation/num steps total     2110000
evaluation/num paths total     4220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9633145174572417
evaluation/Rewards Std         0.05070956725793606
evaluation/Rewards Max         0.9787989703684264
evaluation/Rewards Min         0.4972241610295194
evaluation/Returns Mean        481.6572587286208
evaluation/Returns Std         0.9986047948280323
evaluation/Returns Max         483.313335359093
evaluation/Returns Min         480.43867508071753
evaluation/ExplReturns Mean    481.6572587286208
evaluation/ExplReturns Std     0.9986047948280323
evaluation/ExplReturns Max     483.313335359093
evaluation/ExplReturns Min     480.43867508071753
evaluation/Actions Mean        0.061233908
evaluation/Actions Std         0.44901702
evaluation/Actions Max         0.9985018
evaluation/Actions Min         -0.99948156
evaluation/Num Paths           10
evaluation/Average Returns     481.6572587286208
time/data storing (s)          0.03227548114955425
time/evaluation sampling (s)   114.19973411504179
time/exploration sampling (s)  114.9807868776843
time/logging (s)               0.030415639281272888
time/saving (s)                0.012602439150214195
time/training (s)              10.084212062880397
time/epoch (s)                 239.34002661518753
time/total (s)                 98734.07845475618
Epoch                          421
-----------------------------  ---------------------
2023-08-01 21:23:37.006985 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 422 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4370.6987]
trainer/QF1 Loss               0.033778932
trainer/QF2 Loss               0.035969798
trainer/Policy Loss            -92.42948
trainer/Q1 Predictions Mean    104.45564
trainer/Q1 Predictions Std     3.0527587
trainer/Q1 Predictions Max     106.17945
trainer/Q1 Predictions Min     75.831566
trainer/Q2 Predictions Mean    104.46025
trainer/Q2 Predictions Std     3.0384154
trainer/Q2 Predictions Max     106.127464
trainer/Q2 Predictions Min     76.26475
trainer/Q Targets Mean         104.43612
trainer/Q Targets Std          3.1111686
trainer/Q Targets Max          106.29211
trainer/Q Targets Min          76.09472
trainer/Log Pis Mean           12.112345
trainer/Log Pis Std            9.006804
trainer/Log Pis Max            56.263752
trainer/Log Pis Min            -4.666829
trainer/Policy mu Mean         -0.016160453
trainer/Policy mu Std          1.6221967
trainer/Policy mu Max          10.085279
trainer/Policy mu Min          -13.40554
trainer/Policy log std Mean    -0.71042424
trainer/Policy log std Std     0.29379377
trainer/Policy log std Max     0.88053197
trainer/Policy log std Min     -2.0822427
trainer/Alpha                  0.0015924469335004687
trainer/Alpha Loss             0.7237576246261597
exploration/num steps total    2116000
exploration/num paths total    4232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9520414955764347
exploration/Rewards Std        0.05917310667413938
exploration/Rewards Max        0.9795935345044555
exploration/Rewards Min        0.49604763570655663
exploration/Returns Mean       476.02074778821725
exploration/Returns Std        1.5778832961659397
exploration/Returns Max        478.0684577421834
exploration/Returns Min        473.0343992803843
exploration/Actions Mean       0.023919532
exploration/Actions Std        0.624428
exploration/Actions Max        0.99957514
exploration/Actions Min        -0.9999817
exploration/Num Paths          10
exploration/Average Returns    476.02074778821725
evaluation/num steps total     2115000
evaluation/num paths total     4230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9502538854724305
evaluation/Rewards Std         0.06142877015682275
evaluation/Rewards Max         0.9779292716895539
evaluation/Rewards Min         0.4947409308767677
evaluation/Returns Mean        475.1269427362152
evaluation/Returns Std         4.890113765000473
evaluation/Returns Max         479.2714143882715
evaluation/Returns Min         462.33634151150756
evaluation/ExplReturns Mean    475.1269427362152
evaluation/ExplReturns Std     4.890113765000473
evaluation/ExplReturns Max     479.2714143882715
evaluation/ExplReturns Min     462.33634151150756
evaluation/Actions Mean        0.049531296
evaluation/Actions Std         0.5091695
evaluation/Actions Max         0.99995214
evaluation/Actions Min         -0.99966854
evaluation/Num Paths           10
evaluation/Average Returns     475.1269427362152
time/data storing (s)          0.031796921975910664
time/evaluation sampling (s)   111.74847170058638
time/exploration sampling (s)  112.00003963988274
time/logging (s)               0.031085255555808544
time/saving (s)                0.012825079262256622
time/training (s)              10.165882580913603
time/epoch (s)                 233.9901011781767
time/total (s)                 98968.07099864166
Epoch                          422
-----------------------------  ---------------------
2023-08-01 21:27:31.475575 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 423 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4394.8994]
trainer/QF1 Loss               0.037273943
trainer/QF2 Loss               0.031222682
trainer/Policy Loss            -92.340454
trainer/Q1 Predictions Mean    104.50361
trainer/Q1 Predictions Std     2.597411
trainer/Q1 Predictions Max     105.730644
trainer/Q1 Predictions Min     78.59924
trainer/Q2 Predictions Mean    104.3468
trainer/Q2 Predictions Std     2.5818675
trainer/Q2 Predictions Max     105.550415
trainer/Q2 Predictions Min     78.36346
trainer/Q Targets Mean         104.4243
trainer/Q Targets Std          2.5722532
trainer/Q Targets Max          105.68197
trainer/Q Targets Min          79.16671
trainer/Log Pis Mean           12.132163
trainer/Log Pis Std            8.572622
trainer/Log Pis Max            59.521976
trainer/Log Pis Min            -10.98782
trainer/Policy mu Mean         0.06400397
trainer/Policy mu Std          1.6079782
trainer/Policy mu Max          9.290602
trainer/Policy mu Min          -5.5904064
trainer/Policy log std Mean    -0.6753831
trainer/Policy log std Std     0.27058902
trainer/Policy log std Max     0.95057786
trainer/Policy log std Min     -1.8882834
trainer/Alpha                  0.0015846503665670753
trainer/Alpha Loss             0.8521054983139038
exploration/num steps total    2121000
exploration/num paths total    4242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8352846379939157
exploration/Rewards Std        0.11991410625457069
exploration/Rewards Max        0.9781396802584859
exploration/Rewards Min        0.49698562100346
exploration/Returns Mean       417.64231899695795
exploration/Returns Std        26.898986070521236
exploration/Returns Max        453.45135465877974
exploration/Returns Min        355.1305742132325
exploration/Actions Mean       0.030644253
exploration/Actions Std        0.67473084
exploration/Actions Max        0.9999994
exploration/Actions Min        -0.99999905
exploration/Num Paths          10
exploration/Average Returns    417.64231899695795
evaluation/num steps total     2120000
evaluation/num paths total     4240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8553690475790334
evaluation/Rewards Std         0.11635299863494653
evaluation/Rewards Max         0.9761174014254599
evaluation/Rewards Min         0.4890868895747173
evaluation/Returns Mean        427.6845237895167
evaluation/Returns Std         24.304106711670464
evaluation/Returns Max         452.0082792747256
evaluation/Returns Min         377.30428872538715
evaluation/ExplReturns Mean    427.6845237895167
evaluation/ExplReturns Std     24.304106711670464
evaluation/ExplReturns Max     452.0082792747256
evaluation/ExplReturns Min     377.30428872538715
evaluation/Actions Mean        0.027063262
evaluation/Actions Std         0.6233223
evaluation/Actions Max         0.9999981
evaluation/Actions Min         -0.9999964
evaluation/Num Paths           10
evaluation/Average Returns     427.6845237895167
time/data storing (s)          0.03182685095816851
time/evaluation sampling (s)   111.4735091747716
time/exploration sampling (s)  113.33890002500266
time/logging (s)               0.030862734653055668
time/saving (s)                0.01276443526148796
time/training (s)              9.574449222534895
time/epoch (s)                 234.46231244318187
time/total (s)                 99202.53578032367
Epoch                          423
-----------------------------  ---------------------
2023-08-01 21:31:25.859062 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 424 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4394.7593]
trainer/QF1 Loss               0.06575791
trainer/QF2 Loss               0.053523898
trainer/Policy Loss            -92.45679
trainer/Q1 Predictions Mean    104.07904
trainer/Q1 Predictions Std     3.400528
trainer/Q1 Predictions Max     106.08996
trainer/Q1 Predictions Min     67.78927
trainer/Q2 Predictions Mean    104.12171
trainer/Q2 Predictions Std     3.426469
trainer/Q2 Predictions Max     106.07397
trainer/Q2 Predictions Min     67.11339
trainer/Q Targets Mean         104.296295
trainer/Q Targets Std          3.4754221
trainer/Q Targets Max          106.34486
trainer/Q Targets Min          66.95159
trainer/Log Pis Mean           11.726614
trainer/Log Pis Std            7.776488
trainer/Log Pis Max            57.311813
trainer/Log Pis Min            -3.8433418
trainer/Policy mu Mean         0.049744185
trainer/Policy mu Std          1.6076107
trainer/Policy mu Max          8.68087
trainer/Policy mu Min          -8.549505
trainer/Policy log std Mean    -0.68738335
trainer/Policy log std Std     0.2926023
trainer/Policy log std Max     1.1732898
trainer/Policy log std Min     -1.9590774
trainer/Alpha                  0.0015905710170045495
trainer/Alpha Loss             -1.761620044708252
exploration/num steps total    2126000
exploration/num paths total    4252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.88514279377522
exploration/Rewards Std        0.11814613623221656
exploration/Rewards Max        0.9779322248546571
exploration/Rewards Min        0.4786492901802872
exploration/Returns Mean       442.5713968876101
exploration/Returns Std        28.685607604325845
exploration/Returns Max        470.5104091216021
exploration/Returns Min        371.60786170231574
exploration/Actions Mean       -0.008234099
exploration/Actions Std        0.60175127
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999983
exploration/Num Paths          10
exploration/Average Returns    442.5713968876101
evaluation/num steps total     2125000
evaluation/num paths total     4250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8343075095564567
evaluation/Rewards Std         0.11305528378311873
evaluation/Rewards Max         0.9777768010332949
evaluation/Rewards Min         0.4918257563631147
evaluation/Returns Mean        417.15375477822835
evaluation/Returns Std         29.539380576130036
evaluation/Returns Max         479.9869817402748
evaluation/Returns Min         363.6650696770262
evaluation/ExplReturns Mean    417.15375477822835
evaluation/ExplReturns Std     29.539380576130036
evaluation/ExplReturns Max     479.9869817402748
evaluation/ExplReturns Min     363.6650696770262
evaluation/Actions Mean        -0.0008578285
evaluation/Actions Std         0.5065486
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -0.99990475
evaluation/Num Paths           10
evaluation/Average Returns     417.15375477822835
time/data storing (s)          0.03185004461556673
time/evaluation sampling (s)   111.92676523327827
time/exploration sampling (s)  112.43423070572317
time/logging (s)               0.03053597453981638
time/saving (s)                0.010362914763391018
time/training (s)              9.943373366259038
time/epoch (s)                 234.37711823917925
time/total (s)                 99436.91535216384
Epoch                          424
-----------------------------  ---------------------
2023-08-01 21:35:28.723447 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 425 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3968.0369]
trainer/QF1 Loss               0.022552345
trainer/QF2 Loss               0.03119499
trainer/Policy Loss            -91.66055
trainer/Q1 Predictions Mean    104.162445
trainer/Q1 Predictions Std     3.6745777
trainer/Q1 Predictions Max     106.54473
trainer/Q1 Predictions Min     59.00827
trainer/Q2 Predictions Mean    104.09929
trainer/Q2 Predictions Std     3.71757
trainer/Q2 Predictions Max     106.641945
trainer/Q2 Predictions Min     58.16187
trainer/Q Targets Mean         104.145
trainer/Q Targets Std          3.6297784
trainer/Q Targets Max          106.626305
trainer/Q Targets Min          59.942417
trainer/Log Pis Mean           12.552076
trainer/Log Pis Std            9.308655
trainer/Log Pis Max            55.415516
trainer/Log Pis Min            -3.0853994
trainer/Policy mu Mean         0.1993583
trainer/Policy mu Std          1.6448189
trainer/Policy mu Max          8.972438
trainer/Policy mu Min          -7.108402
trainer/Policy log std Mean    -0.69440323
trainer/Policy log std Std     0.29951227
trainer/Policy log std Max     0.90536857
trainer/Policy log std Min     -2.3324375
trainer/Alpha                  0.0015612152637913823
trainer/Alpha Loss             3.5676732063293457
exploration/num steps total    2131000
exploration/num paths total    4262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9378864141987393
exploration/Rewards Std        0.08349700194039912
exploration/Rewards Max        0.9797734907615429
exploration/Rewards Min        0.49130363328955395
exploration/Returns Mean       468.9432070993697
exploration/Returns Std        28.80251517714495
exploration/Returns Max        482.39931785737235
exploration/Returns Min        383.10766029532505
exploration/Actions Mean       0.18829384
exploration/Actions Std        0.67973655
exploration/Actions Max        1.0
exploration/Actions Min        -0.99993026
exploration/Num Paths          10
exploration/Average Returns    468.9432070993697
evaluation/num steps total     2130000
evaluation/num paths total     4260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.915789289775423
evaluation/Rewards Std         0.09589674198700357
evaluation/Rewards Max         0.9779203372953149
evaluation/Rewards Min         0.49494041403506533
evaluation/Returns Mean        457.89464488771154
evaluation/Returns Std         29.602389290952644
evaluation/Returns Max         479.9367037043352
evaluation/Returns Min         383.4513126633599
evaluation/ExplReturns Mean    457.89464488771154
evaluation/ExplReturns Std     29.602389290952644
evaluation/ExplReturns Max     479.9367037043352
evaluation/ExplReturns Min     383.4513126633599
evaluation/Actions Mean        0.25902668
evaluation/Actions Std         0.60730517
evaluation/Actions Max         0.99999654
evaluation/Actions Min         -0.999357
evaluation/Num Paths           10
evaluation/Average Returns     457.89464488771154
time/data storing (s)          0.031824021600186825
time/evaluation sampling (s)   116.23093841597438
time/exploration sampling (s)  116.09892261773348
time/logging (s)               0.030239593237638474
time/saving (s)                0.012657133862376213
time/training (s)              10.453487015329301
time/epoch (s)                 242.85806879773736
time/total (s)                 99679.7758962214
Epoch                          425
-----------------------------  ---------------------
2023-08-01 21:39:29.135880 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 426 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4469.955]
trainer/QF1 Loss               0.03674993
trainer/QF2 Loss               0.029311728
trainer/Policy Loss            -92.76305
trainer/Q1 Predictions Mean    104.19647
trainer/Q1 Predictions Std     3.4670954
trainer/Q1 Predictions Max     106.82855
trainer/Q1 Predictions Min     67.68052
trainer/Q2 Predictions Mean    103.99709
trainer/Q2 Predictions Std     3.4629793
trainer/Q2 Predictions Max     106.84984
trainer/Q2 Predictions Min     67.920105
trainer/Q Targets Mean         104.08232
trainer/Q Targets Std          3.4503987
trainer/Q Targets Max          106.89622
trainer/Q Targets Min          68.131584
trainer/Log Pis Mean           11.377134
trainer/Log Pis Std            7.6698747
trainer/Log Pis Max            59.373802
trainer/Log Pis Min            -1.260397
trainer/Policy mu Mean         0.2965345
trainer/Policy mu Std          1.553616
trainer/Policy mu Max          11.762941
trainer/Policy mu Min          -10.880707
trainer/Policy log std Mean    -0.69959545
trainer/Policy log std Std     0.29520983
trainer/Policy log std Max     0.3143419
trainer/Policy log std Min     -2.044759
trainer/Alpha                  0.001545214094221592
trainer/Alpha Loss             -4.0314412117004395
exploration/num steps total    2136000
exploration/num paths total    4272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8219592481574993
exploration/Rewards Std        0.10320811879709406
exploration/Rewards Max        0.9787032215197305
exploration/Rewards Min        0.49870744808204404
exploration/Returns Mean       410.9796240787497
exploration/Returns Std        17.31334734030003
exploration/Returns Max        457.52749574714323
exploration/Returns Min        396.14208046837695
exploration/Actions Mean       0.10694137
exploration/Actions Std        0.56687
exploration/Actions Max        0.99999744
exploration/Actions Min        -0.99993443
exploration/Num Paths          10
exploration/Average Returns    410.9796240787497
evaluation/num steps total     2135000
evaluation/num paths total     4270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7876318639336137
evaluation/Rewards Std         0.08464664208049882
evaluation/Rewards Max         0.9788012168415534
evaluation/Rewards Min         0.486406928589613
evaluation/Returns Mean        393.8159319668069
evaluation/Returns Std         9.228409349648793
evaluation/Returns Max         416.16808961009906
evaluation/Returns Min         382.83265399617375
evaluation/ExplReturns Mean    393.8159319668069
evaluation/ExplReturns Std     9.228409349648793
evaluation/ExplReturns Max     416.16808961009906
evaluation/ExplReturns Min     382.83265399617375
evaluation/Actions Mean        0.14854464
evaluation/Actions Std         0.4564121
evaluation/Actions Max         0.9991202
evaluation/Actions Min         -0.9992129
evaluation/Num Paths           10
evaluation/Average Returns     393.8159319668069
time/data storing (s)          0.03197412472218275
time/evaluation sampling (s)   115.51184141542763
time/exploration sampling (s)  115.17093438189477
time/logging (s)               0.03098699077963829
time/saving (s)                0.012922641821205616
time/training (s)              9.648383367806673
time/epoch (s)                 240.4070429224521
time/total (s)                 99920.18548855651
Epoch                          426
-----------------------------  --------------------
2023-08-01 21:43:23.092706 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 427 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4381.0366]
trainer/QF1 Loss               0.03012272
trainer/QF2 Loss               0.03352067
trainer/Policy Loss            -92.12742
trainer/Q1 Predictions Mean    104.113014
trainer/Q1 Predictions Std     2.919531
trainer/Q1 Predictions Max     105.97654
trainer/Q1 Predictions Min     78.04852
trainer/Q2 Predictions Mean    104.194336
trainer/Q2 Predictions Std     2.9718297
trainer/Q2 Predictions Max     106.06986
trainer/Q2 Predictions Min     78.585556
trainer/Q Targets Mean         104.133316
trainer/Q Targets Std          2.9189687
trainer/Q Targets Max          106.08565
trainer/Q Targets Min          78.57495
trainer/Log Pis Mean           12.137287
trainer/Log Pis Std            8.07043
trainer/Log Pis Max            53.716015
trainer/Log Pis Min            -4.7778807
trainer/Policy mu Mean         0.30034146
trainer/Policy mu Std          1.579817
trainer/Policy mu Max          7.8384066
trainer/Policy mu Min          -5.796178
trainer/Policy log std Mean    -0.6690042
trainer/Policy log std Std     0.2782304
trainer/Policy log std Max     0.57760584
trainer/Policy log std Min     -1.7757705
trainer/Alpha                  0.0016222725389525294
trainer/Alpha Loss             0.8819566369056702
exploration/num steps total    2141000
exploration/num paths total    4282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9389956184585353
exploration/Rewards Std        0.05263173217654426
exploration/Rewards Max        0.9786384608111954
exploration/Rewards Min        0.48906967784407407
exploration/Returns Mean       469.4978092292678
exploration/Returns Std        1.9423987612105678
exploration/Returns Max        472.54633066014344
exploration/Returns Min        464.92439854706737
exploration/Actions Mean       0.014910455
exploration/Actions Std        0.58566535
exploration/Actions Max        0.9999736
exploration/Actions Min        -0.9999651
exploration/Num Paths          10
exploration/Average Returns    469.4978092292678
evaluation/num steps total     2140000
evaluation/num paths total     4280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8932209470259691
evaluation/Rewards Std         0.10678081205146527
evaluation/Rewards Max         0.9793533114590203
evaluation/Rewards Min         0.49352591007472074
evaluation/Returns Mean        446.61047351298447
evaluation/Returns Std         18.39553202413874
evaluation/Returns Max         468.56765500360297
evaluation/Returns Min         405.0573015532995
evaluation/ExplReturns Mean    446.61047351298447
evaluation/ExplReturns Std     18.39553202413874
evaluation/ExplReturns Max     468.56765500360297
evaluation/ExplReturns Min     405.0573015532995
evaluation/Actions Mean        0.062724255
evaluation/Actions Std         0.561106
evaluation/Actions Max         0.9999996
evaluation/Actions Min         -0.99999875
evaluation/Num Paths           10
evaluation/Average Returns     446.61047351298447
time/data storing (s)          0.032201457768678665
time/evaluation sampling (s)   111.36265662871301
time/exploration sampling (s)  112.91433484479785
time/logging (s)               0.03031293861567974
time/saving (s)                0.011138135567307472
time/training (s)              9.599466784857213
time/epoch (s)                 233.95011079031974
time/total (s)                 100154.13807261363
Epoch                          427
-----------------------------  ---------------------
2023-08-01 21:47:22.775528 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 428 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4402.8774]
trainer/QF1 Loss               0.021255402
trainer/QF2 Loss               0.021034671
trainer/Policy Loss            -91.72336
trainer/Q1 Predictions Mean    104.07268
trainer/Q1 Predictions Std     2.9666102
trainer/Q1 Predictions Max     106.29497
trainer/Q1 Predictions Min     72.99332
trainer/Q2 Predictions Mean    104.07563
trainer/Q2 Predictions Std     2.9506757
trainer/Q2 Predictions Max     106.40877
trainer/Q2 Predictions Min     72.96655
trainer/Q Targets Mean         104.054596
trainer/Q Targets Std          2.9874725
trainer/Q Targets Max          106.3735
trainer/Q Targets Min          72.99811
trainer/Log Pis Mean           12.448193
trainer/Log Pis Std            7.5777273
trainer/Log Pis Max            42.370834
trainer/Log Pis Min            -2.3256228
trainer/Policy mu Mean         0.3296987
trainer/Policy mu Std          1.6116205
trainer/Policy mu Max          5.66615
trainer/Policy mu Min          -5.535898
trainer/Policy log std Mean    -0.69582033
trainer/Policy log std Std     0.284559
trainer/Policy log std Max     0.075834095
trainer/Policy log std Min     -1.806419
trainer/Alpha                  0.0016441872576251626
trainer/Alpha Loss             2.8731987476348877
exploration/num steps total    2146000
exploration/num paths total    4292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9483364673105367
exploration/Rewards Std        0.04702489948958297
exploration/Rewards Max        0.9746338242907637
exploration/Rewards Min        0.4936291523239841
exploration/Returns Mean       474.16823365526824
exploration/Returns Std        2.7235229644721994
exploration/Returns Max        479.77031663675126
exploration/Returns Min        471.91340954662496
exploration/Actions Mean       0.19362591
exploration/Actions Std        0.5878986
exploration/Actions Max        0.9999723
exploration/Actions Min        -0.9998965
exploration/Num Paths          10
exploration/Average Returns    474.16823365526824
evaluation/num steps total     2145000
evaluation/num paths total     4290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9444634176153504
evaluation/Rewards Std         0.044875300870526956
evaluation/Rewards Max         0.9743728866066296
evaluation/Rewards Min         0.486463778432761
evaluation/Returns Mean        472.2317088076752
evaluation/Returns Std         0.6817120911573172
evaluation/Returns Max         473.2575048432142
evaluation/Returns Min         471.2213329582292
evaluation/ExplReturns Mean    472.2317088076752
evaluation/ExplReturns Std     0.6817120911573172
evaluation/ExplReturns Max     473.2575048432142
evaluation/ExplReturns Min     471.2213329582292
evaluation/Actions Mean        0.19956379
evaluation/Actions Std         0.51023257
evaluation/Actions Max         0.99693346
evaluation/Actions Min         -0.9990542
evaluation/Num Paths           10
evaluation/Average Returns     472.2317088076752
time/data storing (s)          0.031768979504704475
time/evaluation sampling (s)   114.49834256246686
time/exploration sampling (s)  115.48922935780138
time/logging (s)               0.03033064678311348
time/saving (s)                0.010284596122801304
time/training (s)              9.616758310236037
time/epoch (s)                 239.6767144529149
time/total (s)                 100393.81731858756
Epoch                          428
-----------------------------  ---------------------
2023-08-01 21:51:19.800861 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 429 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4380.7046]
trainer/QF1 Loss               0.022929218
trainer/QF2 Loss               0.023098387
trainer/Policy Loss            -91.65534
trainer/Q1 Predictions Mean    103.84471
trainer/Q1 Predictions Std     3.8756855
trainer/Q1 Predictions Max     105.830894
trainer/Q1 Predictions Min     68.05735
trainer/Q2 Predictions Mean    103.86751
trainer/Q2 Predictions Std     3.8879542
trainer/Q2 Predictions Max     105.84328
trainer/Q2 Predictions Min     67.81786
trainer/Q Targets Mean         103.909805
trainer/Q Targets Std          3.9210918
trainer/Q Targets Max          105.84469
trainer/Q Targets Min          67.64475
trainer/Log Pis Mean           12.304617
trainer/Log Pis Std            8.935941
trainer/Log Pis Max            56.2284
trainer/Log Pis Min            -5.8495493
trainer/Policy mu Mean         0.35451236
trainer/Policy mu Std          1.6080208
trainer/Policy mu Max          7.079155
trainer/Policy mu Min          -5.931772
trainer/Policy log std Mean    -0.6898803
trainer/Policy log std Std     0.28420395
trainer/Policy log std Max     0.64039016
trainer/Policy log std Min     -2.1217303
trainer/Alpha                  0.0017372827278450131
trainer/Alpha Loss             1.9359889030456543
exploration/num steps total    2151000
exploration/num paths total    4302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9472377208335485
exploration/Rewards Std        0.05902408831853791
exploration/Rewards Max        0.9768270011514467
exploration/Rewards Min        0.49390030439173044
exploration/Returns Mean       473.6188604167743
exploration/Returns Std        2.0076216228560324
exploration/Returns Max        476.7701021986897
exploration/Returns Min        469.6569254911715
exploration/Actions Mean       0.07874806
exploration/Actions Std        0.66710573
exploration/Actions Max        0.99977463
exploration/Actions Min        -0.99989325
exploration/Num Paths          10
exploration/Average Returns    473.6188604167743
evaluation/num steps total     2150000
evaluation/num paths total     4300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9517464572443552
evaluation/Rewards Std         0.04824054554766689
evaluation/Rewards Max         0.9692915035771066
evaluation/Rewards Min         0.4768310947953409
evaluation/Returns Mean        475.87322862217763
evaluation/Returns Std         1.7314232322616947
evaluation/Returns Max         478.91475170647317
evaluation/Returns Min         473.00063029734304
evaluation/ExplReturns Mean    475.87322862217763
evaluation/ExplReturns Std     1.7314232322616947
evaluation/ExplReturns Max     478.91475170647317
evaluation/ExplReturns Min     473.00063029734304
evaluation/Actions Mean        -0.01703681
evaluation/Actions Std         0.7376847
evaluation/Actions Max         0.9991705
evaluation/Actions Min         -0.99994814
evaluation/Num Paths           10
evaluation/Average Returns     475.87322862217763
time/data storing (s)          0.03173188026994467
time/evaluation sampling (s)   112.85233759880066
time/exploration sampling (s)  114.43634815420955
time/logging (s)               0.030609209090471268
time/saving (s)                0.011252916418015957
time/training (s)              9.657213469035923
time/epoch (s)                 237.01949322782457
time/total (s)                 100630.83933940157
Epoch                          429
-----------------------------  ---------------------
2023-08-01 21:55:16.918905 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 430 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4442.7437]
trainer/QF1 Loss               0.03958978
trainer/QF2 Loss               0.025242716
trainer/Policy Loss            -92.219345
trainer/Q1 Predictions Mean    103.80468
trainer/Q1 Predictions Std     3.524352
trainer/Q1 Predictions Max     105.566795
trainer/Q1 Predictions Min     64.896034
trainer/Q2 Predictions Mean    103.88815
trainer/Q2 Predictions Std     3.511094
trainer/Q2 Predictions Max     105.58779
trainer/Q2 Predictions Min     64.869354
trainer/Q Targets Mean         103.9169
trainer/Q Targets Std          3.4967964
trainer/Q Targets Max          105.63712
trainer/Q Targets Min          65.03072
trainer/Log Pis Mean           11.739433
trainer/Log Pis Std            8.218074
trainer/Log Pis Max            51.17583
trainer/Log Pis Min            -5.3240156
trainer/Policy mu Mean         0.23417866
trainer/Policy mu Std          1.5838284
trainer/Policy mu Max          5.4245453
trainer/Policy mu Min          -7.4555607
trainer/Policy log std Mean    -0.6824351
trainer/Policy log std Std     0.28115955
trainer/Policy log std Max     0.8876955
trainer/Policy log std Min     -1.7334114
trainer/Alpha                  0.001753448392264545
trainer/Alpha Loss             -1.6535985469818115
exploration/num steps total    2156000
exploration/num paths total    4312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9516751602720842
exploration/Rewards Std        0.050019038692846456
exploration/Rewards Max        0.9793768015865094
exploration/Rewards Min        0.5016668218085664
exploration/Returns Mean       475.8375801360421
exploration/Returns Std        4.18332345107539
exploration/Returns Max        480.52069611309304
exploration/Returns Min        471.24924822024803
exploration/Actions Mean       0.0869342
exploration/Actions Std        0.6073738
exploration/Actions Max        0.9997165
exploration/Actions Min        -0.9999208
exploration/Num Paths          10
exploration/Average Returns    475.8375801360421
evaluation/num steps total     2155000
evaluation/num paths total     4310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9423184406113821
evaluation/Rewards Std         0.04900023320193473
evaluation/Rewards Max         0.9781709390081996
evaluation/Rewards Min         0.4907080909167026
evaluation/Returns Mean        471.1592203056912
evaluation/Returns Std         3.7893518942905513
evaluation/Returns Max         482.3529975514239
evaluation/Returns Min         468.8879979375223
evaluation/ExplReturns Mean    471.1592203056912
evaluation/ExplReturns Std     3.7893518942905513
evaluation/ExplReturns Max     482.3529975514239
evaluation/ExplReturns Min     468.8879979375223
evaluation/Actions Mean        0.12560017
evaluation/Actions Std         0.51252794
evaluation/Actions Max         0.9987746
evaluation/Actions Min         -0.99976444
evaluation/Num Paths           10
evaluation/Average Returns     471.1592203056912
time/data storing (s)          0.031681434251368046
time/evaluation sampling (s)   113.40274620149285
time/exploration sampling (s)  114.65070862043649
time/logging (s)               0.03111807256937027
time/saving (s)                0.010347840376198292
time/training (s)              8.98583612870425
time/epoch (s)                 237.11243829783052
time/total (s)                 100867.95484339353
Epoch                          430
-----------------------------  --------------------
2023-08-01 21:59:14.668737 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 431 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4462.7314]
trainer/QF1 Loss               0.01653973
trainer/QF2 Loss               0.019757137
trainer/Policy Loss            -92.75717
trainer/Q1 Predictions Mean    104.2834
trainer/Q1 Predictions Std     1.2815855
trainer/Q1 Predictions Max     105.612885
trainer/Q1 Predictions Min     90.412025
trainer/Q2 Predictions Mean    104.3804
trainer/Q2 Predictions Std     1.2983404
trainer/Q2 Predictions Max     105.684845
trainer/Q2 Predictions Min     89.99947
trainer/Q Targets Mean         104.30669
trainer/Q Targets Std          1.3208051
trainer/Q Targets Max          105.51887
trainer/Q Targets Min          89.501595
trainer/Log Pis Mean           11.678274
trainer/Log Pis Std            7.658321
trainer/Log Pis Max            78.63841
trainer/Log Pis Min            -2.8349235
trainer/Policy mu Mean         0.23106265
trainer/Policy mu Std          1.5579554
trainer/Policy mu Max          6.8784437
trainer/Policy mu Min          -9.966363
trainer/Policy log std Mean    -0.7253888
trainer/Policy log std Std     0.2621876
trainer/Policy log std Max     0.3212189
trainer/Policy log std Min     -1.7280048
trainer/Alpha                  0.0017694926355034113
trainer/Alpha Loss             -2.0388519763946533
exploration/num steps total    2161000
exploration/num paths total    4322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9472054174140309
exploration/Rewards Std        0.04920666798257253
exploration/Rewards Max        0.978863163159835
exploration/Rewards Min        0.49659436421100267
exploration/Returns Mean       473.6027087070156
exploration/Returns Std        0.9981034297340713
exploration/Returns Max        474.6665887903105
exploration/Returns Min        471.70405790327237
exploration/Actions Mean       0.086679116
exploration/Actions Std        0.622328
exploration/Actions Max        0.99969834
exploration/Actions Min        -0.99994373
exploration/Num Paths          10
exploration/Average Returns    473.6027087070156
evaluation/num steps total     2160000
evaluation/num paths total     4320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9365943739877369
evaluation/Rewards Std         0.05966686220798466
evaluation/Rewards Max         0.9776482630785186
evaluation/Rewards Min         0.4905561874711209
evaluation/Returns Mean        468.2971869938684
evaluation/Returns Std         11.385395728107158
evaluation/Returns Max         476.64013996123316
evaluation/Returns Min         446.8946805514343
evaluation/ExplReturns Mean    468.2971869938684
evaluation/ExplReturns Std     11.385395728107158
evaluation/ExplReturns Max     476.64013996123316
evaluation/ExplReturns Min     446.8946805514343
evaluation/Actions Mean        -0.033327628
evaluation/Actions Std         0.52897704
evaluation/Actions Max         0.99763095
evaluation/Actions Min         -0.99920464
evaluation/Num Paths           10
evaluation/Average Returns     468.2971869938684
time/data storing (s)          0.03163414914160967
time/evaluation sampling (s)   113.45347880199552
time/exploration sampling (s)  114.38266219571233
time/logging (s)               0.030560830608010292
time/saving (s)                0.011354242451488972
time/training (s)              9.830706065520644
time/epoch (s)                 237.7403962854296
time/total (s)                 101105.69776327815
Epoch                          431
-----------------------------  ---------------------
2023-08-01 22:03:08.599697 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 432 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4424.677]
trainer/QF1 Loss               0.024090484
trainer/QF2 Loss               0.028778609
trainer/Policy Loss            -93.68495
trainer/Q1 Predictions Mean    104.01422
trainer/Q1 Predictions Std     2.720936
trainer/Q1 Predictions Max     105.62649
trainer/Q1 Predictions Min     83.03158
trainer/Q2 Predictions Mean    104.0414
trainer/Q2 Predictions Std     2.7739367
trainer/Q2 Predictions Max     105.527534
trainer/Q2 Predictions Min     81.082115
trainer/Q Targets Mean         104.02316
trainer/Q Targets Std          2.757544
trainer/Q Targets Max          105.51401
trainer/Q Targets Min          81.70766
trainer/Log Pis Mean           10.453109
trainer/Log Pis Std            7.201925
trainer/Log Pis Max            54.666954
trainer/Log Pis Min            -4.1209645
trainer/Policy mu Mean         0.19966191
trainer/Policy mu Std          1.5184782
trainer/Policy mu Max          7.6710987
trainer/Policy mu Min          -5.6422725
trainer/Policy log std Mean    -0.6928356
trainer/Policy log std Std     0.26907396
trainer/Policy log std Max     0.11767635
trainer/Policy log std Min     -1.7601849
trainer/Alpha                  0.001803893013857305
trainer/Alpha Loss             -9.772512435913086
exploration/num steps total    2166000
exploration/num paths total    4332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9456910019598223
exploration/Rewards Std        0.055291636190112146
exploration/Rewards Max        0.9772160909061391
exploration/Rewards Min        0.5014663573879885
exploration/Returns Mean       472.84550097991115
exploration/Returns Std        3.484960746469918
exploration/Returns Max        474.8953909497698
exploration/Returns Min        462.891136199631
exploration/Actions Mean       -0.08207647
exploration/Actions Std        0.59821284
exploration/Actions Max        0.9997814
exploration/Actions Min        -0.999955
exploration/Num Paths          10
exploration/Average Returns    472.84550097991115
evaluation/num steps total     2165000
evaluation/num paths total     4330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9479493181533056
evaluation/Rewards Std         0.053391050616002036
evaluation/Rewards Max         0.9784663308109558
evaluation/Rewards Min         0.4980536901381307
evaluation/Returns Mean        473.974659076653
evaluation/Returns Std         5.114810471380298
evaluation/Returns Max         479.3139496834235
evaluation/Returns Min         460.1323835234053
evaluation/ExplReturns Mean    473.974659076653
evaluation/ExplReturns Std     5.114810471380298
evaluation/ExplReturns Max     479.3139496834235
evaluation/ExplReturns Min     460.1323835234053
evaluation/Actions Mean        -0.098545514
evaluation/Actions Std         0.4927514
evaluation/Actions Max         0.9953321
evaluation/Actions Min         -0.9998322
evaluation/Num Paths           10
evaluation/Average Returns     473.974659076653
time/data storing (s)          0.03171791974455118
time/evaluation sampling (s)   111.89070385228842
time/exploration sampling (s)  113.00093422178179
time/logging (s)               0.030550921335816383
time/saving (s)                0.010398076847195625
time/training (s)              8.960507176816463
time/epoch (s)                 233.92481216881424
time/total (s)                 101339.62507430092
Epoch                          432
-----------------------------  --------------------
2023-08-01 22:07:05.264472 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 433 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4304.514]
trainer/QF1 Loss               0.01896318
trainer/QF2 Loss               0.029266294
trainer/Policy Loss            -93.56559
trainer/Q1 Predictions Mean    104.452965
trainer/Q1 Predictions Std     1.1540169
trainer/Q1 Predictions Max     105.53379
trainer/Q1 Predictions Min     93.835724
trainer/Q2 Predictions Mean    104.521645
trainer/Q2 Predictions Std     1.1730547
trainer/Q2 Predictions Max     105.70211
trainer/Q2 Predictions Min     93.39233
trainer/Q Targets Mean         104.40381
trainer/Q Targets Std          1.1651919
trainer/Q Targets Max          105.4522
trainer/Q Targets Min          93.168175
trainer/Log Pis Mean           11.008293
trainer/Log Pis Std            6.836114
trainer/Log Pis Max            56.87557
trainer/Log Pis Min            -4.2154613
trainer/Policy mu Mean         0.09847724
trainer/Policy mu Std          1.515877
trainer/Policy mu Max          5.0061197
trainer/Policy mu Min          -6.451634
trainer/Policy log std Mean    -0.7050503
trainer/Policy log std Std     0.2786258
trainer/Policy log std Max     0.2546381
trainer/Policy log std Min     -1.997441
trainer/Alpha                  0.0017390738939866424
trainer/Alpha Loss             -6.301586627960205
exploration/num steps total    2171000
exploration/num paths total    4342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.953170611881928
exploration/Rewards Std        0.051356012276087125
exploration/Rewards Max        0.9781262774070195
exploration/Rewards Min        0.4768745385879358
exploration/Returns Mean       476.58530594096374
exploration/Returns Std        2.5131240059250994
exploration/Returns Max        478.19330278837185
exploration/Returns Min        469.176263355101
exploration/Actions Mean       -0.058095526
exploration/Actions Std        0.5853049
exploration/Actions Max        0.9997552
exploration/Actions Min        -0.99995744
exploration/Num Paths          10
exploration/Average Returns    476.58530594096374
evaluation/num steps total     2170000
evaluation/num paths total     4340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.95041729982851
evaluation/Rewards Std         0.059367506156476936
evaluation/Rewards Max         0.9788856214612454
evaluation/Rewards Min         0.4931708096589028
evaluation/Returns Mean        475.20864991425515
evaluation/Returns Std         12.361042723599322
evaluation/Returns Max         482.1344931133327
evaluation/Returns Min         438.64408144696216
evaluation/ExplReturns Mean    475.20864991425515
evaluation/ExplReturns Std     12.361042723599322
evaluation/ExplReturns Max     482.1344931133327
evaluation/ExplReturns Min     438.64408144696216
evaluation/Actions Mean        -0.07437938
evaluation/Actions Std         0.47489476
evaluation/Actions Max         0.9978079
evaluation/Actions Min         -0.9998035
evaluation/Num Paths           10
evaluation/Average Returns     475.20864991425515
time/data storing (s)          0.03194313682615757
time/evaluation sampling (s)   113.1309802280739
time/exploration sampling (s)  113.77465662173927
time/logging (s)               0.030971039086580276
time/saving (s)                0.012516036629676819
time/training (s)              9.678010364994407
time/epoch (s)                 236.65907742734998
time/total (s)                 101576.2866267953
Epoch                          433
-----------------------------  ---------------------
2023-08-01 22:11:01.234926 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 434 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4319.3877]
trainer/QF1 Loss               0.03422321
trainer/QF2 Loss               0.042472787
trainer/Policy Loss            -92.531494
trainer/Q1 Predictions Mean    104.074036
trainer/Q1 Predictions Std     2.3818092
trainer/Q1 Predictions Max     105.69668
trainer/Q1 Predictions Min     84.417786
trainer/Q2 Predictions Mean    103.95424
trainer/Q2 Predictions Std     2.3704526
trainer/Q2 Predictions Max     105.43779
trainer/Q2 Predictions Min     84.45784
trainer/Q Targets Mean         104.02127
trainer/Q Targets Std          2.41793
trainer/Q Targets Max          105.60034
trainer/Q Targets Min          84.35109
trainer/Log Pis Mean           11.558351
trainer/Log Pis Std            8.470445
trainer/Log Pis Max            52.981842
trainer/Log Pis Min            -1.1884007
trainer/Policy mu Mean         0.18133955
trainer/Policy mu Std          1.5665741
trainer/Policy mu Max          8.57458
trainer/Policy mu Min          -8.845464
trainer/Policy log std Mean    -0.69997436
trainer/Policy log std Std     0.27101788
trainer/Policy log std Max     0.29705682
trainer/Policy log std Min     -2.0166492
trainer/Alpha                  0.0016250667395070195
trainer/Alpha Loss             -2.8362622261047363
exploration/num steps total    2176000
exploration/num paths total    4352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9453478506912852
exploration/Rewards Std        0.05216621301196842
exploration/Rewards Max        0.9797006309947295
exploration/Rewards Min        0.49986378277391624
exploration/Returns Mean       472.6739253456425
exploration/Returns Std        3.9362055544359964
exploration/Returns Max        480.3599827701013
exploration/Returns Min        468.52170267036155
exploration/Actions Mean       -0.042585593
exploration/Actions Std        0.6145724
exploration/Actions Max        0.99993587
exploration/Actions Min        -0.9999752
exploration/Num Paths          10
exploration/Average Returns    472.6739253456425
evaluation/num steps total     2175000
evaluation/num paths total     4350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9459073121668083
evaluation/Rewards Std         0.046183472798169464
evaluation/Rewards Max         0.9793780226570015
evaluation/Rewards Min         0.49180842468070535
evaluation/Returns Mean        472.95365608340416
evaluation/Returns Std         3.2578743810469533
evaluation/Returns Max         479.1082749553955
evaluation/Returns Min         469.62850876170626
evaluation/ExplReturns Mean    472.95365608340416
evaluation/ExplReturns Std     3.2578743810469533
evaluation/ExplReturns Max     479.1082749553955
evaluation/ExplReturns Min     469.62850876170626
evaluation/Actions Mean        -0.112273216
evaluation/Actions Std         0.49390882
evaluation/Actions Max         0.99891645
evaluation/Actions Min         -0.9998379
evaluation/Num Paths           10
evaluation/Average Returns     472.95365608340416
time/data storing (s)          0.03185936249792576
time/evaluation sampling (s)   112.38931843079627
time/exploration sampling (s)  113.94821582827717
time/logging (s)               0.03130564093589783
time/saving (s)                0.01293446309864521
time/training (s)              9.550949316471815
time/epoch (s)                 235.96458304207772
time/total (s)                 101812.25368873961
Epoch                          434
-----------------------------  ---------------------
2023-08-01 22:14:58.518503 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 435 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4120.265]
trainer/QF1 Loss               0.017112995
trainer/QF2 Loss               0.023357265
trainer/Policy Loss            -92.5014
trainer/Q1 Predictions Mean    103.89735
trainer/Q1 Predictions Std     2.4522905
trainer/Q1 Predictions Max     105.35525
trainer/Q1 Predictions Min     74.543915
trainer/Q2 Predictions Mean    103.93284
trainer/Q2 Predictions Std     2.4374394
trainer/Q2 Predictions Max     105.411194
trainer/Q2 Predictions Min     75.01057
trainer/Q Targets Mean         103.88325
trainer/Q Targets Std          2.4722283
trainer/Q Targets Max          105.3404
trainer/Q Targets Min          74.38754
trainer/Log Pis Mean           11.512978
trainer/Log Pis Std            7.5394273
trainer/Log Pis Max            49.649033
trainer/Log Pis Min            -3.13305
trainer/Policy mu Mean         0.18280275
trainer/Policy mu Std          1.5459146
trainer/Policy mu Max          6.587173
trainer/Policy mu Min          -5.480462
trainer/Policy log std Mean    -0.7346446
trainer/Policy log std Std     0.28203765
trainer/Policy log std Max     0.45157754
trainer/Policy log std Min     -2.1446507
trainer/Alpha                  0.0015549713280051947
trainer/Alpha Loss             -3.1491856575012207
exploration/num steps total    2181000
exploration/num paths total    4362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9589550620777539
exploration/Rewards Std        0.049787976511819126
exploration/Rewards Max        0.9797798488821354
exploration/Rewards Min        0.5002838737981393
exploration/Returns Mean       479.4775310388768
exploration/Returns Std        1.058241878266038
exploration/Returns Max        480.90232180472816
exploration/Returns Min        476.8643881994718
exploration/Actions Mean       0.063068114
exploration/Actions Std        0.62193865
exploration/Actions Max        0.9999107
exploration/Actions Min        -0.999661
exploration/Num Paths          10
exploration/Average Returns    479.4775310388768
evaluation/num steps total     2180000
evaluation/num paths total     4360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9647206929049209
evaluation/Rewards Std         0.049046224957406966
evaluation/Rewards Max         0.9799484496871506
evaluation/Rewards Min         0.4962327695883336
evaluation/Returns Mean        482.3603464524605
evaluation/Returns Std         1.104902896531083
evaluation/Returns Max         483.625068009983
evaluation/Returns Min         480.1352589612701
evaluation/ExplReturns Mean    482.3603464524605
evaluation/ExplReturns Std     1.104902896531083
evaluation/ExplReturns Max     483.625068009983
evaluation/ExplReturns Min     480.1352589612701
evaluation/Actions Mean        0.038133077
evaluation/Actions Std         0.5042028
evaluation/Actions Max         0.995343
evaluation/Actions Min         -0.99830246
evaluation/Num Paths           10
evaluation/Average Returns     482.3603464524605
time/data storing (s)          0.03220308665186167
time/evaluation sampling (s)   114.35413000360131
time/exploration sampling (s)  113.146315343678
time/logging (s)               0.03069452755153179
time/saving (s)                0.010987261310219765
time/training (s)              9.7023421311751
time/epoch (s)                 237.27667235396802
time/total (s)                 102049.53300357144
Epoch                          435
-----------------------------  ---------------------
2023-08-01 22:18:54.649260 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 436 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4348.9277]
trainer/QF1 Loss               0.020204302
trainer/QF2 Loss               0.01418492
trainer/Policy Loss            -92.62633
trainer/Q1 Predictions Mean    103.92923
trainer/Q1 Predictions Std     1.7487625
trainer/Q1 Predictions Max     105.19831
trainer/Q1 Predictions Min     87.035934
trainer/Q2 Predictions Mean    103.96661
trainer/Q2 Predictions Std     1.714873
trainer/Q2 Predictions Max     105.23735
trainer/Q2 Predictions Min     87.28275
trainer/Q Targets Mean         103.98968
trainer/Q Targets Std          1.7080175
trainer/Q Targets Max          105.26313
trainer/Q Targets Min          87.16782
trainer/Log Pis Mean           11.403934
trainer/Log Pis Std            8.539395
trainer/Log Pis Max            46.000633
trainer/Log Pis Min            -5.186249
trainer/Policy mu Mean         0.29690233
trainer/Policy mu Std          1.5479078
trainer/Policy mu Max          7.2177134
trainer/Policy mu Min          -7.6832733
trainer/Policy log std Mean    -0.69062215
trainer/Policy log std Std     0.28711703
trainer/Policy log std Max     1.1290648
trainer/Policy log std Min     -1.9854409
trainer/Alpha                  0.001450725132599473
trainer/Alpha Loss             -3.8957467079162598
exploration/num steps total    2186000
exploration/num paths total    4372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9564558610000266
exploration/Rewards Std        0.05122143225028355
exploration/Rewards Max        0.9795160683600607
exploration/Rewards Min        0.4901935958171133
exploration/Returns Mean       478.2279305000131
exploration/Returns Std        0.8478650860903018
exploration/Returns Max        479.60639529933906
exploration/Returns Min        476.6261329041221
exploration/Actions Mean       0.0673957
exploration/Actions Std        0.60031086
exploration/Actions Max        0.99998105
exploration/Actions Min        -0.99994826
exploration/Num Paths          10
exploration/Average Returns    478.2279305000131
evaluation/num steps total     2185000
evaluation/num paths total     4370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9589147006889609
evaluation/Rewards Std         0.051827173111011864
evaluation/Rewards Max         0.9788884494190522
evaluation/Rewards Min         0.49154235061237395
evaluation/Returns Mean        479.45735034448046
evaluation/Returns Std         1.7175966882352969
evaluation/Returns Max         481.0157189949733
evaluation/Returns Min         476.7182180446831
evaluation/ExplReturns Mean    479.45735034448046
evaluation/ExplReturns Std     1.7175966882352969
evaluation/ExplReturns Max     481.0157189949733
evaluation/ExplReturns Min     476.7182180446831
evaluation/Actions Mean        0.08982994
evaluation/Actions Std         0.52952343
evaluation/Actions Max         0.99956656
evaluation/Actions Min         -0.999461
evaluation/Num Paths           10
evaluation/Average Returns     479.45735034448046
time/data storing (s)          0.03170525189489126
time/evaluation sampling (s)   112.93926547467709
time/exploration sampling (s)  114.10252418741584
time/logging (s)               0.030603770166635513
time/saving (s)                0.014697757549583912
time/training (s)              9.005617487244308
time/epoch (s)                 236.12441392894834
time/total (s)                 102285.65998370573
Epoch                          436
-----------------------------  --------------------
2023-08-01 22:22:55.850328 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 437 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4111.25]
trainer/QF1 Loss               0.032646954
trainer/QF2 Loss               0.017934874
trainer/Policy Loss            -90.872665
trainer/Q1 Predictions Mean    103.768326
trainer/Q1 Predictions Std     1.9030067
trainer/Q1 Predictions Max     105.01475
trainer/Q1 Predictions Min     89.11671
trainer/Q2 Predictions Mean    103.85475
trainer/Q2 Predictions Std     1.9070587
trainer/Q2 Predictions Max     105.12912
trainer/Q2 Predictions Min     89.58836
trainer/Q Targets Mean         103.827225
trainer/Q Targets Std          1.9678674
trainer/Q Targets Max          105.19733
trainer/Q Targets Min          88.901955
trainer/Log Pis Mean           13.02009
trainer/Log Pis Std            8.321984
trainer/Log Pis Max            55.495884
trainer/Log Pis Min            -2.0854173
trainer/Policy mu Mean         0.2493153
trainer/Policy mu Std          1.622984
trainer/Policy mu Max          6.0646296
trainer/Policy mu Min          -6.2834415
trainer/Policy log std Mean    -0.6969297
trainer/Policy log std Std     0.28400427
trainer/Policy log std Max     0.48465812
trainer/Policy log std Min     -2.1465273
trainer/Alpha                  0.0014039411908015609
trainer/Alpha Loss             6.700516700744629
exploration/num steps total    2191000
exploration/num paths total    4382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.897806215629071
exploration/Rewards Std        0.10245009418132615
exploration/Rewards Max        0.97790935895129
exploration/Rewards Min        0.49406550422999196
exploration/Returns Mean       448.90310781453564
exploration/Returns Std        24.25676971357696
exploration/Returns Max        475.39541228698715
exploration/Returns Min        409.7534311997478
exploration/Actions Mean       0.071756124
exploration/Actions Std        0.6504456
exploration/Actions Max        0.99999976
exploration/Actions Min        -0.9999535
exploration/Num Paths          10
exploration/Average Returns    448.90310781453564
evaluation/num steps total     2190000
evaluation/num paths total     4380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9371220297784881
evaluation/Rewards Std         0.06821687639858673
evaluation/Rewards Max         0.9777172878810811
evaluation/Rewards Min         0.4931618899599631
evaluation/Returns Mean        468.56101488924406
evaluation/Returns Std         12.94714971865699
evaluation/Returns Max         475.654907792963
evaluation/Returns Min         431.1901789556907
evaluation/ExplReturns Mean    468.56101488924406
evaluation/ExplReturns Std     12.94714971865699
evaluation/ExplReturns Max     475.654907792963
evaluation/ExplReturns Min     431.1901789556907
evaluation/Actions Mean        0.07622027
evaluation/Actions Std         0.58833694
evaluation/Actions Max         0.9999859
evaluation/Actions Min         -0.99991274
evaluation/Num Paths           10
evaluation/Average Returns     468.56101488924406
time/data storing (s)          0.031583367846906185
time/evaluation sampling (s)   115.94623934477568
time/exploration sampling (s)  115.56994295213372
time/logging (s)               0.0304123405367136
time/saving (s)                0.010227598249912262
time/training (s)              9.606288462877274
time/epoch (s)                 241.1946940664202
time/total (s)                 102526.85721363593
Epoch                          437
-----------------------------  ---------------------
2023-08-01 22:26:50.878991 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 438 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4302.0815]
trainer/QF1 Loss               0.050456773
trainer/QF2 Loss               0.016175043
trainer/Policy Loss            -91.24127
trainer/Q1 Predictions Mean    103.56865
trainer/Q1 Predictions Std     2.598164
trainer/Q1 Predictions Max     105.046265
trainer/Q1 Predictions Min     75.560684
trainer/Q2 Predictions Mean    103.63205
trainer/Q2 Predictions Std     2.6358988
trainer/Q2 Predictions Max     104.89264
trainer/Q2 Predictions Min     73.64434
trainer/Q Targets Mean         103.69892
trainer/Q Targets Std          2.6338224
trainer/Q Targets Max          104.96652
trainer/Q Targets Min          73.930405
trainer/Log Pis Mean           12.433563
trainer/Log Pis Std            7.24393
trainer/Log Pis Max            38.259357
trainer/Log Pis Min            -5.290781
trainer/Policy mu Mean         0.12043797
trainer/Policy mu Std          1.6011299
trainer/Policy mu Max          5.715182
trainer/Policy mu Min          -5.055516
trainer/Policy log std Mean    -0.67831355
trainer/Policy log std Std     0.2722136
trainer/Policy log std Max     0.1860404
trainer/Policy log std Min     -2.064947
trainer/Alpha                  0.0014110107440501451
trainer/Alpha Loss             2.845688581466675
exploration/num steps total    2196000
exploration/num paths total    4392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9519500843927458
exploration/Rewards Std        0.05817637408267731
exploration/Rewards Max        0.9796806755205708
exploration/Rewards Min        0.4940084998941119
exploration/Returns Mean       475.97504219637267
exploration/Returns Std        2.141097851305412
exploration/Returns Max        478.93020838532703
exploration/Returns Min        471.8906593498953
exploration/Actions Mean       0.048661716
exploration/Actions Std        0.59692544
exploration/Actions Max        0.9999136
exploration/Actions Min        -0.99995154
exploration/Num Paths          10
exploration/Average Returns    475.97504219637267
evaluation/num steps total     2195000
evaluation/num paths total     4390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.955048324479988
evaluation/Rewards Std         0.0615562374453793
evaluation/Rewards Max         0.9796328815164724
evaluation/Rewards Min         0.49283419562574143
evaluation/Returns Mean        477.52416223999387
evaluation/Returns Std         2.8368909010297254
evaluation/Returns Max         480.8717730606656
evaluation/Returns Min         472.0322603995269
evaluation/ExplReturns Mean    477.52416223999387
evaluation/ExplReturns Std     2.8368909010297254
evaluation/ExplReturns Max     480.8717730606656
evaluation/ExplReturns Min     472.0322603995269
evaluation/Actions Mean        0.029054545
evaluation/Actions Std         0.4521614
evaluation/Actions Max         0.9989742
evaluation/Actions Min         -0.99892366
evaluation/Num Paths           10
evaluation/Average Returns     477.52416223999387
time/data storing (s)          0.032210782170295715
time/evaluation sampling (s)   112.1441844869405
time/exploration sampling (s)  113.15907207131386
time/logging (s)               0.03051457740366459
time/saving (s)                0.010275332257151604
time/training (s)              9.646307836286724
time/epoch (s)                 235.0225650863722
time/total (s)                 102761.8823096333
Epoch                          438
-----------------------------  ---------------------
2023-08-01 22:30:46.187061 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 439 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4251.0894]
trainer/QF1 Loss               0.030728849
trainer/QF2 Loss               0.030175947
trainer/Policy Loss            -90.4954
trainer/Q1 Predictions Mean    103.33573
trainer/Q1 Predictions Std     3.0592663
trainer/Q1 Predictions Max     105.79774
trainer/Q1 Predictions Min     73.40083
trainer/Q2 Predictions Mean    103.383026
trainer/Q2 Predictions Std     3.0081904
trainer/Q2 Predictions Max     105.84942
trainer/Q2 Predictions Min     74.445175
trainer/Q Targets Mean         103.323364
trainer/Q Targets Std          3.0258408
trainer/Q Targets Max          105.79582
trainer/Q Targets Min          74.59788
trainer/Log Pis Mean           12.953473
trainer/Log Pis Std            10.302022
trainer/Log Pis Max            73.05707
trainer/Log Pis Min            -5.40617
trainer/Policy mu Mean         0.15265378
trainer/Policy mu Std          1.6868591
trainer/Policy mu Max          10.05375
trainer/Policy mu Min          -6.653843
trainer/Policy log std Mean    -0.6881072
trainer/Policy log std Std     0.2814046
trainer/Policy log std Max     1.0691934
trainer/Policy log std Min     -2.1242743
trainer/Alpha                  0.0013792630052194
trainer/Alpha Loss             6.279943943023682
exploration/num steps total    2201000
exploration/num paths total    4402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9592476862430198
exploration/Rewards Std        0.05076850945540213
exploration/Rewards Max        0.9794079721098568
exploration/Rewards Min        0.4891042141657123
exploration/Returns Mean       479.6238431215098
exploration/Returns Std        1.6422704987516046
exploration/Returns Max        481.23129860048584
exploration/Returns Min        475.1699164966141
exploration/Actions Mean       0.07252512
exploration/Actions Std        0.5975544
exploration/Actions Max        0.99984
exploration/Actions Min        -0.99999726
exploration/Num Paths          10
exploration/Average Returns    479.6238431215098
evaluation/num steps total     2200000
evaluation/num paths total     4400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9511289011097251
evaluation/Rewards Std         0.06485193056540296
evaluation/Rewards Max         0.9786522333964343
evaluation/Rewards Min         0.48555032294406264
evaluation/Returns Mean        475.5644505548627
evaluation/Returns Std         10.478498961248707
evaluation/Returns Max         480.41478199982697
evaluation/Returns Min         444.3478966506024
evaluation/ExplReturns Mean    475.5644505548627
evaluation/ExplReturns Std     10.478498961248707
evaluation/ExplReturns Max     480.41478199982697
evaluation/ExplReturns Min     444.3478966506024
evaluation/Actions Mean        0.07735075
evaluation/Actions Std         0.44509214
evaluation/Actions Max         0.999869
evaluation/Actions Min         -0.99994737
evaluation/Num Paths           10
evaluation/Average Returns     475.5644505548627
time/data storing (s)          0.03250428196042776
time/evaluation sampling (s)   112.04170192126185
time/exploration sampling (s)  113.4073049146682
time/logging (s)               0.031006012111902237
time/saving (s)                0.010653109289705753
time/training (s)              9.778948994353414
time/epoch (s)                 235.3021192336455
time/total (s)                 102997.18717686646
Epoch                          439
-----------------------------  --------------------
2023-08-01 22:34:39.462566 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 440 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4171.9673]
trainer/QF1 Loss               0.028042115
trainer/QF2 Loss               0.012980532
trainer/Policy Loss            -92.29672
trainer/Q1 Predictions Mean    103.53212
trainer/Q1 Predictions Std     1.7231176
trainer/Q1 Predictions Max     104.97879
trainer/Q1 Predictions Min     90.85165
trainer/Q2 Predictions Mean    103.55229
trainer/Q2 Predictions Std     1.7655296
trainer/Q2 Predictions Max     104.992615
trainer/Q2 Predictions Min     90.159904
trainer/Q Targets Mean         103.58156
trainer/Q Targets Std          1.7600802
trainer/Q Targets Max          105.042015
trainer/Q Targets Min          89.71925
trainer/Log Pis Mean           11.339458
trainer/Log Pis Std            7.6158266
trainer/Log Pis Max            44.790844
trainer/Log Pis Min            -2.2270212
trainer/Policy mu Mean         -0.08350294
trainer/Policy mu Std          1.5774137
trainer/Policy mu Max          5.213701
trainer/Policy mu Min          -5.624365
trainer/Policy log std Mean    -0.6693117
trainer/Policy log std Std     0.282182
trainer/Policy log std Max     0.1530273
trainer/Policy log std Min     -2.245621
trainer/Alpha                  0.0014245030470192432
trainer/Alpha Loss             -4.329138278961182
exploration/num steps total    2206000
exploration/num paths total    4412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.830585562011384
exploration/Rewards Std        0.14436747429106678
exploration/Rewards Max        0.9786970992655258
exploration/Rewards Min        0.48177586078131507
exploration/Returns Mean       415.292781005692
exploration/Returns Std        31.073094392715408
exploration/Returns Max        475.0187179355198
exploration/Returns Min        371.6466772666892
exploration/Actions Mean       0.044522285
exploration/Actions Std        0.6599841
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999997
exploration/Num Paths          10
exploration/Average Returns    415.292781005692
evaluation/num steps total     2205000
evaluation/num paths total     4410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8412486834675051
evaluation/Rewards Std         0.1365714857017314
evaluation/Rewards Max         0.9781200421186775
evaluation/Rewards Min         0.4880034520936605
evaluation/Returns Mean        420.62434173375266
evaluation/Returns Std         39.91013388604741
evaluation/Returns Max         475.1381996347052
evaluation/Returns Min         370.47643897636874
evaluation/ExplReturns Mean    420.62434173375266
evaluation/ExplReturns Std     39.91013388604741
evaluation/ExplReturns Max     475.1381996347052
evaluation/ExplReturns Min     370.47643897636874
evaluation/Actions Mean        0.04958817
evaluation/Actions Std         0.58288074
evaluation/Actions Max         0.99999815
evaluation/Actions Min         -0.9999989
evaluation/Num Paths           10
evaluation/Average Returns     420.62434173375266
time/data storing (s)          0.03220053389668465
time/evaluation sampling (s)   111.74103191774338
time/exploration sampling (s)  111.8407320631668
time/logging (s)               0.030987930484116077
time/saving (s)                0.012952538207173347
time/training (s)              9.611370996572077
time/epoch (s)                 233.26927598007023
time/total (s)                 103230.45892266836
Epoch                          440
-----------------------------  ---------------------
2023-08-01 22:38:32.531515 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 441 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4383.963]
trainer/QF1 Loss               0.027969806
trainer/QF2 Loss               0.014539946
trainer/Policy Loss            -93.15955
trainer/Q1 Predictions Mean    103.46806
trainer/Q1 Predictions Std     1.8730172
trainer/Q1 Predictions Max     104.83421
trainer/Q1 Predictions Min     80.416336
trainer/Q2 Predictions Mean    103.5067
trainer/Q2 Predictions Std     1.8797646
trainer/Q2 Predictions Max     104.90624
trainer/Q2 Predictions Min     80.483765
trainer/Q Targets Mean         103.537766
trainer/Q Targets Std          1.880138
trainer/Q Targets Max          104.98506
trainer/Q Targets Min          80.24018
trainer/Log Pis Mean           10.408805
trainer/Log Pis Std            7.372025
trainer/Log Pis Max            35.01581
trainer/Log Pis Min            -3.3480008
trainer/Policy mu Mean         0.044626106
trainer/Policy mu Std          1.5263087
trainer/Policy mu Max          4.9724727
trainer/Policy mu Min          -5.8822594
trainer/Policy log std Mean    -0.6909566
trainer/Policy log std Std     0.25889638
trainer/Policy log std Max     0.10608497
trainer/Policy log std Min     -2.1779215
trainer/Alpha                  0.0014898596564307809
trainer/Alpha Loss             -10.356977462768555
exploration/num steps total    2211000
exploration/num paths total    4422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9122921798893054
exploration/Rewards Std        0.09435890911377405
exploration/Rewards Max        0.9775897658955421
exploration/Rewards Min        0.48576847839473036
exploration/Returns Mean       456.1460899446527
exploration/Returns Std        24.659444480839248
exploration/Returns Max        477.2932449979733
exploration/Returns Min        398.62037838323783
exploration/Actions Mean       0.05013033
exploration/Actions Std        0.6138669
exploration/Actions Max        0.9999288
exploration/Actions Min        -0.9999044
exploration/Num Paths          10
exploration/Average Returns    456.1460899446527
evaluation/num steps total     2210000
evaluation/num paths total     4420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9540097770970871
evaluation/Rewards Std         0.049585488631335904
evaluation/Rewards Max         0.9711575567656819
evaluation/Rewards Min         0.4890192175152853
evaluation/Returns Mean        477.0048885485436
evaluation/Returns Std         0.4830971900590154
evaluation/Returns Max         477.81350754816305
evaluation/Returns Min         476.2605137226585
evaluation/ExplReturns Mean    477.0048885485436
evaluation/ExplReturns Std     0.4830971900590154
evaluation/ExplReturns Max     477.81350754816305
evaluation/ExplReturns Min     476.2605137226585
evaluation/Actions Mean        0.04284811
evaluation/Actions Std         0.435386
evaluation/Actions Max         0.99894893
evaluation/Actions Min         -0.9985447
evaluation/Num Paths           10
evaluation/Average Returns     477.0048885485436
time/data storing (s)          0.03206510189920664
time/evaluation sampling (s)   111.44777494948357
time/exploration sampling (s)  112.46444503497332
time/logging (s)               0.030638562515378
time/saving (s)                0.010468777269124985
time/training (s)              9.077074048109353
time/epoch (s)                 233.06246647424996
time/total (s)                 103463.52384811919
Epoch                          441
-----------------------------  ---------------------
2023-08-01 22:42:28.782622 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 442 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4321.1304]
trainer/QF1 Loss               0.030990513
trainer/QF2 Loss               0.025355395
trainer/Policy Loss            -91.83249
trainer/Q1 Predictions Mean    103.4938
trainer/Q1 Predictions Std     2.1273625
trainer/Q1 Predictions Max     106.28517
trainer/Q1 Predictions Min     85.9335
trainer/Q2 Predictions Mean    103.332016
trainer/Q2 Predictions Std     2.1032884
trainer/Q2 Predictions Max     105.99749
trainer/Q2 Predictions Min     85.64704
trainer/Q Targets Mean         103.42151
trainer/Q Targets Std          2.1014638
trainer/Q Targets Max          105.79637
trainer/Q Targets Min          86.28851
trainer/Log Pis Mean           11.6416445
trainer/Log Pis Std            7.877754
trainer/Log Pis Max            63.97062
trainer/Log Pis Min            -6.52454
trainer/Policy mu Mean         -0.052519906
trainer/Policy mu Std          1.6085356
trainer/Policy mu Max          8.686789
trainer/Policy mu Min          -6.55701
trainer/Policy log std Mean    -0.67225665
trainer/Policy log std Std     0.26861525
trainer/Policy log std Max     1.0903143
trainer/Policy log std Min     -2.0682964
trainer/Alpha                  0.0015634972369298339
trainer/Alpha Loss             -2.315345287322998
exploration/num steps total    2216000
exploration/num paths total    4432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7843222402479689
exploration/Rewards Std        0.08599542975816389
exploration/Rewards Max        0.9792680401331277
exploration/Rewards Min        0.4945941282929526
exploration/Returns Mean       392.16112012398446
exploration/Returns Std        3.630581026030597
exploration/Returns Max        399.3609017256222
exploration/Returns Min        385.55329424179286
exploration/Actions Mean       0.09238104
exploration/Actions Std        0.6556829
exploration/Actions Max        0.999983
exploration/Actions Min        -0.9999846
exploration/Num Paths          10
exploration/Average Returns    392.16112012398446
evaluation/num steps total     2215000
evaluation/num paths total     4430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7862671995365956
evaluation/Rewards Std         0.08965988162794458
evaluation/Rewards Max         0.9769517509074283
evaluation/Rewards Min         0.48846420193717005
evaluation/Returns Mean        393.1335997682978
evaluation/Returns Std         3.807839749655621
evaluation/Returns Max         399.3324797127923
evaluation/Returns Min         388.47791542586845
evaluation/ExplReturns Mean    393.1335997682978
evaluation/ExplReturns Std     3.807839749655621
evaluation/ExplReturns Max     399.3324797127923
evaluation/ExplReturns Min     388.47791542586845
evaluation/Actions Mean        0.083156995
evaluation/Actions Std         0.6399346
evaluation/Actions Max         0.9997223
evaluation/Actions Min         -0.99983716
evaluation/Num Paths           10
evaluation/Average Returns     393.1335997682978
time/data storing (s)          0.03197401575744152
time/evaluation sampling (s)   112.95544073544443
time/exploration sampling (s)  113.5432103537023
time/logging (s)               0.03096350096166134
time/saving (s)                0.012974259443581104
time/training (s)              9.670493930578232
time/epoch (s)                 236.24505679588765
time/total (s)                 103699.77152311243
Epoch                          442
-----------------------------  ---------------------
2023-08-01 22:46:22.984356 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 443 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4314.148]
trainer/QF1 Loss               0.026084604
trainer/QF2 Loss               0.036808997
trainer/Policy Loss            -90.63432
trainer/Q1 Predictions Mean    103.076614
trainer/Q1 Predictions Std     2.6469479
trainer/Q1 Predictions Max     104.97931
trainer/Q1 Predictions Min     74.98589
trainer/Q2 Predictions Mean    103.03453
trainer/Q2 Predictions Std     2.6496158
trainer/Q2 Predictions Max     104.90156
trainer/Q2 Predictions Min     75.1402
trainer/Q Targets Mean         103.08861
trainer/Q Targets Std          2.6716232
trainer/Q Targets Max          104.97117
trainer/Q Targets Min          75.448006
trainer/Log Pis Mean           12.515831
trainer/Log Pis Std            9.231678
trainer/Log Pis Max            70.19352
trainer/Log Pis Min            -1.4736989
trainer/Policy mu Mean         0.001446755
trainer/Policy mu Std          1.6504074
trainer/Policy mu Max          7.2125654
trainer/Policy mu Min          -8.824883
trainer/Policy log std Mean    -0.7071435
trainer/Policy log std Std     0.26936036
trainer/Policy log std Max     0.13345146
trainer/Policy log std Min     -2.0538628
trainer/Alpha                  0.0015081054298207164
trainer/Alpha Loss             3.351365566253662
exploration/num steps total    2221000
exploration/num paths total    4442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9524057506018729
exploration/Rewards Std        0.052981281313564436
exploration/Rewards Max        0.9783631012923835
exploration/Rewards Min        0.49480631298314715
exploration/Returns Mean       476.20287530093657
exploration/Returns Std        1.0327510086438088
exploration/Returns Max        477.62812744547995
exploration/Returns Min        474.31779545042826
exploration/Actions Mean       0.004557079
exploration/Actions Std        0.6466961
exploration/Actions Max        0.9999493
exploration/Actions Min        -0.9999984
exploration/Num Paths          10
exploration/Average Returns    476.20287530093657
evaluation/num steps total     2220000
evaluation/num paths total     4440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.941344864145644
evaluation/Rewards Std         0.05052759837632276
evaluation/Rewards Max         0.9752044892468494
evaluation/Rewards Min         0.4884288962425867
evaluation/Returns Mean        470.672432072822
evaluation/Returns Std         2.9378041185779593
evaluation/Returns Max         476.58500818850365
evaluation/Returns Min         467.9286351469426
evaluation/ExplReturns Mean    470.672432072822
evaluation/ExplReturns Std     2.9378041185779593
evaluation/ExplReturns Max     476.58500818850365
evaluation/ExplReturns Min     467.9286351469426
evaluation/Actions Mean        -0.11173554
evaluation/Actions Std         0.53412056
evaluation/Actions Max         0.99976015
evaluation/Actions Min         -0.9999923
evaluation/Num Paths           10
evaluation/Average Returns     470.672432072822
time/data storing (s)          0.03244996536523104
time/evaluation sampling (s)   111.70472036767751
time/exploration sampling (s)  112.97076242696494
time/logging (s)               0.030846943147480488
time/saving (s)                0.011636641807854176
time/training (s)              9.444975142367184
time/epoch (s)                 234.1953914873302
time/total (s)                 103933.96939042024
Epoch                          443
-----------------------------  ---------------------
2023-08-01 22:50:15.968297 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 444 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4315.2866]
trainer/QF1 Loss               0.023989039
trainer/QF2 Loss               0.023329725
trainer/Policy Loss            -91.399475
trainer/Q1 Predictions Mean    103.13054
trainer/Q1 Predictions Std     2.5075269
trainer/Q1 Predictions Max     105.35117
trainer/Q1 Predictions Min     73.82772
trainer/Q2 Predictions Mean    103.08917
trainer/Q2 Predictions Std     2.52262
trainer/Q2 Predictions Max     105.11514
trainer/Q2 Predictions Min     73.201935
trainer/Q Targets Mean         103.099655
trainer/Q Targets Std          2.4636674
trainer/Q Targets Max          105.42018
trainer/Q Targets Min          74.07425
trainer/Log Pis Mean           11.799081
trainer/Log Pis Std            8.832613
trainer/Log Pis Max            78.14967
trainer/Log Pis Min            -3.937684
trainer/Policy mu Mean         -0.046004135
trainer/Policy mu Std          1.5731373
trainer/Policy mu Max          5.9590845
trainer/Policy mu Min          -7.1089478
trainer/Policy log std Mean    -0.7222574
trainer/Policy log std Std     0.28421983
trainer/Policy log std Max     0.26495558
trainer/Policy log std Min     -1.8155762
trainer/Alpha                  0.001482479041442275
trainer/Alpha Loss             -1.3087924718856812
exploration/num steps total    2226000
exploration/num paths total    4452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557149390789509
exploration/Rewards Std        0.04881375331279054
exploration/Rewards Max        0.9796486253236765
exploration/Rewards Min        0.4872040111919604
exploration/Returns Mean       477.85746953947546
exploration/Returns Std        1.0063126725772507
exploration/Returns Max        479.25563150062345
exploration/Returns Min        475.9546454740639
exploration/Actions Mean       0.03972542
exploration/Actions Std        0.5710077
exploration/Actions Max        0.9998097
exploration/Actions Min        -0.99993914
exploration/Num Paths          10
exploration/Average Returns    477.85746953947546
evaluation/num steps total     2225000
evaluation/num paths total     4450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9450752251052134
evaluation/Rewards Std         0.04779833211939574
evaluation/Rewards Max         0.9741960851450178
evaluation/Rewards Min         0.4951439930048911
evaluation/Returns Mean        472.5376125526067
evaluation/Returns Std         1.1634529779937242
evaluation/Returns Max         474.5504399202483
evaluation/Returns Min         469.89976131667294
evaluation/ExplReturns Mean    472.5376125526067
evaluation/ExplReturns Std     1.1634529779937242
evaluation/ExplReturns Max     474.5504399202483
evaluation/ExplReturns Min     469.89976131667294
evaluation/Actions Mean        -0.13276234
evaluation/Actions Std         0.49575096
evaluation/Actions Max         0.9998344
evaluation/Actions Min         -0.9994182
evaluation/Num Paths           10
evaluation/Average Returns     472.5376125526067
time/data storing (s)          0.03231279458850622
time/evaluation sampling (s)   111.24104168452322
time/exploration sampling (s)  111.92420578934252
time/logging (s)               0.030415887013077736
time/saving (s)                0.011421346105635166
time/training (s)              9.737941211089492
time/epoch (s)                 232.97733871266246
time/total (s)                 104166.94917917624
Epoch                          444
-----------------------------  --------------------
2023-08-01 22:54:10.582159 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 445 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4317.246]
trainer/QF1 Loss               0.050167616
trainer/QF2 Loss               0.13183255
trainer/Policy Loss            -92.05737
trainer/Q1 Predictions Mean    102.970276
trainer/Q1 Predictions Std     2.913066
trainer/Q1 Predictions Max     105.13341
trainer/Q1 Predictions Min     75.5707
trainer/Q2 Predictions Mean    103.140175
trainer/Q2 Predictions Std     2.8276951
trainer/Q2 Predictions Max     105.04293
trainer/Q2 Predictions Min     78.29179
trainer/Q Targets Mean         102.91884
trainer/Q Targets Std          2.9886377
trainer/Q Targets Max          105.04786
trainer/Q Targets Min          75.55414
trainer/Log Pis Mean           11.023867
trainer/Log Pis Std            7.7773013
trainer/Log Pis Max            66.89165
trainer/Log Pis Min            -4.1819205
trainer/Policy mu Mean         -0.10678458
trainer/Policy mu Std          1.5429329
trainer/Policy mu Max          5.430735
trainer/Policy mu Min          -6.8185368
trainer/Policy log std Mean    -0.6936448
trainer/Policy log std Std     0.2951186
trainer/Policy log std Max     0.071487166
trainer/Policy log std Min     -2.2795205
trainer/Alpha                  0.00152914272621274
trainer/Alpha Loss             -6.32832145690918
exploration/num steps total    2231000
exploration/num paths total    4462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9570731383933431
exploration/Rewards Std        0.04811168962938577
exploration/Rewards Max        0.9789657529876092
exploration/Rewards Min        0.48329915980008525
exploration/Returns Mean       478.53656919667145
exploration/Returns Std        2.1203001469378067
exploration/Returns Max        480.98903821585606
exploration/Returns Min        474.11716188410827
exploration/Actions Mean       -0.02202825
exploration/Actions Std        0.5862225
exploration/Actions Max        0.99975395
exploration/Actions Min        -0.9999611
exploration/Num Paths          10
exploration/Average Returns    478.53656919667145
evaluation/num steps total     2230000
evaluation/num paths total     4460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9527712835347515
evaluation/Rewards Std         0.048832028573691066
evaluation/Rewards Max         0.9790754114498004
evaluation/Rewards Min         0.48804674391434805
evaluation/Returns Mean        476.38564176737583
evaluation/Returns Std         4.305448627416125
evaluation/Returns Max         481.258979985971
evaluation/Returns Min         470.9598123485261
evaluation/ExplReturns Mean    476.38564176737583
evaluation/ExplReturns Std     4.305448627416125
evaluation/ExplReturns Max     481.258979985971
evaluation/ExplReturns Min     470.9598123485261
evaluation/Actions Mean        -0.057528574
evaluation/Actions Std         0.48590183
evaluation/Actions Max         0.9988005
evaluation/Actions Min         -0.9997338
evaluation/Num Paths           10
evaluation/Average Returns     476.38564176737583
time/data storing (s)          0.032627605833113194
time/evaluation sampling (s)   112.6188978832215
time/exploration sampling (s)  112.24642653763294
time/logging (s)               0.030968564562499523
time/saving (s)                0.012061629444360733
time/training (s)              9.667093640193343
time/epoch (s)                 234.60807586088777
time/total (s)                 104401.55978872627
Epoch                          445
-----------------------------  --------------------
2023-08-01 22:58:06.912577 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 446 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4343.803]
trainer/QF1 Loss               0.015751567
trainer/QF2 Loss               0.019768156
trainer/Policy Loss            -91.33582
trainer/Q1 Predictions Mean    103.015045
trainer/Q1 Predictions Std     2.019449
trainer/Q1 Predictions Max     105.243645
trainer/Q1 Predictions Min     86.2472
trainer/Q2 Predictions Mean    103.00195
trainer/Q2 Predictions Std     1.9819869
trainer/Q2 Predictions Max     105.1632
trainer/Q2 Predictions Min     86.06275
trainer/Q Targets Mean         103.03275
trainer/Q Targets Std          1.9876167
trainer/Q Targets Max          105.128395
trainer/Q Targets Min          86.754974
trainer/Log Pis Mean           11.758807
trainer/Log Pis Std            9.042067
trainer/Log Pis Max            54.887566
trainer/Log Pis Min            -5.1477556
trainer/Policy mu Mean         -0.092576325
trainer/Policy mu Std          1.5945318
trainer/Policy mu Max          6.9546375
trainer/Policy mu Min          -4.6834254
trainer/Policy log std Mean    -0.6996064
trainer/Policy log std Std     0.2792159
trainer/Policy log std Max     0.112179816
trainer/Policy log std Min     -1.7325875
trainer/Alpha                  0.0014800196513533592
trainer/Alpha Loss             -1.5715664625167847
exploration/num steps total    2236000
exploration/num paths total    4472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9571498614499602
exploration/Rewards Std        0.05368646251631147
exploration/Rewards Max        0.97855944254752
exploration/Rewards Min        0.48816591117922936
exploration/Returns Mean       478.57493072497994
exploration/Returns Std        1.6233551504815127
exploration/Returns Max        480.38040866560755
exploration/Returns Min        475.41829415549745
exploration/Actions Mean       0.1287047
exploration/Actions Std        0.6845921
exploration/Actions Max        0.9998996
exploration/Actions Min        -0.9999935
exploration/Num Paths          10
exploration/Average Returns    478.57493072497994
evaluation/num steps total     2235000
evaluation/num paths total     4470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9568879383044605
evaluation/Rewards Std         0.0493086277516461
evaluation/Rewards Max         0.9786680718840014
evaluation/Rewards Min         0.4888791874580891
evaluation/Returns Mean        478.44396915223035
evaluation/Returns Std         0.8073775291621553
evaluation/Returns Max         480.12959112463375
evaluation/Returns Min         477.1476380849528
evaluation/ExplReturns Mean    478.44396915223035
evaluation/ExplReturns Std     0.8073775291621553
evaluation/ExplReturns Max     480.12959112463375
evaluation/ExplReturns Min     477.1476380849528
evaluation/Actions Mean        0.08830692
evaluation/Actions Std         0.6307429
evaluation/Actions Max         0.99935585
evaluation/Actions Min         -0.99958265
evaluation/Num Paths           10
evaluation/Average Returns     478.44396915223035
time/data storing (s)          0.03243269398808479
time/evaluation sampling (s)   112.13318393751979
time/exploration sampling (s)  114.58490995690227
time/logging (s)               0.030541974119842052
time/saving (s)                0.01129363663494587
time/training (s)              9.531485294923186
time/epoch (s)                 236.3238474940881
time/total (s)                 104637.88606073707
Epoch                          446
-----------------------------  ---------------------
2023-08-01 23:02:01.008302 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 447 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4371.3486]
trainer/QF1 Loss               0.06447521
trainer/QF2 Loss               0.030526252
trainer/Policy Loss            -90.721306
trainer/Q1 Predictions Mean    102.88898
trainer/Q1 Predictions Std     2.291534
trainer/Q1 Predictions Max     104.85406
trainer/Q1 Predictions Min     80.47553
trainer/Q2 Predictions Mean    102.92816
trainer/Q2 Predictions Std     2.199889
trainer/Q2 Predictions Max     104.89669
trainer/Q2 Predictions Min     81.68826
trainer/Q Targets Mean         102.94534
trainer/Q Targets Std          2.168422
trainer/Q Targets Max          105.09077
trainer/Q Targets Min          82.85489
trainer/Log Pis Mean           12.248013
trainer/Log Pis Std            9.211832
trainer/Log Pis Max            64.225464
trainer/Log Pis Min            -7.35733
trainer/Policy mu Mean         -0.19181418
trainer/Policy mu Std          1.668215
trainer/Policy mu Max          14.206071
trainer/Policy mu Min          -5.57337
trainer/Policy log std Mean    -0.7089003
trainer/Policy log std Std     0.29693675
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -1.9461465
trainer/Alpha                  0.001428514951840043
trainer/Alpha Loss             1.6247258186340332
exploration/num steps total    2241000
exploration/num paths total    4482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9571374197962974
exploration/Rewards Std        0.052092993569114246
exploration/Rewards Max        0.9791459620472196
exploration/Rewards Min        0.4767534890456109
exploration/Returns Mean       478.56870989814854
exploration/Returns Std        0.9054981821073992
exploration/Returns Max        480.0698322947201
exploration/Returns Min        477.2711741787317
exploration/Actions Mean       0.042505942
exploration/Actions Std        0.5589387
exploration/Actions Max        0.9997883
exploration/Actions Min        -0.9999766
exploration/Num Paths          10
exploration/Average Returns    478.56870989814854
evaluation/num steps total     2240000
evaluation/num paths total     4480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.952022584419062
evaluation/Rewards Std         0.052179058327974884
evaluation/Rewards Max         0.9779969041947313
evaluation/Rewards Min         0.4935618584897153
evaluation/Returns Mean        476.011292209531
evaluation/Returns Std         0.7409311240387966
evaluation/Returns Max         477.2580005464869
evaluation/Returns Min         474.68802729603027
evaluation/ExplReturns Mean    476.011292209531
evaluation/ExplReturns Std     0.7409311240387966
evaluation/ExplReturns Max     477.2580005464869
evaluation/ExplReturns Min     474.68802729603027
evaluation/Actions Mean        0.044186298
evaluation/Actions Std         0.4033011
evaluation/Actions Max         0.9985203
evaluation/Actions Min         -0.9995294
evaluation/Num Paths           10
evaluation/Average Returns     476.011292209531
time/data storing (s)          0.032238769344985485
time/evaluation sampling (s)   112.87010109517723
time/exploration sampling (s)  111.43922405783087
time/logging (s)               0.030837303027510643
time/saving (s)                0.012505002319812775
time/training (s)              9.70482377987355
time/epoch (s)                 234.08973000757396
time/total (s)                 104871.97835133597
Epoch                          447
-----------------------------  --------------------
2023-08-01 23:05:56.968415 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 448 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4250.158]
trainer/QF1 Loss               0.05234792
trainer/QF2 Loss               0.038059846
trainer/Policy Loss            -90.90666
trainer/Q1 Predictions Mean    102.73495
trainer/Q1 Predictions Std     2.9287362
trainer/Q1 Predictions Max     105.12777
trainer/Q1 Predictions Min     68.17232
trainer/Q2 Predictions Mean    102.82771
trainer/Q2 Predictions Std     2.9411628
trainer/Q2 Predictions Max     105.00499
trainer/Q2 Predictions Min     67.7447
trainer/Q Targets Mean         102.8281
trainer/Q Targets Std          2.9032617
trainer/Q Targets Max          105.16688
trainer/Q Targets Min          69.02998
trainer/Log Pis Mean           11.951014
trainer/Log Pis Std            8.601021
trainer/Log Pis Max            64.12072
trainer/Log Pis Min            -2.5405889
trainer/Policy mu Mean         -0.064123936
trainer/Policy mu Std          1.6035428
trainer/Policy mu Max          7.8486104
trainer/Policy mu Min          -8.765039
trainer/Policy log std Mean    -0.7127717
trainer/Policy log std Std     0.2953647
trainer/Policy log std Max     0.8489971
trainer/Policy log std Min     -2.0743356
trainer/Alpha                  0.001399031956680119
trainer/Alpha Loss             -0.3219393193721771
exploration/num steps total    2246000
exploration/num paths total    4492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9480256606612304
exploration/Rewards Std        0.06570338523121669
exploration/Rewards Max        0.9797433034610317
exploration/Rewards Min        0.49517156548582064
exploration/Returns Mean       474.01283033061526
exploration/Returns Std        4.212740855326119
exploration/Returns Max        479.28904143096685
exploration/Returns Min        466.1210016688947
exploration/Actions Mean       0.04119524
exploration/Actions Std        0.6635767
exploration/Actions Max        0.9999312
exploration/Actions Min        -0.9999981
exploration/Num Paths          10
exploration/Average Returns    474.01283033061526
evaluation/num steps total     2245000
evaluation/num paths total     4490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9524237187941015
evaluation/Rewards Std         0.05714874222930291
evaluation/Rewards Max         0.9793781606227556
evaluation/Rewards Min         0.48842664716993967
evaluation/Returns Mean        476.21185939705066
evaluation/Returns Std         1.322562019423576
evaluation/Returns Max         478.23391054944506
evaluation/Returns Min         473.1373459360728
evaluation/ExplReturns Mean    476.21185939705066
evaluation/ExplReturns Std     1.322562019423576
evaluation/ExplReturns Max     478.23391054944506
evaluation/ExplReturns Min     473.1373459360728
evaluation/Actions Mean        0.030868914
evaluation/Actions Std         0.57140285
evaluation/Actions Max         0.9994452
evaluation/Actions Min         -0.9997936
evaluation/Num Paths           10
evaluation/Average Returns     476.21185939705066
time/data storing (s)          0.03184566926211119
time/evaluation sampling (s)   112.63099001627415
time/exploration sampling (s)  113.6191628659144
time/logging (s)               0.030685978941619396
time/saving (s)                0.012401917949318886
time/training (s)              9.628566476516426
time/epoch (s)                 235.95365292485803
time/total (s)                 105107.93454606459
Epoch                          448
-----------------------------  --------------------
2023-08-01 23:09:52.023923 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 449 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4315.144]
trainer/QF1 Loss               0.038941838
trainer/QF2 Loss               0.045670584
trainer/Policy Loss            -89.71271
trainer/Q1 Predictions Mean    102.55826
trainer/Q1 Predictions Std     3.305082
trainer/Q1 Predictions Max     105.51314
trainer/Q1 Predictions Min     70.622444
trainer/Q2 Predictions Mean    102.54995
trainer/Q2 Predictions Std     3.3304052
trainer/Q2 Predictions Max     105.382225
trainer/Q2 Predictions Min     69.69112
trainer/Q Targets Mean         102.55357
trainer/Q Targets Std          3.3159134
trainer/Q Targets Max          105.434395
trainer/Q Targets Min          70.69535
trainer/Log Pis Mean           12.923174
trainer/Log Pis Std            9.172605
trainer/Log Pis Max            67.122025
trainer/Log Pis Min            -5.5072813
trainer/Policy mu Mean         -0.114427686
trainer/Policy mu Std          1.652619
trainer/Policy mu Max          9.967174
trainer/Policy mu Min          -7.5283527
trainer/Policy log std Mean    -0.7162917
trainer/Policy log std Std     0.2790663
trainer/Policy log std Max     0.3840596
trainer/Policy log std Min     -1.8952773
trainer/Alpha                  0.0013707088073715568
trainer/Alpha Loss             6.086101055145264
exploration/num steps total    2251000
exploration/num paths total    4502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9448784685344018
exploration/Rewards Std        0.0641252085889348
exploration/Rewards Max        0.9796894247353901
exploration/Rewards Min        0.4975154031755123
exploration/Returns Mean       472.439234267201
exploration/Returns Std        4.134637217434629
exploration/Returns Max        477.3024696977987
exploration/Returns Min        461.46514943360216
exploration/Actions Mean       0.044217575
exploration/Actions Std        0.5937206
exploration/Actions Max        0.99999964
exploration/Actions Min        -0.99994737
exploration/Num Paths          10
exploration/Average Returns    472.439234267201
evaluation/num steps total     2250000
evaluation/num paths total     4500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8963625112104652
evaluation/Rewards Std         0.16467879945929853
evaluation/Rewards Max         0.9710061992168498
evaluation/Rewards Min         0.23417465902952828
evaluation/Returns Mean        448.18125560523276
evaluation/Returns Std         72.67793009323701
evaluation/Returns Max         473.40190976049615
evaluation/Returns Min         230.17046503026185
evaluation/ExplReturns Mean    448.18125560523276
evaluation/ExplReturns Std     72.67793009323701
evaluation/ExplReturns Max     473.40190976049615
evaluation/ExplReturns Min     230.17046503026185
evaluation/Actions Mean        0.044749606
evaluation/Actions Std         0.4572662
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.9999974
evaluation/Num Paths           10
evaluation/Average Returns     448.18125560523276
time/data storing (s)          0.032264892011880875
time/evaluation sampling (s)   112.27657693810761
time/exploration sampling (s)  113.11468256544322
time/logging (s)               0.03093078453093767
time/saving (s)                0.012682706117630005
time/training (s)              9.582374927587807
time/epoch (s)                 235.04951281379908
time/total (s)                 105342.98651372362
Epoch                          449
-----------------------------  ---------------------
2023-08-01 23:13:50.037349 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 450 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4336.911]
trainer/QF1 Loss               0.026627999
trainer/QF2 Loss               0.020198638
trainer/Policy Loss            -90.505875
trainer/Q1 Predictions Mean    102.51814
trainer/Q1 Predictions Std     3.5510056
trainer/Q1 Predictions Max     105.04342
trainer/Q1 Predictions Min     68.85386
trainer/Q2 Predictions Mean    102.4792
trainer/Q2 Predictions Std     3.6414807
trainer/Q2 Predictions Max     105.0206
trainer/Q2 Predictions Min     67.83834
trainer/Q Targets Mean         102.45168
trainer/Q Targets Std          3.6153252
trainer/Q Targets Max          104.65285
trainer/Q Targets Min          68.038025
trainer/Log Pis Mean           12.05824
trainer/Log Pis Std            9.175558
trainer/Log Pis Max            59.073006
trainer/Log Pis Min            -3.2359986
trainer/Policy mu Mean         0.00035956377
trainer/Policy mu Std          1.6159924
trainer/Policy mu Max          5.609612
trainer/Policy mu Min          -9.609648
trainer/Policy log std Mean    -0.6885286
trainer/Policy log std Std     0.28228062
trainer/Policy log std Max     0.50975144
trainer/Policy log std Min     -2.2653491
trainer/Alpha                  0.0014219018630683422
trainer/Alpha Loss             0.3818056583404541
exploration/num steps total    2256000
exploration/num paths total    4512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.936658817714661
exploration/Rewards Std        0.08524837799013779
exploration/Rewards Max        0.9796386945079629
exploration/Rewards Min        0.49303899405497226
exploration/Returns Mean       468.3294088573304
exploration/Returns Std        14.034566512403678
exploration/Returns Max        482.1548336394088
exploration/Returns Min        442.39132812085
exploration/Actions Mean       0.04156167
exploration/Actions Std        0.65585524
exploration/Actions Max        0.9999982
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    468.3294088573304
evaluation/num steps total     2255000
evaluation/num paths total     4510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8906771800979215
evaluation/Rewards Std         0.11903138238873959
evaluation/Rewards Max         0.977553722724938
evaluation/Rewards Min         0.49237506448421664
evaluation/Returns Mean        445.33859004896055
evaluation/Returns Std         52.201874283671124
evaluation/Returns Max         483.4213610186789
evaluation/Returns Min         360.31543451611884
evaluation/ExplReturns Mean    445.33859004896055
evaluation/ExplReturns Std     52.201874283671124
evaluation/ExplReturns Max     483.4213610186789
evaluation/ExplReturns Min     360.31543451611884
evaluation/Actions Mean        0.04267341
evaluation/Actions Std         0.62231874
evaluation/Actions Max         0.9999802
evaluation/Actions Min         -0.99999946
evaluation/Num Paths           10
evaluation/Average Returns     445.33859004896055
time/data storing (s)          0.03206980600953102
time/evaluation sampling (s)   113.51901061274111
time/exploration sampling (s)  114.47537034656852
time/logging (s)               0.030658547766506672
time/saving (s)                0.010273262858390808
time/training (s)              9.939480066299438
time/epoch (s)                 238.0068626422435
time/total (s)                 105580.99589127488
Epoch                          450
-----------------------------  ---------------------
2023-08-01 23:17:41.260644 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 451 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4291.3296]
trainer/QF1 Loss               0.022250142
trainer/QF2 Loss               0.022518873
trainer/Policy Loss            -91.44653
trainer/Q1 Predictions Mean    102.704025
trainer/Q1 Predictions Std     2.199927
trainer/Q1 Predictions Max     104.47639
trainer/Q1 Predictions Min     73.4234
trainer/Q2 Predictions Mean    102.69299
trainer/Q2 Predictions Std     2.1700222
trainer/Q2 Predictions Max     104.38868
trainer/Q2 Predictions Min     73.98737
trainer/Q Targets Mean         102.78271
trainer/Q Targets Std          2.1954198
trainer/Q Targets Max          104.56832
trainer/Q Targets Min          73.53062
trainer/Log Pis Mean           11.318744
trainer/Log Pis Std            8.591877
trainer/Log Pis Max            45.328003
trainer/Log Pis Min            -8.2003975
trainer/Policy mu Mean         0.02645646
trainer/Policy mu Std          1.5999014
trainer/Policy mu Max          5.563552
trainer/Policy mu Min          -7.4672365
trainer/Policy log std Mean    -0.7110631
trainer/Policy log std Std     0.29151577
trainer/Policy log std Max     0.40890273
trainer/Policy log std Min     -1.9464952
trainer/Alpha                  0.0014170772628858685
trainer/Alpha Loss             -4.468386650085449
exploration/num steps total    2261000
exploration/num paths total    4522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9043119742333616
exploration/Rewards Std        0.11779030336705884
exploration/Rewards Max        0.979467849549034
exploration/Rewards Min        0.49135943257703185
exploration/Returns Mean       452.1559871166807
exploration/Returns Std        53.57956300992299
exploration/Returns Max        480.08304705593906
exploration/Returns Min        341.2228226875171
exploration/Actions Mean       0.05573359
exploration/Actions Std        0.61911994
exploration/Actions Max        0.9999905
exploration/Actions Min        -0.99998766
exploration/Num Paths          10
exploration/Average Returns    452.1559871166807
evaluation/num steps total     2260000
evaluation/num paths total     4520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9572479883845477
evaluation/Rewards Std         0.050490619730719194
evaluation/Rewards Max         0.9784932701208557
evaluation/Rewards Min         0.4933211757013816
evaluation/Returns Mean        478.6239941922737
evaluation/Returns Std         1.3130116257527111
evaluation/Returns Max         479.61817947357184
evaluation/Returns Min         475.49542838739575
evaluation/ExplReturns Mean    478.6239941922737
evaluation/ExplReturns Std     1.3130116257527111
evaluation/ExplReturns Max     479.61817947357184
evaluation/ExplReturns Min     475.49542838739575
evaluation/Actions Mean        0.021534294
evaluation/Actions Std         0.53089714
evaluation/Actions Max         0.9997308
evaluation/Actions Min         -0.999519
evaluation/Num Paths           10
evaluation/Average Returns     478.6239941922737
time/data storing (s)          0.032558487728238106
time/evaluation sampling (s)   110.28474315814674
time/exploration sampling (s)  111.22439770493656
time/logging (s)               0.031270090490579605
time/saving (s)                0.01295306347310543
time/training (s)              9.631544400006533
time/epoch (s)                 231.21746690478176
time/total (s)                 105812.21598761529
Epoch                          451
-----------------------------  ---------------------
2023-08-01 23:21:35.294213 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 452 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4079.619]
trainer/QF1 Loss               0.042188786
trainer/QF2 Loss               0.06410347
trainer/Policy Loss            -90.414986
trainer/Q1 Predictions Mean    102.6937
trainer/Q1 Predictions Std     2.6868885
trainer/Q1 Predictions Max     104.57127
trainer/Q1 Predictions Min     70.854996
trainer/Q2 Predictions Mean    102.741806
trainer/Q2 Predictions Std     2.6544557
trainer/Q2 Predictions Max     104.57434
trainer/Q2 Predictions Min     71.57527
trainer/Q Targets Mean         102.5414
trainer/Q Targets Std          2.7031298
trainer/Q Targets Max          104.48394
trainer/Q Targets Min          70.501465
trainer/Log Pis Mean           12.374501
trainer/Log Pis Std            9.064154
trainer/Log Pis Max            59.305527
trainer/Log Pis Min            -3.9750316
trainer/Policy mu Mean         0.06465072
trainer/Policy mu Std          1.6398436
trainer/Policy mu Max          7.0473785
trainer/Policy mu Min          -5.351219
trainer/Policy log std Mean    -0.71304387
trainer/Policy log std Std     0.26880288
trainer/Policy log std Max     0.5125578
trainer/Policy log std Min     -1.9077338
trainer/Alpha                  0.0013934440212324262
trainer/Alpha Loss             2.4627842903137207
exploration/num steps total    2266000
exploration/num paths total    4532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9162123259784457
exploration/Rewards Std        0.1010011338895994
exploration/Rewards Max        0.9793916450062579
exploration/Rewards Min        0.3671442463981592
exploration/Returns Mean       458.106162989223
exploration/Returns Std        16.842885804303553
exploration/Returns Max        480.99389918021507
exploration/Returns Min        417.15371466849933
exploration/Actions Mean       0.079612926
exploration/Actions Std        0.63554853
exploration/Actions Max        0.9999998
exploration/Actions Min        -0.99999696
exploration/Num Paths          10
exploration/Average Returns    458.106162989223
evaluation/num steps total     2265000
evaluation/num paths total     4530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9138666948276332
evaluation/Rewards Std         0.09852696550749421
evaluation/Rewards Max         0.9794097175998298
evaluation/Rewards Min         0.4989876374336813
evaluation/Returns Mean        456.9333474138167
evaluation/Returns Std         33.32932753860288
evaluation/Returns Max         479.4670351387069
evaluation/Returns Min         388.8219917237701
evaluation/ExplReturns Mean    456.9333474138167
evaluation/ExplReturns Std     33.32932753860288
evaluation/ExplReturns Max     479.4670351387069
evaluation/ExplReturns Min     388.8219917237701
evaluation/Actions Mean        0.09215521
evaluation/Actions Std         0.5820145
evaluation/Actions Max         0.9998929
evaluation/Actions Min         -0.9999268
evaluation/Num Paths           10
evaluation/Average Returns     456.9333474138167
time/data storing (s)          0.032338655553758144
time/evaluation sampling (s)   112.03836851287633
time/exploration sampling (s)  112.48910006694496
time/logging (s)               0.031217514537274837
time/saving (s)                0.010345072485506535
time/training (s)              9.425676694139838
time/epoch (s)                 234.02704651653767
time/total (s)                 106046.24569658563
Epoch                          452
-----------------------------  ---------------------
2023-08-01 23:25:30.905504 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 453 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3832.0889]
trainer/QF1 Loss               0.041081145
trainer/QF2 Loss               0.03429966
trainer/Policy Loss            -89.18058
trainer/Q1 Predictions Mean    102.31418
trainer/Q1 Predictions Std     3.4877658
trainer/Q1 Predictions Max     105.4448
trainer/Q1 Predictions Min     72.33581
trainer/Q2 Predictions Mean    102.36392
trainer/Q2 Predictions Std     3.4507203
trainer/Q2 Predictions Max     105.70124
trainer/Q2 Predictions Min     72.78454
trainer/Q Targets Mean         102.322876
trainer/Q Targets Std          3.384222
trainer/Q Targets Max          105.45255
trainer/Q Targets Min          72.78788
trainer/Log Pis Mean           13.244153
trainer/Log Pis Std            9.009171
trainer/Log Pis Max            47.766174
trainer/Log Pis Min            -2.9765174
trainer/Policy mu Mean         0.034574095
trainer/Policy mu Std          1.6874071
trainer/Policy mu Max          7.9245615
trainer/Policy mu Min          -5.6901383
trainer/Policy log std Mean    -0.7095812
trainer/Policy log std Std     0.288932
trainer/Policy log std Max     0.4723119
trainer/Policy log std Min     -2.2813835
trainer/Alpha                  0.0014327424578368664
trainer/Alpha Loss             8.147050857543945
exploration/num steps total    2271000
exploration/num paths total    4542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9561104615886666
exploration/Rewards Std        0.05288767381964242
exploration/Rewards Max        0.9798853081751764
exploration/Rewards Min        0.4877766669262741
exploration/Returns Mean       478.0552307943334
exploration/Returns Std        3.3851878515721143
exploration/Returns Max        480.83222413264
exploration/Returns Min        471.26372749955783
exploration/Actions Mean       0.04752602
exploration/Actions Std        0.6313108
exploration/Actions Max        0.999981
exploration/Actions Min        -0.9999551
exploration/Num Paths          10
exploration/Average Returns    478.0552307943334
evaluation/num steps total     2270000
evaluation/num paths total     4540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9435992009513102
evaluation/Rewards Std         0.07175706840471817
evaluation/Rewards Max         0.9791993154061167
evaluation/Rewards Min         0.49936628411136286
evaluation/Returns Mean        471.799600475655
evaluation/Returns Std         10.738735713889726
evaluation/Returns Max         480.008168314276
evaluation/Returns Min         447.66956736977346
evaluation/ExplReturns Mean    471.799600475655
evaluation/ExplReturns Std     10.738735713889726
evaluation/ExplReturns Max     480.008168314276
evaluation/ExplReturns Min     447.66956736977346
evaluation/Actions Mean        0.06154724
evaluation/Actions Std         0.58371407
evaluation/Actions Max         0.99998146
evaluation/Actions Min         -0.9996676
evaluation/Num Paths           10
evaluation/Average Returns     471.799600475655
time/data storing (s)          0.03248465992510319
time/evaluation sampling (s)   113.76779013499618
time/exploration sampling (s)  112.12253316957504
time/logging (s)               0.030375451780855656
time/saving (s)                0.012791306711733341
time/training (s)              9.63805241882801
time/epoch (s)                 235.6040271418169
time/total (s)                 106281.85233755223
Epoch                          453
-----------------------------  ---------------------
2023-08-01 23:29:23.872759 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 454 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4064.5588]
trainer/QF1 Loss               0.036155708
trainer/QF2 Loss               0.03422139
trainer/Policy Loss            -90.97055
trainer/Q1 Predictions Mean    102.47033
trainer/Q1 Predictions Std     2.9396036
trainer/Q1 Predictions Max     105.25081
trainer/Q1 Predictions Min     68.3801
trainer/Q2 Predictions Mean    102.36174
trainer/Q2 Predictions Std     2.9366734
trainer/Q2 Predictions Max     105.35307
trainer/Q2 Predictions Min     69.132324
trainer/Q Targets Mean         102.42401
trainer/Q Targets Std          2.940469
trainer/Q Targets Max          105.223236
trainer/Q Targets Min          69.035614
trainer/Log Pis Mean           11.507764
trainer/Log Pis Std            8.557041
trainer/Log Pis Max            43.4457
trainer/Log Pis Min            -5.726272
trainer/Policy mu Mean         0.068875924
trainer/Policy mu Std          1.594299
trainer/Policy mu Max          5.137729
trainer/Policy mu Min          -5.2021065
trainer/Policy log std Mean    -0.7380335
trainer/Policy log std Std     0.270102
trainer/Policy log std Max     0.26463357
trainer/Policy log std Min     -2.1508675
trainer/Alpha                  0.0014170906506478786
trainer/Alpha Loss             -3.2286934852600098
exploration/num steps total    2276000
exploration/num paths total    4552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8513800876554058
exploration/Rewards Std        0.1336122507618424
exploration/Rewards Max        0.979354896180257
exploration/Rewards Min        0.4891252821381924
exploration/Returns Mean       425.6900438277029
exploration/Returns Std        62.59923305357366
exploration/Returns Max        479.6737404160727
exploration/Returns Min        346.4192955711473
exploration/Actions Mean       -0.0040486287
exploration/Actions Std        0.6689663
exploration/Actions Max        0.9999961
exploration/Actions Min        -0.999999
exploration/Num Paths          10
exploration/Average Returns    425.6900438277029
evaluation/num steps total     2275000
evaluation/num paths total     4550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8589492408441424
evaluation/Rewards Std         0.13356692571275477
evaluation/Rewards Max         0.9797655324911905
evaluation/Rewards Min         0.4934636386371456
evaluation/Returns Mean        429.47462042207127
evaluation/Returns Std         63.03528843250496
evaluation/Returns Max         481.6623867919692
evaluation/Returns Min         351.1686869399427
evaluation/ExplReturns Mean    429.47462042207127
evaluation/ExplReturns Std     63.03528843250496
evaluation/ExplReturns Max     481.6623867919692
evaluation/ExplReturns Min     351.1686869399427
evaluation/Actions Mean        0.007886933
evaluation/Actions Std         0.597469
evaluation/Actions Max         0.9999995
evaluation/Actions Min         -0.9999997
evaluation/Num Paths           10
evaluation/Average Returns     429.47462042207127
time/data storing (s)          0.032448518089950085
time/evaluation sampling (s)   110.95103884395212
time/exploration sampling (s)  112.27030030917376
time/logging (s)               0.03057375457137823
time/saving (s)                0.01123537216335535
time/training (s)              9.665591053664684
time/epoch (s)                 232.96118785161525
time/total (s)                 106514.81604286749
Epoch                          454
-----------------------------  ---------------------
2023-08-01 23:33:20.096474 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 455 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4084.1433]
trainer/QF1 Loss               0.026519256
trainer/QF2 Loss               0.024020398
trainer/Policy Loss            -89.044075
trainer/Q1 Predictions Mean    102.059296
trainer/Q1 Predictions Std     3.7820587
trainer/Q1 Predictions Max     105.30016
trainer/Q1 Predictions Min     72.15459
trainer/Q2 Predictions Mean    102.11473
trainer/Q2 Predictions Std     3.7616932
trainer/Q2 Predictions Max     105.43292
trainer/Q2 Predictions Min     71.7928
trainer/Q Targets Mean         102.102585
trainer/Q Targets Std          3.7221394
trainer/Q Targets Max          105.2319
trainer/Q Targets Min          72.456215
trainer/Log Pis Mean           13.098408
trainer/Log Pis Std            11.082867
trainer/Log Pis Max            84.55554
trainer/Log Pis Min            -2.721312
trainer/Policy mu Mean         -0.020952761
trainer/Policy mu Std          1.7070055
trainer/Policy mu Max          8.178141
trainer/Policy mu Min          -7.803274
trainer/Policy log std Mean    -0.69284964
trainer/Policy log std Std     0.283045
trainer/Policy log std Max     0.79403114
trainer/Policy log std Min     -1.8664646
trainer/Alpha                  0.0014514842769131064
trainer/Alpha Loss             7.17842435836792
exploration/num steps total    2281000
exploration/num paths total    4562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9132120579145876
exploration/Rewards Std        0.10057884260784439
exploration/Rewards Max        0.978965216225355
exploration/Rewards Min        0.46721710165914515
exploration/Returns Mean       456.6060289572939
exploration/Returns Std        26.36195239087601
exploration/Returns Max        477.413480377388
exploration/Returns Min        391.0948644199304
exploration/Actions Mean       0.049488768
exploration/Actions Std        0.67263377
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    456.6060289572939
evaluation/num steps total     2280000
evaluation/num paths total     4560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8951479637133234
evaluation/Rewards Std         0.11403728541053709
evaluation/Rewards Max         0.9790592989330232
evaluation/Rewards Min         0.44137087093444116
evaluation/Returns Mean        447.5739818566617
evaluation/Returns Std         32.65674580610798
evaluation/Returns Max         478.57479931411706
evaluation/Returns Min         393.64652912872185
evaluation/ExplReturns Mean    447.5739818566617
evaluation/ExplReturns Std     32.65674580610798
evaluation/ExplReturns Max     478.57479931411706
evaluation/ExplReturns Min     393.64652912872185
evaluation/Actions Mean        0.07112247
evaluation/Actions Std         0.6246919
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     447.5739818566617
time/data storing (s)          0.03204521909356117
time/evaluation sampling (s)   113.33366995397955
time/exploration sampling (s)  113.12905118148774
time/logging (s)               0.030531800352036953
time/saving (s)                0.01248074509203434
time/training (s)              9.679632763378322
time/epoch (s)                 236.21741166338325
time/total (s)                 106751.03594521433
Epoch                          455
-----------------------------  ---------------------
2023-08-01 23:37:15.146313 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 456 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3939.2605]
trainer/QF1 Loss               0.031943046
trainer/QF2 Loss               0.029372532
trainer/Policy Loss            -89.97055
trainer/Q1 Predictions Mean    102.11373
trainer/Q1 Predictions Std     3.5185413
trainer/Q1 Predictions Max     104.96588
trainer/Q1 Predictions Min     71.47001
trainer/Q2 Predictions Mean    102.12943
trainer/Q2 Predictions Std     3.5377386
trainer/Q2 Predictions Max     104.928535
trainer/Q2 Predictions Min     71.27087
trainer/Q Targets Mean         102.07712
trainer/Q Targets Std          3.5207744
trainer/Q Targets Max          104.98959
trainer/Q Targets Min          71.37803
trainer/Log Pis Mean           12.235464
trainer/Log Pis Std            9.186576
trainer/Log Pis Max            53.495552
trainer/Log Pis Min            -2.0091631
trainer/Policy mu Mean         0.006916236
trainer/Policy mu Std          1.6201977
trainer/Policy mu Max          5.706809
trainer/Policy mu Min          -7.579958
trainer/Policy log std Mean    -0.70840025
trainer/Policy log std Std     0.27747968
trainer/Policy log std Max     0.4602195
trainer/Policy log std Min     -1.8714063
trainer/Alpha                  0.0014259390300139785
trainer/Alpha Loss             1.5429781675338745
exploration/num steps total    2286000
exploration/num paths total    4572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9581345806708071
exploration/Rewards Std        0.055492342798604516
exploration/Rewards Max        0.979468028009022
exploration/Rewards Min        0.48792552697719177
exploration/Returns Mean       479.0672903354037
exploration/Returns Std        6.189774347863883
exploration/Returns Max        482.04421739065754
exploration/Returns Min        460.6003937378254
exploration/Actions Mean       0.09436946
exploration/Actions Std        0.6050263
exploration/Actions Max        0.99999416
exploration/Actions Min        -0.9999999
exploration/Num Paths          10
exploration/Average Returns    479.0672903354037
evaluation/num steps total     2285000
evaluation/num paths total     4570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9574229019921511
evaluation/Rewards Std         0.04687770572446293
evaluation/Rewards Max         0.9787043919178795
evaluation/Rewards Min         0.5016709305450097
evaluation/Returns Mean        478.7114509960755
evaluation/Returns Std         2.5022304157607183
evaluation/Returns Max         482.6033058733129
evaluation/Returns Min         475.28696331140634
evaluation/ExplReturns Mean    478.7114509960755
evaluation/ExplReturns Std     2.5022304157607183
evaluation/ExplReturns Max     482.6033058733129
evaluation/ExplReturns Min     475.28696331140634
evaluation/Actions Mean        0.08271989
evaluation/Actions Std         0.54465467
evaluation/Actions Max         0.99968535
evaluation/Actions Min         -0.9994901
evaluation/Num Paths           10
evaluation/Average Returns     478.7114509960755
time/data storing (s)          0.03189260698854923
time/evaluation sampling (s)   112.64336560573429
time/exploration sampling (s)  113.28953190799803
time/logging (s)               0.030370837077498436
time/saving (s)                0.010782076977193356
time/training (s)              9.037404844537377
time/epoch (s)                 235.04334787931293
time/total (s)                 106986.0818148572
Epoch                          456
-----------------------------  ---------------------
2023-08-01 23:41:13.408734 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 457 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4253.466]
trainer/QF1 Loss               0.026321756
trainer/QF2 Loss               0.03099009
trainer/Policy Loss            -90.385635
trainer/Q1 Predictions Mean    102.20247
trainer/Q1 Predictions Std     2.9044025
trainer/Q1 Predictions Max     103.84668
trainer/Q1 Predictions Min     72.52415
trainer/Q2 Predictions Mean    102.219604
trainer/Q2 Predictions Std     2.8782914
trainer/Q2 Predictions Max     103.91973
trainer/Q2 Predictions Min     72.64377
trainer/Q Targets Mean         102.19255
trainer/Q Targets Std          2.950807
trainer/Q Targets Max          104.47783
trainer/Q Targets Min          72.97253
trainer/Log Pis Mean           11.90254
trainer/Log Pis Std            9.625792
trainer/Log Pis Max            92.89016
trainer/Log Pis Min            -4.57045
trainer/Policy mu Mean         -0.004559526
trainer/Policy mu Std          1.6032792
trainer/Policy mu Max          9.023745
trainer/Policy mu Min          -6.310485
trainer/Policy log std Mean    -0.719925
trainer/Policy log std Std     0.2759895
trainer/Policy log std Max     0.39275873
trainer/Policy log std Min     -1.9586167
trainer/Alpha                  0.0014829329447820783
trainer/Alpha Loss             -0.6348326206207275
exploration/num steps total    2291000
exploration/num paths total    4582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9548193160202818
exploration/Rewards Std        0.058065092634212764
exploration/Rewards Max        0.9797838997549024
exploration/Rewards Min        0.501677157273502
exploration/Returns Mean       477.4096580101411
exploration/Returns Std        6.355482498645315
exploration/Returns Max        482.6065966184426
exploration/Returns Min        459.0679975226662
exploration/Actions Mean       0.08843251
exploration/Actions Std        0.6621468
exploration/Actions Max        0.999989
exploration/Actions Min        -0.9999986
exploration/Num Paths          10
exploration/Average Returns    477.4096580101411
evaluation/num steps total     2290000
evaluation/num paths total     4580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9619758872926882
evaluation/Rewards Std         0.04880124887493742
evaluation/Rewards Max         0.9784545023063927
evaluation/Rewards Min         0.49342720927063183
evaluation/Returns Mean        480.9879436463442
evaluation/Returns Std         2.208695572166712
evaluation/Returns Max         483.156752700732
evaluation/Returns Min         477.28742207505195
evaluation/ExplReturns Mean    480.9879436463442
evaluation/ExplReturns Std     2.208695572166712
evaluation/ExplReturns Max     483.156752700732
evaluation/ExplReturns Min     477.28742207505195
evaluation/Actions Mean        0.119075954
evaluation/Actions Std         0.60086393
evaluation/Actions Max         0.9998733
evaluation/Actions Min         -0.9997243
evaluation/Num Paths           10
evaluation/Average Returns     480.9879436463442
time/data storing (s)          0.03220242261886597
time/evaluation sampling (s)   113.78019405901432
time/exploration sampling (s)  114.8562489869073
time/logging (s)               0.0303631778806448
time/saving (s)                0.01123736146837473
time/training (s)              9.545874376781285
time/epoch (s)                 238.2561203846708
time/total (s)                 107224.34042120911
Epoch                          457
-----------------------------  ---------------------
2023-08-01 23:45:10.467368 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 458 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4092.8486]
trainer/QF1 Loss               0.037581813
trainer/QF2 Loss               0.030782271
trainer/Policy Loss            -88.94853
trainer/Q1 Predictions Mean    101.76941
trainer/Q1 Predictions Std     3.9100153
trainer/Q1 Predictions Max     104.686386
trainer/Q1 Predictions Min     64.15945
trainer/Q2 Predictions Mean    101.80371
trainer/Q2 Predictions Std     3.8943262
trainer/Q2 Predictions Max     104.61875
trainer/Q2 Predictions Min     64.64454
trainer/Q Targets Mean         101.813644
trainer/Q Targets Std          3.964182
trainer/Q Targets Max          104.819214
trainer/Q Targets Min          64.038635
trainer/Log Pis Mean           12.912996
trainer/Log Pis Std            9.37457
trainer/Log Pis Max            46.930984
trainer/Log Pis Min            -12.482878
trainer/Policy mu Mean         0.05256008
trainer/Policy mu Std          1.6714548
trainer/Policy mu Max          10.749577
trainer/Policy mu Min          -10.783449
trainer/Policy log std Mean    -0.7321767
trainer/Policy log std Std     0.2943603
trainer/Policy log std Max     1.2398846
trainer/Policy log std Min     -1.7612522
trainer/Alpha                  0.0014684789348393679
trainer/Alpha Loss             5.9559125900268555
exploration/num steps total    2296000
exploration/num paths total    4592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9538007226710368
exploration/Rewards Std        0.054285894590147696
exploration/Rewards Max        0.9787702025533064
exploration/Rewards Min        0.498478877428125
exploration/Returns Mean       476.9003613355185
exploration/Returns Std        1.1726909988307124
exploration/Returns Max        478.3202341612823
exploration/Returns Min        473.9138170763892
exploration/Actions Mean       0.10996237
exploration/Actions Std        0.66259766
exploration/Actions Max        0.9999688
exploration/Actions Min        -0.99990606
exploration/Num Paths          10
exploration/Average Returns    476.9003613355185
evaluation/num steps total     2295000
evaluation/num paths total     4590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9549124078212985
evaluation/Rewards Std         0.05346012265223901
evaluation/Rewards Max         0.9791850343454569
evaluation/Rewards Min         0.4863114673111417
evaluation/Returns Mean        477.45620391064915
evaluation/Returns Std         2.5111866842107493
evaluation/Returns Max         481.3093889238664
evaluation/Returns Min         471.90293384823826
evaluation/ExplReturns Mean    477.45620391064915
evaluation/ExplReturns Std     2.5111866842107493
evaluation/ExplReturns Max     481.3093889238664
evaluation/ExplReturns Min     471.90293384823826
evaluation/Actions Mean        0.05000695
evaluation/Actions Std         0.5353443
evaluation/Actions Max         0.9999686
evaluation/Actions Min         -0.99978924
evaluation/Num Paths           10
evaluation/Average Returns     477.45620391064915
time/data storing (s)          0.03232217952609062
time/evaluation sampling (s)   113.74772537592798
time/exploration sampling (s)  113.85307154338807
time/logging (s)               0.03068812284618616
time/saving (s)                0.010332349687814713
time/training (s)              9.378626743331552
time/epoch (s)                 237.0527663147077
time/total (s)                 107461.39560434036
Epoch                          458
-----------------------------  ---------------------
2023-08-01 23:49:06.920633 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 459 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3894.0354]
trainer/QF1 Loss               0.04252374
trainer/QF2 Loss               0.036680046
trainer/Policy Loss            -90.72923
trainer/Q1 Predictions Mean    102.083145
trainer/Q1 Predictions Std     2.2325568
trainer/Q1 Predictions Max     104.31213
trainer/Q1 Predictions Min     81.374115
trainer/Q2 Predictions Mean    102.03653
trainer/Q2 Predictions Std     2.2149363
trainer/Q2 Predictions Max     104.032616
trainer/Q2 Predictions Min     81.316605
trainer/Q Targets Mean         102.036865
trainer/Q Targets Std          2.2806463
trainer/Q Targets Max          104.307625
trainer/Q Targets Min          81.061584
trainer/Log Pis Mean           11.421177
trainer/Log Pis Std            8.889996
trainer/Log Pis Max            48.681404
trainer/Log Pis Min            -4.5061555
trainer/Policy mu Mean         0.049249828
trainer/Policy mu Std          1.5830632
trainer/Policy mu Max          6.636099
trainer/Policy mu Min          -6.4553585
trainer/Policy log std Mean    -0.7308032
trainer/Policy log std Std     0.2901709
trainer/Policy log std Max     0.41170245
trainer/Policy log std Min     -1.7635224
trainer/Alpha                  0.0015272008022293448
trainer/Alpha Loss             -3.753342628479004
exploration/num steps total    2301000
exploration/num paths total    4602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.944451000834849
exploration/Rewards Std        0.07052831553769587
exploration/Rewards Max        0.9797190439210838
exploration/Rewards Min        0.49306556939345336
exploration/Returns Mean       472.2255004174244
exploration/Returns Std        7.374698248726952
exploration/Returns Max        480.69015926074246
exploration/Returns Min        454.78902725034226
exploration/Actions Mean       0.05076688
exploration/Actions Std        0.64288276
exploration/Actions Max        0.9999991
exploration/Actions Min        -0.9997839
exploration/Num Paths          10
exploration/Average Returns    472.2255004174244
evaluation/num steps total     2300000
evaluation/num paths total     4600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9196656966059705
evaluation/Rewards Std         0.09094462912458694
evaluation/Rewards Max         0.9779795936088034
evaluation/Rewards Min         0.4847304378521939
evaluation/Returns Mean        459.83284830298516
evaluation/Returns Std         17.177671310078054
evaluation/Returns Max         479.30605112849094
evaluation/Returns Min         425.01986972318133
evaluation/ExplReturns Mean    459.83284830298516
evaluation/ExplReturns Std     17.177671310078054
evaluation/ExplReturns Max     479.30605112849094
evaluation/ExplReturns Min     425.01986972318133
evaluation/Actions Mean        0.07242493
evaluation/Actions Std         0.58300817
evaluation/Actions Max         0.99999976
evaluation/Actions Min         -0.9999726
evaluation/Num Paths           10
evaluation/Average Returns     459.83284830298516
time/data storing (s)          0.03218567930161953
time/evaluation sampling (s)   113.24224756006151
time/exploration sampling (s)  113.75683518964797
time/logging (s)               0.030692161060869694
time/saving (s)                0.011312345042824745
time/training (s)              9.373587436974049
time/epoch (s)                 236.44686037208885
time/total (s)                 107697.84507889394
Epoch                          459
-----------------------------  ---------------------
2023-08-01 23:53:05.144423 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 460 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3838.3137]
trainer/QF1 Loss               0.040142287
trainer/QF2 Loss               0.021429088
trainer/Policy Loss            -90.431244
trainer/Q1 Predictions Mean    101.97008
trainer/Q1 Predictions Std     2.5635786
trainer/Q1 Predictions Max     104.38051
trainer/Q1 Predictions Min     74.191246
trainer/Q2 Predictions Mean    102.023636
trainer/Q2 Predictions Std     2.5063212
trainer/Q2 Predictions Max     104.40821
trainer/Q2 Predictions Min     74.84461
trainer/Q Targets Mean         102.068695
trainer/Q Targets Std          2.4850676
trainer/Q Targets Max          104.33033
trainer/Q Targets Min          75.30425
trainer/Log Pis Mean           11.66021
trainer/Log Pis Std            8.608421
trainer/Log Pis Max            47.32193
trainer/Log Pis Min            -5.318118
trainer/Policy mu Mean         -0.02249737
trainer/Policy mu Std          1.5911655
trainer/Policy mu Max          5.7810054
trainer/Policy mu Min          -4.8819656
trainer/Policy log std Mean    -0.73052883
trainer/Policy log std Std     0.29799974
trainer/Policy log std Max     0.3411986
trainer/Policy log std Min     -1.7739767
trainer/Alpha                  0.001480352832004428
trainer/Alpha Loss             -2.213900089263916
exploration/num steps total    2306000
exploration/num paths total    4612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557174359168578
exploration/Rewards Std        0.06112992770677938
exploration/Rewards Max        0.9796782246733301
exploration/Rewards Min        0.49432236811477187
exploration/Returns Mean       477.8587179584289
exploration/Returns Std        2.012876219390603
exploration/Returns Max        480.57851526062126
exploration/Returns Min        473.5860789953901
exploration/Actions Mean       0.14951292
exploration/Actions Std        0.6584022
exploration/Actions Max        0.99997956
exploration/Actions Min        -0.9999818
exploration/Num Paths          10
exploration/Average Returns    477.8587179584289
evaluation/num steps total     2305000
evaluation/num paths total     4610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9607131339378184
evaluation/Rewards Std         0.05496424581045127
evaluation/Rewards Max         0.9796755529432742
evaluation/Rewards Min         0.4837416103032972
evaluation/Returns Mean        480.3565669689092
evaluation/Returns Std         0.9353697109366751
evaluation/Returns Max         481.8051342394033
evaluation/Returns Min         479.05208313416836
evaluation/ExplReturns Mean    480.3565669689092
evaluation/ExplReturns Std     0.9353697109366751
evaluation/ExplReturns Max     481.8051342394033
evaluation/ExplReturns Min     479.05208313416836
evaluation/Actions Mean        0.18353473
evaluation/Actions Std         0.60758555
evaluation/Actions Max         0.99966735
evaluation/Actions Min         -0.999623
evaluation/Num Paths           10
evaluation/Average Returns     480.3565669689092
time/data storing (s)          0.03213854879140854
time/evaluation sampling (s)   114.23339269403368
time/exploration sampling (s)  114.27479413710535
time/logging (s)               0.030552650801837444
time/saving (s)                0.010264869779348373
time/training (s)              9.636203712783754
time/epoch (s)                 238.21734661329538
time/total (s)                 107936.06491915789
Epoch                          460
-----------------------------  --------------------
2023-08-01 23:57:11.820339 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 461 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4052.6157]
trainer/QF1 Loss               0.03209597
trainer/QF2 Loss               0.035159394
trainer/Policy Loss            -90.85117
trainer/Q1 Predictions Mean    101.785706
trainer/Q1 Predictions Std     3.0929995
trainer/Q1 Predictions Max     103.826706
trainer/Q1 Predictions Min     73.11112
trainer/Q2 Predictions Mean    101.77594
trainer/Q2 Predictions Std     3.0658646
trainer/Q2 Predictions Max     103.79285
trainer/Q2 Predictions Min     73.59256
trainer/Q Targets Mean         101.88342
trainer/Q Targets Std          3.1045754
trainer/Q Targets Max          103.82785
trainer/Q Targets Min          73.55496
trainer/Log Pis Mean           11.022775
trainer/Log Pis Std            9.130334
trainer/Log Pis Max            58.027725
trainer/Log Pis Min            -4.952147
trainer/Policy mu Mean         -0.084770106
trainer/Policy mu Std          1.5721473
trainer/Policy mu Max          5.9799023
trainer/Policy mu Min          -5.149208
trainer/Policy log std Mean    -0.7086647
trainer/Policy log std Std     0.29117674
trainer/Policy log std Max     0.52757406
trainer/Policy log std Min     -1.863988
trainer/Alpha                  0.0014660253655165434
trainer/Alpha Loss             -6.376247406005859
exploration/num steps total    2311000
exploration/num paths total    4622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9536546783994286
exploration/Rewards Std        0.06720554938212192
exploration/Rewards Max        0.9793733443768597
exploration/Rewards Min        0.49659773322431544
exploration/Returns Mean       476.82733919971434
exploration/Returns Std        6.303164481190626
exploration/Returns Max        482.2594671991391
exploration/Returns Min        464.45108996949375
exploration/Actions Mean       0.10038719
exploration/Actions Std        0.66813093
exploration/Actions Max        0.99999356
exploration/Actions Min        -0.9999428
exploration/Num Paths          10
exploration/Average Returns    476.82733919971434
evaluation/num steps total     2310000
evaluation/num paths total     4620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9606085602584029
evaluation/Rewards Std         0.04737284135862608
evaluation/Rewards Max         0.9795783663117631
evaluation/Rewards Min         0.4797525729018414
evaluation/Returns Mean        480.3042801292014
evaluation/Returns Std         1.5748119174797157
evaluation/Returns Max         481.864283701795
evaluation/Returns Min         477.5369184847572
evaluation/ExplReturns Mean    480.3042801292014
evaluation/ExplReturns Std     1.5748119174797157
evaluation/ExplReturns Max     481.864283701795
evaluation/ExplReturns Min     477.5369184847572
evaluation/Actions Mean        0.074285425
evaluation/Actions Std         0.6112973
evaluation/Actions Max         0.99958646
evaluation/Actions Min         -0.99974686
evaluation/Num Paths           10
evaluation/Average Returns     480.3042801292014
time/data storing (s)          0.033436995930969715
time/evaluation sampling (s)   118.71101260744035
time/exploration sampling (s)  118.220393165946
time/logging (s)               0.030334478244185448
time/saving (s)                0.012518376111984253
time/training (s)              9.661680250428617
time/epoch (s)                 246.66937587410212
time/total (s)                 108182.73678174522
Epoch                          461
-----------------------------  ---------------------
2023-08-02 00:01:04.791997 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 462 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3899.9082]
trainer/QF1 Loss               0.027628453
trainer/QF2 Loss               0.0357821
trainer/Policy Loss            -90.397385
trainer/Q1 Predictions Mean    102.097824
trainer/Q1 Predictions Std     2.0557733
trainer/Q1 Predictions Max     103.7589
trainer/Q1 Predictions Min     85.290375
trainer/Q2 Predictions Mean    102.149605
trainer/Q2 Predictions Std     2.1236744
trainer/Q2 Predictions Max     103.804726
trainer/Q2 Predictions Min     85.122955
trainer/Q Targets Mean         102.03578
trainer/Q Targets Std          2.076593
trainer/Q Targets Max          103.643005
trainer/Q Targets Min          85.08411
trainer/Log Pis Mean           11.789415
trainer/Log Pis Std            8.460084
trainer/Log Pis Max            70.18165
trainer/Log Pis Min            -2.8526955
trainer/Policy mu Mean         0.09141474
trainer/Policy mu Std          1.5859282
trainer/Policy mu Max          7.132389
trainer/Policy mu Min          -6.6485786
trainer/Policy log std Mean    -0.7300016
trainer/Policy log std Std     0.29661492
trainer/Policy log std Max     0.37642306
trainer/Policy log std Min     -2.026912
trainer/Alpha                  0.0014946870505809784
trainer/Alpha Loss             -1.369997262954712
exploration/num steps total    2316000
exploration/num paths total    4632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9647793137887646
exploration/Rewards Std        0.04847439125148646
exploration/Rewards Max        0.979300419621265
exploration/Rewards Min        0.48279123929926915
exploration/Returns Mean       482.3896568943822
exploration/Returns Std        0.5306522814100959
exploration/Returns Max        483.25168346410004
exploration/Returns Min        481.509800848785
exploration/Actions Mean       0.022855591
exploration/Actions Std        0.5710495
exploration/Actions Max        0.9999142
exploration/Actions Min        -0.9999344
exploration/Num Paths          10
exploration/Average Returns    482.3896568943822
evaluation/num steps total     2315000
evaluation/num paths total     4630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609293972383813
evaluation/Rewards Std         0.04716830593470679
evaluation/Rewards Max         0.9780807558197865
evaluation/Rewards Min         0.4951107657194038
evaluation/Returns Mean        480.4646986191905
evaluation/Returns Std         1.3254408652998921
evaluation/Returns Max         482.3571863521765
evaluation/Returns Min         479.0123569474976
evaluation/ExplReturns Mean    480.4646986191905
evaluation/ExplReturns Std     1.3254408652998921
evaluation/ExplReturns Max     482.3571863521765
evaluation/ExplReturns Min     479.0123569474976
evaluation/Actions Mean        -0.097828925
evaluation/Actions Std         0.55676055
evaluation/Actions Max         0.99997914
evaluation/Actions Min         -0.9988683
evaluation/Num Paths           10
evaluation/Average Returns     480.4646986191905
time/data storing (s)          0.03207901865243912
time/evaluation sampling (s)   112.35124163236469
time/exploration sampling (s)  111.01213658694178
time/logging (s)               0.030437306500971317
time/saving (s)                0.010268336161971092
time/training (s)              9.529265026561916
time/epoch (s)                 232.96542790718377
time/total (s)                 108415.70469666272
Epoch                          462
-----------------------------  ---------------------
2023-08-02 00:04:57.205840 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 463 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3717.3743]
trainer/QF1 Loss               0.025582716
trainer/QF2 Loss               0.04295446
trainer/Policy Loss            -90.54626
trainer/Q1 Predictions Mean    102.08269
trainer/Q1 Predictions Std     1.8278091
trainer/Q1 Predictions Max     103.76533
trainer/Q1 Predictions Min     86.50466
trainer/Q2 Predictions Mean    102.089386
trainer/Q2 Predictions Std     1.746025
trainer/Q2 Predictions Max     103.76775
trainer/Q2 Predictions Min     87.77007
trainer/Q Targets Mean         102.103195
trainer/Q Targets Std          1.8644336
trainer/Q Targets Max          103.76862
trainer/Q Targets Min          85.77013
trainer/Log Pis Mean           11.618731
trainer/Log Pis Std            7.5752954
trainer/Log Pis Max            41.68011
trainer/Log Pis Min            -7.883728
trainer/Policy mu Mean         -0.076911345
trainer/Policy mu Std          1.58064
trainer/Policy mu Max          6.0680003
trainer/Policy mu Min          -7.8765197
trainer/Policy log std Mean    -0.7040732
trainer/Policy log std Std     0.28310665
trainer/Policy log std Max     0.8016237
trainer/Policy log std Min     -1.803164
trainer/Alpha                  0.0015207957476377487
trainer/Alpha Loss             -2.4737794399261475
exploration/num steps total    2321000
exploration/num paths total    4642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8752897020851622
exploration/Rewards Std        0.1162776313497581
exploration/Rewards Max        0.9796444492190279
exploration/Rewards Min        0.49768185615133737
exploration/Returns Mean       437.644851042581
exploration/Returns Std        34.68154636729803
exploration/Returns Max        463.8917240054012
exploration/Returns Min        339.3737148326728
exploration/Actions Mean       -0.0333075
exploration/Actions Std        0.62953126
exploration/Actions Max        0.99999976
exploration/Actions Min        -0.99999595
exploration/Num Paths          10
exploration/Average Returns    437.644851042581
evaluation/num steps total     2320000
evaluation/num paths total     4640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8768662334264449
evaluation/Rewards Std         0.11799833804324292
evaluation/Rewards Max         0.9790642115095448
evaluation/Rewards Min         0.4951520744791381
evaluation/Returns Mean        438.43311671322243
evaluation/Returns Std         25.67952325219654
evaluation/Returns Max         483.2512380733759
evaluation/Returns Min         403.3236746863786
evaluation/ExplReturns Mean    438.43311671322243
evaluation/ExplReturns Std     25.67952325219654
evaluation/ExplReturns Max     483.2512380733759
evaluation/ExplReturns Min     403.3236746863786
evaluation/Actions Mean        -0.07647187
evaluation/Actions Std         0.57233983
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     438.43311671322243
time/data storing (s)          0.03257849998772144
time/evaluation sampling (s)   111.75045262370259
time/exploration sampling (s)  111.31278902944177
time/logging (s)               0.030535507015883923
time/saving (s)                0.012019881047308445
time/training (s)              9.269227703101933
time/epoch (s)                 232.4076032442972
time/total (s)                 108648.11478597298
Epoch                          463
-----------------------------  ---------------------
2023-08-02 00:08:50.928838 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 464 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3874.2463]
trainer/QF1 Loss               0.037353504
trainer/QF2 Loss               0.025619105
trainer/Policy Loss            -90.95075
trainer/Q1 Predictions Mean    102.15963
trainer/Q1 Predictions Std     2.386284
trainer/Q1 Predictions Max     103.81522
trainer/Q1 Predictions Min     82.47307
trainer/Q2 Predictions Mean    102.09537
trainer/Q2 Predictions Std     2.3618684
trainer/Q2 Predictions Max     103.79148
trainer/Q2 Predictions Min     83.33495
trainer/Q Targets Mean         102.07014
trainer/Q Targets Std          2.4009433
trainer/Q Targets Max          103.7086
trainer/Q Targets Min          82.82445
trainer/Log Pis Mean           11.243929
trainer/Log Pis Std            7.9552584
trainer/Log Pis Max            53.148266
trainer/Log Pis Min            -6.8824863
trainer/Policy mu Mean         -0.076679744
trainer/Policy mu Std          1.5451839
trainer/Policy mu Max          7.279997
trainer/Policy mu Min          -5.264311
trainer/Policy log std Mean    -0.7343858
trainer/Policy log std Std     0.27549988
trainer/Policy log std Max     0.3582375
trainer/Policy log std Min     -2.03976
trainer/Alpha                  0.0015396082308143377
trainer/Alpha Loss             -4.896582126617432
exploration/num steps total    2326000
exploration/num paths total    4652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639205531721684
exploration/Rewards Std        0.05110280011071305
exploration/Rewards Max        0.9789819422835955
exploration/Rewards Min        0.4988900089500079
exploration/Returns Mean       481.9602765860842
exploration/Returns Std        1.950966876460046
exploration/Returns Max        483.45039236754417
exploration/Returns Min        476.2918824203887
exploration/Actions Mean       -0.08875276
exploration/Actions Std        0.5971894
exploration/Actions Max        0.99984026
exploration/Actions Min        -0.999988
exploration/Num Paths          10
exploration/Average Returns    481.9602765860842
evaluation/num steps total     2325000
evaluation/num paths total     4650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9654616384736171
evaluation/Rewards Std         0.048279568034920485
evaluation/Rewards Max         0.9786725279758075
evaluation/Rewards Min         0.4915723849687534
evaluation/Returns Mean        482.73081923680866
evaluation/Returns Std         0.7984204312953403
evaluation/Returns Max         483.86544639414967
evaluation/Returns Min         481.2509391750254
evaluation/ExplReturns Mean    482.73081923680866
evaluation/ExplReturns Std     0.7984204312953403
evaluation/ExplReturns Max     483.86544639414967
evaluation/ExplReturns Min     481.2509391750254
evaluation/Actions Mean        -0.22716826
evaluation/Actions Std         0.5156208
evaluation/Actions Max         0.9991999
evaluation/Actions Min         -0.9996206
evaluation/Num Paths           10
evaluation/Average Returns     482.73081923680866
time/data storing (s)          0.03229395113885403
time/evaluation sampling (s)   111.63384433556348
time/exploration sampling (s)  112.31314731948078
time/logging (s)               0.030834774486720562
time/saving (s)                0.010408957488834858
time/training (s)              9.696389387361705
time/epoch (s)                 233.71691872552037
time/total (s)                 108881.83422764111
Epoch                          464
-----------------------------  ---------------------
2023-08-02 00:12:45.479234 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 465 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3715.9473]
trainer/QF1 Loss               0.06055704
trainer/QF2 Loss               0.029315794
trainer/Policy Loss            -90.28648
trainer/Q1 Predictions Mean    102.39673
trainer/Q1 Predictions Std     1.5030026
trainer/Q1 Predictions Max     103.87832
trainer/Q1 Predictions Min     91.60349
trainer/Q2 Predictions Mean    102.30914
trainer/Q2 Predictions Std     1.4754841
trainer/Q2 Predictions Max     103.7419
trainer/Q2 Predictions Min     91.183846
trainer/Q Targets Mean         102.210815
trainer/Q Targets Std          1.4649472
trainer/Q Targets Max          103.55242
trainer/Q Targets Min          91.2748
trainer/Log Pis Mean           12.151609
trainer/Log Pis Std            8.189069
trainer/Log Pis Max            41.846695
trainer/Log Pis Min            -6.92239
trainer/Policy mu Mean         -0.09130403
trainer/Policy mu Std          1.6246105
trainer/Policy mu Max          5.955968
trainer/Policy mu Min          -5.236624
trainer/Policy log std Mean    -0.6933246
trainer/Policy log std Std     0.27139872
trainer/Policy log std Max     0.2130796
trainer/Policy log std Min     -1.7916785
trainer/Alpha                  0.0015849571209400892
trainer/Alpha Loss             0.977461576461792
exploration/num steps total    2331000
exploration/num paths total    4662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9648271148164258
exploration/Rewards Std        0.04906522349990964
exploration/Rewards Max        0.9797199219656871
exploration/Rewards Min        0.48669000783158095
exploration/Returns Mean       482.4135574082128
exploration/Returns Std        0.49105529575681967
exploration/Returns Max        483.27718522680874
exploration/Returns Min        481.8439388156976
exploration/Actions Mean       0.030594165
exploration/Actions Std        0.59084356
exploration/Actions Max        0.99995035
exploration/Actions Min        -0.9999499
exploration/Num Paths          10
exploration/Average Returns    482.4135574082128
evaluation/num steps total     2330000
evaluation/num paths total     4660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.915897718180893
evaluation/Rewards Std         0.15236354159783363
evaluation/Rewards Max         0.9792160627062103
evaluation/Rewards Min         0.17612962841555493
evaluation/Returns Mean        457.9488590904466
evaluation/Returns Std         68.71044277408451
evaluation/Returns Max         481.5105148446015
evaluation/Returns Min         251.8302724835855
evaluation/ExplReturns Mean    457.9488590904466
evaluation/ExplReturns Std     68.71044277408451
evaluation/ExplReturns Max     481.5105148446015
evaluation/ExplReturns Min     251.8302724835855
evaluation/Actions Mean        0.034879968
evaluation/Actions Std         0.5621027
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999964
evaluation/Num Paths           10
evaluation/Average Returns     457.9488590904466
time/data storing (s)          0.03246533963829279
time/evaluation sampling (s)   113.98380297236145
time/exploration sampling (s)  111.45268579665571
time/logging (s)               0.0317933140322566
time/saving (s)                0.012274540960788727
time/training (s)              9.031558335758746
time/epoch (s)                 234.54458029940724
time/total (s)                 109116.38169634063
Epoch                          465
-----------------------------  ---------------------
2023-08-02 00:16:40.940399 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 466 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3721.7236]
trainer/QF1 Loss               0.019288305
trainer/QF2 Loss               0.025646135
trainer/Policy Loss            -89.56076
trainer/Q1 Predictions Mean    101.917915
trainer/Q1 Predictions Std     2.6694555
trainer/Q1 Predictions Max     103.5256
trainer/Q1 Predictions Min     79.34691
trainer/Q2 Predictions Mean    101.845245
trainer/Q2 Predictions Std     2.6022477
trainer/Q2 Predictions Max     103.446526
trainer/Q2 Predictions Min     79.76381
trainer/Q Targets Mean         101.91048
trainer/Q Targets Std          2.6479254
trainer/Q Targets Max          103.541954
trainer/Q Targets Min          79.638374
trainer/Log Pis Mean           12.421896
trainer/Log Pis Std            7.6067543
trainer/Log Pis Max            42.07847
trainer/Log Pis Min            -2.2078452
trainer/Policy mu Mean         -0.18566172
trainer/Policy mu Std          1.6451662
trainer/Policy mu Max          14.533015
trainer/Policy mu Min          -4.7401476
trainer/Policy log std Mean    -0.7168352
trainer/Policy log std Std     0.2730853
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -1.6446073
trainer/Alpha                  0.0015775220235809684
trainer/Alpha Loss             2.7221336364746094
exploration/num steps total    2336000
exploration/num paths total    4672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.953700943093628
exploration/Rewards Std        0.0659816880332627
exploration/Rewards Max        0.9799097694917116
exploration/Rewards Min        0.4863644834944973
exploration/Returns Mean       476.8504715468139
exploration/Returns Std        7.946833134730762
exploration/Returns Max        482.1499880049461
exploration/Returns Min        453.9632939068283
exploration/Actions Mean       0.008769465
exploration/Actions Std        0.61656994
exploration/Actions Max        0.99973726
exploration/Actions Min        -0.99993163
exploration/Num Paths          10
exploration/Average Returns    476.8504715468139
evaluation/num steps total     2335000
evaluation/num paths total     4670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8702096845019524
evaluation/Rewards Std         0.12514331148411828
evaluation/Rewards Max         0.9777487711986756
evaluation/Rewards Min         0.4882822028065308
evaluation/Returns Mean        435.10484225097616
evaluation/Returns Std         57.804352291342255
evaluation/Returns Max         483.3445596258436
evaluation/Returns Min         362.95909228528785
evaluation/ExplReturns Mean    435.10484225097616
evaluation/ExplReturns Std     57.804352291342255
evaluation/ExplReturns Max     483.3445596258436
evaluation/ExplReturns Min     362.95909228528785
evaluation/Actions Mean        -0.08362931
evaluation/Actions Std         0.55963963
evaluation/Actions Max         0.9986303
evaluation/Actions Min         -0.99990696
evaluation/Num Paths           10
evaluation/Average Returns     435.10484225097616
time/data storing (s)          0.03242103848606348
time/evaluation sampling (s)   112.5838192794472
time/exploration sampling (s)  113.23500417172909
time/logging (s)               0.030975108966231346
time/saving (s)                0.011504169553518295
time/training (s)              9.560174411162734
time/epoch (s)                 235.45389817934483
time/total (s)                 109351.8380615972
Epoch                          466
-----------------------------  ---------------------
2023-08-02 00:20:36.699941 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 467 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3794.3477]
trainer/QF1 Loss               0.022282712
trainer/QF2 Loss               0.018726267
trainer/Policy Loss            -90.0307
trainer/Q1 Predictions Mean    102.01825
trainer/Q1 Predictions Std     2.4701726
trainer/Q1 Predictions Max     103.90867
trainer/Q1 Predictions Min     78.450134
trainer/Q2 Predictions Mean    101.96425
trainer/Q2 Predictions Std     2.464983
trainer/Q2 Predictions Max     103.65282
trainer/Q2 Predictions Min     78.24155
trainer/Q Targets Mean         102.004486
trainer/Q Targets Std          2.4695742
trainer/Q Targets Max          103.79231
trainer/Q Targets Min          78.072426
trainer/Log Pis Mean           12.047792
trainer/Log Pis Std            7.7884398
trainer/Log Pis Max            54.567417
trainer/Log Pis Min            -4.0161834
trainer/Policy mu Mean         -0.05902074
trainer/Policy mu Std          1.6223459
trainer/Policy mu Max          6.993456
trainer/Policy mu Min          -7.4657235
trainer/Policy log std Mean    -0.6837718
trainer/Policy log std Std     0.25622818
trainer/Policy log std Max     0.62477607
trainer/Policy log std Min     -1.6789191
trainer/Alpha                  0.0015870747156441212
trainer/Alpha Loss             0.3080720901489258
exploration/num steps total    2341000
exploration/num paths total    4682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9454862718760496
exploration/Rewards Std        0.07606569872747139
exploration/Rewards Max        0.9797835965421279
exploration/Rewards Min        0.4931940068551162
exploration/Returns Mean       472.7431359380247
exploration/Returns Std        20.114355271640356
exploration/Returns Max        480.9558332530645
exploration/Returns Min        412.57648822728834
exploration/Actions Mean       0.06853515
exploration/Actions Std        0.61908966
exploration/Actions Max        0.99977845
exploration/Actions Min        -0.99992996
exploration/Num Paths          10
exploration/Average Returns    472.7431359380247
evaluation/num steps total     2340000
evaluation/num paths total     4680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8893952499511435
evaluation/Rewards Std         0.11507650022434887
evaluation/Rewards Max         0.9759886108424433
evaluation/Rewards Min         0.49278609416568653
evaluation/Returns Mean        444.69762497557184
evaluation/Returns Std         52.48528051305465
evaluation/Returns Max         480.5931078544037
evaluation/Returns Min         363.42928157120997
evaluation/ExplReturns Mean    444.69762497557184
evaluation/ExplReturns Std     52.48528051305465
evaluation/ExplReturns Max     480.5931078544037
evaluation/ExplReturns Min     363.42928157120997
evaluation/Actions Mean        -0.028299356
evaluation/Actions Std         0.51003236
evaluation/Actions Max         0.9983215
evaluation/Actions Min         -0.9988846
evaluation/Num Paths           10
evaluation/Average Returns     444.69762497557184
time/data storing (s)          0.03240793477743864
time/evaluation sampling (s)   113.72943399194628
time/exploration sampling (s)  112.37450910173357
time/logging (s)               0.03085851389914751
time/saving (s)                0.012698094360530376
time/training (s)              9.573142398148775
time/epoch (s)                 235.75305003486574
time/total (s)                 109587.59359570127
Epoch                          467
-----------------------------  ---------------------
2023-08-02 00:24:33.292734 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 468 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3476.294]
trainer/QF1 Loss               0.030296456
trainer/QF2 Loss               0.024667572
trainer/Policy Loss            -90.45658
trainer/Q1 Predictions Mean    101.969666
trainer/Q1 Predictions Std     3.1200876
trainer/Q1 Predictions Max     103.82636
trainer/Q1 Predictions Min     67.83078
trainer/Q2 Predictions Mean    102.04823
trainer/Q2 Predictions Std     3.166795
trainer/Q2 Predictions Max     103.96602
trainer/Q2 Predictions Min     67.6797
trainer/Q Targets Mean         101.99164
trainer/Q Targets Std          3.1260478
trainer/Q Targets Max          103.82191
trainer/Q Targets Min          68.02407
trainer/Log Pis Mean           11.637468
trainer/Log Pis Std            8.608917
trainer/Log Pis Max            72.53447
trainer/Log Pis Min            -3.0421429
trainer/Policy mu Mean         -0.04416876
trainer/Policy mu Std          1.5855676
trainer/Policy mu Max          6.5940113
trainer/Policy mu Min          -8.428139
trainer/Policy log std Mean    -0.68702364
trainer/Policy log std Std     0.23866493
trainer/Policy log std Max     0.77898276
trainer/Policy log std Min     -1.7282517
trainer/Alpha                  0.001621142728254199
trainer/Alpha Loss             -2.3291244506835938
exploration/num steps total    2346000
exploration/num paths total    4692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9613614178059783
exploration/Rewards Std        0.05002359300635971
exploration/Rewards Max        0.9796008639035174
exploration/Rewards Min        0.4910775439539845
exploration/Returns Mean       480.6807089029891
exploration/Returns Std        0.9067714581803764
exploration/Returns Max        481.93230455171744
exploration/Returns Min        478.7813910609878
exploration/Actions Mean       0.1392057
exploration/Actions Std        0.60562253
exploration/Actions Max        0.99998397
exploration/Actions Min        -0.99976736
exploration/Num Paths          10
exploration/Average Returns    480.6807089029891
evaluation/num steps total     2345000
evaluation/num paths total     4690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9600492811020799
evaluation/Rewards Std         0.0492735577188175
evaluation/Rewards Max         0.978368441088914
evaluation/Rewards Min         0.49037105793218094
evaluation/Returns Mean        480.0246405510399
evaluation/Returns Std         0.8228280885459087
evaluation/Returns Max         481.91394545155515
evaluation/Returns Min         478.777381088568
evaluation/ExplReturns Mean    480.0246405510399
evaluation/ExplReturns Std     0.8228280885459087
evaluation/ExplReturns Max     481.91394545155515
evaluation/ExplReturns Min     478.777381088568
evaluation/Actions Mean        0.0690932
evaluation/Actions Std         0.53834844
evaluation/Actions Max         0.99972576
evaluation/Actions Min         -0.99938095
evaluation/Num Paths           10
evaluation/Average Returns     480.0246405510399
time/data storing (s)          0.032100887037813663
time/evaluation sampling (s)   113.27315544243902
time/exploration sampling (s)  113.62745581101626
time/logging (s)               0.031116691417992115
time/saving (s)                0.013014894910156727
time/training (s)              9.609712448902428
time/epoch (s)                 236.58655617572367
time/total (s)                 109824.18270110525
Epoch                          468
-----------------------------  --------------------
2023-08-02 00:28:30.965118 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 469 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3782.9514]
trainer/QF1 Loss               0.044511028
trainer/QF2 Loss               0.045293365
trainer/Policy Loss            -91.16954
trainer/Q1 Predictions Mean    101.93846
trainer/Q1 Predictions Std     4.0992565
trainer/Q1 Predictions Max     103.417534
trainer/Q1 Predictions Min     60.80436
trainer/Q2 Predictions Mean    101.90448
trainer/Q2 Predictions Std     4.0776615
trainer/Q2 Predictions Max     103.387924
trainer/Q2 Predictions Min     61.38768
trainer/Q Targets Mean         101.82052
trainer/Q Targets Std          4.0741453
trainer/Q Targets Max          103.22899
trainer/Q Targets Min          60.710884
trainer/Log Pis Mean           10.821447
trainer/Log Pis Std            8.903812
trainer/Log Pis Max            65.024055
trainer/Log Pis Min            -5.8443813
trainer/Policy mu Mean         0.031357285
trainer/Policy mu Std          1.6322061
trainer/Policy mu Max          12.814985
trainer/Policy mu Min          -8.30827
trainer/Policy log std Mean    -0.65709084
trainer/Policy log std Std     0.25934318
trainer/Policy log std Max     0.9359045
trainer/Policy log std Min     -1.9395032
trainer/Alpha                  0.0015920066507533193
trainer/Alpha Loss             -7.592926025390625
exploration/num steps total    2351000
exploration/num paths total    4702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.958396612067649
exploration/Rewards Std        0.04892997983725192
exploration/Rewards Max        0.9794895579697578
exploration/Rewards Min        0.49363269219861183
exploration/Returns Mean       479.1983060338245
exploration/Returns Std        1.084059373777609
exploration/Returns Max        481.368796293697
exploration/Returns Min        477.65786116337523
exploration/Actions Mean       0.04351969
exploration/Actions Std        0.6065859
exploration/Actions Max        0.99973434
exploration/Actions Min        -0.9999117
exploration/Num Paths          10
exploration/Average Returns    479.1983060338245
evaluation/num steps total     2350000
evaluation/num paths total     4700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9570011548346697
evaluation/Rewards Std         0.05087972671323429
evaluation/Rewards Max         0.9786498882762754
evaluation/Rewards Min         0.49293002868284186
evaluation/Returns Mean        478.50057741733497
evaluation/Returns Std         2.0530773985185653
evaluation/Returns Max         483.42876158416846
evaluation/Returns Min         476.27728817776244
evaluation/ExplReturns Mean    478.50057741733497
evaluation/ExplReturns Std     2.0530773985185653
evaluation/ExplReturns Max     483.42876158416846
evaluation/ExplReturns Min     476.27728817776244
evaluation/Actions Mean        -0.0074276994
evaluation/Actions Std         0.54157275
evaluation/Actions Max         0.9999967
evaluation/Actions Min         -0.99983
evaluation/Num Paths           10
evaluation/Average Returns     478.50057741733497
time/data storing (s)          0.032469029538333416
time/evaluation sampling (s)   114.13710375409573
time/exploration sampling (s)  113.31579400133342
time/logging (s)               0.030629152432084084
time/saving (s)                0.011169549077749252
time/training (s)              10.138396291062236
time/epoch (s)                 237.66556177753955
time/total (s)                 110061.85071988218
Epoch                          469
-----------------------------  ---------------------
2023-08-02 00:32:27.741514 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 470 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3594.491]
trainer/QF1 Loss               0.032789305
trainer/QF2 Loss               0.028253146
trainer/Policy Loss            -89.84746
trainer/Q1 Predictions Mean    101.43678
trainer/Q1 Predictions Std     4.586428
trainer/Q1 Predictions Max     103.36489
trainer/Q1 Predictions Min     64.71631
trainer/Q2 Predictions Mean    101.45999
trainer/Q2 Predictions Std     4.6375537
trainer/Q2 Predictions Max     103.366264
trainer/Q2 Predictions Min     64.58039
trainer/Q Targets Mean         101.47609
trainer/Q Targets Std          4.6518793
trainer/Q Targets Max          103.34304
trainer/Q Targets Min          64.724815
trainer/Log Pis Mean           11.680244
trainer/Log Pis Std            9.379678
trainer/Log Pis Max            55.142445
trainer/Log Pis Min            -10.764332
trainer/Policy mu Mean         0.01175715
trainer/Policy mu Std          1.6029664
trainer/Policy mu Max          7.275854
trainer/Policy mu Min          -5.222498
trainer/Policy log std Mean    -0.71306545
trainer/Policy log std Std     0.2574207
trainer/Policy log std Max     0.1475806
trainer/Policy log std Min     -1.6242423
trainer/Alpha                  0.001529219327494502
trainer/Alpha Loss             -2.0728867053985596
exploration/num steps total    2356000
exploration/num paths total    4712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9600476506048137
exploration/Rewards Std        0.05370246621558802
exploration/Rewards Max        0.9797700135245861
exploration/Rewards Min        0.48595141997607527
exploration/Returns Mean       480.02382530240703
exploration/Returns Std        1.3507177966434796
exploration/Returns Max        482.27955436123443
exploration/Returns Min        477.4722582541956
exploration/Actions Mean       0.048981607
exploration/Actions Std        0.60014015
exploration/Actions Max        0.9999105
exploration/Actions Min        -0.9999732
exploration/Num Paths          10
exploration/Average Returns    480.02382530240703
evaluation/num steps total     2355000
evaluation/num paths total     4710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9584961255237188
evaluation/Rewards Std         0.054362823337885474
evaluation/Rewards Max         0.9795216164616666
evaluation/Rewards Min         0.4863775802154169
evaluation/Returns Mean        479.2480627618594
evaluation/Returns Std         2.6059619919612653
evaluation/Returns Max         483.76311583603774
evaluation/Returns Min         474.6997712061492
evaluation/ExplReturns Mean    479.2480627618594
evaluation/ExplReturns Std     2.6059619919612653
evaluation/ExplReturns Max     483.76311583603774
evaluation/ExplReturns Min     474.6997712061492
evaluation/Actions Mean        0.10190399
evaluation/Actions Std         0.46318823
evaluation/Actions Max         0.9987858
evaluation/Actions Min         -0.9997811
evaluation/Num Paths           10
evaluation/Average Returns     479.2480627618594
time/data storing (s)          0.032082753255963326
time/evaluation sampling (s)   112.53383077587932
time/exploration sampling (s)  113.54143727663904
time/logging (s)               0.031143845058977604
time/saving (s)                0.013037336990237236
time/training (s)              10.618901189416647
time/epoch (s)                 236.7704331772402
time/total (s)                 110298.62366867065
Epoch                          470
-----------------------------  --------------------
2023-08-02 00:36:22.859781 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 471 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3957.396]
trainer/QF1 Loss               0.031464055
trainer/QF2 Loss               0.034109958
trainer/Policy Loss            -88.62857
trainer/Q1 Predictions Mean    101.63307
trainer/Q1 Predictions Std     2.9280503
trainer/Q1 Predictions Max     103.48075
trainer/Q1 Predictions Min     83.099815
trainer/Q2 Predictions Mean    101.67439
trainer/Q2 Predictions Std     2.953054
trainer/Q2 Predictions Max     103.620224
trainer/Q2 Predictions Min     83.66268
trainer/Q Targets Mean         101.67372
trainer/Q Targets Std          2.947269
trainer/Q Targets Max          103.70691
trainer/Q Targets Min          83.10821
trainer/Log Pis Mean           13.141403
trainer/Log Pis Std            9.811042
trainer/Log Pis Max            68.35626
trainer/Log Pis Min            -4.238662
trainer/Policy mu Mean         0.2000478
trainer/Policy mu Std          1.7046328
trainer/Policy mu Max          13.262754
trainer/Policy mu Min          -5.2879972
trainer/Policy log std Mean    -0.7030831
trainer/Policy log std Std     0.2661973
trainer/Policy log std Max     0.9862935
trainer/Policy log std Min     -1.8090223
trainer/Alpha                  0.0015370137989521027
trainer/Alpha Loss             7.394040584564209
exploration/num steps total    2361000
exploration/num paths total    4722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9591564779512172
exploration/Rewards Std        0.051183417291764816
exploration/Rewards Max        0.979464704755328
exploration/Rewards Min        0.4910808678445777
exploration/Returns Mean       479.5782389756083
exploration/Returns Std        1.347430727389105
exploration/Returns Max        480.7652607383018
exploration/Returns Min        476.4544777660146
exploration/Actions Mean       -0.0035795802
exploration/Actions Std        0.64138985
exploration/Actions Max        0.99998
exploration/Actions Min        -0.9999935
exploration/Num Paths          10
exploration/Average Returns    479.5782389756083
evaluation/num steps total     2360000
evaluation/num paths total     4720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9553632944630446
evaluation/Rewards Std         0.055657817754970446
evaluation/Rewards Max         0.9787620798752642
evaluation/Rewards Min         0.4999794626509759
evaluation/Returns Mean        477.6816472315222
evaluation/Returns Std         1.5630802574172298
evaluation/Returns Max         480.7667735387613
evaluation/Returns Min         475.49660549701053
evaluation/ExplReturns Mean    477.6816472315222
evaluation/ExplReturns Std     1.5630802574172298
evaluation/ExplReturns Max     480.7667735387613
evaluation/ExplReturns Min     475.49660549701053
evaluation/Actions Mean        0.0028392812
evaluation/Actions Std         0.58543545
evaluation/Actions Max         0.9997605
evaluation/Actions Min         -0.9995999
evaluation/Num Paths           10
evaluation/Average Returns     477.6816472315222
time/data storing (s)          0.03235068637877703
time/evaluation sampling (s)   112.30861879698932
time/exploration sampling (s)  112.3990745190531
time/logging (s)               0.030703394673764706
time/saving (s)                0.012709415517747402
time/training (s)              10.327894482761621
time/epoch (s)                 235.11135129537433
time/total (s)                 110533.73759827949
Epoch                          471
-----------------------------  ---------------------
2023-08-02 00:40:17.932206 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 472 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4269.4497]
trainer/QF1 Loss               0.04250493
trainer/QF2 Loss               0.033159494
trainer/Policy Loss            -90.46907
trainer/Q1 Predictions Mean    101.97917
trainer/Q1 Predictions Std     2.4436285
trainer/Q1 Predictions Max     103.87215
trainer/Q1 Predictions Min     77.46776
trainer/Q2 Predictions Mean    102.0043
trainer/Q2 Predictions Std     2.4636045
trainer/Q2 Predictions Max     103.87102
trainer/Q2 Predictions Min     76.748505
trainer/Q Targets Mean         102.007126
trainer/Q Targets Std          2.523416
trainer/Q Targets Max          103.943
trainer/Q Targets Min          76.1596
trainer/Log Pis Mean           11.598194
trainer/Log Pis Std            9.856106
trainer/Log Pis Max            90.07097
trainer/Log Pis Min            -4.4555006
trainer/Policy mu Mean         0.11639287
trainer/Policy mu Std          1.6041977
trainer/Policy mu Max          14.576138
trainer/Policy mu Min          -11.177768
trainer/Policy log std Mean    -0.70484823
trainer/Policy log std Std     0.26018175
trainer/Policy log std Max     0.61474216
trainer/Policy log std Min     -1.7793031
trainer/Alpha                  0.0015334683703258634
trainer/Alpha Loss             -2.603736639022827
exploration/num steps total    2366000
exploration/num paths total    4732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9556953499634654
exploration/Rewards Std        0.058023741971849695
exploration/Rewards Max        0.9792261257525072
exploration/Rewards Min        0.5022041163237717
exploration/Returns Mean       477.8476749817329
exploration/Returns Std        4.464359942137674
exploration/Returns Max        481.0944563654543
exploration/Returns Min        464.8233179500358
exploration/Actions Mean       0.05747407
exploration/Actions Std        0.6430958
exploration/Actions Max        0.99990755
exploration/Actions Min        -0.99991876
exploration/Num Paths          10
exploration/Average Returns    477.8476749817329
evaluation/num steps total     2365000
evaluation/num paths total     4730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.876415179655516
evaluation/Rewards Std         0.12305092935788489
evaluation/Rewards Max         0.9788016427546954
evaluation/Rewards Min         0.4922998317946554
evaluation/Returns Mean        438.2075898277578
evaluation/Returns Std         53.047377973980666
evaluation/Returns Max         479.07400162167596
evaluation/Returns Min         357.7066255753095
evaluation/ExplReturns Mean    438.2075898277578
evaluation/ExplReturns Std     53.047377973980666
evaluation/ExplReturns Max     479.07400162167596
evaluation/ExplReturns Min     357.7066255753095
evaluation/Actions Mean        -0.018859189
evaluation/Actions Std         0.53260076
evaluation/Actions Max         0.99927294
evaluation/Actions Min         -0.9990464
evaluation/Num Paths           10
evaluation/Average Returns     438.2075898277578
time/data storing (s)          0.032181693241000175
time/evaluation sampling (s)   112.02938620001078
time/exploration sampling (s)  113.13664035312831
time/logging (s)               0.030270027928054333
time/saving (s)                0.011357937008142471
time/training (s)              9.825364957563579
time/epoch (s)                 235.06520116887987
time/total (s)                 110768.80566864554
Epoch                          472
-----------------------------  ---------------------
2023-08-02 00:44:12.466538 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 473 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4250.7974]
trainer/QF1 Loss               0.032476354
trainer/QF2 Loss               0.049600594
trainer/Policy Loss            -90.77417
trainer/Q1 Predictions Mean    102.16057
trainer/Q1 Predictions Std     1.0888346
trainer/Q1 Predictions Max     103.64461
trainer/Q1 Predictions Min     94.86116
trainer/Q2 Predictions Mean    102.10182
trainer/Q2 Predictions Std     1.0890042
trainer/Q2 Predictions Max     103.58373
trainer/Q2 Predictions Min     94.7067
trainer/Q Targets Mean         102.27995
trainer/Q Targets Std          1.0756205
trainer/Q Targets Max          103.737724
trainer/Q Targets Min          94.977745
trainer/Log Pis Mean           11.4534
trainer/Log Pis Std            7.977124
trainer/Log Pis Max            57.050438
trainer/Log Pis Min            -5.063479
trainer/Policy mu Mean         0.104801126
trainer/Policy mu Std          1.5835862
trainer/Policy mu Max          7.244219
trainer/Policy mu Min          -4.800659
trainer/Policy log std Mean    -0.7065094
trainer/Policy log std Std     0.2652474
trainer/Policy log std Max     0.20515275
trainer/Policy log std Min     -1.9845979
trainer/Alpha                  0.0015171726699918509
trainer/Alpha Loss             -3.548029899597168
exploration/num steps total    2371000
exploration/num paths total    4742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9180619781203561
exploration/Rewards Std        0.10835509411954554
exploration/Rewards Max        0.9790073477220886
exploration/Rewards Min        0.31405108585378394
exploration/Returns Mean       459.03098906017806
exploration/Returns Std        36.586477016871164
exploration/Returns Max        475.3056435738878
exploration/Returns Min        353.4970322349121
exploration/Actions Mean       -0.025646193
exploration/Actions Std        0.62973887
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    459.03098906017806
evaluation/num steps total     2370000
evaluation/num paths total     4740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9490751330987929
evaluation/Rewards Std         0.05075915581432104
evaluation/Rewards Max         0.9796761427887617
evaluation/Rewards Min         0.48850751501124157
evaluation/Returns Mean        474.5375665493965
evaluation/Returns Std         1.115759863720656
evaluation/Returns Max         476.1379127116771
evaluation/Returns Min         473.03511045915013
evaluation/ExplReturns Mean    474.5375665493965
evaluation/ExplReturns Std     1.115759863720656
evaluation/ExplReturns Max     476.1379127116771
evaluation/ExplReturns Min     473.03511045915013
evaluation/Actions Mean        -0.08555956
evaluation/Actions Std         0.4932615
evaluation/Actions Max         0.99941844
evaluation/Actions Min         -0.99976104
evaluation/Num Paths           10
evaluation/Average Returns     474.5375665493965
time/data storing (s)          0.032034119591116905
time/evaluation sampling (s)   112.39569211564958
time/exploration sampling (s)  112.42970855068415
time/logging (s)               0.03051869198679924
time/saving (s)                0.037422601133584976
time/training (s)              9.602520589716733
time/epoch (s)                 234.52789666876197
time/total (s)                 111003.33630739711
Epoch                          473
-----------------------------  ---------------------
2023-08-02 00:48:08.656255 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 474 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4238.77]
trainer/QF1 Loss               0.026806615
trainer/QF2 Loss               0.029737452
trainer/Policy Loss            -89.99606
trainer/Q1 Predictions Mean    101.820465
trainer/Q1 Predictions Std     2.9797266
trainer/Q1 Predictions Max     104.03328
trainer/Q1 Predictions Min     72.108055
trainer/Q2 Predictions Mean    101.84013
trainer/Q2 Predictions Std     2.9576306
trainer/Q2 Predictions Max     104.03661
trainer/Q2 Predictions Min     72.06548
trainer/Q Targets Mean         101.81709
trainer/Q Targets Std          3.0253465
trainer/Q Targets Max          104.06622
trainer/Q Targets Min          71.63502
trainer/Log Pis Mean           11.941866
trainer/Log Pis Std            9.344756
trainer/Log Pis Max            47.974586
trainer/Log Pis Min            -2.553341
trainer/Policy mu Mean         -0.06986048
trainer/Policy mu Std          1.6288698
trainer/Policy mu Max          6.6804647
trainer/Policy mu Min          -6.202825
trainer/Policy log std Mean    -0.71600896
trainer/Policy log std Std     0.26508102
trainer/Policy log std Max     0.015083969
trainer/Policy log std Min     -1.8483709
trainer/Alpha                  0.0015266408445313573
trainer/Alpha Loss             -0.37697362899780273
exploration/num steps total    2376000
exploration/num paths total    4752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9479778282589149
exploration/Rewards Std        0.06559115090945422
exploration/Rewards Max        0.9790745976827951
exploration/Rewards Min        0.49952727237309075
exploration/Returns Mean       473.9889141294573
exploration/Returns Std        2.207862407790107
exploration/Returns Max        477.6618719045743
exploration/Returns Min        469.8448164083781
exploration/Actions Mean       0.11917596
exploration/Actions Std        0.63130826
exploration/Actions Max        0.99994594
exploration/Actions Min        -0.99979424
exploration/Num Paths          10
exploration/Average Returns    473.9889141294573
evaluation/num steps total     2375000
evaluation/num paths total     4750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.95320718754048
evaluation/Rewards Std         0.05488729030156705
evaluation/Rewards Max         0.979704138167593
evaluation/Rewards Min         0.47984024312790896
evaluation/Returns Mean        476.60359377023997
evaluation/Returns Std         3.253340016984886
evaluation/Returns Max         482.11283020406984
evaluation/Returns Min         470.8638262973398
evaluation/ExplReturns Mean    476.60359377023997
evaluation/ExplReturns Std     3.253340016984886
evaluation/ExplReturns Max     482.11283020406984
evaluation/ExplReturns Min     470.8638262973398
evaluation/Actions Mean        0.0658414
evaluation/Actions Std         0.5528418
evaluation/Actions Max         0.99926674
evaluation/Actions Min         -0.99983495
evaluation/Num Paths           10
evaluation/Average Returns     476.60359377023997
time/data storing (s)          0.032245950773358345
time/evaluation sampling (s)   112.6432068310678
time/exploration sampling (s)  113.50669678114355
time/logging (s)               0.030708670616149902
time/saving (s)                0.012554666958749294
time/training (s)              9.957737617194653
time/epoch (s)                 236.18315051775426
time/total (s)                 111239.52229725942
Epoch                          474
-----------------------------  ---------------------
2023-08-02 00:52:06.190786 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 475 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4280.202]
trainer/QF1 Loss               0.024776544
trainer/QF2 Loss               0.025352404
trainer/Policy Loss            -89.332535
trainer/Q1 Predictions Mean    102.022446
trainer/Q1 Predictions Std     2.157155
trainer/Q1 Predictions Max     103.53378
trainer/Q1 Predictions Min     77.29722
trainer/Q2 Predictions Mean    102.028885
trainer/Q2 Predictions Std     2.2593882
trainer/Q2 Predictions Max     103.52127
trainer/Q2 Predictions Min     76.07059
trainer/Q Targets Mean         102.09827
trainer/Q Targets Std          2.2095668
trainer/Q Targets Max          103.47791
trainer/Q Targets Min          77.35552
trainer/Log Pis Mean           12.774355
trainer/Log Pis Std            9.552392
trainer/Log Pis Max            62.607094
trainer/Log Pis Min            -4.2482805
trainer/Policy mu Mean         -0.031694803
trainer/Policy mu Std          1.677715
trainer/Policy mu Max          7.0267477
trainer/Policy mu Min          -12.265884
trainer/Policy log std Mean    -0.7106154
trainer/Policy log std Std     0.28528163
trainer/Policy log std Max     0.6183516
trainer/Policy log std Min     -1.9265788
trainer/Alpha                  0.0015516576822847128
trainer/Alpha Loss             5.009094715118408
exploration/num steps total    2381000
exploration/num paths total    4762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9552570747411872
exploration/Rewards Std        0.050776532474516065
exploration/Rewards Max        0.9785356175696629
exploration/Rewards Min        0.4958770794111129
exploration/Returns Mean       477.6285373705934
exploration/Returns Std        1.243132895117755
exploration/Returns Max        478.95882320924767
exploration/Returns Min        474.5226656086071
exploration/Actions Mean       0.12518871
exploration/Actions Std        0.6308832
exploration/Actions Max        0.99990714
exploration/Actions Min        -0.9998629
exploration/Num Paths          10
exploration/Average Returns    477.6285373705934
evaluation/num steps total     2380000
evaluation/num paths total     4760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9441639796792739
evaluation/Rewards Std         0.0710301159876803
evaluation/Rewards Max         0.9785344910242495
evaluation/Rewards Min         0.48096155189589107
evaluation/Returns Mean        472.08198983963683
evaluation/Returns Std         19.564911761655225
evaluation/Returns Max         480.31171355075105
evaluation/Returns Min         413.4349508226593
evaluation/ExplReturns Mean    472.08198983963683
evaluation/ExplReturns Std     19.564911761655225
evaluation/ExplReturns Max     480.31171355075105
evaluation/ExplReturns Min     413.4349508226593
evaluation/Actions Mean        0.12534624
evaluation/Actions Std         0.53024703
evaluation/Actions Max         0.99910355
evaluation/Actions Min         -0.9997487
evaluation/Num Paths           10
evaluation/Average Returns     472.08198983963683
time/data storing (s)          0.03218438848853111
time/evaluation sampling (s)   114.03910250030458
time/exploration sampling (s)  113.78281624335796
time/logging (s)               0.030540166422724724
time/saving (s)                0.010313284583389759
time/training (s)              9.632565375417471
time/epoch (s)                 237.52752195857465
time/total (s)                 111477.05271602981
Epoch                          475
-----------------------------  ---------------------
2023-08-02 00:55:59.342834 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 476 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4089.2136]
trainer/QF1 Loss               0.030754194
trainer/QF2 Loss               0.028801747
trainer/Policy Loss            -89.65098
trainer/Q1 Predictions Mean    102.04985
trainer/Q1 Predictions Std     2.309177
trainer/Q1 Predictions Max     103.94309
trainer/Q1 Predictions Min     74.86848
trainer/Q2 Predictions Mean    102.00662
trainer/Q2 Predictions Std     2.2954657
trainer/Q2 Predictions Max     103.83692
trainer/Q2 Predictions Min     74.68438
trainer/Q Targets Mean         102.00061
trainer/Q Targets Std          2.214479
trainer/Q Targets Max          103.77659
trainer/Q Targets Min          76.10164
trainer/Log Pis Mean           12.470242
trainer/Log Pis Std            8.919309
trainer/Log Pis Max            45.314365
trainer/Log Pis Min            -4.2538433
trainer/Policy mu Mean         0.042484235
trainer/Policy mu Std          1.6334788
trainer/Policy mu Max          6.220035
trainer/Policy mu Min          -7.0504966
trainer/Policy log std Mean    -0.70628613
trainer/Policy log std Std     0.27374914
trainer/Policy log std Max     0.08917454
trainer/Policy log std Min     -1.7778851
trainer/Alpha                  0.0014326679520308971
trainer/Alpha Loss             3.079288959503174
exploration/num steps total    2386000
exploration/num paths total    4772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9448498270528762
exploration/Rewards Std        0.061941822277960835
exploration/Rewards Max        0.9795005918146793
exploration/Rewards Min        0.4922660175962766
exploration/Returns Mean       472.424913526438
exploration/Returns Std        3.901356641097425
exploration/Returns Max        476.50555282384767
exploration/Returns Min        466.8185623101232
exploration/Actions Mean       0.1087432
exploration/Actions Std        0.64062065
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.9999555
exploration/Num Paths          10
exploration/Average Returns    472.424913526438
evaluation/num steps total     2385000
evaluation/num paths total     4770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9336117996746605
evaluation/Rewards Std         0.08036355086618349
evaluation/Rewards Max         0.9796123191932447
evaluation/Rewards Min         0.4970259156940234
evaluation/Returns Mean        466.80589983733034
evaluation/Returns Std         29.078939305007705
evaluation/Returns Max         477.9498909481076
evaluation/Returns Min         379.9090589825511
evaluation/ExplReturns Mean    466.80589983733034
evaluation/ExplReturns Std     29.078939305007705
evaluation/ExplReturns Max     477.9498909481076
evaluation/ExplReturns Min     379.9090589825511
evaluation/Actions Mean        0.10629178
evaluation/Actions Std         0.55194074
evaluation/Actions Max         0.99999404
evaluation/Actions Min         -0.9996167
evaluation/Num Paths           10
evaluation/Average Returns     466.80589983733034
time/data storing (s)          0.032372746616601944
time/evaluation sampling (s)   111.74458403605968
time/exploration sampling (s)  111.67119815759361
time/logging (s)               0.030524564906954765
time/saving (s)                0.012709995731711388
time/training (s)              9.654213583096862
time/epoch (s)                 233.14560308400542
time/total (s)                 111710.20081978012
Epoch                          476
-----------------------------  ---------------------
2023-08-02 00:59:51.445488 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 477 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4088.1287]
trainer/QF1 Loss               0.019185202
trainer/QF2 Loss               0.035635345
trainer/Policy Loss            -91.05701
trainer/Q1 Predictions Mean    102.17985
trainer/Q1 Predictions Std     2.3108747
trainer/Q1 Predictions Max     103.804306
trainer/Q1 Predictions Min     73.66831
trainer/Q2 Predictions Mean    102.22869
trainer/Q2 Predictions Std     2.3730693
trainer/Q2 Predictions Max     103.68031
trainer/Q2 Predictions Min     72.59321
trainer/Q Targets Mean         102.11164
trainer/Q Targets Std          2.3124242
trainer/Q Targets Max          103.7542
trainer/Q Targets Min          73.16716
trainer/Log Pis Mean           11.216986
trainer/Log Pis Std            7.7578793
trainer/Log Pis Max            44.75424
trainer/Log Pis Min            -5.463655
trainer/Policy mu Mean         0.022566432
trainer/Policy mu Std          1.5380086
trainer/Policy mu Max          5.2062798
trainer/Policy mu Min          -5.2574778
trainer/Policy log std Mean    -0.7158425
trainer/Policy log std Std     0.2714929
trainer/Policy log std Max     0.016469061
trainer/Policy log std Min     -1.7884567
trainer/Alpha                  0.0014620684087276459
trainer/Alpha Loss             -5.111249923706055
exploration/num steps total    2391000
exploration/num paths total    4782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9593087803156445
exploration/Rewards Std        0.052878002168282236
exploration/Rewards Max        0.9794293856578209
exploration/Rewards Min        0.4926440381850512
exploration/Returns Mean       479.65439015782215
exploration/Returns Std        1.745638545584261
exploration/Returns Max        481.4497785437707
exploration/Returns Min        475.3789585161225
exploration/Actions Mean       0.02670217
exploration/Actions Std        0.58888096
exploration/Actions Max        0.9998254
exploration/Actions Min        -0.9999727
exploration/Num Paths          10
exploration/Average Returns    479.65439015782215
evaluation/num steps total     2390000
evaluation/num paths total     4780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9640038777227008
evaluation/Rewards Std         0.047765554277003325
evaluation/Rewards Max         0.9781992874710413
evaluation/Rewards Min         0.5005458807802924
evaluation/Returns Mean        482.0019388613503
evaluation/Returns Std         0.5554741416998333
evaluation/Returns Max         482.8089772206289
evaluation/Returns Min         480.7366930518375
evaluation/ExplReturns Mean    482.0019388613503
evaluation/ExplReturns Std     0.5554741416998333
evaluation/ExplReturns Max     482.8089772206289
evaluation/ExplReturns Min     480.7366930518375
evaluation/Actions Mean        0.017550297
evaluation/Actions Std         0.47055736
evaluation/Actions Max         0.99997973
evaluation/Actions Min         -0.9994366
evaluation/Num Paths           10
evaluation/Average Returns     482.0019388613503
time/data storing (s)          0.03261533007025719
time/evaluation sampling (s)   111.21106056962162
time/exploration sampling (s)  111.17375712655485
time/logging (s)               0.031108534894883633
time/saving (s)                0.012995599769055843
time/training (s)              9.635167217813432
time/epoch (s)                 232.0967043787241
time/total (s)                 111942.30004733894
Epoch                          477
-----------------------------  ---------------------
2023-08-02 01:03:46.711244 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 478 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4228.045]
trainer/QF1 Loss               0.021022541
trainer/QF2 Loss               0.024419008
trainer/Policy Loss            -89.70105
trainer/Q1 Predictions Mean    101.73812
trainer/Q1 Predictions Std     4.0483737
trainer/Q1 Predictions Max     103.49502
trainer/Q1 Predictions Min     66.66754
trainer/Q2 Predictions Mean    101.71385
trainer/Q2 Predictions Std     4.0393686
trainer/Q2 Predictions Max     103.43291
trainer/Q2 Predictions Min     67.05636
trainer/Q Targets Mean         101.69676
trainer/Q Targets Std          4.0241985
trainer/Q Targets Max          103.47141
trainer/Q Targets Min          67.42834
trainer/Log Pis Mean           12.116767
trainer/Log Pis Std            8.817208
trainer/Log Pis Max            51.770405
trainer/Log Pis Min            -5.7156935
trainer/Policy mu Mean         -0.031419974
trainer/Policy mu Std          1.6305957
trainer/Policy mu Max          6.864192
trainer/Policy mu Min          -7.4379897
trainer/Policy log std Mean    -0.69992757
trainer/Policy log std Std     0.28182453
trainer/Policy log std Max     0.2184161
trainer/Policy log std Min     -1.7938408
trainer/Alpha                  0.0014977370155975223
trainer/Alpha Loss             0.7594665884971619
exploration/num steps total    2396000
exploration/num paths total    4792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9598890219391107
exploration/Rewards Std        0.05168723374178076
exploration/Rewards Max        0.9799466459247184
exploration/Rewards Min        0.4943264726557541
exploration/Returns Mean       479.94451096955544
exploration/Returns Std        1.3472372618445474
exploration/Returns Max        481.53799166382623
exploration/Returns Min        477.2219153710359
exploration/Actions Mean       0.024659542
exploration/Actions Std        0.61675453
exploration/Actions Max        0.99996376
exploration/Actions Min        -0.99999744
exploration/Num Paths          10
exploration/Average Returns    479.94451096955544
evaluation/num steps total     2395000
evaluation/num paths total     4790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9594924614639105
evaluation/Rewards Std         0.05586040956673937
evaluation/Rewards Max         0.9799289621511967
evaluation/Rewards Min         0.49790384540989496
evaluation/Returns Mean        479.7462307319553
evaluation/Returns Std         0.9789709872480696
evaluation/Returns Max         481.38770323516974
evaluation/Returns Min         478.16127672092915
evaluation/ExplReturns Mean    479.7462307319553
evaluation/ExplReturns Std     0.9789709872480696
evaluation/ExplReturns Max     481.38770323516974
evaluation/ExplReturns Min     478.16127672092915
evaluation/Actions Mean        0.0359501
evaluation/Actions Std         0.50431246
evaluation/Actions Max         0.99883103
evaluation/Actions Min         -0.9991784
evaluation/Num Paths           10
evaluation/Average Returns     479.7462307319553
time/data storing (s)          0.03227148577570915
time/evaluation sampling (s)   113.20942762866616
time/exploration sampling (s)  112.51838905829936
time/logging (s)               0.030559873208403587
time/saving (s)                0.010280251502990723
time/training (s)              9.457775367423892
time/epoch (s)                 235.25870366487652
time/total (s)                 112177.56131716538
Epoch                          478
-----------------------------  ---------------------
2023-08-02 01:07:40.866566 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 479 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4079.029]
trainer/QF1 Loss               0.056923695
trainer/QF2 Loss               0.053081922
trainer/Policy Loss            -89.29856
trainer/Q1 Predictions Mean    101.69656
trainer/Q1 Predictions Std     2.4022815
trainer/Q1 Predictions Max     103.979225
trainer/Q1 Predictions Min     77.70014
trainer/Q2 Predictions Mean    101.76102
trainer/Q2 Predictions Std     2.4439702
trainer/Q2 Predictions Max     103.90592
trainer/Q2 Predictions Min     76.7835
trainer/Q Targets Mean         101.82707
trainer/Q Targets Std          2.3938146
trainer/Q Targets Max          104.05508
trainer/Q Targets Min          78.133705
trainer/Log Pis Mean           12.512404
trainer/Log Pis Std            8.684133
trainer/Log Pis Max            49.863163
trainer/Log Pis Min            -4.289439
trainer/Policy mu Mean         -0.016148554
trainer/Policy mu Std          1.6386777
trainer/Policy mu Max          7.893611
trainer/Policy mu Min          -7.61308
trainer/Policy log std Mean    -0.7044603
trainer/Policy log std Std     0.27218723
trainer/Policy log std Max     0.7322334
trainer/Policy log std Min     -2.3961582
trainer/Alpha                  0.0015098144067451358
trainer/Alpha Loss             3.328467607498169
exploration/num steps total    2401000
exploration/num paths total    4802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9540111456653402
exploration/Rewards Std        0.05195560083931101
exploration/Rewards Max        0.9786049485861963
exploration/Rewards Min        0.49377068117545264
exploration/Returns Mean       477.0055728326703
exploration/Returns Std        3.272851443561965
exploration/Returns Max        479.2647392089065
exploration/Returns Min        468.19952392429946
exploration/Actions Mean       0.038995482
exploration/Actions Std        0.60555506
exploration/Actions Max        0.9999253
exploration/Actions Min        -0.999998
exploration/Num Paths          10
exploration/Average Returns    477.0055728326703
evaluation/num steps total     2400000
evaluation/num paths total     4800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9582773137161233
evaluation/Rewards Std         0.0484406196060864
evaluation/Rewards Max         0.9794337063315949
evaluation/Rewards Min         0.4964553113804199
evaluation/Returns Mean        479.13865685806167
evaluation/Returns Std         1.1215199161424447
evaluation/Returns Max         479.74041594777503
evaluation/Returns Min         475.83136203577544
evaluation/ExplReturns Mean    479.13865685806167
evaluation/ExplReturns Std     1.1215199161424447
evaluation/ExplReturns Max     479.74041594777503
evaluation/ExplReturns Min     475.83136203577544
evaluation/Actions Mean        0.03364571
evaluation/Actions Std         0.497563
evaluation/Actions Max         0.99802727
evaluation/Actions Min         -0.99971694
evaluation/Num Paths           10
evaluation/Average Returns     479.13865685806167
time/data storing (s)          0.03211366478353739
time/evaluation sampling (s)   111.81126888561994
time/exploration sampling (s)  112.55367104988545
time/logging (s)               0.030652595683932304
time/saving (s)                0.012725051492452621
time/training (s)              9.708574111573398
time/epoch (s)                 234.1490053590387
time/total (s)                 112411.71278606262
Epoch                          479
-----------------------------  ---------------------
2023-08-02 01:11:37.963292 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 480 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3985.9902]
trainer/QF1 Loss               0.020546611
trainer/QF2 Loss               0.02462571
trainer/Policy Loss            -88.77068
trainer/Q1 Predictions Mean    101.69773
trainer/Q1 Predictions Std     3.2458785
trainer/Q1 Predictions Max     104.385345
trainer/Q1 Predictions Min     72.50023
trainer/Q2 Predictions Mean    101.626724
trainer/Q2 Predictions Std     3.289283
trainer/Q2 Predictions Max     104.22323
trainer/Q2 Predictions Min     71.46181
trainer/Q Targets Mean         101.65166
trainer/Q Targets Std          3.2380774
trainer/Q Targets Max          104.19453
trainer/Q Targets Min          72.56537
trainer/Log Pis Mean           12.978295
trainer/Log Pis Std            9.7097
trainer/Log Pis Max            63.962433
trainer/Log Pis Min            -4.3618817
trainer/Policy mu Mean         0.021240758
trainer/Policy mu Std          1.6873019
trainer/Policy mu Max          12.081547
trainer/Policy mu Min          -8.414
trainer/Policy log std Mean    -0.7171057
trainer/Policy log std Std     0.27327156
trainer/Policy log std Max     0.77775633
trainer/Policy log std Min     -1.7632306
trainer/Alpha                  0.0015129507519304752
trainer/Alpha Loss             6.352818489074707
exploration/num steps total    2406000
exploration/num paths total    4812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.942701787982351
exploration/Rewards Std        0.05589956468445358
exploration/Rewards Max        0.9776174819788501
exploration/Rewards Min        0.49514682350381567
exploration/Returns Mean       471.3508939911755
exploration/Returns Std        2.91121701744267
exploration/Returns Max        474.75353363455605
exploration/Returns Min        464.0184337240005
exploration/Actions Mean       0.020209247
exploration/Actions Std        0.6325253
exploration/Actions Max        0.99999076
exploration/Actions Min        -0.99998814
exploration/Num Paths          10
exploration/Average Returns    471.3508939911755
evaluation/num steps total     2405000
evaluation/num paths total     4810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9461103758593851
evaluation/Rewards Std         0.051523879918192926
evaluation/Rewards Max         0.9758615574067175
evaluation/Rewards Min         0.49714101475598904
evaluation/Returns Mean        473.05518792969235
evaluation/Returns Std         1.6357210323516855
evaluation/Returns Max         474.78950271885964
evaluation/Returns Min         470.1651448177498
evaluation/ExplReturns Mean    473.05518792969235
evaluation/ExplReturns Std     1.6357210323516855
evaluation/ExplReturns Max     474.78950271885964
evaluation/ExplReturns Min     470.1651448177498
evaluation/Actions Mean        0.019911565
evaluation/Actions Std         0.5246188
evaluation/Actions Max         0.9994973
evaluation/Actions Min         -0.99993765
evaluation/Num Paths           10
evaluation/Average Returns     473.05518792969235
time/data storing (s)          0.03224066086113453
time/evaluation sampling (s)   114.55961647164077
time/exploration sampling (s)  112.8570944564417
time/logging (s)               0.030510583892464638
time/saving (s)                0.02318645268678665
time/training (s)              9.587458786554635
time/epoch (s)                 237.0901074120775
time/total (s)                 112648.80541095324
Epoch                          480
-----------------------------  ---------------------
2023-08-02 01:15:31.099560 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 481 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3962.6685]
trainer/QF1 Loss               0.024814814
trainer/QF2 Loss               0.02028704
trainer/Policy Loss            -89.06761
trainer/Q1 Predictions Mean    101.61111
trainer/Q1 Predictions Std     3.6581066
trainer/Q1 Predictions Max     104.01661
trainer/Q1 Predictions Min     68.53134
trainer/Q2 Predictions Mean    101.73886
trainer/Q2 Predictions Std     3.6913025
trainer/Q2 Predictions Max     104.09046
trainer/Q2 Predictions Min     67.79014
trainer/Q Targets Mean         101.70475
trainer/Q Targets Std          3.6554039
trainer/Q Targets Max          104.14474
trainer/Q Targets Min          68.63754
trainer/Log Pis Mean           12.665432
trainer/Log Pis Std            9.261359
trainer/Log Pis Max            78.9638
trainer/Log Pis Min            -3.7214584
trainer/Policy mu Mean         -0.09274954
trainer/Policy mu Std          1.6551878
trainer/Policy mu Max          7.849855
trainer/Policy mu Min          -10.125679
trainer/Policy log std Mean    -0.6932526
trainer/Policy log std Std     0.27341694
trainer/Policy log std Max     0.90344
trainer/Policy log std Min     -2.0217204
trainer/Alpha                  0.0014824048848822713
trainer/Alpha Loss             4.334783554077148
exploration/num steps total    2411000
exploration/num paths total    4822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9434556010185204
exploration/Rewards Std        0.05720829568400722
exploration/Rewards Max        0.9794461763650377
exploration/Rewards Min        0.49839371752324224
exploration/Returns Mean       471.7278005092603
exploration/Returns Std        4.138584673607488
exploration/Returns Max        474.8199338687484
exploration/Returns Min        461.68860031021114
exploration/Actions Mean       0.024095789
exploration/Actions Std        0.60967493
exploration/Actions Max        0.9999986
exploration/Actions Min        -0.9998442
exploration/Num Paths          10
exploration/Average Returns    471.7278005092603
evaluation/num steps total     2410000
evaluation/num paths total     4820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9455076849210529
evaluation/Rewards Std         0.05173413838836565
evaluation/Rewards Max         0.9776451357620645
evaluation/Rewards Min         0.4948683739491395
evaluation/Returns Mean        472.7538424605265
evaluation/Returns Std         3.3827486814312384
evaluation/Returns Max         479.19735850096714
evaluation/Returns Min         464.7774526105493
evaluation/ExplReturns Mean    472.7538424605265
evaluation/ExplReturns Std     3.3827486814312384
evaluation/ExplReturns Max     479.19735850096714
evaluation/ExplReturns Min     464.7774526105493
evaluation/Actions Mean        0.009612647
evaluation/Actions Std         0.51014763
evaluation/Actions Max         0.9999628
evaluation/Actions Min         -0.9999199
evaluation/Num Paths           10
evaluation/Average Returns     472.7538424605265
time/data storing (s)          0.03240833804011345
time/evaluation sampling (s)   110.78586271964014
time/exploration sampling (s)  112.01785766985267
time/logging (s)               0.031362987123429775
time/saving (s)                0.012956973165273666
time/training (s)              10.249755403958261
time/epoch (s)                 233.1302040917799
time/total (s)                 112881.93851305917
Epoch                          481
-----------------------------  ---------------------
2023-08-02 01:19:29.025949 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 482 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3695.4285]
trainer/QF1 Loss               0.030079087
trainer/QF2 Loss               0.03029668
trainer/Policy Loss            -89.9863
trainer/Q1 Predictions Mean    101.81574
trainer/Q1 Predictions Std     3.595418
trainer/Q1 Predictions Max     104.42265
trainer/Q1 Predictions Min     65.662285
trainer/Q2 Predictions Mean    101.75874
trainer/Q2 Predictions Std     3.567506
trainer/Q2 Predictions Max     104.378876
trainer/Q2 Predictions Min     66.486626
trainer/Q Targets Mean         101.78038
trainer/Q Targets Std          3.5388548
trainer/Q Targets Max          104.37797
trainer/Q Targets Min          66.25592
trainer/Log Pis Mean           11.882545
trainer/Log Pis Std            7.4392486
trainer/Log Pis Max            43.16816
trainer/Log Pis Min            -2.8240795
trainer/Policy mu Mean         -0.11842982
trainer/Policy mu Std          1.6201867
trainer/Policy mu Max          7.1514187
trainer/Policy mu Min          -8.126626
trainer/Policy log std Mean    -0.6850398
trainer/Policy log std Std     0.2616376
trainer/Policy log std Max     1.1441693
trainer/Policy log std Min     -1.8950466
trainer/Alpha                  0.001623412361368537
trainer/Alpha Loss             -0.7544221878051758
exploration/num steps total    2416000
exploration/num paths total    4832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9493021108399724
exploration/Rewards Std        0.05357733632349223
exploration/Rewards Max        0.9785725409758705
exploration/Rewards Min        0.48701671458778484
exploration/Returns Mean       474.65105541998616
exploration/Returns Std        4.277394627564412
exploration/Returns Max        477.39509888499373
exploration/Returns Min        462.1152015356296
exploration/Actions Mean       -0.0016592247
exploration/Actions Std        0.6855545
exploration/Actions Max        0.9999481
exploration/Actions Min        -0.99991703
exploration/Num Paths          10
exploration/Average Returns    474.65105541998616
evaluation/num steps total     2415000
evaluation/num paths total     4830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9518121837579648
evaluation/Rewards Std         0.047183563379306986
evaluation/Rewards Max         0.9765995421365798
evaluation/Rewards Min         0.4963980347295814
evaluation/Returns Mean        475.90609187898247
evaluation/Returns Std         0.8244736141203616
evaluation/Returns Max         477.3982450657407
evaluation/Returns Min         474.7453191356981
evaluation/ExplReturns Mean    475.90609187898247
evaluation/ExplReturns Std     0.8244736141203616
evaluation/ExplReturns Max     477.3982450657407
evaluation/ExplReturns Min     474.7453191356981
evaluation/Actions Mean        -0.0012663605
evaluation/Actions Std         0.6551617
evaluation/Actions Max         0.9993072
evaluation/Actions Min         -0.99961483
evaluation/Num Paths           10
evaluation/Average Returns     475.90609187898247
time/data storing (s)          0.03225701302289963
time/evaluation sampling (s)   113.98578200582415
time/exploration sampling (s)  114.2692742254585
time/logging (s)               0.03087687399238348
time/saving (s)                0.011117802932858467
time/training (s)              9.590078578330576
time/epoch (s)                 237.91938649956137
time/total (s)                 113119.86039821804
Epoch                          482
-----------------------------  --------------------
2023-08-02 01:23:21.603032 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 483 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3692.767]
trainer/QF1 Loss               0.02904537
trainer/QF2 Loss               0.027445747
trainer/Policy Loss            -90.424126
trainer/Q1 Predictions Mean    101.79353
trainer/Q1 Predictions Std     2.371852
trainer/Q1 Predictions Max     103.85962
trainer/Q1 Predictions Min     81.25801
trainer/Q2 Predictions Mean    101.82681
trainer/Q2 Predictions Std     2.3594317
trainer/Q2 Predictions Max     104.02702
trainer/Q2 Predictions Min     81.32269
trainer/Q Targets Mean         101.913315
trainer/Q Targets Std          2.3731408
trainer/Q Targets Max          104.02602
trainer/Q Targets Min          81.57539
trainer/Log Pis Mean           11.485876
trainer/Log Pis Std            8.487943
trainer/Log Pis Max            56.346664
trainer/Log Pis Min            -5.4191957
trainer/Policy mu Mean         -0.11962444
trainer/Policy mu Std          1.5805696
trainer/Policy mu Max          4.952884
trainer/Policy mu Min          -7.850934
trainer/Policy log std Mean    -0.71620864
trainer/Policy log std Std     0.26229632
trainer/Policy log std Max     0.08628458
trainer/Policy log std Min     -1.7342081
trainer/Alpha                  0.0015667197294533253
trainer/Alpha Loss             -3.3205723762512207
exploration/num steps total    2421000
exploration/num paths total    4842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9512274127746958
exploration/Rewards Std        0.05189752625644474
exploration/Rewards Max        0.9788061069484816
exploration/Rewards Min        0.49451456182355663
exploration/Returns Mean       475.61370638734786
exploration/Returns Std        3.3011025351678405
exploration/Returns Max        479.309174536211
exploration/Returns Min        470.3615088773678
exploration/Actions Mean       0.025643019
exploration/Actions Std        0.5931215
exploration/Actions Max        0.9999632
exploration/Actions Min        -0.9999401
exploration/Num Paths          10
exploration/Average Returns    475.61370638734786
evaluation/num steps total     2420000
evaluation/num paths total     4840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9473121691492599
evaluation/Rewards Std         0.053177620881497266
evaluation/Rewards Max         0.9778739630145665
evaluation/Rewards Min         0.48765561008219543
evaluation/Returns Mean        473.65608457462986
evaluation/Returns Std         4.024216011662559
evaluation/Returns Max         479.68253643732237
evaluation/Returns Min         468.90095981195003
evaluation/ExplReturns Mean    473.65608457462986
evaluation/ExplReturns Std     4.024216011662559
evaluation/ExplReturns Max     479.68253643732237
evaluation/ExplReturns Min     468.90095981195003
evaluation/Actions Mean        0.037841816
evaluation/Actions Std         0.4905388
evaluation/Actions Max         0.99998164
evaluation/Actions Min         -0.9995428
evaluation/Num Paths           10
evaluation/Average Returns     473.65608457462986
time/data storing (s)          0.03220717702060938
time/evaluation sampling (s)   111.4882780732587
time/exploration sampling (s)  111.38237886875868
time/logging (s)               0.030412090942263603
time/saving (s)                0.010475018061697483
time/training (s)              9.626362796872854
time/epoch (s)                 232.5701140249148
time/total (s)                 113352.43302797806
Epoch                          483
-----------------------------  ---------------------
2023-08-02 01:27:14.484194 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 484 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3596.7717]
trainer/QF1 Loss               0.027343791
trainer/QF2 Loss               0.037895348
trainer/Policy Loss            -90.1557
trainer/Q1 Predictions Mean    101.86957
trainer/Q1 Predictions Std     2.4593592
trainer/Q1 Predictions Max     103.56635
trainer/Q1 Predictions Min     73.64592
trainer/Q2 Predictions Mean    101.80701
trainer/Q2 Predictions Std     2.4857216
trainer/Q2 Predictions Max     103.528885
trainer/Q2 Predictions Min     72.283585
trainer/Q Targets Mean         101.911934
trainer/Q Targets Std          2.4840665
trainer/Q Targets Max          103.61971
trainer/Q Targets Min          72.66784
trainer/Log Pis Mean           11.766014
trainer/Log Pis Std            7.953375
trainer/Log Pis Max            50.676018
trainer/Log Pis Min            -5.4572115
trainer/Policy mu Mean         -0.19061178
trainer/Policy mu Std          1.5919069
trainer/Policy mu Max          7.236243
trainer/Policy mu Min          -7.0448437
trainer/Policy log std Mean    -0.6926234
trainer/Policy log std Std     0.2633208
trainer/Policy log std Max     0.2845887
trainer/Policy log std Min     -2.291434
trainer/Alpha                  0.0015478084096685052
trainer/Alpha Loss             -1.5141234397888184
exploration/num steps total    2426000
exploration/num paths total    4852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.89551175213568
exploration/Rewards Std        0.10070453066259467
exploration/Rewards Max        0.9789007439379518
exploration/Rewards Min        0.49262442559238323
exploration/Returns Mean       447.75587606783984
exploration/Returns Std        19.869325902208097
exploration/Returns Max        474.02819537325166
exploration/Returns Min        408.1850660795565
exploration/Actions Mean       0.037619762
exploration/Actions Std        0.60125345
exploration/Actions Max        0.9999685
exploration/Actions Min        -0.99997824
exploration/Num Paths          10
exploration/Average Returns    447.75587606783984
evaluation/num steps total     2425000
evaluation/num paths total     4850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8763252685092157
evaluation/Rewards Std         0.11039126920029946
evaluation/Rewards Max         0.9777781358536926
evaluation/Rewards Min         0.5027307502790962
evaluation/Returns Mean        438.16263425460795
evaluation/Returns Std         32.714434471863484
evaluation/Returns Max         477.1985495095263
evaluation/Returns Min         396.2625374145762
evaluation/ExplReturns Mean    438.16263425460795
evaluation/ExplReturns Std     32.714434471863484
evaluation/ExplReturns Max     477.1985495095263
evaluation/ExplReturns Min     396.2625374145762
evaluation/Actions Mean        0.029049486
evaluation/Actions Std         0.52850115
evaluation/Actions Max         0.99995226
evaluation/Actions Min         -0.99998146
evaluation/Num Paths           10
evaluation/Average Returns     438.16263425460795
time/data storing (s)          0.03215818386524916
time/evaluation sampling (s)   111.63770687673241
time/exploration sampling (s)  111.52447167318314
time/logging (s)               0.030441608279943466
time/saving (s)                0.0102037088945508
time/training (s)              9.639796960167587
time/epoch (s)                 232.87477901112288
time/total (s)                 113585.3102611471
Epoch                          484
-----------------------------  ---------------------
2023-08-02 01:31:07.654902 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 485 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3483.1753]
trainer/QF1 Loss               0.031875633
trainer/QF2 Loss               0.026011702
trainer/Policy Loss            -90.15341
trainer/Q1 Predictions Mean    101.640465
trainer/Q1 Predictions Std     3.504456
trainer/Q1 Predictions Max     103.89334
trainer/Q1 Predictions Min     66.431076
trainer/Q2 Predictions Mean    101.63138
trainer/Q2 Predictions Std     3.4624293
trainer/Q2 Predictions Max     103.905266
trainer/Q2 Predictions Min     66.90238
trainer/Q Targets Mean         101.70955
trainer/Q Targets Std          3.5057971
trainer/Q Targets Max          103.93454
trainer/Q Targets Min          66.652176
trainer/Log Pis Mean           11.5680895
trainer/Log Pis Std            9.092678
trainer/Log Pis Max            61.337093
trainer/Log Pis Min            -4.1617374
trainer/Policy mu Mean         -0.12990953
trainer/Policy mu Std          1.5976096
trainer/Policy mu Max          7.86201
trainer/Policy mu Min          -8.518813
trainer/Policy log std Mean    -0.7243111
trainer/Policy log std Std     0.28855956
trainer/Policy log std Max     0.647811
trainer/Policy log std Min     -2.3882008
trainer/Alpha                  0.001456850441172719
trainer/Alpha Loss             -2.8209595680236816
exploration/num steps total    2431000
exploration/num paths total    4862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9539066274645027
exploration/Rewards Std        0.04962557198681328
exploration/Rewards Max        0.9778280090611835
exploration/Rewards Min        0.49166454502422036
exploration/Returns Mean       476.95331373225144
exploration/Returns Std        0.6491006994923088
exploration/Returns Max        478.4599987391553
exploration/Returns Min        476.1483173473079
exploration/Actions Mean       0.09727598
exploration/Actions Std        0.6421253
exploration/Actions Max        0.9999642
exploration/Actions Min        -0.9999705
exploration/Num Paths          10
exploration/Average Returns    476.95331373225144
evaluation/num steps total     2430000
evaluation/num paths total     4860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9488323097822229
evaluation/Rewards Std         0.04620475127157327
evaluation/Rewards Max         0.978481329377455
evaluation/Rewards Min         0.48944047037746
evaluation/Returns Mean        474.4161548911114
evaluation/Returns Std         0.49407250589274476
evaluation/Returns Max         475.65151900466
evaluation/Returns Min         473.91162501378096
evaluation/ExplReturns Mean    474.4161548911114
evaluation/ExplReturns Std     0.49407250589274476
evaluation/ExplReturns Max     475.65151900466
evaluation/ExplReturns Min     473.91162501378096
evaluation/Actions Mean        -0.031491313
evaluation/Actions Std         0.45253575
evaluation/Actions Max         0.99763656
evaluation/Actions Min         -0.99977314
evaluation/Num Paths           10
evaluation/Average Returns     474.4161548911114
time/data storing (s)          0.032282072119414806
time/evaluation sampling (s)   111.2393037835136
time/exploration sampling (s)  112.19936521165073
time/logging (s)               0.030123080126941204
time/saving (s)                0.010587824508547783
time/training (s)              9.652253421023488
time/epoch (s)                 233.16391539294273
time/total (s)                 113818.4766486343
Epoch                          485
-----------------------------  --------------------
2023-08-02 01:35:01.247199 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 486 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3547.3115]
trainer/QF1 Loss               0.017542921
trainer/QF2 Loss               0.023329552
trainer/Policy Loss            -90.38903
trainer/Q1 Predictions Mean    101.90456
trainer/Q1 Predictions Std     2.1033785
trainer/Q1 Predictions Max     103.80622
trainer/Q1 Predictions Min     77.95232
trainer/Q2 Predictions Mean    101.973434
trainer/Q2 Predictions Std     2.1245124
trainer/Q2 Predictions Max     103.885796
trainer/Q2 Predictions Min     77.47276
trainer/Q Targets Mean         101.86946
trainer/Q Targets Std          2.11602
trainer/Q Targets Max          103.858055
trainer/Q Targets Min          77.486435
trainer/Log Pis Mean           11.602945
trainer/Log Pis Std            8.431435
trainer/Log Pis Max            47.28526
trainer/Log Pis Min            -4.9047966
trainer/Policy mu Mean         -0.09866938
trainer/Policy mu Std          1.6000662
trainer/Policy mu Max          6.295362
trainer/Policy mu Min          -4.124212
trainer/Policy log std Mean    -0.6926449
trainer/Policy log std Std     0.26988837
trainer/Policy log std Max     0.13020366
trainer/Policy log std Min     -1.6965919
trainer/Alpha                  0.0014981605345383286
trainer/Alpha Loss             -2.582138776779175
exploration/num steps total    2436000
exploration/num paths total    4872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9089406511611702
exploration/Rewards Std        0.09005376478386057
exploration/Rewards Max        0.9769228373760868
exploration/Rewards Min        0.4926901035636137
exploration/Returns Mean       454.470325580585
exploration/Returns Std        9.810283745836047
exploration/Returns Max        476.5136156720109
exploration/Returns Min        444.8732610997496
exploration/Actions Mean       -0.010562804
exploration/Actions Std        0.60801476
exploration/Actions Max        0.99992657
exploration/Actions Min        -0.99994814
exploration/Num Paths          10
exploration/Average Returns    454.470325580585
evaluation/num steps total     2435000
evaluation/num paths total     4870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8896853535809227
evaluation/Rewards Std         0.09858968611544629
evaluation/Rewards Max         0.9741299242085764
evaluation/Rewards Min         0.479258731573982
evaluation/Returns Mean        444.84267679046127
evaluation/Returns Std         12.742656814801993
evaluation/Returns Max         475.0628847997396
evaluation/Returns Min         423.9666036346186
evaluation/ExplReturns Mean    444.84267679046127
evaluation/ExplReturns Std     12.742656814801993
evaluation/ExplReturns Max     475.0628847997396
evaluation/ExplReturns Min     423.9666036346186
evaluation/Actions Mean        -0.0035820699
evaluation/Actions Std         0.38998044
evaluation/Actions Max         0.9987763
evaluation/Actions Min         -0.99973875
evaluation/Num Paths           10
evaluation/Average Returns     444.84267679046127
time/data storing (s)          0.03227927163243294
time/evaluation sampling (s)   112.00766951497644
time/exploration sampling (s)  111.90153319668025
time/logging (s)               0.03100971318781376
time/saving (s)                0.012781097553670406
time/training (s)              9.601357717998326
time/epoch (s)                 233.58663051202893
time/total (s)                 114052.06578298844
Epoch                          486
-----------------------------  ---------------------
2023-08-02 01:38:55.079030 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 487 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3789.9353]
trainer/QF1 Loss               0.029724509
trainer/QF2 Loss               0.028999101
trainer/Policy Loss            -89.640114
trainer/Q1 Predictions Mean    101.732
trainer/Q1 Predictions Std     1.8894219
trainer/Q1 Predictions Max     103.82201
trainer/Q1 Predictions Min     87.196686
trainer/Q2 Predictions Mean    101.80804
trainer/Q2 Predictions Std     1.8974084
trainer/Q2 Predictions Max     104.02842
trainer/Q2 Predictions Min     87.23799
trainer/Q Targets Mean         101.80554
trainer/Q Targets Std          1.9106784
trainer/Q Targets Max          104.00416
trainer/Q Targets Min          86.49842
trainer/Log Pis Mean           12.191908
trainer/Log Pis Std            8.237182
trainer/Log Pis Max            52.820545
trainer/Log Pis Min            -0.06664848
trainer/Policy mu Mean         -0.0058102743
trainer/Policy mu Std          1.6256827
trainer/Policy mu Max          6.0526867
trainer/Policy mu Min          -5.8448515
trainer/Policy log std Mean    -0.6785925
trainer/Policy log std Std     0.26580173
trainer/Policy log std Max     0.32233602
trainer/Policy log std Min     -1.6067457
trainer/Alpha                  0.0015983701450750232
trainer/Alpha Loss             1.2356600761413574
exploration/num steps total    2441000
exploration/num paths total    4882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9453659264574661
exploration/Rewards Std        0.05740286975395349
exploration/Rewards Max        0.9771880447769208
exploration/Rewards Min        0.4901397360871313
exploration/Returns Mean       472.682963228733
exploration/Returns Std        1.4782844506884714
exploration/Returns Max        475.5219155984949
exploration/Returns Min        470.49087243664405
exploration/Actions Mean       0.015560719
exploration/Actions Std        0.631506
exploration/Actions Max        0.99994105
exploration/Actions Min        -0.99991095
exploration/Num Paths          10
exploration/Average Returns    472.682963228733
evaluation/num steps total     2440000
evaluation/num paths total     4880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9515073708304033
evaluation/Rewards Std         0.0475423030801134
evaluation/Rewards Max         0.9759669592932054
evaluation/Rewards Min         0.4918675986650894
evaluation/Returns Mean        475.7536854152016
evaluation/Returns Std         0.458551974855474
evaluation/Returns Max         476.36673361682875
evaluation/Returns Min         474.84285729563123
evaluation/ExplReturns Mean    475.7536854152016
evaluation/ExplReturns Std     0.458551974855474
evaluation/ExplReturns Max     476.36673361682875
evaluation/ExplReturns Min     474.84285729563123
evaluation/Actions Mean        0.009443367
evaluation/Actions Std         0.4622872
evaluation/Actions Max         0.9983243
evaluation/Actions Min         -0.9996227
evaluation/Num Paths           10
evaluation/Average Returns     475.7536854152016
time/data storing (s)          0.032374572940170765
time/evaluation sampling (s)   112.30457192100585
time/exploration sampling (s)  111.89926522132009
time/logging (s)               0.030908627435564995
time/saving (s)                0.01228116825222969
time/training (s)              9.545797487720847
time/epoch (s)                 233.82519899867475
time/total (s)                 114285.89346508868
Epoch                          487
-----------------------------  ---------------------
2023-08-02 01:42:47.754322 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 488 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3637.01]
trainer/QF1 Loss               0.0252998
trainer/QF2 Loss               0.022975236
trainer/Policy Loss            -89.847565
trainer/Q1 Predictions Mean    101.72489
trainer/Q1 Predictions Std     1.9415662
trainer/Q1 Predictions Max     104.04572
trainer/Q1 Predictions Min     88.64653
trainer/Q2 Predictions Mean    101.82091
trainer/Q2 Predictions Std     1.9484445
trainer/Q2 Predictions Max     104.05375
trainer/Q2 Predictions Min     88.61009
trainer/Q Targets Mean         101.81496
trainer/Q Targets Std          1.9560078
trainer/Q Targets Max          104.122086
trainer/Q Targets Min          88.59699
trainer/Log Pis Mean           11.9931555
trainer/Log Pis Std            7.736376
trainer/Log Pis Max            52.435127
trainer/Log Pis Min            -2.7261176
trainer/Policy mu Mean         -0.045166906
trainer/Policy mu Std          1.6175528
trainer/Policy mu Max          7.079382
trainer/Policy mu Min          -6.3172455
trainer/Policy log std Mean    -0.7105084
trainer/Policy log std Std     0.27831012
trainer/Policy log std Max     0.08448711
trainer/Policy log std Min     -1.7789947
trainer/Alpha                  0.0015250962460413575
trainer/Alpha Loss             -0.04439043998718262
exploration/num steps total    2446000
exploration/num paths total    4892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.95643417257795
exploration/Rewards Std        0.051370698586999664
exploration/Rewards Max        0.9797258761033194
exploration/Rewards Min        0.4886139605211053
exploration/Returns Mean       478.21708628897494
exploration/Returns Std        0.913075917591064
exploration/Returns Max        479.70666376262596
exploration/Returns Min        476.68137658536847
exploration/Actions Mean       0.018704893
exploration/Actions Std        0.6070529
exploration/Actions Max        0.99998945
exploration/Actions Min        -0.9999535
exploration/Num Paths          10
exploration/Average Returns    478.21708628897494
evaluation/num steps total     2445000
evaluation/num paths total     4890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9599083283510654
evaluation/Rewards Std         0.04863494847325291
evaluation/Rewards Max         0.9795154299775142
evaluation/Rewards Min         0.48921223804503955
evaluation/Returns Mean        479.9541641755327
evaluation/Returns Std         2.0316270133242624
evaluation/Returns Max         481.78062475009284
evaluation/Returns Min         476.70714462400105
evaluation/ExplReturns Mean    479.9541641755327
evaluation/ExplReturns Std     2.0316270133242624
evaluation/ExplReturns Max     481.78062475009284
evaluation/ExplReturns Min     476.70714462400105
evaluation/Actions Mean        0.0108120935
evaluation/Actions Std         0.43346867
evaluation/Actions Max         0.99867576
evaluation/Actions Min         -0.9994898
evaluation/Num Paths           10
evaluation/Average Returns     479.9541641755327
time/data storing (s)          0.03212050627917051
time/evaluation sampling (s)   111.75537777412683
time/exploration sampling (s)  111.77390427142382
time/logging (s)               0.030572454445064068
time/saving (s)                0.0119466632604599
time/training (s)              9.064540838822722
time/epoch (s)                 232.66846250835806
time/total (s)                 114518.56441904418
Epoch                          488
-----------------------------  ---------------------
2023-08-02 01:46:42.652418 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 489 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3500.2544]
trainer/QF1 Loss               0.043518305
trainer/QF2 Loss               0.03055932
trainer/Policy Loss            -89.87928
trainer/Q1 Predictions Mean    101.769905
trainer/Q1 Predictions Std     2.1850095
trainer/Q1 Predictions Max     104.04666
trainer/Q1 Predictions Min     81.310745
trainer/Q2 Predictions Mean    101.88402
trainer/Q2 Predictions Std     2.1783135
trainer/Q2 Predictions Max     104.277374
trainer/Q2 Predictions Min     82.03001
trainer/Q Targets Mean         101.835175
trainer/Q Targets Std          2.1416752
trainer/Q Targets Max          104.02752
trainer/Q Targets Min          82.636444
trainer/Log Pis Mean           12.007441
trainer/Log Pis Std            7.8692603
trainer/Log Pis Max            47.712334
trainer/Log Pis Min            -5.3794594
trainer/Policy mu Mean         -0.14922006
trainer/Policy mu Std          1.5949458
trainer/Policy mu Max          5.097661
trainer/Policy mu Min          -5.6441793
trainer/Policy log std Mean    -0.6853301
trainer/Policy log std Std     0.29069567
trainer/Policy log std Max     0.25734526
trainer/Policy log std Min     -1.8663614
trainer/Alpha                  0.0015318627702072263
trainer/Alpha Loss             0.048224687576293945
exploration/num steps total    2451000
exploration/num paths total    4902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9607728443587994
exploration/Rewards Std        0.0487299706836114
exploration/Rewards Max        0.979813021882095
exploration/Rewards Min        0.4879419225356751
exploration/Returns Mean       480.3864221793996
exploration/Returns Std        2.5593618413400576
exploration/Returns Max        482.86207468943087
exploration/Returns Min        475.82935341313987
exploration/Actions Mean       -0.02797293
exploration/Actions Std        0.60839015
exploration/Actions Max        0.99990106
exploration/Actions Min        -0.99993855
exploration/Num Paths          10
exploration/Average Returns    480.3864221793996
evaluation/num steps total     2450000
evaluation/num paths total     4900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9546790960296007
evaluation/Rewards Std         0.04749474980396477
evaluation/Rewards Max         0.9795636821916482
evaluation/Rewards Min         0.49127553766160537
evaluation/Returns Mean        477.3395480148003
evaluation/Returns Std         4.259958379965949
evaluation/Returns Max         484.03339603803346
evaluation/Returns Min         473.62507804197094
evaluation/ExplReturns Mean    477.3395480148003
evaluation/ExplReturns Std     4.259958379965949
evaluation/ExplReturns Max     484.03339603803346
evaluation/ExplReturns Min     473.62507804197094
evaluation/Actions Mean        -0.01562253
evaluation/Actions Std         0.40030575
evaluation/Actions Max         0.99930704
evaluation/Actions Min         -0.99936974
evaluation/Num Paths           10
evaluation/Average Returns     477.3395480148003
time/data storing (s)          0.0316734341904521
time/evaluation sampling (s)   112.71679191105068
time/exploration sampling (s)  112.52547470387071
time/logging (s)               0.030485023744404316
time/saving (s)                0.012558309361338615
time/training (s)              9.57449986692518
time/epoch (s)                 234.89148324914277
time/total (s)                 114753.45842657518
Epoch                          489
-----------------------------  ---------------------
2023-08-02 01:50:38.386532 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 490 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3582.2485]
trainer/QF1 Loss               0.050735828
trainer/QF2 Loss               0.027667608
trainer/Policy Loss            -89.73959
trainer/Q1 Predictions Mean    101.67168
trainer/Q1 Predictions Std     1.389365
trainer/Q1 Predictions Max     103.49634
trainer/Q1 Predictions Min     93.07774
trainer/Q2 Predictions Mean    101.79178
trainer/Q2 Predictions Std     1.3742934
trainer/Q2 Predictions Max     103.6009
trainer/Q2 Predictions Min     93.30904
trainer/Q Targets Mean         101.82868
trainer/Q Targets Std          1.4029951
trainer/Q Targets Max          103.73631
trainer/Q Targets Min          93.37515
trainer/Log Pis Mean           12.0461
trainer/Log Pis Std            8.157413
trainer/Log Pis Max            49.86302
trainer/Log Pis Min            -3.537433
trainer/Policy mu Mean         -0.0064121746
trainer/Policy mu Std          1.6377122
trainer/Policy mu Max          6.5670385
trainer/Policy mu Min          -6.001689
trainer/Policy log std Mean    -0.7071891
trainer/Policy log std Std     0.28022408
trainer/Policy log std Max     0.11631937
trainer/Policy log std Min     -2.0378945
trainer/Alpha                  0.0015510444063693285
trainer/Alpha Loss             0.2982226610183716
exploration/num steps total    2456000
exploration/num paths total    4912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9561036717604587
exploration/Rewards Std        0.05305273340489415
exploration/Rewards Max        0.9795562240012488
exploration/Rewards Min        0.490900907205618
exploration/Returns Mean       478.0518358802293
exploration/Returns Std        1.2269047159317308
exploration/Returns Max        479.0984977411933
exploration/Returns Min        475.11079880011096
exploration/Actions Mean       -0.03369043
exploration/Actions Std        0.6123953
exploration/Actions Max        0.9998144
exploration/Actions Min        -0.999916
exploration/Num Paths          10
exploration/Average Returns    478.0518358802293
evaluation/num steps total     2455000
evaluation/num paths total     4910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9563132671056366
evaluation/Rewards Std         0.050869622658807845
evaluation/Rewards Max         0.9794492757152627
evaluation/Rewards Min         0.4883698985145121
evaluation/Returns Mean        478.1566335528182
evaluation/Returns Std         1.513669691333299
evaluation/Returns Max         480.4254757567287
evaluation/Returns Min         476.2335574577333
evaluation/ExplReturns Mean    478.1566335528182
evaluation/ExplReturns Std     1.513669691333299
evaluation/ExplReturns Max     480.4254757567287
evaluation/ExplReturns Min     476.2335574577333
evaluation/Actions Mean        -0.06306113
evaluation/Actions Std         0.4759424
evaluation/Actions Max         0.99886143
evaluation/Actions Min         -0.9982028
evaluation/Num Paths           10
evaluation/Average Returns     478.1566335528182
time/data storing (s)          0.032039206475019455
time/evaluation sampling (s)   112.76840094663203
time/exploration sampling (s)  113.44940613023937
time/logging (s)               0.03043820895254612
time/saving (s)                0.010666493326425552
time/training (s)              9.436564193107188
time/epoch (s)                 235.72751517873257
time/total (s)                 114989.18845051248
Epoch                          490
-----------------------------  ---------------------
2023-08-02 01:54:34.981624 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 491 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3592.8687]
trainer/QF1 Loss               0.026752926
trainer/QF2 Loss               0.043552153
trainer/Policy Loss            -90.0396
trainer/Q1 Predictions Mean    101.939995
trainer/Q1 Predictions Std     2.2908251
trainer/Q1 Predictions Max     104.195496
trainer/Q1 Predictions Min     72.34127
trainer/Q2 Predictions Mean    101.98251
trainer/Q2 Predictions Std     2.3151248
trainer/Q2 Predictions Max     104.094696
trainer/Q2 Predictions Min     72.06994
trainer/Q Targets Mean         101.82563
trainer/Q Targets Std          2.3254771
trainer/Q Targets Max          103.93163
trainer/Q Targets Min          71.41542
trainer/Log Pis Mean           12.013131
trainer/Log Pis Std            7.496826
trainer/Log Pis Max            38.807632
trainer/Log Pis Min            -1.2952989
trainer/Policy mu Mean         -0.07312614
trainer/Policy mu Std          1.6006913
trainer/Policy mu Max          6.306868
trainer/Policy mu Min          -5.3904614
trainer/Policy log std Mean    -0.7239013
trainer/Policy log std Std     0.28717726
trainer/Policy log std Max     0.22237742
trainer/Policy log std Min     -2.297646
trainer/Alpha                  0.0014215473784133792
trainer/Alpha Loss             0.08608484268188477
exploration/num steps total    2461000
exploration/num paths total    4922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.953909181912666
exploration/Rewards Std        0.049225605429084836
exploration/Rewards Max        0.9772989041756829
exploration/Rewards Min        0.501668796402775
exploration/Returns Mean       476.95459095633305
exploration/Returns Std        0.47501627476836045
exploration/Returns Max        477.8277486940662
exploration/Returns Min        476.22085840185406
exploration/Actions Mean       -0.05461154
exploration/Actions Std        0.55044305
exploration/Actions Max        0.999958
exploration/Actions Min        -0.99989736
exploration/Num Paths          10
exploration/Average Returns    476.95459095633305
evaluation/num steps total     2460000
evaluation/num paths total     4920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9568991489869133
evaluation/Rewards Std         0.04841323008957295
evaluation/Rewards Max         0.9782824876122425
evaluation/Rewards Min         0.4923311391222403
evaluation/Returns Mean        478.4495744934567
evaluation/Returns Std         1.7055481498579332
evaluation/Returns Max         481.74889717359906
evaluation/Returns Min         477.0425974760585
evaluation/ExplReturns Mean    478.4495744934567
evaluation/ExplReturns Std     1.7055481498579332
evaluation/ExplReturns Max     481.74889717359906
evaluation/ExplReturns Min     477.0425974760585
evaluation/Actions Mean        -0.06497045
evaluation/Actions Std         0.42219892
evaluation/Actions Max         0.99957204
evaluation/Actions Min         -0.9996539
evaluation/Num Paths           10
evaluation/Average Returns     478.4495744934567
time/data storing (s)          0.03230736032128334
time/evaluation sampling (s)   113.56042356416583
time/exploration sampling (s)  112.65817102137953
time/logging (s)               0.030659379437565804
time/saving (s)                0.012167122215032578
time/training (s)              10.29503086116165
time/epoch (s)                 236.5887593086809
time/total (s)                 115225.77974615619
Epoch                          491
-----------------------------  ---------------------
2023-08-02 01:58:30.322840 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 492 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4113.6113]
trainer/QF1 Loss               0.035298906
trainer/QF2 Loss               0.020423645
trainer/Policy Loss            -89.486115
trainer/Q1 Predictions Mean    101.7935
trainer/Q1 Predictions Std     1.7776122
trainer/Q1 Predictions Max     103.62469
trainer/Q1 Predictions Min     80.12469
trainer/Q2 Predictions Mean    101.92343
trainer/Q2 Predictions Std     1.7620509
trainer/Q2 Predictions Max     103.878876
trainer/Q2 Predictions Min     80.35388
trainer/Q Targets Mean         101.90752
trainer/Q Targets Std          1.7384945
trainer/Q Targets Max          103.87128
trainer/Q Targets Min          80.77671
trainer/Log Pis Mean           12.403601
trainer/Log Pis Std            7.5078073
trainer/Log Pis Max            36.05464
trainer/Log Pis Min            -6.5955343
trainer/Policy mu Mean         0.046796758
trainer/Policy mu Std          1.6296552
trainer/Policy mu Max          6.1153717
trainer/Policy mu Min          -4.338807
trainer/Policy log std Mean    -0.69765717
trainer/Policy log std Std     0.26056117
trainer/Policy log std Max     0.10846937
trainer/Policy log std Min     -1.97759
trainer/Alpha                  0.0014239326119422913
trainer/Alpha Loss             2.6453380584716797
exploration/num steps total    2466000
exploration/num paths total    4932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9475720797220951
exploration/Rewards Std        0.05709446956025952
exploration/Rewards Max        0.9790257213749869
exploration/Rewards Min        0.49614343648201065
exploration/Returns Mean       473.78603986104747
exploration/Returns Std        6.12842975644828
exploration/Returns Max        481.48104840667133
exploration/Returns Min        465.54306794372565
exploration/Actions Mean       0.0154475
exploration/Actions Std        0.5976864
exploration/Actions Max        0.9999702
exploration/Actions Min        -0.99996275
exploration/Num Paths          10
exploration/Average Returns    473.78603986104747
evaluation/num steps total     2465000
evaluation/num paths total     4930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9579965244860914
evaluation/Rewards Std         0.04737664905371513
evaluation/Rewards Max         0.9792451953221264
evaluation/Rewards Min         0.49312028758032267
evaluation/Returns Mean        478.9982622430458
evaluation/Returns Std         3.2024355397908506
evaluation/Returns Max         481.96434956798794
evaluation/Returns Min         473.81146871606245
evaluation/ExplReturns Mean    478.9982622430458
evaluation/ExplReturns Std     3.2024355397908506
evaluation/ExplReturns Max     481.96434956798794
evaluation/ExplReturns Min     473.81146871606245
evaluation/Actions Mean        -0.023667796
evaluation/Actions Std         0.4865453
evaluation/Actions Max         0.9995618
evaluation/Actions Min         -0.9995163
evaluation/Num Paths           10
evaluation/Average Returns     478.9982622430458
time/data storing (s)          0.032316080294549465
time/evaluation sampling (s)   112.8866124888882
time/exploration sampling (s)  113.39047639351338
time/logging (s)               0.030601266771554947
time/saving (s)                0.010722953826189041
time/training (s)              8.98363474290818
time/epoch (s)                 235.33436392620206
time/total (s)                 115461.1168430075
Epoch                          492
-----------------------------  ---------------------
2023-08-02 02:02:25.390634 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 493 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4108.116]
trainer/QF1 Loss               0.022644503
trainer/QF2 Loss               0.021740941
trainer/Policy Loss            -90.35066
trainer/Q1 Predictions Mean    102.011734
trainer/Q1 Predictions Std     1.753136
trainer/Q1 Predictions Max     103.924965
trainer/Q1 Predictions Min     79.11071
trainer/Q2 Predictions Mean    102.01146
trainer/Q2 Predictions Std     1.7742449
trainer/Q2 Predictions Max     103.974045
trainer/Q2 Predictions Min     78.53077
trainer/Q Targets Mean         101.93005
trainer/Q Targets Std          1.7673376
trainer/Q Targets Max          103.8388
trainer/Q Targets Min          78.46775
trainer/Log Pis Mean           11.727249
trainer/Log Pis Std            8.506738
trainer/Log Pis Max            47.448883
trainer/Log Pis Min            -6.2040586
trainer/Policy mu Mean         0.049203347
trainer/Policy mu Std          1.5934756
trainer/Policy mu Max          7.2485776
trainer/Policy mu Min          -5.0287333
trainer/Policy log std Mean    -0.7191805
trainer/Policy log std Std     0.26972952
trainer/Policy log std Max     0.72144794
trainer/Policy log std Min     -1.9730018
trainer/Alpha                  0.0013322134036570787
trainer/Alpha Loss             -1.8058240413665771
exploration/num steps total    2471000
exploration/num paths total    4942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8912717050087408
exploration/Rewards Std        0.10879411035443558
exploration/Rewards Max        0.9783268493824029
exploration/Rewards Min        0.4757165351315818
exploration/Returns Mean       445.63585250437035
exploration/Returns Std        34.89933021906569
exploration/Returns Max        481.0675941692704
exploration/Returns Min        398.7231096845232
exploration/Actions Mean       -0.09329265
exploration/Actions Std        0.5791337
exploration/Actions Max        0.99989307
exploration/Actions Min        -0.9999725
exploration/Num Paths          10
exploration/Average Returns    445.63585250437035
evaluation/num steps total     2470000
evaluation/num paths total     4940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.900957464338671
evaluation/Rewards Std         0.10423608357355468
evaluation/Rewards Max         0.9784857747651403
evaluation/Rewards Min         0.49016964772945965
evaluation/Returns Mean        450.4787321693354
evaluation/Returns Std         31.74028357254094
evaluation/Returns Max         480.2028715744586
evaluation/Returns Min         399.3733004380165
evaluation/ExplReturns Mean    450.4787321693354
evaluation/ExplReturns Std     31.74028357254094
evaluation/ExplReturns Max     480.2028715744586
evaluation/ExplReturns Min     399.3733004380165
evaluation/Actions Mean        -0.09969954
evaluation/Actions Std         0.49846452
evaluation/Actions Max         0.9999989
evaluation/Actions Min         -0.9999986
evaluation/Num Paths           10
evaluation/Average Returns     450.4787321693354
time/data storing (s)          0.03204347472637892
time/evaluation sampling (s)   112.76470327470452
time/exploration sampling (s)  112.55178675428033
time/logging (s)               0.030634521506726742
time/saving (s)                0.011880798265337944
time/training (s)              9.670214320532978
time/epoch (s)                 235.06126314401627
time/total (s)                 115696.18059886247
Epoch                          493
-----------------------------  ---------------------
2023-08-02 02:06:21.827410 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 494 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4035.2468]
trainer/QF1 Loss               0.02164381
trainer/QF2 Loss               0.017359896
trainer/Policy Loss            -89.86715
trainer/Q1 Predictions Mean    101.82646
trainer/Q1 Predictions Std     2.3488705
trainer/Q1 Predictions Max     103.86391
trainer/Q1 Predictions Min     78.793884
trainer/Q2 Predictions Mean    101.77365
trainer/Q2 Predictions Std     2.3364532
trainer/Q2 Predictions Max     103.81991
trainer/Q2 Predictions Min     78.82395
trainer/Q Targets Mean         101.77359
trainer/Q Targets Std          2.361943
trainer/Q Targets Max          103.72247
trainer/Q Targets Min          77.742035
trainer/Log Pis Mean           12.010392
trainer/Log Pis Std            7.5288186
trainer/Log Pis Max            37.568733
trainer/Log Pis Min            -5.391571
trainer/Policy mu Mean         0.06332325
trainer/Policy mu Std          1.6171954
trainer/Policy mu Max          5.6105704
trainer/Policy mu Min          -5.435773
trainer/Policy log std Mean    -0.71498483
trainer/Policy log std Std     0.26690227
trainer/Policy log std Max     0.046500802
trainer/Policy log std Min     -2.0900679
trainer/Alpha                  0.0013413034612312913
trainer/Alpha Loss             0.0687335729598999
exploration/num steps total    2476000
exploration/num paths total    4952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.965349727387947
exploration/Rewards Std        0.04826661504322412
exploration/Rewards Max        0.9796150573721895
exploration/Rewards Min        0.496460833049846
exploration/Returns Mean       482.6748636939734
exploration/Returns Std        0.7042052198747331
exploration/Returns Max        483.8501727429517
exploration/Returns Min        481.6805687796087
exploration/Actions Mean       -0.061695877
exploration/Actions Std        0.6227774
exploration/Actions Max        0.9999819
exploration/Actions Min        -0.9999209
exploration/Num Paths          10
exploration/Average Returns    482.6748636939734
evaluation/num steps total     2475000
evaluation/num paths total     4950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9653455687570492
evaluation/Rewards Std         0.04810097729298257
evaluation/Rewards Max         0.9797049922548674
evaluation/Rewards Min         0.49468834509575554
evaluation/Returns Mean        482.67278437852457
evaluation/Returns Std         1.193022769832252
evaluation/Returns Max         484.4812991860394
evaluation/Returns Min         480.8304025590435
evaluation/ExplReturns Mean    482.67278437852457
evaluation/ExplReturns Std     1.193022769832252
evaluation/ExplReturns Max     484.4812991860394
evaluation/ExplReturns Min     480.8304025590435
evaluation/Actions Mean        -0.059590656
evaluation/Actions Std         0.5387998
evaluation/Actions Max         0.99979174
evaluation/Actions Min         -0.99934775
evaluation/Num Paths           10
evaluation/Average Returns     482.67278437852457
time/data storing (s)          0.03189223911613226
time/evaluation sampling (s)   112.60270991548896
time/exploration sampling (s)  114.09692228864878
time/logging (s)               0.03046319168061018
time/saving (s)                0.012573149986565113
time/training (s)              9.65533870831132
time/epoch (s)                 236.42989949323237
time/total (s)                 115932.61311837751
Epoch                          494
-----------------------------  ---------------------
2023-08-02 02:10:18.779197 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 495 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4132.9443]
trainer/QF1 Loss               0.018457156
trainer/QF2 Loss               0.019946177
trainer/Policy Loss            -89.364525
trainer/Q1 Predictions Mean    101.87784
trainer/Q1 Predictions Std     1.5070179
trainer/Q1 Predictions Max     103.88677
trainer/Q1 Predictions Min     85.07692
trainer/Q2 Predictions Mean    101.86344
trainer/Q2 Predictions Std     1.4908085
trainer/Q2 Predictions Max     103.85613
trainer/Q2 Predictions Min     85.209015
trainer/Q Targets Mean         101.830215
trainer/Q Targets Std          1.4993684
trainer/Q Targets Max          103.8373
trainer/Q Targets Min          85.41122
trainer/Log Pis Mean           12.591475
trainer/Log Pis Std            9.030532
trainer/Log Pis Max            57.74102
trainer/Log Pis Min            -5.7767506
trainer/Policy mu Mean         0.062217176
trainer/Policy mu Std          1.6591551
trainer/Policy mu Max          10.246418
trainer/Policy mu Min          -6.2915773
trainer/Policy log std Mean    -0.68645054
trainer/Policy log std Std     0.26388848
trainer/Policy log std Max     0.96656656
trainer/Policy log std Min     -1.7631906
trainer/Alpha                  0.001329899881966412
trainer/Alpha Loss             3.917149066925049
exploration/num steps total    2481000
exploration/num paths total    4962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.958016492776401
exploration/Rewards Std        0.05141393300059706
exploration/Rewards Max        0.9783399207871585
exploration/Rewards Min        0.4911981803003035
exploration/Returns Mean       479.0082463882004
exploration/Returns Std        0.8063396221636548
exploration/Returns Max        480.0746663792305
exploration/Returns Min        477.14051774139546
exploration/Actions Mean       -0.03305615
exploration/Actions Std        0.5819909
exploration/Actions Max        0.9999626
exploration/Actions Min        -0.9998893
exploration/Num Paths          10
exploration/Average Returns    479.0082463882004
evaluation/num steps total     2480000
evaluation/num paths total     4960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9612657228004183
evaluation/Rewards Std         0.05065717364773881
evaluation/Rewards Max         0.9789605717589149
evaluation/Rewards Min         0.49473537163396436
evaluation/Returns Mean        480.6328614002091
evaluation/Returns Std         1.2117590184470037
evaluation/Returns Max         482.6037859335341
evaluation/Returns Min         478.5803836985917
evaluation/ExplReturns Mean    480.6328614002091
evaluation/ExplReturns Std     1.2117590184470037
evaluation/ExplReturns Max     482.6037859335341
evaluation/ExplReturns Min     478.5803836985917
evaluation/Actions Mean        -0.042684052
evaluation/Actions Std         0.46576557
evaluation/Actions Max         0.9994177
evaluation/Actions Min         -0.99919623
evaluation/Num Paths           10
evaluation/Average Returns     480.6328614002091
time/data storing (s)          0.03198104165494442
time/evaluation sampling (s)   113.41064644511789
time/exploration sampling (s)  114.30433250777423
time/logging (s)               0.030423776246607304
time/saving (s)                0.010260905139148235
time/training (s)              9.157572054304183
time/epoch (s)                 236.945216730237
time/total (s)                 116169.56083613448
Epoch                          495
-----------------------------  --------------------
2023-08-02 02:14:15.946486 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 496 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4019.966]
trainer/QF1 Loss               0.04385584
trainer/QF2 Loss               0.019186426
trainer/Policy Loss            -90.11603
trainer/Q1 Predictions Mean    102.046555
trainer/Q1 Predictions Std     1.269957
trainer/Q1 Predictions Max     104.01313
trainer/Q1 Predictions Min     88.20804
trainer/Q2 Predictions Mean    101.93768
trainer/Q2 Predictions Std     1.2597164
trainer/Q2 Predictions Max     104.00459
trainer/Q2 Predictions Min     88.594345
trainer/Q Targets Mean         101.88481
trainer/Q Targets Std          1.2573451
trainer/Q Targets Max          103.812546
trainer/Q Targets Min          88.48056
trainer/Log Pis Mean           11.915972
trainer/Log Pis Std            8.543295
trainer/Log Pis Max            46.364803
trainer/Log Pis Min            -4.5850215
trainer/Policy mu Mean         0.0984179
trainer/Policy mu Std          1.5912696
trainer/Policy mu Max          4.609244
trainer/Policy mu Min          -5.6543217
trainer/Policy log std Mean    -0.7357622
trainer/Policy log std Std     0.26272726
trainer/Policy log std Max     0.029996037
trainer/Policy log std Min     -2.4370055
trainer/Alpha                  0.0012835024390369654
trainer/Alpha Loss             -0.5594821572303772
exploration/num steps total    2486000
exploration/num paths total    4972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9638663002730616
exploration/Rewards Std        0.04659653560829151
exploration/Rewards Max        0.9792352824263335
exploration/Rewards Min        0.499422915876933
exploration/Returns Mean       481.93315013653074
exploration/Returns Std        0.7095603020045788
exploration/Returns Max        482.85730749940876
exploration/Returns Min        480.7119627198943
exploration/Actions Mean       0.008191741
exploration/Actions Std        0.5983479
exploration/Actions Max        0.9997683
exploration/Actions Min        -0.99994767
exploration/Num Paths          10
exploration/Average Returns    481.93315013653074
evaluation/num steps total     2485000
evaluation/num paths total     4970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9644930122768168
evaluation/Rewards Std         0.046757131947626075
evaluation/Rewards Max         0.9788720450257847
evaluation/Rewards Min         0.4973962785877647
evaluation/Returns Mean        482.2465061384082
evaluation/Returns Std         1.1261096945343354
evaluation/Returns Max         484.01497244752665
evaluation/Returns Min         479.68170277645544
evaluation/ExplReturns Mean    482.2465061384082
evaluation/ExplReturns Std     1.1261096945343354
evaluation/ExplReturns Max     484.01497244752665
evaluation/ExplReturns Min     479.68170277645544
evaluation/Actions Mean        0.048944417
evaluation/Actions Std         0.4924035
evaluation/Actions Max         0.99879783
evaluation/Actions Min         -0.9996303
evaluation/Num Paths           10
evaluation/Average Returns     482.2465061384082
time/data storing (s)          0.03209517989307642
time/evaluation sampling (s)   113.60321974940598
time/exploration sampling (s)  113.8613727260381
time/logging (s)               0.030571249313652515
time/saving (s)                0.011858321726322174
time/training (s)              9.621802657842636
time/epoch (s)                 237.16091988421977
time/total (s)                 116406.72418951895
Epoch                          496
-----------------------------  ---------------------
2023-08-02 02:18:14.133865 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 497 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3899.3342]
trainer/QF1 Loss               0.016618732
trainer/QF2 Loss               0.015464599
trainer/Policy Loss            -91.70536
trainer/Q1 Predictions Mean    102.02357
trainer/Q1 Predictions Std     0.7236951
trainer/Q1 Predictions Max     103.72213
trainer/Q1 Predictions Min     97.07946
trainer/Q2 Predictions Mean    102.04144
trainer/Q2 Predictions Std     0.7213147
trainer/Q2 Predictions Max     103.70788
trainer/Q2 Predictions Min     97.11756
trainer/Q Targets Mean         101.98707
trainer/Q Targets Std          0.7538834
trainer/Q Targets Max          103.79723
trainer/Q Targets Min          96.92304
trainer/Log Pis Mean           10.395369
trainer/Log Pis Std            7.0964894
trainer/Log Pis Max            38.528053
trainer/Log Pis Min            -5.2630215
trainer/Policy mu Mean         0.24331541
trainer/Policy mu Std          1.506104
trainer/Policy mu Max          4.899968
trainer/Policy mu Min          -4.606618
trainer/Policy log std Mean    -0.691746
trainer/Policy log std Std     0.24192601
trainer/Policy log std Max     0.06712794
trainer/Policy log std Min     -1.6510417
trainer/Alpha                  0.0013036115560680628
trainer/Alpha Loss             -10.65889835357666
exploration/num steps total    2491000
exploration/num paths total    4982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9356811224514852
exploration/Rewards Std        0.08414304539151508
exploration/Rewards Max        0.9798570627111087
exploration/Rewards Min        0.49669319136999857
exploration/Returns Mean       467.84056122574265
exploration/Returns Std        9.175448648233496
exploration/Returns Max        481.8511588755221
exploration/Returns Min        448.2207448962881
exploration/Actions Mean       0.058926977
exploration/Actions Std        0.6648783
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999995
exploration/Num Paths          10
exploration/Average Returns    467.84056122574265
evaluation/num steps total     2490000
evaluation/num paths total     4980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9210744201308073
evaluation/Rewards Std         0.10110879589004575
evaluation/Rewards Max         0.9790734597560441
evaluation/Rewards Min         0.4948213708075499
evaluation/Returns Mean        460.5372100654037
evaluation/Returns Std         31.69372961386688
evaluation/Returns Max         481.2573268137191
evaluation/Returns Min         395.83458568544836
evaluation/ExplReturns Mean    460.5372100654037
evaluation/ExplReturns Std     31.69372961386688
evaluation/ExplReturns Max     481.2573268137191
evaluation/ExplReturns Min     395.83458568544836
evaluation/Actions Mean        0.0626368
evaluation/Actions Std         0.58254194
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999815
evaluation/Num Paths           10
evaluation/Average Returns     460.5372100654037
time/data storing (s)          0.03241808991879225
time/evaluation sampling (s)   113.90317822340876
time/exploration sampling (s)  114.62302379868925
time/logging (s)               0.030530679039657116
time/saving (s)                0.012163636274635792
time/training (s)              9.579340985044837
time/epoch (s)                 238.18065541237593
time/total (s)                 116644.90745533817
Epoch                          497
-----------------------------  ---------------------
2023-08-02 02:22:09.748119 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 498 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3980.2554]
trainer/QF1 Loss               0.019621257
trainer/QF2 Loss               0.022054795
trainer/Policy Loss            -88.98937
trainer/Q1 Predictions Mean    101.81755
trainer/Q1 Predictions Std     1.0621227
trainer/Q1 Predictions Max     104.126854
trainer/Q1 Predictions Min     94.66267
trainer/Q2 Predictions Mean    101.79529
trainer/Q2 Predictions Std     1.0242883
trainer/Q2 Predictions Max     104.14177
trainer/Q2 Predictions Min     95.07038
trainer/Q Targets Mean         101.85608
trainer/Q Targets Std          1.05597
trainer/Q Targets Max          104.159485
trainer/Q Targets Min          94.78162
trainer/Log Pis Mean           12.896417
trainer/Log Pis Std            9.873707
trainer/Log Pis Max            71.03673
trainer/Log Pis Min            -0.9599236
trainer/Policy mu Mean         0.2116694
trainer/Policy mu Std          1.67398
trainer/Policy mu Max          11.063395
trainer/Policy mu Min          -4.7196217
trainer/Policy log std Mean    -0.66820025
trainer/Policy log std Std     0.26105407
trainer/Policy log std Max     1.6729999
trainer/Policy log std Min     -1.8752466
trainer/Alpha                  0.0013432825217023492
trainer/Alpha Loss             5.927689552307129
exploration/num steps total    2496000
exploration/num paths total    4992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9339683657334259
exploration/Rewards Std        0.08212567487240899
exploration/Rewards Max        0.9798802013066829
exploration/Rewards Min        0.49363323510223805
exploration/Returns Mean       466.98418286671296
exploration/Returns Std        5.13398155809231
exploration/Returns Max        472.1022096452406
exploration/Returns Min        455.6549627100664
exploration/Actions Mean       0.02719614
exploration/Actions Std        0.69366395
exploration/Actions Max        0.99999774
exploration/Actions Min        -0.99999714
exploration/Num Paths          10
exploration/Average Returns    466.98418286671296
evaluation/num steps total     2495000
evaluation/num paths total     4990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9430711996613746
evaluation/Rewards Std         0.07657803846808481
evaluation/Rewards Max         0.9789208953629622
evaluation/Rewards Min         0.4845329780259638
evaluation/Returns Mean        471.53559983068715
evaluation/Returns Std         22.13046640356434
evaluation/Returns Max         483.17025745812214
evaluation/Returns Min         409.9810252276394
evaluation/ExplReturns Mean    471.53559983068715
evaluation/ExplReturns Std     22.13046640356434
evaluation/ExplReturns Max     483.17025745812214
evaluation/ExplReturns Min     409.9810252276394
evaluation/Actions Mean        0.055546343
evaluation/Actions Std         0.6255464
evaluation/Actions Max         0.9996952
evaluation/Actions Min         -0.9997953
evaluation/Num Paths           10
evaluation/Average Returns     471.53559983068715
time/data storing (s)          0.0323438486084342
time/evaluation sampling (s)   112.50824964046478
time/exploration sampling (s)  113.40495074447244
time/logging (s)               0.03056907281279564
time/saving (s)                0.012481886893510818
time/training (s)              9.619121230207384
time/epoch (s)                 235.60771642345935
time/total (s)                 116880.51765955053
Epoch                          498
-----------------------------  ---------------------
2023-08-02 02:26:03.426340 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 499 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3753.4797]
trainer/QF1 Loss               0.04970372
trainer/QF2 Loss               0.01377736
trainer/Policy Loss            -90.64751
trainer/Q1 Predictions Mean    102.03826
trainer/Q1 Predictions Std     0.9346514
trainer/Q1 Predictions Max     104.81403
trainer/Q1 Predictions Min     94.03665
trainer/Q2 Predictions Mean    101.87663
trainer/Q2 Predictions Std     0.9241464
trainer/Q2 Predictions Max     104.705574
trainer/Q2 Predictions Min     94.269905
trainer/Q Targets Mean         101.852005
trainer/Q Targets Std          0.9552849
trainer/Q Targets Max          104.370514
trainer/Q Targets Min          93.715034
trainer/Log Pis Mean           11.329694
trainer/Log Pis Std            8.378867
trainer/Log Pis Max            53.138763
trainer/Log Pis Min            -6.2952332
trainer/Policy mu Mean         0.12716356
trainer/Policy mu Std          1.5902869
trainer/Policy mu Max          7.3476067
trainer/Policy mu Min          -4.7620564
trainer/Policy log std Mean    -0.68313545
trainer/Policy log std Std     0.25270763
trainer/Policy log std Max     0.8122698
trainer/Policy log std Min     -1.7257805
trainer/Alpha                  0.0013170851161703467
trainer/Alpha Loss             -4.445889472961426
exploration/num steps total    2501000
exploration/num paths total    5002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9609113401986018
exploration/Rewards Std        0.05343940840647995
exploration/Rewards Max        0.9798370387577441
exploration/Rewards Min        0.47919559963925373
exploration/Returns Mean       480.4556700993009
exploration/Returns Std        1.6542381066674228
exploration/Returns Max        481.7372264863967
exploration/Returns Min        476.1998556148349
exploration/Actions Mean       0.02374119
exploration/Actions Std        0.6550408
exploration/Actions Max        0.9999989
exploration/Actions Min        -0.9999004
exploration/Num Paths          10
exploration/Average Returns    480.4556700993009
evaluation/num steps total     2500000
evaluation/num paths total     5000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9646234967977684
evaluation/Rewards Std         0.050931323975654474
evaluation/Rewards Max         0.9790821972810386
evaluation/Rewards Min         0.4871242093491618
evaluation/Returns Mean        482.3117483988843
evaluation/Returns Std         1.3764951174610764
evaluation/Returns Max         484.1068219581223
evaluation/Returns Min         478.88740358907745
evaluation/ExplReturns Mean    482.3117483988843
evaluation/ExplReturns Std     1.3764951174610764
evaluation/ExplReturns Max     484.1068219581223
evaluation/ExplReturns Min     478.88740358907745
evaluation/Actions Mean        0.06976141
evaluation/Actions Std         0.6550172
evaluation/Actions Max         0.9991219
evaluation/Actions Min         -0.9999189
evaluation/Num Paths           10
evaluation/Average Returns     482.3117483988843
time/data storing (s)          0.03228543233126402
time/evaluation sampling (s)   111.04482711758465
time/exploration sampling (s)  112.84158017858863
time/logging (s)               0.030458291061222553
time/saving (s)                0.012927649542689323
time/training (s)              9.709382588975132
time/epoch (s)                 233.67146125808358
time/total (s)                 117114.19165675063
Epoch                          499
-----------------------------  ---------------------
2023-08-02 02:30:00.579923 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 500 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3852.9678]
trainer/QF1 Loss               0.01114125
trainer/QF2 Loss               0.022259504
trainer/Policy Loss            -91.00918
trainer/Q1 Predictions Mean    101.85464
trainer/Q1 Predictions Std     1.0780458
trainer/Q1 Predictions Max     105.46732
trainer/Q1 Predictions Min     93.77306
trainer/Q2 Predictions Mean    101.85863
trainer/Q2 Predictions Std     1.1176144
trainer/Q2 Predictions Max     105.487755
trainer/Q2 Predictions Min     92.544304
trainer/Q Targets Mean         101.82831
trainer/Q Targets Std          1.0707076
trainer/Q Targets Max          105.267
trainer/Q Targets Min          93.729744
trainer/Log Pis Mean           10.91432
trainer/Log Pis Std            8.194562
trainer/Log Pis Max            41.86366
trainer/Log Pis Min            -5.730489
trainer/Policy mu Mean         0.069915734
trainer/Policy mu Std          1.569401
trainer/Policy mu Max          6.851048
trainer/Policy mu Min          -4.877155
trainer/Policy log std Mean    -0.67515975
trainer/Policy log std Std     0.2717105
trainer/Policy log std Max     0.0991897
trainer/Policy log std Min     -2.1679075
trainer/Alpha                  0.001352977124042809
trainer/Alpha Loss             -7.171243667602539
exploration/num steps total    2506000
exploration/num paths total    5012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9624702333610967
exploration/Rewards Std        0.04877481472775612
exploration/Rewards Max        0.979555483433734
exploration/Rewards Min        0.49430691045333264
exploration/Returns Mean       481.23511668054863
exploration/Returns Std        0.6713563351630126
exploration/Returns Max        482.03482465489
exploration/Returns Min        479.4395988774868
exploration/Actions Mean       -0.021514531
exploration/Actions Std        0.59848166
exploration/Actions Max        0.99992245
exploration/Actions Min        -0.99986655
exploration/Num Paths          10
exploration/Average Returns    481.23511668054863
evaluation/num steps total     2505000
evaluation/num paths total     5010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9654002537160519
evaluation/Rewards Std         0.050578855246030126
evaluation/Rewards Max         0.9792547598887902
evaluation/Rewards Min         0.4896449174062434
evaluation/Returns Mean        482.70012685802595
evaluation/Returns Std         1.4506490806904493
evaluation/Returns Max         483.59909509665283
evaluation/Returns Min         478.4634736069095
evaluation/ExplReturns Mean    482.70012685802595
evaluation/ExplReturns Std     1.4506490806904493
evaluation/ExplReturns Max     483.59909509665283
evaluation/ExplReturns Min     478.4634736069095
evaluation/Actions Mean        0.009096748
evaluation/Actions Std         0.43991524
evaluation/Actions Max         0.9990136
evaluation/Actions Min         -0.9995997
evaluation/Num Paths           10
evaluation/Average Returns     482.70012685802595
time/data storing (s)          0.0320467920973897
time/evaluation sampling (s)   113.86095026228577
time/exploration sampling (s)  113.74705550353974
time/logging (s)               0.03055841289460659
time/saving (s)                0.010306275449693203
time/training (s)              9.466011743061244
time/epoch (s)                 237.14692898932844
time/total (s)                 117351.3412599247
Epoch                          500
-----------------------------  --------------------
2023-08-02 02:33:53.405404 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 501 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3920.0525]
trainer/QF1 Loss               0.018700693
trainer/QF2 Loss               0.024132157
trainer/Policy Loss            -89.6021
trainer/Q1 Predictions Mean    101.931175
trainer/Q1 Predictions Std     1.5902015
trainer/Q1 Predictions Max     105.75779
trainer/Q1 Predictions Min     87.633675
trainer/Q2 Predictions Mean    101.90504
trainer/Q2 Predictions Std     1.6184444
trainer/Q2 Predictions Max     105.4494
trainer/Q2 Predictions Min     87.27066
trainer/Q Targets Mean         101.88817
trainer/Q Targets Std          1.5564317
trainer/Q Targets Max          105.88589
trainer/Q Targets Min          87.99435
trainer/Log Pis Mean           12.425937
trainer/Log Pis Std            9.800191
trainer/Log Pis Max            71.01733
trainer/Log Pis Min            -7.3870234
trainer/Policy mu Mean         0.19299543
trainer/Policy mu Std          1.6600523
trainer/Policy mu Max          5.7218223
trainer/Policy mu Min          -10.478844
trainer/Policy log std Mean    -0.6691392
trainer/Policy log std Std     0.26685676
trainer/Policy log std Max     0.60686123
trainer/Policy log std Min     -2.3047109
trainer/Alpha                  0.001517954282462597
trainer/Alpha Loss             2.76456618309021
exploration/num steps total    2511000
exploration/num paths total    5022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9468930050735084
exploration/Rewards Std        0.06682769311473398
exploration/Rewards Max        0.9798132334987257
exploration/Rewards Min        0.4908030121138661
exploration/Returns Mean       473.4465025367541
exploration/Returns Std        8.860972803694445
exploration/Returns Max        479.8914099982779
exploration/Returns Min        459.3320029294208
exploration/Actions Mean       0.06473095
exploration/Actions Std        0.6034819
exploration/Actions Max        0.99989855
exploration/Actions Min        -0.99976194
exploration/Num Paths          10
exploration/Average Returns    473.4465025367541
evaluation/num steps total     2510000
evaluation/num paths total     5020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9473737887375031
evaluation/Rewards Std         0.0666771959730959
evaluation/Rewards Max         0.9797254925324719
evaluation/Rewards Min         0.4895233708692973
evaluation/Returns Mean        473.68689436875167
evaluation/Returns Std         7.670467100676322
evaluation/Returns Max         480.035610556761
evaluation/Returns Min         458.0320461967058
evaluation/ExplReturns Mean    473.68689436875167
evaluation/ExplReturns Std     7.670467100676322
evaluation/ExplReturns Max     480.035610556761
evaluation/ExplReturns Min     458.0320461967058
evaluation/Actions Mean        0.063188694
evaluation/Actions Std         0.47394007
evaluation/Actions Max         0.9994841
evaluation/Actions Min         -0.9998304
evaluation/Num Paths           10
evaluation/Average Returns     473.68689436875167
time/data storing (s)          0.03240916132926941
time/evaluation sampling (s)   110.66769699007273
time/exploration sampling (s)  112.4396092724055
time/logging (s)               0.031095216050744057
time/saving (s)                0.012353083118796349
time/training (s)              9.63613192550838
time/epoch (s)                 232.81929564848542
time/total (s)                 117584.16316559538
Epoch                          501
-----------------------------  --------------------
2023-08-02 02:37:48.200511 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 502 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3670.8965]
trainer/QF1 Loss               0.03150295
trainer/QF2 Loss               0.030349374
trainer/Policy Loss            -90.03715
trainer/Q1 Predictions Mean    101.910324
trainer/Q1 Predictions Std     1.9383488
trainer/Q1 Predictions Max     106.49323
trainer/Q1 Predictions Min     77.51672
trainer/Q2 Predictions Mean    101.93503
trainer/Q2 Predictions Std     1.9800731
trainer/Q2 Predictions Max     106.65578
trainer/Q2 Predictions Min     76.86497
trainer/Q Targets Mean         101.87358
trainer/Q Targets Std          1.9560466
trainer/Q Targets Max          106.41132
trainer/Q Targets Min          77.27046
trainer/Log Pis Mean           11.978115
trainer/Log Pis Std            8.856278
trainer/Log Pis Max            59.17569
trainer/Log Pis Min            -5.610355
trainer/Policy mu Mean         0.22502457
trainer/Policy mu Std          1.5996214
trainer/Policy mu Max          5.1394796
trainer/Policy mu Min          -7.6841435
trainer/Policy log std Mean    -0.6905008
trainer/Policy log std Std     0.26439062
trainer/Policy log std Max     0.633461
trainer/Policy log std Min     -2.282147
trainer/Alpha                  0.0016422291519120336
trainer/Alpha Loss             -0.14031976461410522
exploration/num steps total    2516000
exploration/num paths total    5032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9510598576865057
exploration/Rewards Std        0.06786695352435893
exploration/Rewards Max        0.9786666602008834
exploration/Rewards Min        0.4914423737429746
exploration/Returns Mean       475.52992884325295
exploration/Returns Std        2.273924389815994
exploration/Returns Max        477.72647727429046
exploration/Returns Min        469.98765279989624
exploration/Actions Mean       0.03738374
exploration/Actions Std        0.61665547
exploration/Actions Max        0.9998955
exploration/Actions Min        -0.99997103
exploration/Num Paths          10
exploration/Average Returns    475.52992884325295
evaluation/num steps total     2515000
evaluation/num paths total     5030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9400473012130205
evaluation/Rewards Std         0.07228816214496499
evaluation/Rewards Max         0.9787118764282687
evaluation/Rewards Min         0.4919888489337747
evaluation/Returns Mean        470.0236506065103
evaluation/Returns Std         5.012905378540293
evaluation/Returns Max         475.1250710005719
evaluation/Returns Min         460.0375689953877
evaluation/ExplReturns Mean    470.0236506065103
evaluation/ExplReturns Std     5.012905378540293
evaluation/ExplReturns Max     475.1250710005719
evaluation/ExplReturns Min     460.0375689953877
evaluation/Actions Mean        0.007260962
evaluation/Actions Std         0.5467638
evaluation/Actions Max         0.9998562
evaluation/Actions Min         -0.99960965
evaluation/Num Paths           10
evaluation/Average Returns     470.0236506065103
time/data storing (s)          0.03204066678881645
time/evaluation sampling (s)   112.14205389469862
time/exploration sampling (s)  112.90828241501004
time/logging (s)               0.03076921869069338
time/saving (s)                0.011437919922173023
time/training (s)              9.663455786183476
time/epoch (s)                 234.7880399012938
time/total (s)                 117818.95376994368
Epoch                          502
-----------------------------  ---------------------
2023-08-02 02:41:43.579492 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 503 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3541.5352]
trainer/QF1 Loss               0.023767509
trainer/QF2 Loss               0.020844115
trainer/Policy Loss            -90.52454
trainer/Q1 Predictions Mean    102.12187
trainer/Q1 Predictions Std     1.6750107
trainer/Q1 Predictions Max     107.20958
trainer/Q1 Predictions Min     88.64079
trainer/Q2 Predictions Mean    102.141
trainer/Q2 Predictions Std     1.6497712
trainer/Q2 Predictions Max     107.216545
trainer/Q2 Predictions Min     88.91193
trainer/Q Targets Mean         102.05481
trainer/Q Targets Std          1.6552656
trainer/Q Targets Max          107.236755
trainer/Q Targets Min          88.6106
trainer/Log Pis Mean           11.719406
trainer/Log Pis Std            8.332188
trainer/Log Pis Max            58.47298
trainer/Log Pis Min            -7.2887774
trainer/Policy mu Mean         0.17742471
trainer/Policy mu Std          1.5917555
trainer/Policy mu Max          5.18662
trainer/Policy mu Min          -7.438344
trainer/Policy log std Mean    -0.69775563
trainer/Policy log std Std     0.2790622
trainer/Policy log std Max     0.2039504
trainer/Policy log std Min     -2.5361097
trainer/Alpha                  0.0016586851561442018
trainer/Alpha Loss             -1.7963100671768188
exploration/num steps total    2521000
exploration/num paths total    5042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9300721520742351
exploration/Rewards Std        0.08023234705296857
exploration/Rewards Max        0.9787914920538052
exploration/Rewards Min        0.48569181003021084
exploration/Returns Mean       465.0360760371177
exploration/Returns Std        19.139759832297017
exploration/Returns Max        480.2465659706864
exploration/Returns Min        411.1563155880522
exploration/Actions Mean       0.015922086
exploration/Actions Std        0.6009806
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    465.0360760371177
evaluation/num steps total     2520000
evaluation/num paths total     5040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9415572931217016
evaluation/Rewards Std         0.057253560935510324
evaluation/Rewards Max         0.9727725368903224
evaluation/Rewards Min         0.48510430315770803
evaluation/Returns Mean        470.7786465608504
evaluation/Returns Std         1.552868887995561
evaluation/Returns Max         473.9100919816449
evaluation/Returns Min         468.9817927778208
evaluation/ExplReturns Mean    470.7786465608504
evaluation/ExplReturns Std     1.552868887995561
evaluation/ExplReturns Max     473.9100919816449
evaluation/ExplReturns Min     468.9817927778208
evaluation/Actions Mean        -0.073023945
evaluation/Actions Std         0.44983247
evaluation/Actions Max         0.99966025
evaluation/Actions Min         -0.9991473
evaluation/Num Paths           10
evaluation/Average Returns     470.7786465608504
time/data storing (s)          0.03216118086129427
time/evaluation sampling (s)   112.46737920120358
time/exploration sampling (s)  113.19999578688294
time/logging (s)               0.030530624091625214
time/saving (s)                0.010275707580149174
time/training (s)              9.631785856559873
time/epoch (s)                 235.37212835717946
time/total (s)                 118054.32840444893
Epoch                          503
-----------------------------  ---------------------
2023-08-02 02:45:39.031074 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 504 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3471.047]
trainer/QF1 Loss               0.023339277
trainer/QF2 Loss               0.023905499
trainer/Policy Loss            -90.62906
trainer/Q1 Predictions Mean    102.2695
trainer/Q1 Predictions Std     1.5866268
trainer/Q1 Predictions Max     106.9575
trainer/Q1 Predictions Min     90.480316
trainer/Q2 Predictions Mean    102.25728
trainer/Q2 Predictions Std     1.5958247
trainer/Q2 Predictions Max     106.96839
trainer/Q2 Predictions Min     90.04701
trainer/Q Targets Mean         102.203804
trainer/Q Targets Std          1.5890226
trainer/Q Targets Max          106.82524
trainer/Q Targets Min          90.40906
trainer/Log Pis Mean           11.773714
trainer/Log Pis Std            7.858998
trainer/Log Pis Max            39.160244
trainer/Log Pis Min            -5.6243095
trainer/Policy mu Mean         0.10670227
trainer/Policy mu Std          1.598917
trainer/Policy mu Max          4.847714
trainer/Policy mu Min          -7.183298
trainer/Policy log std Mean    -0.6881625
trainer/Policy log std Std     0.27354354
trainer/Policy log std Max     0.97285986
trainer/Policy log std Min     -2.2140903
trainer/Alpha                  0.00176535383798182
trainer/Alpha Loss             -1.4345102310180664
exploration/num steps total    2526000
exploration/num paths total    5052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8864393336577936
exploration/Rewards Std        0.1057120924355735
exploration/Rewards Max        0.9783377855770052
exploration/Rewards Min        0.49375203341149954
exploration/Returns Mean       443.2196668288968
exploration/Returns Std        27.855819852336104
exploration/Returns Max        474.4553611690446
exploration/Returns Min        408.46698572090855
exploration/Actions Mean       0.0004819519
exploration/Actions Std        0.6192825
exploration/Actions Max        0.999989
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    443.2196668288968
evaluation/num steps total     2525000
evaluation/num paths total     5050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8864616111440521
evaluation/Rewards Std         0.10522739095314894
evaluation/Rewards Max         0.9777092224345149
evaluation/Rewards Min         0.48250519399546665
evaluation/Returns Mean        443.23080557202593
evaluation/Returns Std         39.13807526441597
evaluation/Returns Max         476.08408165786403
evaluation/Returns Min         387.02230267696916
evaluation/ExplReturns Mean    443.23080557202593
evaluation/ExplReturns Std     39.13807526441597
evaluation/ExplReturns Max     476.08408165786403
evaluation/ExplReturns Min     387.02230267696916
evaluation/Actions Mean        -0.013646392
evaluation/Actions Std         0.52961665
evaluation/Actions Max         0.999906
evaluation/Actions Min         -0.9999744
evaluation/Num Paths           10
evaluation/Average Returns     443.23080557202593
time/data storing (s)          0.03188187163323164
time/evaluation sampling (s)   113.07973490655422
time/exploration sampling (s)  112.5740878554061
time/logging (s)               0.030191603116691113
time/saving (s)                0.0107382507994771
time/training (s)              9.71799648925662
time/epoch (s)                 235.44463097676635
time/total (s)                 118289.77553129569
Epoch                          504
-----------------------------  --------------------
2023-08-02 02:49:37.524394 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 505 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3792.469]
trainer/QF1 Loss               0.021979451
trainer/QF2 Loss               0.017156245
trainer/Policy Loss            -91.046265
trainer/Q1 Predictions Mean    102.600975
trainer/Q1 Predictions Std     1.5030808
trainer/Q1 Predictions Max     106.43325
trainer/Q1 Predictions Min     95.53559
trainer/Q2 Predictions Mean    102.56502
trainer/Q2 Predictions Std     1.4935807
trainer/Q2 Predictions Max     106.44117
trainer/Q2 Predictions Min     96.36179
trainer/Q Targets Mean         102.556854
trainer/Q Targets Std          1.532892
trainer/Q Targets Max          106.551056
trainer/Q Targets Min          96.00562
trainer/Log Pis Mean           11.659187
trainer/Log Pis Std            7.2418504
trainer/Log Pis Max            48.77632
trainer/Log Pis Min            -1.4059385
trainer/Policy mu Mean         0.14812656
trainer/Policy mu Std          1.5585718
trainer/Policy mu Max          5.013441
trainer/Policy mu Min          -5.193194
trainer/Policy log std Mean    -0.73169804
trainer/Policy log std Std     0.26918966
trainer/Policy log std Max     -0.023092628
trainer/Policy log std Min     -2.0603144
trainer/Alpha                  0.0018010669155046344
trainer/Alpha Loss             -2.1536827087402344
exploration/num steps total    2531000
exploration/num paths total    5062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8379589229143497
exploration/Rewards Std        0.12536659449495763
exploration/Rewards Max        0.9789626283701994
exploration/Rewards Min        0.4928256527726048
exploration/Returns Mean       418.97946145717486
exploration/Returns Std        26.381454704363875
exploration/Returns Max        453.8668610890916
exploration/Returns Min        348.0034291381643
exploration/Actions Mean       0.07417841
exploration/Actions Std        0.68117994
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    418.97946145717486
evaluation/num steps total     2530000
evaluation/num paths total     5060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8623302026399424
evaluation/Rewards Std         0.11158554680593422
evaluation/Rewards Max         0.9784550862991376
evaluation/Rewards Min         0.49263742739956584
evaluation/Returns Mean        431.1651013199713
evaluation/Returns Std         11.769928220105069
evaluation/Returns Max         452.8944680676521
evaluation/Returns Min         406.8284232029565
evaluation/ExplReturns Mean    431.1651013199713
evaluation/ExplReturns Std     11.769928220105069
evaluation/ExplReturns Max     452.8944680676521
evaluation/ExplReturns Min     406.8284232029565
evaluation/Actions Mean        0.09820392
evaluation/Actions Std         0.6459109
evaluation/Actions Max         0.9999822
evaluation/Actions Min         -0.9999989
evaluation/Num Paths           10
evaluation/Average Returns     431.1651013199713
time/data storing (s)          0.032069308683276176
time/evaluation sampling (s)   114.65780810266733
time/exploration sampling (s)  113.6499984730035
time/logging (s)               0.03066771849989891
time/saving (s)                0.011452831327915192
time/training (s)              10.105220917612314
time/epoch (s)                 238.48721735179424
time/total (s)                 118528.26520855818
Epoch                          505
-----------------------------  ---------------------
2023-08-02 02:53:35.017646 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 506 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3396.7676]
trainer/QF1 Loss               0.034554213
trainer/QF2 Loss               0.03160668
trainer/Policy Loss            -90.07378
trainer/Q1 Predictions Mean    102.18158
trainer/Q1 Predictions Std     2.5470364
trainer/Q1 Predictions Max     106.42802
trainer/Q1 Predictions Min     84.180954
trainer/Q2 Predictions Mean    102.168564
trainer/Q2 Predictions Std     2.5629296
trainer/Q2 Predictions Max     106.71885
trainer/Q2 Predictions Min     84.65683
trainer/Q Targets Mean         102.25876
trainer/Q Targets Std          2.5438385
trainer/Q Targets Max          106.66882
trainer/Q Targets Min          84.9275
trainer/Log Pis Mean           12.243927
trainer/Log Pis Std            8.282624
trainer/Log Pis Max            43.987244
trainer/Log Pis Min            -2.6434128
trainer/Policy mu Mean         -0.004783828
trainer/Policy mu Std          1.6030895
trainer/Policy mu Max          4.255645
trainer/Policy mu Min          -7.047067
trainer/Policy log std Mean    -0.7278569
trainer/Policy log std Std     0.28030702
trainer/Policy log std Max     1.1709074
trainer/Policy log std Min     -1.955971
trainer/Alpha                  0.0018718027276918292
trainer/Alpha Loss             1.5321061611175537
exploration/num steps total    2536000
exploration/num paths total    5072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9212305322747023
exploration/Rewards Std        0.10851107719039821
exploration/Rewards Max        0.9789615644981231
exploration/Rewards Min        0.4411690803233624
exploration/Returns Mean       460.61526613735106
exploration/Returns Std        30.184000209223264
exploration/Returns Max        481.59522238975273
exploration/Returns Min        396.50817641108955
exploration/Actions Mean       0.05646194
exploration/Actions Std        0.66724646
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    460.61526613735106
evaluation/num steps total     2535000
evaluation/num paths total     5070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8706169602040934
evaluation/Rewards Std         0.11877958748493805
evaluation/Rewards Max         0.9771357010398101
evaluation/Rewards Min         0.4883081103257717
evaluation/Returns Mean        435.3084801020467
evaluation/Returns Std         33.99373306236048
evaluation/Returns Max         480.0666230186142
evaluation/Returns Min         350.54647426291695
evaluation/ExplReturns Mean    435.3084801020467
evaluation/ExplReturns Std     33.99373306236048
evaluation/ExplReturns Max     480.0666230186142
evaluation/ExplReturns Min     350.54647426291695
evaluation/Actions Mean        0.053744238
evaluation/Actions Std         0.6270565
evaluation/Actions Max         0.9999992
evaluation/Actions Min         -0.9999987
evaluation/Num Paths           10
evaluation/Average Returns     435.3084801020467
time/data storing (s)          0.03195445239543915
time/evaluation sampling (s)   114.02225815877318
time/exploration sampling (s)  113.7309630382806
time/logging (s)               0.030581683851778507
time/saving (s)                0.012227077037096024
time/training (s)              9.658431968651712
time/epoch (s)                 237.48641637898982
time/total (s)                 118765.75423156563
Epoch                          506
-----------------------------  ---------------------
2023-08-02 02:57:26.245624 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 507 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4055.5166]
trainer/QF1 Loss               0.026412401
trainer/QF2 Loss               0.030290429
trainer/Policy Loss            -90.873215
trainer/Q1 Predictions Mean    102.767975
trainer/Q1 Predictions Std     2.2089694
trainer/Q1 Predictions Max     107.22634
trainer/Q1 Predictions Min     86.02718
trainer/Q2 Predictions Mean    102.817825
trainer/Q2 Predictions Std     2.2062325
trainer/Q2 Predictions Max     107.256256
trainer/Q2 Predictions Min     85.83427
trainer/Q Targets Mean         102.75227
trainer/Q Targets Std          2.2079318
trainer/Q Targets Max          107.30677
trainer/Q Targets Min          86.02283
trainer/Log Pis Mean           12.06289
trainer/Log Pis Std            8.019316
trainer/Log Pis Max            66.20879
trainer/Log Pis Min            -8.506094
trainer/Policy mu Mean         -0.061004374
trainer/Policy mu Std          1.6287462
trainer/Policy mu Max          5.4491453
trainer/Policy mu Min          -6.624418
trainer/Policy log std Mean    -0.71780485
trainer/Policy log std Std     0.28876722
trainer/Policy log std Max     0.120872796
trainer/Policy log std Min     -1.8918056
trainer/Alpha                  0.002151185879483819
trainer/Alpha Loss             0.38625824451446533
exploration/num steps total    2541000
exploration/num paths total    5082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9623169156202889
exploration/Rewards Std        0.050187443039872215
exploration/Rewards Max        0.9789978017680614
exploration/Rewards Min        0.4921415174039365
exploration/Returns Mean       481.1584578101442
exploration/Returns Std        0.28434344412712426
exploration/Returns Max        481.5070159568011
exploration/Returns Min        480.62393422775926
exploration/Actions Mean       0.02512005
exploration/Actions Std        0.56625134
exploration/Actions Max        0.99995536
exploration/Actions Min        -0.99998325
exploration/Num Paths          10
exploration/Average Returns    481.1584578101442
evaluation/num steps total     2540000
evaluation/num paths total     5080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9622835214338391
evaluation/Rewards Std         0.04916018723456869
evaluation/Rewards Max         0.979046468910441
evaluation/Rewards Min         0.4915309904712077
evaluation/Returns Mean        481.14176071691963
evaluation/Returns Std         0.2850471325361679
evaluation/Returns Max         481.64922010822335
evaluation/Returns Min         480.74906406297384
evaluation/ExplReturns Mean    481.14176071691963
evaluation/ExplReturns Std     0.2850471325361679
evaluation/ExplReturns Max     481.64922010822335
evaluation/ExplReturns Min     480.74906406297384
evaluation/Actions Mean        0.045167718
evaluation/Actions Std         0.4942935
evaluation/Actions Max         0.9999645
evaluation/Actions Min         -0.999866
evaluation/Num Paths           10
evaluation/Average Returns     481.14176071691963
time/data storing (s)          0.03187007177621126
time/evaluation sampling (s)   111.83379841875285
time/exploration sampling (s)  109.73558315820992
time/logging (s)               0.030523723922669888
time/saving (s)                0.011084839701652527
time/training (s)              9.578115336596966
time/epoch (s)                 231.22097554896027
time/total (s)                 118996.97800852731
Epoch                          507
-----------------------------  --------------------
2023-08-02 03:01:17.748241 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 508 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3500.4443]
trainer/QF1 Loss               0.03818375
trainer/QF2 Loss               0.040766887
trainer/Policy Loss            -91.695496
trainer/Q1 Predictions Mean    103.32776
trainer/Q1 Predictions Std     2.2099254
trainer/Q1 Predictions Max     107.516945
trainer/Q1 Predictions Min     86.86585
trainer/Q2 Predictions Mean    103.34066
trainer/Q2 Predictions Std     2.2293646
trainer/Q2 Predictions Max     107.738434
trainer/Q2 Predictions Min     86.806206
trainer/Q Targets Mean         103.25915
trainer/Q Targets Std          2.215298
trainer/Q Targets Max          107.628044
trainer/Q Targets Min          86.556175
trainer/Log Pis Mean           11.818581
trainer/Log Pis Std            7.2875223
trainer/Log Pis Max            42.22967
trainer/Log Pis Min            -5.952548
trainer/Policy mu Mean         -0.039460722
trainer/Policy mu Std          1.5790712
trainer/Policy mu Max          6.020273
trainer/Policy mu Min          -6.147963
trainer/Policy log std Mean    -0.69745415
trainer/Policy log std Std     0.26534554
trainer/Policy log std Max     0.5950177
trainer/Policy log std Min     -1.7216327
trainer/Alpha                  0.0026194602251052856
trainer/Alpha Loss             -1.0785216093063354
exploration/num steps total    2546000
exploration/num paths total    5092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9607097277965854
exploration/Rewards Std        0.05435667811971064
exploration/Rewards Max        0.9778549732955165
exploration/Rewards Min        0.4867759154228776
exploration/Returns Mean       480.35486389829265
exploration/Returns Std        1.3282066190547865
exploration/Returns Max        482.1088296615437
exploration/Returns Min        477.2563577691031
exploration/Actions Mean       0.10398352
exploration/Actions Std        0.5608183
exploration/Actions Max        0.99998444
exploration/Actions Min        -0.9999824
exploration/Num Paths          10
exploration/Average Returns    480.35486389829265
evaluation/num steps total     2545000
evaluation/num paths total     5090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9350909684084167
evaluation/Rewards Std         0.08772915355769802
evaluation/Rewards Max         0.9744673003298067
evaluation/Rewards Min         0.4847047004728672
evaluation/Returns Mean        467.54548420420826
evaluation/Returns Std         36.20878652583801
evaluation/Returns Max         480.27168505488066
evaluation/Returns Min         358.92833091947455
evaluation/ExplReturns Mean    467.54548420420826
evaluation/ExplReturns Std     36.20878652583801
evaluation/ExplReturns Max     480.27168505488066
evaluation/ExplReturns Min     358.92833091947455
evaluation/Actions Mean        0.108427785
evaluation/Actions Std         0.48432836
evaluation/Actions Max         0.99991536
evaluation/Actions Min         -0.99994373
evaluation/Num Paths           10
evaluation/Average Returns     467.54548420420826
time/data storing (s)          0.03192480467259884
time/evaluation sampling (s)   110.47071576025337
time/exploration sampling (s)  111.27354385424405
time/logging (s)               0.030654486268758774
time/saving (s)                0.012537840753793716
time/training (s)              9.676783561706543
time/epoch (s)                 231.49616030789912
time/total (s)                 119228.47661419399
Epoch                          508
-----------------------------  ---------------------
2023-08-02 03:05:08.397579 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 509 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3510.9255]
trainer/QF1 Loss               0.04056135
trainer/QF2 Loss               0.0363822
trainer/Policy Loss            -92.0244
trainer/Q1 Predictions Mean    103.94215
trainer/Q1 Predictions Std     2.4354281
trainer/Q1 Predictions Max     107.73202
trainer/Q1 Predictions Min     86.663155
trainer/Q2 Predictions Mean    103.955246
trainer/Q2 Predictions Std     2.4624062
trainer/Q2 Predictions Max     107.73409
trainer/Q2 Predictions Min     86.50852
trainer/Q Targets Mean         104.028015
trainer/Q Targets Std          2.4332795
trainer/Q Targets Max          107.791916
trainer/Q Targets Min          87.41147
trainer/Log Pis Mean           12.189415
trainer/Log Pis Std            7.0421367
trainer/Log Pis Max            51.958454
trainer/Log Pis Min            -5.9620094
trainer/Policy mu Mean         0.09804388
trainer/Policy mu Std          1.6081585
trainer/Policy mu Max          4.9504466
trainer/Policy mu Min          -5.7107873
trainer/Policy log std Mean    -0.69393045
trainer/Policy log std Std     0.2535025
trainer/Policy log std Max     0.18809453
trainer/Policy log std Min     -1.850841
trainer/Alpha                  0.0028332206420600414
trainer/Alpha Loss             1.111196517944336
exploration/num steps total    2551000
exploration/num paths total    5102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7961084031139717
exploration/Rewards Std        0.11107130236258449
exploration/Rewards Max        0.9744347518579697
exploration/Rewards Min        0.493975681125641
exploration/Returns Mean       398.0542015569858
exploration/Returns Std        7.5037031449474005
exploration/Returns Max        413.3061907653135
exploration/Returns Min        383.6432277493257
exploration/Actions Mean       -0.04110264
exploration/Actions Std        0.57576203
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    398.0542015569858
evaluation/num steps total     2550000
evaluation/num paths total     5100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7030410150816458
evaluation/Rewards Std         0.02410450530495551
evaluation/Rewards Max         0.9335160880695746
evaluation/Rewards Min         0.4936667833905055
evaluation/Returns Mean        351.5205075408229
evaluation/Returns Std         0.7515950438712613
evaluation/Returns Max         353.6010219902287
evaluation/Returns Min         350.9180135441051
evaluation/ExplReturns Mean    351.5205075408229
evaluation/ExplReturns Std     0.7515950438712613
evaluation/ExplReturns Max     353.6010219902287
evaluation/ExplReturns Min     350.9180135441051
evaluation/Actions Mean        -0.121772096
evaluation/Actions Std         0.50824887
evaluation/Actions Max         0.9999995
evaluation/Actions Min         -0.9997791
evaluation/Num Paths           10
evaluation/Average Returns     351.5205075408229
time/data storing (s)          0.032101163640618324
time/evaluation sampling (s)   109.12857168912888
time/exploration sampling (s)  111.77011638414115
time/logging (s)               0.03192115854471922
time/saving (s)                0.012980395928025246
time/training (s)              9.667996465228498
time/epoch (s)                 230.64368725661188
time/total (s)                 119459.12299773935
Epoch                          509
-----------------------------  ---------------------
2023-08-02 03:09:00.266660 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 510 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4123.567]
trainer/QF1 Loss               0.025564222
trainer/QF2 Loss               0.02258502
trainer/Policy Loss            -94.39153
trainer/Q1 Predictions Mean    104.91231
trainer/Q1 Predictions Std     2.3580854
trainer/Q1 Predictions Max     107.99804
trainer/Q1 Predictions Min     85.82813
trainer/Q2 Predictions Mean    104.94704
trainer/Q2 Predictions Std     2.3785198
trainer/Q2 Predictions Max     108.05197
trainer/Q2 Predictions Min     85.41266
trainer/Q Targets Mean         104.90916
trainer/Q Targets Std          2.3554845
trainer/Q Targets Max          108.03379
trainer/Q Targets Min          86.303505
trainer/Log Pis Mean           10.722572
trainer/Log Pis Std            6.22204
trainer/Log Pis Max            32.25003
trainer/Log Pis Min            -5.0378027
trainer/Policy mu Mean         0.095227696
trainer/Policy mu Std          1.5277492
trainer/Policy mu Max          6.7476187
trainer/Policy mu Min          -4.943563
trainer/Policy log std Mean    -0.7048731
trainer/Policy log std Std     0.25210527
trainer/Policy log std Max     0.09196079
trainer/Policy log std Min     -1.6991109
trainer/Alpha                  0.0028891917318105698
trainer/Alpha Loss             -7.468559265136719
exploration/num steps total    2556000
exploration/num paths total    5112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9483836105493029
exploration/Rewards Std        0.07171615993690603
exploration/Rewards Max        0.9765118952157277
exploration/Rewards Min        0.4931943849482523
exploration/Returns Mean       474.1918052746513
exploration/Returns Std        2.35279333088447
exploration/Returns Max        477.18708324348
exploration/Returns Min        469.6691752027417
exploration/Actions Mean       -0.089629635
exploration/Actions Std        0.5217901
exploration/Actions Max        0.99955994
exploration/Actions Min        -0.9999415
exploration/Num Paths          10
exploration/Average Returns    474.1918052746513
evaluation/num steps total     2555000
evaluation/num paths total     5110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.956364171266084
evaluation/Rewards Std         0.06727232604572782
evaluation/Rewards Max         0.9730192444985409
evaluation/Rewards Min         0.4926920015115525
evaluation/Returns Mean        478.182085633042
evaluation/Returns Std         1.3106568621248
evaluation/Returns Max         480.2346630336149
evaluation/Returns Min         474.90379033800275
evaluation/ExplReturns Mean    478.182085633042
evaluation/ExplReturns Std     1.3106568621248
evaluation/ExplReturns Max     480.2346630336149
evaluation/ExplReturns Min     474.90379033800275
evaluation/Actions Mean        -0.08181633
evaluation/Actions Std         0.35563862
evaluation/Actions Max         0.99862736
evaluation/Actions Min         -0.9999279
evaluation/Num Paths           10
evaluation/Average Returns     478.182085633042
time/data storing (s)          0.0319580752402544
time/evaluation sampling (s)   111.13689220976084
time/exploration sampling (s)  111.03820022009313
time/logging (s)               0.030493466183543205
time/saving (s)                0.01274034846574068
time/training (s)              9.610699624754488
time/epoch (s)                 231.860983944498
time/total (s)                 119690.98647814151
Epoch                          510
-----------------------------  ---------------------
2023-08-02 03:12:52.450003 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 511 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3605.0122]
trainer/QF1 Loss               0.0506868
trainer/QF2 Loss               0.041468974
trainer/Policy Loss            -93.49958
trainer/Q1 Predictions Mean    104.682556
trainer/Q1 Predictions Std     2.264209
trainer/Q1 Predictions Max     108.45999
trainer/Q1 Predictions Min     92.05264
trainer/Q2 Predictions Mean    104.72276
trainer/Q2 Predictions Std     2.2292197
trainer/Q2 Predictions Max     108.415016
trainer/Q2 Predictions Min     92.79561
trainer/Q Targets Mean         104.780556
trainer/Q Targets Std          2.2273586
trainer/Q Targets Max          108.40373
trainer/Q Targets Min          92.89418
trainer/Log Pis Mean           11.424143
trainer/Log Pis Std            6.269916
trainer/Log Pis Max            37.795795
trainer/Log Pis Min            -3.202272
trainer/Policy mu Mean         -0.055537272
trainer/Policy mu Std          1.5660073
trainer/Policy mu Max          3.8132904
trainer/Policy mu Min          -5.383742
trainer/Policy log std Mean    -0.7146041
trainer/Policy log std Std     0.26575038
trainer/Policy log std Max     0.10950798
trainer/Policy log std Min     -1.7439708
trainer/Alpha                  0.002733915578573942
trainer/Alpha Loss             -3.398566961288452
exploration/num steps total    2561000
exploration/num paths total    5122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9403803060344824
exploration/Rewards Std        0.0856474928540459
exploration/Rewards Max        0.9796511702012488
exploration/Rewards Min        0.4927407354212216
exploration/Returns Mean       470.1901530172412
exploration/Returns Std        9.948378413349817
exploration/Returns Max        477.9553249272323
exploration/Returns Min        442.84670373131286
exploration/Actions Mean       -0.08663951
exploration/Actions Std        0.58813995
exploration/Actions Max        0.99999285
exploration/Actions Min        -0.99999917
exploration/Num Paths          10
exploration/Average Returns    470.1901530172412
evaluation/num steps total     2560000
evaluation/num paths total     5120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9423713965754097
evaluation/Rewards Std         0.08891301066287977
evaluation/Rewards Max         0.977530787775315
evaluation/Rewards Min         0.4861466055076947
evaluation/Returns Mean        471.1856982877048
evaluation/Returns Std         3.0301519520397977
evaluation/Returns Max         475.8329262042804
evaluation/Returns Min         466.06021539081667
evaluation/ExplReturns Mean    471.1856982877048
evaluation/ExplReturns Std     3.0301519520397977
evaluation/ExplReturns Max     475.8329262042804
evaluation/ExplReturns Min     466.06021539081667
evaluation/Actions Mean        -0.13075121
evaluation/Actions Std         0.40233463
evaluation/Actions Max         0.9993889
evaluation/Actions Min         -0.9998982
evaluation/Num Paths           10
evaluation/Average Returns     471.1856982877048
time/data storing (s)          0.03164394199848175
time/evaluation sampling (s)   111.00310411117971
time/exploration sampling (s)  111.44998699519783
time/logging (s)               0.030583019368350506
time/saving (s)                0.010918754152953625
time/training (s)              9.650491732172668
time/epoch (s)                 232.17672855407
time/total (s)                 119923.16572541744
Epoch                          511
-----------------------------  --------------------
2023-08-02 03:16:43.100841 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 512 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4033.651]
trainer/QF1 Loss               0.04625506
trainer/QF2 Loss               0.04985103
trainer/Policy Loss            -93.41883
trainer/Q1 Predictions Mean    105.12653
trainer/Q1 Predictions Std     2.6329186
trainer/Q1 Predictions Max     108.43183
trainer/Q1 Predictions Min     90.51427
trainer/Q2 Predictions Mean    105.12595
trainer/Q2 Predictions Std     2.5928867
trainer/Q2 Predictions Max     108.40682
trainer/Q2 Predictions Min     91.1796
trainer/Q Targets Mean         105.21782
trainer/Q Targets Std          2.6476204
trainer/Q Targets Max          108.5358
trainer/Q Targets Min          89.57027
trainer/Log Pis Mean           11.924218
trainer/Log Pis Std            6.885667
trainer/Log Pis Max            41.156467
trainer/Log Pis Min            -6.2433805
trainer/Policy mu Mean         0.051532168
trainer/Policy mu Std          1.5682439
trainer/Policy mu Max          4.371749
trainer/Policy mu Min          -5.478504
trainer/Policy log std Mean    -0.71160436
trainer/Policy log std Std     0.26946247
trainer/Policy log std Max     0.05442658
trainer/Policy log std Min     -1.7397329
trainer/Alpha                  0.0028196934144943953
trainer/Alpha Loss             -0.44492530822753906
exploration/num steps total    2566000
exploration/num paths total    5132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9561934575210518
exploration/Rewards Std        0.06694170476093081
exploration/Rewards Max        0.9797437084091399
exploration/Rewards Min        0.4975044883090982
exploration/Returns Mean       478.09672876052593
exploration/Returns Std        1.2060757275903562
exploration/Returns Max        480.5392472457375
exploration/Returns Min        476.268680686188
exploration/Actions Mean       -0.022188846
exploration/Actions Std        0.5613397
exploration/Actions Max        0.99986124
exploration/Actions Min        -0.99995154
exploration/Num Paths          10
exploration/Average Returns    478.09672876052593
evaluation/num steps total     2565000
evaluation/num paths total     5130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9565641382865373
evaluation/Rewards Std         0.06867305688242452
evaluation/Rewards Max         0.976914933957888
evaluation/Rewards Min         0.488003465708929
evaluation/Returns Mean        478.28206914326876
evaluation/Returns Std         0.7914413115750136
evaluation/Returns Max         479.8191016530825
evaluation/Returns Min         477.1598609700585
evaluation/ExplReturns Mean    478.28206914326876
evaluation/ExplReturns Std     0.7914413115750136
evaluation/ExplReturns Max     479.8191016530825
evaluation/ExplReturns Min     477.1598609700585
evaluation/Actions Mean        0.0003957678
evaluation/Actions Std         0.37818176
evaluation/Actions Max         0.99898946
evaluation/Actions Min         -0.9998399
evaluation/Num Paths           10
evaluation/Average Returns     478.28206914326876
time/data storing (s)          0.03184886276721954
time/evaluation sampling (s)   111.02115930430591
time/exploration sampling (s)  109.93557745590806
time/logging (s)               0.030865156091749668
time/saving (s)                0.012881074100732803
time/training (s)              9.611812222748995
time/epoch (s)                 230.64414407592267
time/total (s)                 120153.81266680732
Epoch                          512
-----------------------------  ---------------------
2023-08-02 03:20:34.444834 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 513 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3912.142]
trainer/QF1 Loss               0.05112551
trainer/QF2 Loss               0.051650297
trainer/Policy Loss            -94.19618
trainer/Q1 Predictions Mean    105.77477
trainer/Q1 Predictions Std     2.1692886
trainer/Q1 Predictions Max     108.54807
trainer/Q1 Predictions Min     91.00152
trainer/Q2 Predictions Mean    105.80324
trainer/Q2 Predictions Std     2.1702852
trainer/Q2 Predictions Max     108.61192
trainer/Q2 Predictions Min     91.14216
trainer/Q Targets Mean         105.710884
trainer/Q Targets Std          2.173625
trainer/Q Targets Max          108.424706
trainer/Q Targets Min          91.400116
trainer/Log Pis Mean           11.785212
trainer/Log Pis Std            6.0318093
trainer/Log Pis Max            30.240767
trainer/Log Pis Min            -6.703756
trainer/Policy mu Mean         0.0018312124
trainer/Policy mu Std          1.570839
trainer/Policy mu Max          4.6092405
trainer/Policy mu Min          -4.640401
trainer/Policy log std Mean    -0.7201702
trainer/Policy log std Std     0.2565968
trainer/Policy log std Max     -0.017513275
trainer/Policy log std Min     -1.6853346
trainer/Alpha                  0.0025980134960263968
trainer/Alpha Loss             -1.2786164283752441
exploration/num steps total    2571000
exploration/num paths total    5142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9593896470780281
exploration/Rewards Std        0.0601861560903626
exploration/Rewards Max        0.9795411955740407
exploration/Rewards Min        0.49077150275594417
exploration/Returns Mean       479.694823539014
exploration/Returns Std        4.648286557729577
exploration/Returns Max        482.40449892008417
exploration/Returns Min        467.3903115941722
exploration/Actions Mean       -0.0445985
exploration/Actions Std        0.5681439
exploration/Actions Max        0.99968535
exploration/Actions Min        -0.9999826
exploration/Num Paths          10
exploration/Average Returns    479.694823539014
evaluation/num steps total     2570000
evaluation/num paths total     5140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9643752974478393
evaluation/Rewards Std         0.05415966212565978
evaluation/Rewards Max         0.9785253571707813
evaluation/Rewards Min         0.4938953120500439
evaluation/Returns Mean        482.18764872391966
evaluation/Returns Std         1.1105193543032226
evaluation/Returns Max         483.4903933605561
evaluation/Returns Min         480.35081312017263
evaluation/ExplReturns Mean    482.18764872391966
evaluation/ExplReturns Std     1.1105193543032226
evaluation/ExplReturns Max     483.4903933605561
evaluation/ExplReturns Min     480.35081312017263
evaluation/Actions Mean        -0.048201974
evaluation/Actions Std         0.35535052
evaluation/Actions Max         0.9982545
evaluation/Actions Min         -0.9998186
evaluation/Num Paths           10
evaluation/Average Returns     482.18764872391966
time/data storing (s)          0.032103607431054115
time/evaluation sampling (s)   110.99935878627002
time/exploration sampling (s)  110.7163918800652
time/logging (s)               0.03039238229393959
time/saving (s)                0.01231145765632391
time/training (s)              9.54624043777585
time/epoch (s)                 231.3367985514924
time/total (s)                 120385.15203685965
Epoch                          513
-----------------------------  ---------------------
2023-08-02 03:24:29.085160 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 514 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4137.4453]
trainer/QF1 Loss               0.05645023
trainer/QF2 Loss               0.058213793
trainer/Policy Loss            -94.468414
trainer/Q1 Predictions Mean    105.95058
trainer/Q1 Predictions Std     3.411589
trainer/Q1 Predictions Max     108.34067
trainer/Q1 Predictions Min     72.73258
trainer/Q2 Predictions Mean    105.99432
trainer/Q2 Predictions Std     3.4132357
trainer/Q2 Predictions Max     108.42388
trainer/Q2 Predictions Min     73.16328
trainer/Q Targets Mean         105.89356
trainer/Q Targets Std          3.3608282
trainer/Q Targets Max          108.29144
trainer/Q Targets Min          72.84832
trainer/Log Pis Mean           11.69678
trainer/Log Pis Std            7.3104215
trainer/Log Pis Max            47.09111
trainer/Log Pis Min            -7.449478
trainer/Policy mu Mean         -0.09343345
trainer/Policy mu Std          1.5912254
trainer/Policy mu Max          5.711353
trainer/Policy mu Min          -5.1180143
trainer/Policy log std Mean    -0.69937396
trainer/Policy log std Std     0.24664204
trainer/Policy log std Max     0.5212809
trainer/Policy log std Min     -1.7095248
trainer/Alpha                  0.0025262711569666862
trainer/Alpha Loss             -1.8135560750961304
exploration/num steps total    2576000
exploration/num paths total    5152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9597971953535754
exploration/Rewards Std        0.05954492322230785
exploration/Rewards Max        0.9797018559117012
exploration/Rewards Min        0.4868092298789371
exploration/Returns Mean       479.89859767678774
exploration/Returns Std        4.594049756440793
exploration/Returns Max        482.7389693949194
exploration/Returns Min        466.67861605260987
exploration/Actions Mean       -0.023924017
exploration/Actions Std        0.5748213
exploration/Actions Max        0.99962413
exploration/Actions Min        -0.99988014
exploration/Num Paths          10
exploration/Average Returns    479.89859767678774
evaluation/num steps total     2575000
evaluation/num paths total     5150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9598538365036707
evaluation/Rewards Std         0.05650775650422087
evaluation/Rewards Max         0.9777432981090319
evaluation/Rewards Min         0.4979425330696667
evaluation/Returns Mean        479.9269182518354
evaluation/Returns Std         5.719519611100717
evaluation/Returns Max         482.51845026985796
evaluation/Returns Min         462.82029519874794
evaluation/ExplReturns Mean    479.9269182518354
evaluation/ExplReturns Std     5.719519611100717
evaluation/ExplReturns Max     482.51845026985796
evaluation/ExplReturns Min     462.82029519874794
evaluation/Actions Mean        0.04634003
evaluation/Actions Std         0.43326595
evaluation/Actions Max         0.99789196
evaluation/Actions Min         -0.9991819
evaluation/Num Paths           10
evaluation/Average Returns     479.9269182518354
time/data storing (s)          0.0322075430303812
time/evaluation sampling (s)   112.69085945188999
time/exploration sampling (s)  112.21712280344218
time/logging (s)               0.03059452772140503
time/saving (s)                0.012211491353809834
time/training (s)              9.650749882683158
time/epoch (s)                 234.63374570012093
time/total (s)                 120619.78833529074
Epoch                          514
-----------------------------  ---------------------
2023-08-02 03:28:22.258700 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 515 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3776.8237]
trainer/QF1 Loss               0.025303606
trainer/QF2 Loss               0.030618612
trainer/Policy Loss            -95.67691
trainer/Q1 Predictions Mean    106.45453
trainer/Q1 Predictions Std     2.0949225
trainer/Q1 Predictions Max     108.28191
trainer/Q1 Predictions Min     81.85325
trainer/Q2 Predictions Mean    106.47699
trainer/Q2 Predictions Std     2.1339095
trainer/Q2 Predictions Max     108.355804
trainer/Q2 Predictions Min     81.435036
trainer/Q Targets Mean         106.471825
trainer/Q Targets Std          2.0773969
trainer/Q Targets Max          108.31704
trainer/Q Targets Min          82.67752
trainer/Log Pis Mean           10.972316
trainer/Log Pis Std            6.31326
trainer/Log Pis Max            39.609596
trainer/Log Pis Min            -3.8823905
trainer/Policy mu Mean         0.03832735
trainer/Policy mu Std          1.5495181
trainer/Policy mu Max          4.1067457
trainer/Policy mu Min          -8.901341
trainer/Policy log std Mean    -0.68429214
trainer/Policy log std Std     0.24602097
trainer/Policy log std Max     1.1753863
trainer/Policy log std Min     -1.8992035
trainer/Alpha                  0.00233343499712646
trainer/Alpha Loss             -6.227877140045166
exploration/num steps total    2581000
exploration/num paths total    5162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9597728254519093
exploration/Rewards Std        0.04954824495694755
exploration/Rewards Max        0.9794941274324094
exploration/Rewards Min        0.4898420586459509
exploration/Returns Mean       479.8864127259546
exploration/Returns Std        0.5824445888474147
exploration/Returns Max        480.78440162627095
exploration/Returns Min        478.50946330504803
exploration/Actions Mean       0.05735494
exploration/Actions Std        0.61865294
exploration/Actions Max        0.99994946
exploration/Actions Min        -0.9998544
exploration/Num Paths          10
exploration/Average Returns    479.8864127259546
evaluation/num steps total     2580000
evaluation/num paths total     5160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9630218342154804
evaluation/Rewards Std         0.048694635705125076
evaluation/Rewards Max         0.9798757978804787
evaluation/Rewards Min         0.5003075410421532
evaluation/Returns Mean        481.51091710774
evaluation/Returns Std         0.574593695402664
evaluation/Returns Max         482.04954081376894
evaluation/Returns Min         480.4653310138975
evaluation/ExplReturns Mean    481.51091710774
evaluation/ExplReturns Std     0.574593695402664
evaluation/ExplReturns Max     482.04954081376894
evaluation/ExplReturns Min     480.4653310138975
evaluation/Actions Mean        0.029654583
evaluation/Actions Std         0.5337145
evaluation/Actions Max         0.9979822
evaluation/Actions Min         -0.9992633
evaluation/Num Paths           10
evaluation/Average Returns     481.51091710774
time/data storing (s)          0.03240001201629639
time/evaluation sampling (s)   111.0658629052341
time/exploration sampling (s)  112.38067527394742
time/logging (s)               0.030256723053753376
time/saving (s)                0.012772809714078903
time/training (s)              9.644499809481204
time/epoch (s)                 233.16646753344685
time/total (s)                 120852.95741282217
Epoch                          515
-----------------------------  --------------------
2023-08-02 03:32:17.166133 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 516 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3575.6682]
trainer/QF1 Loss               0.05975756
trainer/QF2 Loss               0.043275625
trainer/Policy Loss            -93.66785
trainer/Q1 Predictions Mean    106.23181
trainer/Q1 Predictions Std     2.3996794
trainer/Q1 Predictions Max     108.13612
trainer/Q1 Predictions Min     77.631096
trainer/Q2 Predictions Mean    106.30678
trainer/Q2 Predictions Std     2.3824456
trainer/Q2 Predictions Max     108.23465
trainer/Q2 Predictions Min     77.9547
trainer/Q Targets Mean         106.38344
trainer/Q Targets Std          2.4016635
trainer/Q Targets Max          108.3005
trainer/Q Targets Min          77.550964
trainer/Log Pis Mean           12.76029
trainer/Log Pis Std            7.2902703
trainer/Log Pis Max            42.660755
trainer/Log Pis Min            -5.327193
trainer/Policy mu Mean         -0.1128844
trainer/Policy mu Std          1.6152661
trainer/Policy mu Max          5.6921983
trainer/Policy mu Min          -4.9994445
trainer/Policy log std Mean    -0.706995
trainer/Policy log std Std     0.2539323
trainer/Policy log std Max     0.061278403
trainer/Policy log std Min     -1.7314032
trainer/Alpha                  0.0021601913031190634
trainer/Alpha Loss             4.666357040405273
exploration/num steps total    2586000
exploration/num paths total    5172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.958292879952836
exploration/Rewards Std        0.04812624884131659
exploration/Rewards Max        0.9784207808390808
exploration/Rewards Min        0.49091260780296575
exploration/Returns Mean       479.1464399764178
exploration/Returns Std        0.44107855555372233
exploration/Returns Max        480.29636924849984
exploration/Returns Min        478.7620615486304
exploration/Actions Mean       0.07963781
exploration/Actions Std        0.6036724
exploration/Actions Max        0.9997705
exploration/Actions Min        -0.99977607
exploration/Num Paths          10
exploration/Average Returns    479.1464399764178
evaluation/num steps total     2585000
evaluation/num paths total     5170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9615351108123432
evaluation/Rewards Std         0.048424877607458595
evaluation/Rewards Max         0.9775618056528623
evaluation/Rewards Min         0.501294956301273
evaluation/Returns Mean        480.7675554061717
evaluation/Returns Std         0.34653912745786625
evaluation/Returns Max         481.4343080458364
evaluation/Returns Min         480.2730021647621
evaluation/ExplReturns Mean    480.7675554061717
evaluation/ExplReturns Std     0.34653912745786625
evaluation/ExplReturns Max     481.4343080458364
evaluation/ExplReturns Min     480.2730021647621
evaluation/Actions Mean        0.078934945
evaluation/Actions Std         0.5620758
evaluation/Actions Max         0.99913543
evaluation/Actions Min         -0.9981141
evaluation/Num Paths           10
evaluation/Average Returns     480.7675554061717
time/data storing (s)          0.032027266919612885
time/evaluation sampling (s)   112.11433090828359
time/exploration sampling (s)  113.11016653385013
time/logging (s)               0.03048934042453766
time/saving (s)                0.012064359150826931
time/training (s)              9.601773857139051
time/epoch (s)                 234.90085226576775
time/total (s)                 121087.86072753835
Epoch                          516
-----------------------------  ---------------------
2023-08-02 03:36:12.268407 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 517 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4041.2515]
trainer/QF1 Loss               0.032610197
trainer/QF2 Loss               0.059158623
trainer/Policy Loss            -94.82258
trainer/Q1 Predictions Mean    106.51834
trainer/Q1 Predictions Std     2.9448018
trainer/Q1 Predictions Max     108.38146
trainer/Q1 Predictions Min     72.83733
trainer/Q2 Predictions Mean    106.405045
trainer/Q2 Predictions Std     2.9480956
trainer/Q2 Predictions Max     108.2575
trainer/Q2 Predictions Min     72.014366
trainer/Q Targets Mean         106.59899
trainer/Q Targets Std          2.9978404
trainer/Q Targets Max          108.332565
trainer/Q Targets Min          71.58558
trainer/Log Pis Mean           11.743383
trainer/Log Pis Std            6.8577
trainer/Log Pis Max            37.25517
trainer/Log Pis Min            -6.040947
trainer/Policy mu Mean         -0.047300566
trainer/Policy mu Std          1.5775018
trainer/Policy mu Max          6.774496
trainer/Policy mu Min          -5.3930016
trainer/Policy log std Mean    -0.7028127
trainer/Policy log std Std     0.27450895
trainer/Policy log std Max     0.43902183
trainer/Policy log std Min     -2.141885
trainer/Alpha                  0.0020264459308236837
trainer/Alpha Loss             -1.5914051532745361
exploration/num steps total    2591000
exploration/num paths total    5182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9579385628225792
exploration/Rewards Std        0.04923505974052933
exploration/Rewards Max        0.9786231249838178
exploration/Rewards Min        0.4951239242653606
exploration/Returns Mean       478.96928141128967
exploration/Returns Std        0.28882883318628494
exploration/Returns Max        479.41965825942856
exploration/Returns Min        478.53591883217183
exploration/Actions Mean       0.049177926
exploration/Actions Std        0.5574644
exploration/Actions Max        0.99990356
exploration/Actions Min        -0.9999065
exploration/Num Paths          10
exploration/Average Returns    478.96928141128967
evaluation/num steps total     2590000
evaluation/num paths total     5180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9579336819365024
evaluation/Rewards Std         0.049465114327479735
evaluation/Rewards Max         0.9795070320090802
evaluation/Rewards Min         0.4894589887590328
evaluation/Returns Mean        478.9668409682512
evaluation/Returns Std         0.39719323176684596
evaluation/Returns Max         479.66326539640295
evaluation/Returns Min         478.30239464533184
evaluation/ExplReturns Mean    478.9668409682512
evaluation/ExplReturns Std     0.39719323176684596
evaluation/ExplReturns Max     479.66326539640295
evaluation/ExplReturns Min     478.30239464533184
evaluation/Actions Mean        0.056873415
evaluation/Actions Std         0.50288063
evaluation/Actions Max         0.99820995
evaluation/Actions Min         -0.9989945
evaluation/Num Paths           10
evaluation/Average Returns     478.9668409682512
time/data storing (s)          0.03216245025396347
time/evaluation sampling (s)   112.56920239795
time/exploration sampling (s)  112.82155304588377
time/logging (s)               0.030844245105981827
time/saving (s)                0.012762571685016155
time/training (s)              9.629397170618176
time/epoch (s)                 235.0959218814969
time/total (s)                 121322.9591422826
Epoch                          517
-----------------------------  ---------------------
2023-08-02 03:40:07.988875 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 518 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3858.6045]
trainer/QF1 Loss               0.035192266
trainer/QF2 Loss               0.043210667
trainer/Policy Loss            -93.98141
trainer/Q1 Predictions Mean    106.57882
trainer/Q1 Predictions Std     1.9033971
trainer/Q1 Predictions Max     108.0955
trainer/Q1 Predictions Min     86.94101
trainer/Q2 Predictions Mean    106.633606
trainer/Q2 Predictions Std     1.9653032
trainer/Q2 Predictions Max     108.08874
trainer/Q2 Predictions Min     85.284805
trainer/Q Targets Mean         106.653114
trainer/Q Targets Std          1.8555037
trainer/Q Targets Max          108.08183
trainer/Q Targets Min          87.68927
trainer/Log Pis Mean           12.743954
trainer/Log Pis Std            8.115085
trainer/Log Pis Max            52.99902
trainer/Log Pis Min            -4.5504446
trainer/Policy mu Mean         0.048589304
trainer/Policy mu Std          1.6333376
trainer/Policy mu Max          7.83819
trainer/Policy mu Min          -6.217475
trainer/Policy log std Mean    -0.69605595
trainer/Policy log std Std     0.26751298
trainer/Policy log std Max     0.57791996
trainer/Policy log std Min     -1.7720735
trainer/Alpha                  0.0018713270546868443
trainer/Alpha Loss             4.672893047332764
exploration/num steps total    2596000
exploration/num paths total    5192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9606719561670628
exploration/Rewards Std        0.0500894686358224
exploration/Rewards Max        0.9792570980912768
exploration/Rewards Min        0.49720433773371886
exploration/Returns Mean       480.33597808353153
exploration/Returns Std        0.2168023967278564
exploration/Returns Max        480.59404675988947
exploration/Returns Min        479.9254180018522
exploration/Actions Mean       0.0509457
exploration/Actions Std        0.56624556
exploration/Actions Max        0.9999353
exploration/Actions Min        -0.9999667
exploration/Num Paths          10
exploration/Average Returns    480.33597808353153
evaluation/num steps total     2595000
evaluation/num paths total     5190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9595472934642996
evaluation/Rewards Std         0.05037853594327385
evaluation/Rewards Max         0.9787495917395486
evaluation/Rewards Min         0.49627241507716635
evaluation/Returns Mean        479.77364673214953
evaluation/Returns Std         0.6885834882379364
evaluation/Returns Max         480.42831416618105
evaluation/Returns Min         478.04873090686345
evaluation/ExplReturns Mean    479.77364673214953
evaluation/ExplReturns Std     0.6885834882379364
evaluation/ExplReturns Max     480.42831416618105
evaluation/ExplReturns Min     478.04873090686345
evaluation/Actions Mean        0.049432684
evaluation/Actions Std         0.47481173
evaluation/Actions Max         0.9992127
evaluation/Actions Min         -0.9999343
evaluation/Num Paths           10
evaluation/Average Returns     479.77364673214953
time/data storing (s)          0.03193842340260744
time/evaluation sampling (s)   113.20717133861035
time/exploration sampling (s)  112.76083045545965
time/logging (s)               0.03092990256845951
time/saving (s)                0.010485948994755745
time/training (s)              9.672105641104281
time/epoch (s)                 235.7134617101401
time/total (s)                 121558.67547248956
Epoch                          518
-----------------------------  ---------------------
2023-08-02 03:44:03.104350 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 519 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4137.7573]
trainer/QF1 Loss               0.019948343
trainer/QF2 Loss               0.023417957
trainer/Policy Loss            -94.70668
trainer/Q1 Predictions Mean    106.69357
trainer/Q1 Predictions Std     1.9650824
trainer/Q1 Predictions Max     108.19147
trainer/Q1 Predictions Min     87.74785
trainer/Q2 Predictions Mean    106.62886
trainer/Q2 Predictions Std     2.0108542
trainer/Q2 Predictions Max     108.12336
trainer/Q2 Predictions Min     87.04609
trainer/Q Targets Mean         106.64926
trainer/Q Targets Std          1.9488771
trainer/Q Targets Max          108.10055
trainer/Q Targets Min          87.36868
trainer/Log Pis Mean           12.091263
trainer/Log Pis Std            7.765928
trainer/Log Pis Max            49.19053
trainer/Log Pis Min            -7.163704
trainer/Policy mu Mean         0.037894066
trainer/Policy mu Std          1.5921159
trainer/Policy mu Max          5.37777
trainer/Policy mu Min          -6.301261
trainer/Policy log std Mean    -0.7086409
trainer/Policy log std Std     0.25616068
trainer/Policy log std Max     0.17221653
trainer/Policy log std Min     -1.7764324
trainer/Alpha                  0.001837468589656055
trainer/Alpha Loss             0.574894368648529
exploration/num steps total    2601000
exploration/num paths total    5202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9595375490947358
exploration/Rewards Std        0.05518874807663281
exploration/Rewards Max        0.9789455771470177
exploration/Rewards Min        0.49910350607453663
exploration/Returns Mean       479.76877454736797
exploration/Returns Std        3.5856921552588883
exploration/Returns Max        482.23665448623865
exploration/Returns Min        469.47241404135116
exploration/Actions Mean       0.034318168
exploration/Actions Std        0.60585207
exploration/Actions Max        0.99986464
exploration/Actions Min        -0.9999075
exploration/Num Paths          10
exploration/Average Returns    479.76877454736797
evaluation/num steps total     2600000
evaluation/num paths total     5200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9625075845970023
evaluation/Rewards Std         0.05249807823339289
evaluation/Rewards Max         0.9793091175698816
evaluation/Rewards Min         0.4889312459430388
evaluation/Returns Mean        481.25379229850114
evaluation/Returns Std         0.693402545392527
evaluation/Returns Max         482.0972146808428
evaluation/Returns Min         480.18023683609846
evaluation/ExplReturns Mean    481.25379229850114
evaluation/ExplReturns Std     0.693402545392527
evaluation/ExplReturns Max     482.0972146808428
evaluation/ExplReturns Min     480.18023683609846
evaluation/Actions Mean        0.026448933
evaluation/Actions Std         0.50445306
evaluation/Actions Max         0.99767756
evaluation/Actions Min         -0.9994101
evaluation/Num Paths           10
evaluation/Average Returns     481.25379229850114
time/data storing (s)          0.03224709816277027
time/evaluation sampling (s)   113.28540205582976
time/exploration sampling (s)  112.63606894016266
time/logging (s)               0.030753721483051777
time/saving (s)                0.010315287858247757
time/training (s)              9.113332479260862
time/epoch (s)                 235.10811958275735
time/total (s)                 121793.78652967606
Epoch                          519
-----------------------------  --------------------
2023-08-02 03:47:58.972024 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 520 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3884.8005]
trainer/QF1 Loss               0.027046472
trainer/QF2 Loss               0.024692856
trainer/Policy Loss            -95.32359
trainer/Q1 Predictions Mean    106.562515
trainer/Q1 Predictions Std     1.2705519
trainer/Q1 Predictions Max     107.63792
trainer/Q1 Predictions Min     97.541916
trainer/Q2 Predictions Mean    106.55951
trainer/Q2 Predictions Std     1.2570643
trainer/Q2 Predictions Max     107.783195
trainer/Q2 Predictions Min     97.92581
trainer/Q Targets Mean         106.64526
trainer/Q Targets Std          1.273653
trainer/Q Targets Max          107.78576
trainer/Q Targets Min          97.12506
trainer/Log Pis Mean           11.342464
trainer/Log Pis Std            7.455124
trainer/Log Pis Max            42.28019
trainer/Log Pis Min            -5.00744
trainer/Policy mu Mean         0.1792087
trainer/Policy mu Std          1.5696615
trainer/Policy mu Max          7.016225
trainer/Policy mu Min          -5.6604238
trainer/Policy log std Mean    -0.6855361
trainer/Policy log std Std     0.26133114
trainer/Policy log std Max     0.17497247
trainer/Policy log std Min     -1.6893444
trainer/Alpha                  0.001728561008349061
trainer/Alpha Loss             -4.18208122253418
exploration/num steps total    2606000
exploration/num paths total    5212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.959456802562586
exploration/Rewards Std        0.050640110296307585
exploration/Rewards Max        0.9793735249227078
exploration/Rewards Min        0.5003940281431256
exploration/Returns Mean       479.72840128129303
exploration/Returns Std        0.23839491603280796
exploration/Returns Max        480.1969182502361
exploration/Returns Min        479.3312909788352
exploration/Actions Mean       0.095766775
exploration/Actions Std        0.6404778
exploration/Actions Max        0.9999719
exploration/Actions Min        -0.9996686
exploration/Num Paths          10
exploration/Average Returns    479.72840128129303
evaluation/num steps total     2605000
evaluation/num paths total     5210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.962134754586365
evaluation/Rewards Std         0.05023172342845338
evaluation/Rewards Max         0.978679445026609
evaluation/Rewards Min         0.5011241076750164
evaluation/Returns Mean        481.0673772931823
evaluation/Returns Std         0.5436145854310397
evaluation/Returns Max         481.7459354497465
evaluation/Returns Min         480.06852779622346
evaluation/ExplReturns Mean    481.0673772931823
evaluation/ExplReturns Std     0.5436145854310397
evaluation/ExplReturns Max     481.7459354497465
evaluation/ExplReturns Min     480.06852779622346
evaluation/Actions Mean        0.08407474
evaluation/Actions Std         0.55280626
evaluation/Actions Max         0.99865717
evaluation/Actions Min         -0.9979689
evaluation/Num Paths           10
evaluation/Average Returns     481.0673772931823
time/data storing (s)          0.032127452082931995
time/evaluation sampling (s)   112.11813743039966
time/exploration sampling (s)  114.24073284491897
time/logging (s)               0.030956653878092766
time/saving (s)                0.011016139760613441
time/training (s)              9.427752396091819
time/epoch (s)                 235.86072291713208
time/total (s)                 122029.65009571798
Epoch                          520
-----------------------------  --------------------
2023-08-02 03:51:57.392067 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 521 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3678.4348]
trainer/QF1 Loss               0.025719438
trainer/QF2 Loss               0.021761632
trainer/Policy Loss            -94.451065
trainer/Q1 Predictions Mean    106.25905
trainer/Q1 Predictions Std     2.125403
trainer/Q1 Predictions Max     107.74157
trainer/Q1 Predictions Min     86.94257
trainer/Q2 Predictions Mean    106.25714
trainer/Q2 Predictions Std     2.0911524
trainer/Q2 Predictions Max     107.86602
trainer/Q2 Predictions Min     87.38728
trainer/Q Targets Mean         106.25793
trainer/Q Targets Std          2.118511
trainer/Q Targets Max          107.78963
trainer/Q Targets Min          86.71777
trainer/Log Pis Mean           11.916024
trainer/Log Pis Std            9.454145
trainer/Log Pis Max            62.336502
trainer/Log Pis Min            -3.8521597
trainer/Policy mu Mean         0.051648557
trainer/Policy mu Std          1.6249995
trainer/Policy mu Max          6.911557
trainer/Policy mu Min          -8.146678
trainer/Policy log std Mean    -0.709472
trainer/Policy log std Std     0.26330003
trainer/Policy log std Max     0.12560982
trainer/Policy log std Min     -2.0028179
trainer/Alpha                  0.0016571427695453167
trainer/Alpha Loss             -0.5376510620117188
exploration/num steps total    2611000
exploration/num paths total    5222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9577185214636371
exploration/Rewards Std        0.05862132186865065
exploration/Rewards Max        0.9795977256474354
exploration/Rewards Min        0.49404551694621035
exploration/Returns Mean       478.8592607318184
exploration/Returns Std        3.634322051502904
exploration/Returns Max        480.78744577583757
exploration/Returns Min        468.06522659717524
exploration/Actions Mean       0.065182775
exploration/Actions Std        0.5995747
exploration/Actions Max        0.9999718
exploration/Actions Min        -0.99999964
exploration/Num Paths          10
exploration/Average Returns    478.8592607318184
evaluation/num steps total     2610000
evaluation/num paths total     5220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9550249434398985
evaluation/Rewards Std         0.059059443744592835
evaluation/Rewards Max         0.9798652783469235
evaluation/Rewards Min         0.495316674103019
evaluation/Returns Mean        477.5124717199495
evaluation/Returns Std         2.669432421423606
evaluation/Returns Max         479.8262164290188
evaluation/Returns Min         471.8457079932743
evaluation/ExplReturns Mean    477.5124717199495
evaluation/ExplReturns Std     2.669432421423606
evaluation/ExplReturns Max     479.8262164290188
evaluation/ExplReturns Min     471.8457079932743
evaluation/Actions Mean        0.090847224
evaluation/Actions Std         0.47104457
evaluation/Actions Max         0.9996303
evaluation/Actions Min         -0.9992579
evaluation/Num Paths           10
evaluation/Average Returns     477.5124717199495
time/data storing (s)          0.0360858328640461
time/evaluation sampling (s)   114.17637058719993
time/exploration sampling (s)  114.51723981555551
time/logging (s)               0.030519092455506325
time/saving (s)                0.011565577238798141
time/training (s)              9.641055564396083
time/epoch (s)                 238.41283646970987
time/total (s)                 122268.06544845924
Epoch                          521
-----------------------------  ---------------------
2023-08-02 03:55:53.813929 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 522 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3522.6873]
trainer/QF1 Loss               0.064703204
trainer/QF2 Loss               0.03414814
trainer/Policy Loss            -94.662766
trainer/Q1 Predictions Mean    106.45808
trainer/Q1 Predictions Std     1.7441562
trainer/Q1 Predictions Max     108.01294
trainer/Q1 Predictions Min     88.51658
trainer/Q2 Predictions Mean    106.34393
trainer/Q2 Predictions Std     1.7341179
trainer/Q2 Predictions Max     108.00458
trainer/Q2 Predictions Min     88.814865
trainer/Q Targets Mean         106.25419
trainer/Q Targets Std          1.7830032
trainer/Q Targets Max          107.770355
trainer/Q Targets Min          87.360344
trainer/Log Pis Mean           11.799339
trainer/Log Pis Std            7.911292
trainer/Log Pis Max            41.82234
trainer/Log Pis Min            -6.477483
trainer/Policy mu Mean         0.1611988
trainer/Policy mu Std          1.597929
trainer/Policy mu Max          5.319187
trainer/Policy mu Min          -6.947642
trainer/Policy log std Mean    -0.7090166
trainer/Policy log std Std     0.27476674
trainer/Policy log std Max     0.3413896
trainer/Policy log std Min     -1.7163388
trainer/Alpha                  0.0015692661982029676
trainer/Alpha Loss             -1.295687198638916
exploration/num steps total    2616000
exploration/num paths total    5232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9514125138772012
exploration/Rewards Std        0.06401975104730434
exploration/Rewards Max        0.9793139755759843
exploration/Rewards Min        0.4884448908884732
exploration/Returns Mean       475.70625693860046
exploration/Returns Std        3.017631840712717
exploration/Returns Max        479.21919501801284
exploration/Returns Min        471.15565146712163
exploration/Actions Mean       0.0890958
exploration/Actions Std        0.60151744
exploration/Actions Max        0.9999986
exploration/Actions Min        -0.9999986
exploration/Num Paths          10
exploration/Average Returns    475.70625693860046
evaluation/num steps total     2615000
evaluation/num paths total     5230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9588476298580004
evaluation/Rewards Std         0.05116741717539575
evaluation/Rewards Max         0.9797694785436895
evaluation/Rewards Min         0.5015952472001198
evaluation/Returns Mean        479.4238149290001
evaluation/Returns Std         0.24288550159387884
evaluation/Returns Max         479.72170632228904
evaluation/Returns Min         478.8469337574118
evaluation/ExplReturns Mean    479.4238149290001
evaluation/ExplReturns Std     0.24288550159387884
evaluation/ExplReturns Max     479.72170632228904
evaluation/ExplReturns Min     478.8469337574118
evaluation/Actions Mean        0.06458054
evaluation/Actions Std         0.4886002
evaluation/Actions Max         0.99778676
evaluation/Actions Min         -0.9990899
evaluation/Num Paths           10
evaluation/Average Returns     479.4238149290001
time/data storing (s)          0.03182490076869726
time/evaluation sampling (s)   112.70478075742722
time/exploration sampling (s)  113.45868516806513
time/logging (s)               0.030608205124735832
time/saving (s)                0.012149356305599213
time/training (s)              10.177121764048934
time/epoch (s)                 236.4151701517403
time/total (s)                 122504.48314324114
Epoch                          522
-----------------------------  ---------------------
2023-08-02 03:59:50.005968 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 523 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3433.7334]
trainer/QF1 Loss               0.031685434
trainer/QF2 Loss               0.024339702
trainer/Policy Loss            -94.609146
trainer/Q1 Predictions Mean    106.18116
trainer/Q1 Predictions Std     1.4756459
trainer/Q1 Predictions Max     107.370895
trainer/Q1 Predictions Min     91.11833
trainer/Q2 Predictions Mean    106.15114
trainer/Q2 Predictions Std     1.4703087
trainer/Q2 Predictions Max     107.38963
trainer/Q2 Predictions Min     91.09289
trainer/Q Targets Mean         106.09481
trainer/Q Targets Std          1.4976588
trainer/Q Targets Max          107.455315
trainer/Q Targets Min          90.24404
trainer/Log Pis Mean           11.637888
trainer/Log Pis Std            8.983378
trainer/Log Pis Max            71.14751
trainer/Log Pis Min            -5.2755585
trainer/Policy mu Mean         0.089701444
trainer/Policy mu Std          1.6153617
trainer/Policy mu Max          6.6314926
trainer/Policy mu Min          -5.3066864
trainer/Policy log std Mean    -0.7039876
trainer/Policy log std Std     0.2770819
trainer/Policy log std Max     0.17009747
trainer/Policy log std Min     -2.0895467
trainer/Alpha                  0.0015104077756404877
trainer/Alpha Loss             -2.3520658016204834
exploration/num steps total    2621000
exploration/num paths total    5242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9546189779799054
exploration/Rewards Std        0.05604261287971978
exploration/Rewards Max        0.9796184740407844
exploration/Rewards Min        0.5004002602806662
exploration/Returns Mean       477.3094889899527
exploration/Returns Std        1.7126821805810801
exploration/Returns Max        479.6991862442002
exploration/Returns Min        474.58359160121256
exploration/Actions Mean       0.1271522
exploration/Actions Std        0.63701403
exploration/Actions Max        0.99999803
exploration/Actions Min        -0.9999393
exploration/Num Paths          10
exploration/Average Returns    477.3094889899527
evaluation/num steps total     2620000
evaluation/num paths total     5240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9556730802133531
evaluation/Rewards Std         0.05539692684067614
evaluation/Rewards Max         0.9784463251621354
evaluation/Rewards Min         0.50294143218106
evaluation/Returns Mean        477.8365401066765
evaluation/Returns Std         1.2180988300139353
evaluation/Returns Max         479.89835415411045
evaluation/Returns Min         474.99006891105967
evaluation/ExplReturns Mean    477.8365401066765
evaluation/ExplReturns Std     1.2180988300139353
evaluation/ExplReturns Max     479.89835415411045
evaluation/ExplReturns Min     474.99006891105967
evaluation/Actions Mean        0.12958044
evaluation/Actions Std         0.57858115
evaluation/Actions Max         0.99998087
evaluation/Actions Min         -0.9999925
evaluation/Num Paths           10
evaluation/Average Returns     477.8365401066765
time/data storing (s)          0.032355339266359806
time/evaluation sampling (s)   112.86070983856916
time/exploration sampling (s)  113.66942637600005
time/logging (s)               0.03083977848291397
time/saving (s)                0.013015723787248135
time/training (s)              9.579087402671576
time/epoch (s)                 236.1854344587773
time/total (s)                 122740.671111512
Epoch                          523
-----------------------------  ---------------------
2023-08-02 04:03:44.838627 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 524 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3571.3303]
trainer/QF1 Loss               0.02631222
trainer/QF2 Loss               0.01581151
trainer/Policy Loss            -95.31644
trainer/Q1 Predictions Mean    105.92709
trainer/Q1 Predictions Std     1.3163712
trainer/Q1 Predictions Max     107.115974
trainer/Q1 Predictions Min     95.711205
trainer/Q2 Predictions Mean    105.98202
trainer/Q2 Predictions Std     1.3564385
trainer/Q2 Predictions Max     107.10291
trainer/Q2 Predictions Min     95.24512
trainer/Q Targets Mean         105.991646
trainer/Q Targets Std          1.3712584
trainer/Q Targets Max          107.08457
trainer/Q Targets Min          95.01115
trainer/Log Pis Mean           10.725447
trainer/Log Pis Std            7.3107634
trainer/Log Pis Max            43.584167
trainer/Log Pis Min            -5.7752085
trainer/Policy mu Mean         0.056541126
trainer/Policy mu Std          1.5401694
trainer/Policy mu Max          5.1557117
trainer/Policy mu Min          -5.660007
trainer/Policy log std Mean    -0.7001459
trainer/Policy log std Std     0.28135478
trainer/Policy log std Max     0.24034142
trainer/Policy log std Min     -1.7197844
trainer/Alpha                  0.001503606210462749
trainer/Alpha Loss             -8.283913612365723
exploration/num steps total    2626000
exploration/num paths total    5252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9490433420086951
exploration/Rewards Std        0.06938611758262074
exploration/Rewards Max        0.9797152427391395
exploration/Rewards Min        0.4959364084669153
exploration/Returns Mean       474.52167100434747
exploration/Returns Std        12.069983515118912
exploration/Returns Max        480.00185998851134
exploration/Returns Min        438.4480036569572
exploration/Actions Mean       0.08098262
exploration/Actions Std        0.5868894
exploration/Actions Max        0.99999267
exploration/Actions Min        -0.9999205
exploration/Num Paths          10
exploration/Average Returns    474.52167100434747
evaluation/num steps total     2625000
evaluation/num paths total     5250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9592568059598819
evaluation/Rewards Std         0.05189919060443209
evaluation/Rewards Max         0.9791023697880988
evaluation/Rewards Min         0.49134113457559336
evaluation/Returns Mean        479.628402979941
evaluation/Returns Std         0.7106271807163601
evaluation/Returns Max         480.50894528952415
evaluation/Returns Min         477.87074443747383
evaluation/ExplReturns Mean    479.628402979941
evaluation/ExplReturns Std     0.7106271807163601
evaluation/ExplReturns Max     480.50894528952415
evaluation/ExplReturns Min     477.87074443747383
evaluation/Actions Mean        0.05620975
evaluation/Actions Std         0.47509393
evaluation/Actions Max         0.99917066
evaluation/Actions Min         -0.9992663
evaluation/Num Paths           10
evaluation/Average Returns     479.628402979941
time/data storing (s)          0.032207272946834564
time/evaluation sampling (s)   112.39265984576195
time/exploration sampling (s)  113.14764205459505
time/logging (s)               0.030779486522078514
time/saving (s)                0.012927033007144928
time/training (s)              9.20957069657743
time/epoch (s)                 234.8257863894105
time/total (s)                 122975.49941817857
Epoch                          524
-----------------------------  --------------------
2023-08-02 04:07:41.497963 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 525 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3481.455]
trainer/QF1 Loss               0.015475579
trainer/QF2 Loss               0.026404746
trainer/Policy Loss            -93.978836
trainer/Q1 Predictions Mean    105.81375
trainer/Q1 Predictions Std     1.4731606
trainer/Q1 Predictions Max     107.21294
trainer/Q1 Predictions Min     89.916016
trainer/Q2 Predictions Mean    105.89791
trainer/Q2 Predictions Std     1.4287701
trainer/Q2 Predictions Max     107.39476
trainer/Q2 Predictions Min     90.55542
trainer/Q Targets Mean         105.79811
trainer/Q Targets Std          1.4818677
trainer/Q Targets Max          107.184425
trainer/Q Targets Min          89.88932
trainer/Log Pis Mean           11.968763
trainer/Log Pis Std            8.035298
trainer/Log Pis Max            57.733868
trainer/Log Pis Min            -1.5031002
trainer/Policy mu Mean         0.02714753
trainer/Policy mu Std          1.5779358
trainer/Policy mu Max          6.452231
trainer/Policy mu Min          -6.2752833
trainer/Policy log std Mean    -0.7206661
trainer/Policy log std Std     0.2841384
trainer/Policy log std Max     0.29327172
trainer/Policy log std Min     -1.9985423
trainer/Alpha                  0.0014520545955747366
trainer/Alpha Loss             -0.20412051677703857
exploration/num steps total    2631000
exploration/num paths total    5262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9633939722341982
exploration/Rewards Std        0.05070370679724785
exploration/Rewards Max        0.9793303305332517
exploration/Rewards Min        0.5009472536784878
exploration/Returns Mean       481.696986117099
exploration/Returns Std        0.7024038644321962
exploration/Returns Max        482.554192050089
exploration/Returns Min        480.0660710036462
exploration/Actions Mean       0.1010475
exploration/Actions Std        0.6329323
exploration/Actions Max        0.9999649
exploration/Actions Min        -0.9998625
exploration/Num Paths          10
exploration/Average Returns    481.696986117099
evaluation/num steps total     2630000
evaluation/num paths total     5260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.957643283150089
evaluation/Rewards Std         0.06111900104172227
evaluation/Rewards Max         0.9795716626487636
evaluation/Rewards Min         0.4901443121681885
evaluation/Returns Mean        478.8216415750444
evaluation/Returns Std         4.4646788455328945
evaluation/Returns Max         482.2885969754437
evaluation/Returns Min         471.3710141808581
evaluation/ExplReturns Mean    478.8216415750444
evaluation/ExplReturns Std     4.4646788455328945
evaluation/ExplReturns Max     482.2885969754437
evaluation/ExplReturns Min     471.3710141808581
evaluation/Actions Mean        0.060287565
evaluation/Actions Std         0.5727253
evaluation/Actions Max         0.999279
evaluation/Actions Min         -0.9998594
evaluation/Num Paths           10
evaluation/Average Returns     478.8216415750444
time/data storing (s)          0.032157634384930134
time/evaluation sampling (s)   112.70196900237352
time/exploration sampling (s)  114.22973672673106
time/logging (s)               0.03159521333873272
time/saving (s)                0.012864464893937111
time/training (s)              9.644949492067099
time/epoch (s)                 236.65327253378928
time/total (s)                 123212.15527546871
Epoch                          525
-----------------------------  ---------------------
2023-08-02 04:11:37.653796 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 526 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3565.8672]
trainer/QF1 Loss               0.02700681
trainer/QF2 Loss               0.014498968
trainer/Policy Loss            -92.965744
trainer/Q1 Predictions Mean    105.55589
trainer/Q1 Predictions Std     1.8834997
trainer/Q1 Predictions Max     108.27783
trainer/Q1 Predictions Min     82.30362
trainer/Q2 Predictions Mean    105.665695
trainer/Q2 Predictions Std     1.8360544
trainer/Q2 Predictions Max     108.46064
trainer/Q2 Predictions Min     82.90474
trainer/Q Targets Mean         105.64349
trainer/Q Targets Std          1.8299851
trainer/Q Targets Max          108.42019
trainer/Q Targets Min          83.1139
trainer/Log Pis Mean           12.709141
trainer/Log Pis Std            8.26195
trainer/Log Pis Max            48.300194
trainer/Log Pis Min            -5.0497446
trainer/Policy mu Mean         -0.062800474
trainer/Policy mu Std          1.645323
trainer/Policy mu Max          7.922138
trainer/Policy mu Min          -4.9643526
trainer/Policy log std Mean    -0.73842126
trainer/Policy log std Std     0.28869832
trainer/Policy log std Max     0.3025784
trainer/Policy log std Min     -2.053188
trainer/Alpha                  0.0015049382345750928
trainer/Alpha Loss             4.608819961547852
exploration/num steps total    2636000
exploration/num paths total    5272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9501585895513679
exploration/Rewards Std        0.06669647734717216
exploration/Rewards Max        0.9791779140629848
exploration/Rewards Min        0.49452513058193937
exploration/Returns Mean       475.07929477568376
exploration/Returns Std        12.063478848415174
exploration/Returns Max        482.0347889923849
exploration/Returns Min        439.0309470933975
exploration/Actions Mean       0.10802672
exploration/Actions Std        0.6301605
exploration/Actions Max        0.99999976
exploration/Actions Min        -0.999996
exploration/Num Paths          10
exploration/Average Returns    475.07929477568376
evaluation/num steps total     2635000
evaluation/num paths total     5270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8869116597693981
evaluation/Rewards Std         0.1454433642740848
evaluation/Rewards Max         0.9790175078525956
evaluation/Rewards Min         0.3488334667688797
evaluation/Returns Mean        443.45582988469926
evaluation/Returns Std         34.36044454188633
evaluation/Returns Max         479.44688721373495
evaluation/Returns Min         384.53039124648586
evaluation/ExplReturns Mean    443.45582988469926
evaluation/ExplReturns Std     34.36044454188633
evaluation/ExplReturns Max     479.44688721373495
evaluation/ExplReturns Min     384.53039124648586
evaluation/Actions Mean        0.09558254
evaluation/Actions Std         0.6131777
evaluation/Actions Max         0.9999998
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     443.45582988469926
time/data storing (s)          0.0322760371491313
time/evaluation sampling (s)   113.4868009435013
time/exploration sampling (s)  113.09998197574168
time/logging (s)               0.03088231384754181
time/saving (s)                0.010429395362734795
time/training (s)              9.487900115549564
time/epoch (s)                 236.14827078115195
time/total (s)                 123448.3060672991
Epoch                          526
-----------------------------  ---------------------
2023-08-02 04:15:40.208660 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 527 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3891.8345]
trainer/QF1 Loss               0.041664217
trainer/QF2 Loss               0.025826182
trainer/Policy Loss            -92.486664
trainer/Q1 Predictions Mean    105.23985
trainer/Q1 Predictions Std     2.7198403
trainer/Q1 Predictions Max     108.1045
trainer/Q1 Predictions Min     75.598854
trainer/Q2 Predictions Mean    105.13033
trainer/Q2 Predictions Std     2.707829
trainer/Q2 Predictions Max     107.75271
trainer/Q2 Predictions Min     75.50951
trainer/Q Targets Mean         105.16145
trainer/Q Targets Std          2.749842
trainer/Q Targets Max          108.01991
trainer/Q Targets Min          75.09547
trainer/Log Pis Mean           12.765837
trainer/Log Pis Std            8.871794
trainer/Log Pis Max            53.753136
trainer/Log Pis Min            -3.1674445
trainer/Policy mu Mean         -0.027757665
trainer/Policy mu Std          1.6414764
trainer/Policy mu Max          6.4913774
trainer/Policy mu Min          -9.723848
trainer/Policy log std Mean    -0.7514963
trainer/Policy log std Std     0.30518085
trainer/Policy log std Max     1.0729599
trainer/Policy log std Min     -1.9575403
trainer/Alpha                  0.0014369831187650561
trainer/Alpha Loss             5.012576103210449
exploration/num steps total    2641000
exploration/num paths total    5282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8896269858266805
exploration/Rewards Std        0.11640362892843573
exploration/Rewards Max        0.9792608054088003
exploration/Rewards Min        0.49422542357875854
exploration/Returns Mean       444.8134929133404
exploration/Returns Std        19.007905094550974
exploration/Returns Max        477.3625120947322
exploration/Returns Min        407.6532384447693
exploration/Actions Mean       0.001793774
exploration/Actions Std        0.6554412
exploration/Actions Max        0.99999964
exploration/Actions Min        -0.9999987
exploration/Num Paths          10
exploration/Average Returns    444.8134929133404
evaluation/num steps total     2640000
evaluation/num paths total     5280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7948045661710174
evaluation/Rewards Std         0.12253741426094775
evaluation/Rewards Max         0.9790376284204012
evaluation/Rewards Min         0.49893445962266086
evaluation/Returns Mean        397.4022830855086
evaluation/Returns Std         27.867249521326826
evaluation/Returns Max         456.4736360854322
evaluation/Returns Min         379.58481801829106
evaluation/ExplReturns Mean    397.4022830855086
evaluation/ExplReturns Std     27.867249521326826
evaluation/ExplReturns Max     456.4736360854322
evaluation/ExplReturns Min     379.58481801829106
evaluation/Actions Mean        -0.18457219
evaluation/Actions Std         0.5540957
evaluation/Actions Max         0.99998736
evaluation/Actions Min         -0.99963593
evaluation/Num Paths           10
evaluation/Average Returns     397.4022830855086
time/data storing (s)          0.03231085557490587
time/evaluation sampling (s)   119.98925991822034
time/exploration sampling (s)  113.30987735372037
time/logging (s)               0.030513946898281574
time/saving (s)                0.01241028867661953
time/training (s)              9.173390520736575
time/epoch (s)                 242.5477628838271
time/total (s)                 123690.85628771596
Epoch                          527
-----------------------------  ---------------------
2023-08-02 04:19:32.660427 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 528 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3378.4712]
trainer/QF1 Loss               0.024723705
trainer/QF2 Loss               0.022636445
trainer/Policy Loss            -93.38412
trainer/Q1 Predictions Mean    105.18708
trainer/Q1 Predictions Std     1.8783563
trainer/Q1 Predictions Max     108.5569
trainer/Q1 Predictions Min     89.38255
trainer/Q2 Predictions Mean    105.1826
trainer/Q2 Predictions Std     1.8472637
trainer/Q2 Predictions Max     108.54778
trainer/Q2 Predictions Min     89.97111
trainer/Q Targets Mean         105.22647
trainer/Q Targets Std          1.8457793
trainer/Q Targets Max          108.41314
trainer/Q Targets Min          89.779854
trainer/Log Pis Mean           11.898987
trainer/Log Pis Std            8.470467
trainer/Log Pis Max            48.7975
trainer/Log Pis Min            -3.398193
trainer/Policy mu Mean         0.063169695
trainer/Policy mu Std          1.5927024
trainer/Policy mu Max          5.495494
trainer/Policy mu Min          -6.3544474
trainer/Policy log std Mean    -0.748934
trainer/Policy log std Std     0.29054296
trainer/Policy log std Max     0.28502274
trainer/Policy log std Min     -2.0306513
trainer/Alpha                  0.0014412967721000314
trainer/Alpha Loss             -0.6608694791793823
exploration/num steps total    2646000
exploration/num paths total    5292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9640773721482876
exploration/Rewards Std        0.0526678678794162
exploration/Rewards Max        0.979808081835051
exploration/Rewards Min        0.4983405395631354
exploration/Returns Mean       482.0386860741437
exploration/Returns Std        1.1773785591268615
exploration/Returns Max        483.3526589527723
exploration/Returns Min        479.72764608854186
exploration/Actions Mean       0.035270397
exploration/Actions Std        0.60536414
exploration/Actions Max        0.9999922
exploration/Actions Min        -0.9998697
exploration/Num Paths          10
exploration/Average Returns    482.0386860741437
evaluation/num steps total     2645000
evaluation/num paths total     5290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9654183576560686
evaluation/Rewards Std         0.050784999595272974
evaluation/Rewards Max         0.9798290414039308
evaluation/Rewards Min         0.49258057262041305
evaluation/Returns Mean        482.70917882803434
evaluation/Returns Std         0.3353430276501253
evaluation/Returns Max         483.1480902808384
evaluation/Returns Min         481.9248163678889
evaluation/ExplReturns Mean    482.70917882803434
evaluation/ExplReturns Std     0.3353430276501253
evaluation/ExplReturns Max     483.1480902808384
evaluation/ExplReturns Min     481.9248163678889
evaluation/Actions Mean        0.011739133
evaluation/Actions Std         0.48489207
evaluation/Actions Max         0.9996518
evaluation/Actions Min         -0.9989708
evaluation/Num Paths           10
evaluation/Average Returns     482.70917882803434
time/data storing (s)          0.03206183947622776
time/evaluation sampling (s)   111.22690103109926
time/exploration sampling (s)  111.67062507010996
time/logging (s)               0.03032471425831318
time/saving (s)                0.011344444006681442
time/training (s)              9.473582941107452
time/epoch (s)                 232.4448400400579
time/total (s)                 123923.30358374584
Epoch                          528
-----------------------------  ---------------------
2023-08-02 04:23:27.007206 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 529 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3969.928]
trainer/QF1 Loss               0.020113192
trainer/QF2 Loss               0.01816985
trainer/Policy Loss            -93.71703
trainer/Q1 Predictions Mean    105.225296
trainer/Q1 Predictions Std     2.0960112
trainer/Q1 Predictions Max     107.79371
trainer/Q1 Predictions Min     79.806984
trainer/Q2 Predictions Mean    105.20559
trainer/Q2 Predictions Std     2.0605605
trainer/Q2 Predictions Max     107.6562
trainer/Q2 Predictions Min     80.24712
trainer/Q Targets Mean         105.21896
trainer/Q Targets Std          2.0303178
trainer/Q Targets Max          107.60102
trainer/Q Targets Min          80.42905
trainer/Log Pis Mean           11.584948
trainer/Log Pis Std            8.345501
trainer/Log Pis Max            52.90473
trainer/Log Pis Min            -4.256363
trainer/Policy mu Mean         0.15675507
trainer/Policy mu Std          1.5444078
trainer/Policy mu Max          8.737687
trainer/Policy mu Min          -4.2085624
trainer/Policy log std Mean    -0.7755029
trainer/Policy log std Std     0.2854793
trainer/Policy log std Max     0.045194507
trainer/Policy log std Min     -1.9292636
trainer/Alpha                  0.0013848210219293833
trainer/Alpha Loss             -2.731865406036377
exploration/num steps total    2651000
exploration/num paths total    5302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9344046080978698
exploration/Rewards Std        0.08867001514257897
exploration/Rewards Max        0.9799494640523934
exploration/Rewards Min        0.4906877180553119
exploration/Returns Mean       467.2023040489348
exploration/Returns Std        14.51699632225376
exploration/Returns Max        478.00960181485607
exploration/Returns Min        427.2437616801835
exploration/Actions Mean       0.108433776
exploration/Actions Std        0.6509097
exploration/Actions Max        0.99999803
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    467.2023040489348
evaluation/num steps total     2650000
evaluation/num paths total     5300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9536462190196758
evaluation/Rewards Std         0.06577333564805317
evaluation/Rewards Max         0.9799511257778551
evaluation/Rewards Min         0.4989289034157207
evaluation/Returns Mean        476.8231095098382
evaluation/Returns Std         4.279015951586335
evaluation/Returns Max         481.067853432819
evaluation/Returns Min         470.89633250747
evaluation/ExplReturns Mean    476.8231095098382
evaluation/ExplReturns Std     4.279015951586335
evaluation/ExplReturns Max     481.067853432819
evaluation/ExplReturns Min     470.89633250747
evaluation/Actions Mean        0.11586651
evaluation/Actions Std         0.5823012
evaluation/Actions Max         0.99999666
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     476.8231095098382
time/data storing (s)          0.03176645562052727
time/evaluation sampling (s)   111.94910829328
time/exploration sampling (s)  112.53325563669205
time/logging (s)               0.030308558605611324
time/saving (s)                0.010643517598509789
time/training (s)              9.78487469162792
time/epoch (s)                 234.33995715342462
time/total (s)                 124157.64605466742
Epoch                          529
-----------------------------  ---------------------
2023-08-02 04:27:20.958331 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 530 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3703.163]
trainer/QF1 Loss               0.02081795
trainer/QF2 Loss               0.015443413
trainer/Policy Loss            -93.26938
trainer/Q1 Predictions Mean    105.13842
trainer/Q1 Predictions Std     1.4735041
trainer/Q1 Predictions Max     108.0095
trainer/Q1 Predictions Min     90.4801
trainer/Q2 Predictions Mean    105.18007
trainer/Q2 Predictions Std     1.5036302
trainer/Q2 Predictions Max     108.095825
trainer/Q2 Predictions Min     90.59172
trainer/Q Targets Mean         105.1667
trainer/Q Targets Std          1.5134346
trainer/Q Targets Max          108.21218
trainer/Q Targets Min          90.72511
trainer/Log Pis Mean           11.977175
trainer/Log Pis Std            8.375896
trainer/Log Pis Max            61.42717
trainer/Log Pis Min            -5.247259
trainer/Policy mu Mean         0.015826061
trainer/Policy mu Std          1.5896773
trainer/Policy mu Max          7.234376
trainer/Policy mu Min          -6.4817724
trainer/Policy log std Mean    -0.77221054
trainer/Policy log std Std     0.29297832
trainer/Policy log std Max     0.09140314
trainer/Policy log std Min     -1.8992901
trainer/Alpha                  0.0013502825750038028
trainer/Alpha Loss             -0.1508197784423828
exploration/num steps total    2656000
exploration/num paths total    5312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9611695416166914
exploration/Rewards Std        0.05362731546566056
exploration/Rewards Max        0.9797241230454576
exploration/Rewards Min        0.4965417145445652
exploration/Returns Mean       480.58477080834564
exploration/Returns Std        0.4932322848778124
exploration/Returns Max        481.36247042954636
exploration/Returns Min        479.6450346128419
exploration/Actions Mean       -0.005987061
exploration/Actions Std        0.60058314
exploration/Actions Max        0.9995637
exploration/Actions Min        -0.9999021
exploration/Num Paths          10
exploration/Average Returns    480.58477080834564
evaluation/num steps total     2655000
evaluation/num paths total     5310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9612712425032456
evaluation/Rewards Std         0.05198788312058706
evaluation/Rewards Max         0.9798860859656984
evaluation/Rewards Min         0.49255188851326415
evaluation/Returns Mean        480.63562125162287
evaluation/Returns Std         0.34961484853901975
evaluation/Returns Max         481.15376765838977
evaluation/Returns Min         480.08512253788
evaluation/ExplReturns Mean    480.63562125162287
evaluation/ExplReturns Std     0.34961484853901975
evaluation/ExplReturns Max     481.15376765838977
evaluation/ExplReturns Min     480.08512253788
evaluation/Actions Mean        -0.02326556
evaluation/Actions Std         0.49337733
evaluation/Actions Max         0.99770564
evaluation/Actions Min         -0.9994456
evaluation/Num Paths           10
evaluation/Average Returns     480.63562125162287
time/data storing (s)          0.0321272648870945
time/evaluation sampling (s)   112.61066468525678
time/exploration sampling (s)  111.58020018506795
time/logging (s)               0.03074974101036787
time/saving (s)                0.011977791786193848
time/training (s)              9.679054862819612
time/epoch (s)                 233.944774530828
time/total (s)                 124391.59330579918
Epoch                          530
-----------------------------  ---------------------
2023-08-02 04:31:13.709722 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 531 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3389.8445]
trainer/QF1 Loss               0.024472423
trainer/QF2 Loss               0.03738067
trainer/Policy Loss            -92.74749
trainer/Q1 Predictions Mean    104.80191
trainer/Q1 Predictions Std     3.2089834
trainer/Q1 Predictions Max     108.215164
trainer/Q1 Predictions Min     58.907677
trainer/Q2 Predictions Mean    104.81324
trainer/Q2 Predictions Std     3.249453
trainer/Q2 Predictions Max     107.986336
trainer/Q2 Predictions Min     57.942444
trainer/Q Targets Mean         104.8219
trainer/Q Targets Std          3.164981
trainer/Q Targets Max          108.123436
trainer/Q Targets Min          60.081516
trainer/Log Pis Mean           12.135721
trainer/Log Pis Std            9.803851
trainer/Log Pis Max            92.774895
trainer/Log Pis Min            -7.8567147
trainer/Policy mu Mean         0.14791787
trainer/Policy mu Std          1.6390487
trainer/Policy mu Max          18.258656
trainer/Policy mu Min          -13.588325
trainer/Policy log std Mean    -0.76244384
trainer/Policy log std Std     0.29807135
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.4916236
trainer/Alpha                  0.0013526197290048003
trainer/Alpha Loss             0.8965722322463989
exploration/num steps total    2661000
exploration/num paths total    5322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9486442067277753
exploration/Rewards Std        0.07143951559009347
exploration/Rewards Max        0.9797921957340625
exploration/Rewards Min        0.4970060792686938
exploration/Returns Mean       474.3221033638876
exploration/Returns Std        9.797538115466374
exploration/Returns Max        481.9283086342345
exploration/Returns Min        457.9718214413474
exploration/Actions Mean       0.04652529
exploration/Actions Std        0.6287622
exploration/Actions Max        0.99997497
exploration/Actions Min        -0.99999946
exploration/Num Paths          10
exploration/Average Returns    474.3221033638876
evaluation/num steps total     2660000
evaluation/num paths total     5320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9109963692183306
evaluation/Rewards Std         0.13610887159561363
evaluation/Rewards Max         0.9800031243385057
evaluation/Rewards Min         0.27988462639186584
evaluation/Returns Mean        455.4981846091654
evaluation/Returns Std         28.02015339431088
evaluation/Returns Max         482.99611736259897
evaluation/Returns Min         416.3690431737569
evaluation/ExplReturns Mean    455.4981846091654
evaluation/ExplReturns Std     28.02015339431088
evaluation/ExplReturns Max     482.99611736259897
evaluation/ExplReturns Min     416.3690431737569
evaluation/Actions Mean        0.07457021
evaluation/Actions Std         0.572572
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     455.4981846091654
time/data storing (s)          0.032049220986664295
time/evaluation sampling (s)   111.45970235858113
time/exploration sampling (s)  112.03944139089435
time/logging (s)               0.03148495592176914
time/saving (s)                0.012913634069263935
time/training (s)              9.169683394953609
time/epoch (s)                 232.74527495540679
time/total (s)                 124624.34108694177
Epoch                          531
-----------------------------  ---------------------
2023-08-02 04:35:07.792525 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 532 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3626.177]
trainer/QF1 Loss               0.024451625
trainer/QF2 Loss               0.022012018
trainer/Policy Loss            -93.9821
trainer/Q1 Predictions Mean    104.95492
trainer/Q1 Predictions Std     1.2263607
trainer/Q1 Predictions Max     108.53024
trainer/Q1 Predictions Min     92.34108
trainer/Q2 Predictions Mean    104.96486
trainer/Q2 Predictions Std     1.2268354
trainer/Q2 Predictions Max     108.65662
trainer/Q2 Predictions Min     92.505295
trainer/Q Targets Mean         104.985405
trainer/Q Targets Std          1.276171
trainer/Q Targets Max          108.668976
trainer/Q Targets Min          91.358
trainer/Log Pis Mean           11.060127
trainer/Log Pis Std            7.3296976
trainer/Log Pis Max            37.53553
trainer/Log Pis Min            -5.0512667
trainer/Policy mu Mean         0.010771933
trainer/Policy mu Std          1.5282408
trainer/Policy mu Max          5.0501413
trainer/Policy mu Min          -4.5975647
trainer/Policy log std Mean    -0.7604385
trainer/Policy log std Std     0.28708705
trainer/Policy log std Max     0.25306702
trainer/Policy log std Min     -1.8663027
trainer/Alpha                  0.0014128872426226735
trainer/Alpha Loss             -6.167415142059326
exploration/num steps total    2666000
exploration/num paths total    5332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.7892937032133112
exploration/Rewards Std        0.16440316551674078
exploration/Rewards Max        0.9793441257866182
exploration/Rewards Min        0.28143201413243607
exploration/Returns Mean       394.6468516066556
exploration/Returns Std        28.05283911486165
exploration/Returns Max        445.8696532150844
exploration/Returns Min        351.8348047316048
exploration/Actions Mean       0.03613427
exploration/Actions Std        0.69735336
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    394.6468516066556
evaluation/num steps total     2665000
evaluation/num paths total     5330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7596458473853338
evaluation/Rewards Std         0.18337325507977742
evaluation/Rewards Max         0.9796258386249511
evaluation/Rewards Min         0.2838629018597595
evaluation/Returns Mean        379.82292369266673
evaluation/Returns Std         38.02989113026724
evaluation/Returns Max         476.57652261152714
evaluation/Returns Min         340.4507767757177
evaluation/ExplReturns Mean    379.82292369266673
evaluation/ExplReturns Std     38.02989113026724
evaluation/ExplReturns Max     476.57652261152714
evaluation/ExplReturns Min     340.4507767757177
evaluation/Actions Mean        0.033926893
evaluation/Actions Std         0.6791396
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     379.82292369266673
time/data storing (s)          0.031740338541567326
time/evaluation sampling (s)   111.88902319967747
time/exploration sampling (s)  112.90811698976904
time/logging (s)               0.03017815761268139
time/saving (s)                0.01131017878651619
time/training (s)              9.204360363073647
time/epoch (s)                 234.07472922746092
time/total (s)                 124858.41830947809
Epoch                          532
-----------------------------  ---------------------
2023-08-02 04:39:00.778921 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 533 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3791.08]
trainer/QF1 Loss               0.02401925
trainer/QF2 Loss               0.022485489
trainer/Policy Loss            -93.03554
trainer/Q1 Predictions Mean    104.7373
trainer/Q1 Predictions Std     1.1691132
trainer/Q1 Predictions Max     107.91102
trainer/Q1 Predictions Min     94.43716
trainer/Q2 Predictions Mean    104.7529
trainer/Q2 Predictions Std     1.1865008
trainer/Q2 Predictions Max     107.85674
trainer/Q2 Predictions Min     93.98738
trainer/Q Targets Mean         104.74347
trainer/Q Targets Std          1.175242
trainer/Q Targets Max          108.050896
trainer/Q Targets Min          94.53056
trainer/Log Pis Mean           11.792479
trainer/Log Pis Std            6.8490963
trainer/Log Pis Max            37.548393
trainer/Log Pis Min            -9.273802
trainer/Policy mu Mean         0.12923634
trainer/Policy mu Std          1.5653989
trainer/Policy mu Max          10.806557
trainer/Policy mu Min          -6.4850435
trainer/Policy log std Mean    -0.7806232
trainer/Policy log std Std     0.30489594
trainer/Policy log std Max     0.7092849
trainer/Policy log std Min     -2.0072277
trainer/Alpha                  0.0013858892489224672
trainer/Alpha Loss             -1.365797519683838
exploration/num steps total    2671000
exploration/num paths total    5342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9530804570408175
exploration/Rewards Std        0.06160259927170773
exploration/Rewards Max        0.9792473367692356
exploration/Rewards Min        0.4888922295368272
exploration/Returns Mean       476.5402285204088
exploration/Returns Std        8.326995339406874
exploration/Returns Max        480.4962822557721
exploration/Returns Min        451.8490984736448
exploration/Actions Mean       0.03646207
exploration/Actions Std        0.6155284
exploration/Actions Max        0.9999917
exploration/Actions Min        -0.99996984
exploration/Num Paths          10
exploration/Average Returns    476.5402285204088
evaluation/num steps total     2670000
evaluation/num paths total     5340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609657396337962
evaluation/Rewards Std         0.047336777785852574
evaluation/Rewards Max         0.9795916749899558
evaluation/Rewards Min         0.49930592185656286
evaluation/Returns Mean        480.4828698168981
evaluation/Returns Std         0.62296006075301
evaluation/Returns Max         481.4078034819519
evaluation/Returns Min         479.0098829898045
evaluation/ExplReturns Mean    480.4828698168981
evaluation/ExplReturns Std     0.62296006075301
evaluation/ExplReturns Max     481.4078034819519
evaluation/ExplReturns Min     479.0098829898045
evaluation/Actions Mean        0.037029643
evaluation/Actions Std         0.48180386
evaluation/Actions Max         0.99954385
evaluation/Actions Min         -0.99957246
evaluation/Num Paths           10
evaluation/Average Returns     480.4828698168981
time/data storing (s)          0.03184229601174593
time/evaluation sampling (s)   111.6590262260288
time/exploration sampling (s)  111.67521254811436
time/logging (s)               0.03047200385481119
time/saving (s)                0.01030217856168747
time/training (s)              9.57306089065969
time/epoch (s)                 232.9799161432311
time/total (s)                 125091.40068550874
Epoch                          533
-----------------------------  ---------------------
2023-08-02 04:42:56.536492 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 534 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3434.606]
trainer/QF1 Loss               0.0219533
trainer/QF2 Loss               0.028703244
trainer/Policy Loss            -93.70201
trainer/Q1 Predictions Mean    104.726425
trainer/Q1 Predictions Std     1.2173429
trainer/Q1 Predictions Max     108.246346
trainer/Q1 Predictions Min     96.6935
trainer/Q2 Predictions Mean    104.731094
trainer/Q2 Predictions Std     1.1966847
trainer/Q2 Predictions Max     108.10165
trainer/Q2 Predictions Min     96.57798
trainer/Q Targets Mean         104.70087
trainer/Q Targets Std          1.2212348
trainer/Q Targets Max          108.14943
trainer/Q Targets Min          96.94596
trainer/Log Pis Mean           11.113433
trainer/Log Pis Std            7.3007164
trainer/Log Pis Max            42.209564
trainer/Log Pis Min            -5.4589767
trainer/Policy mu Mean         0.0050277724
trainer/Policy mu Std          1.5655124
trainer/Policy mu Max          4.99842
trainer/Policy mu Min          -8.056124
trainer/Policy log std Mean    -0.73654634
trainer/Policy log std Std     0.30518082
trainer/Policy log std Max     1.4466105
trainer/Policy log std Min     -1.8746091
trainer/Alpha                  0.0014850982697680593
trainer/Alpha Loss             -5.773663520812988
exploration/num steps total    2676000
exploration/num paths total    5352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9579807291423486
exploration/Rewards Std        0.05558194431927265
exploration/Rewards Max        0.9798735947894857
exploration/Rewards Min        0.4924967230880035
exploration/Returns Mean       478.99036457117427
exploration/Returns Std        3.7872214803663184
exploration/Returns Max        481.6066694545516
exploration/Returns Min        469.96414696410454
exploration/Actions Mean       0.04788637
exploration/Actions Std        0.64628315
exploration/Actions Max        0.9999769
exploration/Actions Min        -0.9999995
exploration/Num Paths          10
exploration/Average Returns    478.99036457117427
evaluation/num steps total     2675000
evaluation/num paths total     5350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9606215816842235
evaluation/Rewards Std         0.049168622922384206
evaluation/Rewards Max         0.9799780288016096
evaluation/Rewards Min         0.4893326660231953
evaluation/Returns Mean        480.3107908421116
evaluation/Returns Std         0.5252720515852011
evaluation/Returns Max         481.0081999768088
evaluation/Returns Min         479.4838326344743
evaluation/ExplReturns Mean    480.3107908421116
evaluation/ExplReturns Std     0.5252720515852011
evaluation/ExplReturns Max     481.0081999768088
evaluation/ExplReturns Min     479.4838326344743
evaluation/Actions Mean        0.01825124
evaluation/Actions Std         0.51711714
evaluation/Actions Max         0.99919075
evaluation/Actions Min         -0.99917
evaluation/Num Paths           10
evaluation/Average Returns     480.3107908421116
time/data storing (s)          0.0320872887969017
time/evaluation sampling (s)   112.57268111687154
time/exploration sampling (s)  113.41868955083191
time/logging (s)               0.03123380057513714
time/saving (s)                0.011546405032277107
time/training (s)              9.685279187746346
time/epoch (s)                 235.7515173498541
time/total (s)                 125327.15464403573
Epoch                          534
-----------------------------  ---------------------
2023-08-02 04:46:55.952278 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 535 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3571.891]
trainer/QF1 Loss               0.0274233
trainer/QF2 Loss               0.019757817
trainer/Policy Loss            -93.03709
trainer/Q1 Predictions Mean    104.541824
trainer/Q1 Predictions Std     1.480405
trainer/Q1 Predictions Max     108.55681
trainer/Q1 Predictions Min     88.00531
trainer/Q2 Predictions Mean    104.57577
trainer/Q2 Predictions Std     1.4755108
trainer/Q2 Predictions Max     108.68168
trainer/Q2 Predictions Min     88.288795
trainer/Q Targets Mean         104.621956
trainer/Q Targets Std          1.4285895
trainer/Q Targets Max          108.43534
trainer/Q Targets Min          88.74055
trainer/Log Pis Mean           11.606875
trainer/Log Pis Std            7.962846
trainer/Log Pis Max            53.456463
trainer/Log Pis Min            -3.7264132
trainer/Policy mu Mean         -0.030100496
trainer/Policy mu Std          1.5682966
trainer/Policy mu Max          7.0933375
trainer/Policy mu Min          -4.4994774
trainer/Policy log std Mean    -0.72715706
trainer/Policy log std Std     0.31024972
trainer/Policy log std Max     0.18128467
trainer/Policy log std Min     -2.004009
trainer/Alpha                  0.0014960112748667598
trainer/Alpha Loss             -2.5572447776794434
exploration/num steps total    2681000
exploration/num paths total    5362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8596524286042033
exploration/Rewards Std        0.1110829426907206
exploration/Rewards Max        0.9793365318459177
exploration/Rewards Min        0.4933035075724461
exploration/Returns Mean       429.82621430210156
exploration/Returns Std        19.80835755530866
exploration/Returns Max        471.20055186878665
exploration/Returns Min        388.40085766994383
exploration/Actions Mean       0.07838441
exploration/Actions Std        0.6934715
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999875
exploration/Num Paths          10
exploration/Average Returns    429.82621430210156
evaluation/num steps total     2680000
evaluation/num paths total     5360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8676744575991999
evaluation/Rewards Std         0.11246688358613467
evaluation/Rewards Max         0.9791699902324578
evaluation/Rewards Min         0.49254770117362584
evaluation/Returns Mean        433.83722879959987
evaluation/Returns Std         17.869507767734074
evaluation/Returns Max         455.72234453474636
evaluation/Returns Min         402.22580862554616
evaluation/ExplReturns Mean    433.83722879959987
evaluation/ExplReturns Std     17.869507767734074
evaluation/ExplReturns Max     455.72234453474636
evaluation/ExplReturns Min     402.22580862554616
evaluation/Actions Mean        0.06584574
evaluation/Actions Std         0.65634334
evaluation/Actions Max         0.9999354
evaluation/Actions Min         -0.9999975
evaluation/Num Paths           10
evaluation/Average Returns     433.83722879959987
time/data storing (s)          0.03509859275072813
time/evaluation sampling (s)   114.6223663026467
time/exploration sampling (s)  115.01085756532848
time/logging (s)               0.030488258227705956
time/saving (s)                0.010277364403009415
time/training (s)              9.699037647806108
time/epoch (s)                 239.40812573116273
time/total (s)                 125566.56534649525
Epoch                          535
-----------------------------  ---------------------
2023-08-02 04:50:53.289250 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 536 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3778.576]
trainer/QF1 Loss               0.02592975
trainer/QF2 Loss               0.02136198
trainer/Policy Loss            -92.113396
trainer/Q1 Predictions Mean    104.39188
trainer/Q1 Predictions Std     2.128796
trainer/Q1 Predictions Max     108.28208
trainer/Q1 Predictions Min     83.33469
trainer/Q2 Predictions Mean    104.40799
trainer/Q2 Predictions Std     2.1760917
trainer/Q2 Predictions Max     108.21414
trainer/Q2 Predictions Min     83.11239
trainer/Q Targets Mean         104.38188
trainer/Q Targets Std          2.1622229
trainer/Q Targets Max          108.51135
trainer/Q Targets Min          83.21156
trainer/Log Pis Mean           12.387759
trainer/Log Pis Std            8.839842
trainer/Log Pis Max            67.41917
trainer/Log Pis Min            -3.9860373
trainer/Policy mu Mean         -0.1078266
trainer/Policy mu Std          1.6002889
trainer/Policy mu Max          6.89775
trainer/Policy mu Min          -6.328267
trainer/Policy log std Mean    -0.76218253
trainer/Policy log std Std     0.31927562
trainer/Policy log std Max     0.45270887
trainer/Policy log std Min     -2.1172688
trainer/Alpha                  0.0014863848919048905
trainer/Alpha Loss             2.524872303009033
exploration/num steps total    2686000
exploration/num paths total    5372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9089499881144416
exploration/Rewards Std        0.09010247788276803
exploration/Rewards Max        0.978682825539724
exploration/Rewards Min        0.49344509948164267
exploration/Returns Mean       454.4749940572207
exploration/Returns Std        13.034610773137757
exploration/Returns Max        469.729325366644
exploration/Returns Min        429.85262814518455
exploration/Actions Mean       0.18085366
exploration/Actions Std        0.64953655
exploration/Actions Max        0.9999952
exploration/Actions Min        -0.99984795
exploration/Num Paths          10
exploration/Average Returns    454.4749940572207
evaluation/num steps total     2685000
evaluation/num paths total     5370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8993887064078564
evaluation/Rewards Std         0.10101794758812861
evaluation/Rewards Max         0.9790392880396519
evaluation/Rewards Min         0.490712297588538
evaluation/Returns Mean        449.6943532039284
evaluation/Returns Std         38.712815231471886
evaluation/Returns Max         478.8386441720322
evaluation/Returns Min         385.6610135820082
evaluation/ExplReturns Mean    449.6943532039284
evaluation/ExplReturns Std     38.712815231471886
evaluation/ExplReturns Max     478.8386441720322
evaluation/ExplReturns Min     385.6610135820082
evaluation/Actions Mean        0.16068332
evaluation/Actions Std         0.6223433
evaluation/Actions Max         0.99994063
evaluation/Actions Min         -0.9998812
evaluation/Num Paths           10
evaluation/Average Returns     449.6943532039284
time/data storing (s)          0.031781730242073536
time/evaluation sampling (s)   113.64224000275135
time/exploration sampling (s)  113.53087117802352
time/logging (s)               0.030550877563655376
time/saving (s)                0.011213177815079689
time/training (s)              10.083558316342533
time/epoch (s)                 237.3302152827382
time/total (s)                 125803.8980013607
Epoch                          536
-----------------------------  ---------------------
2023-08-02 04:54:53.421649 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 537 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3794.6135]
trainer/QF1 Loss               0.025496982
trainer/QF2 Loss               0.022640863
trainer/Policy Loss            -92.55737
trainer/Q1 Predictions Mean    104.541084
trainer/Q1 Predictions Std     1.2517064
trainer/Q1 Predictions Max     108.188354
trainer/Q1 Predictions Min     99.317345
trainer/Q2 Predictions Mean    104.46315
trainer/Q2 Predictions Std     1.2344242
trainer/Q2 Predictions Max     108.12791
trainer/Q2 Predictions Min     99.11109
trainer/Q Targets Mean         104.48774
trainer/Q Targets Std          1.2497674
trainer/Q Targets Max          108.15093
trainer/Q Targets Min          99.238686
trainer/Log Pis Mean           12.003019
trainer/Log Pis Std            7.818251
trainer/Log Pis Max            39.7344
trainer/Log Pis Min            -6.9608827
trainer/Policy mu Mean         0.032340273
trainer/Policy mu Std          1.5675663
trainer/Policy mu Max          5.4029026
trainer/Policy mu Min          -5.4453726
trainer/Policy log std Mean    -0.7588113
trainer/Policy log std Std     0.3001052
trainer/Policy log std Max     0.24582055
trainer/Policy log std Min     -2.0865355
trainer/Alpha                  0.0015078890137374401
trainer/Alpha Loss             0.019616663455963135
exploration/num steps total    2691000
exploration/num paths total    5382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9482224378020714
exploration/Rewards Std        0.07424078901529224
exploration/Rewards Max        0.9797946581745651
exploration/Rewards Min        0.495353600204711
exploration/Returns Mean       474.1112189010355
exploration/Returns Std        13.924173637422001
exploration/Returns Max        482.32250318578065
exploration/Returns Min        443.9142541857398
exploration/Actions Mean       0.13329934
exploration/Actions Std        0.6825407
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999946
exploration/Num Paths          10
exploration/Average Returns    474.1112189010355
evaluation/num steps total     2690000
evaluation/num paths total     5380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9661801967647454
evaluation/Rewards Std         0.051350987626200266
evaluation/Rewards Max         0.9790367468102634
evaluation/Rewards Min         0.48534169661247684
evaluation/Returns Mean        483.0900983823729
evaluation/Returns Std         0.7822344414074285
evaluation/Returns Max         484.28770675149457
evaluation/Returns Min         481.1012109960389
evaluation/ExplReturns Mean    483.0900983823729
evaluation/ExplReturns Std     0.7822344414074285
evaluation/ExplReturns Max     484.28770675149457
evaluation/ExplReturns Min     481.1012109960389
evaluation/Actions Mean        0.11490661
evaluation/Actions Std         0.6407646
evaluation/Actions Max         0.99993443
evaluation/Actions Min         -0.9996376
evaluation/Num Paths           10
evaluation/Average Returns     483.0900983823729
time/data storing (s)          0.032021867111325264
time/evaluation sampling (s)   115.71891532931477
time/exploration sampling (s)  114.76644609123468
time/logging (s)               0.030498482286930084
time/saving (s)                0.01206131186336279
time/training (s)              9.565541997551918
time/epoch (s)                 240.125485079363
time/total (s)                 126044.02601157222
Epoch                          537
-----------------------------  ---------------------
2023-08-02 04:58:53.100760 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 538 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3829.4717]
trainer/QF1 Loss               0.02887844
trainer/QF2 Loss               0.026315406
trainer/Policy Loss            -92.18286
trainer/Q1 Predictions Mean    104.20816
trainer/Q1 Predictions Std     2.5015728
trainer/Q1 Predictions Max     108.286644
trainer/Q1 Predictions Min     74.113495
trainer/Q2 Predictions Mean    104.20703
trainer/Q2 Predictions Std     2.5098577
trainer/Q2 Predictions Max     108.247505
trainer/Q2 Predictions Min     73.38143
trainer/Q Targets Mean         104.11928
trainer/Q Targets Std          2.5072553
trainer/Q Targets Max          107.86346
trainer/Q Targets Min          73.42416
trainer/Log Pis Mean           12.111061
trainer/Log Pis Std            7.718479
trainer/Log Pis Max            48.77517
trainer/Log Pis Min            -3.877999
trainer/Policy mu Mean         -0.07445646
trainer/Policy mu Std          1.599532
trainer/Policy mu Max          6.935176
trainer/Policy mu Min          -5.952113
trainer/Policy log std Mean    -0.75214887
trainer/Policy log std Std     0.29274282
trainer/Policy log std Max     1.4851741
trainer/Policy log std Min     -2.1480834
trainer/Alpha                  0.0015674743335694075
trainer/Alpha Loss             0.717273473739624
exploration/num steps total    2696000
exploration/num paths total    5392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9162265955521579
exploration/Rewards Std        0.09469985208515501
exploration/Rewards Max        0.9788453588269823
exploration/Rewards Min        0.4867888046371738
exploration/Returns Mean       458.1132977760791
exploration/Returns Std        6.489871817158576
exploration/Returns Max        470.93275521008593
exploration/Returns Min        449.1105222707373
exploration/Actions Mean       0.10451847
exploration/Actions Std        0.71602297
exploration/Actions Max        0.9999962
exploration/Actions Min        -0.9999957
exploration/Num Paths          10
exploration/Average Returns    458.1132977760791
evaluation/num steps total     2695000
evaluation/num paths total     5390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9203943464519849
evaluation/Rewards Std         0.09345100383630925
evaluation/Rewards Max         0.9798960156366932
evaluation/Rewards Min         0.4887349434540229
evaluation/Returns Mean        460.19717322599234
evaluation/Returns Std         9.419722496119894
evaluation/Returns Max         469.80081809131127
evaluation/Returns Min         443.64215272062296
evaluation/ExplReturns Mean    460.19717322599234
evaluation/ExplReturns Std     9.419722496119894
evaluation/ExplReturns Max     469.80081809131127
evaluation/ExplReturns Min     443.64215272062296
evaluation/Actions Mean        0.11597938
evaluation/Actions Std         0.70089114
evaluation/Actions Max         0.9999256
evaluation/Actions Min         -0.9999905
evaluation/Num Paths           10
evaluation/Average Returns     460.19717322599234
time/data storing (s)          0.03213168866932392
time/evaluation sampling (s)   114.61873217020184
time/exploration sampling (s)  115.53648142330348
time/logging (s)               0.030689348466694355
time/saving (s)                0.012801690958440304
time/training (s)              9.441574269905686
time/epoch (s)                 239.67241059150547
time/total (s)                 126283.70095243864
Epoch                          538
-----------------------------  ---------------------
2023-08-02 05:02:54.647538 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 539 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3634.434]
trainer/QF1 Loss               0.04058793
trainer/QF2 Loss               0.0283242
trainer/Policy Loss            -92.56931
trainer/Q1 Predictions Mean    104.2045
trainer/Q1 Predictions Std     1.6272578
trainer/Q1 Predictions Max     107.27164
trainer/Q1 Predictions Min     90.55008
trainer/Q2 Predictions Mean    104.14256
trainer/Q2 Predictions Std     1.6736606
trainer/Q2 Predictions Max     107.19597
trainer/Q2 Predictions Min     89.53119
trainer/Q Targets Mean         104.135574
trainer/Q Targets Std          1.7077037
trainer/Q Targets Max          107.22021
trainer/Q Targets Min          90.16914
trainer/Log Pis Mean           11.691795
trainer/Log Pis Std            8.009101
trainer/Log Pis Max            54.4017
trainer/Log Pis Min            -3.3458004
trainer/Policy mu Mean         0.06502801
trainer/Policy mu Std          1.5622332
trainer/Policy mu Max          6.453622
trainer/Policy mu Min          -7.779331
trainer/Policy log std Mean    -0.7782816
trainer/Policy log std Std     0.31307995
trainer/Policy log std Max     0.7508775
trainer/Policy log std Min     -2.076788
trainer/Alpha                  0.0015264916000887752
trainer/Alpha Loss             -1.9985698461532593
exploration/num steps total    2701000
exploration/num paths total    5402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9331025670677416
exploration/Rewards Std        0.10637284665180297
exploration/Rewards Max        0.9782652758414812
exploration/Rewards Min        0.3903603764695107
exploration/Returns Mean       466.5512835338709
exploration/Returns Std        40.49850940413591
exploration/Returns Max        480.7522794606343
exploration/Returns Min        345.0632352947637
exploration/Actions Mean       0.16322477
exploration/Actions Std        0.66445607
exploration/Actions Max        0.9999985
exploration/Actions Min        -0.99998945
exploration/Num Paths          10
exploration/Average Returns    466.5512835338709
evaluation/num steps total     2700000
evaluation/num paths total     5400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9504450344936389
evaluation/Rewards Std         0.0745977647862023
evaluation/Rewards Max         0.9797853554055037
evaluation/Rewards Min         0.44859018505716136
evaluation/Returns Mean        475.22251724681945
evaluation/Returns Std         18.250180508690278
evaluation/Returns Max         482.3879797474901
evaluation/Returns Min         420.51940540906287
evaluation/ExplReturns Mean    475.22251724681945
evaluation/ExplReturns Std     18.250180508690278
evaluation/ExplReturns Max     482.3879797474901
evaluation/ExplReturns Min     420.51940540906287
evaluation/Actions Mean        0.1799023
evaluation/Actions Std         0.6576132
evaluation/Actions Max         0.9999771
evaluation/Actions Min         -0.9999885
evaluation/Num Paths           10
evaluation/Average Returns     475.22251724681945
time/data storing (s)          0.03187693562358618
time/evaluation sampling (s)   115.62010940816253
time/exploration sampling (s)  116.18655863031745
time/logging (s)               0.03047821018844843
time/saving (s)                0.010258989408612251
time/training (s)              9.660316036082804
time/epoch (s)                 241.53959820978343
time/total (s)                 126525.24317814875
Epoch                          539
-----------------------------  ---------------------
2023-08-02 05:06:55.727965 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 540 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3932.9236]
trainer/QF1 Loss               0.032380007
trainer/QF2 Loss               0.027389258
trainer/Policy Loss            -91.69384
trainer/Q1 Predictions Mean    104.0574
trainer/Q1 Predictions Std     2.6162646
trainer/Q1 Predictions Max     107.08157
trainer/Q1 Predictions Min     73.740395
trainer/Q2 Predictions Mean    104.00037
trainer/Q2 Predictions Std     2.6531296
trainer/Q2 Predictions Max     107.14504
trainer/Q2 Predictions Min     73.13941
trainer/Q Targets Mean         103.97716
trainer/Q Targets Std          2.6603453
trainer/Q Targets Max          107.045456
trainer/Q Targets Min          72.71156
trainer/Log Pis Mean           12.404242
trainer/Log Pis Std            7.9920936
trainer/Log Pis Max            64.35272
trainer/Log Pis Min            -6.7431264
trainer/Policy mu Mean         0.030936956
trainer/Policy mu Std          1.6020495
trainer/Policy mu Max          8.571406
trainer/Policy mu Min          -8.870853
trainer/Policy log std Mean    -0.7875299
trainer/Policy log std Std     0.3220215
trainer/Policy log std Max     0.3977944
trainer/Policy log std Min     -1.9817555
trainer/Alpha                  0.0014559364644810557
trainer/Alpha Loss             2.6406002044677734
exploration/num steps total    2706000
exploration/num paths total    5412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9352355871870893
exploration/Rewards Std        0.10397099344766053
exploration/Rewards Max        0.9794334461211517
exploration/Rewards Min        0.4215302826819386
exploration/Returns Mean       467.6177935935446
exploration/Returns Std        27.086429157751468
exploration/Returns Max        482.0820744946092
exploration/Returns Min        406.7996938048448
exploration/Actions Mean       0.080423295
exploration/Actions Std        0.6389351
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.9999998
exploration/Num Paths          10
exploration/Average Returns    467.6177935935446
evaluation/num steps total     2705000
evaluation/num paths total     5410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8970991872624449
evaluation/Rewards Std         0.14420635098377918
evaluation/Rewards Max         0.9786578597192372
evaluation/Rewards Min         0.3588439269979081
evaluation/Returns Mean        448.54959363122225
evaluation/Returns Std         50.2805619755501
evaluation/Returns Max         481.7068715894844
evaluation/Returns Min         362.2187380794589
evaluation/ExplReturns Mean    448.54959363122225
evaluation/ExplReturns Std     50.2805619755501
evaluation/ExplReturns Max     481.7068715894844
evaluation/ExplReturns Min     362.2187380794589
evaluation/Actions Mean        0.091025464
evaluation/Actions Std         0.6385167
evaluation/Actions Max         0.9999996
evaluation/Actions Min         -0.9999982
evaluation/Num Paths           10
evaluation/Average Returns     448.54959363122225
time/data storing (s)          0.031992548145353794
time/evaluation sampling (s)   115.27155073173344
time/exploration sampling (s)  116.69343528710306
time/logging (s)               0.03070547617971897
time/saving (s)                0.011494994163513184
time/training (s)              9.034629674628377
time/epoch (s)                 241.07380871195346
time/total (s)                 126766.31946912594
Epoch                          540
-----------------------------  ---------------------
2023-08-02 05:10:58.972276 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 541 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4024.5024]
trainer/QF1 Loss               0.041115887
trainer/QF2 Loss               0.03606195
trainer/Policy Loss            -91.281494
trainer/Q1 Predictions Mean    104.12201
trainer/Q1 Predictions Std     1.7454205
trainer/Q1 Predictions Max     106.67223
trainer/Q1 Predictions Min     90.6395
trainer/Q2 Predictions Mean    104.113785
trainer/Q2 Predictions Std     1.7127788
trainer/Q2 Predictions Max     106.67886
trainer/Q2 Predictions Min     90.65229
trainer/Q Targets Mean         103.99473
trainer/Q Targets Std          1.7238463
trainer/Q Targets Max          106.55522
trainer/Q Targets Min          90.83061
trainer/Log Pis Mean           12.935051
trainer/Log Pis Std            7.6460257
trainer/Log Pis Max            56.37464
trainer/Log Pis Min            -6.6036086
trainer/Policy mu Mean         -0.053313017
trainer/Policy mu Std          1.6103799
trainer/Policy mu Max          8.39329
trainer/Policy mu Min          -8.446634
trainer/Policy log std Mean    -0.7914732
trainer/Policy log std Std     0.32615447
trainer/Policy log std Max     0.64415103
trainer/Policy log std Min     -2.1014984
trainer/Alpha                  0.00146640429738909
trainer/Alpha Loss             6.101447105407715
exploration/num steps total    2711000
exploration/num paths total    5422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9627623096987129
exploration/Rewards Std        0.0514910078334524
exploration/Rewards Max        0.9799558704899823
exploration/Rewards Min        0.48607061772550253
exploration/Returns Mean       481.38115484935634
exploration/Returns Std        0.8070577956204554
exploration/Returns Max        482.44718524209543
exploration/Returns Min        479.82016942949934
exploration/Actions Mean       0.009540477
exploration/Actions Std        0.65296435
exploration/Actions Max        0.99975455
exploration/Actions Min        -0.999999
exploration/Num Paths          10
exploration/Average Returns    481.38115484935634
evaluation/num steps total     2710000
evaluation/num paths total     5420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9588213836810854
evaluation/Rewards Std         0.04967660558895877
evaluation/Rewards Max         0.9793147192651003
evaluation/Rewards Min         0.4950711148370583
evaluation/Returns Mean        479.41069184054265
evaluation/Returns Std         1.8269867989758786
evaluation/Returns Max         481.44222633207625
evaluation/Returns Min         476.3417349017258
evaluation/ExplReturns Mean    479.41069184054265
evaluation/ExplReturns Std     1.8269867989758786
evaluation/ExplReturns Max     481.44222633207625
evaluation/ExplReturns Min     476.3417349017258
evaluation/Actions Mean        -0.033846583
evaluation/Actions Std         0.6436188
evaluation/Actions Max         0.9980754
evaluation/Actions Min         -0.9999708
evaluation/Num Paths           10
evaluation/Average Returns     479.41069184054265
time/data storing (s)          0.03193147014826536
time/evaluation sampling (s)   115.24806453008205
time/exploration sampling (s)  118.29560572374612
time/logging (s)               0.03042428381741047
time/saving (s)                0.012483419850468636
time/training (s)              9.618567103520036
time/epoch (s)                 243.23707653116435
time/total (s)                 127009.55910706613
Epoch                          541
-----------------------------  --------------------
2023-08-02 05:15:01.680718 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 542 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3549.6936]
trainer/QF1 Loss               0.019053478
trainer/QF2 Loss               0.015886717
trainer/Policy Loss            -92.54432
trainer/Q1 Predictions Mean    104.19189
trainer/Q1 Predictions Std     1.2352544
trainer/Q1 Predictions Max     106.889786
trainer/Q1 Predictions Min     98.11693
trainer/Q2 Predictions Mean    104.15972
trainer/Q2 Predictions Std     1.2277373
trainer/Q2 Predictions Max     106.86819
trainer/Q2 Predictions Min     97.80237
trainer/Q Targets Mean         104.109886
trainer/Q Targets Std          1.2255254
trainer/Q Targets Max          106.69927
trainer/Q Targets Min          98.1518
trainer/Log Pis Mean           11.712053
trainer/Log Pis Std            7.374784
trainer/Log Pis Max            57.326134
trainer/Log Pis Min            -3.125776
trainer/Policy mu Mean         -0.07742072
trainer/Policy mu Std          1.5258954
trainer/Policy mu Max          6.585644
trainer/Policy mu Min          -5.2023563
trainer/Policy log std Mean    -0.81047434
trainer/Policy log std Std     0.33423176
trainer/Policy log std Max     0.41378236
trainer/Policy log std Min     -2.2255883
trainer/Alpha                  0.0014772318536415696
trainer/Alpha Loss             -1.8767070770263672
exploration/num steps total    2716000
exploration/num paths total    5432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9448448721939529
exploration/Rewards Std        0.07797100469110486
exploration/Rewards Max        0.9796030841508316
exploration/Rewards Min        0.49941777130272896
exploration/Returns Mean       472.4224360969765
exploration/Returns Std        18.020035856230574
exploration/Returns Max        482.6618058923342
exploration/Returns Min        430.9941217804091
exploration/Actions Mean       0.02588061
exploration/Actions Std        0.6384594
exploration/Actions Max        0.9999774
exploration/Actions Min        -0.99996096
exploration/Num Paths          10
exploration/Average Returns    472.4224360969765
evaluation/num steps total     2715000
evaluation/num paths total     5430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8764722366666483
evaluation/Rewards Std         0.11144700736831106
evaluation/Rewards Max         0.9790276589189371
evaluation/Rewards Min         0.4970438062896871
evaluation/Returns Mean        438.23611833332416
evaluation/Returns Std         35.956109527286806
evaluation/Returns Max         481.77987111889087
evaluation/Returns Min         396.051181596759
evaluation/ExplReturns Mean    438.23611833332416
evaluation/ExplReturns Std     35.956109527286806
evaluation/ExplReturns Max     481.77987111889087
evaluation/ExplReturns Min     396.051181596759
evaluation/Actions Mean        0.031436674
evaluation/Actions Std         0.6470143
evaluation/Actions Max         0.9991383
evaluation/Actions Min         -0.9999067
evaluation/Num Paths           10
evaluation/Average Returns     438.23611833332416
time/data storing (s)          0.03192521724849939
time/evaluation sampling (s)   114.59786515962332
time/exploration sampling (s)  118.3690061159432
time/logging (s)               0.030677211470901966
time/saving (s)                0.012416563928127289
time/training (s)              9.659795919433236
time/epoch (s)                 242.70168618764728
time/total (s)                 127252.2634535227
Epoch                          542
-----------------------------  ---------------------
2023-08-02 05:18:56.347210 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 543 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4044.6997]
trainer/QF1 Loss               0.028110858
trainer/QF2 Loss               0.030366682
trainer/Policy Loss            -91.66864
trainer/Q1 Predictions Mean    103.63461
trainer/Q1 Predictions Std     3.0023391
trainer/Q1 Predictions Max     106.502365
trainer/Q1 Predictions Min     78.11752
trainer/Q2 Predictions Mean    103.560326
trainer/Q2 Predictions Std     3.0454385
trainer/Q2 Predictions Max     106.39258
trainer/Q2 Predictions Min     77.764595
trainer/Q Targets Mean         103.581635
trainer/Q Targets Std          3.0212429
trainer/Q Targets Max          106.338936
trainer/Q Targets Min          77.86618
trainer/Log Pis Mean           12.0095
trainer/Log Pis Std            8.404461
trainer/Log Pis Max            62.171265
trainer/Log Pis Min            -7.7743435
trainer/Policy mu Mean         -0.04341874
trainer/Policy mu Std          1.5792111
trainer/Policy mu Max          8.879898
trainer/Policy mu Min          -6.5419846
trainer/Policy log std Mean    -0.781636
trainer/Policy log std Std     0.30609354
trainer/Policy log std Max     0.6378733
trainer/Policy log std Min     -1.9647471
trainer/Alpha                  0.0014857371570542455
trainer/Alpha Loss             0.061859130859375
exploration/num steps total    2721000
exploration/num paths total    5442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8538989020367582
exploration/Rewards Std        0.10910273564346008
exploration/Rewards Max        0.9782646564555977
exploration/Rewards Min        0.4754000248038246
exploration/Returns Mean       426.94945101837914
exploration/Returns Std        15.843174734463565
exploration/Returns Max        462.24484865237747
exploration/Returns Min        407.2579508326101
exploration/Actions Mean       0.08647217
exploration/Actions Std        0.6535521
exploration/Actions Max        0.9999992
exploration/Actions Min        -0.99999815
exploration/Num Paths          10
exploration/Average Returns    426.94945101837914
evaluation/num steps total     2720000
evaluation/num paths total     5440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8797668674711513
evaluation/Rewards Std         0.11296481901018922
evaluation/Rewards Max         0.9796532416521821
evaluation/Rewards Min         0.4893208706902732
evaluation/Returns Mean        439.88343373557564
evaluation/Returns Std         20.44902223968842
evaluation/Returns Max         462.2920581844814
evaluation/Returns Min         408.3293254327922
evaluation/ExplReturns Mean    439.88343373557564
evaluation/ExplReturns Std     20.44902223968842
evaluation/ExplReturns Max     462.2920581844814
evaluation/ExplReturns Min     408.3293254327922
evaluation/Actions Mean        0.04417225
evaluation/Actions Std         0.6431352
evaluation/Actions Max         0.99999297
evaluation/Actions Min         -0.99999464
evaluation/Num Paths           10
evaluation/Average Returns     439.88343373557564
time/data storing (s)          0.031869759783148766
time/evaluation sampling (s)   112.46275223232806
time/exploration sampling (s)  112.73056352697313
time/logging (s)               0.030517134815454483
time/saving (s)                0.012654261663556099
time/training (s)              9.391061667352915
time/epoch (s)                 234.65941858291626
time/total (s)                 127486.92540637963
Epoch                          543
-----------------------------  ---------------------
2023-08-02 05:22:51.453712 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 544 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3510.4917]
trainer/QF1 Loss               0.023079634
trainer/QF2 Loss               0.016769024
trainer/Policy Loss            -91.93619
trainer/Q1 Predictions Mean    103.70427
trainer/Q1 Predictions Std     1.9692595
trainer/Q1 Predictions Max     106.00968
trainer/Q1 Predictions Min     80.45777
trainer/Q2 Predictions Mean    103.703674
trainer/Q2 Predictions Std     1.957459
trainer/Q2 Predictions Max     105.959335
trainer/Q2 Predictions Min     80.740814
trainer/Q Targets Mean         103.70347
trainer/Q Targets Std          1.9762609
trainer/Q Targets Max          106.08462
trainer/Q Targets Min          80.343544
trainer/Log Pis Mean           11.8596
trainer/Log Pis Std            7.734204
trainer/Log Pis Max            50.434734
trainer/Log Pis Min            -2.937586
trainer/Policy mu Mean         0.03786649
trainer/Policy mu Std          1.5520059
trainer/Policy mu Max          5.4833455
trainer/Policy mu Min          -4.8925447
trainer/Policy log std Mean    -0.76662683
trainer/Policy log std Std     0.29961678
trainer/Policy log std Max     0.23873422
trainer/Policy log std Min     -1.9478797
trainer/Alpha                  0.0014995828969404101
trainer/Alpha Loss             -0.9129576086997986
exploration/num steps total    2726000
exploration/num paths total    5452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9582552985042454
exploration/Rewards Std        0.04990501575257024
exploration/Rewards Max        0.9792027469484696
exploration/Rewards Min        0.49771696963249035
exploration/Returns Mean       479.12764925212275
exploration/Returns Std        0.33909112931493485
exploration/Returns Max        479.7072471750846
exploration/Returns Min        478.6334628319215
exploration/Actions Mean       0.07858094
exploration/Actions Std        0.6387566
exploration/Actions Max        0.99987876
exploration/Actions Min        -0.99996203
exploration/Num Paths          10
exploration/Average Returns    479.12764925212275
evaluation/num steps total     2725000
evaluation/num paths total     5450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9611082663777754
evaluation/Rewards Std         0.05068533204004881
evaluation/Rewards Max         0.9790569547031084
evaluation/Rewards Min         0.49541348648951583
evaluation/Returns Mean        480.5541331888877
evaluation/Returns Std         1.7284743489284622
evaluation/Returns Max         483.6593738730131
evaluation/Returns Min         477.8672536327762
evaluation/ExplReturns Mean    480.5541331888877
evaluation/ExplReturns Std     1.7284743489284622
evaluation/ExplReturns Max     483.6593738730131
evaluation/ExplReturns Min     477.8672536327762
evaluation/Actions Mean        0.10222893
evaluation/Actions Std         0.5921086
evaluation/Actions Max         0.999629
evaluation/Actions Min         -0.9997582
evaluation/Num Paths           10
evaluation/Average Returns     480.5541331888877
time/data storing (s)          0.031675804406404495
time/evaluation sampling (s)   112.275619068183
time/exploration sampling (s)  112.65818694978952
time/logging (s)               0.03061074484139681
time/saving (s)                0.010999894700944424
time/training (s)              10.09255669824779
time/epoch (s)                 235.09964916016906
time/total (s)                 127722.02758451737
Epoch                          544
-----------------------------  ---------------------
2023-08-02 05:26:45.952596 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 545 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3847.6255]
trainer/QF1 Loss               0.036667757
trainer/QF2 Loss               0.02766606
trainer/Policy Loss            -92.50878
trainer/Q1 Predictions Mean    104.02078
trainer/Q1 Predictions Std     1.0202452
trainer/Q1 Predictions Max     106.259926
trainer/Q1 Predictions Min     99.17176
trainer/Q2 Predictions Mean    103.97128
trainer/Q2 Predictions Std     1.037684
trainer/Q2 Predictions Max     106.025925
trainer/Q2 Predictions Min     98.89246
trainer/Q Targets Mean         103.94499
trainer/Q Targets Std          1.0286154
trainer/Q Targets Max          106.17441
trainer/Q Targets Min          99.00878
trainer/Log Pis Mean           11.576067
trainer/Log Pis Std            7.3427663
trainer/Log Pis Max            45.619396
trainer/Log Pis Min            -2.7588136
trainer/Policy mu Mean         -0.107779145
trainer/Policy mu Std          1.5268896
trainer/Policy mu Max          5.170108
trainer/Policy mu Min          -4.663361
trainer/Policy log std Mean    -0.80645037
trainer/Policy log std Std     0.32197583
trainer/Policy log std Max     -0.011417568
trainer/Policy log std Min     -2.0043175
trainer/Alpha                  0.001508742687292397
trainer/Alpha Loss             -2.754075050354004
exploration/num steps total    2731000
exploration/num paths total    5462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9552017490821941
exploration/Rewards Std        0.047889213285929794
exploration/Rewards Max        0.9777093297072806
exploration/Rewards Min        0.495460864153071
exploration/Returns Mean       477.6008745410971
exploration/Returns Std        0.5181491796601148
exploration/Returns Max        478.2864314683735
exploration/Returns Min        476.62275923758824
exploration/Actions Mean       0.14591621
exploration/Actions Std        0.5981957
exploration/Actions Max        0.9997802
exploration/Actions Min        -0.99995637
exploration/Num Paths          10
exploration/Average Returns    477.6008745410971
evaluation/num steps total     2730000
evaluation/num paths total     5460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9599088952093975
evaluation/Rewards Std         0.04877374514909449
evaluation/Rewards Max         0.9763737614471346
evaluation/Rewards Min         0.49866687283511074
evaluation/Returns Mean        479.9544476046988
evaluation/Returns Std         0.911214519317398
evaluation/Returns Max         481.3229295154197
evaluation/Returns Min         478.6092144969546
evaluation/ExplReturns Mean    479.9544476046988
evaluation/ExplReturns Std     0.911214519317398
evaluation/ExplReturns Max     481.3229295154197
evaluation/ExplReturns Min     478.6092144969546
evaluation/Actions Mean        0.15586369
evaluation/Actions Std         0.5557627
evaluation/Actions Max         0.99848324
evaluation/Actions Min         -0.99967295
evaluation/Num Paths           10
evaluation/Average Returns     479.9544476046988
time/data storing (s)          0.03193111903965473
time/evaluation sampling (s)   112.01871979422867
time/exploration sampling (s)  112.45835146401078
time/logging (s)               0.030546694062650204
time/saving (s)                0.011215207166969776
time/training (s)              9.941111889667809
time/epoch (s)                 234.49187616817653
time/total (s)                 127956.52196896356
Epoch                          545
-----------------------------  --------------------
2023-08-02 05:30:40.974883 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 546 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3267.377]
trainer/QF1 Loss               0.024269523
trainer/QF2 Loss               0.030522577
trainer/Policy Loss            -90.3316
trainer/Q1 Predictions Mean    103.47784
trainer/Q1 Predictions Std     2.8000233
trainer/Q1 Predictions Max     106.07395
trainer/Q1 Predictions Min     69.807045
trainer/Q2 Predictions Mean    103.43441
trainer/Q2 Predictions Std     2.808498
trainer/Q2 Predictions Max     106.117226
trainer/Q2 Predictions Min     69.404
trainer/Q Targets Mean         103.43428
trainer/Q Targets Std          2.8148305
trainer/Q Targets Max          106.071014
trainer/Q Targets Min          69.52509
trainer/Log Pis Mean           13.206778
trainer/Log Pis Std            8.338055
trainer/Log Pis Max            53.040497
trainer/Log Pis Min            -1.3977003
trainer/Policy mu Mean         -0.024438495
trainer/Policy mu Std          1.6446006
trainer/Policy mu Max          7.7808747
trainer/Policy mu Min          -11.7813425
trainer/Policy log std Mean    -0.810544
trainer/Policy log std Std     0.31554192
trainer/Policy log std Max     1.252696
trainer/Policy log std Min     -2.3063908
trainer/Alpha                  0.0014569886261597276
trainer/Alpha Loss             7.882406234741211
exploration/num steps total    2736000
exploration/num paths total    5472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9606726927693622
exploration/Rewards Std        0.05231521294249944
exploration/Rewards Max        0.9793348950151043
exploration/Rewards Min        0.4971088848177921
exploration/Returns Mean       480.3363463846813
exploration/Returns Std        0.3945871596483033
exploration/Returns Max        480.9648684770753
exploration/Returns Min        479.68609919161264
exploration/Actions Mean       0.14927402
exploration/Actions Std        0.62393034
exploration/Actions Max        0.9998716
exploration/Actions Min        -0.9999694
exploration/Num Paths          10
exploration/Average Returns    480.3363463846813
evaluation/num steps total     2735000
evaluation/num paths total     5470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9597471061563155
evaluation/Rewards Std         0.05219040218821871
evaluation/Rewards Max         0.9792581176597216
evaluation/Rewards Min         0.4876798235812408
evaluation/Returns Mean        479.8735530781578
evaluation/Returns Std         1.2456477924629794
evaluation/Returns Max         481.6488439308254
evaluation/Returns Min         478.1816329302446
evaluation/ExplReturns Mean    479.8735530781578
evaluation/ExplReturns Std     1.2456477924629794
evaluation/ExplReturns Max     481.6488439308254
evaluation/ExplReturns Min     478.1816329302446
evaluation/Actions Mean        0.17126158
evaluation/Actions Std         0.5588298
evaluation/Actions Max         0.9989744
evaluation/Actions Min         -0.99997944
evaluation/Num Paths           10
evaluation/Average Returns     479.8735530781578
time/data storing (s)          0.03177190572023392
time/evaluation sampling (s)   112.23527091927826
time/exploration sampling (s)  113.35410660970956
time/logging (s)               0.030496628023684025
time/saving (s)                0.012759235687553883
time/training (s)              9.350774577818811
time/epoch (s)                 235.0151798762381
time/total (s)                 128191.53973794356
Epoch                          546
-----------------------------  ---------------------
2023-08-02 05:34:38.190273 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 547 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3643.2463]
trainer/QF1 Loss               0.019322067
trainer/QF2 Loss               0.015451358
trainer/Policy Loss            -92.50725
trainer/Q1 Predictions Mean    103.71355
trainer/Q1 Predictions Std     1.4327348
trainer/Q1 Predictions Max     106.49731
trainer/Q1 Predictions Min     92.9007
trainer/Q2 Predictions Mean    103.773056
trainer/Q2 Predictions Std     1.4094924
trainer/Q2 Predictions Max     106.379555
trainer/Q2 Predictions Min     92.452126
trainer/Q Targets Mean         103.738815
trainer/Q Targets Std          1.3874955
trainer/Q Targets Max          106.483
trainer/Q Targets Min          92.76869
trainer/Log Pis Mean           11.304337
trainer/Log Pis Std            7.6811833
trainer/Log Pis Max            46.694653
trainer/Log Pis Min            -6.29694
trainer/Policy mu Mean         -0.091716856
trainer/Policy mu Std          1.5387874
trainer/Policy mu Max          5.728856
trainer/Policy mu Min          -4.5782647
trainer/Policy log std Mean    -0.7833665
trainer/Policy log std Std     0.30522093
trainer/Policy log std Max     -0.039643645
trainer/Policy log std Min     -2.0903902
trainer/Alpha                  0.0015295817283913493
trainer/Alpha Loss             -4.5097479820251465
exploration/num steps total    2741000
exploration/num paths total    5482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.956748324337588
exploration/Rewards Std        0.050577633851347344
exploration/Rewards Max        0.979609779532034
exploration/Rewards Min        0.4919060467946865
exploration/Returns Mean       478.3741621687941
exploration/Returns Std        0.5842451520395308
exploration/Returns Max        479.37266911380885
exploration/Returns Min        477.55152025447836
exploration/Actions Mean       0.07678548
exploration/Actions Std        0.6018994
exploration/Actions Max        0.99985415
exploration/Actions Min        -0.99999547
exploration/Num Paths          10
exploration/Average Returns    478.3741621687941
evaluation/num steps total     2740000
evaluation/num paths total     5480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9632906440205281
evaluation/Rewards Std         0.051780897406438854
evaluation/Rewards Max         0.9796323640708424
evaluation/Rewards Min         0.49648342249536087
evaluation/Returns Mean        481.64532201026395
evaluation/Returns Std         1.550432113537097
evaluation/Returns Max         484.2408804547618
evaluation/Returns Min         479.71547224190164
evaluation/ExplReturns Mean    481.64532201026395
evaluation/ExplReturns Std     1.550432113537097
evaluation/ExplReturns Max     484.2408804547618
evaluation/ExplReturns Min     479.71547224190164
evaluation/Actions Mean        0.061495047
evaluation/Actions Std         0.54146665
evaluation/Actions Max         0.99844384
evaluation/Actions Min         -0.9997049
evaluation/Num Paths           10
evaluation/Average Returns     481.64532201026395
time/data storing (s)          0.03254504408687353
time/evaluation sampling (s)   113.02668176684529
time/exploration sampling (s)  114.40794384852052
time/logging (s)               0.03051628638058901
time/saving (s)                0.010792825371026993
time/training (s)              9.69974663015455
time/epoch (s)                 237.20822640135884
time/total (s)                 128428.750623893
Epoch                          547
-----------------------------  ---------------------
2023-08-02 05:38:36.057931 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 548 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3848.848]
trainer/QF1 Loss               0.01961222
trainer/QF2 Loss               0.028602634
trainer/Policy Loss            -92.20987
trainer/Q1 Predictions Mean    103.5284
trainer/Q1 Predictions Std     2.7957668
trainer/Q1 Predictions Max     105.751724
trainer/Q1 Predictions Min     66.88462
trainer/Q2 Predictions Mean    103.58498
trainer/Q2 Predictions Std     2.7691138
trainer/Q2 Predictions Max     105.90557
trainer/Q2 Predictions Min     67.41049
trainer/Q Targets Mean         103.539055
trainer/Q Targets Std          2.7820125
trainer/Q Targets Max          105.74768
trainer/Q Targets Min          66.614876
trainer/Log Pis Mean           11.438767
trainer/Log Pis Std            7.5135436
trainer/Log Pis Max            68.362274
trainer/Log Pis Min            -7.421833
trainer/Policy mu Mean         -0.08213145
trainer/Policy mu Std          1.6290841
trainer/Policy mu Max          18.704853
trainer/Policy mu Min          -12.697889
trainer/Policy log std Mean    -0.7758202
trainer/Policy log std Std     0.31879577
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.1114008
trainer/Alpha                  0.0015641899080947042
trainer/Alpha Loss             -3.625772476196289
exploration/num steps total    2746000
exploration/num paths total    5492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9594906053346007
exploration/Rewards Std        0.05197485281414969
exploration/Rewards Max        0.97957259471443
exploration/Rewards Min        0.4737122558869718
exploration/Returns Mean       479.74530266730045
exploration/Returns Std        0.4824022553417775
exploration/Returns Max        480.46341384122655
exploration/Returns Min        479.1005287783005
exploration/Actions Mean       0.030218937
exploration/Actions Std        0.66005147
exploration/Actions Max        0.99986744
exploration/Actions Min        -0.9999914
exploration/Num Paths          10
exploration/Average Returns    479.74530266730045
evaluation/num steps total     2745000
evaluation/num paths total     5490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9650368019330235
evaluation/Rewards Std         0.05166565390225867
evaluation/Rewards Max         0.9787493647305784
evaluation/Rewards Min         0.4969483977095017
evaluation/Returns Mean        482.5184009665119
evaluation/Returns Std         0.8228418671052109
evaluation/Returns Max         483.94664971211824
evaluation/Returns Min         481.2803860699496
evaluation/ExplReturns Mean    482.5184009665119
evaluation/ExplReturns Std     0.8228418671052109
evaluation/ExplReturns Max     483.94664971211824
evaluation/ExplReturns Min     481.2803860699496
evaluation/Actions Mean        0.011725165
evaluation/Actions Std         0.58770776
evaluation/Actions Max         0.9989122
evaluation/Actions Min         -0.99969137
evaluation/Num Paths           10
evaluation/Average Returns     482.5184009665119
time/data storing (s)          0.03184804040938616
time/evaluation sampling (s)   113.41260153893381
time/exploration sampling (s)  114.98237802926451
time/logging (s)               0.030935966409742832
time/saving (s)                0.010403749532997608
time/training (s)              9.392988622188568
time/epoch (s)                 237.86115594673902
time/total (s)                 128666.6142549282
Epoch                          548
-----------------------------  ---------------------
2023-08-02 05:42:33.847490 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 549 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3708.638]
trainer/QF1 Loss               0.021832835
trainer/QF2 Loss               0.035259493
trainer/Policy Loss            -91.1725
trainer/Q1 Predictions Mean    103.56694
trainer/Q1 Predictions Std     1.5503985
trainer/Q1 Predictions Max     105.94345
trainer/Q1 Predictions Min     84.551216
trainer/Q2 Predictions Mean    103.643875
trainer/Q2 Predictions Std     1.5650023
trainer/Q2 Predictions Max     106.07943
trainer/Q2 Predictions Min     84.28047
trainer/Q Targets Mean         103.539276
trainer/Q Targets Std          1.5142261
trainer/Q Targets Max          105.945404
trainer/Q Targets Min          85.26652
trainer/Log Pis Mean           12.490093
trainer/Log Pis Std            7.4595485
trainer/Log Pis Max            48.81933
trainer/Log Pis Min            -3.8171172
trainer/Policy mu Mean         -0.06053775
trainer/Policy mu Std          1.6023672
trainer/Policy mu Max          5.2532244
trainer/Policy mu Min          -7.4709945
trainer/Policy log std Mean    -0.7604006
trainer/Policy log std Std     0.29404107
trainer/Policy log std Max     0.60726917
trainer/Policy log std Min     -2.572918
trainer/Alpha                  0.001498197903856635
trainer/Alpha Loss             3.1873552799224854
exploration/num steps total    2751000
exploration/num paths total    5502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9570271171223603
exploration/Rewards Std        0.05061231954690272
exploration/Rewards Max        0.979018879938987
exploration/Rewards Min        0.4928753977572988
exploration/Returns Mean       478.51355856118005
exploration/Returns Std        0.8459240639578954
exploration/Returns Max        480.27527157270293
exploration/Returns Min        476.99166012712465
exploration/Actions Mean       0.039704144
exploration/Actions Std        0.6209836
exploration/Actions Max        0.9994538
exploration/Actions Min        -0.9999724
exploration/Num Paths          10
exploration/Average Returns    478.51355856118005
evaluation/num steps total     2750000
evaluation/num paths total     5500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9534840453853203
evaluation/Rewards Std         0.049514619444663274
evaluation/Rewards Max         0.9749148926582679
evaluation/Rewards Min         0.4939187205810631
evaluation/Returns Mean        476.74202269266004
evaluation/Returns Std         2.7338596908415793
evaluation/Returns Max         479.5345120653517
evaluation/Returns Min         472.43562900892607
evaluation/ExplReturns Mean    476.74202269266004
evaluation/ExplReturns Std     2.7338596908415793
evaluation/ExplReturns Max     479.5345120653517
evaluation/ExplReturns Min     472.43562900892607
evaluation/Actions Mean        -0.037244104
evaluation/Actions Std         0.5762433
evaluation/Actions Max         0.99827814
evaluation/Actions Min         -0.9997019
evaluation/Num Paths           10
evaluation/Average Returns     476.74202269266004
time/data storing (s)          0.03217968437820673
time/evaluation sampling (s)   113.22714550141245
time/exploration sampling (s)  115.17654017172754
time/logging (s)               0.030762389302253723
time/saving (s)                0.01270019356161356
time/training (s)              9.303136329166591
time/epoch (s)                 237.78246426954865
time/total (s)                 128904.39921089634
Epoch                          549
-----------------------------  --------------------
2023-08-02 05:46:31.773128 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 550 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3898.595]
trainer/QF1 Loss               0.032049432
trainer/QF2 Loss               0.02840757
trainer/Policy Loss            -92.68153
trainer/Q1 Predictions Mean    103.585495
trainer/Q1 Predictions Std     1.0892386
trainer/Q1 Predictions Max     105.74037
trainer/Q1 Predictions Min     95.16527
trainer/Q2 Predictions Mean    103.587975
trainer/Q2 Predictions Std     1.0994905
trainer/Q2 Predictions Max     105.63459
trainer/Q2 Predictions Min     94.986725
trainer/Q Targets Mean         103.62599
trainer/Q Targets Std          1.1655796
trainer/Q Targets Max          105.727715
trainer/Q Targets Min          93.28444
trainer/Log Pis Mean           10.980738
trainer/Log Pis Std            6.9866376
trainer/Log Pis Max            46.445675
trainer/Log Pis Min            -3.8119125
trainer/Policy mu Mean         0.006217266
trainer/Policy mu Std          1.509544
trainer/Policy mu Max          5.3374214
trainer/Policy mu Min          -5.123822
trainer/Policy log std Mean    -0.7670841
trainer/Policy log std Std     0.29157338
trainer/Policy log std Max     0.26890814
trainer/Policy log std Min     -1.9248859
trainer/Alpha                  0.0014888520818203688
trainer/Alpha Loss             -6.635056972503662
exploration/num steps total    2756000
exploration/num paths total    5512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.960440907165114
exploration/Rewards Std        0.04779124863394749
exploration/Rewards Max        0.9793683473129118
exploration/Rewards Min        0.4984952687028157
exploration/Returns Mean       480.22045358255684
exploration/Returns Std        0.8447276626406044
exploration/Returns Max        481.95441838182956
exploration/Returns Min        479.33864015830204
exploration/Actions Mean       0.07312529
exploration/Actions Std        0.5992844
exploration/Actions Max        0.9999433
exploration/Actions Min        -0.999848
exploration/Num Paths          10
exploration/Average Returns    480.22045358255684
evaluation/num steps total     2755000
evaluation/num paths total     5510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9604527332972707
evaluation/Rewards Std         0.04810650632132246
evaluation/Rewards Max         0.9774444181575932
evaluation/Rewards Min         0.48906752458940006
evaluation/Returns Mean        480.22636664863523
evaluation/Returns Std         1.4163406581853368
evaluation/Returns Max         482.57102476600585
evaluation/Returns Min         478.874351710071
evaluation/ExplReturns Mean    480.22636664863523
evaluation/ExplReturns Std     1.4163406581853368
evaluation/ExplReturns Max     482.57102476600585
evaluation/ExplReturns Min     478.874351710071
evaluation/Actions Mean        0.074194066
evaluation/Actions Std         0.526165
evaluation/Actions Max         0.99883115
evaluation/Actions Min         -0.9991065
evaluation/Num Paths           10
evaluation/Average Returns     480.22636664863523
time/data storing (s)          0.03229112084954977
time/evaluation sampling (s)   113.86209060903639
time/exploration sampling (s)  113.9759364342317
time/logging (s)               0.031201730482280254
time/saving (s)                0.010477918200194836
time/training (s)              10.007049936801195
time/epoch (s)                 237.9190477496013
time/total (s)                 129142.32076580077
Epoch                          550
-----------------------------  ---------------------
2023-08-02 05:50:27.272961 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 551 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3414.422]
trainer/QF1 Loss               0.01254319
trainer/QF2 Loss               0.024371276
trainer/Policy Loss            -92.40144
trainer/Q1 Predictions Mean    103.54236
trainer/Q1 Predictions Std     1.3604927
trainer/Q1 Predictions Max     105.5051
trainer/Q1 Predictions Min     90.91502
trainer/Q2 Predictions Mean    103.464096
trainer/Q2 Predictions Std     1.3781998
trainer/Q2 Predictions Max     105.38633
trainer/Q2 Predictions Min     90.63977
trainer/Q Targets Mean         103.55762
trainer/Q Targets Std          1.3464491
trainer/Q Targets Max          105.37258
trainer/Q Targets Min          91.14224
trainer/Log Pis Mean           11.185764
trainer/Log Pis Std            7.063539
trainer/Log Pis Max            38.733707
trainer/Log Pis Min            -1.88409
trainer/Policy mu Mean         -0.12221708
trainer/Policy mu Std          1.5331956
trainer/Policy mu Max          6.8581
trainer/Policy mu Min          -4.4519777
trainer/Policy log std Mean    -0.7476317
trainer/Policy log std Std     0.28847152
trainer/Policy log std Max     0.2107535
trainer/Policy log std Min     -1.8541496
trainer/Alpha                  0.001525817671790719
trainer/Alpha Loss             -5.28043270111084
exploration/num steps total    2761000
exploration/num paths total    5522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9486653804319721
exploration/Rewards Std        0.06199915458724339
exploration/Rewards Max        0.9790905932365348
exploration/Rewards Min        0.4902406865672374
exploration/Returns Mean       474.33269021598625
exploration/Returns Std        4.206884278103278
exploration/Returns Max        480.55706685791154
exploration/Returns Min        467.91938888938665
exploration/Actions Mean       0.07497084
exploration/Actions Std        0.6207829
exploration/Actions Max        0.999958
exploration/Actions Min        -0.9999889
exploration/Num Paths          10
exploration/Average Returns    474.33269021598625
evaluation/num steps total     2760000
evaluation/num paths total     5520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9576365412101205
evaluation/Rewards Std         0.05622755709770571
evaluation/Rewards Max         0.9786523190877615
evaluation/Rewards Min         0.4946845076764289
evaluation/Returns Mean        478.8182706050604
evaluation/Returns Std         4.6694588404865085
evaluation/Returns Max         483.52687071204446
evaluation/Returns Min         470.1688792571738
evaluation/ExplReturns Mean    478.8182706050604
evaluation/ExplReturns Std     4.6694588404865085
evaluation/ExplReturns Max     483.52687071204446
evaluation/ExplReturns Min     470.1688792571738
evaluation/Actions Mean        0.114387594
evaluation/Actions Std         0.5092776
evaluation/Actions Max         0.9996632
evaluation/Actions Min         -0.99994427
evaluation/Num Paths           10
evaluation/Average Returns     478.8182706050604
time/data storing (s)          0.031701006926596165
time/evaluation sampling (s)   112.3819155851379
time/exploration sampling (s)  113.5306325731799
time/logging (s)               0.030850152485072613
time/saving (s)                0.010455138981342316
time/training (s)              9.506942831911147
time/epoch (s)                 235.49249728862196
time/total (s)                 129377.81575002335
Epoch                          551
-----------------------------  --------------------
2023-08-02 05:54:22.663318 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 552 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3832.951]
trainer/QF1 Loss               0.021593843
trainer/QF2 Loss               0.027989767
trainer/Policy Loss            -91.50342
trainer/Q1 Predictions Mean    103.207214
trainer/Q1 Predictions Std     2.20002
trainer/Q1 Predictions Max     105.43526
trainer/Q1 Predictions Min     87.466515
trainer/Q2 Predictions Mean    103.28488
trainer/Q2 Predictions Std     2.1760523
trainer/Q2 Predictions Max     105.46763
trainer/Q2 Predictions Min     87.87241
trainer/Q Targets Mean         103.27122
trainer/Q Targets Std          2.2028048
trainer/Q Targets Max          105.507225
trainer/Q Targets Min          87.72375
trainer/Log Pis Mean           11.822622
trainer/Log Pis Std            8.912744
trainer/Log Pis Max            56.802628
trainer/Log Pis Min            -9.869507
trainer/Policy mu Mean         -0.07436519
trainer/Policy mu Std          1.5957431
trainer/Policy mu Max          7.3285017
trainer/Policy mu Min          -9.358517
trainer/Policy log std Mean    -0.75429755
trainer/Policy log std Std     0.29610103
trainer/Policy log std Max     0.35453033
trainer/Policy log std Min     -2.0984843
trainer/Alpha                  0.001486565568484366
trainer/Alpha Loss             -1.15492844581604
exploration/num steps total    2766000
exploration/num paths total    5532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9549532565082663
exploration/Rewards Std        0.05150657742551559
exploration/Rewards Max        0.9776757769009738
exploration/Rewards Min        0.5022859849071718
exploration/Returns Mean       477.4766282541332
exploration/Returns Std        0.8032163266767438
exploration/Returns Max        478.97525017250393
exploration/Returns Min        476.25558825503066
exploration/Actions Mean       0.066551566
exploration/Actions Std        0.5969563
exploration/Actions Max        0.9997854
exploration/Actions Min        -0.9999558
exploration/Num Paths          10
exploration/Average Returns    477.4766282541332
evaluation/num steps total     2765000
evaluation/num paths total     5530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9539431939326054
evaluation/Rewards Std         0.047529868635071235
evaluation/Rewards Max         0.9749111992325477
evaluation/Rewards Min         0.4931419688213807
evaluation/Returns Mean        476.9715969663026
evaluation/Returns Std         0.5459706738353428
evaluation/Returns Max         477.6383629291875
evaluation/Returns Min         475.9683470989086
evaluation/ExplReturns Mean    476.9715969663026
evaluation/ExplReturns Std     0.5459706738353428
evaluation/ExplReturns Max     477.6383629291875
evaluation/ExplReturns Min     475.9683470989086
evaluation/Actions Mean        0.07636844
evaluation/Actions Std         0.48806345
evaluation/Actions Max         0.9966811
evaluation/Actions Min         -0.9996686
evaluation/Num Paths           10
evaluation/Average Returns     476.9715969663026
time/data storing (s)          0.03240043297410011
time/evaluation sampling (s)   112.80973526649177
time/exploration sampling (s)  113.24316799268126
time/logging (s)               0.030375219881534576
time/saving (s)                0.01053003128618002
time/training (s)              9.256672482006252
time/epoch (s)                 235.3828814253211
time/total (s)                 129613.20118420105
Epoch                          552
-----------------------------  --------------------
2023-08-02 05:58:19.784866 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 553 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3624.9744]
trainer/QF1 Loss               0.031944435
trainer/QF2 Loss               0.024340928
trainer/Policy Loss            -90.52949
trainer/Q1 Predictions Mean    103.08957
trainer/Q1 Predictions Std     1.7271552
trainer/Q1 Predictions Max     104.76836
trainer/Q1 Predictions Min     85.334045
trainer/Q2 Predictions Mean    103.11629
trainer/Q2 Predictions Std     1.764388
trainer/Q2 Predictions Max     104.86447
trainer/Q2 Predictions Min     84.837944
trainer/Q Targets Mean         103.17135
trainer/Q Targets Std          1.7984772
trainer/Q Targets Max          104.89386
trainer/Q Targets Min          84.19505
trainer/Log Pis Mean           12.661287
trainer/Log Pis Std            8.34609
trainer/Log Pis Max            44.36512
trainer/Log Pis Min            -4.333372
trainer/Policy mu Mean         0.057123158
trainer/Policy mu Std          1.6139249
trainer/Policy mu Max          4.363971
trainer/Policy mu Min          -5.953094
trainer/Policy log std Mean    -0.7769584
trainer/Policy log std Std     0.2930342
trainer/Policy log std Max     0.15541804
trainer/Policy log std Min     -2.1249027
trainer/Alpha                  0.001495109754614532
trainer/Alpha Loss             4.30217981338501
exploration/num steps total    2771000
exploration/num paths total    5542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9573205042869615
exploration/Rewards Std        0.05035085576866425
exploration/Rewards Max        0.9785369752418888
exploration/Rewards Min        0.4986569827292304
exploration/Returns Mean       478.66025214348076
exploration/Returns Std        1.541877923732022
exploration/Returns Max        481.49627764652246
exploration/Returns Min        475.8088012240323
exploration/Actions Mean       0.10997174
exploration/Actions Std        0.6718612
exploration/Actions Max        0.999868
exploration/Actions Min        -0.99991804
exploration/Num Paths          10
exploration/Average Returns    478.66025214348076
evaluation/num steps total     2770000
evaluation/num paths total     5540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9541087832228176
evaluation/Rewards Std         0.05665759184261482
evaluation/Rewards Max         0.9780765340675752
evaluation/Rewards Min         0.4930703780602581
evaluation/Returns Mean        477.05439161140896
evaluation/Returns Std         5.919695976330483
evaluation/Returns Max         482.33359194725676
evaluation/Returns Min         461.83438959974484
evaluation/ExplReturns Mean    477.05439161140896
evaluation/ExplReturns Std     5.919695976330483
evaluation/ExplReturns Max     482.33359194725676
evaluation/ExplReturns Min     461.83438959974484
evaluation/Actions Mean        0.09496199
evaluation/Actions Std         0.6017828
evaluation/Actions Max         0.99998355
evaluation/Actions Min         -0.99948204
evaluation/Num Paths           10
evaluation/Average Returns     477.05439161140896
time/data storing (s)          0.032045451924204826
time/evaluation sampling (s)   112.59905430767685
time/exploration sampling (s)  114.9421078870073
time/logging (s)               0.030408628284931183
time/saving (s)                0.011240414343774319
time/training (s)              9.499770449474454
time/epoch (s)                 237.1146271387115
time/total (s)                 129850.31829540338
Epoch                          553
-----------------------------  --------------------
2023-08-02 06:02:16.168402 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 554 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4416.23]
trainer/QF1 Loss               0.024641663
trainer/QF2 Loss               0.045204878
trainer/Policy Loss            -91.78618
trainer/Q1 Predictions Mean    103.26712
trainer/Q1 Predictions Std     1.5566692
trainer/Q1 Predictions Max     104.75767
trainer/Q1 Predictions Min     90.384346
trainer/Q2 Predictions Mean    103.12508
trainer/Q2 Predictions Std     1.5437053
trainer/Q2 Predictions Max     104.64932
trainer/Q2 Predictions Min     90.380806
trainer/Q Targets Mean         103.27281
trainer/Q Targets Std          1.5605437
trainer/Q Targets Max          104.814865
trainer/Q Targets Min          90.84072
trainer/Log Pis Mean           11.459242
trainer/Log Pis Std            7.7747254
trainer/Log Pis Max            43.113262
trainer/Log Pis Min            -3.1780553
trainer/Policy mu Mean         -0.050118614
trainer/Policy mu Std          1.5678685
trainer/Policy mu Max          5.299174
trainer/Policy mu Min          -7.0226803
trainer/Policy log std Mean    -0.7411456
trainer/Policy log std Std     0.29820713
trainer/Policy log std Max     0.120153725
trainer/Policy log std Min     -2.1223264
trainer/Alpha                  0.0014607443008571863
trainer/Alpha Loss             -3.530421018600464
exploration/num steps total    2776000
exploration/num paths total    5552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9534589501024388
exploration/Rewards Std        0.06191448008523528
exploration/Rewards Max        0.9787101444385204
exploration/Rewards Min        0.4988353335434562
exploration/Returns Mean       476.72947505121937
exploration/Returns Std        8.655754720509929
exploration/Returns Max        481.8570836402672
exploration/Returns Min        451.79902607544847
exploration/Actions Mean       0.010096911
exploration/Actions Std        0.6418197
exploration/Actions Max        0.9998728
exploration/Actions Min        -0.9999458
exploration/Num Paths          10
exploration/Average Returns    476.72947505121937
evaluation/num steps total     2775000
evaluation/num paths total     5550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9535095126236314
evaluation/Rewards Std         0.05212736148125922
evaluation/Rewards Max         0.9798121389663493
evaluation/Rewards Min         0.491584538778929
evaluation/Returns Mean        476.7547563118157
evaluation/Returns Std         2.5101268465382196
evaluation/Returns Max         478.5266661990607
evaluation/Returns Min         471.0766065426036
evaluation/ExplReturns Mean    476.7547563118157
evaluation/ExplReturns Std     2.5101268465382196
evaluation/ExplReturns Max     478.5266661990607
evaluation/ExplReturns Min     471.0766065426036
evaluation/Actions Mean        -0.006189755
evaluation/Actions Std         0.6169251
evaluation/Actions Max         0.99969095
evaluation/Actions Min         -0.99989617
evaluation/Num Paths           10
evaluation/Average Returns     476.7547563118157
time/data storing (s)          0.032235932536423206
time/evaluation sampling (s)   111.84791430085897
time/exploration sampling (s)  114.82022824604064
time/logging (s)               0.03117276541888714
time/saving (s)                0.01264149695634842
time/training (s)              9.633086008019745
time/epoch (s)                 236.37727874983102
time/total (s)                 130086.69808303006
Epoch                          554
-----------------------------  ---------------------
2023-08-02 06:06:11.829390 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 555 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3504.3618]
trainer/QF1 Loss               0.024990251
trainer/QF2 Loss               0.042030096
trainer/Policy Loss            -90.78418
trainer/Q1 Predictions Mean    103.14668
trainer/Q1 Predictions Std     1.919122
trainer/Q1 Predictions Max     104.973015
trainer/Q1 Predictions Min     89.80285
trainer/Q2 Predictions Mean    103.176636
trainer/Q2 Predictions Std     1.9671528
trainer/Q2 Predictions Max     105.04538
trainer/Q2 Predictions Min     89.54432
trainer/Q Targets Mean         103.06645
trainer/Q Targets Std          1.9373237
trainer/Q Targets Max          104.94449
trainer/Q Targets Min          89.70188
trainer/Log Pis Mean           12.449786
trainer/Log Pis Std            8.31983
trainer/Log Pis Max            48.824677
trainer/Log Pis Min            -2.7546985
trainer/Policy mu Mean         -0.07851422
trainer/Policy mu Std          1.6057755
trainer/Policy mu Max          7.198106
trainer/Policy mu Min          -7.23985
trainer/Policy log std Mean    -0.80326414
trainer/Policy log std Std     0.302421
trainer/Policy log std Max     0.5838913
trainer/Policy log std Min     -2.0746684
trainer/Alpha                  0.0014011376770213246
trainer/Alpha Loss             2.955385208129883
exploration/num steps total    2781000
exploration/num paths total    5562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9592306735803935
exploration/Rewards Std        0.04869312021701273
exploration/Rewards Max        0.9793194453142352
exploration/Rewards Min        0.4966458807088765
exploration/Returns Mean       479.6153367901967
exploration/Returns Std        0.9675074876349332
exploration/Returns Max        480.86596172070006
exploration/Returns Min        477.7586231242343
exploration/Actions Mean       -0.0051531796
exploration/Actions Std        0.5577882
exploration/Actions Max        0.9999497
exploration/Actions Min        -0.9999946
exploration/Num Paths          10
exploration/Average Returns    479.6153367901967
evaluation/num steps total     2780000
evaluation/num paths total     5560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9585407386167848
evaluation/Rewards Std         0.04725929372392248
evaluation/Rewards Max         0.9793671330091165
evaluation/Rewards Min         0.5007988708413216
evaluation/Returns Mean        479.2703693083924
evaluation/Returns Std         0.6645045649623437
evaluation/Returns Max         480.48554887340305
evaluation/Returns Min         478.13951925021433
evaluation/ExplReturns Mean    479.2703693083924
evaluation/ExplReturns Std     0.6645045649623437
evaluation/ExplReturns Max     480.48554887340305
evaluation/ExplReturns Min     478.13951925021433
evaluation/Actions Mean        0.0009655099
evaluation/Actions Std         0.42250755
evaluation/Actions Max         0.9996704
evaluation/Actions Min         -0.99991804
evaluation/Num Paths           10
evaluation/Average Returns     479.2703693083924
time/data storing (s)          0.03160218708217144
time/evaluation sampling (s)   113.71902863774449
time/exploration sampling (s)  112.18627823889256
time/logging (s)               0.03069022949784994
time/saving (s)                0.01288196723908186
time/training (s)              9.672991510480642
time/epoch (s)                 235.6534727709368
time/total (s)                 130322.35405873787
Epoch                          555
-----------------------------  ---------------------
2023-08-02 06:10:08.727073 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 556 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3690.2786]
trainer/QF1 Loss               0.033572838
trainer/QF2 Loss               0.03286421
trainer/Policy Loss            -91.47972
trainer/Q1 Predictions Mean    103.065674
trainer/Q1 Predictions Std     1.92275
trainer/Q1 Predictions Max     105.077736
trainer/Q1 Predictions Min     87.46215
trainer/Q2 Predictions Mean    103.22148
trainer/Q2 Predictions Std     1.9558097
trainer/Q2 Predictions Max     105.34776
trainer/Q2 Predictions Min     86.696175
trainer/Q Targets Mean         103.15597
trainer/Q Targets Std          1.962927
trainer/Q Targets Max          105.13975
trainer/Q Targets Min          87.65386
trainer/Log Pis Mean           11.708458
trainer/Log Pis Std            8.183297
trainer/Log Pis Max            45.452606
trainer/Log Pis Min            -3.2451696
trainer/Policy mu Mean         0.008947764
trainer/Policy mu Std          1.5504054
trainer/Policy mu Max          5.1592994
trainer/Policy mu Min          -5.2641716
trainer/Policy log std Mean    -0.76352483
trainer/Policy log std Std     0.30252966
trainer/Policy log std Max     0.10035363
trainer/Policy log std Min     -2.2106159
trainer/Alpha                  0.0013882099883630872
trainer/Alpha Loss             -1.918210506439209
exploration/num steps total    2786000
exploration/num paths total    5572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9674339967674106
exploration/Rewards Std        0.04850604830927353
exploration/Rewards Max        0.9800073972560878
exploration/Rewards Min        0.49433080831054177
exploration/Returns Mean       483.7169983837055
exploration/Returns Std        0.5048544808868385
exploration/Returns Max        484.35504043708283
exploration/Returns Min        482.5350064963016
exploration/Actions Mean       -0.067263186
exploration/Actions Std        0.58267033
exploration/Actions Max        0.99993104
exploration/Actions Min        -0.99986213
exploration/Num Paths          10
exploration/Average Returns    483.7169983837055
evaluation/num steps total     2785000
evaluation/num paths total     5570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9644982709790023
evaluation/Rewards Std         0.04916950666431468
evaluation/Rewards Max         0.9796865743736629
evaluation/Rewards Min         0.48919540328994887
evaluation/Returns Mean        482.249135489501
evaluation/Returns Std         0.8741698517571552
evaluation/Returns Max         483.3041917213941
evaluation/Returns Min         480.9414814747328
evaluation/ExplReturns Mean    482.249135489501
evaluation/ExplReturns Std     0.8741698517571552
evaluation/ExplReturns Max     483.3041917213941
evaluation/ExplReturns Min     480.9414814747328
evaluation/Actions Mean        -0.03848283
evaluation/Actions Std         0.45864785
evaluation/Actions Max         0.99899256
evaluation/Actions Min         -0.99943453
evaluation/Num Paths           10
evaluation/Average Returns     482.249135489501
time/data storing (s)          0.032010446302592754
time/evaluation sampling (s)   113.0396081507206
time/exploration sampling (s)  114.0329739768058
time/logging (s)               0.033657314255833626
time/saving (s)                0.012026818469166756
time/training (s)              9.743330478668213
time/epoch (s)                 236.8936071852222
time/total (s)                 130559.25022096932
Epoch                          556
-----------------------------  ---------------------
2023-08-02 06:14:07.231012 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 557 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3885.9514]
trainer/QF1 Loss               0.025694288
trainer/QF2 Loss               0.02670702
trainer/Policy Loss            -91.32315
trainer/Q1 Predictions Mean    103.05705
trainer/Q1 Predictions Std     1.4974266
trainer/Q1 Predictions Max     106.03674
trainer/Q1 Predictions Min     90.9635
trainer/Q2 Predictions Mean    103.17428
trainer/Q2 Predictions Std     1.5130906
trainer/Q2 Predictions Max     106.15481
trainer/Q2 Predictions Min     91.29756
trainer/Q Targets Mean         103.09341
trainer/Q Targets Std          1.5889044
trainer/Q Targets Max          106.10731
trainer/Q Targets Min          90.3236
trainer/Log Pis Mean           11.844162
trainer/Log Pis Std            7.737173
trainer/Log Pis Max            43.094196
trainer/Log Pis Min            -6.6760845
trainer/Policy mu Mean         -0.09662505
trainer/Policy mu Std          1.573984
trainer/Policy mu Max          5.526194
trainer/Policy mu Min          -6.3103023
trainer/Policy log std Mean    -0.7731745
trainer/Policy log std Std     0.2810114
trainer/Policy log std Max     -0.025782883
trainer/Policy log std Min     -1.9868913
trainer/Alpha                  0.0014212545938789845
trainer/Alpha Loss             -1.0217036008834839
exploration/num steps total    2791000
exploration/num paths total    5582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9364499385310155
exploration/Rewards Std        0.08466149046493074
exploration/Rewards Max        0.9786507357784369
exploration/Rewards Min        0.4872323501528878
exploration/Returns Mean       468.2249692655076
exploration/Returns Std        13.331378385385502
exploration/Returns Max        481.5226682955185
exploration/Returns Min        431.10729857828125
exploration/Actions Mean       -0.04029703
exploration/Actions Std        0.6202986
exploration/Actions Max        0.9999998
exploration/Actions Min        -0.99999946
exploration/Num Paths          10
exploration/Average Returns    468.2249692655076
evaluation/num steps total     2790000
evaluation/num paths total     5580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8378898324874783
evaluation/Rewards Std         0.12296371211293766
evaluation/Rewards Max         0.9754172719627597
evaluation/Rewards Min         0.4960356986287548
evaluation/Returns Mean        418.94491624373916
evaluation/Returns Std         52.67103011916376
evaluation/Returns Max         473.3577008987993
evaluation/Returns Min         365.15177208928117
evaluation/ExplReturns Mean    418.94491624373916
evaluation/ExplReturns Std     52.67103011916376
evaluation/ExplReturns Max     473.3577008987993
evaluation/ExplReturns Min     365.15177208928117
evaluation/Actions Mean        -0.13381074
evaluation/Actions Std         0.5588928
evaluation/Actions Max         0.9999999
evaluation/Actions Min         -0.9999893
evaluation/Num Paths           10
evaluation/Average Returns     418.94491624373916
time/data storing (s)          0.03218550607562065
time/evaluation sampling (s)   113.59597420413047
time/exploration sampling (s)  114.53531188704073
time/logging (s)               0.03124091774225235
time/saving (s)                0.012879259884357452
time/training (s)              10.286735858768225
time/epoch (s)                 238.49432763364166
time/total (s)                 130797.74711622018
Epoch                          557
-----------------------------  ---------------------
2023-08-02 06:18:00.761552 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 558 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3760.8767]
trainer/QF1 Loss               0.014691789
trainer/QF2 Loss               0.025721507
trainer/Policy Loss            -91.85849
trainer/Q1 Predictions Mean    103.04794
trainer/Q1 Predictions Std     1.4337991
trainer/Q1 Predictions Max     104.57456
trainer/Q1 Predictions Min     93.16792
trainer/Q2 Predictions Mean    102.985245
trainer/Q2 Predictions Std     1.4184139
trainer/Q2 Predictions Max     104.51418
trainer/Q2 Predictions Min     93.0736
trainer/Q Targets Mean         103.033264
trainer/Q Targets Std          1.4385974
trainer/Q Targets Max          104.52392
trainer/Q Targets Min          93.107895
trainer/Log Pis Mean           11.216984
trainer/Log Pis Std            7.3096766
trainer/Log Pis Max            37.509907
trainer/Log Pis Min            -4.1830177
trainer/Policy mu Mean         0.03341626
trainer/Policy mu Std          1.562349
trainer/Policy mu Max          8.552597
trainer/Policy mu Min          -5.593938
trainer/Policy log std Mean    -0.7290682
trainer/Policy log std Std     0.28148347
trainer/Policy log std Max     0.85444653
trainer/Policy log std Min     -1.8730605
trainer/Alpha                  0.00141908077057451
trainer/Alpha Loss             -5.134810447692871
exploration/num steps total    2796000
exploration/num paths total    5592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9658830586097346
exploration/Rewards Std        0.046851975796929894
exploration/Rewards Max        0.9798103515591496
exploration/Rewards Min        0.49776194896623754
exploration/Returns Mean       482.9415293048672
exploration/Returns Std        0.7196122333809944
exploration/Returns Max        483.55136314849744
exploration/Returns Min        481.0897092379665
exploration/Actions Mean       -0.054440286
exploration/Actions Std        0.57738394
exploration/Actions Max        0.9999525
exploration/Actions Min        -0.99996114
exploration/Num Paths          10
exploration/Average Returns    482.9415293048672
evaluation/num steps total     2795000
evaluation/num paths total     5590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9672095413854087
evaluation/Rewards Std         0.04768497831835122
evaluation/Rewards Max         0.9788156202879329
evaluation/Rewards Min         0.4795315206334805
evaluation/Returns Mean        483.60477069270445
evaluation/Returns Std         0.3163964976272975
evaluation/Returns Max         484.05730701304327
evaluation/Returns Min         483.03892832577446
evaluation/ExplReturns Mean    483.60477069270445
evaluation/ExplReturns Std     0.3163964976272975
evaluation/ExplReturns Max     484.05730701304327
evaluation/ExplReturns Min     483.03892832577446
evaluation/Actions Mean        -0.07289373
evaluation/Actions Std         0.41658306
evaluation/Actions Max         0.99884886
evaluation/Actions Min         -0.99991596
evaluation/Num Paths           10
evaluation/Average Returns     483.60477069270445
time/data storing (s)          0.03209928050637245
time/evaluation sampling (s)   111.98485772125423
time/exploration sampling (s)  111.8616565586999
time/logging (s)               0.030929055996239185
time/saving (s)                0.011088376864790916
time/training (s)              9.602611374109983
time/epoch (s)                 233.52324236743152
time/total (s)                 131031.27282551397
Epoch                          558
-----------------------------  --------------------
2023-08-02 06:21:56.439677 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 559 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3705.0454]
trainer/QF1 Loss               0.020812482
trainer/QF2 Loss               0.013898481
trainer/Policy Loss            -90.959595
trainer/Q1 Predictions Mean    102.891945
trainer/Q1 Predictions Std     1.5920261
trainer/Q1 Predictions Max     105.015434
trainer/Q1 Predictions Min     89.56531
trainer/Q2 Predictions Mean    102.897705
trainer/Q2 Predictions Std     1.5807697
trainer/Q2 Predictions Max     105.00053
trainer/Q2 Predictions Min     90.02727
trainer/Q Targets Mean         102.89987
trainer/Q Targets Std          1.5840776
trainer/Q Targets Max          105.14073
trainer/Q Targets Min          90.15043
trainer/Log Pis Mean           12.012043
trainer/Log Pis Std            8.121766
trainer/Log Pis Max            60.348907
trainer/Log Pis Min            -4.045518
trainer/Policy mu Mean         0.16135071
trainer/Policy mu Std          1.577666
trainer/Policy mu Max          5.4409504
trainer/Policy mu Min          -6.441631
trainer/Policy log std Mean    -0.762531
trainer/Policy log std Std     0.28879178
trainer/Policy log std Max     0.16933626
trainer/Policy log std Min     -2.006209
trainer/Alpha                  0.001345993485301733
trainer/Alpha Loss             0.07961177825927734
exploration/num steps total    2801000
exploration/num paths total    5602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9638588429426047
exploration/Rewards Std        0.05040616213585002
exploration/Rewards Max        0.9795434092570869
exploration/Rewards Min        0.4873442161376505
exploration/Returns Mean       481.92942147130236
exploration/Returns Std        0.6856187688564093
exploration/Returns Max        483.2002966237413
exploration/Returns Min        480.85315871020043
exploration/Actions Mean       -0.033530384
exploration/Actions Std        0.5965218
exploration/Actions Max        0.9999437
exploration/Actions Min        -0.9999797
exploration/Num Paths          10
exploration/Average Returns    481.92942147130236
evaluation/num steps total     2800000
evaluation/num paths total     5600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9656919120532411
evaluation/Rewards Std         0.04916030283358308
evaluation/Rewards Max         0.9795368447701345
evaluation/Rewards Min         0.48923571859606474
evaluation/Returns Mean        482.84595602662046
evaluation/Returns Std         1.9791034001736096
evaluation/Returns Max         484.95815119814307
evaluation/Returns Min         477.859698384573
evaluation/ExplReturns Mean    482.84595602662046
evaluation/ExplReturns Std     1.9791034001736096
evaluation/ExplReturns Max     484.95815119814307
evaluation/ExplReturns Min     477.859698384573
evaluation/Actions Mean        -0.044293325
evaluation/Actions Std         0.51229984
evaluation/Actions Max         0.99871445
evaluation/Actions Min         -0.99966025
evaluation/Num Paths           10
evaluation/Average Returns     482.84595602662046
time/data storing (s)          0.032184033654630184
time/evaluation sampling (s)   112.39818396512419
time/exploration sampling (s)  113.58269486576319
time/logging (s)               0.030667202547192574
time/saving (s)                0.01048178132623434
time/training (s)              9.61670011933893
time/epoch (s)                 235.67091196775436
time/total (s)                 131266.9461858375
Epoch                          559
-----------------------------  --------------------
2023-08-02 06:25:50.657754 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 560 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3369.9182]
trainer/QF1 Loss               0.017387856
trainer/QF2 Loss               0.012095241
trainer/Policy Loss            -91.24135
trainer/Q1 Predictions Mean    103.00375
trainer/Q1 Predictions Std     1.2464561
trainer/Q1 Predictions Max     104.41224
trainer/Q1 Predictions Min     89.31102
trainer/Q2 Predictions Mean    102.942894
trainer/Q2 Predictions Std     1.2819047
trainer/Q2 Predictions Max     104.30508
trainer/Q2 Predictions Min     89.181076
trainer/Q Targets Mean         102.958725
trainer/Q Targets Std          1.2785275
trainer/Q Targets Max          104.40437
trainer/Q Targets Min          89.350746
trainer/Log Pis Mean           11.809509
trainer/Log Pis Std            7.5471473
trainer/Log Pis Max            39.838757
trainer/Log Pis Min            -5.0318356
trainer/Policy mu Mean         0.019529974
trainer/Policy mu Std          1.5684221
trainer/Policy mu Max          4.6019535
trainer/Policy mu Min          -6.7221375
trainer/Policy log std Mean    -0.75132996
trainer/Policy log std Std     0.29410055
trainer/Policy log std Max     0.36117452
trainer/Policy log std Min     -1.9965891
trainer/Alpha                  0.001309374114498496
trainer/Alpha Loss             -1.2645280361175537
exploration/num steps total    2806000
exploration/num paths total    5612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9612770403106559
exploration/Rewards Std        0.05032760223717008
exploration/Rewards Max        0.9796400995705918
exploration/Rewards Min        0.4831967736699057
exploration/Returns Mean       480.6385201553279
exploration/Returns Std        0.3862093464950828
exploration/Returns Max        481.19783528838127
exploration/Returns Min        480.14502152105183
exploration/Actions Mean       0.0120145185
exploration/Actions Std        0.6129303
exploration/Actions Max        0.99997693
exploration/Actions Min        -0.99999624
exploration/Num Paths          10
exploration/Average Returns    480.6385201553279
evaluation/num steps total     2805000
evaluation/num paths total     5610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9621413955804433
evaluation/Rewards Std         0.04944423090632756
evaluation/Rewards Max         0.9788901698810606
evaluation/Rewards Min         0.4987595828726982
evaluation/Returns Mean        481.0706977902216
evaluation/Returns Std         0.5521819388952821
evaluation/Returns Max         482.0451685880866
evaluation/Returns Min         480.21181938532106
evaluation/ExplReturns Mean    481.0706977902216
evaluation/ExplReturns Std     0.5521819388952821
evaluation/ExplReturns Max     482.0451685880866
evaluation/ExplReturns Min     480.21181938532106
evaluation/Actions Mean        -0.0027495425
evaluation/Actions Std         0.51014143
evaluation/Actions Max         0.99980515
evaluation/Actions Min         -0.9997298
evaluation/Num Paths           10
evaluation/Average Returns     481.0706977902216
time/data storing (s)          0.0323948971927166
time/evaluation sampling (s)   111.52350090816617
time/exploration sampling (s)  113.07964530028403
time/logging (s)               0.030615312978625298
time/saving (s)                0.010337783955037594
time/training (s)              9.53449633717537
time/epoch (s)                 234.21099053975195
time/total (s)                 131501.15968180262
Epoch                          560
-----------------------------  --------------------
2023-08-02 06:29:43.957364 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 561 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3328.5398]
trainer/QF1 Loss               0.016929053
trainer/QF2 Loss               0.0156085845
trainer/Policy Loss            -90.83349
trainer/Q1 Predictions Mean    102.81526
trainer/Q1 Predictions Std     2.0050325
trainer/Q1 Predictions Max     104.35334
trainer/Q1 Predictions Min     82.482666
trainer/Q2 Predictions Mean    102.82967
trainer/Q2 Predictions Std     1.9480708
trainer/Q2 Predictions Max     104.23825
trainer/Q2 Predictions Min     83.646805
trainer/Q Targets Mean         102.75816
trainer/Q Targets Std          1.9628931
trainer/Q Targets Max          104.297424
trainer/Q Targets Min          83.28332
trainer/Log Pis Mean           12.069741
trainer/Log Pis Std            9.043623
trainer/Log Pis Max            77.390366
trainer/Log Pis Min            -8.375488
trainer/Policy mu Mean         0.13001399
trainer/Policy mu Std          1.6073878
trainer/Policy mu Max          11.428344
trainer/Policy mu Min          -7.7856226
trainer/Policy log std Mean    -0.76329184
trainer/Policy log std Std     0.29172972
trainer/Policy log std Max     0.32839876
trainer/Policy log std Min     -2.3660338
trainer/Alpha                  0.0012967119691893458
trainer/Alpha Loss             0.46364474296569824
exploration/num steps total    2811000
exploration/num paths total    5622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9616787241432474
exploration/Rewards Std        0.052330963026929384
exploration/Rewards Max        0.9795915608450682
exploration/Rewards Min        0.4944888202724143
exploration/Returns Mean       480.83936207162367
exploration/Returns Std        2.2183676384240765
exploration/Returns Max        482.2159148039995
exploration/Returns Min        474.4324868990721
exploration/Actions Mean       -0.028012069
exploration/Actions Std        0.6019726
exploration/Actions Max        0.99993074
exploration/Actions Min        -0.99999785
exploration/Num Paths          10
exploration/Average Returns    480.83936207162367
evaluation/num steps total     2810000
evaluation/num paths total     5620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9634087338926757
evaluation/Rewards Std         0.047258933839716674
evaluation/Rewards Max         0.9780760277692586
evaluation/Rewards Min         0.4967496054436369
evaluation/Returns Mean        481.7043669463378
evaluation/Returns Std         0.3222219043889512
evaluation/Returns Max         482.0484592598479
evaluation/Returns Min         481.0238300071149
evaluation/ExplReturns Mean    481.7043669463378
evaluation/ExplReturns Std     0.3222219043889512
evaluation/ExplReturns Max     482.0484592598479
evaluation/ExplReturns Min     481.0238300071149
evaluation/Actions Mean        -0.07620959
evaluation/Actions Std         0.46508786
evaluation/Actions Max         0.9991139
evaluation/Actions Min         -0.9997427
evaluation/Num Paths           10
evaluation/Average Returns     481.7043669463378
time/data storing (s)          0.03213369194418192
time/evaluation sampling (s)   110.98250577691942
time/exploration sampling (s)  112.604929914698
time/logging (s)               0.0308810044080019
time/saving (s)                0.012338689528405666
time/training (s)              9.630048888735473
time/epoch (s)                 233.2928379662335
time/total (s)                 131734.45499264915
Epoch                          561
-----------------------------  ---------------------
2023-08-02 06:33:38.429436 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 562 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3979.5737]
trainer/QF1 Loss               0.011950342
trainer/QF2 Loss               0.021549871
trainer/Policy Loss            -91.40964
trainer/Q1 Predictions Mean    102.87986
trainer/Q1 Predictions Std     1.1014249
trainer/Q1 Predictions Max     104.12543
trainer/Q1 Predictions Min     93.67639
trainer/Q2 Predictions Mean    102.97933
trainer/Q2 Predictions Std     1.134319
trainer/Q2 Predictions Max     104.3807
trainer/Q2 Predictions Min     93.18135
trainer/Q Targets Mean         102.89389
trainer/Q Targets Std          1.1110806
trainer/Q Targets Max          104.226
trainer/Q Targets Min          93.49843
trainer/Log Pis Mean           11.572681
trainer/Log Pis Std            7.3742495
trainer/Log Pis Max            34.267067
trainer/Log Pis Min            -3.4957724
trainer/Policy mu Mean         0.05215354
trainer/Policy mu Std          1.5415316
trainer/Policy mu Max          4.2401447
trainer/Policy mu Min          -5.84023
trainer/Policy log std Mean    -0.7763893
trainer/Policy log std Std     0.2883253
trainer/Policy log std Max     -0.022105083
trainer/Policy log std Min     -2.0446396
trainer/Alpha                  0.0012861399445682764
trainer/Alpha Loss             -2.844210147857666
exploration/num steps total    2816000
exploration/num paths total    5632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.962135398652226
exploration/Rewards Std        0.04925855647196054
exploration/Rewards Max        0.9797684715291617
exploration/Rewards Min        0.4958994595430688
exploration/Returns Mean       481.067699326113
exploration/Returns Std        0.44701658683654355
exploration/Returns Max        481.85777954707316
exploration/Returns Min        480.35280075906024
exploration/Actions Mean       -0.022285542
exploration/Actions Std        0.59407413
exploration/Actions Max        0.99968296
exploration/Actions Min        -0.99999326
exploration/Num Paths          10
exploration/Average Returns    481.067699326113
evaluation/num steps total     2815000
evaluation/num paths total     5630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9577651891442635
evaluation/Rewards Std         0.05279402667685012
evaluation/Rewards Max         0.979533955140417
evaluation/Rewards Min         0.4891555050870393
evaluation/Returns Mean        478.8825945721316
evaluation/Returns Std         2.614335237571833
evaluation/Returns Max         480.51573770250064
evaluation/Returns Min         471.39069367473013
evaluation/ExplReturns Mean    478.8825945721316
evaluation/ExplReturns Std     2.614335237571833
evaluation/ExplReturns Max     480.51573770250064
evaluation/ExplReturns Min     471.39069367473013
evaluation/Actions Mean        0.019131692
evaluation/Actions Std         0.52947277
evaluation/Actions Max         0.9979399
evaluation/Actions Min         -0.99989164
evaluation/Num Paths           10
evaluation/Average Returns     478.8825945721316
time/data storing (s)          0.03194074798375368
time/evaluation sampling (s)   112.323445382528
time/exploration sampling (s)  112.49686071649194
time/logging (s)               0.031004000455141068
time/saving (s)                0.01222183182835579
time/training (s)              9.569534244947135
time/epoch (s)                 234.46500692423433
time/total (s)                 131968.92259641737
Epoch                          562
-----------------------------  ---------------------
2023-08-02 06:37:34.572048 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 563 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4255.96]
trainer/QF1 Loss               0.014332547
trainer/QF2 Loss               0.018568238
trainer/Policy Loss            -91.73233
trainer/Q1 Predictions Mean    102.71608
trainer/Q1 Predictions Std     1.0613846
trainer/Q1 Predictions Max     104.37997
trainer/Q1 Predictions Min     93.86381
trainer/Q2 Predictions Mean    102.699394
trainer/Q2 Predictions Std     1.0341014
trainer/Q2 Predictions Max     104.34722
trainer/Q2 Predictions Min     94.27692
trainer/Q Targets Mean         102.72099
trainer/Q Targets Std          1.0742611
trainer/Q Targets Max          104.371574
trainer/Q Targets Min          94.05475
trainer/Log Pis Mean           11.044098
trainer/Log Pis Std            7.8913274
trainer/Log Pis Max            40.356834
trainer/Log Pis Min            -10.599289
trainer/Policy mu Mean         0.15833777
trainer/Policy mu Std          1.5393503
trainer/Policy mu Max          4.8395014
trainer/Policy mu Min          -4.7366056
trainer/Policy log std Mean    -0.7252727
trainer/Policy log std Std     0.2770098
trainer/Policy log std Max     0.089000344
trainer/Policy log std Min     -2.0244446
trainer/Alpha                  0.001334607950411737
trainer/Alpha Loss             -6.327202796936035
exploration/num steps total    2821000
exploration/num paths total    5642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639639538317349
exploration/Rewards Std        0.04947987673215818
exploration/Rewards Max        0.979819247620984
exploration/Rewards Min        0.4804590790417745
exploration/Returns Mean       481.9819769158674
exploration/Returns Std        0.40958929209305267
exploration/Returns Max        482.75076503438436
exploration/Returns Min        481.50906640203596
exploration/Actions Mean       -0.031233128
exploration/Actions Std        0.6128369
exploration/Actions Max        0.9996984
exploration/Actions Min        -0.9999927
exploration/Num Paths          10
exploration/Average Returns    481.9819769158674
evaluation/num steps total     2820000
evaluation/num paths total     5640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9625800022945367
evaluation/Rewards Std         0.048165093191241834
evaluation/Rewards Max         0.9789169869419478
evaluation/Rewards Min         0.49912644153740715
evaluation/Returns Mean        481.2900011472684
evaluation/Returns Std         0.2475133265263602
evaluation/Returns Max         481.6752365264006
evaluation/Returns Min         480.89729043407516
evaluation/ExplReturns Mean    481.2900011472684
evaluation/ExplReturns Std     0.2475133265263602
evaluation/ExplReturns Max     481.6752365264006
evaluation/ExplReturns Min     480.89729043407516
evaluation/Actions Mean        0.042701915
evaluation/Actions Std         0.48000985
evaluation/Actions Max         0.99874526
evaluation/Actions Min         -0.99979573
evaluation/Num Paths           10
evaluation/Average Returns     481.2900011472684
time/data storing (s)          0.0324362451210618
time/evaluation sampling (s)   112.49171919096261
time/exploration sampling (s)  113.87893214542419
time/logging (s)               0.03164741396903992
time/saving (s)                0.012927277013659477
time/training (s)              9.688496213406324
time/epoch (s)                 236.13615848589689
time/total (s)                 132205.06125567295
Epoch                          563
-----------------------------  --------------------
2023-08-02 06:41:30.294592 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 564 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4231.969]
trainer/QF1 Loss               0.018575689
trainer/QF2 Loss               0.01495014
trainer/Policy Loss            -90.67917
trainer/Q1 Predictions Mean    102.47701
trainer/Q1 Predictions Std     1.6898246
trainer/Q1 Predictions Max     106.76634
trainer/Q1 Predictions Min     88.4937
trainer/Q2 Predictions Mean    102.49382
trainer/Q2 Predictions Std     1.6990628
trainer/Q2 Predictions Max     106.913826
trainer/Q2 Predictions Min     88.37697
trainer/Q Targets Mean         102.49188
trainer/Q Targets Std          1.7103436
trainer/Q Targets Max          107.1208
trainer/Q Targets Min          87.792915
trainer/Log Pis Mean           11.886308
trainer/Log Pis Std            9.380048
trainer/Log Pis Max            48.73417
trainer/Log Pis Min            -7.2644463
trainer/Policy mu Mean         0.004045123
trainer/Policy mu Std          1.578992
trainer/Policy mu Max          7.4893045
trainer/Policy mu Min          -5.502077
trainer/Policy log std Mean    -0.7777961
trainer/Policy log std Std     0.2868264
trainer/Policy log std Max     0.05598265
trainer/Policy log std Min     -1.9798698
trainer/Alpha                  0.0012568486854434013
trainer/Alpha Loss             -0.7593506574630737
exploration/num steps total    2826000
exploration/num paths total    5652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9577644797436162
exploration/Rewards Std        0.04849898542415063
exploration/Rewards Max        0.9793564809279908
exploration/Rewards Min        0.4941739235475724
exploration/Returns Mean       478.8822398718081
exploration/Returns Std        0.4522177272744988
exploration/Returns Max        479.6007959668148
exploration/Returns Min        478.3518200379794
exploration/Actions Mean       0.007439693
exploration/Actions Std        0.6038137
exploration/Actions Max        0.99987876
exploration/Actions Min        -0.9999752
exploration/Num Paths          10
exploration/Average Returns    478.8822398718081
evaluation/num steps total     2825000
evaluation/num paths total     5650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9544686450062035
evaluation/Rewards Std         0.04648138388297151
evaluation/Rewards Max         0.9729058043124182
evaluation/Rewards Min         0.4981852127130328
evaluation/Returns Mean        477.2343225031018
evaluation/Returns Std         0.2121503354383094
evaluation/Returns Max         477.55602482105047
evaluation/Returns Min         476.8506723469079
evaluation/ExplReturns Mean    477.2343225031018
evaluation/ExplReturns Std     0.2121503354383094
evaluation/ExplReturns Max     477.55602482105047
evaluation/ExplReturns Min     476.8506723469079
evaluation/Actions Mean        0.067287244
evaluation/Actions Std         0.44832635
evaluation/Actions Max         0.9992409
evaluation/Actions Min         -0.9996569
evaluation/Num Paths           10
evaluation/Average Returns     477.2343225031018
time/data storing (s)          0.032413339242339134
time/evaluation sampling (s)   112.69111867342144
time/exploration sampling (s)  113.17454169504344
time/logging (s)               0.03257498424500227
time/saving (s)                0.01207126583904028
time/training (s)              9.773483699187636
time/epoch (s)                 235.7162036569789
time/total (s)                 132440.78050892614
Epoch                          564
-----------------------------  ---------------------
2023-08-02 06:45:26.282909 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 565 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4214.445]
trainer/QF1 Loss               0.02140408
trainer/QF2 Loss               0.02377814
trainer/Policy Loss            -90.4135
trainer/Q1 Predictions Mean    102.34718
trainer/Q1 Predictions Std     1.8759667
trainer/Q1 Predictions Max     104.23125
trainer/Q1 Predictions Min     87.648186
trainer/Q2 Predictions Mean    102.38338
trainer/Q2 Predictions Std     1.8576187
trainer/Q2 Predictions Max     104.24215
trainer/Q2 Predictions Min     87.70884
trainer/Q Targets Mean         102.38156
trainer/Q Targets Std          1.8908781
trainer/Q Targets Max          104.234955
trainer/Q Targets Min          88.180664
trainer/Log Pis Mean           12.028585
trainer/Log Pis Std            8.009994
trainer/Log Pis Max            48.41646
trainer/Log Pis Min            -5.2220693
trainer/Policy mu Mean         0.090314455
trainer/Policy mu Std          1.5816079
trainer/Policy mu Max          6.1910634
trainer/Policy mu Min          -5.903533
trainer/Policy log std Mean    -0.74640733
trainer/Policy log std Std     0.30513054
trainer/Policy log std Max     0.1634027
trainer/Policy log std Min     -2.2676396
trainer/Alpha                  0.001268940046429634
trainer/Alpha Loss             0.19064664840698242
exploration/num steps total    2831000
exploration/num paths total    5662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9252198460339698
exploration/Rewards Std        0.10632261264771789
exploration/Rewards Max        0.9795423352405573
exploration/Rewards Min        0.4166877666341304
exploration/Returns Mean       462.60992301698496
exploration/Returns Std        37.03470749518882
exploration/Returns Max        482.3260170819456
exploration/Returns Min        352.485684704732
exploration/Actions Mean       0.048623983
exploration/Actions Std        0.657869
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    462.60992301698496
evaluation/num steps total     2830000
evaluation/num paths total     5660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9466848733185912
evaluation/Rewards Std         0.06135242635405613
evaluation/Rewards Max         0.9799082334413405
evaluation/Rewards Min         0.49401742011959526
evaluation/Returns Mean        473.34243665929563
evaluation/Returns Std         8.169825199338861
evaluation/Returns Max         482.17738348231944
evaluation/Returns Min         452.2510647763696
evaluation/ExplReturns Mean    473.34243665929563
evaluation/ExplReturns Std     8.169825199338861
evaluation/ExplReturns Max     482.17738348231944
evaluation/ExplReturns Min     452.2510647763696
evaluation/Actions Mean        0.10460376
evaluation/Actions Std         0.625409
evaluation/Actions Max         0.99999213
evaluation/Actions Min         -0.9999994
evaluation/Num Paths           10
evaluation/Average Returns     473.34243665929563
time/data storing (s)          0.03229941055178642
time/evaluation sampling (s)   113.03031627088785
time/exploration sampling (s)  113.15491748787463
time/logging (s)               0.030479485169053078
time/saving (s)                0.01079298835247755
time/training (s)              9.717537281103432
time/epoch (s)                 235.97634292393923
time/total (s)                 132676.75915227644
Epoch                          565
-----------------------------  --------------------
2023-08-02 06:49:22.900029 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 566 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4075.1658]
trainer/QF1 Loss               0.021699082
trainer/QF2 Loss               0.030152833
trainer/Policy Loss            -90.92279
trainer/Q1 Predictions Mean    102.44133
trainer/Q1 Predictions Std     1.4529929
trainer/Q1 Predictions Max     107.33916
trainer/Q1 Predictions Min     94.25734
trainer/Q2 Predictions Mean    102.35439
trainer/Q2 Predictions Std     1.4521781
trainer/Q2 Predictions Max     107.19518
trainer/Q2 Predictions Min     94.13071
trainer/Q Targets Mean         102.435585
trainer/Q Targets Std          1.4627384
trainer/Q Targets Max          107.43283
trainer/Q Targets Min          94.48786
trainer/Log Pis Mean           11.541449
trainer/Log Pis Std            9.207675
trainer/Log Pis Max            49.77368
trainer/Log Pis Min            -4.8050222
trainer/Policy mu Mean         0.103715725
trainer/Policy mu Std          1.586124
trainer/Policy mu Max          5.5698195
trainer/Policy mu Min          -5.556482
trainer/Policy log std Mean    -0.7300055
trainer/Policy log std Std     0.28765136
trainer/Policy log std Max     0.21420175
trainer/Policy log std Min     -2.0952044
trainer/Alpha                  0.001366512500680983
trainer/Alpha Loss             -3.0243403911590576
exploration/num steps total    2836000
exploration/num paths total    5672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9452991404884231
exploration/Rewards Std        0.06799005317097796
exploration/Rewards Max        0.9794199268950557
exploration/Rewards Min        0.49302996129116905
exploration/Returns Mean       472.64957024421153
exploration/Returns Std        8.231542520635527
exploration/Returns Max        478.51788622761507
exploration/Returns Min        451.70295110120145
exploration/Actions Mean       0.112548046
exploration/Actions Std        0.6339399
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    472.64957024421153
evaluation/num steps total     2835000
evaluation/num paths total     5670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9242688948927665
evaluation/Rewards Std         0.0890985302989237
evaluation/Rewards Max         0.97972605294456
evaluation/Rewards Min         0.49717669264514835
evaluation/Returns Mean        462.13444744638326
evaluation/Returns Std         17.76477688665578
evaluation/Returns Max         477.99080606981755
evaluation/Returns Min         428.15380358440626
evaluation/ExplReturns Mean    462.13444744638326
evaluation/ExplReturns Std     17.76477688665578
evaluation/ExplReturns Max     477.99080606981755
evaluation/ExplReturns Min     428.15380358440626
evaluation/Actions Mean        0.12237666
evaluation/Actions Std         0.61545324
evaluation/Actions Max         0.99999994
evaluation/Actions Min         -0.9999998
evaluation/Num Paths           10
evaluation/Average Returns     462.13444744638326
time/data storing (s)          0.0318891117349267
time/evaluation sampling (s)   113.47241756133735
time/exploration sampling (s)  113.64258123189211
time/logging (s)               0.030632455833256245
time/saving (s)                0.01032200362533331
time/training (s)              9.422431383281946
time/epoch (s)                 236.61027374770492
time/total (s)                 132913.37190793082
Epoch                          566
-----------------------------  --------------------
2023-08-02 06:53:21.315980 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 567 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3934.523]
trainer/QF1 Loss               0.013555368
trainer/QF2 Loss               0.018913526
trainer/Policy Loss            -90.26145
trainer/Q1 Predictions Mean    102.39498
trainer/Q1 Predictions Std     1.8850074
trainer/Q1 Predictions Max     107.21983
trainer/Q1 Predictions Min     77.23948
trainer/Q2 Predictions Mean    102.360916
trainer/Q2 Predictions Std     1.8677851
trainer/Q2 Predictions Max     107.13935
trainer/Q2 Predictions Min     77.65527
trainer/Q Targets Mean         102.38999
trainer/Q Targets Std          1.8806609
trainer/Q Targets Max          107.31247
trainer/Q Targets Min          77.34255
trainer/Log Pis Mean           12.180309
trainer/Log Pis Std            7.813182
trainer/Log Pis Max            48.912964
trainer/Log Pis Min            -2.6511533
trainer/Policy mu Mean         0.057138074
trainer/Policy mu Std          1.5786861
trainer/Policy mu Max          5.3086205
trainer/Policy mu Min          -10.881571
trainer/Policy log std Mean    -0.784647
trainer/Policy log std Std     0.3059328
trainer/Policy log std Max     0.14277396
trainer/Policy log std Min     -2.2547429
trainer/Alpha                  0.001321985269896686
trainer/Alpha Loss             1.1952111721038818
exploration/num steps total    2841000
exploration/num paths total    5682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8886031974870894
exploration/Rewards Std        0.172816113741751
exploration/Rewards Max        0.9794526340721872
exploration/Rewards Min        0.15760423961219852
exploration/Returns Mean       444.3015987435445
exploration/Returns Std        47.30429214306264
exploration/Returns Max        475.6396921976519
exploration/Returns Min        311.8946895965055
exploration/Actions Mean       0.056905787
exploration/Actions Std        0.7262252
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    444.3015987435445
evaluation/num steps total     2840000
evaluation/num paths total     5680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9375487110120871
evaluation/Rewards Std         0.0711731133791582
evaluation/Rewards Max         0.979015861529663
evaluation/Rewards Min         0.502208250218359
evaluation/Returns Mean        468.77435550604343
evaluation/Returns Std         7.721546977363456
evaluation/Returns Max         474.1285049992893
evaluation/Returns Min         446.04950069731575
evaluation/ExplReturns Mean    468.77435550604343
evaluation/ExplReturns Std     7.721546977363456
evaluation/ExplReturns Max     474.1285049992893
evaluation/ExplReturns Min     446.04950069731575
evaluation/Actions Mean        0.16905673
evaluation/Actions Std         0.68608415
evaluation/Actions Max         0.9999999
evaluation/Actions Min         -0.99999744
evaluation/Num Paths           10
evaluation/Average Returns     468.77435550604343
time/data storing (s)          0.031717716716229916
time/evaluation sampling (s)   114.20356807485223
time/exploration sampling (s)  114.44289954937994
time/logging (s)               0.03037615865468979
time/saving (s)                0.011395343579351902
time/training (s)              9.688712156377733
time/epoch (s)                 238.40866899956018
time/total (s)                 133151.78302584216
Epoch                          567
-----------------------------  --------------------
2023-08-02 06:57:19.216472 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 568 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3977.6006]
trainer/QF1 Loss               0.019242417
trainer/QF2 Loss               0.020783786
trainer/Policy Loss            -90.94847
trainer/Q1 Predictions Mean    102.28929
trainer/Q1 Predictions Std     2.146363
trainer/Q1 Predictions Max     106.7909
trainer/Q1 Predictions Min     81.75259
trainer/Q2 Predictions Mean    102.31706
trainer/Q2 Predictions Std     2.1506789
trainer/Q2 Predictions Max     106.69384
trainer/Q2 Predictions Min     81.48875
trainer/Q Targets Mean         102.262375
trainer/Q Targets Std          2.1580296
trainer/Q Targets Max          106.78341
trainer/Q Targets Min          81.44169
trainer/Log Pis Mean           11.424133
trainer/Log Pis Std            8.264761
trainer/Log Pis Max            48.798744
trainer/Log Pis Min            -4.5207024
trainer/Policy mu Mean         0.20601575
trainer/Policy mu Std          1.567447
trainer/Policy mu Max          7.925276
trainer/Policy mu Min          -9.024089
trainer/Policy log std Mean    -0.7703759
trainer/Policy log std Std     0.29846504
trainer/Policy log std Max     0.3550546
trainer/Policy log std Min     -2.6982977
trainer/Alpha                  0.001372902188450098
trainer/Alpha Loss             -3.7954254150390625
exploration/num steps total    2846000
exploration/num paths total    5692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8452534054222675
exploration/Rewards Std        0.1826004312801475
exploration/Rewards Max        0.9780525790871938
exploration/Rewards Min        0.11549763774020122
exploration/Returns Mean       422.6267027111338
exploration/Returns Std        62.46791373590002
exploration/Returns Max        478.09235642449505
exploration/Returns Min        285.4760743208338
exploration/Actions Mean       0.09702225
exploration/Actions Std        0.70034075
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    422.6267027111338
evaluation/num steps total     2845000
evaluation/num paths total     5690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.916134178960124
evaluation/Rewards Std         0.10400228020910482
evaluation/Rewards Max         0.9772085404287563
evaluation/Rewards Min         0.46830371451879654
evaluation/Returns Mean        458.06708948006207
evaluation/Returns Std         23.92225108533015
evaluation/Returns Max         477.39987427134037
evaluation/Returns Min         408.48575040881985
evaluation/ExplReturns Mean    458.06708948006207
evaluation/ExplReturns Std     23.92225108533015
evaluation/ExplReturns Max     477.39987427134037
evaluation/ExplReturns Min     408.48575040881985
evaluation/Actions Mean        0.08462688
evaluation/Actions Std         0.6358152
evaluation/Actions Max         0.99998635
evaluation/Actions Min         -0.99999946
evaluation/Num Paths           10
evaluation/Average Returns     458.06708948006207
time/data storing (s)          0.03231797367334366
time/evaluation sampling (s)   114.00269516464323
time/exploration sampling (s)  114.13974771089852
time/logging (s)               0.030631600879132748
time/saving (s)                0.012402676977217197
time/training (s)              9.675925835967064
time/epoch (s)                 237.8937209630385
time/total (s)                 133389.67921849154
Epoch                          568
-----------------------------  --------------------
2023-08-02 07:01:19.308241 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 569 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3885.3987]
trainer/QF1 Loss               0.02587317
trainer/QF2 Loss               0.018793508
trainer/Policy Loss            -90.339554
trainer/Q1 Predictions Mean    102.225784
trainer/Q1 Predictions Std     1.7509809
trainer/Q1 Predictions Max     106.392525
trainer/Q1 Predictions Min     88.94106
trainer/Q2 Predictions Mean    102.24979
trainer/Q2 Predictions Std     1.7461294
trainer/Q2 Predictions Max     106.63346
trainer/Q2 Predictions Min     89.2143
trainer/Q Targets Mean         102.24429
trainer/Q Targets Std          1.7736609
trainer/Q Targets Max          106.59928
trainer/Q Targets Min          89.36717
trainer/Log Pis Mean           11.9762335
trainer/Log Pis Std            8.490166
trainer/Log Pis Max            42.571186
trainer/Log Pis Min            -7.173591
trainer/Policy mu Mean         0.062957205
trainer/Policy mu Std          1.6055926
trainer/Policy mu Max          5.7512903
trainer/Policy mu Min          -6.3204184
trainer/Policy log std Mean    -0.75333184
trainer/Policy log std Std     0.30299222
trainer/Policy log std Max     0.41189197
trainer/Policy log std Min     -2.136572
trainer/Alpha                  0.0014117826940491796
trainer/Alpha Loss             -0.15597915649414062
exploration/num steps total    2851000
exploration/num paths total    5702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9128485342280342
exploration/Rewards Std        0.0886551773458571
exploration/Rewards Max        0.9773741068901309
exploration/Rewards Min        0.4906255613756466
exploration/Returns Mean       456.42426711401714
exploration/Returns Std        22.156963363077853
exploration/Returns Max        474.2713508410651
exploration/Returns Min        413.03243195120587
exploration/Actions Mean       0.1650414
exploration/Actions Std        0.6575329
exploration/Actions Max        0.99998236
exploration/Actions Min        -0.9999991
exploration/Num Paths          10
exploration/Average Returns    456.42426711401714
evaluation/num steps total     2850000
evaluation/num paths total     5700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9285023490562387
evaluation/Rewards Std         0.07483884897198637
evaluation/Rewards Max         0.9759527489047747
evaluation/Rewards Min         0.48377573687167513
evaluation/Returns Mean        464.2511745281196
evaluation/Returns Std         20.648403158957645
evaluation/Returns Max         472.9865292156954
evaluation/Returns Min         402.5763953612908
evaluation/ExplReturns Mean    464.2511745281196
evaluation/ExplReturns Std     20.648403158957645
evaluation/ExplReturns Max     472.9865292156954
evaluation/ExplReturns Min     402.5763953612908
evaluation/Actions Mean        0.19104174
evaluation/Actions Std         0.5798696
evaluation/Actions Max         0.99998957
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     464.2511745281196
time/data storing (s)          0.03241121303290129
time/evaluation sampling (s)   114.86384344939142
time/exploration sampling (s)  115.50353100057691
time/logging (s)               0.030506844632327557
time/saving (s)                0.011427942663431168
time/training (s)              9.642780494876206
time/epoch (s)                 240.0845009451732
time/total (s)                 133629.76621855423
Epoch                          569
-----------------------------  ---------------------
2023-08-02 07:05:13.771438 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 570 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3892.8242]
trainer/QF1 Loss               0.030578975
trainer/QF2 Loss               0.036602415
trainer/Policy Loss            -89.55638
trainer/Q1 Predictions Mean    102.37202
trainer/Q1 Predictions Std     1.8623745
trainer/Q1 Predictions Max     104.18104
trainer/Q1 Predictions Min     81.19786
trainer/Q2 Predictions Mean    102.40019
trainer/Q2 Predictions Std     1.8733038
trainer/Q2 Predictions Max     104.14371
trainer/Q2 Predictions Min     81.14261
trainer/Q Targets Mean         102.30986
trainer/Q Targets Std          1.8567152
trainer/Q Targets Max          104.09346
trainer/Q Targets Min          81.391304
trainer/Log Pis Mean           12.912144
trainer/Log Pis Std            9.037024
trainer/Log Pis Max            57.47193
trainer/Log Pis Min            -2.9999917
trainer/Policy mu Mean         0.08405431
trainer/Policy mu Std          1.6160841
trainer/Policy mu Max          7.2891726
trainer/Policy mu Min          -5.3935146
trainer/Policy log std Mean    -0.79090214
trainer/Policy log std Std     0.29169607
trainer/Policy log std Max     0.34666163
trainer/Policy log std Min     -2.116823
trainer/Alpha                  0.0014507168671116233
trainer/Alpha Loss             5.961664199829102
exploration/num steps total    2856000
exploration/num paths total    5712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9330420991914454
exploration/Rewards Std        0.08250156572347965
exploration/Rewards Max        0.9787882707373218
exploration/Rewards Min        0.491458947890418
exploration/Returns Mean       466.5210495957228
exploration/Returns Std        12.125648708030942
exploration/Returns Max        481.0712404824759
exploration/Returns Min        440.3421912098439
exploration/Actions Mean       0.05466698
exploration/Actions Std        0.646899
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999828
exploration/Num Paths          10
exploration/Average Returns    466.5210495957228
evaluation/num steps total     2855000
evaluation/num paths total     5710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9429633924492882
evaluation/Rewards Std         0.07480306484960124
evaluation/Rewards Max         0.9788564364233745
evaluation/Rewards Min         0.4950401450693594
evaluation/Returns Mean        471.4816962246441
evaluation/Returns Std         18.567971233311376
evaluation/Returns Max         481.64141399551943
evaluation/Returns Min         433.78904245305836
evaluation/ExplReturns Mean    471.4816962246441
evaluation/ExplReturns Std     18.567971233311376
evaluation/ExplReturns Max     481.64141399551943
evaluation/ExplReturns Min     433.78904245305836
evaluation/Actions Mean        0.08626117
evaluation/Actions Std         0.51160014
evaluation/Actions Max         0.9998558
evaluation/Actions Min         -0.99998057
evaluation/Num Paths           10
evaluation/Average Returns     471.4816962246441
time/data storing (s)          0.03231820650398731
time/evaluation sampling (s)   112.38506289198995
time/exploration sampling (s)  112.38962672371417
time/logging (s)               0.03085758350789547
time/saving (s)                0.012789921835064888
time/training (s)              9.605846231803298
time/epoch (s)                 234.45650155935436
time/total (s)                 133864.22517316043
Epoch                          570
-----------------------------  ---------------------
2023-08-02 07:09:08.075749 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 571 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4029.7927]
trainer/QF1 Loss               0.018082406
trainer/QF2 Loss               0.01907632
trainer/Policy Loss            -89.90164
trainer/Q1 Predictions Mean    102.29651
trainer/Q1 Predictions Std     1.6335211
trainer/Q1 Predictions Max     104.35299
trainer/Q1 Predictions Min     86.20799
trainer/Q2 Predictions Mean    102.28891
trainer/Q2 Predictions Std     1.6256154
trainer/Q2 Predictions Max     104.43956
trainer/Q2 Predictions Min     86.638916
trainer/Q Targets Mean         102.26338
trainer/Q Targets Std          1.6434344
trainer/Q Targets Max          104.569664
trainer/Q Targets Min          85.80842
trainer/Log Pis Mean           12.4931555
trainer/Log Pis Std            7.734708
trainer/Log Pis Max            42.721725
trainer/Log Pis Min            -3.8949792
trainer/Policy mu Mean         0.024462074
trainer/Policy mu Std          1.598982
trainer/Policy mu Max          5.986083
trainer/Policy mu Min          -5.7275057
trainer/Policy log std Mean    -0.78116304
trainer/Policy log std Std     0.29854125
trainer/Policy log std Max     0.17055488
trainer/Policy log std Min     -1.9513772
trainer/Alpha                  0.0014320308109745383
trainer/Alpha Loss             3.22959041595459
exploration/num steps total    2861000
exploration/num paths total    5722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9624961322094103
exploration/Rewards Std        0.05015990348144606
exploration/Rewards Max        0.9799850311581517
exploration/Rewards Min        0.4933661888194637
exploration/Returns Mean       481.24806610470506
exploration/Returns Std        1.2660809055330817
exploration/Returns Max        482.77666152125397
exploration/Returns Min        478.86721747007505
exploration/Actions Mean       0.20986876
exploration/Actions Std        0.61031926
exploration/Actions Max        0.99991816
exploration/Actions Min        -0.9999516
exploration/Num Paths          10
exploration/Average Returns    481.24806610470506
evaluation/num steps total     2860000
evaluation/num paths total     5720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9637074968728475
evaluation/Rewards Std         0.048494943141377124
evaluation/Rewards Max         0.977340460509418
evaluation/Rewards Min         0.4853115872973186
evaluation/Returns Mean        481.85374843642376
evaluation/Returns Std         0.7223644995348001
evaluation/Returns Max         482.94718814086696
evaluation/Returns Min         480.53537890950923
evaluation/ExplReturns Mean    481.85374843642376
evaluation/ExplReturns Std     0.7223644995348001
evaluation/ExplReturns Max     482.94718814086696
evaluation/ExplReturns Min     480.53537890950923
evaluation/Actions Mean        0.23995973
evaluation/Actions Std         0.59333086
evaluation/Actions Max         0.99922067
evaluation/Actions Min         -0.99914813
evaluation/Num Paths           10
evaluation/Average Returns     481.85374843642376
time/data storing (s)          0.03212073631584644
time/evaluation sampling (s)   111.66987982951105
time/exploration sampling (s)  112.94180225767195
time/logging (s)               0.03084142692387104
time/saving (s)                0.012730642221868038
time/training (s)              9.609807222150266
time/epoch (s)                 234.29718211479485
time/total (s)                 134098.5248188516
Epoch                          571
-----------------------------  ---------------------
2023-08-02 07:13:02.329919 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 572 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3306.2537]
trainer/QF1 Loss               0.018007325
trainer/QF2 Loss               0.047480345
trainer/Policy Loss            -90.720856
trainer/Q1 Predictions Mean    102.367004
trainer/Q1 Predictions Std     1.1761082
trainer/Q1 Predictions Max     103.923035
trainer/Q1 Predictions Min     94.89431
trainer/Q2 Predictions Mean    102.4904
trainer/Q2 Predictions Std     1.2133847
trainer/Q2 Predictions Max     104.19247
trainer/Q2 Predictions Min     94.52465
trainer/Q Targets Mean         102.33147
trainer/Q Targets Std          1.1978244
trainer/Q Targets Max          104.00317
trainer/Q Targets Min          93.95711
trainer/Log Pis Mean           11.748232
trainer/Log Pis Std            8.118452
trainer/Log Pis Max            53.081432
trainer/Log Pis Min            -4.329277
trainer/Policy mu Mean         0.06327965
trainer/Policy mu Std          1.5540714
trainer/Policy mu Max          4.973136
trainer/Policy mu Min          -5.319744
trainer/Policy log std Mean    -0.7870364
trainer/Policy log std Std     0.30047464
trainer/Policy log std Max     0.28291845
trainer/Policy log std Min     -1.9686518
trainer/Alpha                  0.0015104940393939614
trainer/Alpha Loss             -1.635272741317749
exploration/num steps total    2866000
exploration/num paths total    5732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9577963279936692
exploration/Rewards Std        0.04708029839501016
exploration/Rewards Max        0.9799431652991984
exploration/Rewards Min        0.49965554486628144
exploration/Returns Mean       478.8981639968347
exploration/Returns Std        0.5892617637504198
exploration/Returns Max        479.6991767089999
exploration/Returns Min        477.7834060341816
exploration/Actions Mean       0.084493354
exploration/Actions Std        0.5734654
exploration/Actions Max        0.9995496
exploration/Actions Min        -0.9999038
exploration/Num Paths          10
exploration/Average Returns    478.8981639968347
evaluation/num steps total     2865000
evaluation/num paths total     5730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.95737415147184
evaluation/Rewards Std         0.044354005512819074
evaluation/Rewards Max         0.9741923590088573
evaluation/Rewards Min         0.49302971380805716
evaluation/Returns Mean        478.68707573592
evaluation/Returns Std         0.2936479221130082
evaluation/Returns Max         479.2464743398208
evaluation/Returns Min         478.1743616914392
evaluation/ExplReturns Mean    478.68707573592
evaluation/ExplReturns Std     0.2936479221130082
evaluation/ExplReturns Max     479.2464743398208
evaluation/ExplReturns Min     478.1743616914392
evaluation/Actions Mean        0.15380113
evaluation/Actions Std         0.53503215
evaluation/Actions Max         0.99884564
evaluation/Actions Min         -0.9995778
evaluation/Num Paths           10
evaluation/Average Returns     478.68707573592
time/data storing (s)          0.03187169600278139
time/evaluation sampling (s)   112.97836162056774
time/exploration sampling (s)  112.63194279558957
time/logging (s)               0.030500189401209354
time/saving (s)                0.0102527542039752
time/training (s)              8.56381819397211
time/epoch (s)                 234.24674724973738
time/total (s)                 134332.77403340954
Epoch                          572
-----------------------------  ---------------------
2023-08-02 07:16:53.971449 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 573 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4151.5435]
trainer/QF1 Loss               0.02435663
trainer/QF2 Loss               0.021320727
trainer/Policy Loss            -90.38957
trainer/Q1 Predictions Mean    102.169464
trainer/Q1 Predictions Std     2.4098988
trainer/Q1 Predictions Max     106.27992
trainer/Q1 Predictions Min     78.578926
trainer/Q2 Predictions Mean    102.112564
trainer/Q2 Predictions Std     2.4177513
trainer/Q2 Predictions Max     106.45857
trainer/Q2 Predictions Min     77.665695
trainer/Q Targets Mean         102.14634
trainer/Q Targets Std          2.4425116
trainer/Q Targets Max          106.03338
trainer/Q Targets Min          77.48665
trainer/Log Pis Mean           11.825385
trainer/Log Pis Std            8.077311
trainer/Log Pis Max            79.63458
trainer/Log Pis Min            -1.0498931
trainer/Policy mu Mean         -0.025758749
trainer/Policy mu Std          1.5636029
trainer/Policy mu Max          6.907118
trainer/Policy mu Min          -6.297262
trainer/Policy log std Mean    -0.7925938
trainer/Policy log std Std     0.29197586
trainer/Policy log std Max     0.2266253
trainer/Policy log std Min     -2.090489
trainer/Alpha                  0.0014015872729942203
trainer/Alpha Loss             -1.1472373008728027
exploration/num steps total    2871000
exploration/num paths total    5742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9539043044653361
exploration/Rewards Std        0.05026153217398911
exploration/Rewards Max        0.9792037952574983
exploration/Rewards Min        0.4953306760983721
exploration/Returns Mean       476.952152232668
exploration/Returns Std        0.48269438862291286
exploration/Returns Max        477.8857193052384
exploration/Returns Min        476.4042427169359
exploration/Actions Mean       0.13486141
exploration/Actions Std        0.5984988
exploration/Actions Max        0.9999636
exploration/Actions Min        -0.9999223
exploration/Num Paths          10
exploration/Average Returns    476.952152232668
evaluation/num steps total     2870000
evaluation/num paths total     5740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9311317253080088
evaluation/Rewards Std         0.08128611258689039
evaluation/Rewards Max         0.9775493638908916
evaluation/Rewards Min         0.5059511975795028
evaluation/Returns Mean        465.5658626540044
evaluation/Returns Std         16.773922916515197
evaluation/Returns Max         477.91169785791203
evaluation/Returns Min         432.7018932624259
evaluation/ExplReturns Mean    465.5658626540044
evaluation/ExplReturns Std     16.773922916515197
evaluation/ExplReturns Max     477.91169785791203
evaluation/ExplReturns Min     432.7018932624259
evaluation/Actions Mean        0.1498063
evaluation/Actions Std         0.58564276
evaluation/Actions Max         0.9999761
evaluation/Actions Min         -0.9996795
evaluation/Num Paths           10
evaluation/Average Returns     465.5658626540044
time/data storing (s)          0.032034436240792274
time/evaluation sampling (s)   110.36429570056498
time/exploration sampling (s)  111.60588345583528
time/logging (s)               0.030411062762141228
time/saving (s)                0.012587464414536953
time/training (s)              9.58913308288902
time/epoch (s)                 231.63434520270675
time/total (s)                 134564.4108912712
Epoch                          573
-----------------------------  ---------------------
2023-08-02 07:20:47.229113 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 574 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3835.349]
trainer/QF1 Loss               0.024529316
trainer/QF2 Loss               0.025909085
trainer/Policy Loss            -90.12573
trainer/Q1 Predictions Mean    102.19812
trainer/Q1 Predictions Std     1.2620252
trainer/Q1 Predictions Max     104.30284
trainer/Q1 Predictions Min     95.492645
trainer/Q2 Predictions Mean    102.159775
trainer/Q2 Predictions Std     1.2742755
trainer/Q2 Predictions Max     104.05859
trainer/Q2 Predictions Min     95.35827
trainer/Q Targets Mean         102.26834
trainer/Q Targets Std          1.2870364
trainer/Q Targets Max          104.071724
trainer/Q Targets Min          95.03251
trainer/Log Pis Mean           12.122185
trainer/Log Pis Std            7.685192
trainer/Log Pis Max            42.14343
trainer/Log Pis Min            -10.564445
trainer/Policy mu Mean         0.019240549
trainer/Policy mu Std          1.5656595
trainer/Policy mu Max          4.902743
trainer/Policy mu Min          -6.5550303
trainer/Policy log std Mean    -0.8054435
trainer/Policy log std Std     0.29570708
trainer/Policy log std Max     0.19516498
trainer/Policy log std Min     -2.1054647
trainer/Alpha                  0.0014266212237998843
trainer/Alpha Loss             0.8005870580673218
exploration/num steps total    2876000
exploration/num paths total    5752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9650028260792706
exploration/Rewards Std        0.049648715416942345
exploration/Rewards Max        0.9796228816494628
exploration/Rewards Min        0.4924857208086926
exploration/Returns Mean       482.50141303963517
exploration/Returns Std        0.4284860984135507
exploration/Returns Max        483.11435821088
exploration/Returns Min        481.8645020931375
exploration/Actions Mean       0.039518394
exploration/Actions Std        0.5281378
exploration/Actions Max        0.9998984
exploration/Actions Min        -0.9999169
exploration/Num Paths          10
exploration/Average Returns    482.50141303963517
evaluation/num steps total     2875000
evaluation/num paths total     5750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9653119840457098
evaluation/Rewards Std         0.051169177975119155
evaluation/Rewards Max         0.9790810750724543
evaluation/Rewards Min         0.4966490443413471
evaluation/Returns Mean        482.65599202285483
evaluation/Returns Std         0.4233366439251431
evaluation/Returns Max         483.415448006938
evaluation/Returns Min         481.78675989845186
evaluation/ExplReturns Mean    482.65599202285483
evaluation/ExplReturns Std     0.4233366439251431
evaluation/ExplReturns Max     483.415448006938
evaluation/ExplReturns Min     481.78675989845186
evaluation/Actions Mean        0.05434332
evaluation/Actions Std         0.3989142
evaluation/Actions Max         0.99913746
evaluation/Actions Min         -0.99919415
evaluation/Num Paths           10
evaluation/Average Returns     482.65599202285483
time/data storing (s)          0.031908730044960976
time/evaluation sampling (s)   112.07291282806545
time/exploration sampling (s)  111.52903665509075
time/logging (s)               0.03090468794107437
time/saving (s)                0.011229539290070534
time/training (s)              9.575008815154433
time/epoch (s)                 233.25100125558674
time/total (s)                 134797.66438183188
Epoch                          574
-----------------------------  ---------------------
2023-08-02 07:24:42.562558 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 575 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4238.2524]
trainer/QF1 Loss               0.031668033
trainer/QF2 Loss               0.029347587
trainer/Policy Loss            -90.16829
trainer/Q1 Predictions Mean    102.134636
trainer/Q1 Predictions Std     1.8871316
trainer/Q1 Predictions Max     104.24287
trainer/Q1 Predictions Min     82.56107
trainer/Q2 Predictions Mean    102.124405
trainer/Q2 Predictions Std     1.8923767
trainer/Q2 Predictions Max     104.20548
trainer/Q2 Predictions Min     82.27155
trainer/Q Targets Mean         102.18674
trainer/Q Targets Std          1.8826503
trainer/Q Targets Max          104.141014
trainer/Q Targets Min          82.582535
trainer/Log Pis Mean           12.034475
trainer/Log Pis Std            7.980901
trainer/Log Pis Max            75.094376
trainer/Log Pis Min            -0.5506778
trainer/Policy mu Mean         -0.09355652
trainer/Policy mu Std          1.5557538
trainer/Policy mu Max          6.6422286
trainer/Policy mu Min          -9.008888
trainer/Policy log std Mean    -0.8048871
trainer/Policy log std Std     0.28804502
trainer/Policy log std Max     0.4421339
trainer/Policy log std Min     -1.9537755
trainer/Alpha                  0.0013766505289822817
trainer/Alpha Loss             0.2271277904510498
exploration/num steps total    2881000
exploration/num paths total    5762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9650068345265393
exploration/Rewards Std        0.047844651434015964
exploration/Rewards Max        0.9796988221847647
exploration/Rewards Min        0.49258995321310706
exploration/Returns Mean       482.5034172632695
exploration/Returns Std        0.36595503115960976
exploration/Returns Max        483.1488813963975
exploration/Returns Min        481.8155472867272
exploration/Actions Mean       0.11427865
exploration/Actions Std        0.572709
exploration/Actions Max        0.9998403
exploration/Actions Min        -0.9999386
exploration/Num Paths          10
exploration/Average Returns    482.5034172632695
evaluation/num steps total     2880000
evaluation/num paths total     5760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9611275195243663
evaluation/Rewards Std         0.056436026292752975
evaluation/Rewards Max         0.9773312494799747
evaluation/Rewards Min         0.49072736053564175
evaluation/Returns Mean        480.56375976218317
evaluation/Returns Std         6.718561519150082
evaluation/Returns Max         484.26047638895545
evaluation/Returns Min         460.5862785070867
evaluation/ExplReturns Mean    480.56375976218317
evaluation/ExplReturns Std     6.718561519150082
evaluation/ExplReturns Max     484.26047638895545
evaluation/ExplReturns Min     460.5862785070867
evaluation/Actions Mean        0.119041204
evaluation/Actions Std         0.45334837
evaluation/Actions Max         0.99958336
evaluation/Actions Min         -0.999611
evaluation/Num Paths           10
evaluation/Average Returns     480.56375976218317
time/data storing (s)          0.03232559934258461
time/evaluation sampling (s)   112.10657259635627
time/exploration sampling (s)  113.54165565408766
time/logging (s)               0.030869423411786556
time/saving (s)                0.011847859248518944
time/training (s)              9.602827813476324
time/epoch (s)                 235.32609894592315
time/total (s)                 135032.99311771896
Epoch                          575
-----------------------------  ---------------------
2023-08-02 07:28:36.023285 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 576 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4144.9673]
trainer/QF1 Loss               0.029675312
trainer/QF2 Loss               0.026509035
trainer/Policy Loss            -89.302986
trainer/Q1 Predictions Mean    102.07477
trainer/Q1 Predictions Std     2.6100721
trainer/Q1 Predictions Max     104.21971
trainer/Q1 Predictions Min     74.9431
trainer/Q2 Predictions Mean    102.10837
trainer/Q2 Predictions Std     2.580259
trainer/Q2 Predictions Max     104.1949
trainer/Q2 Predictions Min     75.304146
trainer/Q Targets Mean         102.09655
trainer/Q Targets Std          2.622931
trainer/Q Targets Max          104.19768
trainer/Q Targets Min          75.72305
trainer/Log Pis Mean           12.875238
trainer/Log Pis Std            9.754567
trainer/Log Pis Max            71.04237
trainer/Log Pis Min            -1.940732
trainer/Policy mu Mean         -0.11777084
trainer/Policy mu Std          1.659044
trainer/Policy mu Max          8.665865
trainer/Policy mu Min          -14.036257
trainer/Policy log std Mean    -0.7706833
trainer/Policy log std Std     0.3019034
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.1716805
trainer/Alpha                  0.0014329877449199557
trainer/Alpha Loss             5.731113910675049
exploration/num steps total    2886000
exploration/num paths total    5772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8660110581321695
exploration/Rewards Std        0.11586904731880633
exploration/Rewards Max        0.9782804446171035
exploration/Rewards Min        0.49269271319316144
exploration/Returns Mean       433.00552906608465
exploration/Returns Std        42.9106897508209
exploration/Returns Max        480.59979179005046
exploration/Returns Min        388.00078038535713
exploration/Actions Mean       0.053969678
exploration/Actions Std        0.56390387
exploration/Actions Max        0.9999277
exploration/Actions Min        -0.9999827
exploration/Num Paths          10
exploration/Average Returns    433.00552906608465
evaluation/num steps total     2885000
evaluation/num paths total     5770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8624639626914115
evaluation/Rewards Std         0.11967781589642758
evaluation/Rewards Max         0.9776536510002544
evaluation/Rewards Min         0.48503423788649985
evaluation/Returns Mean        431.23198134570566
evaluation/Returns Std         49.04891765794824
evaluation/Returns Max         481.78231502714254
evaluation/Returns Min         380.0986562839942
evaluation/ExplReturns Mean    431.23198134570566
evaluation/ExplReturns Std     49.04891765794824
evaluation/ExplReturns Max     481.78231502714254
evaluation/ExplReturns Min     380.0986562839942
evaluation/Actions Mean        0.03834715
evaluation/Actions Std         0.47411072
evaluation/Actions Max         0.9990409
evaluation/Actions Min         -0.99986917
evaluation/Num Paths           10
evaluation/Average Returns     431.23198134570566
time/data storing (s)          0.03188357222825289
time/evaluation sampling (s)   112.42671569343656
time/exploration sampling (s)  111.81748294271529
time/logging (s)               0.03025119286030531
time/saving (s)                0.010511358268558979
time/training (s)              9.135967357084155
time/epoch (s)                 233.45281211659312
time/total (s)                 135266.44859905168
Epoch                          576
-----------------------------  ---------------------
2023-08-02 07:32:29.836691 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 577 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3924.812]
trainer/QF1 Loss               0.0302652
trainer/QF2 Loss               0.025820458
trainer/Policy Loss            -90.8342
trainer/Q1 Predictions Mean    102.10894
trainer/Q1 Predictions Std     2.3192596
trainer/Q1 Predictions Max     105.80504
trainer/Q1 Predictions Min     71.66234
trainer/Q2 Predictions Mean    102.11398
trainer/Q2 Predictions Std     2.2902954
trainer/Q2 Predictions Max     105.67467
trainer/Q2 Predictions Min     71.8372
trainer/Q Targets Mean         102.14702
trainer/Q Targets Std          2.278402
trainer/Q Targets Max          105.811165
trainer/Q Targets Min          71.874146
trainer/Log Pis Mean           11.365057
trainer/Log Pis Std            6.857635
trainer/Log Pis Max            41.493343
trainer/Log Pis Min            -2.4148495
trainer/Policy mu Mean         -0.05366193
trainer/Policy mu Std          1.520984
trainer/Policy mu Max          4.627989
trainer/Policy mu Min          -4.6808004
trainer/Policy log std Mean    -0.7794023
trainer/Policy log std Std     0.28222793
trainer/Policy log std Max     -0.061747022
trainer/Policy log std Min     -2.1558845
trainer/Alpha                  0.0014296550070866942
trainer/Alpha Loss             -4.159101486206055
exploration/num steps total    2891000
exploration/num paths total    5782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8998361672173676
exploration/Rewards Std        0.10067942991161757
exploration/Rewards Max        0.978230549286028
exploration/Rewards Min        0.4917523214135021
exploration/Returns Mean       449.918083608684
exploration/Returns Std        9.224864577764581
exploration/Returns Max        464.1318311154653
exploration/Returns Min        432.1893283498101
exploration/Actions Mean       0.043185756
exploration/Actions Std        0.56957626
exploration/Actions Max        0.99983686
exploration/Actions Min        -0.9999117
exploration/Num Paths          10
exploration/Average Returns    449.918083608684
evaluation/num steps total     2890000
evaluation/num paths total     5780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8735986663283672
evaluation/Rewards Std         0.10382106762440037
evaluation/Rewards Max         0.9791654172913221
evaluation/Rewards Min         0.4946724926709933
evaluation/Returns Mean        436.7993331641836
evaluation/Returns Std         18.601252886797067
evaluation/Returns Max         472.25194508688077
evaluation/Returns Min         415.21672240169005
evaluation/ExplReturns Mean    436.7993331641836
evaluation/ExplReturns Std     18.601252886797067
evaluation/ExplReturns Max     472.25194508688077
evaluation/ExplReturns Min     415.21672240169005
evaluation/Actions Mean        0.045462
evaluation/Actions Std         0.490467
evaluation/Actions Max         0.9980787
evaluation/Actions Min         -0.9996967
evaluation/Num Paths           10
evaluation/Average Returns     436.7993331641836
time/data storing (s)          0.03175759315490723
time/evaluation sampling (s)   112.56919640209526
time/exploration sampling (s)  111.56348458305001
time/logging (s)               0.031470008194446564
time/saving (s)                0.0114829046651721
time/training (s)              9.600182161666453
time/epoch (s)                 233.80757365282625
time/total (s)                 135500.2586080646
Epoch                          577
-----------------------------  ---------------------
2023-08-02 07:36:23.700183 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 578 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3986.9727]
trainer/QF1 Loss               0.051269323
trainer/QF2 Loss               0.04307364
trainer/Policy Loss            -90.71988
trainer/Q1 Predictions Mean    102.45193
trainer/Q1 Predictions Std     1.6539897
trainer/Q1 Predictions Max     106.130264
trainer/Q1 Predictions Min     82.919525
trainer/Q2 Predictions Mean    102.40662
trainer/Q2 Predictions Std     1.6123385
trainer/Q2 Predictions Max     106.18311
trainer/Q2 Predictions Min     83.350464
trainer/Q Targets Mean         102.27604
trainer/Q Targets Std          1.6348039
trainer/Q Targets Max          106.11791
trainer/Q Targets Min          82.935646
trainer/Log Pis Mean           11.775543
trainer/Log Pis Std            8.413772
trainer/Log Pis Max            47.313778
trainer/Log Pis Min            -10.383814
trainer/Policy mu Mean         -0.13486974
trainer/Policy mu Std          1.5952823
trainer/Policy mu Max          5.102663
trainer/Policy mu Min          -5.605642
trainer/Policy log std Mean    -0.7292126
trainer/Policy log std Std     0.26928052
trainer/Policy log std Max     1.4798408
trainer/Policy log std Min     -1.9248261
trainer/Alpha                  0.0014820231590420008
trainer/Alpha Loss             -1.462207317352295
exploration/num steps total    2896000
exploration/num paths total    5792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8724994045274606
exploration/Rewards Std        0.11337044562752151
exploration/Rewards Max        0.9789962661126659
exploration/Rewards Min        0.4929945706930224
exploration/Returns Mean       436.2497022637302
exploration/Returns Std        7.837256384576904
exploration/Returns Max        445.22975921447176
exploration/Returns Min        423.7926513652013
exploration/Actions Mean       0.019876115
exploration/Actions Std        0.66633546
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999987
exploration/Num Paths          10
exploration/Average Returns    436.2497022637302
evaluation/num steps total     2895000
evaluation/num paths total     5790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8543796748119803
evaluation/Rewards Std         0.10984024103251101
evaluation/Rewards Max         0.9740894179623434
evaluation/Rewards Min         0.497869244457931
evaluation/Returns Mean        427.18983740599003
evaluation/Returns Std         5.755349770659311
evaluation/Returns Max         433.613819530618
evaluation/Returns Min         411.3811853584204
evaluation/ExplReturns Mean    427.18983740599003
evaluation/ExplReturns Std     5.755349770659311
evaluation/ExplReturns Max     433.613819530618
evaluation/ExplReturns Min     411.3811853584204
evaluation/Actions Mean        0.06519301
evaluation/Actions Std         0.5225978
evaluation/Actions Max         0.9979458
evaluation/Actions Min         -0.99938446
evaluation/Num Paths           10
evaluation/Average Returns     427.18983740599003
time/data storing (s)          0.03210855461657047
time/evaluation sampling (s)   110.2182745616883
time/exploration sampling (s)  113.88869941793382
time/logging (s)               0.030438114888966084
time/saving (s)                0.012545681558549404
time/training (s)              9.673237456008792
time/epoch (s)                 233.855303786695
time/total (s)                 135734.11637948267
Epoch                          578
-----------------------------  ---------------------
2023-08-02 07:40:16.942080 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 579 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3829.657]
trainer/QF1 Loss               0.052512452
trainer/QF2 Loss               0.028518524
trainer/Policy Loss            -90.60747
trainer/Q1 Predictions Mean    102.541565
trainer/Q1 Predictions Std     1.3301324
trainer/Q1 Predictions Max     104.47295
trainer/Q1 Predictions Min     91.02843
trainer/Q2 Predictions Mean    102.47155
trainer/Q2 Predictions Std     1.3551059
trainer/Q2 Predictions Max     104.4721
trainer/Q2 Predictions Min     90.31134
trainer/Q Targets Mean         102.38814
trainer/Q Targets Std          1.3562993
trainer/Q Targets Max          104.364334
trainer/Q Targets Min          89.317375
trainer/Log Pis Mean           11.980894
trainer/Log Pis Std            6.9337883
trainer/Log Pis Max            50.529182
trainer/Log Pis Min            -2.5686557
trainer/Policy mu Mean         -0.20955157
trainer/Policy mu Std          1.5319957
trainer/Policy mu Max          6.157913
trainer/Policy mu Min          -5.162839
trainer/Policy log std Mean    -0.752475
trainer/Policy log std Std     0.286318
trainer/Policy log std Max     0.07776779
trainer/Policy log std Min     -2.1038585
trainer/Alpha                  0.0014978792751207948
trainer/Alpha Loss             -0.12425446510314941
exploration/num steps total    2901000
exploration/num paths total    5802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8995260396584436
exploration/Rewards Std        0.10250697577702653
exploration/Rewards Max        0.9774131736238929
exploration/Rewards Min        0.4968570507228953
exploration/Returns Mean       449.7630198292219
exploration/Returns Std        34.99250916137633
exploration/Returns Max        479.4840629603347
exploration/Returns Min        397.3080887185081
exploration/Actions Mean       0.040002022
exploration/Actions Std        0.6061329
exploration/Actions Max        0.99988866
exploration/Actions Min        -0.9999867
exploration/Num Paths          10
exploration/Average Returns    449.7630198292219
evaluation/num steps total     2900000
evaluation/num paths total     5800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9078560621249706
evaluation/Rewards Std         0.09284851616494605
evaluation/Rewards Max         0.9751325286405536
evaluation/Rewards Min         0.499986863856994
evaluation/Returns Mean        453.9280310624854
evaluation/Returns Std         23.309986102087585
evaluation/Returns Max         481.4971125680691
evaluation/Returns Min         413.4598423494159
evaluation/ExplReturns Mean    453.9280310624854
evaluation/ExplReturns Std     23.309986102087585
evaluation/ExplReturns Max     481.4971125680691
evaluation/ExplReturns Min     413.4598423494159
evaluation/Actions Mean        0.03976828
evaluation/Actions Std         0.55036783
evaluation/Actions Max         0.99896777
evaluation/Actions Min         -0.9999055
evaluation/Num Paths           10
evaluation/Average Returns     453.9280310624854
time/data storing (s)          0.03203997574746609
time/evaluation sampling (s)   111.37083193659782
time/exploration sampling (s)  112.52669355925173
time/logging (s)               0.030505812726914883
time/saving (s)                0.011925432831048965
time/training (s)              9.26289333216846
time/epoch (s)                 233.23489004932344
time/total (s)                 135967.3537177192
Epoch                          579
-----------------------------  ---------------------
2023-08-02 07:44:13.123920 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 580 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3979.5383]
trainer/QF1 Loss               0.02132406
trainer/QF2 Loss               0.021540036
trainer/Policy Loss            -90.688965
trainer/Q1 Predictions Mean    102.50877
trainer/Q1 Predictions Std     1.4072789
trainer/Q1 Predictions Max     106.37368
trainer/Q1 Predictions Min     89.76842
trainer/Q2 Predictions Mean    102.38982
trainer/Q2 Predictions Std     1.4154129
trainer/Q2 Predictions Max     106.02086
trainer/Q2 Predictions Min     89.81047
trainer/Q Targets Mean         102.42447
trainer/Q Targets Std          1.4190372
trainer/Q Targets Max          106.186165
trainer/Q Targets Min          89.81919
trainer/Log Pis Mean           11.82291
trainer/Log Pis Std            7.698141
trainer/Log Pis Max            49.03206
trainer/Log Pis Min            -3.4847846
trainer/Policy mu Mean         -0.11967418
trainer/Policy mu Std          1.574192
trainer/Policy mu Max          6.8193808
trainer/Policy mu Min          -5.833152
trainer/Policy log std Mean    -0.77743554
trainer/Policy log std Std     0.29314616
trainer/Policy log std Max     0.37723058
trainer/Policy log std Min     -2.086656
trainer/Alpha                  0.001545930397696793
trainer/Alpha Loss             -1.1461073160171509
exploration/num steps total    2906000
exploration/num paths total    5812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.961811421331156
exploration/Rewards Std        0.05049687930446477
exploration/Rewards Max        0.9778383783740255
exploration/Rewards Min        0.4965274063181741
exploration/Returns Mean       480.90571066557794
exploration/Returns Std        2.340919174433724
exploration/Returns Max        482.825292374633
exploration/Returns Min        476.2809578568258
exploration/Actions Mean       0.007261547
exploration/Actions Std        0.57920355
exploration/Actions Max        0.99989873
exploration/Actions Min        -0.99994105
exploration/Num Paths          10
exploration/Average Returns    480.90571066557794
evaluation/num steps total     2905000
evaluation/num paths total     5810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9544835960047425
evaluation/Rewards Std         0.05057671897733192
evaluation/Rewards Max         0.9747881579151289
evaluation/Rewards Min         0.49789195111530726
evaluation/Returns Mean        477.2417980023712
evaluation/Returns Std         2.68975056667698
evaluation/Returns Max         482.8587392564537
evaluation/Returns Min         470.9333973781458
evaluation/ExplReturns Mean    477.2417980023712
evaluation/ExplReturns Std     2.68975056667698
evaluation/ExplReturns Max     482.8587392564537
evaluation/ExplReturns Min     470.9333973781458
evaluation/Actions Mean        0.13596058
evaluation/Actions Std         0.51423675
evaluation/Actions Max         0.999676
evaluation/Actions Min         -0.9995527
evaluation/Num Paths           10
evaluation/Average Returns     477.2417980023712
time/data storing (s)          0.03216988127678633
time/evaluation sampling (s)   113.08644306659698
time/exploration sampling (s)  113.41619488131255
time/logging (s)               0.030477833934128284
time/saving (s)                0.010223431512713432
time/training (s)              9.599174793809652
time/epoch (s)                 236.17468388844281
time/total (s)                 136203.53089076374
Epoch                          580
-----------------------------  --------------------
2023-08-02 07:48:06.661661 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 581 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3914.9458]
trainer/QF1 Loss               0.039896447
trainer/QF2 Loss               0.058951482
trainer/Policy Loss            -89.849335
trainer/Q1 Predictions Mean    102.37584
trainer/Q1 Predictions Std     1.8813593
trainer/Q1 Predictions Max     104.38268
trainer/Q1 Predictions Min     81.49865
trainer/Q2 Predictions Mean    102.41867
trainer/Q2 Predictions Std     1.8155537
trainer/Q2 Predictions Max     104.370056
trainer/Q2 Predictions Min     82.959076
trainer/Q Targets Mean         102.251785
trainer/Q Targets Std          1.8342429
trainer/Q Targets Max          104.235115
trainer/Q Targets Min          82.149445
trainer/Log Pis Mean           12.630706
trainer/Log Pis Std            7.343899
trainer/Log Pis Max            45.202347
trainer/Log Pis Min            -6.24158
trainer/Policy mu Mean         -0.19404154
trainer/Policy mu Std          1.5981877
trainer/Policy mu Max          8.06793
trainer/Policy mu Min          -4.841501
trainer/Policy log std Mean    -0.76631576
trainer/Policy log std Std     0.2942682
trainer/Policy log std Max     0.32191718
trainer/Policy log std Min     -2.0379918
trainer/Alpha                  0.0014448425499722362
trainer/Alpha Loss             4.124752521514893
exploration/num steps total    2911000
exploration/num paths total    5822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9655096549263137
exploration/Rewards Std        0.05104788814373856
exploration/Rewards Max        0.9797994043084262
exploration/Rewards Min        0.4941811358964538
exploration/Returns Mean       482.75482746315686
exploration/Returns Std        0.3224649181852904
exploration/Returns Max        483.53509436738653
exploration/Returns Min        482.28136026325853
exploration/Actions Mean       0.10178679
exploration/Actions Std        0.5736043
exploration/Actions Max        0.9998021
exploration/Actions Min        -0.9999437
exploration/Num Paths          10
exploration/Average Returns    482.75482746315686
evaluation/num steps total     2910000
evaluation/num paths total     5820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9627145897886447
evaluation/Rewards Std         0.05115826757666459
evaluation/Rewards Max         0.9784382224105133
evaluation/Rewards Min         0.4831427189815604
evaluation/Returns Mean        481.3572948943223
evaluation/Returns Std         0.4859825072739702
evaluation/Returns Max         481.962992133067
evaluation/Returns Min         480.3107272758806
evaluation/ExplReturns Mean    481.3572948943223
evaluation/ExplReturns Std     0.4859825072739702
evaluation/ExplReturns Max     481.962992133067
evaluation/ExplReturns Min     480.3107272758806
evaluation/Actions Mean        0.10904346
evaluation/Actions Std         0.4823101
evaluation/Actions Max         0.99903363
evaluation/Actions Min         -0.99962527
evaluation/Num Paths           10
evaluation/Average Returns     481.3572948943223
time/data storing (s)          0.031980485655367374
time/evaluation sampling (s)   111.66600251663476
time/exploration sampling (s)  112.14598630554974
time/logging (s)               0.030921139754354954
time/saving (s)                0.012142150662839413
time/training (s)              9.643760040402412
time/epoch (s)                 233.53079263865948
time/total (s)                 136437.0643884521
Epoch                          581
-----------------------------  ---------------------
2023-08-02 07:52:02.561766 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 582 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3749.648]
trainer/QF1 Loss               0.025071084
trainer/QF2 Loss               0.019876597
trainer/Policy Loss            -90.74045
trainer/Q1 Predictions Mean    102.268745
trainer/Q1 Predictions Std     1.5352223
trainer/Q1 Predictions Max     103.87103
trainer/Q1 Predictions Min     91.50377
trainer/Q2 Predictions Mean    102.17713
trainer/Q2 Predictions Std     1.5547593
trainer/Q2 Predictions Max     103.802574
trainer/Q2 Predictions Min     91.58205
trainer/Q Targets Mean         102.17221
trainer/Q Targets Std          1.5648583
trainer/Q Targets Max          103.78121
trainer/Q Targets Min          90.85687
trainer/Log Pis Mean           11.552295
trainer/Log Pis Std            8.133653
trainer/Log Pis Max            66.1363
trainer/Log Pis Min            -2.8267322
trainer/Policy mu Mean         -0.163075
trainer/Policy mu Std          1.5420536
trainer/Policy mu Max          6.609133
trainer/Policy mu Min          -5.51435
trainer/Policy log std Mean    -0.7846696
trainer/Policy log std Std     0.29203647
trainer/Policy log std Max     0.1932534
trainer/Policy log std Min     -1.9569938
trainer/Alpha                  0.0014465074054896832
trainer/Alpha Loss             -2.9273123741149902
exploration/num steps total    2916000
exploration/num paths total    5832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9611363250400599
exploration/Rewards Std        0.05187465429023981
exploration/Rewards Max        0.9794522824520412
exploration/Rewards Min        0.4943274628983897
exploration/Returns Mean       480.56816252002983
exploration/Returns Std        0.6105378877903064
exploration/Returns Max        481.8094481429056
exploration/Returns Min        479.78217104313956
exploration/Actions Mean       0.039075274
exploration/Actions Std        0.5721786
exploration/Actions Max        0.99993694
exploration/Actions Min        -0.99995524
exploration/Num Paths          10
exploration/Average Returns    480.56816252002983
evaluation/num steps total     2915000
evaluation/num paths total     5830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9635107285758242
evaluation/Rewards Std         0.05118643152410512
evaluation/Rewards Max         0.9795885918026852
evaluation/Rewards Min         0.4890666956910078
evaluation/Returns Mean        481.75536428791213
evaluation/Returns Std         1.4255839909377857
evaluation/Returns Max         484.14433426054035
evaluation/Returns Min         480.28988695241975
evaluation/ExplReturns Mean    481.75536428791213
evaluation/ExplReturns Std     1.4255839909377857
evaluation/ExplReturns Max     484.14433426054035
evaluation/ExplReturns Min     480.28988695241975
evaluation/Actions Mean        0.015598734
evaluation/Actions Std         0.4449234
evaluation/Actions Max         0.9995534
evaluation/Actions Min         -0.9998715
evaluation/Num Paths           10
evaluation/Average Returns     481.75536428791213
time/data storing (s)          0.032250006683170795
time/evaluation sampling (s)   113.44852854683995
time/exploration sampling (s)  112.77541353181005
time/logging (s)               0.030571003444492817
time/saving (s)                0.012699740938842297
time/training (s)              9.592916548252106
time/epoch (s)                 235.8923793779686
time/total (s)                 136672.95945844613
Epoch                          582
-----------------------------  ---------------------
2023-08-02 07:55:55.065793 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 583 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3562.4763]
trainer/QF1 Loss               0.022741549
trainer/QF2 Loss               0.02302859
trainer/Policy Loss            -89.862175
trainer/Q1 Predictions Mean    102.06983
trainer/Q1 Predictions Std     1.913563
trainer/Q1 Predictions Max     103.918434
trainer/Q1 Predictions Min     89.42981
trainer/Q2 Predictions Mean    102.05293
trainer/Q2 Predictions Std     1.8526083
trainer/Q2 Predictions Max     103.80933
trainer/Q2 Predictions Min     89.61525
trainer/Q Targets Mean         102.09407
trainer/Q Targets Std          1.891318
trainer/Q Targets Max          103.823845
trainer/Q Targets Min          89.54649
trainer/Log Pis Mean           12.293857
trainer/Log Pis Std            8.7062435
trainer/Log Pis Max            63.39073
trainer/Log Pis Min            -3.7566783
trainer/Policy mu Mean         -0.10565945
trainer/Policy mu Std          1.596598
trainer/Policy mu Max          6.6150026
trainer/Policy mu Min          -9.523562
trainer/Policy log std Mean    -0.77497655
trainer/Policy log std Std     0.3195707
trainer/Policy log std Max     1.0622642
trainer/Policy log std Min     -2.2620513
trainer/Alpha                  0.0014556379755958915
trainer/Alpha Loss             1.9195759296417236
exploration/num steps total    2921000
exploration/num paths total    5842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.960692826871384
exploration/Rewards Std        0.050647660448044196
exploration/Rewards Max        0.9793086533184416
exploration/Rewards Min        0.487908488437822
exploration/Returns Mean       480.34641343569183
exploration/Returns Std        0.8905599269489016
exploration/Returns Max        481.4007875013616
exploration/Returns Min        478.923337651957
exploration/Actions Mean       0.039944213
exploration/Actions Std        0.6012817
exploration/Actions Max        0.9999299
exploration/Actions Min        -0.9999082
exploration/Num Paths          10
exploration/Average Returns    480.34641343569183
evaluation/num steps total     2920000
evaluation/num paths total     5840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9576617671108055
evaluation/Rewards Std         0.05589280155725247
evaluation/Rewards Max         0.9781203337116628
evaluation/Rewards Min         0.4899902154142748
evaluation/Returns Mean        478.83088355540286
evaluation/Returns Std         5.0936714152948985
evaluation/Returns Max         481.01229647230866
evaluation/Returns Min         463.5696374410804
evaluation/ExplReturns Mean    478.83088355540286
evaluation/ExplReturns Std     5.0936714152948985
evaluation/ExplReturns Max     481.01229647230866
evaluation/ExplReturns Min     463.5696374410804
evaluation/Actions Mean        0.0608733
evaluation/Actions Std         0.51345056
evaluation/Actions Max         0.99964887
evaluation/Actions Min         -0.999768
evaluation/Num Paths           10
evaluation/Average Returns     478.83088355540286
time/data storing (s)          0.03168243728578091
time/evaluation sampling (s)   111.14922160841525
time/exploration sampling (s)  111.62846805062145
time/logging (s)               0.03149963077157736
time/saving (s)                0.012807287275791168
time/training (s)              9.64398717135191
time/epoch (s)                 232.49766618572176
time/total (s)                 136905.4597651912
Epoch                          583
-----------------------------  ---------------------
2023-08-02 07:59:47.826600 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 584 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3792.3843]
trainer/QF1 Loss               0.019386198
trainer/QF2 Loss               0.023713738
trainer/Policy Loss            -90.39021
trainer/Q1 Predictions Mean    102.190704
trainer/Q1 Predictions Std     2.2223527
trainer/Q1 Predictions Max     103.75898
trainer/Q1 Predictions Min     81.705246
trainer/Q2 Predictions Mean    102.19654
trainer/Q2 Predictions Std     2.2072647
trainer/Q2 Predictions Max     103.81828
trainer/Q2 Predictions Min     81.69663
trainer/Q Targets Mean         102.1575
trainer/Q Targets Std          2.1986654
trainer/Q Targets Max          103.82734
trainer/Q Targets Min          81.83231
trainer/Log Pis Mean           11.898032
trainer/Log Pis Std            8.2770195
trainer/Log Pis Max            44.894367
trainer/Log Pis Min            -7.320991
trainer/Policy mu Mean         -0.14829135
trainer/Policy mu Std          1.5750167
trainer/Policy mu Max          7.226616
trainer/Policy mu Min          -6.0189366
trainer/Policy log std Mean    -0.7468784
trainer/Policy log std Std     0.28781652
trainer/Policy log std Max     0.06417769
trainer/Policy log std Min     -2.094059
trainer/Alpha                  0.0014764114748686552
trainer/Alpha Loss             -0.664644718170166
exploration/num steps total    2926000
exploration/num paths total    5852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9579625609784356
exploration/Rewards Std        0.04966751575025189
exploration/Rewards Max        0.9792359306735913
exploration/Rewards Min        0.48704429056487913
exploration/Returns Mean       478.98128048921774
exploration/Returns Std        0.414009817136483
exploration/Returns Max        479.90643952046014
exploration/Returns Min        478.16802059591674
exploration/Actions Mean       0.013176648
exploration/Actions Std        0.5752308
exploration/Actions Max        0.99984723
exploration/Actions Min        -0.9998508
exploration/Num Paths          10
exploration/Average Returns    478.98128048921774
evaluation/num steps total     2925000
evaluation/num paths total     5850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9643781401090744
evaluation/Rewards Std         0.050941980980063736
evaluation/Rewards Max         0.9782153257068077
evaluation/Rewards Min         0.4986833938285208
evaluation/Returns Mean        482.1890700545371
evaluation/Returns Std         1.72298265418111
evaluation/Returns Max         484.22874636597913
evaluation/Returns Min         479.56343993603343
evaluation/ExplReturns Mean    482.1890700545371
evaluation/ExplReturns Std     1.72298265418111
evaluation/ExplReturns Max     484.22874636597913
evaluation/ExplReturns Min     479.56343993603343
evaluation/Actions Mean        -0.049516317
evaluation/Actions Std         0.5012718
evaluation/Actions Max         0.99923784
evaluation/Actions Min         -0.9994429
evaluation/Num Paths           10
evaluation/Average Returns     482.1890700545371
time/data storing (s)          0.03234341833740473
time/evaluation sampling (s)   111.03229002747685
time/exploration sampling (s)  111.85693267732859
time/logging (s)               0.03116498328745365
time/saving (s)                0.012929491698741913
time/training (s)              9.787524906918406
time/epoch (s)                 232.75318550504744
time/total (s)                 137138.21552625112
Epoch                          584
-----------------------------  ---------------------
2023-08-02 08:03:42.162773 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 585 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3545.4033]
trainer/QF1 Loss               0.017039292
trainer/QF2 Loss               0.010920263
trainer/Policy Loss            -91.4462
trainer/Q1 Predictions Mean    102.578575
trainer/Q1 Predictions Std     1.0069017
trainer/Q1 Predictions Max     103.70125
trainer/Q1 Predictions Min     94.84337
trainer/Q2 Predictions Mean    102.50818
trainer/Q2 Predictions Std     1.0037192
trainer/Q2 Predictions Max     103.602806
trainer/Q2 Predictions Min     94.83436
trainer/Q Targets Mean         102.513535
trainer/Q Targets Std          1.0378219
trainer/Q Targets Max          103.69849
trainer/Q Targets Min          94.11703
trainer/Log Pis Mean           11.160678
trainer/Log Pis Std            7.4387827
trainer/Log Pis Max            41.84418
trainer/Log Pis Min            -6.717973
trainer/Policy mu Mean         -0.09587968
trainer/Policy mu Std          1.5406891
trainer/Policy mu Max          5.029487
trainer/Policy mu Min          -4.6607003
trainer/Policy log std Mean    -0.7635045
trainer/Policy log std Std     0.29685298
trainer/Policy log std Max     0.10013318
trainer/Policy log std Min     -2.0378306
trainer/Alpha                  0.0014182832092046738
trainer/Alpha Loss             -5.504443168640137
exploration/num steps total    2931000
exploration/num paths total    5862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557707184383806
exploration/Rewards Std        0.047589771657563486
exploration/Rewards Max        0.9776383335136907
exploration/Rewards Min        0.4953556128985488
exploration/Returns Mean       477.8853592191904
exploration/Returns Std        0.6096795262919477
exploration/Returns Max        479.02580400077
exploration/Returns Min        477.06864477183507
exploration/Actions Mean       0.012780411
exploration/Actions Std        0.59301305
exploration/Actions Max        0.99980646
exploration/Actions Min        -0.9999033
exploration/Num Paths          10
exploration/Average Returns    477.8853592191904
evaluation/num steps total     2930000
evaluation/num paths total     5860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9624830675449182
evaluation/Rewards Std         0.04890114957395656
evaluation/Rewards Max         0.9790454835794574
evaluation/Rewards Min         0.4850334091333231
evaluation/Returns Mean        481.2415337724591
evaluation/Returns Std         0.7376869392708117
evaluation/Returns Max         482.7766546111408
evaluation/Returns Min         480.2776993658734
evaluation/ExplReturns Mean    481.2415337724591
evaluation/ExplReturns Std     0.7376869392708117
evaluation/ExplReturns Max     482.7766546111408
evaluation/ExplReturns Min     480.2776993658734
evaluation/Actions Mean        -0.0042820037
evaluation/Actions Std         0.48197082
evaluation/Actions Max         0.9988736
evaluation/Actions Min         -0.999455
evaluation/Num Paths           10
evaluation/Average Returns     481.2415337724591
time/data storing (s)          0.03226247802376747
time/evaluation sampling (s)   112.12355392705649
time/exploration sampling (s)  112.88435730803758
time/logging (s)               0.03127677459269762
time/saving (s)                0.01096086110919714
time/training (s)              9.246623162180185
time/epoch (s)                 234.32903451099992
time/total (s)                 137372.54706197605
Epoch                          585
-----------------------------  ---------------------
2023-08-02 08:07:37.605126 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 586 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3629.2832]
trainer/QF1 Loss               0.02003688
trainer/QF2 Loss               0.012200647
trainer/Policy Loss            -91.20047
trainer/Q1 Predictions Mean    102.20735
trainer/Q1 Predictions Std     1.6278012
trainer/Q1 Predictions Max     103.54029
trainer/Q1 Predictions Min     88.97208
trainer/Q2 Predictions Mean    102.29077
trainer/Q2 Predictions Std     1.6010152
trainer/Q2 Predictions Max     103.553314
trainer/Q2 Predictions Min     89.28402
trainer/Q Targets Mean         102.28932
trainer/Q Targets Std          1.6097018
trainer/Q Targets Max          103.51244
trainer/Q Targets Min          89.39594
trainer/Log Pis Mean           11.126465
trainer/Log Pis Std            7.8385053
trainer/Log Pis Max            39.680603
trainer/Log Pis Min            -6.707652
trainer/Policy mu Mean         -0.069630325
trainer/Policy mu Std          1.5645434
trainer/Policy mu Max          5.5714045
trainer/Policy mu Min          -4.667215
trainer/Policy log std Mean    -0.71310043
trainer/Policy log std Std     0.27762967
trainer/Policy log std Max     0.039087318
trainer/Policy log std Min     -2.0935922
trainer/Alpha                  0.0014692102558910847
trainer/Alpha Loss             -5.697995185852051
exploration/num steps total    2936000
exploration/num paths total    5872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9554998744328655
exploration/Rewards Std        0.05170662540512726
exploration/Rewards Max        0.9780647776214103
exploration/Rewards Min        0.4868045097290077
exploration/Returns Mean       477.74993721643267
exploration/Returns Std        1.5813158619878578
exploration/Returns Max        478.9514793114203
exploration/Returns Min        473.18660462429546
exploration/Actions Mean       0.015541275
exploration/Actions Std        0.59687257
exploration/Actions Max        0.99993014
exploration/Actions Min        -0.99993837
exploration/Num Paths          10
exploration/Average Returns    477.74993721643267
evaluation/num steps total     2935000
evaluation/num paths total     5870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9579503660965616
evaluation/Rewards Std         0.04922160977366076
evaluation/Rewards Max         0.9787710194808574
evaluation/Rewards Min         0.49145125494842906
evaluation/Returns Mean        478.9751830482807
evaluation/Returns Std         0.28744730669139723
evaluation/Returns Max         479.66996048577107
evaluation/Returns Min         478.5219677838477
evaluation/ExplReturns Mean    478.9751830482807
evaluation/ExplReturns Std     0.28744730669139723
evaluation/ExplReturns Max     479.66996048577107
evaluation/ExplReturns Min     478.5219677838477
evaluation/Actions Mean        -0.009590966
evaluation/Actions Std         0.43035945
evaluation/Actions Max         0.9985872
evaluation/Actions Min         -0.99911267
evaluation/Num Paths           10
evaluation/Average Returns     478.9751830482807
time/data storing (s)          0.03533657267689705
time/evaluation sampling (s)   112.51338013354689
time/exploration sampling (s)  113.29461906570941
time/logging (s)               0.03139687329530716
time/saving (s)                0.012668314389884472
time/training (s)              9.547824093140662
time/epoch (s)                 235.43522505275905
time/total (s)                 137607.9847437078
Epoch                          586
-----------------------------  ---------------------
2023-08-02 08:11:34.719273 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 587 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3670.7607]
trainer/QF1 Loss               0.030340718
trainer/QF2 Loss               0.01718552
trainer/Policy Loss            -89.76454
trainer/Q1 Predictions Mean    102.226
trainer/Q1 Predictions Std     1.7743822
trainer/Q1 Predictions Max     103.62589
trainer/Q1 Predictions Min     84.19029
trainer/Q2 Predictions Mean    102.231636
trainer/Q2 Predictions Std     1.7838392
trainer/Q2 Predictions Max     103.617516
trainer/Q2 Predictions Min     84.041
trainer/Q Targets Mean         102.21091
trainer/Q Targets Std          1.7860036
trainer/Q Targets Max          103.620926
trainer/Q Targets Min          84.17664
trainer/Log Pis Mean           12.552349
trainer/Log Pis Std            8.243738
trainer/Log Pis Max            67.11722
trainer/Log Pis Min            -4.296831
trainer/Policy mu Mean         -0.06791609
trainer/Policy mu Std          1.619952
trainer/Policy mu Max          6.4551067
trainer/Policy mu Min          -6.0170403
trainer/Policy log std Mean    -0.75979584
trainer/Policy log std Std     0.30700403
trainer/Policy log std Max     0.4027455
trainer/Policy log std Min     -2.2320373
trainer/Alpha                  0.00138962478376925
trainer/Alpha Loss             3.6337220668792725
exploration/num steps total    2941000
exploration/num paths total    5882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9615214161073105
exploration/Rewards Std        0.04815458006224924
exploration/Rewards Max        0.9787889164607428
exploration/Rewards Min        0.4940783189836948
exploration/Returns Mean       480.76070805365526
exploration/Returns Std        0.48930461929194713
exploration/Returns Max        481.46292001210935
exploration/Returns Min        479.9709556477296
exploration/Actions Mean       0.087861635
exploration/Actions Std        0.6058958
exploration/Actions Max        0.9995925
exploration/Actions Min        -0.9999217
exploration/Num Paths          10
exploration/Average Returns    480.76070805365526
evaluation/num steps total     2940000
evaluation/num paths total     5880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9662202073752709
evaluation/Rewards Std         0.04821092454245426
evaluation/Rewards Max         0.9769586532159178
evaluation/Rewards Min         0.4975272638912352
evaluation/Returns Mean        483.11010368763544
evaluation/Returns Std         0.18391877107866186
evaluation/Returns Max         483.39367735766604
evaluation/Returns Min         482.81718924188664
evaluation/ExplReturns Mean    483.11010368763544
evaluation/ExplReturns Std     0.18391877107866186
evaluation/ExplReturns Max     483.39367735766604
evaluation/ExplReturns Min     482.81718924188664
evaluation/Actions Mean        0.121616684
evaluation/Actions Std         0.5539682
evaluation/Actions Max         0.9983377
evaluation/Actions Min         -0.99929917
evaluation/Num Paths           10
evaluation/Average Returns     483.11010368763544
time/data storing (s)          0.03232002165168524
time/evaluation sampling (s)   112.50427925027907
time/exploration sampling (s)  114.81969153694808
time/logging (s)               0.0308261439204216
time/saving (s)                0.010455372743308544
time/training (s)              9.708739383146167
time/epoch (s)                 237.10631170868874
time/total (s)                 137845.09357280657
Epoch                          587
-----------------------------  --------------------
2023-08-02 08:15:30.376484 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 588 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3561.2834]
trainer/QF1 Loss               0.01671724
trainer/QF2 Loss               0.03960122
trainer/Policy Loss            -90.94832
trainer/Q1 Predictions Mean    102.3798
trainer/Q1 Predictions Std     1.5780218
trainer/Q1 Predictions Max     103.53256
trainer/Q1 Predictions Min     84.41183
trainer/Q2 Predictions Mean    102.22667
trainer/Q2 Predictions Std     1.6133457
trainer/Q2 Predictions Max     103.37786
trainer/Q2 Predictions Min     83.80405
trainer/Q Targets Mean         102.36255
trainer/Q Targets Std          1.5485654
trainer/Q Targets Max          103.46929
trainer/Q Targets Min          85.19842
trainer/Log Pis Mean           11.403545
trainer/Log Pis Std            7.706742
trainer/Log Pis Max            54.46644
trainer/Log Pis Min            -4.1309586
trainer/Policy mu Mean         -0.08236902
trainer/Policy mu Std          1.5646416
trainer/Policy mu Max          11.939129
trainer/Policy mu Min          -6.615121
trainer/Policy log std Mean    -0.73276615
trainer/Policy log std Std     0.30759183
trainer/Policy log std Max     1.5639008
trainer/Policy log std Min     -2.202512
trainer/Alpha                  0.0013577460777014494
trainer/Alpha Loss             -3.937777042388916
exploration/num steps total    2946000
exploration/num paths total    5892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9568943038278641
exploration/Rewards Std        0.04811067171834516
exploration/Rewards Max        0.9794161702336157
exploration/Rewards Min        0.5004872874170115
exploration/Returns Mean       478.44715191393215
exploration/Returns Std        0.6676085774995392
exploration/Returns Max        480.26524857673485
exploration/Returns Min        477.7487196647026
exploration/Actions Mean       -0.0172385
exploration/Actions Std        0.60943085
exploration/Actions Max        0.99990124
exploration/Actions Min        -0.999963
exploration/Num Paths          10
exploration/Average Returns    478.44715191393215
evaluation/num steps total     2945000
evaluation/num paths total     5890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9556747665644456
evaluation/Rewards Std         0.047636141849852424
evaluation/Rewards Max         0.9791472927592647
evaluation/Rewards Min         0.49933358057953436
evaluation/Returns Mean        477.83738328222273
evaluation/Returns Std         0.18382080722719374
evaluation/Returns Max         478.0826623725609
evaluation/Returns Min         477.54171190087766
evaluation/ExplReturns Mean    477.83738328222273
evaluation/ExplReturns Std     0.18382080722719374
evaluation/ExplReturns Max     478.0826623725609
evaluation/ExplReturns Min     477.54171190087766
evaluation/Actions Mean        -0.008120165
evaluation/Actions Std         0.4092754
evaluation/Actions Max         0.99906147
evaluation/Actions Min         -0.9993639
evaluation/Num Paths           10
evaluation/Average Returns     477.83738328222273
time/data storing (s)          0.031945377588272095
time/evaluation sampling (s)   113.80133820604533
time/exploration sampling (s)  112.24032178614289
time/logging (s)               0.03061769250780344
time/saving (s)                0.012567824684083462
time/training (s)              9.5330101698637
time/epoch (s)                 235.64980105683208
time/total (s)                 138080.7458983818
Epoch                          588
-----------------------------  ---------------------
2023-08-02 08:19:23.346169 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 589 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3507.5955]
trainer/QF1 Loss               0.016964369
trainer/QF2 Loss               0.018253792
trainer/Policy Loss            -89.321175
trainer/Q1 Predictions Mean    102.18668
trainer/Q1 Predictions Std     2.0548284
trainer/Q1 Predictions Max     103.422806
trainer/Q1 Predictions Min     83.636856
trainer/Q2 Predictions Mean    102.181595
trainer/Q2 Predictions Std     2.0782912
trainer/Q2 Predictions Max     103.33867
trainer/Q2 Predictions Min     83.044525
trainer/Q Targets Mean         102.20505
trainer/Q Targets Std          2.0701325
trainer/Q Targets Max          103.44453
trainer/Q Targets Min          83.50988
trainer/Log Pis Mean           12.949043
trainer/Log Pis Std            9.060729
trainer/Log Pis Max            62.325863
trainer/Log Pis Min            -2.679536
trainer/Policy mu Mean         0.07574461
trainer/Policy mu Std          1.6361957
trainer/Policy mu Max          7.8873506
trainer/Policy mu Min          -6.2232437
trainer/Policy log std Mean    -0.7561445
trainer/Policy log std Std     0.2911426
trainer/Policy log std Max     0.4152915
trainer/Policy log std Min     -2.0785635
trainer/Alpha                  0.0014347415417432785
trainer/Alpha Loss             6.213504314422607
exploration/num steps total    2951000
exploration/num paths total    5902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9566231935092726
exploration/Rewards Std        0.05086579566747903
exploration/Rewards Max        0.9796233535277274
exploration/Rewards Min        0.49369669518053794
exploration/Returns Mean       478.31159675463624
exploration/Returns Std        0.8682675671531758
exploration/Returns Max        479.57156630050514
exploration/Returns Min        476.8574577526486
exploration/Actions Mean       0.03642021
exploration/Actions Std        0.59294397
exploration/Actions Max        0.99981546
exploration/Actions Min        -0.9999786
exploration/Num Paths          10
exploration/Average Returns    478.31159675463624
evaluation/num steps total     2950000
evaluation/num paths total     5900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.956593812762579
evaluation/Rewards Std         0.05191726698465828
evaluation/Rewards Max         0.9794595559290035
evaluation/Rewards Min         0.49894677531344683
evaluation/Returns Mean        478.2969063812896
evaluation/Returns Std         1.9091605434372845
evaluation/Returns Max         483.80027641933947
evaluation/Returns Min         476.84265619891846
evaluation/ExplReturns Mean    478.2969063812896
evaluation/ExplReturns Std     1.9091605434372845
evaluation/ExplReturns Max     483.80027641933947
evaluation/ExplReturns Min     476.84265619891846
evaluation/Actions Mean        0.022018787
evaluation/Actions Std         0.42525756
evaluation/Actions Max         0.99909705
evaluation/Actions Min         -0.9998808
evaluation/Num Paths           10
evaluation/Average Returns     478.2969063812896
time/data storing (s)          0.03236090298742056
time/evaluation sampling (s)   111.84599355235696
time/exploration sampling (s)  111.4362483555451
time/logging (s)               0.030718082562088966
time/saving (s)                0.012025803327560425
time/training (s)              9.605202949605882
time/epoch (s)                 232.962549646385
time/total (s)                 138313.71090729255
Epoch                          589
-----------------------------  ---------------------
2023-08-02 08:23:18.385577 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 590 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3388.1875]
trainer/QF1 Loss               0.027417965
trainer/QF2 Loss               0.027866635
trainer/Policy Loss            -91.46647
trainer/Q1 Predictions Mean    102.34002
trainer/Q1 Predictions Std     2.7895331
trainer/Q1 Predictions Max     105.4438
trainer/Q1 Predictions Min     65.388245
trainer/Q2 Predictions Mean    102.33508
trainer/Q2 Predictions Std     2.8140838
trainer/Q2 Predictions Max     105.220924
trainer/Q2 Predictions Min     65.164085
trainer/Q Targets Mean         102.25476
trainer/Q Targets Std          2.8561904
trainer/Q Targets Max          105.108086
trainer/Q Targets Min          64.37885
trainer/Log Pis Mean           10.965677
trainer/Log Pis Std            8.75724
trainer/Log Pis Max            74.354454
trainer/Log Pis Min            -4.608679
trainer/Policy mu Mean         0.05062595
trainer/Policy mu Std          1.5490483
trainer/Policy mu Max          9.995352
trainer/Policy mu Min          -11.031005
trainer/Policy log std Mean    -0.7717387
trainer/Policy log std Std     0.28729153
trainer/Policy log std Max     -0.0089688
trainer/Policy log std Min     -2.447131
trainer/Alpha                  0.0013748877681791782
trainer/Alpha Loss             -6.8154191970825195
exploration/num steps total    2956000
exploration/num paths total    5912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9617217506449277
exploration/Rewards Std        0.0486944788875133
exploration/Rewards Max        0.9788125022325572
exploration/Rewards Min        0.4942671731959089
exploration/Returns Mean       480.86087532246376
exploration/Returns Std        0.5003294373052326
exploration/Returns Max        481.6478543624
exploration/Returns Min        479.6920732250163
exploration/Actions Mean       -0.019121908
exploration/Actions Std        0.59237117
exploration/Actions Max        0.9996947
exploration/Actions Min        -0.999906
exploration/Num Paths          10
exploration/Average Returns    480.86087532246376
evaluation/num steps total     2955000
evaluation/num paths total     5910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9638230492585163
evaluation/Rewards Std         0.04846204226521293
evaluation/Rewards Max         0.9785789473094149
evaluation/Rewards Min         0.4951081929122479
evaluation/Returns Mean        481.91152462925794
evaluation/Returns Std         0.1362645726352834
evaluation/Returns Max         482.0360926136285
evaluation/Returns Min         481.5670444231534
evaluation/ExplReturns Mean    481.91152462925794
evaluation/ExplReturns Std     0.1362645726352834
evaluation/ExplReturns Max     482.0360926136285
evaluation/ExplReturns Min     481.5670444231534
evaluation/Actions Mean        0.08013204
evaluation/Actions Std         0.5627574
evaluation/Actions Max         0.99908996
evaluation/Actions Min         -0.99946237
evaluation/Num Paths           10
evaluation/Average Returns     481.91152462925794
time/data storing (s)          0.0322786895558238
time/evaluation sampling (s)   112.85599733144045
time/exploration sampling (s)  112.5068042119965
time/logging (s)               0.030979227274656296
time/saving (s)                0.011117844842374325
time/training (s)              9.595227325335145
time/epoch (s)                 235.03240463044494
time/total (s)                 138548.74580406304
Epoch                          590
-----------------------------  ---------------------
2023-08-02 08:27:13.153680 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 591 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3769.1458]
trainer/QF1 Loss               0.018366478
trainer/QF2 Loss               0.016863419
trainer/Policy Loss            -90.74562
trainer/Q1 Predictions Mean    102.35085
trainer/Q1 Predictions Std     1.403872
trainer/Q1 Predictions Max     103.33316
trainer/Q1 Predictions Min     89.28925
trainer/Q2 Predictions Mean    102.34098
trainer/Q2 Predictions Std     1.3665805
trainer/Q2 Predictions Max     103.34851
trainer/Q2 Predictions Min     89.42849
trainer/Q Targets Mean         102.33296
trainer/Q Targets Std          1.3962842
trainer/Q Targets Max          103.322845
trainer/Q Targets Min          89.12277
trainer/Log Pis Mean           11.694945
trainer/Log Pis Std            7.5528407
trainer/Log Pis Max            41.17148
trainer/Log Pis Min            -3.9259148
trainer/Policy mu Mean         0.012763411
trainer/Policy mu Std          1.5667787
trainer/Policy mu Max          4.9077883
trainer/Policy mu Min          -6.772337
trainer/Policy log std Mean    -0.75053865
trainer/Policy log std Std     0.30193186
trainer/Policy log std Max     0.084926724
trainer/Policy log std Min     -2.2198284
trainer/Alpha                  0.0013742729788646102
trainer/Alpha Loss             -2.0102386474609375
exploration/num steps total    2961000
exploration/num paths total    5922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9495254708688692
exploration/Rewards Std        0.061578061040939644
exploration/Rewards Max        0.9797799905284311
exploration/Rewards Min        0.4827257079297619
exploration/Returns Mean       474.7627354344346
exploration/Returns Std        10.692153471183781
exploration/Returns Max        478.86946836275075
exploration/Returns Min        442.71803021698156
exploration/Actions Mean       -0.090990424
exploration/Actions Std        0.57588273
exploration/Actions Max        0.99999326
exploration/Actions Min        -0.99999964
exploration/Num Paths          10
exploration/Average Returns    474.7627354344346
evaluation/num steps total     2960000
evaluation/num paths total     5920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.957068940646514
evaluation/Rewards Std         0.049469618502898445
evaluation/Rewards Max         0.9777238216489126
evaluation/Rewards Min         0.4880103997313042
evaluation/Returns Mean        478.5344703232571
evaluation/Returns Std         1.2059856423327013
evaluation/Returns Max         480.3743428554674
evaluation/Returns Min         477.1668279657554
evaluation/ExplReturns Mean    478.5344703232571
evaluation/ExplReturns Std     1.2059856423327013
evaluation/ExplReturns Max     480.3743428554674
evaluation/ExplReturns Min     477.1668279657554
evaluation/Actions Mean        -0.07524044
evaluation/Actions Std         0.44939023
evaluation/Actions Max         0.99836284
evaluation/Actions Min         -0.9996071
evaluation/Num Paths           10
evaluation/Average Returns     478.5344703232571
time/data storing (s)          0.03192056529223919
time/evaluation sampling (s)   111.90650163777173
time/exploration sampling (s)  113.1610429706052
time/logging (s)               0.030856561847031116
time/saving (s)                0.012184355407953262
time/training (s)              9.618197723291814
time/epoch (s)                 234.76070381421596
time/total (s)                 138783.50900542084
Epoch                          591
-----------------------------  ---------------------
2023-08-02 08:31:05.374217 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 592 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3489.8552]
trainer/QF1 Loss               0.014032683
trainer/QF2 Loss               0.018101858
trainer/Policy Loss            -90.59453
trainer/Q1 Predictions Mean    102.47887
trainer/Q1 Predictions Std     0.94905865
trainer/Q1 Predictions Max     105.24541
trainer/Q1 Predictions Min     95.14458
trainer/Q2 Predictions Mean    102.49392
trainer/Q2 Predictions Std     0.96603596
trainer/Q2 Predictions Max     105.10131
trainer/Q2 Predictions Min     95.363625
trainer/Q Targets Mean         102.4409
trainer/Q Targets Std          0.9669165
trainer/Q Targets Max          105.25415
trainer/Q Targets Min          95.336945
trainer/Log Pis Mean           11.969719
trainer/Log Pis Std            7.75605
trainer/Log Pis Max            45.567513
trainer/Log Pis Min            -6.1652536
trainer/Policy mu Mean         0.09761313
trainer/Policy mu Std          1.5585794
trainer/Policy mu Max          5.347562
trainer/Policy mu Min          -4.3939896
trainer/Policy log std Mean    -0.75155663
trainer/Policy log std Std     0.26581773
trainer/Policy log std Max     -0.13865614
trainer/Policy log std Min     -2.0370705
trainer/Alpha                  0.0014037530636414886
trainer/Alpha Loss             -0.19890755414962769
exploration/num steps total    2966000
exploration/num paths total    5932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.957625923370127
exploration/Rewards Std        0.04831226796439651
exploration/Rewards Max        0.9787652949578778
exploration/Rewards Min        0.49676009195694326
exploration/Returns Mean       478.81296168506344
exploration/Returns Std        1.2321313805822494
exploration/Returns Max        480.8906027796465
exploration/Returns Min        477.4882463039267
exploration/Actions Mean       -0.028026264
exploration/Actions Std        0.5910035
exploration/Actions Max        0.9998431
exploration/Actions Min        -0.999952
exploration/Num Paths          10
exploration/Average Returns    478.81296168506344
evaluation/num steps total     2965000
evaluation/num paths total     5930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609591392735887
evaluation/Rewards Std         0.04868811545409537
evaluation/Rewards Max         0.9781332083834994
evaluation/Rewards Min         0.48496534578180084
evaluation/Returns Mean        480.47956963679445
evaluation/Returns Std         0.7889053312435844
evaluation/Returns Max         481.3138525148491
evaluation/Returns Min         478.84815742068406
evaluation/ExplReturns Mean    480.47956963679445
evaluation/ExplReturns Std     0.7889053312435844
evaluation/ExplReturns Max     481.3138525148491
evaluation/ExplReturns Min     478.84815742068406
evaluation/Actions Mean        0.0062697474
evaluation/Actions Std         0.4993852
evaluation/Actions Max         0.9991223
evaluation/Actions Min         -0.99984616
evaluation/Num Paths           10
evaluation/Average Returns     480.47956963679445
time/data storing (s)          0.03220323193818331
time/evaluation sampling (s)   112.06281886342913
time/exploration sampling (s)  110.48648134805262
time/logging (s)               0.03100062906742096
time/saving (s)                0.012043067254126072
time/training (s)              9.588854127563536
time/epoch (s)                 232.21340126730502
time/total (s)                 139015.72490698285
Epoch                          592
-----------------------------  ---------------------
2023-08-02 08:35:00.148118 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 593 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3663.5164]
trainer/QF1 Loss               0.017575862
trainer/QF2 Loss               0.029292919
trainer/Policy Loss            -90.04907
trainer/Q1 Predictions Mean    102.14829
trainer/Q1 Predictions Std     2.3704216
trainer/Q1 Predictions Max     103.71968
trainer/Q1 Predictions Min     74.61454
trainer/Q2 Predictions Mean    102.208305
trainer/Q2 Predictions Std     2.3396623
trainer/Q2 Predictions Max     103.90858
trainer/Q2 Predictions Min     75.22716
trainer/Q Targets Mean         102.13875
trainer/Q Targets Std          2.3642015
trainer/Q Targets Max          103.705505
trainer/Q Targets Min          74.902916
trainer/Log Pis Mean           12.202647
trainer/Log Pis Std            7.493835
trainer/Log Pis Max            51.27172
trainer/Log Pis Min            -4.8336406
trainer/Policy mu Mean         0.088423215
trainer/Policy mu Std          1.5952486
trainer/Policy mu Max          6.109415
trainer/Policy mu Min          -6.898172
trainer/Policy log std Mean    -0.75660175
trainer/Policy log std Std     0.28046578
trainer/Policy log std Max     0.29737443
trainer/Policy log std Min     -2.1212552
trainer/Alpha                  0.0013513233279809356
trainer/Alpha Loss             1.3388354778289795
exploration/num steps total    2971000
exploration/num paths total    5942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9622649898652131
exploration/Rewards Std        0.048430701085235846
exploration/Rewards Max        0.9796016654312987
exploration/Rewards Min        0.4988885998227779
exploration/Returns Mean       481.13249493260656
exploration/Returns Std        0.43992459807570367
exploration/Returns Max        481.7816037893618
exploration/Returns Min        480.54681661189704
exploration/Actions Mean       -0.08993123
exploration/Actions Std        0.6045188
exploration/Actions Max        0.99979955
exploration/Actions Min        -0.9998599
exploration/Num Paths          10
exploration/Average Returns    481.13249493260656
evaluation/num steps total     2970000
evaluation/num paths total     5940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9642890475618917
evaluation/Rewards Std         0.048078104568939704
evaluation/Rewards Max         0.979593740484382
evaluation/Rewards Min         0.4993026264695889
evaluation/Returns Mean        482.14452378094586
evaluation/Returns Std         1.0052632727841702
evaluation/Returns Max         483.75251708215626
evaluation/Returns Min         480.2879537710622
evaluation/ExplReturns Mean    482.14452378094586
evaluation/ExplReturns Std     1.0052632727841702
evaluation/ExplReturns Max     483.75251708215626
evaluation/ExplReturns Min     480.2879537710622
evaluation/Actions Mean        -0.06287178
evaluation/Actions Std         0.5487784
evaluation/Actions Max         0.9987105
evaluation/Actions Min         -0.9992446
evaluation/Num Paths           10
evaluation/Average Returns     482.14452378094586
time/data storing (s)          0.031935812905430794
time/evaluation sampling (s)   112.83482209313661
time/exploration sampling (s)  112.23887578118593
time/logging (s)               0.030469238758087158
time/saving (s)                0.012519699521362782
time/training (s)              9.617546925321221
time/epoch (s)                 234.76616955082864
time/total (s)                 139250.49355549365
Epoch                          593
-----------------------------  ---------------------
2023-08-02 08:38:53.094827 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 594 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4063.9321]
trainer/QF1 Loss               0.026426861
trainer/QF2 Loss               0.022156866
trainer/Policy Loss            -91.17934
trainer/Q1 Predictions Mean    102.18907
trainer/Q1 Predictions Std     2.497869
trainer/Q1 Predictions Max     103.6653
trainer/Q1 Predictions Min     67.05852
trainer/Q2 Predictions Mean    102.12286
trainer/Q2 Predictions Std     2.4439871
trainer/Q2 Predictions Max     103.63725
trainer/Q2 Predictions Min     67.9377
trainer/Q Targets Mean         102.19002
trainer/Q Targets Std          2.426342
trainer/Q Targets Max          103.68429
trainer/Q Targets Min          68.45041
trainer/Log Pis Mean           11.059923
trainer/Log Pis Std            8.784009
trainer/Log Pis Max            64.75123
trainer/Log Pis Min            -5.7701616
trainer/Policy mu Mean         0.07589039
trainer/Policy mu Std          1.5438461
trainer/Policy mu Max          5.762803
trainer/Policy mu Min          -8.648519
trainer/Policy log std Mean    -0.7543898
trainer/Policy log std Std     0.2856386
trainer/Policy log std Max     0.5383049
trainer/Policy log std Min     -2.2053914
trainer/Alpha                  0.0013895598240196705
trainer/Alpha Loss             -6.18441104888916
exploration/num steps total    2976000
exploration/num paths total    5952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9522649271545474
exploration/Rewards Std        0.06402341848466828
exploration/Rewards Max        0.9796556302903507
exploration/Rewards Min        0.4983943191554536
exploration/Returns Mean       476.1324635772736
exploration/Returns Std        12.484972484732676
exploration/Returns Max        481.27413133144535
exploration/Returns Min        438.7588100943906
exploration/Actions Mean       -0.044194043
exploration/Actions Std        0.5904889
exploration/Actions Max        0.9998316
exploration/Actions Min        -0.99989766
exploration/Num Paths          10
exploration/Average Returns    476.1324635772736
evaluation/num steps total     2975000
evaluation/num paths total     5950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9436852841030832
evaluation/Rewards Std         0.07220701479133526
evaluation/Rewards Max         0.9791384487328214
evaluation/Rewards Min         0.5005513769922135
evaluation/Returns Mean        471.8426420515415
evaluation/Returns Std         21.69694536084468
evaluation/Returns Max         480.6004855350228
evaluation/Returns Min         406.80527241866923
evaluation/ExplReturns Mean    471.8426420515415
evaluation/ExplReturns Std     21.69694536084468
evaluation/ExplReturns Max     480.6004855350228
evaluation/ExplReturns Min     406.80527241866923
evaluation/Actions Mean        -0.034004036
evaluation/Actions Std         0.44965193
evaluation/Actions Max         0.9988352
evaluation/Actions Min         -0.9997598
evaluation/Num Paths           10
evaluation/Average Returns     471.8426420515415
time/data storing (s)          0.032134294509887695
time/evaluation sampling (s)   112.30516374111176
time/exploration sampling (s)  110.94355937931687
time/logging (s)               0.030581568367779255
time/saving (s)                0.010267779231071472
time/training (s)              9.617925763130188
time/epoch (s)                 232.93963252566755
time/total (s)                 139483.43563755974
Epoch                          594
-----------------------------  ---------------------
2023-08-02 08:42:46.515492 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 595 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3883.881]
trainer/QF1 Loss               0.013813307
trainer/QF2 Loss               0.017517027
trainer/Policy Loss            -91.03047
trainer/Q1 Predictions Mean    102.42423
trainer/Q1 Predictions Std     0.9774592
trainer/Q1 Predictions Max     103.736115
trainer/Q1 Predictions Min     94.833336
trainer/Q2 Predictions Mean    102.33819
trainer/Q2 Predictions Std     0.96710277
trainer/Q2 Predictions Max     103.65217
trainer/Q2 Predictions Min     94.86011
trainer/Q Targets Mean         102.3876
trainer/Q Targets Std          0.9988498
trainer/Q Targets Max          103.65872
trainer/Q Targets Min          94.22262
trainer/Log Pis Mean           11.428646
trainer/Log Pis Std            7.358516
trainer/Log Pis Max            37.335846
trainer/Log Pis Min            -6.537612
trainer/Policy mu Mean         0.048600744
trainer/Policy mu Std          1.5521907
trainer/Policy mu Max          5.0493107
trainer/Policy mu Min          -5.393157
trainer/Policy log std Mean    -0.7513383
trainer/Policy log std Std     0.28667688
trainer/Policy log std Max     1.0395784
trainer/Policy log std Min     -2.098981
trainer/Alpha                  0.001401066780090332
trainer/Alpha Loss             -3.754091739654541
exploration/num steps total    2981000
exploration/num paths total    5962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9620054989793997
exploration/Rewards Std        0.04830733343675951
exploration/Rewards Max        0.9796785290047524
exploration/Rewards Min        0.49617837320864383
exploration/Returns Mean       481.0027494896998
exploration/Returns Std        0.422516367466349
exploration/Returns Max        481.73933305927125
exploration/Returns Min        480.4688304604059
exploration/Actions Mean       0.024551798
exploration/Actions Std        0.59967613
exploration/Actions Max        0.9996846
exploration/Actions Min        -0.9998557
exploration/Num Paths          10
exploration/Average Returns    481.0027494896998
evaluation/num steps total     2980000
evaluation/num paths total     5960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9618926216797925
evaluation/Rewards Std         0.047201324614120535
evaluation/Rewards Max         0.9784712022712347
evaluation/Rewards Min         0.5040304213176373
evaluation/Returns Mean        480.94631083989617
evaluation/Returns Std         0.17839390013224413
evaluation/Returns Max         481.2307366583368
evaluation/Returns Min         480.7090788440858
evaluation/ExplReturns Mean    480.94631083989617
evaluation/ExplReturns Std     0.17839390013224413
evaluation/ExplReturns Max     481.2307366583368
evaluation/ExplReturns Min     480.7090788440858
evaluation/Actions Mean        0.024536876
evaluation/Actions Std         0.48394355
evaluation/Actions Max         0.99903816
evaluation/Actions Min         -0.99942744
evaluation/Num Paths           10
evaluation/Average Returns     480.94631083989617
time/data storing (s)          0.03221369441598654
time/evaluation sampling (s)   111.43045399710536
time/exploration sampling (s)  112.38686045538634
time/logging (s)               0.030505027621984482
time/saving (s)                0.012528560124337673
time/training (s)              9.520663623698056
time/epoch (s)                 233.41322535835207
time/total (s)                 139716.85145086423
Epoch                          595
-----------------------------  --------------------
2023-08-02 08:46:40.664305 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 596 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4240.42]
trainer/QF1 Loss               0.013639813
trainer/QF2 Loss               0.012769351
trainer/Policy Loss            -90.48963
trainer/Q1 Predictions Mean    102.477974
trainer/Q1 Predictions Std     0.83322984
trainer/Q1 Predictions Max     105.38173
trainer/Q1 Predictions Min     96.94983
trainer/Q2 Predictions Mean    102.46584
trainer/Q2 Predictions Std     0.82863355
trainer/Q2 Predictions Max     105.47483
trainer/Q2 Predictions Min     97.26822
trainer/Q Targets Mean         102.486496
trainer/Q Targets Std          0.84354216
trainer/Q Targets Max          105.50429
trainer/Q Targets Min          96.876686
trainer/Log Pis Mean           12.061232
trainer/Log Pis Std            7.5681014
trainer/Log Pis Max            46.446136
trainer/Log Pis Min            -9.050886
trainer/Policy mu Mean         0.069813885
trainer/Policy mu Std          1.5750355
trainer/Policy mu Max          4.5652766
trainer/Policy mu Min          -5.2268353
trainer/Policy log std Mean    -0.7512622
trainer/Policy log std Std     0.2800048
trainer/Policy log std Max     0.07672459
trainer/Policy log std Min     -2.3623462
trainer/Alpha                  0.0013513891026377678
trainer/Alpha Loss             0.4045443534851074
exploration/num steps total    2986000
exploration/num paths total    5972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9578784710261622
exploration/Rewards Std        0.05744170197124214
exploration/Rewards Max        0.979679856790308
exploration/Rewards Min        0.5023821201433447
exploration/Returns Mean       478.939235513081
exploration/Returns Std        6.021891395311527
exploration/Returns Max        481.8580610858056
exploration/Returns Min        461.1169657376759
exploration/Actions Mean       0.07220531
exploration/Actions Std        0.6579545
exploration/Actions Max        1.0
exploration/Actions Min        -0.9999822
exploration/Num Paths          10
exploration/Average Returns    478.939235513081
evaluation/num steps total     2985000
evaluation/num paths total     5970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9391984000762954
evaluation/Rewards Std         0.10016938048213346
evaluation/Rewards Max         0.9791679539031848
evaluation/Rewards Min         0.20930102025934474
evaluation/Returns Mean        469.59920003814784
evaluation/Returns Std         30.05469054692561
evaluation/Returns Max         482.2541667617787
evaluation/Returns Min         380.40699761137125
evaluation/ExplReturns Mean    469.59920003814784
evaluation/ExplReturns Std     30.05469054692561
evaluation/ExplReturns Max     482.2541667617787
evaluation/ExplReturns Min     380.40699761137125
evaluation/Actions Mean        0.068740524
evaluation/Actions Std         0.62679553
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     469.59920003814784
time/data storing (s)          0.03222214989364147
time/evaluation sampling (s)   112.25750302150846
time/exploration sampling (s)  112.25551421009004
time/logging (s)               0.030223459005355835
time/saving (s)                0.012361905537545681
time/training (s)              9.5535279950127
time/epoch (s)                 234.14135274104774
time/total (s)                 139950.99525168817
Epoch                          596
-----------------------------  ---------------------
2023-08-02 08:50:29.423314 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 597 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4027.1475]
trainer/QF1 Loss               0.01499977
trainer/QF2 Loss               0.016085599
trainer/Policy Loss            -89.530304
trainer/Q1 Predictions Mean    102.347404
trainer/Q1 Predictions Std     0.9963234
trainer/Q1 Predictions Max     103.93616
trainer/Q1 Predictions Min     93.90938
trainer/Q2 Predictions Mean    102.323814
trainer/Q2 Predictions Std     0.97533405
trainer/Q2 Predictions Max     103.8023
trainer/Q2 Predictions Min     94.052864
trainer/Q Targets Mean         102.39225
trainer/Q Targets Std          0.9768527
trainer/Q Targets Max          103.81999
trainer/Q Targets Min          94.352295
trainer/Log Pis Mean           12.8930855
trainer/Log Pis Std            8.219538
trainer/Log Pis Max            49.084328
trainer/Log Pis Min            -1.2314886
trainer/Policy mu Mean         -0.077275686
trainer/Policy mu Std          1.6176127
trainer/Policy mu Max          6.1309266
trainer/Policy mu Min          -5.8546314
trainer/Policy log std Mean    -0.75137043
trainer/Policy log std Std     0.27915397
trainer/Policy log std Max     0.8197926
trainer/Policy log std Min     -1.9308417
trainer/Alpha                  0.0013153271283954382
trainer/Alpha Loss             5.924452304840088
exploration/num steps total    2991000
exploration/num paths total    5982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.95747958534029
exploration/Rewards Std        0.05082833282650772
exploration/Rewards Max        0.9797100334498563
exploration/Rewards Min        0.500709375930773
exploration/Returns Mean       478.7397926701451
exploration/Returns Std        1.4927853921568859
exploration/Returns Max        480.4199894112841
exploration/Returns Min        475.9303782194042
exploration/Actions Mean       0.02758493
exploration/Actions Std        0.6200425
exploration/Actions Max        0.9999023
exploration/Actions Min        -0.99999094
exploration/Num Paths          10
exploration/Average Returns    478.7397926701451
evaluation/num steps total     2990000
evaluation/num paths total     5980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9572590705234403
evaluation/Rewards Std         0.0491381154123309
evaluation/Rewards Max         0.9777560487631058
evaluation/Rewards Min         0.5067671535334531
evaluation/Returns Mean        478.62953526172
evaluation/Returns Std         0.6905921262199421
evaluation/Returns Max         479.60752342077365
evaluation/Returns Min         476.87190527549495
evaluation/ExplReturns Mean    478.62953526172
evaluation/ExplReturns Std     0.6905921262199421
evaluation/ExplReturns Max     479.60752342077365
evaluation/ExplReturns Min     476.87190527549495
evaluation/Actions Mean        0.03808279
evaluation/Actions Std         0.51752055
evaluation/Actions Max         0.9992506
evaluation/Actions Min         -0.9997836
evaluation/Num Paths           10
evaluation/Average Returns     478.62953526172
time/data storing (s)          0.031792678870260715
time/evaluation sampling (s)   108.87350384145975
time/exploration sampling (s)  110.21446823701262
time/logging (s)               0.030427157878875732
time/saving (s)                0.01273901667445898
time/training (s)              9.589105252176523
time/epoch (s)                 228.7520361840725
time/total (s)                 140179.74972965475
Epoch                          597
-----------------------------  ---------------------
2023-08-02 08:54:23.856085 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 598 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4043.9634]
trainer/QF1 Loss               0.023513524
trainer/QF2 Loss               0.012249861
trainer/Policy Loss            -91.0352
trainer/Q1 Predictions Mean    102.28382
trainer/Q1 Predictions Std     1.0085014
trainer/Q1 Predictions Max     103.86027
trainer/Q1 Predictions Min     96.24689
trainer/Q2 Predictions Mean    102.360504
trainer/Q2 Predictions Std     0.99899757
trainer/Q2 Predictions Max     103.928444
trainer/Q2 Predictions Min     96.907166
trainer/Q Targets Mean         102.38576
trainer/Q Targets Std          1.0079981
trainer/Q Targets Max          103.90312
trainer/Q Targets Min          96.6191
trainer/Log Pis Mean           11.352509
trainer/Log Pis Std            7.0632396
trainer/Log Pis Max            37.80813
trainer/Log Pis Min            -3.5567932
trainer/Policy mu Mean         -0.0026639986
trainer/Policy mu Std          1.5583926
trainer/Policy mu Max          5.3960233
trainer/Policy mu Min          -8.47338
trainer/Policy log std Mean    -0.72990036
trainer/Policy log std Std     0.26751727
trainer/Policy log std Max     0.44268504
trainer/Policy log std Min     -1.8707693
trainer/Alpha                  0.0014071554178372025
trainer/Alpha Loss             -4.251529693603516
exploration/num steps total    2996000
exploration/num paths total    5992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9646032397617673
exploration/Rewards Std        0.05152118953717662
exploration/Rewards Max        0.9798463472651433
exploration/Rewards Min        0.5001764920153603
exploration/Returns Mean       482.3016198808838
exploration/Returns Std        0.8498870798183429
exploration/Returns Max        483.1257235159029
exploration/Returns Min        479.9927374217625
exploration/Actions Mean       0.08205871
exploration/Actions Std        0.5847748
exploration/Actions Max        0.99994797
exploration/Actions Min        -0.99988824
exploration/Num Paths          10
exploration/Average Returns    482.3016198808838
evaluation/num steps total     2995000
evaluation/num paths total     5990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9636747893310145
evaluation/Rewards Std         0.049787431607455496
evaluation/Rewards Max         0.9778351965183953
evaluation/Rewards Min         0.4936457392909825
evaluation/Returns Mean        481.8373946655071
evaluation/Returns Std         1.0537468053016321
evaluation/Returns Max         483.2871212233322
evaluation/Returns Min         479.129163674981
evaluation/ExplReturns Mean    481.8373946655071
evaluation/ExplReturns Std     1.0537468053016321
evaluation/ExplReturns Max     483.2871212233322
evaluation/ExplReturns Min     479.129163674981
evaluation/Actions Mean        0.09529272
evaluation/Actions Std         0.49325123
evaluation/Actions Max         0.9979113
evaluation/Actions Min         -0.99908596
evaluation/Num Paths           10
evaluation/Average Returns     481.8373946655071
time/data storing (s)          0.032312083058059216
time/evaluation sampling (s)   112.45156816486269
time/exploration sampling (s)  112.32186774164438
time/logging (s)               0.030583862215280533
time/saving (s)                0.010255237109959126
time/training (s)              9.579077976755798
time/epoch (s)                 234.42566506564617
time/total (s)                 140414.1778509058
Epoch                          598
-----------------------------  ---------------------
2023-08-02 08:58:16.875547 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 599 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3915.1074]
trainer/QF1 Loss               0.015572755
trainer/QF2 Loss               0.029588867
trainer/Policy Loss            -89.618484
trainer/Q1 Predictions Mean    102.41282
trainer/Q1 Predictions Std     1.9745198
trainer/Q1 Predictions Max     104.85522
trainer/Q1 Predictions Min     74.24417
trainer/Q2 Predictions Mean    102.26871
trainer/Q2 Predictions Std     1.9787089
trainer/Q2 Predictions Max     104.7248
trainer/Q2 Predictions Min     74.10255
trainer/Q Targets Mean         102.39534
trainer/Q Targets Std          2.0065193
trainer/Q Targets Max          104.75173
trainer/Q Targets Min          73.55531
trainer/Log Pis Mean           12.781818
trainer/Log Pis Std            7.0787134
trainer/Log Pis Max            43.29879
trainer/Log Pis Min            -3.388725
trainer/Policy mu Mean         -0.013711979
trainer/Policy mu Std          1.6212387
trainer/Policy mu Max          5.7296567
trainer/Policy mu Min          -11.3219795
trainer/Policy log std Mean    -0.7436413
trainer/Policy log std Std     0.26913917
trainer/Policy log std Max     1.243703
trainer/Policy log std Min     -2.37105
trainer/Alpha                  0.0014524132711812854
trainer/Alpha Loss             5.108985424041748
exploration/num steps total    3001000
exploration/num paths total    6002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9554755889347143
exploration/Rewards Std        0.0496186237299287
exploration/Rewards Max        0.979320119317902
exploration/Rewards Min        0.5022367322895609
exploration/Returns Mean       477.73779446735705
exploration/Returns Std        1.9582843646561712
exploration/Returns Max        482.69246997512397
exploration/Returns Min        474.49718813373397
exploration/Actions Mean       0.11529539
exploration/Actions Std        0.5992749
exploration/Actions Max        0.9999841
exploration/Actions Min        -0.9998134
exploration/Num Paths          10
exploration/Average Returns    477.73779446735705
evaluation/num steps total     3000000
evaluation/num paths total     6000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9516417732964132
evaluation/Rewards Std         0.0645577985998428
evaluation/Rewards Max         0.9763205482310012
evaluation/Rewards Min         0.5006036253081104
evaluation/Returns Mean        475.8208866482067
evaluation/Returns Std         7.218086477488183
evaluation/Returns Max         482.13235093630203
evaluation/Returns Min         461.74339816059484
evaluation/ExplReturns Mean    475.8208866482067
evaluation/ExplReturns Std     7.218086477488183
evaluation/ExplReturns Max     482.13235093630203
evaluation/ExplReturns Min     461.74339816059484
evaluation/Actions Mean        0.10823611
evaluation/Actions Std         0.52627957
evaluation/Actions Max         0.999984
evaluation/Actions Min         -0.99998957
evaluation/Num Paths           10
evaluation/Average Returns     475.8208866482067
time/data storing (s)          0.03226578049361706
time/evaluation sampling (s)   111.24564375262707
time/exploration sampling (s)  112.0637704860419
time/logging (s)               0.030368616804480553
time/saving (s)                0.012481731362640858
time/training (s)              9.627493974752724
time/epoch (s)                 233.01202434208244
time/total (s)                 140647.19233423937
Epoch                          599
-----------------------------  ---------------------
2023-08-02 09:02:10.736068 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 600 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4059.089]
trainer/QF1 Loss               0.026475366
trainer/QF2 Loss               0.030913927
trainer/Policy Loss            -90.594215
trainer/Q1 Predictions Mean    102.334625
trainer/Q1 Predictions Std     1.0384772
trainer/Q1 Predictions Max     104.02098
trainer/Q1 Predictions Min     94.61594
trainer/Q2 Predictions Mean    102.30409
trainer/Q2 Predictions Std     1.0482966
trainer/Q2 Predictions Max     103.98932
trainer/Q2 Predictions Min     94.82709
trainer/Q Targets Mean         102.44672
trainer/Q Targets Std          1.0490158
trainer/Q Targets Max          104.23949
trainer/Q Targets Min          94.767365
trainer/Log Pis Mean           11.801324
trainer/Log Pis Std            7.015183
trainer/Log Pis Max            34.17896
trainer/Log Pis Min            -1.9721515
trainer/Policy mu Mean         -0.017870314
trainer/Policy mu Std          1.5851004
trainer/Policy mu Max          4.9716578
trainer/Policy mu Min          -4.963645
trainer/Policy log std Mean    -0.733679
trainer/Policy log std Std     0.24884132
trainer/Policy log std Max     0.030356467
trainer/Policy log std Min     -1.869174
trainer/Alpha                  0.001504763145931065
trainer/Alpha Loss             -1.291211485862732
exploration/num steps total    3006000
exploration/num paths total    6012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9611554557151109
exploration/Rewards Std        0.048761748402456964
exploration/Rewards Max        0.9777926441932472
exploration/Rewards Min        0.4870167692209519
exploration/Returns Mean       480.5777278575555
exploration/Returns Std        0.3942285414592532
exploration/Returns Max        481.500832660267
exploration/Returns Min        479.84674040004717
exploration/Actions Mean       0.10713216
exploration/Actions Std        0.5942792
exploration/Actions Max        0.99973875
exploration/Actions Min        -0.9998252
exploration/Num Paths          10
exploration/Average Returns    480.5777278575555
evaluation/num steps total     3005000
evaluation/num paths total     6010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9635300813615537
evaluation/Rewards Std         0.048853909977112246
evaluation/Rewards Max         0.9753351497681146
evaluation/Rewards Min         0.4943651709408548
evaluation/Returns Mean        481.7650406807767
evaluation/Returns Std         0.612305261022398
evaluation/Returns Max         482.614326876131
evaluation/Returns Min         480.4979126872638
evaluation/ExplReturns Mean    481.7650406807767
evaluation/ExplReturns Std     0.612305261022398
evaluation/ExplReturns Max     482.614326876131
evaluation/ExplReturns Min     480.4979126872638
evaluation/Actions Mean        0.11069363
evaluation/Actions Std         0.5036441
evaluation/Actions Max         0.9979788
evaluation/Actions Min         -0.9984192
evaluation/Num Paths           10
evaluation/Average Returns     481.7650406807767
time/data storing (s)          0.03221456054598093
time/evaluation sampling (s)   111.97303197160363
time/exploration sampling (s)  112.20398701447994
time/logging (s)               0.030938327312469482
time/saving (s)                0.011590426787734032
time/training (s)              9.602058234624565
time/epoch (s)                 233.85382053535432
time/total (s)                 140881.04862981103
Epoch                          600
-----------------------------  --------------------
2023-08-02 09:06:04.846093 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 601 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3725.6648]
trainer/QF1 Loss               0.019414248
trainer/QF2 Loss               0.018402793
trainer/Policy Loss            -90.10119
trainer/Q1 Predictions Mean    102.53053
trainer/Q1 Predictions Std     1.6210158
trainer/Q1 Predictions Max     104.43156
trainer/Q1 Predictions Min     81.96722
trainer/Q2 Predictions Mean    102.47103
trainer/Q2 Predictions Std     1.6459771
trainer/Q2 Predictions Max     104.37011
trainer/Q2 Predictions Min     81.164635
trainer/Q Targets Mean         102.46118
trainer/Q Targets Std          1.629507
trainer/Q Targets Max          104.38163
trainer/Q Targets Min          81.9899
trainer/Log Pis Mean           12.471619
trainer/Log Pis Std            7.002787
trainer/Log Pis Max            52.02104
trainer/Log Pis Min            -1.0385109
trainer/Policy mu Mean         -0.001488878
trainer/Policy mu Std          1.612863
trainer/Policy mu Max          5.4696436
trainer/Policy mu Min          -5.7305975
trainer/Policy log std Mean    -0.72781897
trainer/Policy log std Std     0.24822667
trainer/Policy log std Max     -0.0073277354
trainer/Policy log std Min     -1.7451395
trainer/Alpha                  0.0015057048294693232
trainer/Alpha Loss             3.064884901046753
exploration/num steps total    3011000
exploration/num paths total    6022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9659137411328517
exploration/Rewards Std        0.051175727727937076
exploration/Rewards Max        0.979796371795821
exploration/Rewards Min        0.4932162195001681
exploration/Returns Mean       482.95687056642583
exploration/Returns Std        0.1994950292036538
exploration/Returns Max        483.351474003838
exploration/Returns Min        482.6311875147529
exploration/Actions Mean       0.09247169
exploration/Actions Std        0.6090924
exploration/Actions Max        0.9997976
exploration/Actions Min        -0.9999698
exploration/Num Paths          10
exploration/Average Returns    482.95687056642583
evaluation/num steps total     3010000
evaluation/num paths total     6020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9668733173455115
evaluation/Rewards Std         0.05149560216869711
evaluation/Rewards Max         0.9765015097014372
evaluation/Rewards Min         0.4883447921296303
evaluation/Returns Mean        483.43665867275587
evaluation/Returns Std         0.13936172527445423
evaluation/Returns Max         483.60129591848136
evaluation/Returns Min         483.2108016150903
evaluation/ExplReturns Mean    483.43665867275587
evaluation/ExplReturns Std     0.13936172527445423
evaluation/ExplReturns Max     483.60129591848136
evaluation/ExplReturns Min     483.2108016150903
evaluation/Actions Mean        0.11449354
evaluation/Actions Std         0.49509987
evaluation/Actions Max         0.9976267
evaluation/Actions Min         -0.9994493
evaluation/Num Paths           10
evaluation/Average Returns     483.43665867275587
time/data storing (s)          0.03266630880534649
time/evaluation sampling (s)   112.07515374571085
time/exploration sampling (s)  112.3681216808036
time/logging (s)               0.03101238887757063
time/saving (s)                0.012067725881934166
time/training (s)              9.583713604137301
time/epoch (s)                 234.1027354542166
time/total (s)                 141115.1538644163
Epoch                          601
-----------------------------  ---------------------
2023-08-02 09:09:59.677737 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 602 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4066.4194]
trainer/QF1 Loss               0.014515799
trainer/QF2 Loss               0.022312716
trainer/Policy Loss            -90.828964
trainer/Q1 Predictions Mean    102.46855
trainer/Q1 Predictions Std     1.2070565
trainer/Q1 Predictions Max     104.929115
trainer/Q1 Predictions Min     91.54997
trainer/Q2 Predictions Mean    102.58679
trainer/Q2 Predictions Std     1.2196405
trainer/Q2 Predictions Max     105.02126
trainer/Q2 Predictions Min     90.88513
trainer/Q Targets Mean         102.500244
trainer/Q Targets Std          1.2294614
trainer/Q Targets Max          105.14153
trainer/Q Targets Min          91.043365
trainer/Log Pis Mean           11.757176
trainer/Log Pis Std            7.2076945
trainer/Log Pis Max            47.39003
trainer/Log Pis Min            -5.178256
trainer/Policy mu Mean         -0.08459693
trainer/Policy mu Std          1.5609215
trainer/Policy mu Max          4.4475203
trainer/Policy mu Min          -6.3953676
trainer/Policy log std Mean    -0.7282036
trainer/Policy log std Std     0.26250404
trainer/Policy log std Max     -0.0372954
trainer/Policy log std Min     -2.102178
trainer/Alpha                  0.0014681442407891154
trainer/Alpha Loss             -1.584058403968811
exploration/num steps total    3016000
exploration/num paths total    6032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9653057169217838
exploration/Rewards Std        0.049904884669215756
exploration/Rewards Max        0.9791806919213601
exploration/Rewards Min        0.49344111876214813
exploration/Returns Mean       482.65285846089193
exploration/Returns Std        0.4301057469271152
exploration/Returns Max        483.2445382849457
exploration/Returns Min        481.8181162131952
exploration/Actions Mean       0.07487654
exploration/Actions Std        0.60971713
exploration/Actions Max        0.99993485
exploration/Actions Min        -0.9999896
exploration/Num Paths          10
exploration/Average Returns    482.65285846089193
evaluation/num steps total     3015000
evaluation/num paths total     6030
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9662104012011947
evaluation/Rewards Std         0.04939788966358367
evaluation/Rewards Max         0.9766556238025729
evaluation/Rewards Min         0.5024940709970355
evaluation/Returns Mean        483.10520060059724
evaluation/Returns Std         0.652647696816666
evaluation/Returns Max         483.6072943435584
evaluation/Returns Min         481.40415781490384
evaluation/ExplReturns Mean    483.10520060059724
evaluation/ExplReturns Std     0.652647696816666
evaluation/ExplReturns Max     483.6072943435584
evaluation/ExplReturns Min     481.40415781490384
evaluation/Actions Mean        0.08991271
evaluation/Actions Std         0.5168885
evaluation/Actions Max         0.99951786
evaluation/Actions Min         -0.99920887
evaluation/Num Paths           10
evaluation/Average Returns     483.10520060059724
time/data storing (s)          0.03231000527739525
time/evaluation sampling (s)   112.58230512216687
time/exploration sampling (s)  112.28444103337824
time/logging (s)               0.031645734794437885
time/saving (s)                0.012832117266952991
time/training (s)              9.881377132609487
time/epoch (s)                 234.8249111454934
time/total (s)                 141349.98129630275
Epoch                          602
-----------------------------  ---------------------
2023-08-02 09:13:55.065962 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 603 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3805.209]
trainer/QF1 Loss               0.015859831
trainer/QF2 Loss               0.015108556
trainer/Policy Loss            -90.50827
trainer/Q1 Predictions Mean    102.46459
trainer/Q1 Predictions Std     1.8883967
trainer/Q1 Predictions Max     104.3307
trainer/Q1 Predictions Min     80.39677
trainer/Q2 Predictions Mean    102.47208
trainer/Q2 Predictions Std     1.8795133
trainer/Q2 Predictions Max     104.2925
trainer/Q2 Predictions Min     80.767105
trainer/Q Targets Mean         102.452255
trainer/Q Targets Std          1.8568
trainer/Q Targets Max          104.267075
trainer/Q Targets Min          80.95075
trainer/Log Pis Mean           12.055579
trainer/Log Pis Std            6.9339337
trainer/Log Pis Max            40.77536
trainer/Log Pis Min            -2.0692492
trainer/Policy mu Mean         -0.046531517
trainer/Policy mu Std          1.5902512
trainer/Policy mu Max          5.2667804
trainer/Policy mu Min          -5.7554584
trainer/Policy log std Mean    -0.7450242
trainer/Policy log std Std     0.2606767
trainer/Policy log std Max     0.07851088
trainer/Policy log std Min     -1.9073321
trainer/Alpha                  0.0014441380044445395
trainer/Alpha Loss             0.3635111451148987
exploration/num steps total    3021000
exploration/num paths total    6042
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9648341374578878
exploration/Rewards Std        0.05134293324788972
exploration/Rewards Max        0.9796538039753746
exploration/Rewards Min        0.4980816418834031
exploration/Returns Mean       482.41706872894366
exploration/Returns Std        0.5401810883721897
exploration/Returns Max        482.96752092291837
exploration/Returns Min        481.0509004233285
exploration/Actions Mean       0.109771796
exploration/Actions Std        0.6188349
exploration/Actions Max        0.99986905
exploration/Actions Min        -0.9998976
exploration/Num Paths          10
exploration/Average Returns    482.41706872894366
evaluation/num steps total     3020000
evaluation/num paths total     6040
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9651387517305106
evaluation/Rewards Std         0.052950622324732494
evaluation/Rewards Max         0.9769928086406856
evaluation/Rewards Min         0.49662213290955154
evaluation/Returns Mean        482.5693758652551
evaluation/Returns Std         0.7347394504210981
evaluation/Returns Max         483.3773586337012
evaluation/Returns Min         480.68352459842515
evaluation/ExplReturns Mean    482.5693758652551
evaluation/ExplReturns Std     0.7347394504210981
evaluation/ExplReturns Max     483.3773586337012
evaluation/ExplReturns Min     480.68352459842515
evaluation/Actions Mean        0.1354962
evaluation/Actions Std         0.5399912
evaluation/Actions Max         0.99874634
evaluation/Actions Min         -0.99951965
evaluation/Num Paths           10
evaluation/Average Returns     482.5693758652551
time/data storing (s)          0.032209902070462704
time/evaluation sampling (s)   112.20890170242637
time/exploration sampling (s)  112.58950114250183
time/logging (s)               0.030954748392105103
time/saving (s)                0.012155150063335896
time/training (s)              10.506492502056062
time/epoch (s)                 235.38021514751017
time/total (s)                 141585.36397702992
Epoch                          603
-----------------------------  ---------------------
2023-08-02 09:17:50.602860 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 604 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3768.8867]
trainer/QF1 Loss               0.020294512
trainer/QF2 Loss               0.020931052
trainer/Policy Loss            -90.55329
trainer/Q1 Predictions Mean    102.52698
trainer/Q1 Predictions Std     1.2118295
trainer/Q1 Predictions Max     106.739876
trainer/Q1 Predictions Min     93.615036
trainer/Q2 Predictions Mean    102.53258
trainer/Q2 Predictions Std     1.1817219
trainer/Q2 Predictions Max     106.68469
trainer/Q2 Predictions Min     93.894135
trainer/Q Targets Mean         102.462074
trainer/Q Targets Std          1.1985664
trainer/Q Targets Max          106.69156
trainer/Q Targets Min          93.311325
trainer/Log Pis Mean           12.073925
trainer/Log Pis Std            7.533112
trainer/Log Pis Max            41.55542
trainer/Log Pis Min            -5.5472302
trainer/Policy mu Mean         -0.14706375
trainer/Policy mu Std          1.5997845
trainer/Policy mu Max          5.1338444
trainer/Policy mu Min          -5.1297913
trainer/Policy log std Mean    -0.7298953
trainer/Policy log std Std     0.27359042
trainer/Policy log std Max     0.6553577
trainer/Policy log std Min     -2.1399837
trainer/Alpha                  0.001449258648790419
trainer/Alpha Loss             0.48322606086730957
exploration/num steps total    3026000
exploration/num paths total    6052
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9605914102668383
exploration/Rewards Std        0.04892251585671701
exploration/Rewards Max        0.9791331974828085
exploration/Rewards Min        0.49965601405781435
exploration/Returns Mean       480.29570513341935
exploration/Returns Std        0.4492606962905286
exploration/Returns Max        480.7336715328284
exploration/Returns Min        479.4155895106845
exploration/Actions Mean       0.045472205
exploration/Actions Std        0.5957165
exploration/Actions Max        0.9998654
exploration/Actions Min        -0.9998979
exploration/Num Paths          10
exploration/Average Returns    480.29570513341935
evaluation/num steps total     3025000
evaluation/num paths total     6050
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9618225153170215
evaluation/Rewards Std         0.04957364637156311
evaluation/Rewards Max         0.975912849635246
evaluation/Rewards Min         0.4891105275369985
evaluation/Returns Mean        480.91125765851064
evaluation/Returns Std         0.13034682499102465
evaluation/Returns Max         481.0570435373928
evaluation/Returns Min         480.68789299100644
evaluation/ExplReturns Mean    480.91125765851064
evaluation/ExplReturns Std     0.13034682499102465
evaluation/ExplReturns Max     481.0570435373928
evaluation/ExplReturns Min     480.68789299100644
evaluation/Actions Mean        0.045134477
evaluation/Actions Std         0.4296564
evaluation/Actions Max         0.9987857
evaluation/Actions Min         -0.99926215
evaluation/Num Paths           10
evaluation/Average Returns     480.91125765851064
time/data storing (s)          0.031706721521914005
time/evaluation sampling (s)   113.37399107497185
time/exploration sampling (s)  111.6429849518463
time/logging (s)               0.030566024594008923
time/saving (s)                0.010229311883449554
time/training (s)              10.439672716893256
time/epoch (s)                 235.52915080171078
time/total (s)                 141820.89567637444
Epoch                          604
-----------------------------  --------------------
2023-08-02 09:21:46.311085 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 605 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3510.529]
trainer/QF1 Loss               0.019048028
trainer/QF2 Loss               0.021375924
trainer/Policy Loss            -90.28764
trainer/Q1 Predictions Mean    102.630615
trainer/Q1 Predictions Std     1.315482
trainer/Q1 Predictions Max     106.65247
trainer/Q1 Predictions Min     88.356804
trainer/Q2 Predictions Mean    102.53334
trainer/Q2 Predictions Std     1.319635
trainer/Q2 Predictions Max     106.51774
trainer/Q2 Predictions Min     88.321266
trainer/Q Targets Mean         102.57624
trainer/Q Targets Std          1.2727605
trainer/Q Targets Max          106.76535
trainer/Q Targets Min          88.941765
trainer/Log Pis Mean           12.362537
trainer/Log Pis Std            9.292358
trainer/Log Pis Max            99.08036
trainer/Log Pis Min            -3.2152486
trainer/Policy mu Mean         -0.121385574
trainer/Policy mu Std          1.6359771
trainer/Policy mu Max          6.7593064
trainer/Policy mu Min          -7.9188275
trainer/Policy log std Mean    -0.71570563
trainer/Policy log std Std     0.27993447
trainer/Policy log std Max     0.39143956
trainer/Policy log std Min     -2.4120026
trainer/Alpha                  0.0015018864069133997
trainer/Alpha Loss             2.3569154739379883
exploration/num steps total    3031000
exploration/num paths total    6062
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9624300789556166
exploration/Rewards Std        0.054181027976852224
exploration/Rewards Max        0.9798040234537547
exploration/Rewards Min        0.4960887371964091
exploration/Returns Mean       481.2150394778081
exploration/Returns Std        0.37225607343829453
exploration/Returns Max        481.7387565454091
exploration/Returns Min        480.6570896897381
exploration/Actions Mean       0.06895582
exploration/Actions Std        0.62074363
exploration/Actions Max        0.9997976
exploration/Actions Min        -0.9999925
exploration/Num Paths          10
exploration/Average Returns    481.2150394778081
evaluation/num steps total     3030000
evaluation/num paths total     6060
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9604127928111046
evaluation/Rewards Std         0.05365370415894182
evaluation/Rewards Max         0.9757450644570679
evaluation/Rewards Min         0.4936724395743622
evaluation/Returns Mean        480.20639640555237
evaluation/Returns Std         0.2439026537468772
evaluation/Returns Max         480.6638200874286
evaluation/Returns Min         479.75452180629406
evaluation/ExplReturns Mean    480.20639640555237
evaluation/ExplReturns Std     0.2439026537468772
evaluation/ExplReturns Max     480.6638200874286
evaluation/ExplReturns Min     479.75452180629406
evaluation/Actions Mean        0.07282034
evaluation/Actions Std         0.503033
evaluation/Actions Max         0.99896467
evaluation/Actions Min         -0.9992287
evaluation/Num Paths           10
evaluation/Average Returns     480.20639640555237
time/data storing (s)          0.032677420414984226
time/evaluation sampling (s)   113.42788222245872
time/exploration sampling (s)  112.63012094050646
time/logging (s)               0.03070355299860239
time/saving (s)                0.012842115946114063
time/training (s)              9.566837079823017
time/epoch (s)                 235.7010633321479
time/total (s)                 142056.59919823054
Epoch                          605
-----------------------------  ---------------------
2023-08-02 09:25:38.868523 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 606 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3521.1704]
trainer/QF1 Loss               0.016776055
trainer/QF2 Loss               0.016765319
trainer/Policy Loss            -90.98143
trainer/Q1 Predictions Mean    102.510124
trainer/Q1 Predictions Std     1.6079265
trainer/Q1 Predictions Max     105.91824
trainer/Q1 Predictions Min     87.47503
trainer/Q2 Predictions Mean    102.49186
trainer/Q2 Predictions Std     1.5992159
trainer/Q2 Predictions Max     105.7292
trainer/Q2 Predictions Min     87.41862
trainer/Q Targets Mean         102.52269
trainer/Q Targets Std          1.5808514
trainer/Q Targets Max          105.5258
trainer/Q Targets Min          87.96453
trainer/Log Pis Mean           11.611118
trainer/Log Pis Std            7.309656
trainer/Log Pis Max            43.85547
trainer/Log Pis Min            -2.5960045
trainer/Policy mu Mean         -0.041822538
trainer/Policy mu Std          1.5612231
trainer/Policy mu Max          7.015233
trainer/Policy mu Min          -5.222233
trainer/Policy log std Mean    -0.74025935
trainer/Policy log std Std     0.27372047
trainer/Policy log std Max     0.33404124
trainer/Policy log std Min     -2.3521476
trainer/Alpha                  0.0014771571150049567
trainer/Alpha Loss             -2.534576654434204
exploration/num steps total    3036000
exploration/num paths total    6072
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639182321230059
exploration/Rewards Std        0.04991704235920952
exploration/Rewards Max        0.9796006575297315
exploration/Rewards Min        0.49426213286021004
exploration/Returns Mean       481.95911606150275
exploration/Returns Std        0.3512548385640929
exploration/Returns Max        482.49856158598146
exploration/Returns Min        481.46976790813693
exploration/Actions Mean       0.041524626
exploration/Actions Std        0.6177422
exploration/Actions Max        0.9998332
exploration/Actions Min        -0.99982476
exploration/Num Paths          10
exploration/Average Returns    481.95911606150275
evaluation/num steps total     3035000
evaluation/num paths total     6070
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9618601842545748
evaluation/Rewards Std         0.04938873108481093
evaluation/Rewards Max         0.9765418754517194
evaluation/Rewards Min         0.4931231921928363
evaluation/Returns Mean        480.9300921272875
evaluation/Returns Std         1.4320605957970711
evaluation/Returns Max         482.18752796122226
evaluation/Returns Min         477.9943785046924
evaluation/ExplReturns Mean    480.9300921272875
evaluation/ExplReturns Std     1.4320605957970711
evaluation/ExplReturns Max     482.18752796122226
evaluation/ExplReturns Min     477.9943785046924
evaluation/Actions Mean        0.03884569
evaluation/Actions Std         0.46511546
evaluation/Actions Max         0.9981793
evaluation/Actions Min         -0.99884343
evaluation/Num Paths           10
evaluation/Average Returns     480.9300921272875
time/data storing (s)          0.03197835944592953
time/evaluation sampling (s)   111.70790709462017
time/exploration sampling (s)  111.07265462167561
time/logging (s)               0.030779668129980564
time/saving (s)                0.012869920581579208
time/training (s)              9.693820902146399
time/epoch (s)                 232.55001056659967
time/total (s)                 142289.15182794817
Epoch                          606
-----------------------------  ---------------------
2023-08-02 09:29:31.541983 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 607 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3546.0483]
trainer/QF1 Loss               0.011931476
trainer/QF2 Loss               0.018314704
trainer/Policy Loss            -90.71029
trainer/Q1 Predictions Mean    102.65623
trainer/Q1 Predictions Std     1.2844776
trainer/Q1 Predictions Max     104.36467
trainer/Q1 Predictions Min     87.77409
trainer/Q2 Predictions Mean    102.644775
trainer/Q2 Predictions Std     1.3045995
trainer/Q2 Predictions Max     104.4464
trainer/Q2 Predictions Min     87.23549
trainer/Q Targets Mean         102.64558
trainer/Q Targets Std          1.3012426
trainer/Q Targets Max          104.401855
trainer/Q Targets Min          87.35759
trainer/Log Pis Mean           12.031864
trainer/Log Pis Std            6.9381857
trainer/Log Pis Max            46.815453
trainer/Log Pis Min            -2.4100041
trainer/Policy mu Mean         0.017226085
trainer/Policy mu Std          1.5870665
trainer/Policy mu Max          4.725415
trainer/Policy mu Min          -4.8561563
trainer/Policy log std Mean    -0.71014285
trainer/Policy log std Std     0.26989755
trainer/Policy log std Max     0.18472195
trainer/Policy log std Min     -2.0697722
trainer/Alpha                  0.0014635137049481273
trainer/Alpha Loss             0.2079830765724182
exploration/num steps total    3041000
exploration/num paths total    6082
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9604279652226502
exploration/Rewards Std        0.047953036826551956
exploration/Rewards Max        0.979624349839996
exploration/Rewards Min        0.493896769596978
exploration/Returns Mean       480.2139826113251
exploration/Returns Std        0.5799290141978783
exploration/Returns Max        481.261831833357
exploration/Returns Min        479.1383752552327
exploration/Actions Mean       0.022604413
exploration/Actions Std        0.5978756
exploration/Actions Max        0.9997573
exploration/Actions Min        -0.99997294
exploration/Num Paths          10
exploration/Average Returns    480.2139826113251
evaluation/num steps total     3040000
evaluation/num paths total     6080
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9643159602341271
evaluation/Rewards Std         0.04792922187231989
evaluation/Rewards Max         0.9785272425610286
evaluation/Rewards Min         0.49061284039932307
evaluation/Returns Mean        482.1579801170636
evaluation/Returns Std         0.30668606847751223
evaluation/Returns Max         482.6349742138105
evaluation/Returns Min         481.7265304676556
evaluation/ExplReturns Mean    482.1579801170636
evaluation/ExplReturns Std     0.30668606847751223
evaluation/ExplReturns Max     482.6349742138105
evaluation/ExplReturns Min     481.7265304676556
evaluation/Actions Mean        0.030326176
evaluation/Actions Std         0.39450958
evaluation/Actions Max         0.9983113
evaluation/Actions Min         -0.99952567
evaluation/Num Paths           10
evaluation/Average Returns     482.1579801170636
time/data storing (s)          0.03201717045158148
time/evaluation sampling (s)   111.29935452900827
time/exploration sampling (s)  111.69779064040631
time/logging (s)               0.030595814809203148
time/saving (s)                0.012073496356606483
time/training (s)              9.59411580208689
time/epoch (s)                 232.66594745311886
time/total (s)                 142521.82026918326
Epoch                          607
-----------------------------  ---------------------
2023-08-02 09:33:27.544237 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 608 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3673.2876]
trainer/QF1 Loss               0.021231472
trainer/QF2 Loss               0.01880002
trainer/Policy Loss            -89.44568
trainer/Q1 Predictions Mean    102.46523
trainer/Q1 Predictions Std     2.7490413
trainer/Q1 Predictions Max     104.37732
trainer/Q1 Predictions Min     63.40944
trainer/Q2 Predictions Mean    102.46187
trainer/Q2 Predictions Std     2.8065302
trainer/Q2 Predictions Max     104.48555
trainer/Q2 Predictions Min     62.597027
trainer/Q Targets Mean         102.47038
trainer/Q Targets Std          2.7899475
trainer/Q Targets Max          104.48776
trainer/Q Targets Min          62.541462
trainer/Log Pis Mean           13.097921
trainer/Log Pis Std            7.8930516
trainer/Log Pis Max            66.04406
trainer/Log Pis Min            -3.1901526
trainer/Policy mu Mean         -0.08752365
trainer/Policy mu Std          1.6189808
trainer/Policy mu Max          5.4626765
trainer/Policy mu Min          -6.399914
trainer/Policy log std Mean    -0.71964914
trainer/Policy log std Std     0.281103
trainer/Policy log std Max     0.3475684
trainer/Policy log std Min     -2.01232
trainer/Alpha                  0.0014435892226174474
trainer/Alpha Loss             7.18106746673584
exploration/num steps total    3046000
exploration/num paths total    6092
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.95867844628893
exploration/Rewards Std        0.04876496698917165
exploration/Rewards Max        0.9793069569210154
exploration/Rewards Min        0.49509894641075497
exploration/Returns Mean       479.3392231444649
exploration/Returns Std        0.2706322983184698
exploration/Returns Max        479.79584343886944
exploration/Returns Min        478.9091180558124
exploration/Actions Mean       -0.035649616
exploration/Actions Std        0.62248015
exploration/Actions Max        0.99971545
exploration/Actions Min        -0.9999408
exploration/Num Paths          10
exploration/Average Returns    479.3392231444649
evaluation/num steps total     3045000
evaluation/num paths total     6090
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9602376649244525
evaluation/Rewards Std         0.04940355191562388
evaluation/Rewards Max         0.9795149799076784
evaluation/Rewards Min         0.4913156976850632
evaluation/Returns Mean        480.11883246222607
evaluation/Returns Std         0.5512999782416167
evaluation/Returns Max         480.7273533764418
evaluation/Returns Min         478.74144743957373
evaluation/ExplReturns Mean    480.11883246222607
evaluation/ExplReturns Std     0.5512999782416167
evaluation/ExplReturns Max     480.7273533764418
evaluation/ExplReturns Min     478.74144743957373
evaluation/Actions Mean        -0.04095801
evaluation/Actions Std         0.50099397
evaluation/Actions Max         0.99888235
evaluation/Actions Min         -0.99974424
evaluation/Num Paths           10
evaluation/Average Returns     480.11883246222607
time/data storing (s)          0.03203630819916725
time/evaluation sampling (s)   113.3176857335493
time/exploration sampling (s)  112.94202060904354
time/logging (s)               0.030590618029236794
time/saving (s)                0.011485117487609386
time/training (s)              9.6607562340796
time/epoch (s)                 235.99457462038845
time/total (s)                 142757.81764990743
Epoch                          608
-----------------------------  ---------------------
2023-08-02 09:37:21.130214 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 609 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3531.1255]
trainer/QF1 Loss               0.015424846
trainer/QF2 Loss               0.013584841
trainer/Policy Loss            -90.68241
trainer/Q1 Predictions Mean    102.485725
trainer/Q1 Predictions Std     1.3143413
trainer/Q1 Predictions Max     104.45497
trainer/Q1 Predictions Min     93.27998
trainer/Q2 Predictions Mean    102.491844
trainer/Q2 Predictions Std     1.3023553
trainer/Q2 Predictions Max     104.37879
trainer/Q2 Predictions Min     93.28339
trainer/Q Targets Mean         102.54027
trainer/Q Targets Std          1.3138238
trainer/Q Targets Max          104.43175
trainer/Q Targets Min          93.05431
trainer/Log Pis Mean           11.88077
trainer/Log Pis Std            7.9792547
trainer/Log Pis Max            50.6808
trainer/Log Pis Min            -2.678442
trainer/Policy mu Mean         0.005257728
trainer/Policy mu Std          1.5874947
trainer/Policy mu Max          5.014085
trainer/Policy mu Min          -5.6652446
trainer/Policy log std Mean    -0.7323534
trainer/Policy log std Std     0.27639005
trainer/Policy log std Max     0.05361799
trainer/Policy log std Min     -1.9175671
trainer/Alpha                  0.0013800879241898656
trainer/Alpha Loss             -0.7852035760879517
exploration/num steps total    3051000
exploration/num paths total    6102
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9607652688401631
exploration/Rewards Std        0.04869564843860889
exploration/Rewards Max        0.9793925059084856
exploration/Rewards Min        0.4981254966506793
exploration/Returns Mean       480.3826344200817
exploration/Returns Std        0.7170459105178635
exploration/Returns Max        481.6122784068818
exploration/Returns Min        479.1226676182306
exploration/Actions Mean       0.0056378017
exploration/Actions Std        0.5931094
exploration/Actions Max        0.99961376
exploration/Actions Min        -0.9999942
exploration/Num Paths          10
exploration/Average Returns    480.3826344200817
evaluation/num steps total     3050000
evaluation/num paths total     6100
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9609163896168448
evaluation/Rewards Std         0.050157969503361294
evaluation/Rewards Max         0.9796207146337171
evaluation/Rewards Min         0.4929685020356382
evaluation/Returns Mean        480.4581948084224
evaluation/Returns Std         3.839277517649136
evaluation/Returns Max         482.1778888279007
evaluation/Returns Min         468.98553916559644
evaluation/ExplReturns Mean    480.4581948084224
evaluation/ExplReturns Std     3.839277517649136
evaluation/ExplReturns Max     482.1778888279007
evaluation/ExplReturns Min     468.98553916559644
evaluation/Actions Mean        0.0057427497
evaluation/Actions Std         0.46884134
evaluation/Actions Max         0.99817604
evaluation/Actions Min         -0.9997686
evaluation/Num Paths           10
evaluation/Average Returns     480.4581948084224
time/data storing (s)          0.03175888955593109
time/evaluation sampling (s)   111.93439952749759
time/exploration sampling (s)  112.01372795179486
time/logging (s)               0.030503103509545326
time/saving (s)                0.010800885036587715
time/training (s)              9.557388728484511
time/epoch (s)                 233.57857908587903
time/total (s)                 142991.39871489815
Epoch                          609
-----------------------------  ---------------------
2023-08-02 09:41:14.409622 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 610 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3674.7932]
trainer/QF1 Loss               0.020243563
trainer/QF2 Loss               0.01377381
trainer/Policy Loss            -91.202614
trainer/Q1 Predictions Mean    102.60232
trainer/Q1 Predictions Std     1.1846105
trainer/Q1 Predictions Max     104.0687
trainer/Q1 Predictions Min     93.40805
trainer/Q2 Predictions Mean    102.64235
trainer/Q2 Predictions Std     1.1383566
trainer/Q2 Predictions Max     104.05977
trainer/Q2 Predictions Min     93.75953
trainer/Q Targets Mean         102.671646
trainer/Q Targets Std          1.1328346
trainer/Q Targets Max          104.07091
trainer/Q Targets Min          94.44275
trainer/Log Pis Mean           11.504496
trainer/Log Pis Std            7.0017366
trainer/Log Pis Max            50.571804
trainer/Log Pis Min            -6.1432
trainer/Policy mu Mean         0.062820055
trainer/Policy mu Std          1.5475112
trainer/Policy mu Max          6.5177546
trainer/Policy mu Min          -5.1010094
trainer/Policy log std Mean    -0.73155594
trainer/Policy log std Std     0.28107512
trainer/Policy log std Max     0.012534171
trainer/Policy log std Min     -1.9003875
trainer/Alpha                  0.0014008409343659878
trainer/Alpha Loss             -3.255711078643799
exploration/num steps total    3056000
exploration/num paths total    6112
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9600711563641471
exploration/Rewards Std        0.048915615767750144
exploration/Rewards Max        0.9795873802597423
exploration/Rewards Min        0.4927632242136204
exploration/Returns Mean       480.03557818207344
exploration/Returns Std        3.0288986780526344
exploration/Returns Max        481.9945189816005
exploration/Returns Min        471.54647150808364
exploration/Actions Mean       0.078383796
exploration/Actions Std        0.6035127
exploration/Actions Max        0.99993825
exploration/Actions Min        -0.9999368
exploration/Num Paths          10
exploration/Average Returns    480.03557818207344
evaluation/num steps total     3055000
evaluation/num paths total     6110
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9550388402964188
evaluation/Rewards Std         0.051773553242663785
evaluation/Rewards Max         0.9785448982012785
evaluation/Rewards Min         0.49463030682755876
evaluation/Returns Mean        477.51942014820924
evaluation/Returns Std         4.108860349618598
evaluation/Returns Max         482.2148039717771
evaluation/Returns Min         470.20839349857204
evaluation/ExplReturns Mean    477.51942014820924
evaluation/ExplReturns Std     4.108860349618598
evaluation/ExplReturns Max     482.2148039717771
evaluation/ExplReturns Min     470.20839349857204
evaluation/Actions Mean        0.11122004
evaluation/Actions Std         0.53882253
evaluation/Actions Max         0.99988735
evaluation/Actions Min         -0.9998572
evaluation/Num Paths           10
evaluation/Average Returns     477.51942014820924
time/data storing (s)          0.03209583554416895
time/evaluation sampling (s)   111.61113807745278
time/exploration sampling (s)  111.96475304104388
time/logging (s)               0.030627231113612652
time/saving (s)                0.010397338308393955
time/training (s)              9.62307420372963
time/epoch (s)                 233.27208572719246
time/total (s)                 143224.67337958887
Epoch                          610
-----------------------------  ---------------------
2023-08-02 09:45:08.427414 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 611 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3654.496]
trainer/QF1 Loss               0.021683278
trainer/QF2 Loss               0.02114521
trainer/Policy Loss            -89.62276
trainer/Q1 Predictions Mean    102.40579
trainer/Q1 Predictions Std     1.7630483
trainer/Q1 Predictions Max     104.15413
trainer/Q1 Predictions Min     84.07534
trainer/Q2 Predictions Mean    102.432625
trainer/Q2 Predictions Std     1.8000833
trainer/Q2 Predictions Max     104.12201
trainer/Q2 Predictions Min     83.87426
trainer/Q Targets Mean         102.42006
trainer/Q Targets Std          1.7709498
trainer/Q Targets Max          104.090836
trainer/Q Targets Min          84.05062
trainer/Log Pis Mean           12.881249
trainer/Log Pis Std            8.71872
trainer/Log Pis Max            71.35192
trainer/Log Pis Min            -3.9294324
trainer/Policy mu Mean         -0.061608825
trainer/Policy mu Std          1.6548262
trainer/Policy mu Max          15.219496
trainer/Policy mu Min          -8.56338
trainer/Policy log std Mean    -0.74071455
trainer/Policy log std Std     0.29211822
trainer/Policy log std Max     0.725072
trainer/Policy log std Min     -2.1496878
trainer/Alpha                  0.0013864835491403937
trainer/Alpha Loss             5.799582481384277
exploration/num steps total    3061000
exploration/num paths total    6122
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9632937791301037
exploration/Rewards Std        0.05128131145000641
exploration/Rewards Max        0.9798828422229419
exploration/Rewards Min        0.49043313408650696
exploration/Returns Mean       481.6468895650517
exploration/Returns Std        0.7373205933543036
exploration/Returns Max        482.4238205219512
exploration/Returns Min        480.4858053928452
exploration/Actions Mean       0.042819593
exploration/Actions Std        0.6232151
exploration/Actions Max        0.9994965
exploration/Actions Min        -0.99994075
exploration/Num Paths          10
exploration/Average Returns    481.6468895650517
evaluation/num steps total     3060000
evaluation/num paths total     6120
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9627919438750683
evaluation/Rewards Std         0.05370703305373401
evaluation/Rewards Max         0.9794633260315533
evaluation/Rewards Min         0.48960268245993177
evaluation/Returns Mean        481.395971937534
evaluation/Returns Std         0.7151555574335614
evaluation/Returns Max         482.87042554295107
evaluation/Returns Min         480.43621616684686
evaluation/ExplReturns Mean    481.395971937534
evaluation/ExplReturns Std     0.7151555574335614
evaluation/ExplReturns Max     482.87042554295107
evaluation/ExplReturns Min     480.43621616684686
evaluation/Actions Mean        0.041802302
evaluation/Actions Std         0.5105271
evaluation/Actions Max         0.9971637
evaluation/Actions Min         -0.99980474
evaluation/Num Paths           10
evaluation/Average Returns     481.395971937534
time/data storing (s)          0.032331306487321854
time/evaluation sampling (s)   111.91807726491243
time/exploration sampling (s)  112.37530667055398
time/logging (s)               0.030873630195856094
time/saving (s)                0.010682528838515282
time/training (s)              9.643379122950137
time/epoch (s)                 234.01065052393824
time/total (s)                 143458.6865278175
Epoch                          611
-----------------------------  ---------------------
2023-08-02 09:49:00.749340 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 612 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4382.232]
trainer/QF1 Loss               0.020723496
trainer/QF2 Loss               0.015350218
trainer/Policy Loss            -90.84964
trainer/Q1 Predictions Mean    102.56772
trainer/Q1 Predictions Std     0.9896769
trainer/Q1 Predictions Max     106.982155
trainer/Q1 Predictions Min     97.09074
trainer/Q2 Predictions Mean    102.63218
trainer/Q2 Predictions Std     0.99195457
trainer/Q2 Predictions Max     106.99098
trainer/Q2 Predictions Min     97.10242
trainer/Q Targets Mean         102.64555
trainer/Q Targets Std          0.99888545
trainer/Q Targets Max          107.024506
trainer/Q Targets Min          96.99563
trainer/Log Pis Mean           11.814814
trainer/Log Pis Std            7.342257
trainer/Log Pis Max            34.11006
trainer/Log Pis Min            -4.759177
trainer/Policy mu Mean         -0.14410491
trainer/Policy mu Std          1.5883399
trainer/Policy mu Max          5.0200605
trainer/Policy mu Min          -5.378465
trainer/Policy log std Mean    -0.7195189
trainer/Policy log std Std     0.28629577
trainer/Policy log std Max     0.16778052
trainer/Policy log std Min     -2.301144
trainer/Alpha                  0.0013923142105340958
trainer/Alpha Loss             -1.2179319858551025
exploration/num steps total    3066000
exploration/num paths total    6132
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9583559366863342
exploration/Rewards Std        0.051858914887873496
exploration/Rewards Max        0.9784117234605205
exploration/Rewards Min        0.4913287359026093
exploration/Returns Mean       479.17796834316715
exploration/Returns Std        0.8825242930866514
exploration/Returns Max        480.1370991644568
exploration/Returns Min        477.41314995408516
exploration/Actions Mean       0.00024166782
exploration/Actions Std        0.6030233
exploration/Actions Max        0.99974835
exploration/Actions Min        -0.9999973
exploration/Num Paths          10
exploration/Average Returns    479.17796834316715
evaluation/num steps total     3065000
evaluation/num paths total     6130
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.96063420881635
evaluation/Rewards Std         0.04943576024278412
evaluation/Rewards Max         0.9786473336184077
evaluation/Rewards Min         0.4969951476523091
evaluation/Returns Mean        480.31710440817494
evaluation/Returns Std         0.723430608191999
evaluation/Returns Max         481.6899370735203
evaluation/Returns Min         479.21516768408355
evaluation/ExplReturns Mean    480.31710440817494
evaluation/ExplReturns Std     0.723430608191999
evaluation/ExplReturns Max     481.6899370735203
evaluation/ExplReturns Min     479.21516768408355
evaluation/Actions Mean        -0.024381762
evaluation/Actions Std         0.46021196
evaluation/Actions Max         0.99809176
evaluation/Actions Min         -0.99947655
evaluation/Num Paths           10
evaluation/Average Returns     480.31710440817494
time/data storing (s)          0.03177774325013161
time/evaluation sampling (s)   110.99133772868663
time/exploration sampling (s)  111.64292541891336
time/logging (s)               0.03035012725740671
time/saving (s)                0.01275651529431343
time/training (s)              9.604932839050889
time/epoch (s)                 232.31408037245274
time/total (s)                 143691.00304569025
Epoch                          612
-----------------------------  ---------------------
2023-08-02 09:52:57.415637 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 613 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4347.121]
trainer/QF1 Loss               0.01853529
trainer/QF2 Loss               0.026410222
trainer/Policy Loss            -90.10067
trainer/Q1 Predictions Mean    102.51794
trainer/Q1 Predictions Std     1.463374
trainer/Q1 Predictions Max     104.06779
trainer/Q1 Predictions Min     89.44775
trainer/Q2 Predictions Mean    102.53733
trainer/Q2 Predictions Std     1.4447547
trainer/Q2 Predictions Max     104.07896
trainer/Q2 Predictions Min     90.80028
trainer/Q Targets Mean         102.50127
trainer/Q Targets Std          1.5106475
trainer/Q Targets Max          104.02761
trainer/Q Targets Min          88.93768
trainer/Log Pis Mean           12.492741
trainer/Log Pis Std            8.8007965
trainer/Log Pis Max            67.69885
trainer/Log Pis Min            -3.0510657
trainer/Policy mu Mean         -0.10312656
trainer/Policy mu Std          1.6103841
trainer/Policy mu Max          7.4495034
trainer/Policy mu Min          -7.041849
trainer/Policy log std Mean    -0.7322199
trainer/Policy log std Std     0.29252335
trainer/Policy log std Max     0.49814248
trainer/Policy log std Min     -2.8038282
trainer/Alpha                  0.001272475579753518
trainer/Alpha Loss             3.2851102352142334
exploration/num steps total    3071000
exploration/num paths total    6142
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9491496680668493
exploration/Rewards Std        0.06235354484844089
exploration/Rewards Max        0.9796526044424061
exploration/Rewards Min        0.4904175368525361
exploration/Returns Mean       474.57483403342485
exploration/Returns Std        8.179046819436081
exploration/Returns Max        479.6893380908437
exploration/Returns Min        450.64307634012135
exploration/Actions Mean       -0.05234116
exploration/Actions Std        0.6045011
exploration/Actions Max        0.9999968
exploration/Actions Min        -0.99995816
exploration/Num Paths          10
exploration/Average Returns    474.57483403342485
evaluation/num steps total     3070000
evaluation/num paths total     6140
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9596021122071848
evaluation/Rewards Std         0.05155756454502079
evaluation/Rewards Max         0.9798688009671948
evaluation/Rewards Min         0.4969275464618093
evaluation/Returns Mean        479.8010561035923
evaluation/Returns Std         3.12044984980555
evaluation/Returns Max         484.71301741806036
evaluation/Returns Min         476.305209923563
evaluation/ExplReturns Mean    479.8010561035923
evaluation/ExplReturns Std     3.12044984980555
evaluation/ExplReturns Max     484.71301741806036
evaluation/ExplReturns Min     476.305209923563
evaluation/Actions Mean        -0.005477348
evaluation/Actions Std         0.5159325
evaluation/Actions Max         0.99987394
evaluation/Actions Min         -0.9995211
evaluation/Num Paths           10
evaluation/Average Returns     479.8010561035923
time/data storing (s)          0.031875213608145714
time/evaluation sampling (s)   113.35658663511276
time/exploration sampling (s)  113.63034694362432
time/logging (s)               0.030569549649953842
time/saving (s)                0.01060468889772892
time/training (s)              9.599200239405036
time/epoch (s)                 236.65918327029794
time/total (s)                 143927.6647434896
Epoch                          613
-----------------------------  --------------------
2023-08-02 09:56:52.545174 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 614 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4340.927]
trainer/QF1 Loss               0.026460461
trainer/QF2 Loss               0.027826954
trainer/Policy Loss            -90.16666
trainer/Q1 Predictions Mean    102.32712
trainer/Q1 Predictions Std     2.0544264
trainer/Q1 Predictions Max     104.53419
trainer/Q1 Predictions Min     82.50962
trainer/Q2 Predictions Mean    102.312294
trainer/Q2 Predictions Std     2.0736444
trainer/Q2 Predictions Max     104.53081
trainer/Q2 Predictions Min     82.1468
trainer/Q Targets Mean         102.42543
trainer/Q Targets Std          2.0403798
trainer/Q Targets Max          104.505844
trainer/Q Targets Min          82.4987
trainer/Log Pis Mean           12.238368
trainer/Log Pis Std            9.524367
trainer/Log Pis Max            77.65195
trainer/Log Pis Min            -3.9672108
trainer/Policy mu Mean         0.045428976
trainer/Policy mu Std          1.6513476
trainer/Policy mu Max          14.128502
trainer/Policy mu Min          -8.597433
trainer/Policy log std Mean    -0.7459979
trainer/Policy log std Std     0.30657277
trainer/Policy log std Max     1.9786661
trainer/Policy log std Min     -2.1093416
trainer/Alpha                  0.001281254575587809
trainer/Alpha Loss             1.5875022411346436
exploration/num steps total    3076000
exploration/num paths total    6152
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9593724660996373
exploration/Rewards Std        0.0590041699730426
exploration/Rewards Max        0.9792683646293807
exploration/Rewards Min        0.4895857654925852
exploration/Returns Mean       479.68623304981855
exploration/Returns Std        3.016536569866853
exploration/Returns Max        482.4833387641531
exploration/Returns Min        474.2374386846962
exploration/Actions Mean       0.07704204
exploration/Actions Std        0.6211442
exploration/Actions Max        0.9999622
exploration/Actions Min        -0.999987
exploration/Num Paths          10
exploration/Average Returns    479.68623304981855
evaluation/num steps total     3075000
evaluation/num paths total     6150
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9618513187984048
evaluation/Rewards Std         0.05561627185017419
evaluation/Rewards Max         0.978751669308577
evaluation/Rewards Min         0.49136576283131767
evaluation/Returns Mean        480.9256593992024
evaluation/Returns Std         2.603798603619484
evaluation/Returns Max         483.8009877038379
evaluation/Returns Min         476.784115823255
evaluation/ExplReturns Mean    480.9256593992024
evaluation/ExplReturns Std     2.603798603619484
evaluation/ExplReturns Max     483.8009877038379
evaluation/ExplReturns Min     476.784115823255
evaluation/Actions Mean        0.09184274
evaluation/Actions Std         0.50871336
evaluation/Actions Max         0.9998435
evaluation/Actions Min         -0.9998632
evaluation/Num Paths           10
evaluation/Average Returns     480.9256593992024
time/data storing (s)          0.0322543578222394
time/evaluation sampling (s)   112.85595064610243
time/exploration sampling (s)  112.87925941962749
time/logging (s)               0.03081563673913479
time/saving (s)                0.012300149537622929
time/training (s)              9.31176702491939
time/epoch (s)                 235.1223472347483
time/total (s)                 144162.78960746713
Epoch                          614
-----------------------------  --------------------
2023-08-02 10:00:49.012515 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 615 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4195.0654]
trainer/QF1 Loss               0.033283
trainer/QF2 Loss               0.034553744
trainer/Policy Loss            -90.50473
trainer/Q1 Predictions Mean    102.38804
trainer/Q1 Predictions Std     1.1358273
trainer/Q1 Predictions Max     104.108154
trainer/Q1 Predictions Min     96.1778
trainer/Q2 Predictions Mean    102.38794
trainer/Q2 Predictions Std     1.1374731
trainer/Q2 Predictions Max     104.15437
trainer/Q2 Predictions Min     95.89934
trainer/Q Targets Mean         102.50834
trainer/Q Targets Std          1.106651
trainer/Q Targets Max          104.19714
trainer/Q Targets Min          96.221794
trainer/Log Pis Mean           11.968704
trainer/Log Pis Std            7.204313
trainer/Log Pis Max            37.85217
trainer/Log Pis Min            -7.099168
trainer/Policy mu Mean         0.13277064
trainer/Policy mu Std          1.5796629
trainer/Policy mu Max          5.0103464
trainer/Policy mu Min          -5.0255823
trainer/Policy log std Mean    -0.7240532
trainer/Policy log std Std     0.2806821
trainer/Policy log std Max     0.19697942
trainer/Policy log std Min     -1.8373088
trainer/Alpha                  0.0012938195141032338
trainer/Alpha Loss             -0.20812100172042847
exploration/num steps total    3081000
exploration/num paths total    6162
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9013066023653215
exploration/Rewards Std        0.12214846711308802
exploration/Rewards Max        0.978578636934254
exploration/Rewards Min        0.31306613294752816
exploration/Returns Mean       450.65330118266064
exploration/Returns Std        28.46150893258517
exploration/Returns Max        481.84543221129564
exploration/Returns Min        403.142235509851
exploration/Actions Mean       0.1599971
exploration/Actions Std        0.6611132
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    450.65330118266064
evaluation/num steps total     3080000
evaluation/num paths total     6160
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.943534791254124
evaluation/Rewards Std         0.06580351666241
evaluation/Rewards Max         0.9791882306366821
evaluation/Rewards Min         0.49434031155500213
evaluation/Returns Mean        471.76739562706206
evaluation/Returns Std         13.508535756002981
evaluation/Returns Max         481.89730363993056
evaluation/Returns Min         431.70071880090677
evaluation/ExplReturns Mean    471.76739562706206
evaluation/ExplReturns Std     13.508535756002981
evaluation/ExplReturns Max     481.89730363993056
evaluation/ExplReturns Min     431.70071880090677
evaluation/Actions Mean        0.223939
evaluation/Actions Std         0.53095627
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     471.76739562706206
time/data storing (s)          0.032534245401620865
time/evaluation sampling (s)   113.28055103868246
time/exploration sampling (s)  113.49311929009855
time/logging (s)               0.030487196519970894
time/saving (s)                0.012398521415889263
time/training (s)              9.610521917231381
time/epoch (s)                 236.45961220934987
time/total (s)                 144399.2517352989
Epoch                          615
-----------------------------  ---------------------
2023-08-02 10:04:47.050748 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 616 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4331.3076]
trainer/QF1 Loss               0.015790218
trainer/QF2 Loss               0.028833535
trainer/Policy Loss            -90.45937
trainer/Q1 Predictions Mean    102.561874
trainer/Q1 Predictions Std     1.7031552
trainer/Q1 Predictions Max     106.21438
trainer/Q1 Predictions Min     79.24366
trainer/Q2 Predictions Mean    102.44008
trainer/Q2 Predictions Std     1.6815784
trainer/Q2 Predictions Max     106.10379
trainer/Q2 Predictions Min     79.3642
trainer/Q Targets Mean         102.5441
trainer/Q Targets Std          1.662517
trainer/Q Targets Max          106.26956
trainer/Q Targets Min          80.10681
trainer/Log Pis Mean           12.091035
trainer/Log Pis Std            7.3420224
trainer/Log Pis Max            49.146835
trainer/Log Pis Min            -2.6318967
trainer/Policy mu Mean         -0.06621811
trainer/Policy mu Std          1.5996964
trainer/Policy mu Max          5.015768
trainer/Policy mu Min          -8.27246
trainer/Policy log std Mean    -0.7600009
trainer/Policy log std Std     0.29309216
trainer/Policy log std Max     0.69122493
trainer/Policy log std Min     -2.1753263
trainer/Alpha                  0.0012512808898463845
trainer/Alpha Loss             0.6084522008895874
exploration/num steps total    3086000
exploration/num paths total    6172
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9560053079311063
exploration/Rewards Std        0.053081437691804095
exploration/Rewards Max        0.9786050623547503
exploration/Rewards Min        0.4942468868908762
exploration/Returns Mean       478.00265396555324
exploration/Returns Std        1.5511606553031585
exploration/Returns Max        480.31341254101005
exploration/Returns Min        475.6339728196302
exploration/Actions Mean       -0.034686428
exploration/Actions Std        0.6468668
exploration/Actions Max        0.9999874
exploration/Actions Min        -0.9999638
exploration/Num Paths          10
exploration/Average Returns    478.00265396555324
evaluation/num steps total     3085000
evaluation/num paths total     6170
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9632295019727589
evaluation/Rewards Std         0.0491982475990292
evaluation/Rewards Max         0.9796099132617861
evaluation/Rewards Min         0.4790703549521199
evaluation/Returns Mean        481.6147509863796
evaluation/Returns Std         0.6994874269235659
evaluation/Returns Max         482.9552320179728
evaluation/Returns Min         480.1401371226313
evaluation/ExplReturns Mean    481.6147509863796
evaluation/ExplReturns Std     0.6994874269235659
evaluation/ExplReturns Max     482.9552320179728
evaluation/ExplReturns Min     480.1401371226313
evaluation/Actions Mean        0.0028327315
evaluation/Actions Std         0.4709638
evaluation/Actions Max         0.9992786
evaluation/Actions Min         -0.9999031
evaluation/Num Paths           10
evaluation/Average Returns     481.6147509863796
time/data storing (s)          0.0317971296608448
time/evaluation sampling (s)   115.1469455100596
time/exploration sampling (s)  113.24608104582876
time/logging (s)               0.030436321161687374
time/saving (s)                0.012710985727608204
time/training (s)              9.562841072678566
time/epoch (s)                 238.03081206511706
time/total (s)                 144637.28502749186
Epoch                          616
-----------------------------  ---------------------
2023-08-02 10:08:44.379158 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 617 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4037.228]
trainer/QF1 Loss               0.016318453
trainer/QF2 Loss               0.0152699435
trainer/Policy Loss            -90.022156
trainer/Q1 Predictions Mean    102.406525
trainer/Q1 Predictions Std     1.8471676
trainer/Q1 Predictions Max     104.48411
trainer/Q1 Predictions Min     79.860596
trainer/Q2 Predictions Mean    102.42378
trainer/Q2 Predictions Std     1.8698169
trainer/Q2 Predictions Max     104.447876
trainer/Q2 Predictions Min     79.51913
trainer/Q Targets Mean         102.42084
trainer/Q Targets Std          1.8749878
trainer/Q Targets Max          104.48925
trainer/Q Targets Min          79.43898
trainer/Log Pis Mean           12.468503
trainer/Log Pis Std            8.7848625
trainer/Log Pis Max            67.31658
trainer/Log Pis Min            -4.748524
trainer/Policy mu Mean         0.010815151
trainer/Policy mu Std          1.6368076
trainer/Policy mu Max          7.388292
trainer/Policy mu Min          -7.8129387
trainer/Policy log std Mean    -0.72258043
trainer/Policy log std Std     0.28220305
trainer/Policy log std Max     0.53790426
trainer/Policy log std Min     -2.06859
trainer/Alpha                  0.0013216632651165128
trainer/Alpha Loss             3.1056978702545166
exploration/num steps total    3091000
exploration/num paths total    6182
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.890479990416779
exploration/Rewards Std        0.1467764264569562
exploration/Rewards Max        0.9793462946427444
exploration/Rewards Min        0.2658015674119795
exploration/Returns Mean       445.2399952083897
exploration/Returns Std        32.119248135816406
exploration/Returns Max        476.28905083575995
exploration/Returns Min        384.2761799981428
exploration/Actions Mean       0.062059827
exploration/Actions Std        0.66210514
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    445.2399952083897
evaluation/num steps total     3090000
evaluation/num paths total     6180
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.7903197360029354
evaluation/Rewards Std         0.25391232113514983
evaluation/Rewards Max         0.9790429971439668
evaluation/Rewards Min         0.10669460216005405
evaluation/Returns Mean        395.1598680014677
evaluation/Returns Std         44.865043223860305
evaluation/Returns Max         478.50434960146197
evaluation/Returns Min         333.7252384339995
evaluation/ExplReturns Mean    395.1598680014677
evaluation/ExplReturns Std     44.865043223860305
evaluation/ExplReturns Max     478.50434960146197
evaluation/ExplReturns Min     333.7252384339995
evaluation/Actions Mean        0.14229363
evaluation/Actions Std         0.71455544
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     395.1598680014677
time/data storing (s)          0.032072813250124454
time/evaluation sampling (s)   113.80480988137424
time/exploration sampling (s)  113.88381524104625
time/logging (s)               0.030385113321244717
time/saving (s)                0.010609406046569347
time/training (s)              9.559160841628909
time/epoch (s)                 237.32085329666734
time/total (s)                 144874.60847093817
Epoch                          617
-----------------------------  ---------------------
2023-08-02 10:12:40.113754 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 618 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4134.8315]
trainer/QF1 Loss               0.022956
trainer/QF2 Loss               0.018532049
trainer/Policy Loss            -90.67162
trainer/Q1 Predictions Mean    102.32261
trainer/Q1 Predictions Std     1.5222951
trainer/Q1 Predictions Max     104.27505
trainer/Q1 Predictions Min     84.41266
trainer/Q2 Predictions Mean    102.42998
trainer/Q2 Predictions Std     1.589412
trainer/Q2 Predictions Max     104.3098
trainer/Q2 Predictions Min     83.00139
trainer/Q Targets Mean         102.41116
trainer/Q Targets Std          1.5519327
trainer/Q Targets Max          104.33354
trainer/Q Targets Min          84.000465
trainer/Log Pis Mean           11.759747
trainer/Log Pis Std            7.9381375
trainer/Log Pis Max            69.577484
trainer/Log Pis Min            -3.5500808
trainer/Policy mu Mean         0.0065295175
trainer/Policy mu Std          1.5711625
trainer/Policy mu Max          6.1616526
trainer/Policy mu Min          -5.609588
trainer/Policy log std Mean    -0.73659515
trainer/Policy log std Std     0.26791593
trainer/Policy log std Max     0.2236216
trainer/Policy log std Min     -2.0143988
trainer/Alpha                  0.001301643787883222
trainer/Alpha Loss             -1.596212387084961
exploration/num steps total    3096000
exploration/num paths total    6192
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9545036045181825
exploration/Rewards Std        0.04734091828449482
exploration/Rewards Max        0.979543477726809
exploration/Rewards Min        0.4967171455819925
exploration/Returns Mean       477.2518022590913
exploration/Returns Std        0.725510806288674
exploration/Returns Max        478.33346099259865
exploration/Returns Min        475.64544135984715
exploration/Actions Mean       -0.030102618
exploration/Actions Std        0.56879044
exploration/Actions Max        0.9999133
exploration/Actions Min        -0.9999865
exploration/Num Paths          10
exploration/Average Returns    477.2518022590913
evaluation/num steps total     3095000
evaluation/num paths total     6190
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9582272096287725
evaluation/Rewards Std         0.05420826354939522
evaluation/Rewards Max         0.9788184181751828
evaluation/Rewards Min         0.4845512836203436
evaluation/Returns Mean        479.11360481438624
evaluation/Returns Std         4.719838833289622
evaluation/Returns Max         484.05746815841724
evaluation/Returns Min         467.45009844946935
evaluation/ExplReturns Mean    479.11360481438624
evaluation/ExplReturns Std     4.719838833289622
evaluation/ExplReturns Max     484.05746815841724
evaluation/ExplReturns Min     467.45009844946935
evaluation/Actions Mean        0.08455823
evaluation/Actions Std         0.53016376
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999994
evaluation/Num Paths           10
evaluation/Average Returns     479.11360481438624
time/data storing (s)          0.032172744162380695
time/evaluation sampling (s)   113.01339070592076
time/exploration sampling (s)  112.99531204998493
time/logging (s)               0.03186248429119587
time/saving (s)                0.012956629507243633
time/training (s)              9.642898707650602
time/epoch (s)                 235.7285933215171
time/total (s)                 145110.33956627082
Epoch                          618
-----------------------------  --------------------
2023-08-02 10:16:35.852723 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 619 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4053.4556]
trainer/QF1 Loss               0.012425349
trainer/QF2 Loss               0.06871425
trainer/Policy Loss            -91.938126
trainer/Q1 Predictions Mean    102.6013
trainer/Q1 Predictions Std     0.9100294
trainer/Q1 Predictions Max     104.44577
trainer/Q1 Predictions Min     96.05006
trainer/Q2 Predictions Mean    102.781364
trainer/Q2 Predictions Std     0.89851373
trainer/Q2 Predictions Max     104.60516
trainer/Q2 Predictions Min     96.250275
trainer/Q Targets Mean         102.54209
trainer/Q Targets Std          0.9033633
trainer/Q Targets Max          104.27492
trainer/Q Targets Min          96.09104
trainer/Log Pis Mean           10.7761545
trainer/Log Pis Std            7.1958623
trainer/Log Pis Max            42.258614
trainer/Log Pis Min            -2.4789655
trainer/Policy mu Mean         -0.099035144
trainer/Policy mu Std          1.5210674
trainer/Policy mu Max          5.092306
trainer/Policy mu Min          -5.763255
trainer/Policy log std Mean    -0.71748275
trainer/Policy log std Std     0.25154415
trainer/Policy log std Max     0.28322405
trainer/Policy log std Min     -1.8385332
trainer/Alpha                  0.0013484822120517492
trainer/Alpha Loss             -8.088011741638184
exploration/num steps total    3101000
exploration/num paths total    6202
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.957635947349641
exploration/Rewards Std        0.04944096401251462
exploration/Rewards Max        0.9792298424856973
exploration/Rewards Min        0.4933888276887257
exploration/Returns Mean       478.8179736748205
exploration/Returns Std        0.905335563997096
exploration/Returns Max        480.82253583567405
exploration/Returns Min        477.05826063077956
exploration/Actions Mean       -0.11765662
exploration/Actions Std        0.5912267
exploration/Actions Max        0.99996454
exploration/Actions Min        -0.9999874
exploration/Num Paths          10
exploration/Average Returns    478.8179736748205
evaluation/num steps total     3100000
evaluation/num paths total     6200
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9545738609580119
evaluation/Rewards Std         0.048800085325323865
evaluation/Rewards Max         0.9789824069486187
evaluation/Rewards Min         0.49717672149891756
evaluation/Returns Mean        477.2869304790059
evaluation/Returns Std         1.9666985062817186
evaluation/Returns Max         482.46910316318167
evaluation/Returns Min         474.93400117324137
evaluation/ExplReturns Mean    477.2869304790059
evaluation/ExplReturns Std     1.9666985062817186
evaluation/ExplReturns Max     482.46910316318167
evaluation/ExplReturns Min     474.93400117324137
evaluation/Actions Mean        -0.08342377
evaluation/Actions Std         0.5092346
evaluation/Actions Max         0.9989799
evaluation/Actions Min         -0.999862
evaluation/Num Paths           10
evaluation/Average Returns     477.2869304790059
time/data storing (s)          0.03239748254418373
time/evaluation sampling (s)   113.05504060257226
time/exploration sampling (s)  112.96253043785691
time/logging (s)               0.030421425588428974
time/saving (s)                0.011322707869112492
time/training (s)              9.638348836451769
time/epoch (s)                 235.73006149288267
time/total (s)                 145346.07216744684
Epoch                          619
-----------------------------  ---------------------
2023-08-02 10:20:32.156129 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 620 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3715.1995]
trainer/QF1 Loss               0.027611457
trainer/QF2 Loss               0.023167117
trainer/Policy Loss            -90.52029
trainer/Q1 Predictions Mean    102.19313
trainer/Q1 Predictions Std     2.4607687
trainer/Q1 Predictions Max     104.502846
trainer/Q1 Predictions Min     72.537125
trainer/Q2 Predictions Mean    102.24896
trainer/Q2 Predictions Std     2.3765948
trainer/Q2 Predictions Max     104.588844
trainer/Q2 Predictions Min     74.31826
trainer/Q Targets Mean         102.271935
trainer/Q Targets Std          2.4352236
trainer/Q Targets Max          104.57951
trainer/Q Targets Min          73.50897
trainer/Log Pis Mean           11.77593
trainer/Log Pis Std            9.3751745
trainer/Log Pis Max            67.77755
trainer/Log Pis Min            -3.209804
trainer/Policy mu Mean         -0.011106461
trainer/Policy mu Std          1.6203214
trainer/Policy mu Max          16.720856
trainer/Policy mu Min          -5.4465804
trainer/Policy log std Mean    -0.7542498
trainer/Policy log std Std     0.28529134
trainer/Policy log std Max     2.0
trainer/Policy log std Min     -2.2366717
trainer/Alpha                  0.001329732476733625
trainer/Alpha Loss             -1.4839625358581543
exploration/num steps total    3106000
exploration/num paths total    6212
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9385848406207602
exploration/Rewards Std        0.08090212781572759
exploration/Rewards Max        0.9797666882440197
exploration/Rewards Min        0.48895346741165313
exploration/Returns Mean       469.2924203103802
exploration/Returns Std        19.901720467529323
exploration/Returns Max        480.38537602948776
exploration/Returns Min        412.49358680296024
exploration/Actions Mean       0.032641057
exploration/Actions Std        0.64411616
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    469.2924203103802
evaluation/num steps total     3105000
evaluation/num paths total     6210
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9090968772458167
evaluation/Rewards Std         0.12849729551236225
evaluation/Rewards Max         0.9790752378761008
evaluation/Rewards Min         0.3241423457914054
evaluation/Returns Mean        454.54843862290846
evaluation/Returns Std         52.01991636101202
evaluation/Returns Max         482.541672605589
evaluation/Returns Min         307.50419528034325
evaluation/ExplReturns Mean    454.54843862290846
evaluation/ExplReturns Std     52.01991636101202
evaluation/ExplReturns Max     482.541672605589
evaluation/ExplReturns Min     307.50419528034325
evaluation/Actions Mean        0.04512324
evaluation/Actions Std         0.5842305
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     454.54843862290846
time/data storing (s)          0.03234550077468157
time/evaluation sampling (s)   113.6165896160528
time/exploration sampling (s)  112.97728337813169
time/logging (s)               0.03377246484160423
time/saving (s)                0.012502631172537804
time/training (s)              9.62680912669748
time/epoch (s)                 236.2993027176708
time/total (s)                 145582.37396377418
Epoch                          620
-----------------------------  --------------------
2023-08-02 10:24:28.086482 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 621 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4125.6484]
trainer/QF1 Loss               0.042615265
trainer/QF2 Loss               0.035256002
trainer/Policy Loss            -90.37395
trainer/Q1 Predictions Mean    102.379364
trainer/Q1 Predictions Std     1.3943628
trainer/Q1 Predictions Max     104.60364
trainer/Q1 Predictions Min     87.17805
trainer/Q2 Predictions Mean    102.33052
trainer/Q2 Predictions Std     1.3947197
trainer/Q2 Predictions Max     104.522644
trainer/Q2 Predictions Min     87.156685
trainer/Q Targets Mean         102.3561
trainer/Q Targets Std          1.444822
trainer/Q Targets Max          104.66608
trainer/Q Targets Min          87.21348
trainer/Log Pis Mean           12.045843
trainer/Log Pis Std            8.060642
trainer/Log Pis Max            63.5095
trainer/Log Pis Min            -4.3251343
trainer/Policy mu Mean         0.050721947
trainer/Policy mu Std          1.5810689
trainer/Policy mu Max          6.8424873
trainer/Policy mu Min          -6.002109
trainer/Policy log std Mean    -0.73371094
trainer/Policy log std Std     0.27685836
trainer/Policy log std Max     0.23988861
trainer/Policy log std Min     -2.3308911
trainer/Alpha                  0.0013650505570694804
trainer/Alpha Loss             0.3024017810821533
exploration/num steps total    3111000
exploration/num paths total    6222
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9502221061427113
exploration/Rewards Std        0.05666847709130003
exploration/Rewards Max        0.978410583151387
exploration/Rewards Min        0.498732657335474
exploration/Returns Mean       475.1110530713557
exploration/Returns Std        4.8213576873283746
exploration/Returns Max        480.3918438628011
exploration/Returns Min        463.0695229289606
exploration/Actions Mean       -0.011401247
exploration/Actions Std        0.60213983
exploration/Actions Max        0.99989504
exploration/Actions Min        -0.9999526
exploration/Num Paths          10
exploration/Average Returns    475.1110530713557
evaluation/num steps total     3110000
evaluation/num paths total     6220
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9463339631393958
evaluation/Rewards Std         0.045929665217830956
evaluation/Rewards Max         0.9797090883308475
evaluation/Rewards Min         0.4912900053272578
evaluation/Returns Mean        473.16698156969795
evaluation/Returns Std         0.22095005983152466
evaluation/Returns Max         473.6732135231025
evaluation/Returns Min         472.9229567418816
evaluation/ExplReturns Mean    473.16698156969795
evaluation/ExplReturns Std     0.22095005983152466
evaluation/ExplReturns Max     473.6732135231025
evaluation/ExplReturns Min     472.9229567418816
evaluation/Actions Mean        -0.12126899
evaluation/Actions Std         0.43646377
evaluation/Actions Max         0.9981886
evaluation/Actions Min         -0.9999148
evaluation/Num Paths           10
evaluation/Average Returns     473.16698156969795
time/data storing (s)          0.03213907405734062
time/evaluation sampling (s)   113.40054710581899
time/exploration sampling (s)  112.82101868931204
time/logging (s)               0.030605417676270008
time/saving (s)                0.010677640326321125
time/training (s)              9.624681262299418
time/epoch (s)                 235.91966918949038
time/total (s)                 145818.29615504853
Epoch                          621
-----------------------------  ---------------------
2023-08-02 10:28:24.190638 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 622 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4063.6365]
trainer/QF1 Loss               0.02092867
trainer/QF2 Loss               0.021235697
trainer/Policy Loss            -89.5099
trainer/Q1 Predictions Mean    102.337845
trainer/Q1 Predictions Std     1.2415384
trainer/Q1 Predictions Max     105.03631
trainer/Q1 Predictions Min     95.13189
trainer/Q2 Predictions Mean    102.39687
trainer/Q2 Predictions Std     1.2295675
trainer/Q2 Predictions Max     104.9688
trainer/Q2 Predictions Min     95.06776
trainer/Q Targets Mean         102.39247
trainer/Q Targets Std          1.2382107
trainer/Q Targets Max          104.90964
trainer/Q Targets Min          95.57777
trainer/Log Pis Mean           12.939835
trainer/Log Pis Std            7.7724724
trainer/Log Pis Max            44.94007
trainer/Log Pis Min            -9.810366
trainer/Policy mu Mean         0.10391212
trainer/Policy mu Std          1.6586108
trainer/Policy mu Max          6.377611
trainer/Policy mu Min          -6.3606844
trainer/Policy log std Mean    -0.72516966
trainer/Policy log std Std     0.2677081
trainer/Policy log std Max     0.4316159
trainer/Policy log std Min     -2.1692712
trainer/Alpha                  0.0013686815509572625
trainer/Alpha Loss             6.197626113891602
exploration/num steps total    3116000
exploration/num paths total    6232
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9619091006464813
exploration/Rewards Std        0.047040634919549094
exploration/Rewards Max        0.9798983828519076
exploration/Rewards Min        0.4866886773143807
exploration/Returns Mean       480.95455032324054
exploration/Returns Std        1.1235562377457398
exploration/Returns Max        483.24581281509234
exploration/Returns Min        479.35641686865534
exploration/Actions Mean       -0.10588674
exploration/Actions Std        0.59704494
exploration/Actions Max        0.9997893
exploration/Actions Min        -0.999959
exploration/Num Paths          10
exploration/Average Returns    480.95455032324054
evaluation/num steps total     3115000
evaluation/num paths total     6230
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.960754997706311
evaluation/Rewards Std         0.046760924003367746
evaluation/Rewards Max         0.9777366193168838
evaluation/Rewards Min         0.49539312192397483
evaluation/Returns Mean        480.37749885315543
evaluation/Returns Std         0.10963324156024025
evaluation/Returns Max         480.5614766418492
evaluation/Returns Min         480.16713614841774
evaluation/ExplReturns Mean    480.37749885315543
evaluation/ExplReturns Std     0.10963324156024025
evaluation/ExplReturns Max     480.5614766418492
evaluation/ExplReturns Min     480.16713614841774
evaluation/Actions Mean        -0.15615764
evaluation/Actions Std         0.48281634
evaluation/Actions Max         0.9971797
evaluation/Actions Min         -0.99965924
evaluation/Num Paths           10
evaluation/Average Returns     480.37749885315543
time/data storing (s)          0.031921377405524254
time/evaluation sampling (s)   113.48283292539418
time/exploration sampling (s)  112.99585789721459
time/logging (s)               0.03048048820346594
time/saving (s)                0.010215667076408863
time/training (s)              9.545271698385477
time/epoch (s)                 236.09658005367965
time/total (s)                 146054.39520700742
Epoch                          622
-----------------------------  ---------------------
2023-08-02 10:32:17.999000 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 623 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4153.9873]
trainer/QF1 Loss               0.016241085
trainer/QF2 Loss               0.020561941
trainer/Policy Loss            -91.42386
trainer/Q1 Predictions Mean    102.437515
trainer/Q1 Predictions Std     0.8425204
trainer/Q1 Predictions Max     103.61833
trainer/Q1 Predictions Min     97.390495
trainer/Q2 Predictions Mean    102.380585
trainer/Q2 Predictions Std     0.8453207
trainer/Q2 Predictions Max     103.632225
trainer/Q2 Predictions Min     97.36677
trainer/Q Targets Mean         102.44438
trainer/Q Targets Std          0.8475667
trainer/Q Targets Max          103.85448
trainer/Q Targets Min          97.16124
trainer/Log Pis Mean           11.041307
trainer/Log Pis Std            7.310577
trainer/Log Pis Max            39.858017
trainer/Log Pis Min            -4.557677
trainer/Policy mu Mean         0.11471083
trainer/Policy mu Std          1.5365726
trainer/Policy mu Max          4.608881
trainer/Policy mu Min          -4.9996614
trainer/Policy log std Mean    -0.7451207
trainer/Policy log std Std     0.25349942
trainer/Policy log std Max     0.11397077
trainer/Policy log std Min     -1.9340689
trainer/Alpha                  0.0013268563197925687
trainer/Alpha Loss             -6.351109027862549
exploration/num steps total    3121000
exploration/num paths total    6242
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9606320164887611
exploration/Rewards Std        0.05157152593018493
exploration/Rewards Max        0.9796337896068548
exploration/Rewards Min        0.47753349264617945
exploration/Returns Mean       480.31600824438055
exploration/Returns Std        1.47588181656164
exploration/Returns Max        481.39998524170073
exploration/Returns Min        476.12983550975156
exploration/Actions Mean       0.06476295
exploration/Actions Std        0.58800113
exploration/Actions Max        0.9997655
exploration/Actions Min        -0.99999946
exploration/Num Paths          10
exploration/Average Returns    480.31600824438055
evaluation/num steps total     3120000
evaluation/num paths total     6240
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9597115396184547
evaluation/Rewards Std         0.052682152232174824
evaluation/Rewards Max         0.9774482248783936
evaluation/Rewards Min         0.4924874175993281
evaluation/Returns Mean        479.85576980922724
evaluation/Returns Std         2.115894489467058
evaluation/Returns Max         481.82263664255623
evaluation/Returns Min         475.1024010742483
evaluation/ExplReturns Mean    479.85576980922724
evaluation/ExplReturns Std     2.115894489467058
evaluation/ExplReturns Max     481.82263664255623
evaluation/ExplReturns Min     475.1024010742483
evaluation/Actions Mean        0.039197993
evaluation/Actions Std         0.47903326
evaluation/Actions Max         0.9991917
evaluation/Actions Min         -0.99992615
evaluation/Num Paths           10
evaluation/Average Returns     479.85576980922724
time/data storing (s)          0.032151966355741024
time/evaluation sampling (s)   111.59304705355316
time/exploration sampling (s)  112.67874919530004
time/logging (s)               0.031256070360541344
time/saving (s)                0.012852396816015244
time/training (s)              9.453659269958735
time/epoch (s)                 233.80171595234424
time/total (s)                 146288.19938703347
Epoch                          623
-----------------------------  ---------------------
2023-08-02 10:36:07.874634 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 624 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3840.2515]
trainer/QF1 Loss               0.018707601
trainer/QF2 Loss               0.015316844
trainer/Policy Loss            -90.7825
trainer/Q1 Predictions Mean    102.43654
trainer/Q1 Predictions Std     1.0276592
trainer/Q1 Predictions Max     104.20867
trainer/Q1 Predictions Min     91.30476
trainer/Q2 Predictions Mean    102.45693
trainer/Q2 Predictions Std     1.0283831
trainer/Q2 Predictions Max     104.244385
trainer/Q2 Predictions Min     91.78434
trainer/Q Targets Mean         102.4722
trainer/Q Targets Std          1.0644752
trainer/Q Targets Max          104.193825
trainer/Q Targets Min          91.16186
trainer/Log Pis Mean           11.7540245
trainer/Log Pis Std            7.407011
trainer/Log Pis Max            56.97435
trainer/Log Pis Min            -3.5353324
trainer/Policy mu Mean         0.14223374
trainer/Policy mu Std          1.5794556
trainer/Policy mu Max          7.097588
trainer/Policy mu Min          -5.3955555
trainer/Policy log std Mean    -0.7318229
trainer/Policy log std Std     0.23392853
trainer/Policy log std Max     0.5259299
trainer/Policy log std Min     -1.7061119
trainer/Alpha                  0.0013627612497657537
trainer/Alpha Loss             -1.6230192184448242
exploration/num steps total    3126000
exploration/num paths total    6252
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9652746558696638
exploration/Rewards Std        0.04916558839719992
exploration/Rewards Max        0.9792966209996236
exploration/Rewards Min        0.49793806850343403
exploration/Returns Mean       482.63732793483194
exploration/Returns Std        0.262379460669206
exploration/Returns Max        483.14467723609897
exploration/Returns Min        482.37435483018277
exploration/Actions Mean       -0.032481913
exploration/Actions Std        0.5379303
exploration/Actions Max        0.99974555
exploration/Actions Min        -0.9999024
exploration/Num Paths          10
exploration/Average Returns    482.63732793483194
evaluation/num steps total     3125000
evaluation/num paths total     6250
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9644632596438402
evaluation/Rewards Std         0.048833404706580395
evaluation/Rewards Max         0.9786669700669697
evaluation/Rewards Min         0.49447248096654484
evaluation/Returns Mean        482.23162982191997
evaluation/Returns Std         0.17082018754349862
evaluation/Returns Max         482.4399110505172
evaluation/Returns Min         481.7840345714901
evaluation/ExplReturns Mean    482.23162982191997
evaluation/ExplReturns Std     0.17082018754349862
evaluation/ExplReturns Max     482.4399110505172
evaluation/ExplReturns Min     481.7840345714901
evaluation/Actions Mean        -0.013001911
evaluation/Actions Std         0.3668717
evaluation/Actions Max         0.99814266
evaluation/Actions Min         -0.9997686
evaluation/Num Paths           10
evaluation/Average Returns     482.23162982191997
time/data storing (s)          0.03192712925374508
time/evaluation sampling (s)   109.76764027401805
time/exploration sampling (s)  110.43327056244016
time/logging (s)               0.030160210095345974
time/saving (s)                0.012733380310237408
time/training (s)              9.591303080320358
time/epoch (s)                 229.8670346364379
time/total (s)                 146518.06897644512
Epoch                          624
-----------------------------  ---------------------
2023-08-02 10:40:00.153813 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 625 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4040.1301]
trainer/QF1 Loss               0.014252184
trainer/QF2 Loss               0.013068384
trainer/Policy Loss            -89.846695
trainer/Q1 Predictions Mean    102.547066
trainer/Q1 Predictions Std     1.0549911
trainer/Q1 Predictions Max     105.14375
trainer/Q1 Predictions Min     96.46984
trainer/Q2 Predictions Mean    102.523865
trainer/Q2 Predictions Std     1.0382658
trainer/Q2 Predictions Max     105.03184
trainer/Q2 Predictions Min     96.725494
trainer/Q Targets Mean         102.56857
trainer/Q Targets Std          1.0295461
trainer/Q Targets Max          105.042915
trainer/Q Targets Min          96.673706
trainer/Log Pis Mean           12.802036
trainer/Log Pis Std            9.767239
trainer/Log Pis Max            46.8581
trainer/Log Pis Min            -9.8933325
trainer/Policy mu Mean         -0.01903604
trainer/Policy mu Std          1.6668425
trainer/Policy mu Max          5.1764855
trainer/Policy mu Min          -6.0157814
trainer/Policy log std Mean    -0.69268924
trainer/Policy log std Std     0.26636124
trainer/Policy log std Max     0.507281
trainer/Policy log std Min     -1.8356928
trainer/Alpha                  0.0016461687628179789
trainer/Alpha Loss             5.140862941741943
exploration/num steps total    3131000
exploration/num paths total    6262
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9672048471487519
exploration/Rewards Std        0.047196710905699865
exploration/Rewards Max        0.9798254224520557
exploration/Rewards Min        0.49539351223366035
exploration/Returns Mean       483.602423574376
exploration/Returns Std        0.30270642939548437
exploration/Returns Max        484.12290279688654
exploration/Returns Min        483.07392956882234
exploration/Actions Mean       -0.02146476
exploration/Actions Std        0.58822095
exploration/Actions Max        0.9994199
exploration/Actions Min        -0.999926
exploration/Num Paths          10
exploration/Average Returns    483.602423574376
evaluation/num steps total     3130000
evaluation/num paths total     6260
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9676511205466491
evaluation/Rewards Std         0.047269208980209886
evaluation/Rewards Max         0.979784781294921
evaluation/Rewards Min         0.49748136971353757
evaluation/Returns Mean        483.8255602733246
evaluation/Returns Std         0.34129082528956955
evaluation/Returns Max         484.21207589820057
evaluation/Returns Min         483.0094102871055
evaluation/ExplReturns Mean    483.8255602733246
evaluation/ExplReturns Std     0.34129082528956955
evaluation/ExplReturns Max     484.21207589820057
evaluation/ExplReturns Min     483.0094102871055
evaluation/Actions Mean        -0.037441183
evaluation/Actions Std         0.4833461
evaluation/Actions Max         0.99779946
evaluation/Actions Min         -0.99966866
evaluation/Num Paths           10
evaluation/Average Returns     483.8255602733246
time/data storing (s)          0.03244271408766508
time/evaluation sampling (s)   111.02317838836461
time/exploration sampling (s)  111.483080544509
time/logging (s)               0.030588154681026936
time/saving (s)                0.010391969233751297
time/training (s)              9.692356759682298
time/epoch (s)                 232.27203853055835
time/total (s)                 146750.3436329011
Epoch                          625
-----------------------------  ---------------------
2023-08-02 10:43:59.006593 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 626 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3946.763]
trainer/QF1 Loss               0.049115382
trainer/QF2 Loss               0.025522944
trainer/Policy Loss            -90.27512
trainer/Q1 Predictions Mean    102.515076
trainer/Q1 Predictions Std     1.8151095
trainer/Q1 Predictions Max     105.75317
trainer/Q1 Predictions Min     85.716324
trainer/Q2 Predictions Mean    102.48162
trainer/Q2 Predictions Std     1.8271241
trainer/Q2 Predictions Max     105.72873
trainer/Q2 Predictions Min     85.94572
trainer/Q Targets Mean         102.42726
trainer/Q Targets Std          1.8225968
trainer/Q Targets Max          105.724655
trainer/Q Targets Min          86.11728
trainer/Log Pis Mean           12.317254
trainer/Log Pis Std            8.571518
trainer/Log Pis Max            58.363956
trainer/Log Pis Min            -5.438191
trainer/Policy mu Mean         -0.07317043
trainer/Policy mu Std          1.6354629
trainer/Policy mu Max          5.6369944
trainer/Policy mu Min          -8.570867
trainer/Policy log std Mean    -0.7139413
trainer/Policy log std Std     0.26742035
trainer/Policy log std Max     1.0792644
trainer/Policy log std Min     -2.090938
trainer/Alpha                  0.0016517018666490912
trainer/Alpha Loss             2.0323915481567383
exploration/num steps total    3136000
exploration/num paths total    6272
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8895694542315372
exploration/Rewards Std        0.11271115143334129
exploration/Rewards Max        0.9799302126477271
exploration/Rewards Min        0.4965865048984613
exploration/Returns Mean       444.7847271157686
exploration/Returns Std        41.3898912195571
exploration/Returns Max        480.18247304001216
exploration/Returns Min        379.49574096596746
exploration/Actions Mean       0.097364336
exploration/Actions Std        0.64423424
exploration/Actions Max        0.99999535
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    444.7847271157686
evaluation/num steps total     3135000
evaluation/num paths total     6270
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9541429636881905
evaluation/Rewards Std         0.052246532018652724
evaluation/Rewards Max         0.9792504962672416
evaluation/Rewards Min         0.49129419534255603
evaluation/Returns Mean        477.07148184409533
evaluation/Returns Std         3.512931183317464
evaluation/Returns Max         483.7148198055363
evaluation/Returns Min         471.1913931211512
evaluation/ExplReturns Mean    477.07148184409533
evaluation/ExplReturns Std     3.512931183317464
evaluation/ExplReturns Max     483.7148198055363
evaluation/ExplReturns Min     471.1913931211512
evaluation/Actions Mean        0.12284039
evaluation/Actions Std         0.5700628
evaluation/Actions Max         0.99983275
evaluation/Actions Min         -0.99976724
evaluation/Num Paths           10
evaluation/Average Returns     477.07148184409533
time/data storing (s)          0.032124849036335945
time/evaluation sampling (s)   114.42920546326786
time/exploration sampling (s)  115.23425366636366
time/logging (s)               0.03053800482302904
time/saving (s)                0.01025430765002966
time/training (s)              9.108898150734603
time/epoch (s)                 238.84527444187552
time/total (s)                 146989.19140982628
Epoch                          626
-----------------------------  ---------------------
2023-08-02 10:48:02.025481 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 627 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3874.9597]
trainer/QF1 Loss               0.015336107
trainer/QF2 Loss               0.0130207855
trainer/Policy Loss            -90.89301
trainer/Q1 Predictions Mean    102.6919
trainer/Q1 Predictions Std     1.1592541
trainer/Q1 Predictions Max     106.00097
trainer/Q1 Predictions Min     95.049545
trainer/Q2 Predictions Mean    102.67692
trainer/Q2 Predictions Std     1.1432179
trainer/Q2 Predictions Max     106.05133
trainer/Q2 Predictions Min     95.30695
trainer/Q Targets Mean         102.66684
trainer/Q Targets Std          1.1643852
trainer/Q Targets Max          105.97674
trainer/Q Targets Min          94.946
trainer/Log Pis Mean           11.904238
trainer/Log Pis Std            7.736645
trainer/Log Pis Max            39.44519
trainer/Log Pis Min            -2.459365
trainer/Policy mu Mean         -0.1542186
trainer/Policy mu Std          1.5741962
trainer/Policy mu Max          4.5357013
trainer/Policy mu Min          -4.6642914
trainer/Policy log std Mean    -0.7307592
trainer/Policy log std Std     0.2578761
trainer/Policy log std Max     0.09749463
trainer/Policy log std Min     -2.1762502
trainer/Alpha                  0.0017140847630798817
trainer/Alpha Loss             -0.6099109053611755
exploration/num steps total    3141000
exploration/num paths total    6282
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.869106414295519
exploration/Rewards Std        0.11747886418678596
exploration/Rewards Max        0.9795092855865521
exploration/Rewards Min        0.4976152395139861
exploration/Returns Mean       434.5532071477595
exploration/Returns Std        32.359416505904335
exploration/Returns Max        479.65021289024946
exploration/Returns Min        361.89074314101373
exploration/Actions Mean       0.026377592
exploration/Actions Std        0.63950276
exploration/Actions Max        0.99999446
exploration/Actions Min        -0.9999999
exploration/Num Paths          10
exploration/Average Returns    434.5532071477595
evaluation/num steps total     3140000
evaluation/num paths total     6280
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8512218396744778
evaluation/Rewards Std         0.11549579370497698
evaluation/Rewards Max         0.9793986566646933
evaluation/Rewards Min         0.49853146595148
evaluation/Returns Mean        425.61091983723884
evaluation/Returns Std         34.49320294636352
evaluation/Returns Max         482.6071563937223
evaluation/Returns Min         387.4935877971288
evaluation/ExplReturns Mean    425.61091983723884
evaluation/ExplReturns Std     34.49320294636352
evaluation/ExplReturns Max     482.6071563937223
evaluation/ExplReturns Min     387.4935877971288
evaluation/Actions Mean        0.0090032
evaluation/Actions Std         0.5962032
evaluation/Actions Max         0.99995035
evaluation/Actions Min         -0.9999957
evaluation/Num Paths           10
evaluation/Average Returns     425.61091983723884
time/data storing (s)          0.03205827996134758
time/evaluation sampling (s)   115.35506460536271
time/exploration sampling (s)  117.98980164248496
time/logging (s)               0.0304275406524539
time/saving (s)                0.010981389321386814
time/training (s)              9.59297235775739
time/epoch (s)                 243.01130581554025
time/total (s)                 147232.20522767492
Epoch                          627
-----------------------------  ---------------------
2023-08-02 10:51:57.732612 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 628 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3971.5828]
trainer/QF1 Loss               0.030982215
trainer/QF2 Loss               0.011408362
trainer/Policy Loss            -92.02506
trainer/Q1 Predictions Mean    103.11177
trainer/Q1 Predictions Std     1.2024363
trainer/Q1 Predictions Max     106.32808
trainer/Q1 Predictions Min     98.448685
trainer/Q2 Predictions Mean    103.00415
trainer/Q2 Predictions Std     1.1798234
trainer/Q2 Predictions Max     106.10218
trainer/Q2 Predictions Min     98.4055
trainer/Q Targets Mean         102.97804
trainer/Q Targets Std          1.2084427
trainer/Q Targets Max          106.21992
trainer/Q Targets Min          98.319786
trainer/Log Pis Mean           11.096085
trainer/Log Pis Std            6.8307934
trainer/Log Pis Max            35.77684
trainer/Log Pis Min            -6.5465493
trainer/Policy mu Mean         -0.09607756
trainer/Policy mu Std          1.5007601
trainer/Policy mu Max          4.5729556
trainer/Policy mu Min          -4.6671214
trainer/Policy log std Mean    -0.7583694
trainer/Policy log std Std     0.26068518
trainer/Policy log std Max     0.068321824
trainer/Policy log std Min     -1.9676337
trainer/Alpha                  0.0017331787385046482
trainer/Alpha Loss             -5.746804237365723
exploration/num steps total    3146000
exploration/num paths total    6292
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9097340919933131
exploration/Rewards Std        0.11636206947477595
exploration/Rewards Max        0.9792085706828844
exploration/Rewards Min        0.2175332193643547
exploration/Returns Mean       454.86704599665666
exploration/Returns Std        29.020520839431782
exploration/Returns Max        481.75642652909056
exploration/Returns Min        387.2437665896503
exploration/Actions Mean       0.030914616
exploration/Actions Std        0.63009566
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    454.86704599665666
evaluation/num steps total     3145000
evaluation/num paths total     6290
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9311723574970443
evaluation/Rewards Std         0.08644594375711631
evaluation/Rewards Max         0.979185074511971
evaluation/Rewards Min         0.4877010221766933
evaluation/Returns Mean        465.586178748522
evaluation/Returns Std         18.92946222152007
evaluation/Returns Max         478.95806295738015
evaluation/Returns Min         413.71805035671986
evaluation/ExplReturns Mean    465.586178748522
evaluation/ExplReturns Std     18.92946222152007
evaluation/ExplReturns Max     478.95806295738015
evaluation/ExplReturns Min     413.71805035671986
evaluation/Actions Mean        0.06727934
evaluation/Actions Std         0.5661754
evaluation/Actions Max         0.9999997
evaluation/Actions Min         -0.99999976
evaluation/Num Paths           10
evaluation/Average Returns     465.586178748522
time/data storing (s)          0.03222550731152296
time/evaluation sampling (s)   112.98026759177446
time/exploration sampling (s)  113.00878104846925
time/logging (s)               0.0304187024012208
time/saving (s)                0.010313439182937145
time/training (s)              9.637648889794946
time/epoch (s)                 235.69965517893434
time/total (s)                 147467.9073791001
Epoch                          628
-----------------------------  ---------------------
2023-08-02 10:55:56.460845 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 629 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4064.7043]
trainer/QF1 Loss               0.021594975
trainer/QF2 Loss               0.060989756
trainer/Policy Loss            -89.53383
trainer/Q1 Predictions Mean    102.646484
trainer/Q1 Predictions Std     1.9388694
trainer/Q1 Predictions Max     105.99424
trainer/Q1 Predictions Min     89.50907
trainer/Q2 Predictions Mean    102.49591
trainer/Q2 Predictions Std     1.9458686
trainer/Q2 Predictions Max     105.95566
trainer/Q2 Predictions Min     90.01008
trainer/Q Targets Mean         102.70511
trainer/Q Targets Std          1.9332185
trainer/Q Targets Max          106.19471
trainer/Q Targets Min          90.565315
trainer/Log Pis Mean           13.087002
trainer/Log Pis Std            9.103389
trainer/Log Pis Max            66.842384
trainer/Log Pis Min            -7.022662
trainer/Policy mu Mean         0.01588356
trainer/Policy mu Std          1.6321542
trainer/Policy mu Max          6.901186
trainer/Policy mu Min          -7.288871
trainer/Policy log std Mean    -0.7603819
trainer/Policy log std Std     0.2547298
trainer/Policy log std Max     0.7665181
trainer/Policy log std Min     -2.2024114
trainer/Alpha                  0.0017426159465685487
trainer/Alpha Loss             6.90533447265625
exploration/num steps total    3151000
exploration/num paths total    6302
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8261549163828313
exploration/Rewards Std        0.13891919636826464
exploration/Rewards Max        0.9785575294079485
exploration/Rewards Min        0.37817484814306557
exploration/Returns Mean       413.07745819141564
exploration/Returns Std        33.809927465485096
exploration/Returns Max        473.45923995679414
exploration/Returns Min        365.2626821711884
exploration/Actions Mean       0.15488376
exploration/Actions Std        0.63738936
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    413.07745819141564
evaluation/num steps total     3150000
evaluation/num paths total     6300
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8170305710371073
evaluation/Rewards Std         0.12476084762714817
evaluation/Rewards Max         0.9793172689211735
evaluation/Rewards Min         0.4945298840176253
evaluation/Returns Mean        408.51528551855364
evaluation/Returns Std         31.075518740151168
evaluation/Returns Max         474.0661056693629
evaluation/Returns Min         373.0444347860252
evaluation/ExplReturns Mean    408.51528551855364
evaluation/ExplReturns Std     31.075518740151168
evaluation/ExplReturns Max     474.0661056693629
evaluation/ExplReturns Min     373.0444347860252
evaluation/Actions Mean        0.20136635
evaluation/Actions Std         0.58580416
evaluation/Actions Max         0.9999356
evaluation/Actions Min         -0.9998784
evaluation/Num Paths           10
evaluation/Average Returns     408.51528551855364
time/data storing (s)          0.032431090250611305
time/evaluation sampling (s)   114.25346243754029
time/exploration sampling (s)  114.8248294070363
time/logging (s)               0.03041811939328909
time/saving (s)                0.011259417049586773
time/training (s)              9.568199470639229
time/epoch (s)                 238.7205999419093
time/total (s)                 147706.63062055595
Epoch                          629
-----------------------------  ---------------------
2023-08-02 10:59:50.347102 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 630 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4037.9978]
trainer/QF1 Loss               0.021191478
trainer/QF2 Loss               0.015291905
trainer/Policy Loss            -90.22136
trainer/Q1 Predictions Mean    103.08403
trainer/Q1 Predictions Std     1.3696661
trainer/Q1 Predictions Max     106.28166
trainer/Q1 Predictions Min     95.60112
trainer/Q2 Predictions Mean    103.06666
trainer/Q2 Predictions Std     1.3811277
trainer/Q2 Predictions Max     106.27993
trainer/Q2 Predictions Min     95.4277
trainer/Q Targets Mean         103.063934
trainer/Q Targets Std          1.3931971
trainer/Q Targets Max          106.277084
trainer/Q Targets Min          95.57783
trainer/Log Pis Mean           12.966759
trainer/Log Pis Std            6.8223166
trainer/Log Pis Max            40.160873
trainer/Log Pis Min            -2.9070766
trainer/Policy mu Mean         0.021825202
trainer/Policy mu Std          1.6098182
trainer/Policy mu Max          4.4990172
trainer/Policy mu Min          -5.2051415
trainer/Policy log std Mean    -0.75937873
trainer/Policy log std Std     0.24350488
trainer/Policy log std Max     -0.08473253
trainer/Policy log std Min     -1.7820432
trainer/Alpha                  0.0017550034681335092
trainer/Alpha Loss             6.134713172912598
exploration/num steps total    3156000
exploration/num paths total    6312
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8276521593414942
exploration/Rewards Std        0.13036602503406272
exploration/Rewards Max        0.9791077770058166
exploration/Rewards Min        0.48002437222718997
exploration/Returns Mean       413.826079670747
exploration/Returns Std        30.953940538131302
exploration/Returns Max        475.92091424888275
exploration/Returns Min        371.2128188046158
exploration/Actions Mean       0.11227402
exploration/Actions Std        0.6486883
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    413.826079670747
evaluation/num steps total     3155000
evaluation/num paths total     6310
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8207287831496626
evaluation/Rewards Std         0.1309006642733359
evaluation/Rewards Max         0.9787856302070372
evaluation/Rewards Min         0.4018027623436887
evaluation/Returns Mean        410.3643915748315
evaluation/Returns Std         31.15240015478191
evaluation/Returns Max         473.44973472685103
evaluation/Returns Min         364.80282507131756
evaluation/ExplReturns Mean    410.3643915748315
evaluation/ExplReturns Std     31.15240015478191
evaluation/ExplReturns Max     473.44973472685103
evaluation/ExplReturns Min     364.80282507131756
evaluation/Actions Mean        0.08047524
evaluation/Actions Std         0.60584617
evaluation/Actions Max         1.0
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     410.3643915748315
time/data storing (s)          0.032118610106408596
time/evaluation sampling (s)   112.92998715862632
time/exploration sampling (s)  111.20932914596051
time/logging (s)               0.030932003632187843
time/saving (s)                0.012017954140901566
time/training (s)              9.664821771904826
time/epoch (s)                 233.87920664437115
time/total (s)                 147940.51236305293
Epoch                          630
-----------------------------  ---------------------
2023-08-02 11:03:42.323576 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 631 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3836.652]
trainer/QF1 Loss               0.032886956
trainer/QF2 Loss               0.026704382
trainer/Policy Loss            -90.75481
trainer/Q1 Predictions Mean    103.00678
trainer/Q1 Predictions Std     2.6823888
trainer/Q1 Predictions Max     105.955765
trainer/Q1 Predictions Min     72.42342
trainer/Q2 Predictions Mean    103.00229
trainer/Q2 Predictions Std     2.70939
trainer/Q2 Predictions Max     105.89836
trainer/Q2 Predictions Min     72.48595
trainer/Q Targets Mean         102.93157
trainer/Q Targets Std          2.6805801
trainer/Q Targets Max          105.822586
trainer/Q Targets Min          73.392136
trainer/Log Pis Mean           12.361084
trainer/Log Pis Std            8.209587
trainer/Log Pis Max            71.881035
trainer/Log Pis Min            -2.4040651
trainer/Policy mu Mean         0.012548012
trainer/Policy mu Std          1.5883719
trainer/Policy mu Max          8.252467
trainer/Policy mu Min          -6.725464
trainer/Policy log std Mean    -0.7406316
trainer/Policy log std Std     0.23575485
trainer/Policy log std Max     0.69612586
trainer/Policy log std Min     -2.6246517
trainer/Alpha                  0.0018239690689370036
trainer/Alpha Loss             2.2772951126098633
exploration/num steps total    3161000
exploration/num paths total    6322
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8561125007755973
exploration/Rewards Std        0.12758232968929378
exploration/Rewards Max        0.9798192268100792
exploration/Rewards Min        0.5034772427830039
exploration/Returns Mean       428.05625038779874
exploration/Returns Std        32.14182003749044
exploration/Returns Max        475.6372669917225
exploration/Returns Min        382.7433885398215
exploration/Actions Mean       0.034971017
exploration/Actions Std        0.6415873
exploration/Actions Max        0.99999595
exploration/Actions Min        -0.9999924
exploration/Num Paths          10
exploration/Average Returns    428.05625038779874
evaluation/num steps total     3160000
evaluation/num paths total     6320
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.770975099264608
evaluation/Rewards Std         0.11142433841412747
evaluation/Rewards Max         0.978617004388791
evaluation/Rewards Min         0.49681111210751594
evaluation/Returns Mean        385.48754963230414
evaluation/Returns Std         12.227876187700254
evaluation/Returns Max         410.42648500555055
evaluation/Returns Min         373.4981522239046
evaluation/ExplReturns Mean    385.48754963230414
evaluation/ExplReturns Std     12.227876187700254
evaluation/ExplReturns Max     410.42648500555055
evaluation/ExplReturns Min     373.4981522239046
evaluation/Actions Mean        0.04525118
evaluation/Actions Std         0.61561936
evaluation/Actions Max         0.9999916
evaluation/Actions Min         -0.9998936
evaluation/Num Paths           10
evaluation/Average Returns     385.48754963230414
time/data storing (s)          0.03214772045612335
time/evaluation sampling (s)   111.0408184658736
time/exploration sampling (s)  111.59223392419517
time/logging (s)               0.030741482973098755
time/saving (s)                0.010674544610083103
time/training (s)              9.262085432186723
time/epoch (s)                 231.9687015702948
time/total (s)                 148172.4836123446
Epoch                          631
-----------------------------  ---------------------
2023-08-02 11:07:36.233591 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 632 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4203.7456]
trainer/QF1 Loss               0.03600975
trainer/QF2 Loss               0.042786654
trainer/Policy Loss            -89.53714
trainer/Q1 Predictions Mean    102.644196
trainer/Q1 Predictions Std     2.7150323
trainer/Q1 Predictions Max     105.947945
trainer/Q1 Predictions Min     82.110825
trainer/Q2 Predictions Mean    102.60389
trainer/Q2 Predictions Std     2.6932185
trainer/Q2 Predictions Max     105.90623
trainer/Q2 Predictions Min     83.115776
trainer/Q Targets Mean         102.59047
trainer/Q Targets Std          2.7780087
trainer/Q Targets Max          105.8251
trainer/Q Targets Min          80.83738
trainer/Log Pis Mean           13.183958
trainer/Log Pis Std            9.300756
trainer/Log Pis Max            65.20327
trainer/Log Pis Min            -4.3065615
trainer/Policy mu Mean         0.05331415
trainer/Policy mu Std          1.6732711
trainer/Policy mu Max          8.187641
trainer/Policy mu Min          -7.5046797
trainer/Policy log std Mean    -0.735157
trainer/Policy log std Std     0.2501833
trainer/Policy log std Max     0.9035655
trainer/Policy log std Min     -2.1018255
trainer/Alpha                  0.0017533196369186044
trainer/Alpha Loss             7.514077663421631
exploration/num steps total    3166000
exploration/num paths total    6332
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8469053237388143
exploration/Rewards Std        0.12412217816391345
exploration/Rewards Max        0.9797128398202454
exploration/Rewards Min        0.49682889124425506
exploration/Returns Mean       423.45266186940717
exploration/Returns Std        36.457516468772404
exploration/Returns Max        471.01176046382983
exploration/Returns Min        372.976863960916
exploration/Actions Mean       0.009678827
exploration/Actions Std        0.5882146
exploration/Actions Max        0.9999966
exploration/Actions Min        -0.9999944
exploration/Num Paths          10
exploration/Average Returns    423.45266186940717
evaluation/num steps total     3165000
evaluation/num paths total     6330
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8796194747468279
evaluation/Rewards Std         0.11336221048321757
evaluation/Rewards Max         0.9799237176476201
evaluation/Rewards Min         0.5044179390605915
evaluation/Returns Mean        439.8097373734139
evaluation/Returns Std         33.43401224572142
evaluation/Returns Max         473.60793190426335
evaluation/Returns Min         399.5991070216078
evaluation/ExplReturns Mean    439.8097373734139
evaluation/ExplReturns Std     33.43401224572142
evaluation/ExplReturns Max     473.60793190426335
evaluation/ExplReturns Min     399.5991070216078
evaluation/Actions Mean        -0.018905878
evaluation/Actions Std         0.49560478
evaluation/Actions Max         0.99902976
evaluation/Actions Min         -0.9999064
evaluation/Num Paths           10
evaluation/Average Returns     439.8097373734139
time/data storing (s)          0.03240556828677654
time/evaluation sampling (s)   112.4138635089621
time/exploration sampling (s)  111.83191102650017
time/logging (s)               0.030844945460557938
time/saving (s)                0.010404040105640888
time/training (s)              9.583183765411377
time/epoch (s)                 233.9026128547266
time/total (s)                 148406.38867419492
Epoch                          632
-----------------------------  ---------------------
2023-08-02 11:11:31.591719 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 633 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4483.645]
trainer/QF1 Loss               0.029690815
trainer/QF2 Loss               0.020798825
trainer/Policy Loss            -91.062744
trainer/Q1 Predictions Mean    103.032715
trainer/Q1 Predictions Std     1.823075
trainer/Q1 Predictions Max     105.694695
trainer/Q1 Predictions Min     92.08372
trainer/Q2 Predictions Mean    103.02408
trainer/Q2 Predictions Std     1.8343924
trainer/Q2 Predictions Max     105.61013
trainer/Q2 Predictions Min     91.50781
trainer/Q Targets Mean         103.08278
trainer/Q Targets Std          1.8237633
trainer/Q Targets Max          105.78338
trainer/Q Targets Min          91.20602
trainer/Log Pis Mean           12.074878
trainer/Log Pis Std            7.8582025
trainer/Log Pis Max            37.334095
trainer/Log Pis Min            -5.8523183
trainer/Policy mu Mean         -0.017893495
trainer/Policy mu Std          1.6044501
trainer/Policy mu Max          5.066606
trainer/Policy mu Min          -5.4070463
trainer/Policy log std Mean    -0.74934417
trainer/Policy log std Std     0.23700789
trainer/Policy log std Max     0.21959877
trainer/Policy log std Min     -2.048462
trainer/Alpha                  0.0017504059942439198
trainer/Alpha Loss             0.4753311276435852
exploration/num steps total    3171000
exploration/num paths total    6342
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9418614325965246
exploration/Rewards Std        0.061548441681075435
exploration/Rewards Max        0.9788606274963784
exploration/Rewards Min        0.49852214503849396
exploration/Returns Mean       470.93071629826227
exploration/Returns Std        9.027811425296933
exploration/Returns Max        474.2956634664973
exploration/Returns Min        443.86020773181883
exploration/Actions Mean       0.048511356
exploration/Actions Std        0.5671133
exploration/Actions Max        0.9999972
exploration/Actions Min        -0.9999679
exploration/Num Paths          10
exploration/Average Returns    470.93071629826227
evaluation/num steps total     3170000
evaluation/num paths total     6340
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9486988731717667
evaluation/Rewards Std         0.04858534710763277
evaluation/Rewards Max         0.9787019683801544
evaluation/Rewards Min         0.49207856437484987
evaluation/Returns Mean        474.34943658588327
evaluation/Returns Std         1.2936003800545746
evaluation/Returns Max         477.3845629676018
evaluation/Returns Min         472.6751809233185
evaluation/ExplReturns Mean    474.34943658588327
evaluation/ExplReturns Std     1.2936003800545746
evaluation/ExplReturns Max     477.3845629676018
evaluation/ExplReturns Min     472.6751809233185
evaluation/Actions Mean        0.04066911
evaluation/Actions Std         0.45229954
evaluation/Actions Max         0.99974835
evaluation/Actions Min         -0.99980205
evaluation/Num Paths           10
evaluation/Average Returns     474.34943658588327
time/data storing (s)          0.03199039399623871
time/evaluation sampling (s)   112.91503961849958
time/exploration sampling (s)  112.40251449681818
time/logging (s)               0.03039667196571827
time/saving (s)                0.011442654766142368
time/training (s)              9.958817187696695
time/epoch (s)                 235.35020102374256
time/total (s)                 148641.74134314712
Epoch                          633
-----------------------------  ---------------------
2023-08-02 11:15:24.902101 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 634 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3902.775]
trainer/QF1 Loss               0.025084376
trainer/QF2 Loss               0.0211167
trainer/Policy Loss            -91.77712
trainer/Q1 Predictions Mean    103.21773
trainer/Q1 Predictions Std     1.9420832
trainer/Q1 Predictions Max     105.670944
trainer/Q1 Predictions Min     90.85781
trainer/Q2 Predictions Mean    103.16728
trainer/Q2 Predictions Std     1.8802322
trainer/Q2 Predictions Max     105.60888
trainer/Q2 Predictions Min     91.51188
trainer/Q Targets Mean         103.197464
trainer/Q Targets Std          1.907221
trainer/Q Targets Max          105.66521
trainer/Q Targets Min          91.191536
trainer/Log Pis Mean           11.496191
trainer/Log Pis Std            7.0141945
trainer/Log Pis Max            38.420757
trainer/Log Pis Min            -3.8912716
trainer/Policy mu Mean         0.13734508
trainer/Policy mu Std          1.5400485
trainer/Policy mu Max          4.9870386
trainer/Policy mu Min          -4.673582
trainer/Policy log std Mean    -0.73328894
trainer/Policy log std Std     0.22475791
trainer/Policy log std Max     -0.0066952705
trainer/Policy log std Min     -1.9453298
trainer/Alpha                  0.0017929180758073926
trainer/Alpha Loss             -3.186117649078369
exploration/num steps total    3176000
exploration/num paths total    6352
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9521970183233363
exploration/Rewards Std        0.04740640450092347
exploration/Rewards Max        0.9788783365298631
exploration/Rewards Min        0.4951463877237012
exploration/Returns Mean       476.0985091616682
exploration/Returns Std        0.5004671725876414
exploration/Returns Max        476.9278418925643
exploration/Returns Min        475.3044393589755
exploration/Actions Mean       -0.011993581
exploration/Actions Std        0.61265165
exploration/Actions Max        0.9999726
exploration/Actions Min        -0.9998793
exploration/Num Paths          10
exploration/Average Returns    476.0985091616682
evaluation/num steps total     3175000
evaluation/num paths total     6350
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9627122235203402
evaluation/Rewards Std         0.0480013345927684
evaluation/Rewards Max         0.9795104771127333
evaluation/Rewards Min         0.4849519562653677
evaluation/Returns Mean        481.35611176017
evaluation/Returns Std         1.507191137128943
evaluation/Returns Max         483.249568343247
evaluation/Returns Min         478.5222870344338
evaluation/ExplReturns Mean    481.35611176017
evaluation/ExplReturns Std     1.507191137128943
evaluation/ExplReturns Max     483.249568343247
evaluation/ExplReturns Min     478.5222870344338
evaluation/Actions Mean        -0.07952955
evaluation/Actions Std         0.57985383
evaluation/Actions Max         0.99870634
evaluation/Actions Min         -0.99945974
evaluation/Num Paths           10
evaluation/Average Returns     481.35611176017
time/data storing (s)          0.03197432868182659
time/evaluation sampling (s)   110.2802831120789
time/exploration sampling (s)  112.93111144285649
time/logging (s)               0.03135732002556324
time/saving (s)                0.01280739065259695
time/training (s)              10.016262670047581
time/epoch (s)                 233.30379626434296
time/total (s)                 148875.0476880744
Epoch                          634
-----------------------------  ---------------------
2023-08-02 11:19:22.262421 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 635 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4180.1245]
trainer/QF1 Loss               0.01940332
trainer/QF2 Loss               0.018765632
trainer/Policy Loss            -91.3836
trainer/Q1 Predictions Mean    103.15742
trainer/Q1 Predictions Std     2.182909
trainer/Q1 Predictions Max     105.56773
trainer/Q1 Predictions Min     81.241066
trainer/Q2 Predictions Mean    103.16353
trainer/Q2 Predictions Std     2.2278879
trainer/Q2 Predictions Max     105.63445
trainer/Q2 Predictions Min     80.49343
trainer/Q Targets Mean         103.17339
trainer/Q Targets Std          2.2185495
trainer/Q Targets Max          105.69102
trainer/Q Targets Min          80.65558
trainer/Log Pis Mean           11.897208
trainer/Log Pis Std            7.4230366
trainer/Log Pis Max            60.4345
trainer/Log Pis Min            -3.2054677
trainer/Policy mu Mean         0.046404094
trainer/Policy mu Std          1.5872203
trainer/Policy mu Max          7.611811
trainer/Policy mu Min          -8.677065
trainer/Policy log std Mean    -0.70594597
trainer/Policy log std Std     0.2400752
trainer/Policy log std Max     0.89599645
trainer/Policy log std Min     -1.9176396
trainer/Alpha                  0.0018127156654372811
trainer/Alpha Loss             -0.648894190788269
exploration/num steps total    3181000
exploration/num paths total    6362
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9505153605249982
exploration/Rewards Std        0.05493083767521457
exploration/Rewards Max        0.9794293394104576
exploration/Rewards Min        0.49368598437198064
exploration/Returns Mean       475.25768026249887
exploration/Returns Std        1.5421783279207877
exploration/Returns Max        476.9440215463877
exploration/Returns Min        471.46425561973854
exploration/Actions Mean       0.010428683
exploration/Actions Std        0.57543933
exploration/Actions Max        0.99992794
exploration/Actions Min        -0.9999592
exploration/Num Paths          10
exploration/Average Returns    475.25768026249887
evaluation/num steps total     3180000
evaluation/num paths total     6360
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.939706607999716
evaluation/Rewards Std         0.08485941978677079
evaluation/Rewards Max         0.9778340301465273
evaluation/Rewards Min         0.47427282380592617
evaluation/Returns Mean        469.85330399985787
evaluation/Returns Std         21.73381745634888
evaluation/Returns Max         479.72669572171725
evaluation/Returns Min         404.8165140800014
evaluation/ExplReturns Mean    469.85330399985787
evaluation/ExplReturns Std     21.73381745634888
evaluation/ExplReturns Max     479.72669572171725
evaluation/ExplReturns Min     404.8165140800014
evaluation/Actions Mean        -0.017420042
evaluation/Actions Std         0.47432226
evaluation/Actions Max         0.9999999
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     469.85330399985787
time/data storing (s)          0.03212923277169466
time/evaluation sampling (s)   113.54049568902701
time/exploration sampling (s)  113.59489091578871
time/logging (s)               0.030274825170636177
time/saving (s)                0.012753432616591454
time/training (s)              10.141082683578134
time/epoch (s)                 237.35162677895278
time/total (s)                 149112.4018994458
Epoch                          635
-----------------------------  ---------------------
2023-08-02 11:23:15.110226 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 636 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4175.489]
trainer/QF1 Loss               0.045308627
trainer/QF2 Loss               0.04108625
trainer/Policy Loss            -91.54663
trainer/Q1 Predictions Mean    103.27907
trainer/Q1 Predictions Std     2.0898848
trainer/Q1 Predictions Max     105.62466
trainer/Q1 Predictions Min     87.94648
trainer/Q2 Predictions Mean    103.11632
trainer/Q2 Predictions Std     2.111162
trainer/Q2 Predictions Max     105.36097
trainer/Q2 Predictions Min     86.43395
trainer/Q Targets Mean         103.236465
trainer/Q Targets Std          2.1352232
trainer/Q Targets Max          105.43263
trainer/Q Targets Min          85.49539
trainer/Log Pis Mean           11.712719
trainer/Log Pis Std            8.722394
trainer/Log Pis Max            64.4173
trainer/Log Pis Min            -5.5557055
trainer/Policy mu Mean         0.103413545
trainer/Policy mu Std          1.5925157
trainer/Policy mu Max          9.022607
trainer/Policy mu Min          -8.7586565
trainer/Policy log std Mean    -0.7239097
trainer/Policy log std Std     0.24425055
trainer/Policy log std Max     0.65892094
trainer/Policy log std Min     -2.1719303
trainer/Alpha                  0.001869864179752767
trainer/Alpha Loss             -1.8046125173568726
exploration/num steps total    3186000
exploration/num paths total    6372
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9565716519192516
exploration/Rewards Std        0.07287288083692849
exploration/Rewards Max        0.9799454409612118
exploration/Rewards Min        0.493417875521978
exploration/Returns Mean       478.2858259596257
exploration/Returns Std        9.671498581142615
exploration/Returns Max        483.39759723593835
exploration/Returns Min        453.0388585815249
exploration/Actions Mean       -0.004111681
exploration/Actions Std        0.59328616
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    478.2858259596257
evaluation/num steps total     3185000
evaluation/num paths total     6370
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9664580487814677
evaluation/Rewards Std         0.05215166640407019
evaluation/Rewards Max         0.979615056186688
evaluation/Rewards Min         0.49338078496926185
evaluation/Returns Mean        483.2290243907338
evaluation/Returns Std         0.2369105388926851
evaluation/Returns Max         483.51623156774184
evaluation/Returns Min         482.84974667552785
evaluation/ExplReturns Mean    483.2290243907338
evaluation/ExplReturns Std     0.2369105388926851
evaluation/ExplReturns Max     483.51623156774184
evaluation/ExplReturns Min     482.84974667552785
evaluation/Actions Mean        -0.029048657
evaluation/Actions Std         0.4568101
evaluation/Actions Max         0.99980015
evaluation/Actions Min         -0.99905545
evaluation/Num Paths           10
evaluation/Average Returns     483.2290243907338
time/data storing (s)          0.03198047447949648
time/evaluation sampling (s)   111.44178682565689
time/exploration sampling (s)  111.71087422221899
time/logging (s)               0.030462974682450294
time/saving (s)                0.010304735973477364
time/training (s)              9.615077583119273
time/epoch (s)                 232.84048681613058
time/total (s)                 149345.24489256833
Epoch                          636
-----------------------------  --------------------
2023-08-02 11:27:07.742033 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 637 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4322.608]
trainer/QF1 Loss               0.021916885
trainer/QF2 Loss               0.028479548
trainer/Policy Loss            -91.60272
trainer/Q1 Predictions Mean    103.280685
trainer/Q1 Predictions Std     2.455936
trainer/Q1 Predictions Max     105.53242
trainer/Q1 Predictions Min     78.800865
trainer/Q2 Predictions Mean    103.178406
trainer/Q2 Predictions Std     2.4569433
trainer/Q2 Predictions Max     105.28941
trainer/Q2 Predictions Min     79.03043
trainer/Q Targets Mean         103.281166
trainer/Q Targets Std          2.4684496
trainer/Q Targets Max          105.63169
trainer/Q Targets Min          78.94835
trainer/Log Pis Mean           11.723112
trainer/Log Pis Std            7.4592934
trainer/Log Pis Max            66.72006
trainer/Log Pis Min            -5.6497164
trainer/Policy mu Mean         0.07391929
trainer/Policy mu Std          1.5670491
trainer/Policy mu Max          8.522187
trainer/Policy mu Min          -9.274626
trainer/Policy log std Mean    -0.72867346
trainer/Policy log std Std     0.25254527
trainer/Policy log std Max     0.24880803
trainer/Policy log std Min     -2.2355509
trainer/Alpha                  0.0017373398877680302
trainer/Alpha Loss             -1.7596980333328247
exploration/num steps total    3191000
exploration/num paths total    6382
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9457716291552081
exploration/Rewards Std        0.04703574945341204
exploration/Rewards Max        0.979564555888452
exploration/Rewards Min        0.4877732494259448
exploration/Returns Mean       472.88581457760404
exploration/Returns Std        0.42509228038584235
exploration/Returns Max        473.71017844770284
exploration/Returns Min        472.45238228120263
exploration/Actions Mean       0.0020625088
exploration/Actions Std        0.5656846
exploration/Actions Max        0.9999003
exploration/Actions Min        -0.99992526
exploration/Num Paths          10
exploration/Average Returns    472.88581457760404
evaluation/num steps total     3190000
evaluation/num paths total     6380
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.962425177275535
evaluation/Rewards Std         0.049627982600580454
evaluation/Rewards Max         0.9794771841661885
evaluation/Rewards Min         0.4884521810878857
evaluation/Returns Mean        481.2125886377674
evaluation/Returns Std         2.7538369810183863
evaluation/Returns Max         484.07955989988193
evaluation/Returns Min         475.9788845463068
evaluation/ExplReturns Mean    481.2125886377674
evaluation/ExplReturns Std     2.7538369810183863
evaluation/ExplReturns Max     484.07955989988193
evaluation/ExplReturns Min     475.9788845463068
evaluation/Actions Mean        -0.097973704
evaluation/Actions Std         0.5392339
evaluation/Actions Max         0.9983017
evaluation/Actions Min         -0.99962354
evaluation/Num Paths           10
evaluation/Average Returns     481.2125886377674
time/data storing (s)          0.032178737223148346
time/evaluation sampling (s)   110.73045496735722
time/exploration sampling (s)  112.15520051494241
time/logging (s)               0.030328646302223206
time/saving (s)                0.010829000733792782
time/training (s)              9.665001759305596
time/epoch (s)                 232.6239936258644
time/total (s)                 149577.87153186183
Epoch                          637
-----------------------------  ---------------------
2023-08-02 11:31:01.591551 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 638 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4130.9297]
trainer/QF1 Loss               0.027298689
trainer/QF2 Loss               0.026784569
trainer/Policy Loss            -91.76911
trainer/Q1 Predictions Mean    103.49407
trainer/Q1 Predictions Std     1.7369809
trainer/Q1 Predictions Max     105.28244
trainer/Q1 Predictions Min     89.08649
trainer/Q2 Predictions Mean    103.56738
trainer/Q2 Predictions Std     1.7343068
trainer/Q2 Predictions Max     105.389404
trainer/Q2 Predictions Min     89.07783
trainer/Q Targets Mean         103.48724
trainer/Q Targets Std          1.764584
trainer/Q Targets Max          105.35249
trainer/Q Targets Min          88.5883
trainer/Log Pis Mean           11.864292
trainer/Log Pis Std            7.3205533
trainer/Log Pis Max            45.642883
trainer/Log Pis Min            -5.5988617
trainer/Policy mu Mean         -0.022211855
trainer/Policy mu Std          1.5953747
trainer/Policy mu Max          6.119252
trainer/Policy mu Min          -6.9902296
trainer/Policy log std Mean    -0.7265132
trainer/Policy log std Std     0.2497147
trainer/Policy log std Max     0.38117105
trainer/Policy log std Min     -2.3296757
trainer/Alpha                  0.0017507524462416768
trainer/Alpha Loss             -0.8614377975463867
exploration/num steps total    3196000
exploration/num paths total    6392
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.961090910946823
exploration/Rewards Std        0.04978282016211374
exploration/Rewards Max        0.9797950470658464
exploration/Rewards Min        0.49141824425014147
exploration/Returns Mean       480.5454554734116
exploration/Returns Std        0.48224945132423347
exploration/Returns Max        481.1893597439819
exploration/Returns Min        479.71889520488565
exploration/Actions Mean       -0.0045678965
exploration/Actions Std        0.5845807
exploration/Actions Max        0.9998568
exploration/Actions Min        -0.9999578
exploration/Num Paths          10
exploration/Average Returns    480.5454554734116
evaluation/num steps total     3195000
evaluation/num paths total     6390
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.960970861021723
evaluation/Rewards Std         0.048872409702711284
evaluation/Rewards Max         0.9793742819604644
evaluation/Rewards Min         0.5001903607593189
evaluation/Returns Mean        480.48543051086165
evaluation/Returns Std         0.4766192573329994
evaluation/Returns Max         481.43856929773904
evaluation/Returns Min         479.79831524729485
evaluation/ExplReturns Mean    480.48543051086165
evaluation/ExplReturns Std     0.4766192573329994
evaluation/ExplReturns Max     481.43856929773904
evaluation/ExplReturns Min     479.79831524729485
evaluation/Actions Mean        -0.047253575
evaluation/Actions Std         0.42565733
evaluation/Actions Max         0.99955654
evaluation/Actions Min         -0.99894243
evaluation/Num Paths           10
evaluation/Average Returns     480.48543051086165
time/data storing (s)          0.03180544916540384
time/evaluation sampling (s)   112.31974588613957
time/exploration sampling (s)  111.8283335659653
time/logging (s)               0.03061226475983858
time/saving (s)                0.012540771625936031
time/training (s)              9.619265461340547
time/epoch (s)                 233.8423033989966
time/total (s)                 149811.71632639598
Epoch                          638
-----------------------------  ---------------------
2023-08-02 11:34:53.667383 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 639 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4213.76]
trainer/QF1 Loss               0.050656576
trainer/QF2 Loss               0.045544967
trainer/Policy Loss            -92.327255
trainer/Q1 Predictions Mean    103.49509
trainer/Q1 Predictions Std     2.005999
trainer/Q1 Predictions Max     105.21612
trainer/Q1 Predictions Min     85.40591
trainer/Q2 Predictions Mean    103.48854
trainer/Q2 Predictions Std     2.0178492
trainer/Q2 Predictions Max     105.232315
trainer/Q2 Predictions Min     85.05084
trainer/Q Targets Mean         103.345955
trainer/Q Targets Std          2.0847173
trainer/Q Targets Max          105.08355
trainer/Q Targets Min          84.24228
trainer/Log Pis Mean           11.274107
trainer/Log Pis Std            7.775265
trainer/Log Pis Max            44.540546
trainer/Log Pis Min            -5.4487176
trainer/Policy mu Mean         0.0534274
trainer/Policy mu Std          1.5330038
trainer/Policy mu Max          6.8290453
trainer/Policy mu Min          -4.5108795
trainer/Policy log std Mean    -0.7530718
trainer/Policy log std Std     0.27605945
trainer/Policy log std Max     0.109544754
trainer/Policy log std Min     -2.198354
trainer/Alpha                  0.001637360081076622
trainer/Alpha Loss             -4.656239032745361
exploration/num steps total    3201000
exploration/num paths total    6402
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9649153891055912
exploration/Rewards Std        0.052100363732561245
exploration/Rewards Max        0.979930422417203
exploration/Rewards Min        0.49294974255768276
exploration/Returns Mean       482.4576945527956
exploration/Returns Std        0.4614818980919231
exploration/Returns Max        483.1434323692761
exploration/Returns Min        481.6352217229662
exploration/Actions Mean       -0.011332127
exploration/Actions Std        0.5725149
exploration/Actions Max        0.9999245
exploration/Actions Min        -0.9999722
exploration/Num Paths          10
exploration/Average Returns    482.4576945527956
evaluation/num steps total     3200000
evaluation/num paths total     6400
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9670141619016155
evaluation/Rewards Std         0.051617157224526776
evaluation/Rewards Max         0.9788968601174212
evaluation/Rewards Min         0.495774625209523
evaluation/Returns Mean        483.50708095080745
evaluation/Returns Std         0.28127917780760053
evaluation/Returns Max         483.87744675201924
evaluation/Returns Min         482.83205466841173
evaluation/ExplReturns Mean    483.50708095080745
evaluation/ExplReturns Std     0.28127917780760053
evaluation/ExplReturns Max     483.87744675201924
evaluation/ExplReturns Min     482.83205466841173
evaluation/Actions Mean        -0.024941955
evaluation/Actions Std         0.41777766
evaluation/Actions Max         0.99935746
evaluation/Actions Min         -0.9996938
evaluation/Num Paths           10
evaluation/Average Returns     483.50708095080745
time/data storing (s)          0.03238485660403967
time/evaluation sampling (s)   111.17843042965978
time/exploration sampling (s)  111.22974289860576
time/logging (s)               0.030406459234654903
time/saving (s)                0.012628366239368916
time/training (s)              9.584503403864801
time/epoch (s)                 232.0680964142084
time/total (s)                 150043.78690173663
Epoch                          639
-----------------------------  --------------------
2023-08-02 11:38:41.540268 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 640 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4473.855]
trainer/QF1 Loss               0.032286033
trainer/QF2 Loss               0.03273365
trainer/Policy Loss            -92.71301
trainer/Q1 Predictions Mean    103.79059
trainer/Q1 Predictions Std     1.2287284
trainer/Q1 Predictions Max     105.18122
trainer/Q1 Predictions Min     92.62464
trainer/Q2 Predictions Mean    103.80889
trainer/Q2 Predictions Std     1.247368
trainer/Q2 Predictions Max     105.188065
trainer/Q2 Predictions Min     92.31965
trainer/Q Targets Mean         103.683334
trainer/Q Targets Std          1.238798
trainer/Q Targets Max          105.00782
trainer/Q Targets Min          92.41295
trainer/Log Pis Mean           11.195186
trainer/Log Pis Std            7.356185
trainer/Log Pis Max            43.48147
trainer/Log Pis Min            -3.7496161
trainer/Policy mu Mean         0.0011002406
trainer/Policy mu Std          1.5253181
trainer/Policy mu Max          4.7902503
trainer/Policy mu Min          -4.120794
trainer/Policy log std Mean    -0.74203855
trainer/Policy log std Std     0.280772
trainer/Policy log std Max     0.16993797
trainer/Policy log std Min     -2.4194574
trainer/Alpha                  0.001635726890526712
trainer/Alpha Loss             -5.163374423980713
exploration/num steps total    3206000
exploration/num paths total    6412
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9486095239644088
exploration/Rewards Std        0.047069630187698774
exploration/Rewards Max        0.9767403590306447
exploration/Rewards Min        0.4974366970909497
exploration/Returns Mean       474.3047619822047
exploration/Returns Std        0.3414366903041235
exploration/Returns Max        474.9388821027399
exploration/Returns Min        473.85535059282324
exploration/Actions Mean       -0.0057431683
exploration/Actions Std        0.60073775
exploration/Actions Max        0.99982893
exploration/Actions Min        -0.99983954
exploration/Num Paths          10
exploration/Average Returns    474.3047619822047
evaluation/num steps total     3205000
evaluation/num paths total     6410
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9473887341399965
evaluation/Rewards Std         0.04773946614186016
evaluation/Rewards Max         0.9679311077777775
evaluation/Rewards Min         0.49394569840423297
evaluation/Returns Mean        473.69436706999824
evaluation/Returns Std         0.4510200133023171
evaluation/Returns Max         474.3793084068907
evaluation/Returns Min         472.7705838994887
evaluation/ExplReturns Mean    473.69436706999824
evaluation/ExplReturns Std     0.4510200133023171
evaluation/ExplReturns Max     474.3793084068907
evaluation/ExplReturns Min     472.7705838994887
evaluation/Actions Mean        -0.010313135
evaluation/Actions Std         0.51373154
evaluation/Actions Max         0.9989812
evaluation/Actions Min         -0.99947375
evaluation/Num Paths           10
evaluation/Average Returns     473.69436706999824
time/data storing (s)          0.03222812060266733
time/evaluation sampling (s)   108.93714158702642
time/exploration sampling (s)  110.46405008994043
time/logging (s)               0.030352097935974598
time/saving (s)                0.010196286253631115
time/training (s)              8.391281794756651
time/epoch (s)                 227.86524997651577
time/total (s)                 150271.65463848785
Epoch                          640
-----------------------------  --------------------
2023-08-02 11:42:30.563029 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 641 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4070.0645]
trainer/QF1 Loss               0.01831513
trainer/QF2 Loss               0.015224816
trainer/Policy Loss            -91.27192
trainer/Q1 Predictions Mean    103.53811
trainer/Q1 Predictions Std     1.8546435
trainer/Q1 Predictions Max     104.860535
trainer/Q1 Predictions Min     83.76056
trainer/Q2 Predictions Mean    103.61755
trainer/Q2 Predictions Std     1.8518087
trainer/Q2 Predictions Max     104.93437
trainer/Q2 Predictions Min     84.06046
trainer/Q Targets Mean         103.603905
trainer/Q Targets Std          1.8570777
trainer/Q Targets Max          104.89202
trainer/Q Targets Min          84.3606
trainer/Log Pis Mean           12.390396
trainer/Log Pis Std            9.212901
trainer/Log Pis Max            70.72387
trainer/Log Pis Min            -3.9535017
trainer/Policy mu Mean         -0.07284454
trainer/Policy mu Std          1.6257412
trainer/Policy mu Max          5.99109
trainer/Policy mu Min          -6.948283
trainer/Policy log std Mean    -0.7176334
trainer/Policy log std Std     0.2695212
trainer/Policy log std Max     0.580177
trainer/Policy log std Min     -2.4663744
trainer/Alpha                  0.0015502783935517073
trainer/Alpha Loss             2.5256295204162598
exploration/num steps total    3211000
exploration/num paths total    6422
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9589076521139733
exploration/Rewards Std        0.04857851498245798
exploration/Rewards Max        0.9796754985864378
exploration/Rewards Min        0.49628350065966215
exploration/Returns Mean       479.4538260569866
exploration/Returns Std        0.5825737736948823
exploration/Returns Max        480.2751403815874
exploration/Returns Min        478.308348099628
exploration/Actions Mean       -0.009250842
exploration/Actions Std        0.6044488
exploration/Actions Max        0.9996457
exploration/Actions Min        -0.99983835
exploration/Num Paths          10
exploration/Average Returns    479.4538260569866
evaluation/num steps total     3210000
evaluation/num paths total     6420
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9598594546140652
evaluation/Rewards Std         0.04826296179630549
evaluation/Rewards Max         0.9798177964125577
evaluation/Rewards Min         0.4953314345406007
evaluation/Returns Mean        479.9297273070327
evaluation/Returns Std         0.28438349951505637
evaluation/Returns Max         480.35082648656606
evaluation/Returns Min         479.5752863713747
evaluation/ExplReturns Mean    479.9297273070327
evaluation/ExplReturns Std     0.28438349951505637
evaluation/ExplReturns Max     480.35082648656606
evaluation/ExplReturns Min     479.5752863713747
evaluation/Actions Mean        -0.016360588
evaluation/Actions Std         0.4959476
evaluation/Actions Max         0.9982275
evaluation/Actions Min         -0.9996616
evaluation/Num Paths           10
evaluation/Average Returns     479.9297273070327
time/data storing (s)          0.031766174361109734
time/evaluation sampling (s)   108.36243573203683
time/exploration sampling (s)  110.98036674689502
time/logging (s)               0.030553730204701424
time/saving (s)                0.012694289907813072
time/training (s)              9.59755162987858
time/epoch (s)                 229.01536830328405
time/total (s)                 150500.67255154718
Epoch                          641
-----------------------------  ---------------------
2023-08-02 11:46:25.713531 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 642 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3872.0305]
trainer/QF1 Loss               0.029150458
trainer/QF2 Loss               0.03038018
trainer/Policy Loss            -90.79393
trainer/Q1 Predictions Mean    103.337616
trainer/Q1 Predictions Std     2.0683458
trainer/Q1 Predictions Max     104.87128
trainer/Q1 Predictions Min     87.320816
trainer/Q2 Predictions Mean    103.34494
trainer/Q2 Predictions Std     2.0781662
trainer/Q2 Predictions Max     105.03371
trainer/Q2 Predictions Min     87.59219
trainer/Q Targets Mean         103.27316
trainer/Q Targets Std          2.0767577
trainer/Q Targets Max          104.79043
trainer/Q Targets Min          87.938705
trainer/Log Pis Mean           12.647949
trainer/Log Pis Std            8.546364
trainer/Log Pis Max            56.13761
trainer/Log Pis Min            -2.7006955
trainer/Policy mu Mean         0.04942396
trainer/Policy mu Std          1.6247416
trainer/Policy mu Max          5.174644
trainer/Policy mu Min          -8.105406
trainer/Policy log std Mean    -0.75295454
trainer/Policy log std Std     0.28743252
trainer/Policy log std Max     0.1014334
trainer/Policy log std Min     -2.423052
trainer/Alpha                  0.0015096530551090837
trainer/Alpha Loss             4.208969593048096
exploration/num steps total    3216000
exploration/num paths total    6432
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9600375244494819
exploration/Rewards Std        0.05028520701987135
exploration/Rewards Max        0.9795769936329111
exploration/Rewards Min        0.49202643581699396
exploration/Returns Mean       480.01876222474095
exploration/Returns Std        0.5086345555033392
exploration/Returns Max        480.8224281273104
exploration/Returns Min        479.27820604072963
exploration/Actions Mean       0.02162802
exploration/Actions Std        0.5947172
exploration/Actions Max        0.99982756
exploration/Actions Min        -0.99974304
exploration/Num Paths          10
exploration/Average Returns    480.01876222474095
evaluation/num steps total     3215000
evaluation/num paths total     6430
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9556110948317365
evaluation/Rewards Std         0.04817049879476924
evaluation/Rewards Max         0.9739659173621018
evaluation/Rewards Min         0.4910514362820492
evaluation/Returns Mean        477.8055474158683
evaluation/Returns Std         0.7199789246611955
evaluation/Returns Max         478.7655676378809
evaluation/Returns Min         476.31668297384067
evaluation/ExplReturns Mean    477.8055474158683
evaluation/ExplReturns Std     0.7199789246611955
evaluation/ExplReturns Max     478.7655676378809
evaluation/ExplReturns Min     476.31668297384067
evaluation/Actions Mean        0.001011611
evaluation/Actions Std         0.5180079
evaluation/Actions Max         0.9987592
evaluation/Actions Min         -0.99896455
evaluation/Num Paths           10
evaluation/Average Returns     477.8055474158683
time/data storing (s)          0.03230709210038185
time/evaluation sampling (s)   112.72983241733164
time/exploration sampling (s)  112.73970118816942
time/logging (s)               0.030597256496548653
time/saving (s)                0.012040515430271626
time/training (s)              9.598356938920915
time/epoch (s)                 235.14283540844917
time/total (s)                 150735.8179923799
Epoch                          642
-----------------------------  ---------------------
2023-08-02 11:50:20.955265 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 643 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4024.362]
trainer/QF1 Loss               0.018214075
trainer/QF2 Loss               0.016248513
trainer/Policy Loss            -91.643036
trainer/Q1 Predictions Mean    103.56119
trainer/Q1 Predictions Std     1.5617329
trainer/Q1 Predictions Max     104.87852
trainer/Q1 Predictions Min     92.56121
trainer/Q2 Predictions Mean    103.499695
trainer/Q2 Predictions Std     1.5555719
trainer/Q2 Predictions Max     104.75923
trainer/Q2 Predictions Min     92.53009
trainer/Q Targets Mean         103.54307
trainer/Q Targets Std          1.5676423
trainer/Q Targets Max          104.767944
trainer/Q Targets Min          92.624405
trainer/Log Pis Mean           11.966623
trainer/Log Pis Std            7.3678255
trainer/Log Pis Max            43.537876
trainer/Log Pis Min            -4.2094617
trainer/Policy mu Mean         -0.022499241
trainer/Policy mu Std          1.5908123
trainer/Policy mu Max          5.0249033
trainer/Policy mu Min          -6.0450854
trainer/Policy log std Mean    -0.7217157
trainer/Policy log std Std     0.26030344
trainer/Policy log std Max     0.45196348
trainer/Policy log std Min     -2.368402
trainer/Alpha                  0.00146775646135211
trainer/Alpha Loss             -0.21776506304740906
exploration/num steps total    3221000
exploration/num paths total    6442
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9568355073437884
exploration/Rewards Std        0.050236562003347404
exploration/Rewards Max        0.979312673180213
exploration/Rewards Min        0.4924269959056471
exploration/Returns Mean       478.4177536718942
exploration/Returns Std        0.5668201481188593
exploration/Returns Max        479.3626414979225
exploration/Returns Min        477.5351268367463
exploration/Actions Mean       0.040013853
exploration/Actions Std        0.5831837
exploration/Actions Max        0.9998619
exploration/Actions Min        -0.999856
exploration/Num Paths          10
exploration/Average Returns    478.4177536718942
evaluation/num steps total     3220000
evaluation/num paths total     6440
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9555641701600205
evaluation/Rewards Std         0.04995465690629801
evaluation/Rewards Max         0.9726315949034205
evaluation/Rewards Min         0.49336838541190753
evaluation/Returns Mean        477.7820850800102
evaluation/Returns Std         0.3016176270631816
evaluation/Returns Max         478.21363215589355
evaluation/Returns Min         477.22787402422733
evaluation/ExplReturns Mean    477.7820850800102
evaluation/ExplReturns Std     0.3016176270631816
evaluation/ExplReturns Max     478.21363215589355
evaluation/ExplReturns Min     477.22787402422733
evaluation/Actions Mean        0.047989715
evaluation/Actions Std         0.49451146
evaluation/Actions Max         0.9986789
evaluation/Actions Min         -0.9994659
evaluation/Num Paths           10
evaluation/Average Returns     477.7820850800102
time/data storing (s)          0.03196335956454277
time/evaluation sampling (s)   112.40199664607644
time/exploration sampling (s)  113.17850304115564
time/logging (s)               0.03098977915942669
time/saving (s)                0.010693402029573917
time/training (s)              9.580361044034362
time/epoch (s)                 235.23450727201998
time/total (s)                 150971.05503057875
Epoch                          643
-----------------------------  --------------------
2023-08-02 11:54:16.413469 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 644 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3769.3533]
trainer/QF1 Loss               0.053463235
trainer/QF2 Loss               0.037977666
trainer/Policy Loss            -91.734665
trainer/Q1 Predictions Mean    103.580734
trainer/Q1 Predictions Std     1.8742405
trainer/Q1 Predictions Max     104.933105
trainer/Q1 Predictions Min     79.17448
trainer/Q2 Predictions Mean    103.473015
trainer/Q2 Predictions Std     1.8719983
trainer/Q2 Predictions Max     104.77263
trainer/Q2 Predictions Min     78.93511
trainer/Q Targets Mean         103.4469
trainer/Q Targets Std          1.8740174
trainer/Q Targets Max          104.761246
trainer/Q Targets Min          79.16017
trainer/Log Pis Mean           11.853999
trainer/Log Pis Std            8.918996
trainer/Log Pis Max            69.74338
trainer/Log Pis Min            -5.779772
trainer/Policy mu Mean         0.018188128
trainer/Policy mu Std          1.6364998
trainer/Policy mu Max          7.969671
trainer/Policy mu Min          -7.447504
trainer/Policy log std Mean    -0.70157
trainer/Policy log std Std     0.26330638
trainer/Policy log std Max     0.48337948
trainer/Policy log std Min     -1.8923279
trainer/Alpha                  0.0014633804094046354
trainer/Alpha Loss             -0.9529116153717041
exploration/num steps total    3226000
exploration/num paths total    6452
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9614114909255126
exploration/Rewards Std        0.048739258469351975
exploration/Rewards Max        0.9787117742960088
exploration/Rewards Min        0.49437171781684
exploration/Returns Mean       480.7057454627562
exploration/Returns Std        0.5001990029982488
exploration/Returns Max        481.5304777065009
exploration/Returns Min        479.95642403048714
exploration/Actions Mean       0.036962677
exploration/Actions Std        0.6312441
exploration/Actions Max        0.9999864
exploration/Actions Min        -0.999932
exploration/Num Paths          10
exploration/Average Returns    480.7057454627562
evaluation/num steps total     3225000
evaluation/num paths total     6450
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9560431125555169
evaluation/Rewards Std         0.04679190879344504
evaluation/Rewards Max         0.969237906678885
evaluation/Rewards Min         0.5014915481545603
evaluation/Returns Mean        478.0215562777583
evaluation/Returns Std         0.5071139551500913
evaluation/Returns Max         478.9371077744455
evaluation/Returns Min         477.25288356700213
evaluation/ExplReturns Mean    478.0215562777583
evaluation/ExplReturns Std     0.5071139551500913
evaluation/ExplReturns Max     478.9371077744455
evaluation/ExplReturns Min     477.25288356700213
evaluation/Actions Mean        0.01787542
evaluation/Actions Std         0.55218035
evaluation/Actions Max         0.9978787
evaluation/Actions Min         -0.9992593
evaluation/Num Paths           10
evaluation/Average Returns     478.0215562777583
time/data storing (s)          0.0321691045537591
time/evaluation sampling (s)   113.34009176306427
time/exploration sampling (s)  112.43249640706927
time/logging (s)               0.03106924146413803
time/saving (s)                0.012272646650671959
time/training (s)              9.602506472729146
time/epoch (s)                 235.45060563553125
time/total (s)                 151206.5081596179
Epoch                          644
-----------------------------  ---------------------
2023-08-02 11:58:10.300302 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 645 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3867.943]
trainer/QF1 Loss               0.021639265
trainer/QF2 Loss               0.018440215
trainer/Policy Loss            -91.1569
trainer/Q1 Predictions Mean    103.52379
trainer/Q1 Predictions Std     1.791451
trainer/Q1 Predictions Max     104.743004
trainer/Q1 Predictions Min     80.513885
trainer/Q2 Predictions Mean    103.52544
trainer/Q2 Predictions Std     1.7865647
trainer/Q2 Predictions Max     104.93216
trainer/Q2 Predictions Min     80.75456
trainer/Q Targets Mean         103.49057
trainer/Q Targets Std          1.7462486
trainer/Q Targets Max          104.74057
trainer/Q Targets Min          81.37456
trainer/Log Pis Mean           12.456249
trainer/Log Pis Std            8.609399
trainer/Log Pis Max            71.19885
trainer/Log Pis Min            -6.162849
trainer/Policy mu Mean         -0.004857448
trainer/Policy mu Std          1.6243811
trainer/Policy mu Max          7.258167
trainer/Policy mu Min          -10.102461
trainer/Policy log std Mean    -0.7402709
trainer/Policy log std Std     0.29380107
trainer/Policy log std Max     -0.0032328963
trainer/Policy log std Min     -2.4070206
trainer/Alpha                  0.0013619919773191214
trainer/Alpha Loss             3.010723114013672
exploration/num steps total    3231000
exploration/num paths total    6462
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8196976985547176
exploration/Rewards Std        0.10276923274401355
exploration/Rewards Max        0.9791140934320682
exploration/Rewards Min        0.49343675628712935
exploration/Returns Mean       409.84884927735874
exploration/Returns Std        6.929486746237428
exploration/Returns Max        425.14281754412235
exploration/Returns Min        397.2550112144926
exploration/Actions Mean       0.043275528
exploration/Actions Std        0.5681911
exploration/Actions Max        0.99980706
exploration/Actions Min        -0.9998965
exploration/Num Paths          10
exploration/Average Returns    409.84884927735874
evaluation/num steps total     3230000
evaluation/num paths total     6460
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8137828756120405
evaluation/Rewards Std         0.10332186346709717
evaluation/Rewards Max         0.9791224655418829
evaluation/Rewards Min         0.4921667201326371
evaluation/Returns Mean        406.89143780602024
evaluation/Returns Std         24.10293725448391
evaluation/Returns Max         478.34371122406196
evaluation/Returns Min         394.00557886940277
evaluation/ExplReturns Mean    406.89143780602024
evaluation/ExplReturns Std     24.10293725448391
evaluation/ExplReturns Max     478.34371122406196
evaluation/ExplReturns Min     394.00557886940277
evaluation/Actions Mean        0.055500444
evaluation/Actions Std         0.47004345
evaluation/Actions Max         0.99915946
evaluation/Actions Min         -0.9989798
evaluation/Num Paths           10
evaluation/Average Returns     406.89143780602024
time/data storing (s)          0.03197734709829092
time/evaluation sampling (s)   111.86274913419038
time/exploration sampling (s)  112.35508659202605
time/logging (s)               0.030872791074216366
time/saving (s)                0.012737562879920006
time/training (s)              9.585547898896039
time/epoch (s)                 233.8789713261649
time/total (s)                 151440.38966653682
Epoch                          645
-----------------------------  ---------------------
2023-08-02 12:02:03.752765 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 646 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3781.0696]
trainer/QF1 Loss               0.0108225895
trainer/QF2 Loss               0.012989844
trainer/Policy Loss            -92.44982
trainer/Q1 Predictions Mean    103.474365
trainer/Q1 Predictions Std     1.5318209
trainer/Q1 Predictions Max     104.61613
trainer/Q1 Predictions Min     87.89139
trainer/Q2 Predictions Mean    103.47301
trainer/Q2 Predictions Std     1.488891
trainer/Q2 Predictions Max     104.67579
trainer/Q2 Predictions Min     89.19921
trainer/Q Targets Mean         103.48433
trainer/Q Targets Std          1.5203424
trainer/Q Targets Max          104.67357
trainer/Q Targets Min          88.04276
trainer/Log Pis Mean           11.10702
trainer/Log Pis Std            7.003819
trainer/Log Pis Max            38.917816
trainer/Log Pis Min            -4.5326223
trainer/Policy mu Mean         0.09337568
trainer/Policy mu Std          1.5447745
trainer/Policy mu Max          4.973888
trainer/Policy mu Min          -4.0561824
trainer/Policy log std Mean    -0.7376061
trainer/Policy log std Std     0.28150436
trainer/Policy log std Max     0.07080138
trainer/Policy log std Min     -2.4414406
trainer/Alpha                  0.0014183000894263387
trainer/Alpha Loss             -5.856346607208252
exploration/num steps total    3236000
exploration/num paths total    6472
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8994080529772338
exploration/Rewards Std        0.1568424129635882
exploration/Rewards Max        0.9794874100570756
exploration/Rewards Min        0.2557161671085923
exploration/Returns Mean       449.7040264886168
exploration/Returns Std        68.7537027882016
exploration/Returns Max        481.91719227964927
exploration/Returns Min        246.92171427036806
exploration/Actions Mean       0.040797755
exploration/Actions Std        0.6292819
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    449.7040264886168
evaluation/num steps total     3235000
evaluation/num paths total     6470
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9569854908072021
evaluation/Rewards Std         0.04722755058858985
evaluation/Rewards Max         0.9795020987340548
evaluation/Rewards Min         0.48384422359530677
evaluation/Returns Mean        478.492745403601
evaluation/Returns Std         2.0427610479734266
evaluation/Returns Max         481.6517196123709
evaluation/Returns Min         476.33139400423687
evaluation/ExplReturns Mean    478.492745403601
evaluation/ExplReturns Std     2.0427610479734266
evaluation/ExplReturns Max     481.6517196123709
evaluation/ExplReturns Min     476.33139400423687
evaluation/Actions Mean        -0.0004124664
evaluation/Actions Std         0.5307067
evaluation/Actions Max         0.99895847
evaluation/Actions Min         -0.99961156
evaluation/Num Paths           10
evaluation/Average Returns     478.492745403601
time/data storing (s)          0.03278218675404787
time/evaluation sampling (s)   112.14720364101231
time/exploration sampling (s)  111.62007671874017
time/logging (s)               0.030534179881215096
time/saving (s)                0.011186333373188972
time/training (s)              9.602810518816113
time/epoch (s)                 233.44459357857704
time/total (s)                 151673.83673097566
Epoch                          646
-----------------------------  ---------------------
2023-08-02 12:05:56.185336 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 647 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3753.6946]
trainer/QF1 Loss               0.013555156
trainer/QF2 Loss               0.019274637
trainer/Policy Loss            -91.33196
trainer/Q1 Predictions Mean    103.56621
trainer/Q1 Predictions Std     1.0568428
trainer/Q1 Predictions Max     104.52547
trainer/Q1 Predictions Min     95.671234
trainer/Q2 Predictions Mean    103.50997
trainer/Q2 Predictions Std     1.0368775
trainer/Q2 Predictions Max     104.53038
trainer/Q2 Predictions Min     95.914474
trainer/Q Targets Mean         103.53115
trainer/Q Targets Std          1.080824
trainer/Q Targets Max          104.44549
trainer/Q Targets Min          95.12884
trainer/Log Pis Mean           12.266397
trainer/Log Pis Std            7.5838256
trainer/Log Pis Max            39.31009
trainer/Log Pis Min            -2.8954842
trainer/Policy mu Mean         0.06300521
trainer/Policy mu Std          1.581368
trainer/Policy mu Max          5.8978767
trainer/Policy mu Min          -4.6564345
trainer/Policy log std Mean    -0.7276266
trainer/Policy log std Std     0.26526842
trainer/Policy log std Max     0.079355
trainer/Policy log std Min     -2.3993993
trainer/Alpha                  0.0014341702917590737
trainer/Alpha Loss             1.744142770767212
exploration/num steps total    3241000
exploration/num paths total    6482
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9495132070113493
exploration/Rewards Std        0.06109942247910499
exploration/Rewards Max        0.9793753689046772
exploration/Rewards Min        0.4960919061355594
exploration/Returns Mean       474.7566035056745
exploration/Returns Std        7.147064570488313
exploration/Returns Max        479.18532526287936
exploration/Returns Min        453.6821840038313
exploration/Actions Mean       0.04731931
exploration/Actions Std        0.6102672
exploration/Actions Max        0.9999989
exploration/Actions Min        -0.9999567
exploration/Num Paths          10
exploration/Average Returns    474.7566035056745
evaluation/num steps total     3240000
evaluation/num paths total     6480
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9433766002384107
evaluation/Rewards Std         0.07771666331950264
evaluation/Rewards Max         0.9769141202329469
evaluation/Rewards Min         0.47956129879345355
evaluation/Returns Mean        471.6883001192053
evaluation/Returns Std         17.988180956663914
evaluation/Returns Max         478.4900107263216
evaluation/Returns Min         417.78368424827846
evaluation/ExplReturns Mean    471.6883001192053
evaluation/ExplReturns Std     17.988180956663914
evaluation/ExplReturns Max     478.4900107263216
evaluation/ExplReturns Min     417.78368424827846
evaluation/Actions Mean        0.039131355
evaluation/Actions Std         0.5103706
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.99999976
evaluation/Num Paths           10
evaluation/Average Returns     471.6883001192053
time/data storing (s)          0.03224959224462509
time/evaluation sampling (s)   111.26912820897996
time/exploration sampling (s)  111.49832513090223
time/logging (s)               0.030520799569785595
time/saving (s)                0.012084586545825005
time/training (s)              9.582666989415884
time/epoch (s)                 232.42497530765831
time/total (s)                 151906.26423730794
Epoch                          647
-----------------------------  ---------------------
2023-08-02 12:09:46.876427 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 648 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4006.2844]
trainer/QF1 Loss               0.018556686
trainer/QF2 Loss               0.034823425
trainer/Policy Loss            -90.577866
trainer/Q1 Predictions Mean    103.21423
trainer/Q1 Predictions Std     2.3747349
trainer/Q1 Predictions Max     104.609085
trainer/Q1 Predictions Min     78.731766
trainer/Q2 Predictions Mean    103.25641
trainer/Q2 Predictions Std     2.3934612
trainer/Q2 Predictions Max     104.69316
trainer/Q2 Predictions Min     78.793976
trainer/Q Targets Mean         103.18203
trainer/Q Targets Std          2.390487
trainer/Q Targets Max          104.895615
trainer/Q Targets Min          77.76744
trainer/Log Pis Mean           12.750296
trainer/Log Pis Std            8.808912
trainer/Log Pis Max            56.110527
trainer/Log Pis Min            -3.0846753
trainer/Policy mu Mean         0.121414684
trainer/Policy mu Std          1.650208
trainer/Policy mu Max          10.558197
trainer/Policy mu Min          -10.300484
trainer/Policy log std Mean    -0.7387516
trainer/Policy log std Std     0.28637955
trainer/Policy log std Max     0.77380264
trainer/Policy log std Min     -2.890663
trainer/Alpha                  0.0013787217903882265
trainer/Alpha Loss             4.941920757293701
exploration/num steps total    3246000
exploration/num paths total    6492
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.941152338221365
exploration/Rewards Std        0.0696142490437338
exploration/Rewards Max        0.9791731011857433
exploration/Rewards Min        0.48729615914612706
exploration/Returns Mean       470.57616911068254
exploration/Returns Std        4.846516892141158
exploration/Returns Max        480.42387937776414
exploration/Returns Min        463.03822339745284
exploration/Actions Mean       0.028018635
exploration/Actions Std        0.60428935
exploration/Actions Max        0.99990195
exploration/Actions Min        -0.9999105
exploration/Num Paths          10
exploration/Average Returns    470.57616911068254
evaluation/num steps total     3245000
evaluation/num paths total     6490
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9375158079804831
evaluation/Rewards Std         0.0766736824380057
evaluation/Rewards Max         0.9786912836769585
evaluation/Rewards Min         0.4882465423954136
evaluation/Returns Mean        468.7579039902415
evaluation/Returns Std         8.112879190038024
evaluation/Returns Max         481.07828230129496
evaluation/Returns Min         453.13082274026215
evaluation/ExplReturns Mean    468.7579039902415
evaluation/ExplReturns Std     8.112879190038024
evaluation/ExplReturns Max     481.07828230129496
evaluation/ExplReturns Min     453.13082274026215
evaluation/Actions Mean        0.03060238
evaluation/Actions Std         0.5176588
evaluation/Actions Max         0.99939126
evaluation/Actions Min         -0.9994445
evaluation/Num Paths           10
evaluation/Average Returns     468.7579039902415
time/data storing (s)          0.031845878809690475
time/evaluation sampling (s)   110.33701772149652
time/exploration sampling (s)  110.76398996263742
time/logging (s)               0.03089979663491249
time/saving (s)                0.010376540943980217
time/training (s)              9.509596196003258
time/epoch (s)                 230.6837260965258
time/total (s)                 152136.95056862198
Epoch                          648
-----------------------------  ---------------------
2023-08-02 12:13:39.540291 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 649 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3917.6008]
trainer/QF1 Loss               0.031328026
trainer/QF2 Loss               0.028087642
trainer/Policy Loss            -92.097046
trainer/Q1 Predictions Mean    103.62674
trainer/Q1 Predictions Std     0.9177358
trainer/Q1 Predictions Max     104.71415
trainer/Q1 Predictions Min     96.00769
trainer/Q2 Predictions Mean    103.62098
trainer/Q2 Predictions Std     0.89623755
trainer/Q2 Predictions Max     104.70922
trainer/Q2 Predictions Min     96.40472
trainer/Q Targets Mean         103.50205
trainer/Q Targets Std          0.936955
trainer/Q Targets Max          104.67059
trainer/Q Targets Min          95.64006
trainer/Log Pis Mean           11.6271105
trainer/Log Pis Std            7.4396
trainer/Log Pis Max            42.149055
trainer/Log Pis Min            -4.181123
trainer/Policy mu Mean         0.095088415
trainer/Policy mu Std          1.5527412
trainer/Policy mu Max          4.979288
trainer/Policy mu Min          -5.3031745
trainer/Policy log std Mean    -0.7248826
trainer/Policy log std Std     0.2745974
trainer/Policy log std Max     0.048455954
trainer/Policy log std Min     -2.2133272
trainer/Alpha                  0.0014052967308089137
trainer/Alpha Loss             -2.4489481449127197
exploration/num steps total    3251000
exploration/num paths total    6502
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.961681314256767
exploration/Rewards Std        0.04889750960314329
exploration/Rewards Max        0.9794551647692485
exploration/Rewards Min        0.4895977200757961
exploration/Returns Mean       480.8406571283834
exploration/Returns Std        0.7759071412604299
exploration/Returns Max        481.6323499047123
exploration/Returns Min        479.1087972309701
exploration/Actions Mean       0.056088448
exploration/Actions Std        0.604716
exploration/Actions Max        0.9998639
exploration/Actions Min        -0.99990296
exploration/Num Paths          10
exploration/Average Returns    480.8406571283834
evaluation/num steps total     3250000
evaluation/num paths total     6500
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9630171762962356
evaluation/Rewards Std         0.048023476461249756
evaluation/Rewards Max         0.9788336010148474
evaluation/Rewards Min         0.48767412310050373
evaluation/Returns Mean        481.5085881481177
evaluation/Returns Std         1.2021101037873847
evaluation/Returns Max         483.1800213617952
evaluation/Returns Min         480.18168769546884
evaluation/ExplReturns Mean    481.5085881481177
evaluation/ExplReturns Std     1.2021101037873847
evaluation/ExplReturns Max     483.1800213617952
evaluation/ExplReturns Min     480.18168769546884
evaluation/Actions Mean        0.07753339
evaluation/Actions Std         0.5220536
evaluation/Actions Max         0.998794
evaluation/Actions Min         -0.99915516
evaluation/Num Paths           10
evaluation/Average Returns     481.5085881481177
time/data storing (s)          0.032396480441093445
time/evaluation sampling (s)   111.16698548663408
time/exploration sampling (s)  112.11241052672267
time/logging (s)               0.031129476614296436
time/saving (s)                0.01281717885285616
time/training (s)              9.300690507516265
time/epoch (s)                 232.65642965678126
time/total (s)                 152369.60950682499
Epoch                          649
-----------------------------  ---------------------
2023-08-02 12:17:33.426470 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 650 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3652.212]
trainer/QF1 Loss               0.021233793
trainer/QF2 Loss               0.0201696
trainer/Policy Loss            -91.145775
trainer/Q1 Predictions Mean    103.27617
trainer/Q1 Predictions Std     2.0661485
trainer/Q1 Predictions Max     104.899414
trainer/Q1 Predictions Min     81.550545
trainer/Q2 Predictions Mean    103.26581
trainer/Q2 Predictions Std     2.038503
trainer/Q2 Predictions Max     104.97874
trainer/Q2 Predictions Min     81.38673
trainer/Q Targets Mean         103.26134
trainer/Q Targets Std          2.025043
trainer/Q Targets Max          104.93718
trainer/Q Targets Min          81.45774
trainer/Log Pis Mean           12.224699
trainer/Log Pis Std            8.589625
trainer/Log Pis Max            52.866558
trainer/Log Pis Min            -2.7053804
trainer/Policy mu Mean         0.09823022
trainer/Policy mu Std          1.6171049
trainer/Policy mu Max          6.3574724
trainer/Policy mu Min          -5.7568884
trainer/Policy log std Mean    -0.72253996
trainer/Policy log std Std     0.26763597
trainer/Policy log std Max     0.38570952
trainer/Policy log std Min     -2.1630528
trainer/Alpha                  0.0014190509682521224
trainer/Alpha Loss             1.4734961986541748
exploration/num steps total    3256000
exploration/num paths total    6512
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9574569865124304
exploration/Rewards Std        0.05383411921435125
exploration/Rewards Max        0.9795540178685576
exploration/Rewards Min        0.49928158894522057
exploration/Returns Mean       478.7284932562152
exploration/Returns Std        1.883146377131333
exploration/Returns Max        482.1172493891241
exploration/Returns Min        475.3440177156172
exploration/Actions Mean       0.043619864
exploration/Actions Std        0.6708277
exploration/Actions Max        0.9999248
exploration/Actions Min        -0.9998743
exploration/Num Paths          10
exploration/Average Returns    478.7284932562152
evaluation/num steps total     3255000
evaluation/num paths total     6510
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.952822713804875
evaluation/Rewards Std         0.06283019476320614
evaluation/Rewards Max         0.9796592273562311
evaluation/Rewards Min         0.4896063036975541
evaluation/Returns Mean        476.4113569024374
evaluation/Returns Std         7.3476345831215815
evaluation/Returns Max         481.76944968235154
evaluation/Returns Min         455.80732542894197
evaluation/ExplReturns Mean    476.4113569024374
evaluation/ExplReturns Std     7.3476345831215815
evaluation/ExplReturns Max     481.76944968235154
evaluation/ExplReturns Min     455.80732542894197
evaluation/Actions Mean        0.054001693
evaluation/Actions Std         0.6356239
evaluation/Actions Max         0.99998844
evaluation/Actions Min         -0.99996036
evaluation/Num Paths           10
evaluation/Average Returns     476.4113569024374
time/data storing (s)          0.032328604720532894
time/evaluation sampling (s)   111.89062551036477
time/exploration sampling (s)  112.19348762743175
time/logging (s)               0.030359934084117413
time/saving (s)                0.011925108730793
time/training (s)              9.71908734086901
time/epoch (s)                 233.87781412620097
time/total (s)                 152603.48978086747
Epoch                          650
-----------------------------  ---------------------
2023-08-02 12:21:25.986793 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 651 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4032.0234]
trainer/QF1 Loss               0.047204863
trainer/QF2 Loss               0.0252877
trainer/Policy Loss            -90.77398
trainer/Q1 Predictions Mean    103.16856
trainer/Q1 Predictions Std     1.506368
trainer/Q1 Predictions Max     104.6089
trainer/Q1 Predictions Min     89.63842
trainer/Q2 Predictions Mean    103.266914
trainer/Q2 Predictions Std     1.5217011
trainer/Q2 Predictions Max     104.774536
trainer/Q2 Predictions Min     89.88474
trainer/Q Targets Mean         103.30709
trainer/Q Targets Std          1.4855038
trainer/Q Targets Max          104.85176
trainer/Q Targets Min          90.77448
trainer/Log Pis Mean           12.53157
trainer/Log Pis Std            8.184773
trainer/Log Pis Max            67.90252
trainer/Log Pis Min            -2.8723092
trainer/Policy mu Mean         0.13899094
trainer/Policy mu Std          1.6291426
trainer/Policy mu Max          6.559357
trainer/Policy mu Min          -6.765477
trainer/Policy log std Mean    -0.71610737
trainer/Policy log std Std     0.27691624
trainer/Policy log std Max     0.6645648
trainer/Policy log std Min     -2.118844
trainer/Alpha                  0.001477258512750268
trainer/Alpha Loss             3.464604377746582
exploration/num steps total    3261000
exploration/num paths total    6522
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9360991377712642
exploration/Rewards Std        0.0757022960837498
exploration/Rewards Max        0.978821987770548
exploration/Rewards Min        0.4937763526192141
exploration/Returns Mean       468.0495688856322
exploration/Returns Std        11.249997594044142
exploration/Returns Max        478.18575790609106
exploration/Returns Min        453.04673293715916
exploration/Actions Mean       0.09830242
exploration/Actions Std        0.62521756
exploration/Actions Max        0.9998173
exploration/Actions Min        -0.99988276
exploration/Num Paths          10
exploration/Average Returns    468.0495688856322
evaluation/num steps total     3260000
evaluation/num paths total     6520
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9260748045242954
evaluation/Rewards Std         0.08176351999813095
evaluation/Rewards Max         0.9786425616529244
evaluation/Rewards Min         0.48594118887370064
evaluation/Returns Mean        463.03740226214757
evaluation/Returns Std         9.886198342688434
evaluation/Returns Max         478.01529298833026
evaluation/Returns Min         448.05848306541236
evaluation/ExplReturns Mean    463.03740226214757
evaluation/ExplReturns Std     9.886198342688434
evaluation/ExplReturns Max     478.01529298833026
evaluation/ExplReturns Min     448.05848306541236
evaluation/Actions Mean        0.126899
evaluation/Actions Std         0.5556517
evaluation/Actions Max         0.999206
evaluation/Actions Min         -0.9997751
evaluation/Num Paths           10
evaluation/Average Returns     463.03740226214757
time/data storing (s)          0.03229559399187565
time/evaluation sampling (s)   110.81936274841428
time/exploration sampling (s)  111.99557024147362
time/logging (s)               0.030545057728886604
time/saving (s)                0.0127029400318861
time/training (s)              9.662412376143038
time/epoch (s)                 232.55288895778358
time/total (s)                 152836.04515417386
Epoch                          651
-----------------------------  --------------------
2023-08-02 12:25:21.857284 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 652 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4011.7876]
trainer/QF1 Loss               0.02403504
trainer/QF2 Loss               0.02431379
trainer/Policy Loss            -91.37072
trainer/Q1 Predictions Mean    103.203636
trainer/Q1 Predictions Std     2.3506477
trainer/Q1 Predictions Max     104.667885
trainer/Q1 Predictions Min     74.68352
trainer/Q2 Predictions Mean    103.22082
trainer/Q2 Predictions Std     2.345426
trainer/Q2 Predictions Max     104.61978
trainer/Q2 Predictions Min     75.56527
trainer/Q Targets Mean         103.16581
trainer/Q Targets Std          2.3910432
trainer/Q Targets Max          104.5363
trainer/Q Targets Min          74.803
trainer/Log Pis Mean           11.932527
trainer/Log Pis Std            9.939241
trainer/Log Pis Max            90.00226
trainer/Log Pis Min            -3.435027
trainer/Policy mu Mean         0.08150388
trainer/Policy mu Std          1.616118
trainer/Policy mu Max          8.872729
trainer/Policy mu Min          -7.89532
trainer/Policy log std Mean    -0.7346234
trainer/Policy log std Std     0.27437997
trainer/Policy log std Max     0.34310818
trainer/Policy log std Min     -2.1337805
trainer/Alpha                  0.0014380770735442638
trainer/Alpha Loss             -0.4415666460990906
exploration/num steps total    3266000
exploration/num paths total    6532
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9596555854386234
exploration/Rewards Std        0.05334649449707514
exploration/Rewards Max        0.9797697856968042
exploration/Rewards Min        0.4936295643745114
exploration/Returns Mean       479.8277927193117
exploration/Returns Std        1.8926585643978926
exploration/Returns Max        482.3380471418706
exploration/Returns Min        475.09096920545886
exploration/Actions Mean       0.087502025
exploration/Actions Std        0.6115724
exploration/Actions Max        0.99987626
exploration/Actions Min        -0.99995416
exploration/Num Paths          10
exploration/Average Returns    479.8277927193117
evaluation/num steps total     3265000
evaluation/num paths total     6530
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9505056576917618
evaluation/Rewards Std         0.06576694433559879
evaluation/Rewards Max         0.9786348065826269
evaluation/Rewards Min         0.4930477917012979
evaluation/Returns Mean        475.25282884588086
evaluation/Returns Std         2.27011156229323
evaluation/Returns Max         478.62346236328335
evaluation/Returns Min         472.2592264113646
evaluation/ExplReturns Mean    475.25282884588086
evaluation/ExplReturns Std     2.27011156229323
evaluation/ExplReturns Max     478.62346236328335
evaluation/ExplReturns Min     472.2592264113646
evaluation/Actions Mean        0.12339914
evaluation/Actions Std         0.55647737
evaluation/Actions Max         0.9994199
evaluation/Actions Min         -0.9991381
evaluation/Num Paths           10
evaluation/Average Returns     475.25282884588086
time/data storing (s)          0.03234615549445152
time/evaluation sampling (s)   113.25693962723017
time/exploration sampling (s)  112.9370991261676
time/logging (s)               0.031091739423573017
time/saving (s)                0.012291645631194115
time/training (s)              9.593529214151204
time/epoch (s)                 235.86329750809819
time/total (s)                 153071.9109632168
Epoch                          652
-----------------------------  ---------------------
2023-08-02 12:29:15.095919 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 653 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3992.291]
trainer/QF1 Loss               0.02326607
trainer/QF2 Loss               0.020769492
trainer/Policy Loss            -91.812256
trainer/Q1 Predictions Mean    103.31564
trainer/Q1 Predictions Std     1.4374696
trainer/Q1 Predictions Max     104.57704
trainer/Q1 Predictions Min     91.28896
trainer/Q2 Predictions Mean    103.35156
trainer/Q2 Predictions Std     1.4446818
trainer/Q2 Predictions Max     104.63541
trainer/Q2 Predictions Min     91.18256
trainer/Q Targets Mean         103.27662
trainer/Q Targets Std          1.4268917
trainer/Q Targets Max          104.4734
trainer/Q Targets Min          91.51181
trainer/Log Pis Mean           11.613087
trainer/Log Pis Std            8.183999
trainer/Log Pis Max            47.83003
trainer/Log Pis Min            -6.764923
trainer/Policy mu Mean         0.0652141
trainer/Policy mu Std          1.5744611
trainer/Policy mu Max          5.0654597
trainer/Policy mu Min          -6.0368958
trainer/Policy log std Mean    -0.7414546
trainer/Policy log std Std     0.26989716
trainer/Policy log std Max     0.28624356
trainer/Policy log std Min     -2.1090338
trainer/Alpha                  0.0014069435419514775
trainer/Alpha Loss             -2.54046893119812
exploration/num steps total    3271000
exploration/num paths total    6542
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9604320391163989
exploration/Rewards Std        0.047249921360799946
exploration/Rewards Max        0.9796661302855285
exploration/Rewards Min        0.49543046888624204
exploration/Returns Mean       480.2160195581993
exploration/Returns Std        0.31586512440066755
exploration/Returns Max        480.74447984514086
exploration/Returns Min        479.5112021931179
exploration/Actions Mean       0.025589557
exploration/Actions Std        0.6088319
exploration/Actions Max        0.99976325
exploration/Actions Min        -0.9998978
exploration/Num Paths          10
exploration/Average Returns    480.2160195581993
evaluation/num steps total     3270000
evaluation/num paths total     6540
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9597725817472452
evaluation/Rewards Std         0.04619038380578098
evaluation/Rewards Max         0.9788679816283804
evaluation/Rewards Min         0.49673312736029107
evaluation/Returns Mean        479.88629087362244
evaluation/Returns Std         0.13766424897970847
evaluation/Returns Max         480.0390177435336
evaluation/Returns Min         479.5971085996501
evaluation/ExplReturns Mean    479.88629087362244
evaluation/ExplReturns Std     0.13766424897970847
evaluation/ExplReturns Max     480.0390177435336
evaluation/ExplReturns Min     479.5971085996501
evaluation/Actions Mean        0.034193225
evaluation/Actions Std         0.51769656
evaluation/Actions Max         0.997722
evaluation/Actions Min         -0.9994878
evaluation/Num Paths           10
evaluation/Average Returns     479.88629087362244
time/data storing (s)          0.032377745024859905
time/evaluation sampling (s)   111.12281699106097
time/exploration sampling (s)  112.39470319263637
time/logging (s)               0.030378286726772785
time/saving (s)                0.011370849795639515
time/training (s)              9.638549510389566
time/epoch (s)                 233.23019657563418
time/total (s)                 153305.14374238998
Epoch                          653
-----------------------------  ---------------------
2023-08-02 12:33:11.285729 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 654 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3872.3394]
trainer/QF1 Loss               0.018622063
trainer/QF2 Loss               0.016208367
trainer/Policy Loss            -91.171844
trainer/Q1 Predictions Mean    103.25939
trainer/Q1 Predictions Std     1.3840069
trainer/Q1 Predictions Max     104.53661
trainer/Q1 Predictions Min     93.46539
trainer/Q2 Predictions Mean    103.32445
trainer/Q2 Predictions Std     1.3793479
trainer/Q2 Predictions Max     104.648796
trainer/Q2 Predictions Min     93.246864
trainer/Q Targets Mean         103.32039
trainer/Q Targets Std          1.361836
trainer/Q Targets Max          104.506996
trainer/Q Targets Min          93.91139
trainer/Log Pis Mean           12.20602
trainer/Log Pis Std            8.357864
trainer/Log Pis Max            67.4167
trainer/Log Pis Min            -5.9322395
trainer/Policy mu Mean         0.0012803487
trainer/Policy mu Std          1.614422
trainer/Policy mu Max          8.661131
trainer/Policy mu Min          -7.9870973
trainer/Policy log std Mean    -0.73867416
trainer/Policy log std Std     0.27839997
trainer/Policy log std Max     1.030314
trainer/Policy log std Min     -2.783216
trainer/Alpha                  0.0014447523280978203
trainer/Alpha Loss             1.347353219985962
exploration/num steps total    3276000
exploration/num paths total    6552
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9562552262738202
exploration/Rewards Std        0.06551862435334707
exploration/Rewards Max        0.9798386254004732
exploration/Rewards Min        0.4865957919267449
exploration/Returns Mean       478.12761313691
exploration/Returns Std        11.383977642753056
exploration/Returns Max        482.9110489892851
exploration/Returns Min        444.5020404260535
exploration/Actions Mean       -0.052085735
exploration/Actions Std        0.5880641
exploration/Actions Max        0.9999822
exploration/Actions Min        -0.9999659
exploration/Num Paths          10
exploration/Average Returns    478.12761313691
evaluation/num steps total     3275000
evaluation/num paths total     6550
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9603081800854285
evaluation/Rewards Std         0.05881943808586771
evaluation/Rewards Max         0.9779036714712673
evaluation/Rewards Min         0.4964468282902639
evaluation/Returns Mean        480.1540900427143
evaluation/Returns Std         8.163860424581342
evaluation/Returns Max         483.2742576250919
evaluation/Returns Min         455.68383085433305
evaluation/ExplReturns Mean    480.1540900427143
evaluation/ExplReturns Std     8.163860424581342
evaluation/ExplReturns Max     483.2742576250919
evaluation/ExplReturns Min     455.68383085433305
evaluation/Actions Mean        -0.06456551
evaluation/Actions Std         0.49239966
evaluation/Actions Max         0.99887145
evaluation/Actions Min         -0.9993215
evaluation/Num Paths           10
evaluation/Average Returns     480.1540900427143
time/data storing (s)          0.03233284782618284
time/evaluation sampling (s)   113.55795439518988
time/exploration sampling (s)  112.96852825582027
time/logging (s)               0.030998378060758114
time/saving (s)                0.011188692413270473
time/training (s)              9.581781219691038
time/epoch (s)                 236.1827837890014
time/total (s)                 153541.32897244114
Epoch                          654
-----------------------------  ---------------------
2023-08-02 12:37:03.196705 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 655 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4121.884]
trainer/QF1 Loss               0.023163777
trainer/QF2 Loss               0.014948523
trainer/Policy Loss            -91.445816
trainer/Q1 Predictions Mean    103.15854
trainer/Q1 Predictions Std     1.6792506
trainer/Q1 Predictions Max     104.58237
trainer/Q1 Predictions Min     89.434006
trainer/Q2 Predictions Mean    103.1974
trainer/Q2 Predictions Std     1.6785265
trainer/Q2 Predictions Max     104.63918
trainer/Q2 Predictions Min     89.51348
trainer/Q Targets Mean         103.21893
trainer/Q Targets Std          1.6557888
trainer/Q Targets Max          104.66076
trainer/Q Targets Min          89.55159
trainer/Log Pis Mean           11.811972
trainer/Log Pis Std            8.333993
trainer/Log Pis Max            67.035255
trainer/Log Pis Min            -2.7701838
trainer/Policy mu Mean         -0.09238672
trainer/Policy mu Std          1.5661587
trainer/Policy mu Max          7.636054
trainer/Policy mu Min          -5.6243677
trainer/Policy log std Mean    -0.7319017
trainer/Policy log std Std     0.28738603
trainer/Policy log std Max     0.32020903
trainer/Policy log std Min     -1.9460361
trainer/Alpha                  0.0014129073824733496
trainer/Alpha Loss             -1.2338074445724487
exploration/num steps total    3281000
exploration/num paths total    6562
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9593317816848436
exploration/Rewards Std        0.049095545531144265
exploration/Rewards Max        0.9798856438043922
exploration/Rewards Min        0.4814006407464537
exploration/Returns Mean       479.6658908424218
exploration/Returns Std        0.6073008396793915
exploration/Returns Max        480.345724733658
exploration/Returns Min        478.5299231057832
exploration/Actions Mean       0.013685228
exploration/Actions Std        0.57176316
exploration/Actions Max        0.99974257
exploration/Actions Min        -0.99990815
exploration/Num Paths          10
exploration/Average Returns    479.6658908424218
evaluation/num steps total     3280000
evaluation/num paths total     6560
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9318557259189448
evaluation/Rewards Std         0.0842597290670387
evaluation/Rewards Max         0.9791202727526062
evaluation/Rewards Min         0.491548371777807
evaluation/Returns Mean        465.92786295947246
evaluation/Returns Std         35.02368073391735
evaluation/Returns Max         478.11098559757914
evaluation/Returns Min         360.86475279832763
evaluation/ExplReturns Mean    465.92786295947246
evaluation/ExplReturns Std     35.02368073391735
evaluation/ExplReturns Max     478.11098559757914
evaluation/ExplReturns Min     360.86475279832763
evaluation/Actions Mean        0.017538656
evaluation/Actions Std         0.47043413
evaluation/Actions Max         0.9983286
evaluation/Actions Min         -0.9998116
evaluation/Num Paths           10
evaluation/Average Returns     465.92786295947246
time/data storing (s)          0.03198659233748913
time/evaluation sampling (s)   111.13626630511135
time/exploration sampling (s)  111.01309080049396
time/logging (s)               0.030623476952314377
time/saving (s)                0.010366537608206272
time/training (s)              9.68061064183712
time/epoch (s)                 231.90294435434043
time/total (s)                 153773.23440972064
Epoch                          655
-----------------------------  ---------------------
2023-08-02 12:40:57.855010 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 656 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4158.794]
trainer/QF1 Loss               0.021326005
trainer/QF2 Loss               0.022838168
trainer/Policy Loss            -91.91716
trainer/Q1 Predictions Mean    103.23813
trainer/Q1 Predictions Std     2.2278461
trainer/Q1 Predictions Max     104.84476
trainer/Q1 Predictions Min     78.395134
trainer/Q2 Predictions Mean    103.19339
trainer/Q2 Predictions Std     2.2027628
trainer/Q2 Predictions Max     104.737236
trainer/Q2 Predictions Min     78.963295
trainer/Q Targets Mean         103.25688
trainer/Q Targets Std          2.2258093
trainer/Q Targets Max          104.727486
trainer/Q Targets Min          79.187546
trainer/Log Pis Mean           11.3580265
trainer/Log Pis Std            7.880507
trainer/Log Pis Max            52.23259
trainer/Log Pis Min            -8.25697
trainer/Policy mu Mean         0.14221686
trainer/Policy mu Std          1.5947646
trainer/Policy mu Max          10.382169
trainer/Policy mu Min          -6.250026
trainer/Policy log std Mean    -0.69832796
trainer/Policy log std Std     0.27233297
trainer/Policy log std Max     1.7830837
trainer/Policy log std Min     -1.981257
trainer/Alpha                  0.0013810807140544057
trainer/Alpha Loss             -4.227344989776611
exploration/num steps total    3286000
exploration/num paths total    6572
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9653025927560699
exploration/Rewards Std        0.048485205407220025
exploration/Rewards Max        0.9793536756365546
exploration/Rewards Min        0.49825427041354
exploration/Returns Mean       482.65129637803483
exploration/Returns Std        0.22542193976592434
exploration/Returns Max        482.8920336860185
exploration/Returns Min        482.2450772776517
exploration/Actions Mean       0.11446527
exploration/Actions Std        0.6339833
exploration/Actions Max        0.9995624
exploration/Actions Min        -0.99994725
exploration/Num Paths          10
exploration/Average Returns    482.65129637803483
evaluation/num steps total     3285000
evaluation/num paths total     6570
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9645211804453997
evaluation/Rewards Std         0.04807790972356836
evaluation/Rewards Max         0.979216299461586
evaluation/Rewards Min         0.4987957252239785
evaluation/Returns Mean        482.2605902226998
evaluation/Returns Std         0.18965661203346001
evaluation/Returns Max         482.57202343987217
evaluation/Returns Min         481.9795262214915
evaluation/ExplReturns Mean    482.2605902226998
evaluation/ExplReturns Std     0.18965661203346001
evaluation/ExplReturns Max     482.57202343987217
evaluation/ExplReturns Min     481.9795262214915
evaluation/Actions Mean        0.15552272
evaluation/Actions Std         0.52507955
evaluation/Actions Max         0.9973806
evaluation/Actions Min         -0.9995098
evaluation/Num Paths           10
evaluation/Average Returns     482.2605902226998
time/data storing (s)          0.03223981522023678
time/evaluation sampling (s)   112.4402353959158
time/exploration sampling (s)  112.46403132099658
time/logging (s)               0.030503293499350548
time/saving (s)                0.010329035110771656
time/training (s)              9.673205006867647
time/epoch (s)                 234.6505438676104
time/total (s)                 154007.88743068464
Epoch                          656
-----------------------------  ---------------------
2023-08-02 12:44:51.554932 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 657 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4185.672]
trainer/QF1 Loss               0.014242811
trainer/QF2 Loss               0.014924614
trainer/Policy Loss            -92.22682
trainer/Q1 Predictions Mean    103.30121
trainer/Q1 Predictions Std     1.3752002
trainer/Q1 Predictions Max     104.95835
trainer/Q1 Predictions Min     91.46431
trainer/Q2 Predictions Mean    103.2507
trainer/Q2 Predictions Std     1.3736993
trainer/Q2 Predictions Max     104.82673
trainer/Q2 Predictions Min     91.55208
trainer/Q Targets Mean         103.25463
trainer/Q Targets Std          1.3693962
trainer/Q Targets Max          104.81526
trainer/Q Targets Min          91.623405
trainer/Log Pis Mean           11.13701
trainer/Log Pis Std            7.299379
trainer/Log Pis Max            45.579678
trainer/Log Pis Min            -7.47821
trainer/Policy mu Mean         0.08281244
trainer/Policy mu Std          1.5639815
trainer/Policy mu Max          5.667809
trainer/Policy mu Min          -5.158483
trainer/Policy log std Mean    -0.74343175
trainer/Policy log std Std     0.2783068
trainer/Policy log std Max     0.09337938
trainer/Policy log std Min     -2.218508
trainer/Alpha                  0.0013264779699966311
trainer/Alpha Loss             -5.717523574829102
exploration/num steps total    3291000
exploration/num paths total    6582
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9660046528826044
exploration/Rewards Std        0.04729629252061837
exploration/Rewards Max        0.9797518919214003
exploration/Rewards Min        0.4928303007645231
exploration/Returns Mean       483.0023264413021
exploration/Returns Std        0.1947423447904344
exploration/Returns Max        483.421252045699
exploration/Returns Min        482.7924211424166
exploration/Actions Mean       0.08786926
exploration/Actions Std        0.6216838
exploration/Actions Max        0.99968547
exploration/Actions Min        -0.9998036
exploration/Num Paths          10
exploration/Average Returns    483.0023264413021
evaluation/num steps total     3290000
evaluation/num paths total     6580
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9660285455734078
evaluation/Rewards Std         0.04635042706315463
evaluation/Rewards Max         0.978974970298896
evaluation/Rewards Min         0.501116426426398
evaluation/Returns Mean        483.0142727867039
evaluation/Returns Std         0.1334026347628667
evaluation/Returns Max         483.3456708413262
evaluation/Returns Min         482.79665816221365
evaluation/ExplReturns Mean    483.0142727867039
evaluation/ExplReturns Std     0.1334026347628667
evaluation/ExplReturns Max     483.3456708413262
evaluation/ExplReturns Min     482.79665816221365
evaluation/Actions Mean        0.114550576
evaluation/Actions Std         0.5073165
evaluation/Actions Max         0.9982297
evaluation/Actions Min         -0.9988039
evaluation/Num Paths           10
evaluation/Average Returns     483.0142727867039
time/data storing (s)          0.03234775736927986
time/evaluation sampling (s)   112.48055280838162
time/exploration sampling (s)  112.12022807728499
time/logging (s)               0.030644116923213005
time/saving (s)                0.01041257195174694
time/training (s)              9.018215141259134
time/epoch (s)                 233.69240047316998
time/total (s)                 154241.58234059624
Epoch                          657
-----------------------------  ---------------------
2023-08-02 12:48:46.784326 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 658 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3978.93]
trainer/QF1 Loss               0.012075886
trainer/QF2 Loss               0.012916159
trainer/Policy Loss            -91.60034
trainer/Q1 Predictions Mean    103.19252
trainer/Q1 Predictions Std     2.2532961
trainer/Q1 Predictions Max     104.88648
trainer/Q1 Predictions Min     76.78424
trainer/Q2 Predictions Mean    103.232895
trainer/Q2 Predictions Std     2.239486
trainer/Q2 Predictions Max     104.95251
trainer/Q2 Predictions Min     76.97209
trainer/Q Targets Mean         103.189835
trainer/Q Targets Std          2.2618964
trainer/Q Targets Max          104.93317
trainer/Q Targets Min          76.54059
trainer/Log Pis Mean           11.68688
trainer/Log Pis Std            8.184296
trainer/Log Pis Max            49.580105
trainer/Log Pis Min            -5.764147
trainer/Policy mu Mean         0.119935654
trainer/Policy mu Std          1.5793636
trainer/Policy mu Max          5.9776187
trainer/Policy mu Min          -6.979696
trainer/Policy log std Mean    -0.75529766
trainer/Policy log std Std     0.28335774
trainer/Policy log std Max     0.8133932
trainer/Policy log std Min     -2.0510669
trainer/Alpha                  0.0013746131444349885
trainer/Alpha Loss             -2.063339948654175
exploration/num steps total    3296000
exploration/num paths total    6592
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9384364987997779
exploration/Rewards Std        0.05091567356640866
exploration/Rewards Max        0.9791948924006908
exploration/Rewards Min        0.4880207152002385
exploration/Returns Mean       469.2182493998889
exploration/Returns Std        2.427387862327046
exploration/Returns Max        472.2650489923415
exploration/Returns Min        463.7486445151466
exploration/Actions Mean       0.004078668
exploration/Actions Std        0.5908001
exploration/Actions Max        0.9997868
exploration/Actions Min        -0.99997175
exploration/Num Paths          10
exploration/Average Returns    469.2182493998889
evaluation/num steps total     3295000
evaluation/num paths total     6590
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9409011067022557
evaluation/Rewards Std         0.04479575343189984
evaluation/Rewards Max         0.9795480691362238
evaluation/Rewards Min         0.49362293650178507
evaluation/Returns Mean        470.45055335112784
evaluation/Returns Std         2.661459361154241
evaluation/Returns Max         475.7464061305504
evaluation/Returns Min         468.12447741768705
evaluation/ExplReturns Mean    470.45055335112784
evaluation/ExplReturns Std     2.661459361154241
evaluation/ExplReturns Max     475.7464061305504
evaluation/ExplReturns Min     468.12447741768705
evaluation/Actions Mean        0.074641876
evaluation/Actions Std         0.48703536
evaluation/Actions Max         0.99790543
evaluation/Actions Min         -0.9998541
evaluation/Num Paths           10
evaluation/Average Returns     470.45055335112784
time/data storing (s)          0.03203133028000593
time/evaluation sampling (s)   111.78433200530708
time/exploration sampling (s)  113.71525567397475
time/logging (s)               0.03093897830694914
time/saving (s)                0.011740527115762234
time/training (s)              9.647588345222175
time/epoch (s)                 235.22188686020672
time/total (s)                 154476.80669702217
Epoch                          658
-----------------------------  ---------------------
2023-08-02 12:52:40.466909 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 659 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4099.291]
trainer/QF1 Loss               0.024963621
trainer/QF2 Loss               0.023329988
trainer/Policy Loss            -91.718216
trainer/Q1 Predictions Mean    103.10497
trainer/Q1 Predictions Std     1.4340662
trainer/Q1 Predictions Max     104.81191
trainer/Q1 Predictions Min     88.33163
trainer/Q2 Predictions Mean    103.13608
trainer/Q2 Predictions Std     1.4205112
trainer/Q2 Predictions Max     104.694786
trainer/Q2 Predictions Min     88.465515
trainer/Q Targets Mean         103.20363
trainer/Q Targets Std          1.4084538
trainer/Q Targets Max          104.832306
trainer/Q Targets Min          88.707634
trainer/Log Pis Mean           11.482794
trainer/Log Pis Std            7.904632
trainer/Log Pis Max            45.88935
trainer/Log Pis Min            -3.8413262
trainer/Policy mu Mean         0.02892156
trainer/Policy mu Std          1.5432204
trainer/Policy mu Max          9.344164
trainer/Policy mu Min          -5.043091
trainer/Policy log std Mean    -0.73103386
trainer/Policy log std Std     0.26906148
trainer/Policy log std Max     0.20840788
trainer/Policy log std Min     -2.1181815
trainer/Alpha                  0.001368384575471282
trainer/Alpha Loss             -3.410416603088379
exploration/num steps total    3301000
exploration/num paths total    6602
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9570874821761965
exploration/Rewards Std        0.04774501696744048
exploration/Rewards Max        0.9784056778606927
exploration/Rewards Min        0.4921329585915098
exploration/Returns Mean       478.54374108809816
exploration/Returns Std        0.317790409631112
exploration/Returns Max        479.1660184902432
exploration/Returns Min        477.90459834276123
exploration/Actions Mean       -0.05007086
exploration/Actions Std        0.5837423
exploration/Actions Max        0.99997926
exploration/Actions Min        -0.999927
exploration/Num Paths          10
exploration/Average Returns    478.54374108809816
evaluation/num steps total     3300000
evaluation/num paths total     6600
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9592991962652202
evaluation/Rewards Std         0.04596292882618839
evaluation/Rewards Max         0.9793342168071532
evaluation/Rewards Min         0.4982607867184077
evaluation/Returns Mean        479.6495981326103
evaluation/Returns Std         0.46297778813262097
evaluation/Returns Max         480.20056471846766
evaluation/Returns Min         478.92208210700363
evaluation/ExplReturns Mean    479.6495981326103
evaluation/ExplReturns Std     0.46297778813262097
evaluation/ExplReturns Max     480.20056471846766
evaluation/ExplReturns Min     478.92208210700363
evaluation/Actions Mean        -0.0414919
evaluation/Actions Std         0.42097256
evaluation/Actions Max         0.9987331
evaluation/Actions Min         -0.9995618
evaluation/Num Paths           10
evaluation/Average Returns     479.6495981326103
time/data storing (s)          0.032223593443632126
time/evaluation sampling (s)   111.7175451554358
time/exploration sampling (s)  112.20209975261241
time/logging (s)               0.031087996438145638
time/saving (s)                0.010421471670269966
time/training (s)              9.681556071154773
time/epoch (s)                 233.67493404075503
time/total (s)                 154710.4841788169
Epoch                          659
-----------------------------  --------------------
2023-08-02 12:56:35.224249 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 660 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4032.6116]
trainer/QF1 Loss               0.017242216
trainer/QF2 Loss               0.016424242
trainer/Policy Loss            -91.80583
trainer/Q1 Predictions Mean    103.15053
trainer/Q1 Predictions Std     1.2631426
trainer/Q1 Predictions Max     104.83052
trainer/Q1 Predictions Min     94.51266
trainer/Q2 Predictions Mean    103.13274
trainer/Q2 Predictions Std     1.2793347
trainer/Q2 Predictions Max     104.85245
trainer/Q2 Predictions Min     94.33536
trainer/Q Targets Mean         103.128494
trainer/Q Targets Std          1.269848
trainer/Q Targets Max          104.881035
trainer/Q Targets Min          95.42411
trainer/Log Pis Mean           11.420057
trainer/Log Pis Std            7.8322673
trainer/Log Pis Max            45.874023
trainer/Log Pis Min            -4.189066
trainer/Policy mu Mean         0.04096651
trainer/Policy mu Std          1.5738312
trainer/Policy mu Max          4.8956585
trainer/Policy mu Min          -5.329133
trainer/Policy log std Mean    -0.7240537
trainer/Policy log std Std     0.28219536
trainer/Policy log std Max     0.162175
trainer/Policy log std Min     -2.123226
trainer/Alpha                  0.001359567861072719
trainer/Alpha Loss             -3.827854871749878
exploration/num steps total    3306000
exploration/num paths total    6612
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9569733837241667
exploration/Rewards Std        0.051598553874734936
exploration/Rewards Max        0.9788983173517132
exploration/Rewards Min        0.49877494002977785
exploration/Returns Mean       478.48669186208326
exploration/Returns Std        1.3385606248805568
exploration/Returns Max        479.9748794780202
exploration/Returns Min        475.33808417684224
exploration/Actions Mean       0.031143434
exploration/Actions Std        0.6375242
exploration/Actions Max        0.99997646
exploration/Actions Min        -0.9999141
exploration/Num Paths          10
exploration/Average Returns    478.48669186208326
evaluation/num steps total     3305000
evaluation/num paths total     6610
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9562009110293413
evaluation/Rewards Std         0.054231562630972396
evaluation/Rewards Max         0.9792587297462572
evaluation/Rewards Min         0.4861095458742778
evaluation/Returns Mean        478.10045551467067
evaluation/Returns Std         2.6899295847399323
evaluation/Returns Max         480.9684352195339
evaluation/Returns Min         472.3827048649753
evaluation/ExplReturns Mean    478.10045551467067
evaluation/ExplReturns Std     2.6899295847399323
evaluation/ExplReturns Max     480.9684352195339
evaluation/ExplReturns Min     472.3827048649753
evaluation/Actions Mean        0.029935535
evaluation/Actions Std         0.574749
evaluation/Actions Max         0.9997395
evaluation/Actions Min         -0.99968576
evaluation/Num Paths           10
evaluation/Average Returns     478.10045551467067
time/data storing (s)          0.033029778860509396
time/evaluation sampling (s)   111.6945103732869
time/exploration sampling (s)  113.0144749796018
time/logging (s)               0.031329321675002575
time/saving (s)                0.012699900195002556
time/training (s)              9.96353049762547
time/epoch (s)                 234.7495748512447
time/total (s)                 154945.23646989837
Epoch                          660
-----------------------------  --------------------
2023-08-02 13:00:30.117824 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 661 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3811.2183]
trainer/QF1 Loss               0.015808241
trainer/QF2 Loss               0.012818886
trainer/Policy Loss            -91.79133
trainer/Q1 Predictions Mean    103.34969
trainer/Q1 Predictions Std     0.9571998
trainer/Q1 Predictions Max     105.308975
trainer/Q1 Predictions Min     95.61084
trainer/Q2 Predictions Mean    103.320435
trainer/Q2 Predictions Std     0.95372474
trainer/Q2 Predictions Max     105.301735
trainer/Q2 Predictions Min     95.855865
trainer/Q Targets Mean         103.32232
trainer/Q Targets Std          0.9611
trainer/Q Targets Max          105.25838
trainer/Q Targets Min          95.603226
trainer/Log Pis Mean           11.61706
trainer/Log Pis Std            6.969223
trainer/Log Pis Max            43.760704
trainer/Log Pis Min            -5.664966
trainer/Policy mu Mean         -0.06563342
trainer/Policy mu Std          1.5338157
trainer/Policy mu Max          4.49402
trainer/Policy mu Min          -4.317035
trainer/Policy log std Mean    -0.76879627
trainer/Policy log std Std     0.26932147
trainer/Policy log std Max     0.0069149733
trainer/Policy log std Min     -1.9350425
trainer/Alpha                  0.0013151390012353659
trainer/Alpha Loss             -2.540287733078003
exploration/num steps total    3311000
exploration/num paths total    6622
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9529447181066724
exploration/Rewards Std        0.06112752339205489
exploration/Rewards Max        0.9798039943385115
exploration/Rewards Min        0.49907560975208975
exploration/Returns Mean       476.4723590533361
exploration/Returns Std        1.8762102296692889
exploration/Returns Max        478.65245389784036
exploration/Returns Min        473.59542657358094
exploration/Actions Mean       0.065827765
exploration/Actions Std        0.6534231
exploration/Actions Max        0.9998484
exploration/Actions Min        -0.9999516
exploration/Num Paths          10
exploration/Average Returns    476.4723590533361
evaluation/num steps total     3310000
evaluation/num paths total     6620
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9597441623046198
evaluation/Rewards Std         0.046598721075466865
evaluation/Rewards Max         0.9790320599603576
evaluation/Rewards Min         0.4984505419907545
evaluation/Returns Mean        479.87208115231
evaluation/Returns Std         0.35359799639097256
evaluation/Returns Max         480.4356296497486
evaluation/Returns Min         479.34292908522633
evaluation/ExplReturns Mean    479.87208115231
evaluation/ExplReturns Std     0.35359799639097256
evaluation/ExplReturns Max     480.4356296497486
evaluation/ExplReturns Min     479.34292908522633
evaluation/Actions Mean        0.095506355
evaluation/Actions Std         0.571548
evaluation/Actions Max         0.9986172
evaluation/Actions Min         -0.999339
evaluation/Num Paths           10
evaluation/Average Returns     479.87208115231
time/data storing (s)          0.03266705293208361
time/evaluation sampling (s)   112.26970593165606
time/exploration sampling (s)  112.98405450768769
time/logging (s)               0.031984396278858185
time/saving (s)                0.011857440695166588
time/training (s)              9.55593359284103
time/epoch (s)                 234.8862029220909
time/total (s)                 155180.1253708722
Epoch                          661
-----------------------------  ---------------------
2023-08-02 13:04:21.090120 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 662 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3815.9595]
trainer/QF1 Loss               0.020547982
trainer/QF2 Loss               0.019551419
trainer/Policy Loss            -91.66375
trainer/Q1 Predictions Mean    102.99475
trainer/Q1 Predictions Std     2.0521293
trainer/Q1 Predictions Max     105.28365
trainer/Q1 Predictions Min     76.629776
trainer/Q2 Predictions Mean    103.02471
trainer/Q2 Predictions Std     2.0883873
trainer/Q2 Predictions Max     105.3313
trainer/Q2 Predictions Min     76.181175
trainer/Q Targets Mean         103.04766
trainer/Q Targets Std          2.0642715
trainer/Q Targets Max          105.339554
trainer/Q Targets Min          76.54173
trainer/Log Pis Mean           11.4349
trainer/Log Pis Std            7.3011303
trainer/Log Pis Max            58.27803
trainer/Log Pis Min            -4.9634194
trainer/Policy mu Mean         -0.03417893
trainer/Policy mu Std          1.5333539
trainer/Policy mu Max          9.370526
trainer/Policy mu Min          -7.073524
trainer/Policy log std Mean    -0.7624232
trainer/Policy log std Std     0.30171418
trainer/Policy log std Max     0.49311435
trainer/Policy log std Min     -2.4483688
trainer/Alpha                  0.0012535566929727793
trainer/Alpha Loss             -3.7757315635681152
exploration/num steps total    3316000
exploration/num paths total    6632
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9579549858385588
exploration/Rewards Std        0.051181635879838545
exploration/Rewards Max        0.9788105015332511
exploration/Rewards Min        0.4903473733964863
exploration/Returns Mean       478.9774929192792
exploration/Returns Std        1.643760735044147
exploration/Returns Max        480.5483271687903
exploration/Returns Min        475.74765326937404
exploration/Actions Mean       0.14386953
exploration/Actions Std        0.5709049
exploration/Actions Max        0.9996912
exploration/Actions Min        -0.999983
exploration/Num Paths          10
exploration/Average Returns    478.9774929192792
evaluation/num steps total     3315000
evaluation/num paths total     6630
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9549196374339018
evaluation/Rewards Std         0.046072218114111815
evaluation/Rewards Max         0.9790799247422467
evaluation/Rewards Min         0.48795130946471277
evaluation/Returns Mean        477.459818716951
evaluation/Returns Std         0.6474861937415901
evaluation/Returns Max         479.2060788933908
evaluation/Returns Min         476.77274977331194
evaluation/ExplReturns Mean    477.459818716951
evaluation/ExplReturns Std     0.6474861937415901
evaluation/ExplReturns Max     479.2060788933908
evaluation/ExplReturns Min     476.77274977331194
evaluation/Actions Mean        0.16835369
evaluation/Actions Std         0.5045525
evaluation/Actions Max         0.99857557
evaluation/Actions Min         -0.99959487
evaluation/Num Paths           10
evaluation/Average Returns     477.459818716951
time/data storing (s)          0.0324201500043273
time/evaluation sampling (s)   110.09612906910479
time/exploration sampling (s)  111.47627661097795
time/logging (s)               0.030627110041677952
time/saving (s)                0.012803631834685802
time/training (s)              9.31496470887214
time/epoch (s)                 230.96322128083557
time/total (s)                 155411.09106652718
Epoch                          662
-----------------------------  ---------------------
2023-08-02 13:08:17.494620 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 663 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3616.2424]
trainer/QF1 Loss               0.018847153
trainer/QF2 Loss               0.026672514
trainer/Policy Loss            -90.579834
trainer/Q1 Predictions Mean    102.95512
trainer/Q1 Predictions Std     1.6682107
trainer/Q1 Predictions Max     105.39783
trainer/Q1 Predictions Min     90.37436
trainer/Q2 Predictions Mean    102.88396
trainer/Q2 Predictions Std     1.6978086
trainer/Q2 Predictions Max     105.2486
trainer/Q2 Predictions Min     89.89381
trainer/Q Targets Mean         102.98538
trainer/Q Targets Std          1.69855
trainer/Q Targets Max          105.36188
trainer/Q Targets Min          90.437836
trainer/Log Pis Mean           12.418782
trainer/Log Pis Std            8.94208
trainer/Log Pis Max            60.66612
trainer/Log Pis Min            -5.1323075
trainer/Policy mu Mean         -0.1322496
trainer/Policy mu Std          1.6021818
trainer/Policy mu Max          7.0269566
trainer/Policy mu Min          -6.7349195
trainer/Policy log std Mean    -0.74796677
trainer/Policy log std Std     0.29549202
trainer/Policy log std Max     0.3040272
trainer/Policy log std Min     -2.1771846
trainer/Alpha                  0.0012560824397951365
trainer/Alpha Loss             2.7973403930664062
exploration/num steps total    3321000
exploration/num paths total    6642
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9631666281062582
exploration/Rewards Std        0.04872923374812478
exploration/Rewards Max        0.9782745605608956
exploration/Rewards Min        0.4932695448760561
exploration/Returns Mean       481.58331405312913
exploration/Returns Std        0.8102563577891352
exploration/Returns Max        482.13261252085925
exploration/Returns Min        479.5843787999347
exploration/Actions Mean       0.14700042
exploration/Actions Std        0.6116225
exploration/Actions Max        0.99977076
exploration/Actions Min        -0.9998949
exploration/Num Paths          10
exploration/Average Returns    481.58331405312913
evaluation/num steps total     3320000
evaluation/num paths total     6640
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9653442634179675
evaluation/Rewards Std         0.04705644812097339
evaluation/Rewards Max         0.9792280899287376
evaluation/Rewards Min         0.5000432754002813
evaluation/Returns Mean        482.6721317089838
evaluation/Returns Std         0.42233571989933094
evaluation/Returns Max         483.75900080959184
evaluation/Returns Min         482.17959733981087
evaluation/ExplReturns Mean    482.6721317089838
evaluation/ExplReturns Std     0.42233571989933094
evaluation/ExplReturns Max     483.75900080959184
evaluation/ExplReturns Min     482.17959733981087
evaluation/Actions Mean        0.14371817
evaluation/Actions Std         0.58571166
evaluation/Actions Max         0.9985964
evaluation/Actions Min         -0.9993024
evaluation/Num Paths           10
evaluation/Average Returns     482.6721317089838
time/data storing (s)          0.03256261069327593
time/evaluation sampling (s)   114.13561759609729
time/exploration sampling (s)  112.36099626403302
time/logging (s)               0.031066366471350193
time/saving (s)                0.012966913171112537
time/training (s)              9.823866595514119
time/epoch (s)                 236.39707634598017
time/total (s)                 155647.49074439984
Epoch                          663
-----------------------------  ---------------------
2023-08-02 13:12:14.139109 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 664 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3586.4102]
trainer/QF1 Loss               0.02754898
trainer/QF2 Loss               0.01834407
trainer/Policy Loss            -90.432846
trainer/Q1 Predictions Mean    102.947205
trainer/Q1 Predictions Std     1.4346423
trainer/Q1 Predictions Max     105.41097
trainer/Q1 Predictions Min     89.28447
trainer/Q2 Predictions Mean    103.01218
trainer/Q2 Predictions Std     1.4061432
trainer/Q2 Predictions Max     105.45751
trainer/Q2 Predictions Min     90.274315
trainer/Q Targets Mean         103.07465
trainer/Q Targets Std          1.4315109
trainer/Q Targets Max          105.6167
trainer/Q Targets Min          89.45176
trainer/Log Pis Mean           12.616668
trainer/Log Pis Std            8.0040655
trainer/Log Pis Max            45.79396
trainer/Log Pis Min            -2.882524
trainer/Policy mu Mean         -0.08650213
trainer/Policy mu Std          1.6201067
trainer/Policy mu Max          6.447597
trainer/Policy mu Min          -5.0391726
trainer/Policy log std Mean    -0.73585004
trainer/Policy log std Std     0.28407153
trainer/Policy log std Max     0.28360212
trainer/Policy log std Min     -1.9376341
trainer/Alpha                  0.0012783516431227326
trainer/Alpha Loss             4.108659744262695
exploration/num steps total    3326000
exploration/num paths total    6652
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9573644195142038
exploration/Rewards Std        0.049366777327272654
exploration/Rewards Max        0.9795476373425331
exploration/Rewards Min        0.5011594701145702
exploration/Returns Mean       478.68220975710193
exploration/Returns Std        2.0023692897366354
exploration/Returns Max        481.77075213666876
exploration/Returns Min        474.34431108772753
exploration/Actions Mean       0.07529722
exploration/Actions Std        0.63702524
exploration/Actions Max        0.9999383
exploration/Actions Min        -0.99997526
exploration/Num Paths          10
exploration/Average Returns    478.68220975710193
evaluation/num steps total     3325000
evaluation/num paths total     6650
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9617134565309461
evaluation/Rewards Std         0.04887125810906748
evaluation/Rewards Max         0.9770543968517837
evaluation/Rewards Min         0.4892864128303873
evaluation/Returns Mean        480.85672826547324
evaluation/Returns Std         1.1551443741603564
evaluation/Returns Max         481.9384190711416
evaluation/Returns Min         477.6660826546021
evaluation/ExplReturns Mean    480.85672826547324
evaluation/ExplReturns Std     1.1551443741603564
evaluation/ExplReturns Max     481.9384190711416
evaluation/ExplReturns Min     477.6660826546021
evaluation/Actions Mean        0.09217005
evaluation/Actions Std         0.61035144
evaluation/Actions Max         0.9989687
evaluation/Actions Min         -0.9998113
evaluation/Num Paths           10
evaluation/Average Returns     480.85672826547324
time/data storing (s)          0.03239540196955204
time/evaluation sampling (s)   113.68713283725083
time/exploration sampling (s)  113.86990011204034
time/logging (s)               0.037757241167128086
time/saving (s)                0.010340026579797268
time/training (s)              9.005883499979973
time/epoch (s)                 236.64340911898762
time/total (s)                 155884.1366474973
Epoch                          664
-----------------------------  ---------------------
2023-08-02 13:16:13.211947 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 665 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3824.527]
trainer/QF1 Loss               0.019947913
trainer/QF2 Loss               0.022394853
trainer/Policy Loss            -90.783295
trainer/Q1 Predictions Mean    103.0682
trainer/Q1 Predictions Std     1.2613913
trainer/Q1 Predictions Max     105.84443
trainer/Q1 Predictions Min     89.90142
trainer/Q2 Predictions Mean    103.08667
trainer/Q2 Predictions Std     1.2438391
trainer/Q2 Predictions Max     105.83704
trainer/Q2 Predictions Min     90.26894
trainer/Q Targets Mean         103.0526
trainer/Q Targets Std          1.2749492
trainer/Q Targets Max          105.796295
trainer/Q Targets Min          89.97925
trainer/Log Pis Mean           12.378993
trainer/Log Pis Std            7.2300916
trainer/Log Pis Max            45.985317
trainer/Log Pis Min            -4.0771704
trainer/Policy mu Mean         -0.15512346
trainer/Policy mu Std          1.6124359
trainer/Policy mu Max          5.4985533
trainer/Policy mu Min          -5.0738306
trainer/Policy log std Mean    -0.7202048
trainer/Policy log std Std     0.26944262
trainer/Policy log std Max     0.2924511
trainer/Policy log std Min     -1.8192987
trainer/Alpha                  0.0014132363721728325
trainer/Alpha Loss             2.4869883060455322
exploration/num steps total    3331000
exploration/num paths total    6662
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9595140016442508
exploration/Rewards Std        0.05433712202799486
exploration/Rewards Max        0.9795079820580818
exploration/Rewards Min        0.4859295147135176
exploration/Returns Mean       479.7570008221254
exploration/Returns Std        3.3874957625308366
exploration/Returns Max        482.8155075295253
exploration/Returns Min        474.20770532365555
exploration/Actions Mean       0.09786354
exploration/Actions Std        0.6402313
exploration/Actions Max        0.99998856
exploration/Actions Min        -0.9999772
exploration/Num Paths          10
exploration/Average Returns    479.7570008221254
evaluation/num steps total     3330000
evaluation/num paths total     6660
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9514566723647909
evaluation/Rewards Std         0.0590650481081579
evaluation/Rewards Max         0.978181214008786
evaluation/Rewards Min         0.5016480484982021
evaluation/Returns Mean        475.7283361823955
evaluation/Returns Std         4.575943345871988
evaluation/Returns Max         483.146739121397
evaluation/Returns Min         468.97338173350175
evaluation/ExplReturns Mean    475.7283361823955
evaluation/ExplReturns Std     4.575943345871988
evaluation/ExplReturns Max     483.146739121397
evaluation/ExplReturns Min     468.97338173350175
evaluation/Actions Mean        0.121597275
evaluation/Actions Std         0.6046189
evaluation/Actions Max         0.999963
evaluation/Actions Min         -0.9993601
evaluation/Num Paths           10
evaluation/Average Returns     475.7283361823955
time/data storing (s)          0.03233707416802645
time/evaluation sampling (s)   114.32337809540331
time/exploration sampling (s)  115.02122506685555
time/logging (s)               0.03134958818554878
time/saving (s)                0.013015714474022388
time/training (s)              9.637312187813222
time/epoch (s)                 239.05861772689968
time/total (s)                 156123.19777162373
Epoch                          665
-----------------------------  ---------------------
2023-08-02 13:20:09.533464 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 666 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3835.2732]
trainer/QF1 Loss               0.019656172
trainer/QF2 Loss               0.01540987
trainer/Policy Loss            -92.12152
trainer/Q1 Predictions Mean    103.11922
trainer/Q1 Predictions Std     1.1170938
trainer/Q1 Predictions Max     105.872574
trainer/Q1 Predictions Min     94.139114
trainer/Q2 Predictions Mean    103.03123
trainer/Q2 Predictions Std     1.1310503
trainer/Q2 Predictions Max     105.70998
trainer/Q2 Predictions Min     93.93549
trainer/Q Targets Mean         103.04801
trainer/Q Targets Std          1.1128879
trainer/Q Targets Max          105.75029
trainer/Q Targets Min          94.15816
trainer/Log Pis Mean           11.026478
trainer/Log Pis Std            7.5518856
trainer/Log Pis Max            40.892952
trainer/Log Pis Min            -5.2331686
trainer/Policy mu Mean         -0.13214807
trainer/Policy mu Std          1.5230958
trainer/Policy mu Max          4.619974
trainer/Policy mu Min          -5.8548355
trainer/Policy log std Mean    -0.722617
trainer/Policy log std Std     0.2667077
trainer/Policy log std Max     0.4303478
trainer/Policy log std Min     -1.907167
trainer/Alpha                  0.001457548700273037
trainer/Alpha Loss             -6.357785224914551
exploration/num steps total    3336000
exploration/num paths total    6672
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8480877869434346
exploration/Rewards Std        0.115184950731577
exploration/Rewards Max        0.978905164631089
exploration/Rewards Min        0.49821182463367997
exploration/Returns Mean       424.0438934717173
exploration/Returns Std        17.007135734788477
exploration/Returns Max        455.04198866567975
exploration/Returns Min        400.126174337322
exploration/Actions Mean       0.06602727
exploration/Actions Std        0.7155999
exploration/Actions Max        0.9999932
exploration/Actions Min        -0.9999633
exploration/Num Paths          10
exploration/Average Returns    424.0438934717173
evaluation/num steps total     3335000
evaluation/num paths total     6670
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8926324264277434
evaluation/Rewards Std         0.1078554370066956
evaluation/Rewards Max         0.979276028066423
evaluation/Rewards Min         0.49737714480352796
evaluation/Returns Mean        446.3162132138717
evaluation/Returns Std         28.034210499303434
evaluation/Returns Max         479.1144382803462
evaluation/Returns Min         397.0570566740555
evaluation/ExplReturns Mean    446.3162132138717
evaluation/ExplReturns Std     28.034210499303434
evaluation/ExplReturns Max     479.1144382803462
evaluation/ExplReturns Min     397.0570566740555
evaluation/Actions Mean        0.07078549
evaluation/Actions Std         0.7310498
evaluation/Actions Max         0.9999732
evaluation/Actions Min         -0.9999897
evaluation/Num Paths           10
evaluation/Average Returns     446.3162132138717
time/data storing (s)          0.03221313841640949
time/evaluation sampling (s)   113.43170595820993
time/exploration sampling (s)  113.70498583186418
time/logging (s)               0.030345577746629715
time/saving (s)                0.01210880372673273
time/training (s)              9.101032488048077
time/epoch (s)                 236.31239179801196
time/total (s)                 156359.51304488163
Epoch                          666
-----------------------------  --------------------
2023-08-02 13:24:08.247253 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 667 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3754.0432]
trainer/QF1 Loss               0.012414951
trainer/QF2 Loss               0.015972823
trainer/Policy Loss            -91.63637
trainer/Q1 Predictions Mean    103.06174
trainer/Q1 Predictions Std     1.5863007
trainer/Q1 Predictions Max     105.5815
trainer/Q1 Predictions Min     82.30081
trainer/Q2 Predictions Mean    103.01536
trainer/Q2 Predictions Std     1.6154318
trainer/Q2 Predictions Max     105.63693
trainer/Q2 Predictions Min     81.9335
trainer/Q Targets Mean         103.01944
trainer/Q Targets Std          1.5746794
trainer/Q Targets Max          105.49356
trainer/Q Targets Min          82.489006
trainer/Log Pis Mean           11.475346
trainer/Log Pis Std            7.470707
trainer/Log Pis Max            44.320515
trainer/Log Pis Min            -4.955413
trainer/Policy mu Mean         -0.12128297
trainer/Policy mu Std          1.5378389
trainer/Policy mu Max          5.131627
trainer/Policy mu Min          -4.487768
trainer/Policy log std Mean    -0.737405
trainer/Policy log std Std     0.28459457
trainer/Policy log std Max     0.116341054
trainer/Policy log std Min     -1.99861
trainer/Alpha                  0.0014527443563565612
trainer/Alpha Loss             -3.4282169342041016
exploration/num steps total    3341000
exploration/num paths total    6682
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.953191778946505
exploration/Rewards Std        0.047724182434167116
exploration/Rewards Max        0.9789972071871106
exploration/Rewards Min        0.48748957113582664
exploration/Returns Mean       476.59588947325244
exploration/Returns Std        1.6899378858163987
exploration/Returns Max        480.28363954751836
exploration/Returns Min        474.8550233425576
exploration/Actions Mean       0.19184405
exploration/Actions Std        0.6376757
exploration/Actions Max        0.99995744
exploration/Actions Min        -0.99990374
exploration/Num Paths          10
exploration/Average Returns    476.59588947325244
evaluation/num steps total     3340000
evaluation/num paths total     6680
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9509790172848348
evaluation/Rewards Std         0.048538674857266345
evaluation/Rewards Max         0.9783343464858995
evaluation/Rewards Min         0.4993174786896874
evaluation/Returns Mean        475.48950864241743
evaluation/Returns Std         2.021917285162746
evaluation/Returns Max         478.3775218157205
evaluation/Returns Min         471.3474110980222
evaluation/ExplReturns Mean    475.48950864241743
evaluation/ExplReturns Std     2.021917285162746
evaluation/ExplReturns Max     478.3775218157205
evaluation/ExplReturns Min     471.3474110980222
evaluation/Actions Mean        0.22299722
evaluation/Actions Std         0.5987388
evaluation/Actions Max         0.99961287
evaluation/Actions Min         -0.9994146
evaluation/Num Paths           10
evaluation/Average Returns     475.48950864241743
time/data storing (s)          0.03221229184418917
time/evaluation sampling (s)   114.03360939770937
time/exploration sampling (s)  115.43603374995291
time/logging (s)               0.030468067154288292
time/saving (s)                0.012740690261125565
time/training (s)              9.160971571691334
time/epoch (s)                 238.70603576861322
time/total (s)                 156598.22169975378
Epoch                          667
-----------------------------  ---------------------
2023-08-02 13:28:07.666926 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 668 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3851.5396]
trainer/QF1 Loss               0.019445807
trainer/QF2 Loss               0.023857214
trainer/Policy Loss            -91.01778
trainer/Q1 Predictions Mean    102.98969
trainer/Q1 Predictions Std     1.5456033
trainer/Q1 Predictions Max     105.30106
trainer/Q1 Predictions Min     89.90179
trainer/Q2 Predictions Mean    103.04313
trainer/Q2 Predictions Std     1.522915
trainer/Q2 Predictions Max     105.29712
trainer/Q2 Predictions Min     90.852455
trainer/Q Targets Mean         102.99743
trainer/Q Targets Std          1.5466148
trainer/Q Targets Max          105.309525
trainer/Q Targets Min          90.08373
trainer/Log Pis Mean           12.069294
trainer/Log Pis Std            7.922557
trainer/Log Pis Max            41.99465
trainer/Log Pis Min            -7.3012986
trainer/Policy mu Mean         -0.16260163
trainer/Policy mu Std          1.583171
trainer/Policy mu Max          5.7001457
trainer/Policy mu Min          -5.7338796
trainer/Policy log std Mean    -0.73499435
trainer/Policy log std Std     0.27778712
trainer/Policy log std Max     0.08030701
trainer/Policy log std Min     -2.175467
trainer/Alpha                  0.0015091082314029336
trainer/Alpha Loss             0.4501546621322632
exploration/num steps total    3346000
exploration/num paths total    6692
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9568633355646258
exploration/Rewards Std        0.04654861419501315
exploration/Rewards Max        0.9796166202624299
exploration/Rewards Min        0.4937588520316156
exploration/Returns Mean       478.4316677823129
exploration/Returns Std        0.9486207440531406
exploration/Returns Max        480.43629201416593
exploration/Returns Min        477.06567605798665
exploration/Actions Mean       0.060134806
exploration/Actions Std        0.639523
exploration/Actions Max        0.9998475
exploration/Actions Min        -0.999998
exploration/Num Paths          10
exploration/Average Returns    478.4316677823129
evaluation/num steps total     3345000
evaluation/num paths total     6690
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9591623192319682
evaluation/Rewards Std         0.04654235257456052
evaluation/Rewards Max         0.9797731907316969
evaluation/Rewards Min         0.4853628675785796
evaluation/Returns Mean        479.58115961598406
evaluation/Returns Std         1.5601387181739659
evaluation/Returns Max         481.6533986929824
evaluation/Returns Min         476.4438009088716
evaluation/ExplReturns Mean    479.58115961598406
evaluation/ExplReturns Std     1.5601387181739659
evaluation/ExplReturns Max     481.6533986929824
evaluation/ExplReturns Min     476.4438009088716
evaluation/Actions Mean        -0.0013488459
evaluation/Actions Std         0.6104077
evaluation/Actions Max         0.99965256
evaluation/Actions Min         -0.9999666
evaluation/Num Paths           10
evaluation/Average Returns     479.58115961598406
time/data storing (s)          0.03235890530049801
time/evaluation sampling (s)   114.7976326867938
time/exploration sampling (s)  114.48706176877022
time/logging (s)               0.030486391857266426
time/saving (s)                0.010648021474480629
time/training (s)              10.053773205727339
time/epoch (s)                 239.4119609799236
time/total (s)                 156837.6361311935
Epoch                          668
-----------------------------  ---------------------
2023-08-02 13:32:27.315212 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 669 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3775.556]
trainer/QF1 Loss               0.024885256
trainer/QF2 Loss               0.032431353
trainer/Policy Loss            -90.35688
trainer/Q1 Predictions Mean    102.85263
trainer/Q1 Predictions Std     2.138368
trainer/Q1 Predictions Max     104.8975
trainer/Q1 Predictions Min     82.99196
trainer/Q2 Predictions Mean    102.8226
trainer/Q2 Predictions Std     2.1663964
trainer/Q2 Predictions Max     104.79558
trainer/Q2 Predictions Min     82.861855
trainer/Q Targets Mean         102.92389
trainer/Q Targets Std          2.1462185
trainer/Q Targets Max          105.13497
trainer/Q Targets Min          82.84218
trainer/Log Pis Mean           12.579535
trainer/Log Pis Std            8.015731
trainer/Log Pis Max            60.879784
trainer/Log Pis Min            -3.6495461
trainer/Policy mu Mean         -0.21823578
trainer/Policy mu Std          1.6069005
trainer/Policy mu Max          7.4588704
trainer/Policy mu Min          -8.573163
trainer/Policy log std Mean    -0.7264045
trainer/Policy log std Std     0.26136371
trainer/Policy log std Max     0.33719945
trainer/Policy log std Min     -2.2820058
trainer/Alpha                  0.0015517028514295816
trainer/Alpha Loss             3.7485835552215576
exploration/num steps total    3351000
exploration/num paths total    6702
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9266758069114505
exploration/Rewards Std        0.08921728932312657
exploration/Rewards Max        0.9795160093929633
exploration/Rewards Min        0.49145602295164015
exploration/Returns Mean       463.33790345572527
exploration/Returns Std        23.686188074149552
exploration/Returns Max        480.115647511267
exploration/Returns Min        415.38622527548443
exploration/Actions Mean       0.04851209
exploration/Actions Std        0.6424351
exploration/Actions Max        0.99999744
exploration/Actions Min        -0.99999565
exploration/Num Paths          10
exploration/Average Returns    463.33790345572527
evaluation/num steps total     3350000
evaluation/num paths total     6700
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8856605511344462
evaluation/Rewards Std         0.11335744253372326
evaluation/Rewards Max         0.979635764365664
evaluation/Rewards Min         0.49395467253976827
evaluation/Returns Mean        442.830275567223
evaluation/Returns Std         25.856700219089888
evaluation/Returns Max         481.99188068138324
evaluation/Returns Min         407.77353188648226
evaluation/ExplReturns Mean    442.830275567223
evaluation/ExplReturns Std     25.856700219089888
evaluation/ExplReturns Max     481.99188068138324
evaluation/ExplReturns Min     407.77353188648226
evaluation/Actions Mean        0.068873934
evaluation/Actions Std         0.63652766
evaluation/Actions Max         0.9999928
evaluation/Actions Min         -0.9999999
evaluation/Num Paths           10
evaluation/Average Returns     442.830275567223
time/data storing (s)          0.032551093958318233
time/evaluation sampling (s)   117.15718194562942
time/exploration sampling (s)  122.71659078542143
time/logging (s)               0.031232242472469807
time/saving (s)                0.020379744470119476
time/training (s)              19.683111774735153
time/epoch (s)                 259.6410475866869
time/total (s)                 157097.27988057304
Epoch                          669
-----------------------------  ---------------------
2023-08-02 13:36:42.478747 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 670 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4107.1562]
trainer/QF1 Loss               0.02096182
trainer/QF2 Loss               0.033509664
trainer/Policy Loss            -90.56271
trainer/Q1 Predictions Mean    102.97748
trainer/Q1 Predictions Std     2.1327255
trainer/Q1 Predictions Max     105.41194
trainer/Q1 Predictions Min     81.49153
trainer/Q2 Predictions Mean    102.89038
trainer/Q2 Predictions Std     2.1423202
trainer/Q2 Predictions Max     105.256065
trainer/Q2 Predictions Min     81.5225
trainer/Q Targets Mean         102.95562
trainer/Q Targets Std          2.1251063
trainer/Q Targets Max          105.425804
trainer/Q Targets Min          81.58528
trainer/Log Pis Mean           12.450393
trainer/Log Pis Std            8.12182
trainer/Log Pis Max            62.975925
trainer/Log Pis Min            -5.415696
trainer/Policy mu Mean         -0.12989299
trainer/Policy mu Std          1.6174341
trainer/Policy mu Max          11.631155
trainer/Policy mu Min          -7.504327
trainer/Policy log std Mean    -0.7473001
trainer/Policy log std Std     0.2754407
trainer/Policy log std Max     0.7243269
trainer/Policy log std Min     -1.8596491
trainer/Alpha                  0.0015054584946483374
trainer/Alpha Loss             2.92698073387146
exploration/num steps total    3356000
exploration/num paths total    6712
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9567494253217812
exploration/Rewards Std        0.05242187450756795
exploration/Rewards Max        0.9793685077231378
exploration/Rewards Min        0.49175861617788197
exploration/Returns Mean       478.3747126608906
exploration/Returns Std        1.8226695661268344
exploration/Returns Max        481.98491065354943
exploration/Returns Min        476.1416491146552
exploration/Actions Mean       0.023972062
exploration/Actions Std        0.6371461
exploration/Actions Max        0.999989
exploration/Actions Min        -0.9999759
exploration/Num Paths          10
exploration/Average Returns    478.3747126608906
evaluation/num steps total     3355000
evaluation/num paths total     6710
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9523050991986657
evaluation/Rewards Std         0.058590121117392015
evaluation/Rewards Max         0.9784897658543559
evaluation/Rewards Min         0.4913886325458508
evaluation/Returns Mean        476.15254959933293
evaluation/Returns Std         4.42664303640176
evaluation/Returns Max         482.00377743709566
evaluation/Returns Min         467.91689955940654
evaluation/ExplReturns Mean    476.15254959933293
evaluation/ExplReturns Std     4.42664303640176
evaluation/ExplReturns Max     482.00377743709566
evaluation/ExplReturns Min     467.91689955940654
evaluation/Actions Mean        0.0168394
evaluation/Actions Std         0.6066098
evaluation/Actions Max         0.99974036
evaluation/Actions Min         -0.99985665
evaluation/Num Paths           10
evaluation/Average Returns     476.15254959933293
time/data storing (s)          0.03228384256362915
time/evaluation sampling (s)   121.15899018291384
time/exploration sampling (s)  119.93700062390417
time/logging (s)               0.03119247779250145
time/saving (s)                0.012922498397529125
time/training (s)              13.983166157267988
time/epoch (s)                 255.15555578283966
time/total (s)                 157352.43805443216
Epoch                          670
-----------------------------  ---------------------
2023-08-02 13:41:11.662199 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 671 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3685.7434]
trainer/QF1 Loss               0.014411211
trainer/QF2 Loss               0.011588121
trainer/Policy Loss            -90.89067
trainer/Q1 Predictions Mean    103.14922
trainer/Q1 Predictions Std     2.1446438
trainer/Q1 Predictions Max     105.146126
trainer/Q1 Predictions Min     71.97878
trainer/Q2 Predictions Mean    103.138214
trainer/Q2 Predictions Std     2.133198
trainer/Q2 Predictions Max     105.20816
trainer/Q2 Predictions Min     72.23585
trainer/Q Targets Mean         103.12598
trainer/Q Targets Std          2.1597817
trainer/Q Targets Max          104.9917
trainer/Q Targets Min          71.85097
trainer/Log Pis Mean           12.346624
trainer/Log Pis Std            7.539372
trainer/Log Pis Max            49.482986
trainer/Log Pis Min            -3.348103
trainer/Policy mu Mean         -0.16990435
trainer/Policy mu Std          1.5747364
trainer/Policy mu Max          4.8678837
trainer/Policy mu Min          -4.917878
trainer/Policy log std Mean    -0.7362148
trainer/Policy log std Std     0.27310404
trainer/Policy log std Max     0.93654096
trainer/Policy log std Min     -2.364221
trainer/Alpha                  0.0015396588714793324
trainer/Alpha Loss             2.244791269302368
exploration/num steps total    3361000
exploration/num paths total    6722
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9470845841137637
exploration/Rewards Std        0.07051125641359192
exploration/Rewards Max        0.9794748164932554
exploration/Rewards Min        0.5024194732355427
exploration/Returns Mean       473.542292056882
exploration/Returns Std        4.878551214349008
exploration/Returns Max        480.8761919086828
exploration/Returns Min        467.30213883919305
exploration/Actions Mean       0.05505758
exploration/Actions Std        0.6206543
exploration/Actions Max        0.9999841
exploration/Actions Min        -0.9999812
exploration/Num Paths          10
exploration/Average Returns    473.542292056882
evaluation/num steps total     3360000
evaluation/num paths total     6720
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9421085228883042
evaluation/Rewards Std         0.06988883956987235
evaluation/Rewards Max         0.9763836063848621
evaluation/Rewards Min         0.5005310829726729
evaluation/Returns Mean        471.05426144415213
evaluation/Returns Std         5.002754345198337
evaluation/Returns Max         476.76715440015073
evaluation/Returns Min         461.8420685720704
evaluation/ExplReturns Mean    471.05426144415213
evaluation/ExplReturns Std     5.002754345198337
evaluation/ExplReturns Max     476.76715440015073
evaluation/ExplReturns Min     461.8420685720704
evaluation/Actions Mean        -0.0019068879
evaluation/Actions Std         0.5646807
evaluation/Actions Max         0.99977076
evaluation/Actions Min         -0.99996144
evaluation/Num Paths           10
evaluation/Average Returns     471.05426144415213
time/data storing (s)          0.03225534036755562
time/evaluation sampling (s)   120.07920377701521
time/exploration sampling (s)  127.09729111287743
time/logging (s)               0.03116279188543558
time/saving (s)                0.02514760009944439
time/training (s)              21.910528707318008
time/epoch (s)                 269.1755893295631
time/total (s)                 157621.61615690775
Epoch                          671
-----------------------------  ---------------------
2023-08-02 13:45:48.540852 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 672 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3833.6199]
trainer/QF1 Loss               0.021461837
trainer/QF2 Loss               0.016146077
trainer/Policy Loss            -91.08913
trainer/Q1 Predictions Mean    103.10501
trainer/Q1 Predictions Std     2.176923
trainer/Q1 Predictions Max     105.49762
trainer/Q1 Predictions Min     78.31834
trainer/Q2 Predictions Mean    102.978516
trainer/Q2 Predictions Std     2.1374154
trainer/Q2 Predictions Max     105.16181
trainer/Q2 Predictions Min     78.92891
trainer/Q Targets Mean         103.027405
trainer/Q Targets Std          2.1660883
trainer/Q Targets Max          105.2653
trainer/Q Targets Min          78.276436
trainer/Log Pis Mean           12.023876
trainer/Log Pis Std            8.186336
trainer/Log Pis Max            53.245354
trainer/Log Pis Min            -5.9800935
trainer/Policy mu Mean         -0.15307105
trainer/Policy mu Std          1.598181
trainer/Policy mu Max          7.3176336
trainer/Policy mu Min          -11.287197
trainer/Policy log std Mean    -0.7361323
trainer/Policy log std Std     0.26454422
trainer/Policy log std Max     0.5830953
trainer/Policy log std Min     -1.8153682
trainer/Alpha                  0.0014691731194034219
trainer/Alpha Loss             0.15574705600738525
exploration/num steps total    3366000
exploration/num paths total    6732
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9603469185417071
exploration/Rewards Std        0.05101620644550154
exploration/Rewards Max        0.9798026584245543
exploration/Rewards Min        0.4932263088273743
exploration/Returns Mean       480.1734592708537
exploration/Returns Std        2.8645612401610125
exploration/Returns Max        482.6515740657244
exploration/Returns Min        471.9600825785355
exploration/Actions Mean       0.06292155
exploration/Actions Std        0.6152623
exploration/Actions Max        0.99998933
exploration/Actions Min        -0.99997014
exploration/Num Paths          10
exploration/Average Returns    480.1734592708537
evaluation/num steps total     3365000
evaluation/num paths total     6730
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9358155085910482
evaluation/Rewards Std         0.09374863016474219
evaluation/Rewards Max         0.9798134192697927
evaluation/Rewards Min         0.49447421144540415
evaluation/Returns Mean        467.9077542955242
evaluation/Returns Std         39.163515249152525
evaluation/Returns Max         485.0776913899691
evaluation/Returns Min         350.6709722418963
evaluation/ExplReturns Mean    467.9077542955242
evaluation/ExplReturns Std     39.163515249152525
evaluation/ExplReturns Max     485.0776913899691
evaluation/ExplReturns Min     350.6709722418963
evaluation/Actions Mean        0.10761873
evaluation/Actions Std         0.6124941
evaluation/Actions Max         1.0
evaluation/Actions Min         -0.9999996
evaluation/Num Paths           10
evaluation/Average Returns     467.9077542955242
time/data storing (s)          0.032252549193799496
time/evaluation sampling (s)   133.15972302295268
time/exploration sampling (s)  129.68094310723245
time/logging (s)               0.03073485754430294
time/saving (s)                0.010413629934191704
time/training (s)              13.956248938106
time/epoch (s)                 276.8703161049634
time/total (s)                 157898.4889992969
Epoch                          672
-----------------------------  ---------------------
2023-08-02 13:50:41.201295 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 673 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4215.706]
trainer/QF1 Loss               0.018655198
trainer/QF2 Loss               0.014831697
trainer/Policy Loss            -91.0348
trainer/Q1 Predictions Mean    103.19475
trainer/Q1 Predictions Std     1.6321825
trainer/Q1 Predictions Max     104.8472
trainer/Q1 Predictions Min     82.26964
trainer/Q2 Predictions Mean    103.199905
trainer/Q2 Predictions Std     1.6594819
trainer/Q2 Predictions Max     104.82188
trainer/Q2 Predictions Min     81.859474
trainer/Q Targets Mean         103.15196
trainer/Q Targets Std          1.6954453
trainer/Q Targets Max          104.76364
trainer/Q Targets Min          81.147026
trainer/Log Pis Mean           12.265592
trainer/Log Pis Std            7.975418
trainer/Log Pis Max            66.784584
trainer/Log Pis Min            -5.472931
trainer/Policy mu Mean         -0.113269605
trainer/Policy mu Std          1.5870601
trainer/Policy mu Max          8.586836
trainer/Policy mu Min          -5.93348
trainer/Policy log std Mean    -0.76517963
trainer/Policy log std Std     0.28000268
trainer/Policy log std Max     0.95425
trainer/Policy log std Min     -1.9213411
trainer/Alpha                  0.001470229821279645
trainer/Alpha Loss             1.7323434352874756
exploration/num steps total    3371000
exploration/num paths total    6742
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639985162980036
exploration/Rewards Std        0.04697802257392168
exploration/Rewards Max        0.9799430729383737
exploration/Rewards Min        0.49477277891304494
exploration/Returns Mean       481.999258149002
exploration/Returns Std        0.5232345221304784
exploration/Returns Max        482.9073700689188
exploration/Returns Min        481.1623714497959
exploration/Actions Mean       -0.010629609
exploration/Actions Std        0.5528163
exploration/Actions Max        0.9999897
exploration/Actions Min        -0.999958
exploration/Num Paths          10
exploration/Average Returns    481.999258149002
evaluation/num steps total     3370000
evaluation/num paths total     6740
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.961744600959455
evaluation/Rewards Std         0.04588982592947518
evaluation/Rewards Max         0.979141644476205
evaluation/Rewards Min         0.49856094534091455
evaluation/Returns Mean        480.8723004797275
evaluation/Returns Std         0.3353438016467902
evaluation/Returns Max         481.2734751552196
evaluation/Returns Min         480.0354743115743
evaluation/ExplReturns Mean    480.8723004797275
evaluation/ExplReturns Std     0.3353438016467902
evaluation/ExplReturns Max     481.2734751552196
evaluation/ExplReturns Min     480.0354743115743
evaluation/Actions Mean        -0.029377345
evaluation/Actions Std         0.45379648
evaluation/Actions Max         0.9997941
evaluation/Actions Min         -0.9996739
evaluation/Num Paths           10
evaluation/Average Returns     480.8723004797275
time/data storing (s)          0.03262921329587698
time/evaluation sampling (s)   132.65728374011815
time/exploration sampling (s)  134.95232094917446
time/logging (s)               0.03146034199744463
time/saving (s)                0.020620372146368027
time/training (s)              24.95884772296995
time/epoch (s)                 292.65316233970225
time/total (s)                 158191.14480479434
Epoch                          673
-----------------------------  --------------------
2023-08-02 13:55:47.988695 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 674 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4371.4814]
trainer/QF1 Loss               0.009515768
trainer/QF2 Loss               0.023483
trainer/Policy Loss            -91.346016
trainer/Q1 Predictions Mean    103.18182
trainer/Q1 Predictions Std     0.82299143
trainer/Q1 Predictions Max     104.55928
trainer/Q1 Predictions Min     98.73661
trainer/Q2 Predictions Mean    103.30539
trainer/Q2 Predictions Std     0.8161093
trainer/Q2 Predictions Max     104.62526
trainer/Q2 Predictions Min     98.76446
trainer/Q Targets Mean         103.199646
trainer/Q Targets Std          0.8367674
trainer/Q Targets Max          104.6406
trainer/Q Targets Min          98.62954
trainer/Log Pis Mean           11.934187
trainer/Log Pis Std            7.0688744
trainer/Log Pis Max            45.860634
trainer/Log Pis Min            -3.6641355
trainer/Policy mu Mean         -0.198583
trainer/Policy mu Std          1.5405046
trainer/Policy mu Max          4.594405
trainer/Policy mu Min          -5.0884314
trainer/Policy log std Mean    -0.74118215
trainer/Policy log std Std     0.27175176
trainer/Policy log std Max     -0.03785999
trainer/Policy log std Min     -2.2256153
trainer/Alpha                  0.0013765684561803937
trainer/Alpha Loss             -0.4335770010948181
exploration/num steps total    3376000
exploration/num paths total    6752
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9452826331159319
exploration/Rewards Std        0.04659207211647792
exploration/Rewards Max        0.9781108305541297
exploration/Rewards Min        0.4969068534601542
exploration/Returns Mean       472.6413165579661
exploration/Returns Std        1.666686810263988
exploration/Returns Max        476.99407531007984
exploration/Returns Min        471.32840807261607
exploration/Actions Mean       0.046609893
exploration/Actions Std        0.5951984
exploration/Actions Max        0.99993867
exploration/Actions Min        -0.9999539
exploration/Num Paths          10
exploration/Average Returns    472.6413165579661
evaluation/num steps total     3375000
evaluation/num paths total     6750
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.945534674058676
evaluation/Rewards Std         0.04616335434773122
evaluation/Rewards Max         0.9645958134851714
evaluation/Rewards Min         0.4940705212592163
evaluation/Returns Mean        472.7673370293379
evaluation/Returns Std         0.6688272929600282
evaluation/Returns Max         474.29489592587936
evaluation/Returns Min         471.8077272827194
evaluation/ExplReturns Mean    472.7673370293379
evaluation/ExplReturns Std     0.6688272929600282
evaluation/ExplReturns Max     474.29489592587936
evaluation/ExplReturns Min     471.8077272827194
evaluation/Actions Mean        0.06944674
evaluation/Actions Std         0.5162532
evaluation/Actions Max         0.99865496
evaluation/Actions Min         -0.999526
evaluation/Num Paths           10
evaluation/Average Returns     472.7673370293379
time/data storing (s)          0.035456943325698376
time/evaluation sampling (s)   134.57815729267895
time/exploration sampling (s)  138.71685412805527
time/logging (s)               0.03220207244157791
time/saving (s)                0.010767531581223011
time/training (s)              33.40674927830696
time/epoch (s)                 306.7801872463897
time/total (s)                 158497.92756064795
Epoch                          674
-----------------------------  ---------------------
2023-08-02 14:00:52.248459 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 675 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4187.494]
trainer/QF1 Loss               0.015261424
trainer/QF2 Loss               0.02488431
trainer/Policy Loss            -89.60538
trainer/Q1 Predictions Mean    103.04731
trainer/Q1 Predictions Std     1.523985
trainer/Q1 Predictions Max     105.01544
trainer/Q1 Predictions Min     91.446335
trainer/Q2 Predictions Mean    102.95553
trainer/Q2 Predictions Std     1.5220057
trainer/Q2 Predictions Max     104.74116
trainer/Q2 Predictions Min     91.19673
trainer/Q Targets Mean         103.04674
trainer/Q Targets Std          1.5132812
trainer/Q Targets Max          105.19787
trainer/Q Targets Min          91.40951
trainer/Log Pis Mean           13.460062
trainer/Log Pis Std            8.279991
trainer/Log Pis Max            48.871117
trainer/Log Pis Min            -3.4807053
trainer/Policy mu Mean         -0.07553957
trainer/Policy mu Std          1.6314731
trainer/Policy mu Max          5.261179
trainer/Policy mu Min          -5.809575
trainer/Policy log std Mean    -0.74812967
trainer/Policy log std Std     0.30120292
trainer/Policy log std Max     0.13591003
trainer/Policy log std Min     -2.2170115
trainer/Alpha                  0.0013328234199434519
trainer/Alpha Loss             9.666852951049805
exploration/num steps total    3381000
exploration/num paths total    6762
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9484386018999846
exploration/Rewards Std        0.047722830558305424
exploration/Rewards Max        0.9777770393158285
exploration/Rewards Min        0.48920595074840884
exploration/Returns Mean       474.21930094999243
exploration/Returns Std        1.9034448880605819
exploration/Returns Max        479.7848667765569
exploration/Returns Min        472.7263367666359
exploration/Actions Mean       0.013153741
exploration/Actions Std        0.5745563
exploration/Actions Max        0.99987227
exploration/Actions Min        -0.9999679
exploration/Num Paths          10
exploration/Average Returns    474.21930094999243
evaluation/num steps total     3380000
evaluation/num paths total     6760
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9454959276649626
evaluation/Rewards Std         0.05180769054756002
evaluation/Rewards Max         0.9777284096137289
evaluation/Rewards Min         0.46906036442734406
evaluation/Returns Mean        472.7479638324812
evaluation/Returns Std         1.7747332062336587
evaluation/Returns Max         473.585987654772
evaluation/Returns Min         467.4675895931447
evaluation/ExplReturns Mean    472.7479638324812
evaluation/ExplReturns Std     1.7747332062336587
evaluation/ExplReturns Max     473.585987654772
evaluation/ExplReturns Min     467.4675895931447
evaluation/Actions Mean        0.015595853
evaluation/Actions Std         0.5173278
evaluation/Actions Max         0.99936
evaluation/Actions Min         -0.99994004
evaluation/Num Paths           10
evaluation/Average Returns     472.7479638324812
time/data storing (s)          0.03794931806623936
time/evaluation sampling (s)   139.59415422286838
time/exploration sampling (s)  142.47349566593766
time/logging (s)               0.03848650399595499
time/saving (s)                0.023141944780945778
time/training (s)              22.090527416206896
time/epoch (s)                 304.2577550718561
time/total (s)                 158802.18810572196
Epoch                          675
-----------------------------  ---------------------
2023-08-02 14:06:18.066934 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 676 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4158.4297]
trainer/QF1 Loss               0.026968278
trainer/QF2 Loss               0.022108838
trainer/Policy Loss            -91.37468
trainer/Q1 Predictions Mean    103.15961
trainer/Q1 Predictions Std     0.90100956
trainer/Q1 Predictions Max     105.06497
trainer/Q1 Predictions Min     97.0278
trainer/Q2 Predictions Mean    103.12335
trainer/Q2 Predictions Std     0.90912205
trainer/Q2 Predictions Max     104.86852
trainer/Q2 Predictions Min     96.94897
trainer/Q Targets Mean         103.212524
trainer/Q Targets Std          0.9432062
trainer/Q Targets Max          105.080956
trainer/Q Targets Min          96.84084
trainer/Log Pis Mean           11.840147
trainer/Log Pis Std            7.0975513
trainer/Log Pis Max            37.125957
trainer/Log Pis Min            -7.857071
trainer/Policy mu Mean         0.06361755
trainer/Policy mu Std          1.5797241
trainer/Policy mu Max          6.2511163
trainer/Policy mu Min          -4.470641
trainer/Policy log std Mean    -0.7368465
trainer/Policy log std Std     0.29226673
trainer/Policy log std Max     0.17686999
trainer/Policy log std Min     -1.9667586
trainer/Alpha                  0.001404849928803742
trainer/Alpha Loss             -1.0498948097229004
exploration/num steps total    3386000
exploration/num paths total    6772
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9531255698064398
exploration/Rewards Std        0.05016454643102345
exploration/Rewards Max        0.9792265553363058
exploration/Rewards Min        0.49145267956617417
exploration/Returns Mean       476.56278490321995
exploration/Returns Std        0.9664839502776283
exploration/Returns Max        478.1756388423253
exploration/Returns Min        475.1316631470321
exploration/Actions Mean       0.048164777
exploration/Actions Std        0.59541297
exploration/Actions Max        0.9999633
exploration/Actions Min        -0.99989957
exploration/Num Paths          10
exploration/Average Returns    476.56278490321995
evaluation/num steps total     3385000
evaluation/num paths total     6770
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9563152514533649
evaluation/Rewards Std         0.047455321844407865
evaluation/Rewards Max         0.9761490090785826
evaluation/Rewards Min         0.48213918428787345
evaluation/Returns Mean        478.15762572668245
evaluation/Returns Std         0.6876613905327593
evaluation/Returns Max         479.7998704626671
evaluation/Returns Min         477.009037272802
evaluation/ExplReturns Mean    478.15762572668245
evaluation/ExplReturns Std     0.6876613905327593
evaluation/ExplReturns Max     479.7998704626671
evaluation/ExplReturns Min     477.009037272802
evaluation/Actions Mean        0.06963606
evaluation/Actions Std         0.49198297
evaluation/Actions Max         0.9978944
evaluation/Actions Min         -0.99937546
evaluation/Num Paths           10
evaluation/Average Returns     478.15762572668245
time/data storing (s)          0.04071652051061392
time/evaluation sampling (s)   150.44273716490716
time/exploration sampling (s)  144.64060845877975
time/logging (s)               0.0547556234523654
time/saving (s)                0.01683184504508972
time/training (s)              30.63057314325124
time/epoch (s)                 325.8262227559462
time/total (s)                 159128.0188291287
Epoch                          676
-----------------------------  --------------------
2023-08-02 14:11:12.418950 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 677 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4482.335]
trainer/QF1 Loss               0.025992863
trainer/QF2 Loss               0.041178726
trainer/Policy Loss            -92.06355
trainer/Q1 Predictions Mean    103.02888
trainer/Q1 Predictions Std     2.1898384
trainer/Q1 Predictions Max     104.75956
trainer/Q1 Predictions Min     74.43979
trainer/Q2 Predictions Mean    103.091934
trainer/Q2 Predictions Std     2.1404364
trainer/Q2 Predictions Max     104.87605
trainer/Q2 Predictions Min     75.26389
trainer/Q Targets Mean         102.92534
trainer/Q Targets Std          2.1364326
trainer/Q Targets Max          104.719696
trainer/Q Targets Min          74.82908
trainer/Log Pis Mean           11.061529
trainer/Log Pis Std            8.204848
trainer/Log Pis Max            48.67719
trainer/Log Pis Min            -5.2235804
trainer/Policy mu Mean         0.028844321
trainer/Policy mu Std          1.5556551
trainer/Policy mu Max          5.3365397
trainer/Policy mu Min          -6.7192965
trainer/Policy log std Mean    -0.74149036
trainer/Policy log std Std     0.28076327
trainer/Policy log std Max     0.21279025
trainer/Policy log std Min     -2.1530662
trainer/Alpha                  0.0013539277715608478
trainer/Alpha Loss             -6.198306083679199
exploration/num steps total    3391000
exploration/num paths total    6782
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9481295036031795
exploration/Rewards Std        0.07757375298575228
exploration/Rewards Max        0.979194335119392
exploration/Rewards Min        0.4953694134754032
exploration/Returns Mean       474.0647518015897
exploration/Returns Std        12.999856165168552
exploration/Returns Max        481.58304480643477
exploration/Returns Min        445.2961545883173
exploration/Actions Mean       0.005936141
exploration/Actions Std        0.60631824
exploration/Actions Max        0.9999997
exploration/Actions Min        -0.99999684
exploration/Num Paths          10
exploration/Average Returns    474.0647518015897
evaluation/num steps total     3390000
evaluation/num paths total     6780
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9621824941651217
evaluation/Rewards Std         0.04737608604935113
evaluation/Rewards Max         0.9794657974061721
evaluation/Rewards Min         0.4936813138338716
evaluation/Returns Mean        481.0912470825609
evaluation/Returns Std         0.6954799872726495
evaluation/Returns Max         482.2575734969732
evaluation/Returns Min         479.99295854918415
evaluation/ExplReturns Mean    481.0912470825609
evaluation/ExplReturns Std     0.6954799872726495
evaluation/ExplReturns Max     482.2575734969732
evaluation/ExplReturns Min     479.99295854918415
evaluation/Actions Mean        -0.003424243
evaluation/Actions Std         0.5353173
evaluation/Actions Max         0.9976392
evaluation/Actions Min         -0.99992746
evaluation/Num Paths           10
evaluation/Average Returns     481.0912470825609
time/data storing (s)          0.03363214433193207
time/evaluation sampling (s)   144.74460800550878
time/exploration sampling (s)  135.5526984948665
time/logging (s)               0.038984269835054874
time/saving (s)                0.011403350159525871
time/training (s)              13.93899318575859
time/epoch (s)                 294.3203194504604
time/total (s)                 159422.3468614947
Epoch                          677
-----------------------------  ---------------------
2023-08-02 14:16:06.906968 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 678 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4315.5957]
trainer/QF1 Loss               0.016642079
trainer/QF2 Loss               0.018054308
trainer/Policy Loss            -90.48924
trainer/Q1 Predictions Mean    103.13991
trainer/Q1 Predictions Std     1.0055466
trainer/Q1 Predictions Max     105.30571
trainer/Q1 Predictions Min     93.699745
trainer/Q2 Predictions Mean    103.19691
trainer/Q2 Predictions Std     1.0491394
trainer/Q2 Predictions Max     105.61022
trainer/Q2 Predictions Min     93.19362
trainer/Q Targets Mean         103.1703
trainer/Q Targets Std          1.0103803
trainer/Q Targets Max          105.46445
trainer/Q Targets Min          94.36838
trainer/Log Pis Mean           12.733552
trainer/Log Pis Std            6.88807
trainer/Log Pis Max            57.9626
trainer/Log Pis Min            -3.9734902
trainer/Policy mu Mean         0.06826981
trainer/Policy mu Std          1.6028621
trainer/Policy mu Max          6.0105076
trainer/Policy mu Min          -6.0822773
trainer/Policy log std Mean    -0.7507231
trainer/Policy log std Std     0.29100624
trainer/Policy log std Max     0.28924537
trainer/Policy log std Min     -2.1834311
trainer/Alpha                  0.0013780758017674088
trainer/Alpha Loss             4.832064151763916
exploration/num steps total    3396000
exploration/num paths total    6792
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9624311196340651
exploration/Rewards Std        0.04824425403629708
exploration/Rewards Max        0.9796819066031848
exploration/Rewards Min        0.4983737441402267
exploration/Returns Mean       481.2155598170324
exploration/Returns Std        1.0846839900858793
exploration/Returns Max        482.6599232249174
exploration/Returns Min        478.45294435519213
exploration/Actions Mean       0.03523563
exploration/Actions Std        0.63380563
exploration/Actions Max        0.99991286
exploration/Actions Min        -0.9999922
exploration/Num Paths          10
exploration/Average Returns    481.2155598170324
evaluation/num steps total     3395000
evaluation/num paths total     6790
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9622573803672915
evaluation/Rewards Std         0.046943240972095214
evaluation/Rewards Max         0.9779413692588345
evaluation/Rewards Min         0.49047600837239397
evaluation/Returns Mean        481.1286901836458
evaluation/Returns Std         1.6812495518338366
evaluation/Returns Max         483.2113044595512
evaluation/Returns Min         478.1383143228179
evaluation/ExplReturns Mean    481.1286901836458
evaluation/ExplReturns Std     1.6812495518338366
evaluation/ExplReturns Max     483.2113044595512
evaluation/ExplReturns Min     478.1383143228179
evaluation/Actions Mean        0.01165095
evaluation/Actions Std         0.59287614
evaluation/Actions Max         0.99966717
evaluation/Actions Min         -0.9998561
evaluation/Num Paths           10
evaluation/Average Returns     481.1286901836458
time/data storing (s)          0.036487357690930367
time/evaluation sampling (s)   139.67294702120125
time/exploration sampling (s)  141.49915941804647
time/logging (s)               0.05293087102472782
time/saving (s)                0.016101161018013954
time/training (s)              13.212435306049883
time/epoch (s)                 294.4900611350313
time/total (s)                 159716.83882497624
Epoch                          678
-----------------------------  ---------------------
2023-08-02 14:21:04.435576 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 679 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4252.961]
trainer/QF1 Loss               0.014466418
trainer/QF2 Loss               0.0141349435
trainer/Policy Loss            -92.056046
trainer/Q1 Predictions Mean    103.13365
trainer/Q1 Predictions Std     0.939677
trainer/Q1 Predictions Max     105.30745
trainer/Q1 Predictions Min     95.77551
trainer/Q2 Predictions Mean    103.107834
trainer/Q2 Predictions Std     0.9322764
trainer/Q2 Predictions Max     105.29734
trainer/Q2 Predictions Min     95.96203
trainer/Q Targets Mean         103.06673
trainer/Q Targets Std          0.9462247
trainer/Q Targets Max          105.36764
trainer/Q Targets Min          95.978134
trainer/Log Pis Mean           11.141973
trainer/Log Pis Std            6.3690605
trainer/Log Pis Max            40.63423
trainer/Log Pis Min            -3.297075
trainer/Policy mu Mean         0.16211058
trainer/Policy mu Std          1.501719
trainer/Policy mu Max          4.230673
trainer/Policy mu Min          -4.983689
trainer/Policy log std Mean    -0.7762603
trainer/Policy log std Std     0.28405097
trainer/Policy log std Max     0.052221596
trainer/Policy log std Min     -2.2451634
trainer/Alpha                  0.0013267911272123456
trainer/Alpha Loss             -5.684377670288086
exploration/num steps total    3401000
exploration/num paths total    6802
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9583117533439501
exploration/Rewards Std        0.055942074485590965
exploration/Rewards Max        0.9799504031883517
exploration/Rewards Min        0.5053319423832229
exploration/Returns Mean       479.1558766719751
exploration/Returns Std        1.7827057053239468
exploration/Returns Max        481.4084913314055
exploration/Returns Min        475.8935916897612
exploration/Actions Mean       0.023121435
exploration/Actions Std        0.62899524
exploration/Actions Max        0.99999994
exploration/Actions Min        -0.9998757
exploration/Num Paths          10
exploration/Average Returns    479.1558766719751
evaluation/num steps total     3400000
evaluation/num paths total     6800
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9639827582323196
evaluation/Rewards Std         0.048960930752642275
evaluation/Rewards Max         0.979203968988414
evaluation/Rewards Min         0.49756549071817846
evaluation/Returns Mean        481.9913791161598
evaluation/Returns Std         0.9526098758205449
evaluation/Returns Max         484.6002997627617
evaluation/Returns Min         480.99844514568554
evaluation/ExplReturns Mean    481.9913791161598
evaluation/ExplReturns Std     0.9526098758205449
evaluation/ExplReturns Max     484.6002997627617
evaluation/ExplReturns Min     480.99844514568554
evaluation/Actions Mean        -0.006628715
evaluation/Actions Std         0.5211852
evaluation/Actions Max         0.9984973
evaluation/Actions Min         -0.9995076
evaluation/Num Paths           10
evaluation/Average Returns     481.9913791161598
time/data storing (s)          0.0410436037927866
time/evaluation sampling (s)   141.20093291904777
time/exploration sampling (s)  142.5856941845268
time/logging (s)               0.03985351882874966
time/saving (s)                0.012241683900356293
time/training (s)              13.621870948933065
time/epoch (s)                 297.50163685902953
time/total (s)                 160014.34344964754
Epoch                          679
-----------------------------  ---------------------
2023-08-02 14:26:05.238346 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 680 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4264.3486]
trainer/QF1 Loss               0.011142696
trainer/QF2 Loss               0.01657432
trainer/Policy Loss            -91.089325
trainer/Q1 Predictions Mean    102.97768
trainer/Q1 Predictions Std     1.0510306
trainer/Q1 Predictions Max     105.98803
trainer/Q1 Predictions Min     94.85016
trainer/Q2 Predictions Mean    103.05734
trainer/Q2 Predictions Std     1.0501118
trainer/Q2 Predictions Max     106.137085
trainer/Q2 Predictions Min     95.01158
trainer/Q Targets Mean         102.984985
trainer/Q Targets Std          1.0535827
trainer/Q Targets Max          105.99965
trainer/Q Targets Min          95.05976
trainer/Log Pis Mean           11.975789
trainer/Log Pis Std            6.2893977
trainer/Log Pis Max            39.41143
trainer/Log Pis Min            -2.249795
trainer/Policy mu Mean         0.22013295
trainer/Policy mu Std          1.5275342
trainer/Policy mu Max          5.4666433
trainer/Policy mu Min          -5.6596193
trainer/Policy log std Mean    -0.74226594
trainer/Policy log std Std     0.27891353
trainer/Policy log std Max     0.04583329
trainer/Policy log std Min     -2.2008138
trainer/Alpha                  0.0013562041567638516
trainer/Alpha Loss             -0.15986990928649902
exploration/num steps total    3406000
exploration/num paths total    6812
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9632000619009785
exploration/Rewards Std        0.04904381782883387
exploration/Rewards Max        0.9791889446236497
exploration/Rewards Min        0.48717428357455267
exploration/Returns Mean       481.60003095048904
exploration/Returns Std        1.1627908646896434
exploration/Returns Max        482.8270912703367
exploration/Returns Min        479.3885767891547
exploration/Actions Mean       -0.038843587
exploration/Actions Std        0.66401863
exploration/Actions Max        0.9999962
exploration/Actions Min        -0.99998486
exploration/Num Paths          10
exploration/Average Returns    481.60003095048904
evaluation/num steps total     3405000
evaluation/num paths total     6810
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9649230647960577
evaluation/Rewards Std         0.047050846826930226
evaluation/Rewards Max         0.9797046228018739
evaluation/Rewards Min         0.5015733078682477
evaluation/Returns Mean        482.4615323980289
evaluation/Returns Std         0.9077418572022304
evaluation/Returns Max         484.14615604912495
evaluation/Returns Min         481.3299553466305
evaluation/ExplReturns Mean    482.4615323980289
evaluation/ExplReturns Std     0.9077418572022304
evaluation/ExplReturns Max     484.14615604912495
evaluation/ExplReturns Min     481.3299553466305
evaluation/Actions Mean        -0.034152497
evaluation/Actions Std         0.6009566
evaluation/Actions Max         0.9990876
evaluation/Actions Min         -0.99982506
evaluation/Num Paths           10
evaluation/Average Returns     482.4615323980289
time/data storing (s)          0.033286675810813904
time/evaluation sampling (s)   141.4326646272093
time/exploration sampling (s)  142.4301285278052
time/logging (s)               0.033734312281012535
time/saving (s)                0.01248767226934433
time/training (s)              16.842173228040338
time/epoch (s)                 300.784475043416
time/total (s)                 160315.13307193294
Epoch                          680
-----------------------------  ---------------------
2023-08-02 14:31:01.408561 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 681 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4203.3496]
trainer/QF1 Loss               0.01715523
trainer/QF2 Loss               0.009138688
trainer/Policy Loss            -91.1735
trainer/Q1 Predictions Mean    102.95237
trainer/Q1 Predictions Std     0.80429476
trainer/Q1 Predictions Max     104.326355
trainer/Q1 Predictions Min     96.27018
trainer/Q2 Predictions Mean    102.995636
trainer/Q2 Predictions Std     0.832165
trainer/Q2 Predictions Max     104.27922
trainer/Q2 Predictions Min     95.500206
trainer/Q Targets Mean         103.01199
trainer/Q Targets Std          0.8218362
trainer/Q Targets Max          104.32655
trainer/Q Targets Min          95.51276
trainer/Log Pis Mean           11.875063
trainer/Log Pis Std            7.5074763
trainer/Log Pis Max            53.274044
trainer/Log Pis Min            -2.0072403
trainer/Policy mu Mean         0.15277071
trainer/Policy mu Std          1.5684819
trainer/Policy mu Max          7.2978277
trainer/Policy mu Min          -7.8811026
trainer/Policy log std Mean    -0.7581591
trainer/Policy log std Std     0.28176355
trainer/Policy log std Max     0.3624795
trainer/Policy log std Min     -2.1719673
trainer/Alpha                  0.0013287024339661002
trainer/Alpha Loss             -0.8275272846221924
exploration/num steps total    3411000
exploration/num paths total    6822
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9600162279706267
exploration/Rewards Std        0.053880984590301044
exploration/Rewards Max        0.9797088376093388
exploration/Rewards Min        0.49647092764081685
exploration/Returns Mean       480.00811398531334
exploration/Returns Std        1.3445683241847595
exploration/Returns Max        481.9704759099293
exploration/Returns Min        477.1291469827048
exploration/Actions Mean       -0.010787655
exploration/Actions Std        0.5720046
exploration/Actions Max        0.99990314
exploration/Actions Min        -0.9999424
exploration/Num Paths          10
exploration/Average Returns    480.00811398531334
evaluation/num steps total     3410000
evaluation/num paths total     6820
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9650934551787236
evaluation/Rewards Std         0.04811867122984183
evaluation/Rewards Max         0.979429151271197
evaluation/Rewards Min         0.5009427265234924
evaluation/Returns Mean        482.5467275893616
evaluation/Returns Std         0.35440253274084843
evaluation/Returns Max         482.8970292968774
evaluation/Returns Min         481.5642432571469
evaluation/ExplReturns Mean    482.5467275893616
evaluation/ExplReturns Std     0.35440253274084843
evaluation/ExplReturns Max     482.8970292968774
evaluation/ExplReturns Min     481.5642432571469
evaluation/Actions Mean        -0.024694912
evaluation/Actions Std         0.4814725
evaluation/Actions Max         0.99855727
evaluation/Actions Min         -0.99969506
evaluation/Num Paths           10
evaluation/Average Returns     482.5467275893616
time/data storing (s)          0.03454312216490507
time/evaluation sampling (s)   140.20932720508426
time/exploration sampling (s)  141.09754093922675
time/logging (s)               0.04145845677703619
time/saving (s)                0.015041251666843891
time/training (s)              14.771390341222286
time/epoch (s)                 296.1693013161421
time/total (s)                 160611.30569408275
Epoch                          681
-----------------------------  ---------------------
2023-08-02 14:36:02.219298 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 682 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3749.3262]
trainer/QF1 Loss               0.01245708
trainer/QF2 Loss               0.018111482
trainer/Policy Loss            -91.81513
trainer/Q1 Predictions Mean    103.01526
trainer/Q1 Predictions Std     0.8883335
trainer/Q1 Predictions Max     106.375244
trainer/Q1 Predictions Min     97.286095
trainer/Q2 Predictions Mean    103.06445
trainer/Q2 Predictions Std     0.8928372
trainer/Q2 Predictions Max     106.569176
trainer/Q2 Predictions Min     97.49403
trainer/Q Targets Mean         102.99272
trainer/Q Targets Std          0.8904727
trainer/Q Targets Max          106.61453
trainer/Q Targets Min          97.66779
trainer/Log Pis Mean           11.293953
trainer/Log Pis Std            7.020222
trainer/Log Pis Max            39.297375
trainer/Log Pis Min            -2.612321
trainer/Policy mu Mean         0.15402924
trainer/Policy mu Std          1.5183562
trainer/Policy mu Max          5.571296
trainer/Policy mu Min          -6.0775337
trainer/Policy log std Mean    -0.74933654
trainer/Policy log std Std     0.28278
trainer/Policy log std Max     0.09695622
trainer/Policy log std Min     -2.0380237
trainer/Alpha                  0.0013335479889065027
trainer/Alpha Loss             -4.673926830291748
exploration/num steps total    3416000
exploration/num paths total    6832
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9604175505598982
exploration/Rewards Std        0.048850495623829766
exploration/Rewards Max        0.9797191265413243
exploration/Rewards Min        0.4903734440211766
exploration/Returns Mean       480.20877527994907
exploration/Returns Std        2.256613069986341
exploration/Returns Max        483.66078669142564
exploration/Returns Min        477.32667692553616
exploration/Actions Mean       0.0435798
exploration/Actions Std        0.6275742
exploration/Actions Max        0.99997735
exploration/Actions Min        -0.9999509
exploration/Num Paths          10
exploration/Average Returns    480.20877527994907
evaluation/num steps total     3415000
evaluation/num paths total     6830
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9577867697654707
evaluation/Rewards Std         0.053205629116485194
evaluation/Rewards Max         0.9794500641111586
evaluation/Rewards Min         0.4891803595122943
evaluation/Returns Mean        478.89338488273535
evaluation/Returns Std         4.592833650038984
evaluation/Returns Max         481.96276016958313
evaluation/Returns Min         469.75505370615184
evaluation/ExplReturns Mean    478.89338488273535
evaluation/ExplReturns Std     4.592833650038984
evaluation/ExplReturns Max     481.96276016958313
evaluation/ExplReturns Min     469.75505370615184
evaluation/Actions Mean        0.014449404
evaluation/Actions Std         0.54662704
evaluation/Actions Max         0.99884087
evaluation/Actions Min         -0.99905014
evaluation/Num Paths           10
evaluation/Average Returns     478.89338488273535
time/data storing (s)          0.03829539194703102
time/evaluation sampling (s)   141.52861664444208
time/exploration sampling (s)  142.4095492810011
time/logging (s)               0.03669076692312956
time/saving (s)                0.01534747239202261
time/training (s)              16.768140511587262
time/epoch (s)                 300.7966400682926
time/total (s)                 160912.10504465736
Epoch                          682
-----------------------------  ---------------------
2023-08-02 14:40:59.822162 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 683 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3727.6807]
trainer/QF1 Loss               0.025592458
trainer/QF2 Loss               0.012868641
trainer/Policy Loss            -90.51251
trainer/Q1 Predictions Mean    102.98767
trainer/Q1 Predictions Std     1.1088609
trainer/Q1 Predictions Max     104.439804
trainer/Q1 Predictions Min     90.85131
trainer/Q2 Predictions Mean    102.86096
trainer/Q2 Predictions Std     1.1032965
trainer/Q2 Predictions Max     104.50128
trainer/Q2 Predictions Min     90.91516
trainer/Q Targets Mean         102.86666
trainer/Q Targets Std          1.1330967
trainer/Q Targets Max          104.327484
trainer/Q Targets Min          90.35428
trainer/Log Pis Mean           12.449204
trainer/Log Pis Std            7.636119
trainer/Log Pis Max            41.423622
trainer/Log Pis Min            -3.6157641
trainer/Policy mu Mean         0.062010437
trainer/Policy mu Std          1.5707338
trainer/Policy mu Max          5.7391605
trainer/Policy mu Min          -4.8355913
trainer/Policy log std Mean    -0.7583022
trainer/Policy log std Std     0.27907068
trainer/Policy log std Max     0.2103281
trainer/Policy log std Min     -1.9170102
trainer/Alpha                  0.0012985867215320468
trainer/Alpha Loss             2.9856131076812744
exploration/num steps total    3421000
exploration/num paths total    6842
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9566120594720101
exploration/Rewards Std        0.04814434559810091
exploration/Rewards Max        0.9794133740716848
exploration/Rewards Min        0.5023917712323372
exploration/Returns Mean       478.30602973600526
exploration/Returns Std        0.2763959419094318
exploration/Returns Max        478.7462860768603
exploration/Returns Min        477.9098308694042
exploration/Actions Mean       -0.04896846
exploration/Actions Std        0.5965423
exploration/Actions Max        0.9998788
exploration/Actions Min        -0.9999901
exploration/Num Paths          10
exploration/Average Returns    478.30602973600526
evaluation/num steps total     3420000
evaluation/num paths total     6840
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9607723729460422
evaluation/Rewards Std         0.04746867344427171
evaluation/Rewards Max         0.9791617985535608
evaluation/Rewards Min         0.487096634726877
evaluation/Returns Mean        480.386186473021
evaluation/Returns Std         0.16663429380507697
evaluation/Returns Max         480.71425175999485
evaluation/Returns Min         480.1270348743119
evaluation/ExplReturns Mean    480.386186473021
evaluation/ExplReturns Std     0.16663429380507697
evaluation/ExplReturns Max     480.71425175999485
evaluation/ExplReturns Min     480.1270348743119
evaluation/Actions Mean        -0.07682279
evaluation/Actions Std         0.46267244
evaluation/Actions Max         0.9991793
evaluation/Actions Min         -0.99943686
evaluation/Num Paths           10
evaluation/Average Returns     480.386186473021
time/data storing (s)          0.04085944592952728
time/evaluation sampling (s)   138.90679800510406
time/exploration sampling (s)  141.8992042178288
time/logging (s)               0.04380863253027201
time/saving (s)                0.011944971978664398
time/training (s)              16.696449087932706
time/epoch (s)                 297.59906436130404
time/total (s)                 161209.7089245282
Epoch                          683
-----------------------------  ---------------------
2023-08-02 14:46:01.313739 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 684 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3947.8884]
trainer/QF1 Loss               0.009329673
trainer/QF2 Loss               0.0090366015
trainer/Policy Loss            -92.10675
trainer/Q1 Predictions Mean    102.91847
trainer/Q1 Predictions Std     0.8330603
trainer/Q1 Predictions Max     104.796234
trainer/Q1 Predictions Min     98.17214
trainer/Q2 Predictions Mean    102.90367
trainer/Q2 Predictions Std     0.83337146
trainer/Q2 Predictions Max     104.73067
trainer/Q2 Predictions Min     98.1192
trainer/Q Targets Mean         102.91454
trainer/Q Targets Std          0.80981314
trainer/Q Targets Max          104.68967
trainer/Q Targets Min          98.45489
trainer/Log Pis Mean           10.866314
trainer/Log Pis Std            6.968096
trainer/Log Pis Max            40.799828
trainer/Log Pis Min            -5.384775
trainer/Policy mu Mean         0.11247232
trainer/Policy mu Std          1.5173804
trainer/Policy mu Max          4.9346128
trainer/Policy mu Min          -4.3435154
trainer/Policy log std Mean    -0.7669647
trainer/Policy log std Std     0.28631997
trainer/Policy log std Max     -0.0484232
trainer/Policy log std Min     -2.0932143
trainer/Alpha                  0.001289229141548276
trainer/Alpha Loss             -7.542969703674316
exploration/num steps total    3426000
exploration/num paths total    6852
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9062223400046169
exploration/Rewards Std        0.09900621736299747
exploration/Rewards Max        0.9796571437526036
exploration/Rewards Min        0.4899487209439218
exploration/Returns Mean       453.1111700023084
exploration/Returns Std        5.940813916462678
exploration/Returns Max        465.9255792842878
exploration/Returns Min        446.52967182363057
exploration/Actions Mean       0.107122496
exploration/Actions Std        0.60772806
exploration/Actions Max        0.9998082
exploration/Actions Min        -0.9999583
exploration/Num Paths          10
exploration/Average Returns    453.1111700023084
evaluation/num steps total     3425000
evaluation/num paths total     6850
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9577697805239511
evaluation/Rewards Std         0.05536686222231298
evaluation/Rewards Max         0.9795300066834663
evaluation/Rewards Min         0.49096597938010506
evaluation/Returns Mean        478.8848902619754
evaluation/Returns Std         5.5795018847534585
evaluation/Returns Max         481.42940355567936
evaluation/Returns Min         462.22656470210404
evaluation/ExplReturns Mean    478.8848902619754
evaluation/ExplReturns Std     5.5795018847534585
evaluation/ExplReturns Max     481.42940355567936
evaluation/ExplReturns Min     462.22656470210404
evaluation/Actions Mean        0.0070590205
evaluation/Actions Std         0.53864515
evaluation/Actions Max         0.99879813
evaluation/Actions Min         -0.9995011
evaluation/Num Paths           10
evaluation/Average Returns     478.8848902619754
time/data storing (s)          0.03966145496815443
time/evaluation sampling (s)   143.02661261800677
time/exploration sampling (s)  141.41627693362534
time/logging (s)               0.03381830453872681
time/saving (s)                0.014577092602849007
time/training (s)              16.942233385518193
time/epoch (s)                 301.47317978926003
time/total (s)                 161511.18490219396
Epoch                          684
-----------------------------  --------------------
2023-08-02 14:50:59.993593 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 685 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4056.4514]
trainer/QF1 Loss               0.020159978
trainer/QF2 Loss               0.012015907
trainer/Policy Loss            -91.34179
trainer/Q1 Predictions Mean    102.832214
trainer/Q1 Predictions Std     0.86701965
trainer/Q1 Predictions Max     105.873924
trainer/Q1 Predictions Min     95.13591
trainer/Q2 Predictions Mean    102.92108
trainer/Q2 Predictions Std     0.831013
trainer/Q2 Predictions Max     105.74692
trainer/Q2 Predictions Min     95.43683
trainer/Q Targets Mean         102.906975
trainer/Q Targets Std          0.8422899
trainer/Q Targets Max          105.59417
trainer/Q Targets Min          95.36979
trainer/Log Pis Mean           11.583685
trainer/Log Pis Std            7.571602
trainer/Log Pis Max            39.111282
trainer/Log Pis Min            -4.907225
trainer/Policy mu Mean         0.15067293
trainer/Policy mu Std          1.5438498
trainer/Policy mu Max          4.281417
trainer/Policy mu Min          -5.368705
trainer/Policy log std Mean    -0.76074195
trainer/Policy log std Std     0.27896172
trainer/Policy log std Max     0.026912332
trainer/Policy log std Min     -2.1784763
trainer/Alpha                  0.0013120616786181927
trainer/Alpha Loss             -2.7627949714660645
exploration/num steps total    3431000
exploration/num paths total    6862
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9551947619437753
exploration/Rewards Std        0.04681584356753896
exploration/Rewards Max        0.9795613500764493
exploration/Rewards Min        0.48445793495946554
exploration/Returns Mean       477.5973809718877
exploration/Returns Std        0.749370800812419
exploration/Returns Max        479.39807632966347
exploration/Returns Min        476.5467951283587
exploration/Actions Mean       0.08831176
exploration/Actions Std        0.61377215
exploration/Actions Max        0.9998866
exploration/Actions Min        -0.99986905
exploration/Num Paths          10
exploration/Average Returns    477.5973809718877
evaluation/num steps total     3430000
evaluation/num paths total     6860
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.957033314357575
evaluation/Rewards Std         0.04768685710991527
evaluation/Rewards Max         0.9785708046030136
evaluation/Rewards Min         0.48186183019697487
evaluation/Returns Mean        478.51665717878734
evaluation/Returns Std         0.6576261479030541
evaluation/Returns Max         479.40027737183664
evaluation/Returns Min         477.4608794090362
evaluation/ExplReturns Mean    478.51665717878734
evaluation/ExplReturns Std     0.6576261479030541
evaluation/ExplReturns Max     479.40027737183664
evaluation/ExplReturns Min     477.4608794090362
evaluation/Actions Mean        0.05847063
evaluation/Actions Std         0.49623185
evaluation/Actions Max         0.99962145
evaluation/Actions Min         -0.9997251
evaluation/Num Paths           10
evaluation/Average Returns     478.51665717878734
time/data storing (s)          0.04610984027385712
time/evaluation sampling (s)   140.9791526403278
time/exploration sampling (s)  141.51959691848606
time/logging (s)               0.038458989933133125
time/saving (s)                0.013815156184136868
time/training (s)              16.07850873656571
time/epoch (s)                 298.6756422817707
time/total (s)                 161809.86354570836
Epoch                          685
-----------------------------  ---------------------
2023-08-02 14:55:57.771005 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 686 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4175.6416]
trainer/QF1 Loss               0.016920527
trainer/QF2 Loss               0.023012733
trainer/Policy Loss            -92.02358
trainer/Q1 Predictions Mean    102.889275
trainer/Q1 Predictions Std     1.1748306
trainer/Q1 Predictions Max     105.25176
trainer/Q1 Predictions Min     90.16166
trainer/Q2 Predictions Mean    102.94378
trainer/Q2 Predictions Std     1.1647689
trainer/Q2 Predictions Max     105.38703
trainer/Q2 Predictions Min     90.55947
trainer/Q Targets Mean         102.84231
trainer/Q Targets Std          1.1960161
trainer/Q Targets Max          105.20792
trainer/Q Targets Min          89.8424
trainer/Log Pis Mean           10.963641
trainer/Log Pis Std            7.359093
trainer/Log Pis Max            41.637074
trainer/Log Pis Min            -4.4213967
trainer/Policy mu Mean         0.022564314
trainer/Policy mu Std          1.5303632
trainer/Policy mu Max          7.70994
trainer/Policy mu Min          -5.2833815
trainer/Policy log std Mean    -0.76708645
trainer/Policy log std Std     0.29513758
trainer/Policy log std Max     0.34071636
trainer/Policy log std Min     -2.102687
trainer/Alpha                  0.001308940933085978
trainer/Alpha Loss             -6.879672050476074
exploration/num steps total    3436000
exploration/num paths total    6872
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9557534841813372
exploration/Rewards Std        0.047166735209318016
exploration/Rewards Max        0.9792784033492101
exploration/Rewards Min        0.4970760555162649
exploration/Returns Mean       477.8767420906687
exploration/Returns Std        0.30603360332005913
exploration/Returns Max        478.3758951398815
exploration/Returns Min        477.393614228076
exploration/Actions Mean       -0.016498683
exploration/Actions Std        0.5845334
exploration/Actions Max        0.99984974
exploration/Actions Min        -0.99997056
exploration/Num Paths          10
exploration/Average Returns    477.8767420906687
evaluation/num steps total     3435000
evaluation/num paths total     6870
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9517979850097705
evaluation/Rewards Std         0.06015168026435344
evaluation/Rewards Max         0.978551604554021
evaluation/Rewards Min         0.47632982000496615
evaluation/Returns Mean        475.89899250488514
evaluation/Returns Std         9.778511053049964
evaluation/Returns Max         480.522671005689
evaluation/Returns Min         446.645013576206
evaluation/ExplReturns Mean    475.89899250488514
evaluation/ExplReturns Std     9.778511053049964
evaluation/ExplReturns Max     480.522671005689
evaluation/ExplReturns Min     446.645013576206
evaluation/Actions Mean        -0.030880906
evaluation/Actions Std         0.46385363
evaluation/Actions Max         0.9999374
evaluation/Actions Min         -0.9999468
evaluation/Num Paths           10
evaluation/Average Returns     475.89899250488514
time/data storing (s)          0.038603344932198524
time/evaluation sampling (s)   140.86731347907335
time/exploration sampling (s)  142.56658325344324
time/logging (s)               0.042575870640575886
time/saving (s)                0.02149651851505041
time/training (s)              14.236373812891543
time/epoch (s)                 297.77294627949595
time/total (s)                 162107.640100223
Epoch                          686
-----------------------------  --------------------
2023-08-02 15:00:55.696254 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 687 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3633.6672]
trainer/QF1 Loss               0.019875567
trainer/QF2 Loss               0.033078186
trainer/Policy Loss            -91.17442
trainer/Q1 Predictions Mean    102.65449
trainer/Q1 Predictions Std     1.5927163
trainer/Q1 Predictions Max     104.49914
trainer/Q1 Predictions Min     86.048515
trainer/Q2 Predictions Mean    102.728
trainer/Q2 Predictions Std     1.5125738
trainer/Q2 Predictions Max     104.50566
trainer/Q2 Predictions Min     87.13681
trainer/Q Targets Mean         102.67752
trainer/Q Targets Std          1.639119
trainer/Q Targets Max          104.387146
trainer/Q Targets Min          85.880714
trainer/Log Pis Mean           11.572157
trainer/Log Pis Std            7.872345
trainer/Log Pis Max            53.119835
trainer/Log Pis Min            -6.806029
trainer/Policy mu Mean         0.12034958
trainer/Policy mu Std          1.559159
trainer/Policy mu Max          6.2475357
trainer/Policy mu Min          -4.709723
trainer/Policy log std Mean    -0.7542767
trainer/Policy log std Std     0.28559726
trainer/Policy log std Max     0.06395054
trainer/Policy log std Min     -2.5073397
trainer/Alpha                  0.0012971009127795696
trainer/Alpha Loss             -2.8441171646118164
exploration/num steps total    3441000
exploration/num paths total    6882
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9574694290387215
exploration/Rewards Std        0.046917062251292926
exploration/Rewards Max        0.9780077849539874
exploration/Rewards Min        0.49104616822234864
exploration/Returns Mean       478.73471451936064
exploration/Returns Std        0.3603162437087712
exploration/Returns Max        479.1747113027359
exploration/Returns Min        477.9399592427967
exploration/Actions Mean       0.034833454
exploration/Actions Std        0.62549645
exploration/Actions Max        0.99996006
exploration/Actions Min        -0.99991125
exploration/Num Paths          10
exploration/Average Returns    478.73471451936064
evaluation/num steps total     3440000
evaluation/num paths total     6880
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9580527676511401
evaluation/Rewards Std         0.046924366360741376
evaluation/Rewards Max         0.9769181793542732
evaluation/Rewards Min         0.4921531641745709
evaluation/Returns Mean        479.0263838255702
evaluation/Returns Std         0.2631821210888247
evaluation/Returns Max         479.5766035322197
evaluation/Returns Min         478.41502959551315
evaluation/ExplReturns Mean    479.0263838255702
evaluation/ExplReturns Std     0.2631821210888247
evaluation/ExplReturns Max     479.5766035322197
evaluation/ExplReturns Min     478.41502959551315
evaluation/Actions Mean        0.07083656
evaluation/Actions Std         0.54665357
evaluation/Actions Max         0.9993234
evaluation/Actions Min         -0.9997556
evaluation/Num Paths           10
evaluation/Average Returns     479.0263838255702
time/data storing (s)          0.034843048080801964
time/evaluation sampling (s)   139.7042733244598
time/exploration sampling (s)  142.01543623860925
time/logging (s)               0.036036524921655655
time/saving (s)                0.015713957138359547
time/training (s)              16.101356456056237
time/epoch (s)                 297.9076595492661
time/total (s)                 162405.5504182037
Epoch                          687
-----------------------------  ---------------------
2023-08-02 15:05:56.197549 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 688 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3688.248]
trainer/QF1 Loss               0.010960424
trainer/QF2 Loss               0.014911449
trainer/Policy Loss            -91.91709
trainer/Q1 Predictions Mean    102.712845
trainer/Q1 Predictions Std     0.906093
trainer/Q1 Predictions Max     105.69901
trainer/Q1 Predictions Min     97.80653
trainer/Q2 Predictions Mean    102.6875
trainer/Q2 Predictions Std     0.91486955
trainer/Q2 Predictions Max     105.75219
trainer/Q2 Predictions Min     97.741905
trainer/Q Targets Mean         102.70036
trainer/Q Targets Std          0.8910614
trainer/Q Targets Max          105.65873
trainer/Q Targets Min          97.77893
trainer/Log Pis Mean           10.854172
trainer/Log Pis Std            7.3187203
trainer/Log Pis Max            39.920975
trainer/Log Pis Min            -5.1026506
trainer/Policy mu Mean         0.04016104
trainer/Policy mu Std          1.5133166
trainer/Policy mu Max          5.496147
trainer/Policy mu Min          -4.875551
trainer/Policy log std Mean    -0.7827417
trainer/Policy log std Std     0.30147043
trainer/Policy log std Max     0.04439926
trainer/Policy log std Min     -2.2815614
trainer/Alpha                  0.001270399196073413
trainer/Alpha Loss             -7.640789031982422
exploration/num steps total    3446000
exploration/num paths total    6892
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.960218575684485
exploration/Rewards Std        0.04725953060201312
exploration/Rewards Max        0.9796408858520984
exploration/Rewards Min        0.49516340830649197
exploration/Returns Mean       480.1092878422425
exploration/Returns Std        0.37430277075554874
exploration/Returns Max        480.7118844364927
exploration/Returns Min        479.4545599809525
exploration/Actions Mean       0.19363046
exploration/Actions Std        0.5769674
exploration/Actions Max        0.99987775
exploration/Actions Min        -0.99991727
exploration/Num Paths          10
exploration/Average Returns    480.1092878422425
evaluation/num steps total     3445000
evaluation/num paths total     6890
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9614914109667788
evaluation/Rewards Std         0.04813500357594887
evaluation/Rewards Max         0.9770615960404113
evaluation/Rewards Min         0.49673477534377775
evaluation/Returns Mean        480.74570548338943
evaluation/Returns Std         1.067448056967755
evaluation/Returns Max         482.16345659233804
evaluation/Returns Min         478.33346235950256
evaluation/ExplReturns Mean    480.74570548338943
evaluation/ExplReturns Std     1.067448056967755
evaluation/ExplReturns Max     482.16345659233804
evaluation/ExplReturns Min     478.33346235950256
evaluation/Actions Mean        0.20997787
evaluation/Actions Std         0.5162051
evaluation/Actions Max         0.99952984
evaluation/Actions Min         -0.99977136
evaluation/Num Paths           10
evaluation/Average Returns     480.74570548338943
time/data storing (s)          0.03344881348311901
time/evaluation sampling (s)   141.53036028891802
time/exploration sampling (s)  143.19691104255617
time/logging (s)               0.037103321403265
time/saving (s)                0.013433416374027729
time/training (s)              15.680760486982763
time/epoch (s)                 300.49201736971736
time/total (s)                 162706.04589807056
Epoch                          688
-----------------------------  --------------------
2023-08-02 15:10:58.168249 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 689 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3578.0103]
trainer/QF1 Loss               0.016884208
trainer/QF2 Loss               0.019166706
trainer/Policy Loss            -91.03195
trainer/Q1 Predictions Mean    102.487495
trainer/Q1 Predictions Std     2.0135608
trainer/Q1 Predictions Max     104.23169
trainer/Q1 Predictions Min     81.59237
trainer/Q2 Predictions Mean    102.54108
trainer/Q2 Predictions Std     1.9736494
trainer/Q2 Predictions Max     104.25165
trainer/Q2 Predictions Min     81.465645
trainer/Q Targets Mean         102.52494
trainer/Q Targets Std          2.0171404
trainer/Q Targets Max          104.338165
trainer/Q Targets Min          81.394005
trainer/Log Pis Mean           11.551766
trainer/Log Pis Std            9.177134
trainer/Log Pis Max            87.94824
trainer/Log Pis Min            -0.7089573
trainer/Policy mu Mean         0.052086085
trainer/Policy mu Std          1.6138295
trainer/Policy mu Max          13.760212
trainer/Policy mu Min          -14.164698
trainer/Policy log std Mean    -0.7607927
trainer/Policy log std Std     0.30461514
trainer/Policy log std Max     0.99332976
trainer/Policy log std Min     -2.7576034
trainer/Alpha                  0.0012686139671131968
trainer/Alpha Loss             -2.989610195159912
exploration/num steps total    3451000
exploration/num paths total    6902
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9368626658451306
exploration/Rewards Std        0.08179125712696986
exploration/Rewards Max        0.9796813285070052
exploration/Rewards Min        0.48866555582531324
exploration/Returns Mean       468.43133292256533
exploration/Returns Std        23.793998093635295
exploration/Returns Max        481.49843649223493
exploration/Returns Min        405.7717024565858
exploration/Actions Mean       0.12311163
exploration/Actions Std        0.64009434
exploration/Actions Max        0.9999895
exploration/Actions Min        -0.99999845
exploration/Num Paths          10
exploration/Average Returns    468.43133292256533
evaluation/num steps total     3450000
evaluation/num paths total     6900
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8822718664772933
evaluation/Rewards Std         0.10992362064106201
evaluation/Rewards Max         0.9787336896262616
evaluation/Rewards Min         0.4943143498976527
evaluation/Returns Mean        441.1359332386466
evaluation/Returns Std         25.425967686766025
evaluation/Returns Max         482.022741426994
evaluation/Returns Min         403.1729477207514
evaluation/ExplReturns Mean    441.1359332386466
evaluation/ExplReturns Std     25.425967686766025
evaluation/ExplReturns Max     482.022741426994
evaluation/ExplReturns Min     403.1729477207514
evaluation/Actions Mean        0.10403027
evaluation/Actions Std         0.6231162
evaluation/Actions Max         0.99995804
evaluation/Actions Min         -0.99999607
evaluation/Num Paths           10
evaluation/Average Returns     441.1359332386466
time/data storing (s)          0.03824194334447384
time/evaluation sampling (s)   141.81274725776166
time/exploration sampling (s)  144.17110432405025
time/logging (s)               0.03737885504961014
time/saving (s)                0.01648768875747919
time/training (s)              15.88650491181761
time/epoch (s)                 301.9624649807811
time/total (s)                 163008.01121927612
Epoch                          689
-----------------------------  ---------------------
2023-08-02 15:16:00.842441 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 690 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3957.5005]
trainer/QF1 Loss               0.017557096
trainer/QF2 Loss               0.010613307
trainer/Policy Loss            -90.76902
trainer/Q1 Predictions Mean    102.55597
trainer/Q1 Predictions Std     1.1727108
trainer/Q1 Predictions Max     104.10724
trainer/Q1 Predictions Min     89.592125
trainer/Q2 Predictions Mean    102.618195
trainer/Q2 Predictions Std     1.1597487
trainer/Q2 Predictions Max     104.23406
trainer/Q2 Predictions Min     89.94838
trainer/Q Targets Mean         102.62831
trainer/Q Targets Std          1.1463519
trainer/Q Targets Max          104.20224
trainer/Q Targets Min          89.87659
trainer/Log Pis Mean           11.89396
trainer/Log Pis Std            7.708024
trainer/Log Pis Max            59.882225
trainer/Log Pis Min            -8.802391
trainer/Policy mu Mean         0.05579419
trainer/Policy mu Std          1.5710181
trainer/Policy mu Max          10.219542
trainer/Policy mu Min          -4.788636
trainer/Policy log std Mean    -0.78025603
trainer/Policy log std Std     0.29947895
trainer/Policy log std Max     1.181608
trainer/Policy log std Min     -2.1524107
trainer/Alpha                  0.0012061340967193246
trainer/Alpha Loss             -0.7126071453094482
exploration/num steps total    3456000
exploration/num paths total    6912
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9357165246198101
exploration/Rewards Std        0.08394181505497351
exploration/Rewards Max        0.9785604284126954
exploration/Rewards Min        0.5023242690702848
exploration/Returns Mean       467.85826230990494
exploration/Returns Std        22.968677012631726
exploration/Returns Max        480.30496990207774
exploration/Returns Min        418.9732191914889
exploration/Actions Mean       0.20400131
exploration/Actions Std        0.63949025
exploration/Actions Max        0.99997914
exploration/Actions Min        -0.9999065
exploration/Num Paths          10
exploration/Average Returns    467.85826230990494
evaluation/num steps total     3455000
evaluation/num paths total     6910
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9387440471305476
evaluation/Rewards Std         0.08513373595105167
evaluation/Rewards Max         0.9776784734099812
evaluation/Rewards Min         0.4948736808064717
evaluation/Returns Mean        469.37202356527376
evaluation/Returns Std         31.16927201785779
evaluation/Returns Max         481.0230116425272
evaluation/Returns Min         375.8938199448012
evaluation/ExplReturns Mean    469.37202356527376
evaluation/ExplReturns Std     31.16927201785779
evaluation/ExplReturns Max     481.0230116425272
evaluation/ExplReturns Min     375.8938199448012
evaluation/Actions Mean        0.20954292
evaluation/Actions Std         0.63666576
evaluation/Actions Max         0.9997404
evaluation/Actions Min         -0.9997861
evaluation/Num Paths           10
evaluation/Average Returns     469.37202356527376
time/data storing (s)          0.04619297757744789
time/evaluation sampling (s)   142.33338296506554
time/exploration sampling (s)  144.25979897379875
time/logging (s)               0.04079982731491327
time/saving (s)                0.014661776833236217
time/training (s)              15.973695767112076
time/epoch (s)                 302.66853228770196
time/total (s)                 163310.6831907211
Epoch                          690
-----------------------------  ---------------------
2023-08-02 15:21:04.326600 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 691 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3909.6145]
trainer/QF1 Loss               0.011890452
trainer/QF2 Loss               0.01499444
trainer/Policy Loss            -91.0858
trainer/Q1 Predictions Mean    102.528915
trainer/Q1 Predictions Std     1.6477084
trainer/Q1 Predictions Max     105.54154
trainer/Q1 Predictions Min     86.174065
trainer/Q2 Predictions Mean    102.50103
trainer/Q2 Predictions Std     1.6535748
trainer/Q2 Predictions Max     105.635925
trainer/Q2 Predictions Min     85.70714
trainer/Q Targets Mean         102.50563
trainer/Q Targets Std          1.6325599
trainer/Q Targets Max          105.12179
trainer/Q Targets Min          86.21044
trainer/Log Pis Mean           11.514898
trainer/Log Pis Std            8.312028
trainer/Log Pis Max            55.125137
trainer/Log Pis Min            -3.805899
trainer/Policy mu Mean         0.064798765
trainer/Policy mu Std          1.5787413
trainer/Policy mu Max          7.334093
trainer/Policy mu Min          -5.985971
trainer/Policy log std Mean    -0.77380395
trainer/Policy log std Std     0.30592266
trainer/Policy log std Max     0.16476792
trainer/Policy log std Min     -1.9045974
trainer/Alpha                  0.0012442084262147546
trainer/Alpha Loss             -3.24495530128479
exploration/num steps total    3461000
exploration/num paths total    6922
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.920238305311873
exploration/Rewards Std        0.0912089219252365
exploration/Rewards Max        0.9783907540490893
exploration/Rewards Min        0.4906432821711828
exploration/Returns Mean       460.1191526559366
exploration/Returns Std        24.59408998675443
exploration/Returns Max        477.18541305502407
exploration/Returns Min        419.156337115294
exploration/Actions Mean       0.17782193
exploration/Actions Std        0.6641857
exploration/Actions Max        0.9999998
exploration/Actions Min        -0.99996996
exploration/Num Paths          10
exploration/Average Returns    460.1191526559366
evaluation/num steps total     3460000
evaluation/num paths total     6920
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9416832698233683
evaluation/Rewards Std         0.06911568540457977
evaluation/Rewards Max         0.975476492440075
evaluation/Rewards Min         0.4897965355609241
evaluation/Returns Mean        470.8416349116842
evaluation/Returns Std         18.478466074748617
evaluation/Returns Max         477.80269259312536
evaluation/Returns Min         415.4474301161253
evaluation/ExplReturns Mean    470.8416349116842
evaluation/ExplReturns Std     18.478466074748617
evaluation/ExplReturns Max     477.80269259312536
evaluation/ExplReturns Min     415.4474301161253
evaluation/Actions Mean        0.21183623
evaluation/Actions Std         0.58783823
evaluation/Actions Max         0.99994344
evaluation/Actions Min         -0.99964064
evaluation/Num Paths           10
evaluation/Average Returns     470.8416349116842
time/data storing (s)          0.04209900461137295
time/evaluation sampling (s)   142.15248141344637
time/exploration sampling (s)  146.92140538804233
time/logging (s)               0.03326746728271246
time/saving (s)                0.021363497711718082
time/training (s)              14.296418596059084
time/epoch (s)                 303.4670353671536
time/total (s)                 163614.15316542983
Epoch                          691
-----------------------------  ---------------------
2023-08-02 15:26:04.539885 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 692 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3931.8835]
trainer/QF1 Loss               0.027337974
trainer/QF2 Loss               0.022194255
trainer/Policy Loss            -90.66531
trainer/Q1 Predictions Mean    102.57477
trainer/Q1 Predictions Std     1.1270463
trainer/Q1 Predictions Max     105.58001
trainer/Q1 Predictions Min     91.454285
trainer/Q2 Predictions Mean    102.53502
trainer/Q2 Predictions Std     1.1438453
trainer/Q2 Predictions Max     105.117386
trainer/Q2 Predictions Min     91.33245
trainer/Q Targets Mean         102.54308
trainer/Q Targets Std          1.1623398
trainer/Q Targets Max          105.2465
trainer/Q Targets Min          91.08816
trainer/Log Pis Mean           11.973297
trainer/Log Pis Std            7.321659
trainer/Log Pis Max            43.915997
trainer/Log Pis Min            -7.102579
trainer/Policy mu Mean         0.112563096
trainer/Policy mu Std          1.5570486
trainer/Policy mu Max          4.9143915
trainer/Policy mu Min          -4.206861
trainer/Policy log std Mean    -0.7824645
trainer/Policy log std Std     0.31484783
trainer/Policy log std Max     0.066841364
trainer/Policy log std Min     -2.2337718
trainer/Alpha                  0.0012757094809785485
trainer/Alpha Loss             -0.17795252799987793
exploration/num steps total    3466000
exploration/num paths total    6932
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9243492315491705
exploration/Rewards Std        0.09006199259326142
exploration/Rewards Max        0.9794975800653462
exploration/Rewards Min        0.4931657641048228
exploration/Returns Mean       462.1746157745853
exploration/Returns Std        13.63048270360254
exploration/Returns Max        474.55577197908025
exploration/Returns Min        427.3766795097547
exploration/Actions Mean       0.009800122
exploration/Actions Std        0.62065804
exploration/Actions Max        0.99999887
exploration/Actions Min        -0.99999624
exploration/Num Paths          10
exploration/Average Returns    462.1746157745853
evaluation/num steps total     3465000
evaluation/num paths total     6930
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9227548284493682
evaluation/Rewards Std         0.09478152140782237
evaluation/Rewards Max         0.9789788914846735
evaluation/Rewards Min         0.4965407813568238
evaluation/Returns Mean        461.3774142246839
evaluation/Returns Std         17.517618214455744
evaluation/Returns Max         482.7040824299459
evaluation/Returns Min         421.1893891604755
evaluation/ExplReturns Mean    461.3774142246839
evaluation/ExplReturns Std     17.517618214455744
evaluation/ExplReturns Max     482.7040824299459
evaluation/ExplReturns Min     421.1893891604755
evaluation/Actions Mean        0.03288424
evaluation/Actions Std         0.60175663
evaluation/Actions Max         0.99999964
evaluation/Actions Min         -0.99999994
evaluation/Num Paths           10
evaluation/Average Returns     461.3774142246839
time/data storing (s)          0.037880321964621544
time/evaluation sampling (s)   141.8233015332371
time/exploration sampling (s)  142.9395967805758
time/logging (s)               0.03715892694890499
time/saving (s)                0.055413613095879555
time/training (s)              15.315010814927518
time/epoch (s)                 300.20836199074984
time/total (s)                 163914.36540031247
Epoch                          692
-----------------------------  ---------------------
2023-08-02 15:31:06.491540 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 693 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [4178.1353]
trainer/QF1 Loss               0.017209819
trainer/QF2 Loss               0.015176403
trainer/Policy Loss            -90.05295
trainer/Q1 Predictions Mean    102.43997
trainer/Q1 Predictions Std     1.2773429
trainer/Q1 Predictions Max     105.591736
trainer/Q1 Predictions Min     91.14025
trainer/Q2 Predictions Mean    102.46834
trainer/Q2 Predictions Std     1.2625667
trainer/Q2 Predictions Max     105.408485
trainer/Q2 Predictions Min     91.85048
trainer/Q Targets Mean         102.47392
trainer/Q Targets Std          1.2675143
trainer/Q Targets Max          105.77433
trainer/Q Targets Min          91.35604
trainer/Log Pis Mean           12.457213
trainer/Log Pis Std            8.20197
trainer/Log Pis Max            71.245514
trainer/Log Pis Min            -3.998176
trainer/Policy mu Mean         0.07606899
trainer/Policy mu Std          1.5927082
trainer/Policy mu Max          6.505665
trainer/Policy mu Min          -6.159319
trainer/Policy log std Mean    -0.7673273
trainer/Policy log std Std     0.303789
trainer/Policy log std Max     0.49132615
trainer/Policy log std Min     -1.9150208
trainer/Alpha                  0.0013298713602125645
trainer/Alpha Loss             3.028048515319824
exploration/num steps total    3471000
exploration/num paths total    6942
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9394993127329279
exploration/Rewards Std        0.0809173988388864
exploration/Rewards Max        0.9794323954899185
exploration/Rewards Min        0.48939451511303755
exploration/Returns Mean       469.74965636646385
exploration/Returns Std        13.765103363269212
exploration/Returns Max        482.09582812863755
exploration/Returns Min        435.6150291258354
exploration/Actions Mean       0.08827513
exploration/Actions Std        0.67544043
exploration/Actions Max        0.9999889
exploration/Actions Min        -0.99998504
exploration/Num Paths          10
exploration/Average Returns    469.74965636646385
evaluation/num steps total     3470000
evaluation/num paths total     6940
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.931301194334614
evaluation/Rewards Std         0.08643953636611648
evaluation/Rewards Max         0.9795154304706521
evaluation/Rewards Min         0.49617256833810286
evaluation/Returns Mean        465.65059716730696
evaluation/Returns Std         7.921333359444903
evaluation/Returns Max         478.7045283957254
evaluation/Returns Min         451.8446692020503
evaluation/ExplReturns Mean    465.65059716730696
evaluation/ExplReturns Std     7.921333359444903
evaluation/ExplReturns Max     478.7045283957254
evaluation/ExplReturns Min     451.8446692020503
evaluation/Actions Mean        0.06168741
evaluation/Actions Std         0.65306723
evaluation/Actions Max         0.99999595
evaluation/Actions Min         -0.99998844
evaluation/Num Paths           10
evaluation/Average Returns     465.65059716730696
time/data storing (s)          0.033776165917515755
time/evaluation sampling (s)   142.61875593010336
time/exploration sampling (s)  143.51526930741966
time/logging (s)               0.041442942805588245
time/saving (s)                0.010785533115267754
time/training (s)              15.726481243036687
time/epoch (s)                 301.9465111223981
time/total (s)                 164216.3149104314
Epoch                          693
-----------------------------  ---------------------
2023-08-02 15:36:05.146572 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 694 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3884.9248]
trainer/QF1 Loss               0.014909891
trainer/QF2 Loss               0.0104024885
trainer/Policy Loss            -91.24219
trainer/Q1 Predictions Mean    102.5234
trainer/Q1 Predictions Std     1.0341126
trainer/Q1 Predictions Max     104.75504
trainer/Q1 Predictions Min     93.7951
trainer/Q2 Predictions Mean    102.5324
trainer/Q2 Predictions Std     1.0185714
trainer/Q2 Predictions Max     104.72724
trainer/Q2 Predictions Min     94.096794
trainer/Q Targets Mean         102.52813
trainer/Q Targets Std          1.0278798
trainer/Q Targets Max          104.52589
trainer/Q Targets Min          94.03302
trainer/Log Pis Mean           11.365631
trainer/Log Pis Std            7.310657
trainer/Log Pis Max            43.65207
trainer/Log Pis Min            -2.7628465
trainer/Policy mu Mean         0.0488687
trainer/Policy mu Std          1.5128146
trainer/Policy mu Max          4.74581
trainer/Policy mu Min          -5.074931
trainer/Policy log std Mean    -0.7818988
trainer/Policy log std Std     0.30769065
trainer/Policy log std Max     0.0403156
trainer/Policy log std Min     -2.044023
trainer/Alpha                  0.0013476258609443903
trainer/Alpha Loss             -4.192619323730469
exploration/num steps total    3476000
exploration/num paths total    6952
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.845593981772786
exploration/Rewards Std        0.13648239957512745
exploration/Rewards Max        0.9797432371756507
exploration/Rewards Min        0.4044561726067606
exploration/Returns Mean       422.7969908863932
exploration/Returns Std        33.51388257040012
exploration/Returns Max        459.2823340029256
exploration/Returns Min        359.8836093902785
exploration/Actions Mean       -0.05817162
exploration/Actions Std        0.73752856
exploration/Actions Max        1.0
exploration/Actions Min        -1.0
exploration/Num Paths          10
exploration/Average Returns    422.7969908863932
evaluation/num steps total     3475000
evaluation/num paths total     6950
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.8266982247008842
evaluation/Rewards Std         0.1223293472508363
evaluation/Rewards Max         0.9788531096672561
evaluation/Rewards Min         0.47899410630233286
evaluation/Returns Mean        413.349112350442
evaluation/Returns Std         32.56526542860312
evaluation/Returns Max         467.35935953910234
evaluation/Returns Min         370.0854293994642
evaluation/ExplReturns Mean    413.349112350442
evaluation/ExplReturns Std     32.56526542860312
evaluation/ExplReturns Max     467.35935953910234
evaluation/ExplReturns Min     370.0854293994642
evaluation/Actions Mean        0.057996493
evaluation/Actions Std         0.6085648
evaluation/Actions Max         0.9999848
evaluation/Actions Min         -1.0
evaluation/Num Paths           10
evaluation/Average Returns     413.349112350442
time/data storing (s)          0.03368535451591015
time/evaluation sampling (s)   141.20589554775506
time/exploration sampling (s)  141.364826570265
time/logging (s)               0.03779907803982496
time/saving (s)                0.01646693702787161
time/training (s)              15.9825669080019
time/epoch (s)                 298.64124039560556
time/total (s)                 164514.95857452974
Epoch                          694
-----------------------------  ---------------------
2023-08-02 15:41:06.160468 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 695 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3661.7612]
trainer/QF1 Loss               0.013446869
trainer/QF2 Loss               0.019924268
trainer/Policy Loss            -91.077965
trainer/Q1 Predictions Mean    102.311874
trainer/Q1 Predictions Std     2.7573886
trainer/Q1 Predictions Max     104.872284
trainer/Q1 Predictions Min     62.569317
trainer/Q2 Predictions Mean    102.31265
trainer/Q2 Predictions Std     2.7404687
trainer/Q2 Predictions Max     104.911
trainer/Q2 Predictions Min     62.792324
trainer/Q Targets Mean         102.34065
trainer/Q Targets Std          2.7304018
trainer/Q Targets Max          104.73082
trainer/Q Targets Min          63.11047
trainer/Log Pis Mean           11.299138
trainer/Log Pis Std            8.209427
trainer/Log Pis Max            75.64223
trainer/Log Pis Min            -8.503151
trainer/Policy mu Mean         0.19457696
trainer/Policy mu Std          1.5399191
trainer/Policy mu Max          6.2409096
trainer/Policy mu Min          -6.1489096
trainer/Policy log std Mean    -0.76760244
trainer/Policy log std Std     0.3067704
trainer/Policy log std Max     0.66852236
trainer/Policy log std Min     -2.3319368
trainer/Alpha                  0.001359567861072719
trainer/Alpha Loss             -4.6260986328125
exploration/num steps total    3481000
exploration/num paths total    6962
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.882165199918162
exploration/Rewards Std        0.11767265544769695
exploration/Rewards Max        0.9797339579533676
exploration/Rewards Min        0.4730027139360862
exploration/Returns Mean       441.0825999590808
exploration/Returns Std        43.33598869603192
exploration/Returns Max        475.75264176345456
exploration/Returns Min        372.74481918257
exploration/Actions Mean       0.10783736
exploration/Actions Std        0.6822197
exploration/Actions Max        1.0
exploration/Actions Min        -0.99999994
exploration/Num Paths          10
exploration/Average Returns    441.0825999590808
evaluation/num steps total     3480000
evaluation/num paths total     6960
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9496481660587613
evaluation/Rewards Std         0.046777557006412555
evaluation/Rewards Max         0.9784502173131617
evaluation/Rewards Min         0.4841118321491424
evaluation/Returns Mean        474.82408302938074
evaluation/Returns Std         4.016045179898342
evaluation/Returns Max         480.6489672259769
evaluation/Returns Min         469.3888033761021
evaluation/ExplReturns Mean    474.82408302938074
evaluation/ExplReturns Std     4.016045179898342
evaluation/ExplReturns Max     480.6489672259769
evaluation/ExplReturns Min     469.3888033761021
evaluation/Actions Mean        0.13111825
evaluation/Actions Std         0.67060906
evaluation/Actions Max         0.99936587
evaluation/Actions Min         -0.9992377
evaluation/Num Paths           10
evaluation/Average Returns     474.82408302938074
time/data storing (s)          0.03804487269371748
time/evaluation sampling (s)   142.953496822156
time/exploration sampling (s)  142.17678215820342
time/logging (s)               0.037156229838728905
time/saving (s)                0.011257318779826164
time/training (s)              15.787739044055343
time/epoch (s)                 301.00447644572705
time/total (s)                 164815.96591244917
Epoch                          695
-----------------------------  --------------------
2023-08-02 15:46:16.865913 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 696 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3764.3047]
trainer/QF1 Loss               0.077063575
trainer/QF2 Loss               0.059985686
trainer/Policy Loss            -89.85147
trainer/Q1 Predictions Mean    102.33185
trainer/Q1 Predictions Std     1.4380802
trainer/Q1 Predictions Max     106.26308
trainer/Q1 Predictions Min     89.072754
trainer/Q2 Predictions Mean    102.39754
trainer/Q2 Predictions Std     1.4262451
trainer/Q2 Predictions Max     106.440216
trainer/Q2 Predictions Min     89.44522
trainer/Q Targets Mean         102.37126
trainer/Q Targets Std          1.5316058
trainer/Q Targets Max          106.3501
trainer/Q Targets Min          88.88627
trainer/Log Pis Mean           12.5944195
trainer/Log Pis Std            8.198414
trainer/Log Pis Max            47.84961
trainer/Log Pis Min            -1.047317
trainer/Policy mu Mean         0.1860135
trainer/Policy mu Std          1.5839175
trainer/Policy mu Max          8.119236
trainer/Policy mu Min          -6.175255
trainer/Policy log std Mean    -0.78750676
trainer/Policy log std Std     0.2992715
trainer/Policy log std Max     0.24739718
trainer/Policy log std Min     -2.025132
trainer/Alpha                  0.001364518073387444
trainer/Alpha Loss             3.9214940071105957
exploration/num steps total    3486000
exploration/num paths total    6972
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9612159638067141
exploration/Rewards Std        0.047734048855030436
exploration/Rewards Max        0.9786538668503856
exploration/Rewards Min        0.49554512818063423
exploration/Returns Mean       480.6079819033572
exploration/Returns Std        1.1470564712554423
exploration/Returns Max        482.2247746041734
exploration/Returns Min        479.2692026851676
exploration/Actions Mean       0.094085075
exploration/Actions Std        0.6835829
exploration/Actions Max        0.9999328
exploration/Actions Min        -0.999987
exploration/Num Paths          10
exploration/Average Returns    480.6079819033572
evaluation/num steps total     3485000
evaluation/num paths total     6970
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9486256884223643
evaluation/Rewards Std         0.062428290599092315
evaluation/Rewards Max         0.979161332257898
evaluation/Rewards Min         0.4929450973868459
evaluation/Returns Mean        474.31284421118215
evaluation/Returns Std         12.596142620770664
evaluation/Returns Max         482.819496414418
evaluation/Returns Min         436.8709033694645
evaluation/ExplReturns Mean    474.31284421118215
evaluation/ExplReturns Std     12.596142620770664
evaluation/ExplReturns Max     482.819496414418
evaluation/ExplReturns Min     436.8709033694645
evaluation/Actions Mean        0.105650984
evaluation/Actions Std         0.65870315
evaluation/Actions Max         0.9995796
evaluation/Actions Min         -0.99978215
evaluation/Num Paths           10
evaluation/Average Returns     474.31284421118215
time/data storing (s)          0.04569143150001764
time/evaluation sampling (s)   137.26975040510297
time/exploration sampling (s)  155.2330005178228
time/logging (s)               0.052577678114175797
time/saving (s)                0.016435448080301285
time/training (s)              18.09481172915548
time/epoch (s)                 310.71226720977575
time/total (s)                 165126.68117456697
Epoch                          696
-----------------------------  --------------------
2023-08-02 15:51:56.042677 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 697 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3610.3723]
trainer/QF1 Loss               0.03823159
trainer/QF2 Loss               0.019193083
trainer/Policy Loss            -90.87933
trainer/Q1 Predictions Mean    102.56516
trainer/Q1 Predictions Std     1.0459044
trainer/Q1 Predictions Max     104.16442
trainer/Q1 Predictions Min     96.314705
trainer/Q2 Predictions Mean    102.51131
trainer/Q2 Predictions Std     1.0384843
trainer/Q2 Predictions Max     104.14282
trainer/Q2 Predictions Min     97.10529
trainer/Q Targets Mean         102.4573
trainer/Q Targets Std          1.0879223
trainer/Q Targets Max          104.06071
trainer/Q Targets Min          96.42244
trainer/Log Pis Mean           11.728794
trainer/Log Pis Std            7.8803425
trainer/Log Pis Max            45.455605
trainer/Log Pis Min            -4.2963004
trainer/Policy mu Mean         0.18705274
trainer/Policy mu Std          1.5108082
trainer/Policy mu Max          5.035431
trainer/Policy mu Min          -6.085253
trainer/Policy log std Mean    -0.81128246
trainer/Policy log std Std     0.30660853
trainer/Policy log std Max     0.03281045
trainer/Policy log std Min     -2.21071
trainer/Alpha                  0.001370715326629579
trainer/Alpha Loss             -1.7879098653793335
exploration/num steps total    3491000
exploration/num paths total    6982
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9568008229743551
exploration/Rewards Std        0.05855768975051006
exploration/Rewards Max        0.9793798744353173
exploration/Rewards Min        0.49857206320543174
exploration/Returns Mean       478.4004114871776
exploration/Returns Std        8.851728185784566
exploration/Returns Max        481.89635405211925
exploration/Returns Min        451.89736732619025
exploration/Actions Mean       0.019401327
exploration/Actions Std        0.6165983
exploration/Actions Max        0.99999005
exploration/Actions Min        -0.99999505
exploration/Num Paths          10
exploration/Average Returns    478.4004114871776
evaluation/num steps total     3490000
evaluation/num paths total     6980
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9620853638649034
evaluation/Rewards Std         0.047237876427364454
evaluation/Rewards Max         0.9791403113497141
evaluation/Rewards Min         0.496703611966748
evaluation/Returns Mean        481.0426819324517
evaluation/Returns Std         0.2519588062970207
evaluation/Returns Max         481.4350881428377
evaluation/Returns Min         480.59349128475026
evaluation/ExplReturns Mean    481.0426819324517
evaluation/ExplReturns Std     0.2519588062970207
evaluation/ExplReturns Max     481.4350881428377
evaluation/ExplReturns Min     480.59349128475026
evaluation/Actions Mean        0.0076408978
evaluation/Actions Std         0.55767524
evaluation/Actions Max         0.99937135
evaluation/Actions Min         -0.9998866
evaluation/Num Paths           10
evaluation/Average Returns     481.0426819324517
time/data storing (s)          0.03989094402641058
time/evaluation sampling (s)   159.41427119076252
time/exploration sampling (s)  161.7884323010221
time/logging (s)               0.04160856734961271
time/saving (s)                0.01323541346937418
time/training (s)              17.857804126106203
time/epoch (s)                 339.15524254273623
time/total (s)                 165465.83940314408
Epoch                          697
-----------------------------  --------------------
2023-08-02 15:57:40.348542 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 698 finished
-----------------------------  --------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3995.135]
trainer/QF1 Loss               0.019623343
trainer/QF2 Loss               0.020212801
trainer/Policy Loss            -90.8817
trainer/Q1 Predictions Mean    102.55733
trainer/Q1 Predictions Std     1.0113696
trainer/Q1 Predictions Max     103.96439
trainer/Q1 Predictions Min     95.52018
trainer/Q2 Predictions Mean    102.499985
trainer/Q2 Predictions Std     0.9780474
trainer/Q2 Predictions Max     103.81133
trainer/Q2 Predictions Min     95.35992
trainer/Q Targets Mean         102.50798
trainer/Q Targets Std          1.0171957
trainer/Q Targets Max          103.85547
trainer/Q Targets Min          95.39753
trainer/Log Pis Mean           11.707001
trainer/Log Pis Std            7.6682835
trainer/Log Pis Max            52.050636
trainer/Log Pis Min            -2.8174477
trainer/Policy mu Mean         0.22765465
trainer/Policy mu Std          1.5200076
trainer/Policy mu Max          4.9281096
trainer/Policy mu Min          -6.012496
trainer/Policy log std Mean    -0.79046416
trainer/Policy log std Std     0.3127552
trainer/Policy log std Max     -0.027277589
trainer/Policy log std Min     -2.2068913
trainer/Alpha                  0.001370509504340589
trainer/Alpha Loss             -1.931612491607666
exploration/num steps total    3496000
exploration/num paths total    6992
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9643258202317525
exploration/Rewards Std        0.0510451351252615
exploration/Rewards Max        0.9794235153091165
exploration/Rewards Min        0.496400113901321
exploration/Returns Mean       482.1629101158763
exploration/Returns Std        0.49115036517793265
exploration/Returns Max        482.92166959053554
exploration/Returns Min        481.11330547310496
exploration/Actions Mean       0.15279096
exploration/Actions Std        0.70734894
exploration/Actions Max        0.9998896
exploration/Actions Min        -0.9999649
exploration/Num Paths          10
exploration/Average Returns    482.1629101158763
evaluation/num steps total     3495000
evaluation/num paths total     6990
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9627174803859369
evaluation/Rewards Std         0.050442957911384076
evaluation/Rewards Max         0.9796203317644032
evaluation/Rewards Min         0.4940765874540045
evaluation/Returns Mean        481.3587401929684
evaluation/Returns Std         1.1487614081782729
evaluation/Returns Max         482.6586590581324
evaluation/Returns Min         479.47250398646634
evaluation/ExplReturns Mean    481.3587401929684
evaluation/ExplReturns Std     1.1487614081782729
evaluation/ExplReturns Max     482.6586590581324
evaluation/ExplReturns Min     479.47250398646634
evaluation/Actions Mean        0.14088534
evaluation/Actions Std         0.6474741
evaluation/Actions Max         0.99928135
evaluation/Actions Min         -0.9999249
evaluation/Num Paths           10
evaluation/Average Returns     481.3587401929684
time/data storing (s)          0.03885926678776741
time/evaluation sampling (s)   163.06106109637767
time/exploration sampling (s)  163.56320787593722
time/logging (s)               0.04552060645073652
time/saving (s)                0.018003011122345924
time/training (s)              17.57135143596679
time/epoch (s)                 344.29800329264253
time/total (s)                 165810.14333087113
Epoch                          698
-----------------------------  --------------------
2023-08-02 16:03:20.824807 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 699 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3368.7915]
trainer/QF1 Loss               0.020827211
trainer/QF2 Loss               0.014554083
trainer/Policy Loss            -90.39537
trainer/Q1 Predictions Mean    102.35786
trainer/Q1 Predictions Std     2.095966
trainer/Q1 Predictions Max     105.37671
trainer/Q1 Predictions Min     72.97877
trainer/Q2 Predictions Mean    102.36415
trainer/Q2 Predictions Std     2.0866177
trainer/Q2 Predictions Max     105.41581
trainer/Q2 Predictions Min     73.07322
trainer/Q Targets Mean         102.31592
trainer/Q Targets Std          2.1062515
trainer/Q Targets Max          105.38478
trainer/Q Targets Min          72.451584
trainer/Log Pis Mean           12.063509
trainer/Log Pis Std            7.7521167
trainer/Log Pis Max            63.848854
trainer/Log Pis Min            -4.1075253
trainer/Policy mu Mean         0.12432075
trainer/Policy mu Std          1.549014
trainer/Policy mu Max          7.8341985
trainer/Policy mu Min          -5.3233757
trainer/Policy log std Mean    -0.7771855
trainer/Policy log std Std     0.3168162
trainer/Policy log std Max     0.4779482
trainer/Policy log std Min     -2.1193616
trainer/Alpha                  0.0013185825664550066
trainer/Alpha Loss             0.42114174365997314
exploration/num steps total    3501000
exploration/num paths total    7002
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9634408301421614
exploration/Rewards Std        0.048040686771736486
exploration/Rewards Max        0.978490614832688
exploration/Rewards Min        0.49663880906433366
exploration/Returns Mean       481.72041507108077
exploration/Returns Std        1.37452304584316
exploration/Returns Max        483.5066512779348
exploration/Returns Min        478.9925927601734
exploration/Actions Mean       0.123422444
exploration/Actions Std        0.7008911
exploration/Actions Max        0.99993217
exploration/Actions Min        -0.99995553
exploration/Num Paths          10
exploration/Average Returns    481.72041507108077
evaluation/num steps total     3500000
evaluation/num paths total     7000
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9637173864199265
evaluation/Rewards Std         0.04898311641308302
evaluation/Rewards Max         0.9794953397614106
evaluation/Rewards Min         0.489385078028322
evaluation/Returns Mean        481.85869320996346
evaluation/Returns Std         1.3307975143731023
evaluation/Returns Max         484.04809556890064
evaluation/Returns Min         480.2239665646439
evaluation/ExplReturns Mean    481.85869320996346
evaluation/ExplReturns Std     1.3307975143731023
evaluation/ExplReturns Max     484.04809556890064
evaluation/ExplReturns Min     480.2239665646439
evaluation/Actions Mean        0.11379303
evaluation/Actions Std         0.69783366
evaluation/Actions Max         0.9987882
evaluation/Actions Min         -0.99986655
evaluation/Num Paths           10
evaluation/Average Returns     481.85869320996346
time/data storing (s)          0.04428432788699865
time/evaluation sampling (s)   161.04763663373888
time/exploration sampling (s)  162.4958600718528
time/logging (s)               0.0461213905364275
time/saving (s)                0.017358778975903988
time/training (s)              16.816518939100206
time/epoch (s)                 340.4677801420912
time/total (s)                 166150.61413539108
Epoch                          699
-----------------------------  ---------------------
2023-08-02 16:09:01.656099 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 700 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3470.592]
trainer/QF1 Loss               0.023133978
trainer/QF2 Loss               0.01564003
trainer/Policy Loss            -91.282715
trainer/Q1 Predictions Mean    102.26048
trainer/Q1 Predictions Std     1.2627493
trainer/Q1 Predictions Max     105.31532
trainer/Q1 Predictions Min     90.17927
trainer/Q2 Predictions Mean    102.26936
trainer/Q2 Predictions Std     1.3079369
trainer/Q2 Predictions Max     105.22121
trainer/Q2 Predictions Min     89.298546
trainer/Q Targets Mean         102.32936
trainer/Q Targets Std          1.2979013
trainer/Q Targets Max          105.46818
trainer/Q Targets Min          89.4659
trainer/Log Pis Mean           11.061686
trainer/Log Pis Std            7.716045
trainer/Log Pis Max            42.812523
trainer/Log Pis Min            -8.124038
trainer/Policy mu Mean         0.042681083
trainer/Policy mu Std          1.5019844
trainer/Policy mu Max          4.7778907
trainer/Policy mu Min          -5.5453568
trainer/Policy log std Mean    -0.8108833
trainer/Policy log std Std     0.3114948
trainer/Policy log std Max     0.40986192
trainer/Policy log std Min     -2.339751
trainer/Alpha                  0.0012506681960076094
trainer/Alpha Loss             -6.271580696105957
exploration/num steps total    3506000
exploration/num paths total    7012
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9639535675114165
exploration/Rewards Std        0.04799267131443116
exploration/Rewards Max        0.9795610223812009
exploration/Rewards Min        0.48742384053144827
exploration/Returns Mean       481.9767837557082
exploration/Returns Std        1.0972834991738798
exploration/Returns Max        482.89431950642233
exploration/Returns Min        479.16518382381804
exploration/Actions Mean       0.06700695
exploration/Actions Std        0.6219422
exploration/Actions Max        0.9999488
exploration/Actions Min        -0.99999225
exploration/Num Paths          10
exploration/Average Returns    481.9767837557082
evaluation/num steps total     3505000
evaluation/num paths total     7010
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9652602706286587
evaluation/Rewards Std         0.04787676000792289
evaluation/Rewards Max         0.9791001047300757
evaluation/Rewards Min         0.48195524603925455
evaluation/Returns Mean        482.6301353143293
evaluation/Returns Std         1.0690522288312483
evaluation/Returns Max         483.574705501078
evaluation/Returns Min         479.8389797838996
evaluation/ExplReturns Mean    482.6301353143293
evaluation/ExplReturns Std     1.0690522288312483
evaluation/ExplReturns Max     483.574705501078
evaluation/ExplReturns Min     479.8389797838996
evaluation/Actions Mean        0.025261149
evaluation/Actions Std         0.52907026
evaluation/Actions Max         0.99951214
evaluation/Actions Min         -0.9997627
evaluation/Num Paths           10
evaluation/Average Returns     482.6301353143293
time/data storing (s)          0.051584936678409576
time/evaluation sampling (s)   157.73487032204866
time/exploration sampling (s)  164.65981581248343
time/logging (s)               0.04250284377485514
time/saving (s)                0.14418476168066263
time/training (s)              18.181681877933443
time/epoch (s)                 340.81464055459946
time/total (s)                 166491.4332159739
Epoch                          700
-----------------------------  ---------------------
2023-08-02 16:14:41.246121 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 701 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3496.793]
trainer/QF1 Loss               0.026472794
trainer/QF2 Loss               0.024239898
trainer/Policy Loss            -91.77435
trainer/Q1 Predictions Mean    102.256546
trainer/Q1 Predictions Std     1.1631023
trainer/Q1 Predictions Max     105.18261
trainer/Q1 Predictions Min     92.67762
trainer/Q2 Predictions Mean    102.249374
trainer/Q2 Predictions Std     1.1921076
trainer/Q2 Predictions Max     104.98153
trainer/Q2 Predictions Min     92.07244
trainer/Q Targets Mean         102.363556
trainer/Q Targets Std          1.1950862
trainer/Q Targets Max          105.06712
trainer/Q Targets Min          91.838646
trainer/Log Pis Mean           10.531646
trainer/Log Pis Std            7.4051723
trainer/Log Pis Max            45.31301
trainer/Log Pis Min            -5.513467
trainer/Policy mu Mean         0.1454666
trainer/Policy mu Std          1.4754212
trainer/Policy mu Max          4.646742
trainer/Policy mu Min          -5.051338
trainer/Policy log std Mean    -0.8208852
trainer/Policy log std Std     0.30224693
trainer/Policy log std Max     0.17484641
trainer/Policy log std Min     -2.228606
trainer/Alpha                  0.0012311128666624427
trainer/Alpha Loss             -9.837701797485352
exploration/num steps total    3511000
exploration/num paths total    7022
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.8891094572764058
exploration/Rewards Std        0.12364141365794847
exploration/Rewards Max        0.9779238886677556
exploration/Rewards Min        0.49965379518283043
exploration/Returns Mean       444.55472863820296
exploration/Returns Std        38.579213483463654
exploration/Returns Max        481.9747551526905
exploration/Returns Min        381.18779405176343
exploration/Actions Mean       0.04977672
exploration/Actions Std        0.628575
exploration/Actions Max        0.9999949
exploration/Actions Min        -0.999994
exploration/Num Paths          10
exploration/Average Returns    444.55472863820296
evaluation/num steps total     3510000
evaluation/num paths total     7020
evaluation/path length Mean    500.0
evaluation/path length Std     0.0
evaluation/path length Max     500
evaluation/path length Min     500
evaluation/Rewards Mean        0.9065859427827668
evaluation/Rewards Std         0.1181503255005286
evaluation/Rewards Max         0.9799016102763514
evaluation/Rewards Min         0.5040287531487719
evaluation/Returns Mean        453.29297139138345
evaluation/Returns Std         44.385728204419465
evaluation/Returns Max         483.8265275973875
evaluation/Returns Min         373.2373621039282
evaluation/ExplReturns Mean    453.29297139138345
evaluation/ExplReturns Std     44.385728204419465
evaluation/ExplReturns Max     483.8265275973875
evaluation/ExplReturns Min     373.2373621039282
evaluation/Actions Mean        0.04931039
evaluation/Actions Std         0.56535196
evaluation/Actions Max         0.9999162
evaluation/Actions Min         -0.99986386
evaluation/Num Paths           10
evaluation/Average Returns     453.29297139138345
time/data storing (s)          0.03981985151767731
time/evaluation sampling (s)   160.97756641544402
time/exploration sampling (s)  160.35649554338306
time/logging (s)               0.05195157416164875
time/saving (s)                0.02096214797347784
time/training (s)              18.144021820276976
time/epoch (s)                 339.59081735275686
time/total (s)                 166831.02708871383
Epoch                          701
-----------------------------  ---------------------
2023-08-02 16:19:36.614431 CST | [TwoArmPegInHole_PandaPanda_OSC_POSE_SEED17_2023_07_31_17_54_08_0000--s-0] Epoch 702 finished
-----------------------------  ---------------------
replay_buffer/size             1000000
trainer/tdrp Loss              [3406.2988]
trainer/QF1 Loss               0.027811956
trainer/QF2 Loss               0.0153159555
trainer/Policy Loss            -89.80969
trainer/Q1 Predictions Mean    102.268845
trainer/Q1 Predictions Std     1.5691963
trainer/Q1 Predictions Max     103.546165
trainer/Q1 Predictions Min     92.003586
trainer/Q2 Predictions Mean    102.2039
trainer/Q2 Predictions Std     1.5445263
trainer/Q2 Predictions Max     103.442825
trainer/Q2 Predictions Min     91.527534
trainer/Q Targets Mean         102.16518
trainer/Q Targets Std          1.5172186
trainer/Q Targets Max          103.43074
trainer/Q Targets Min          91.96165
trainer/Log Pis Mean           12.490585
trainer/Log Pis Std            9.032847
trainer/Log Pis Max            72.45118
trainer/Log Pis Min            -6.589463
trainer/Policy mu Mean         0.183213
trainer/Policy mu Std          1.5775144
trainer/Policy mu Max          5.666498
trainer/Policy mu Min          -5.9700446
trainer/Policy log std Mean    -0.81919193
trainer/Policy log std Std     0.31914055
trainer/Policy log std Max     0.18268478
trainer/Policy log std Min     -2.2922938
trainer/Alpha                  0.0012126227375119925
trainer/Alpha Loss             3.294325351715088
exploration/num steps total    3516000
exploration/num paths total    7032
exploration/path length Mean   500.0
exploration/path length Std    0.0
exploration/path length Max    500
exploration/path length Min    500
exploration/Rewards Mean       0.9609015231879413
exploration/Rewards Std        0.054877000648240325
exploration/Rewards Max        0.9793558941381835
exploration/Rewards Min        0.4988383943720588
exploration/Returns Mean       480.4507615939707
exploration/Returns Std        4.158389353801424
exploration/Returns Max        